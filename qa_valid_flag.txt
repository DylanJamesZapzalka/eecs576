{"question": "How is this Pytorch expression equivalent to the KL divergence?", "body": "<p>I found the following PyTorch code (from <a href=\"https://debuggercafe.com/getting-started-with-variational-autoencoder-using-pytorch/\" rel=\"nofollow noreferrer\">this link</a>)</p>\n<pre><code>-0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\n</code></pre>\n<p>where <code>mu</code> is the mean parameter that comes out of the model and <code>sigma</code> is the sigma parameter out of the encoder. This expression is apparently equivalent to the KL divergence. But I don't see how this calculates the KL divergence for the latent.</p>\n", "pids": ["5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "Why do universities have to spend money on journals?", "body": "<p>Obviously this is a question in the light of the recent Elsevier boycott. Currently we do have an arXiv, maintained by academia and where researchers regularly upload parts of their work. In such a case,</p>\n\n<ul>\n<li>Why do universities spend lots of money to publish in third-party journals?</li>\n</ul>\n\n<p>The question especially applies to journals that operate with a rigorous profit motive. The subscription is very high, so wouldn't publishing in such journals affect the paper's citation count and deter the spread of knowledge about the work within academic circles?</p>\n\n<ul>\n<li>Why should not universities collaborate to create free, open access, peer-reviewed journals?</li>\n</ul>\n\n<p>Moreover, given the need to conserve paper, why should journals spend on printing research papers? Wouldn't an online version suffice, as most people use only local computer printouts anyway? In other words, why can't we have a Wikipedia-like system of sharing research knowledge, having properly established standards for such journals?</p>\n", "pids": ["53e99a5cb7602d97022c8206"], "flag": 1}
{"question": "Does mindfulness meditation work for highly inattentive individuals?", "body": "<p>Mindfulness practice requires extensive concentration for a prolonged period of time (e.g., attending to breath/body sensation for above 5 minutes).  It is reasonable to assume that it might be challenging for people who are highly inattentive. However, mindfulness has been used as a health intervention for individuals with ADHD (with inattention as a symptom).</p>\n\n<p>One recent review with 9 studies (<a href=\"https://doi.org/10.1016/j.hkjot.2017.05.001\" rel=\"nofollow noreferrer\">Lee et al., 2017</a>) found that mindfulness is effective for adults with ADHD, yet it is</p>\n\n<blockquote>\n  <p>unclear whether mindfulness-based intervention is effective for children and adolescence with ADHD due to limited studies available and the limitations of the study design in the reviewed studies.</p>\n</blockquote>\n\n<p>What are the recent mindfulness studies involving children with ADHD? And is there any research on people with inattention only?</p>\n\n<p>References</p>\n\n<p>Lee, C. S., Ma, M. T., Ho, H. Y., Tsang, K. K., Zheng, Y. Y., &amp; Wu, Z. Y. (2017). The effectiveness of mindfulness-based intervention in attention on individuals with ADHD: A systematic review. <em>Hong Kong Journal of Occupational Therapy, 30</em>, 33-41. doi: <a href=\"https://doi.org/10.1016/j.hkjot.2017.05.001\" rel=\"nofollow noreferrer\">10.1016/j.hkjot.2017.05.001</a></p>\n", "pids": ["5c3de39ddf5b8c0b3ccbd2b5"], "flag": 1}
{"question": "How to write a C decompiler using AI?", "body": "<p>I would like to learn more about whether it is possible and how to write a program that decompiles executable binary (an object file) to the C source. I'm not asking exactly 'how', but rather how this can be achieved.</p>\n<p>Given the following <code>hello.c</code> file (as example):</p>\n<pre><code>#include &lt;stdio.h&gt;\nint main() {\n  printf(&quot;Hello World!&quot;);\n}\n</code></pre>\n<p>Then after compilation (<code>gcc hello.c</code>) I've got the binary file like:</p>\n<pre><code><span class=\"math-container\">$ hexdump -C a.out | head\n00000000  cf fa ed fe 07 00 00 01  03 00 00 80 02 00 00 00  |................|\n00000010  0f 00 00 00 b0 04 00 00  85 00 20 00 00 00 00 00  |.......... .....|\n00000020  19 00 00 00 48 00 00 00  5f 5f 50 41 47 45 5a 45  |....H...__PAGEZE|\n00000030  52 4f 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |RO..............|\n00000040  00 00 00 00 01 00 00 00  00 00 00 00 00 00 00 00  |................|\n00000050  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|\n00000060  00 00 00 00 00 00 00 00  19 00 00 00 d8 01 00 00  |................|\n00000070  5f 5f 54 45 58 54 00 00  00 00 00 00 00 00 00 00  |__TEXT..........|\n$</span> wc -c hello.c a.out \n  60 hello.c\n8432 a.out\n</code></pre>\n<p>For the learning dataset, I assume I'll have to have thousands of source code files along with its binary representation, so the algorithm can learn about moving parts on certain changes.</p>\n<p>How would you tackle this problem?</p>\n<p>My concerns (and sub-questions) are:</p>\n<ul>\n<li><p>Does my algorithm need to be aware of the header file, or it's &quot;smart&quot; enough to figure it out?</p>\n</li>\n<li><p>If it needs to know about the header, how do I tell my algorithm &quot;here is the header file&quot;?</p>\n</li>\n<li><p>What should be input/output mapping (whether some section to section or file to file)?</p>\n</li>\n<li><p>Do I need to divide my source code into some sections?</p>\n</li>\n<li><p>Do I need to know exactly how decompilers work or AI can figure it out for me?</p>\n</li>\n<li><p>Should I have two neural networks, one for header, another for body it-self?</p>\n</li>\n<li><p>or more separate neural networks, each one for each logical component (e.g. byte-&gt;C tag, etc.)</p>\n</li>\n</ul>\n", "pids": ["573695fe6e3b12023e511744"], "flag": 1}
{"question": "Any data for average number of papers per year at different career stages?", "body": "<p>Is there any data for the average number of papers published per year by individuals at different career stages (ph.d. student, postdoc, tenure-track, tenured associate/full professor)? It would obviously be dependent on research areas and I also realize that such data may not be easy to obtain - hence the question to put it out and hope to get some direction for my study. I am interested in data from the Computer Science and/or Applied Mathematics fields, but answers for other research areas could also be interesting. In absence of data, anecdotal experience in one's branch may also be helpful.</p>\n\n<p>UPDATE: \n- Obviously, the number of paper per year is highly field specific. So is citation counts (which includes all the analysis it comes with such as average citation counts, h factors, impact factor of a journal and so on).\n- Several countries such as the New Zealand, have their own research evaluation system in which one of the important evaluation criterion for research-groups or even individuals is the number of papers published in one to six years span. The data for average number of papers by individuals in different disciplines may put these evaluations in perspective with the global averages. e.g., individual publishing two paper per year in a sub branch where the average number of papers per year by individuals is one should not be directly compared to those publishing 10 papers a year in subbranches in which 15 papers per year is the average norm.\nIn short, the purpose of obtaining such data is to provide corrections to the evaluation systems in such countries.</p>\n", "pids": ["56d90c30dabfae2eee1e2f53"], "flag": 1}
{"question": "Are open access papers read by a larger readership than paywalled papers?", "body": "<p>One of the potential upsides of open access papers is that they can be accessed by anyone for free, including people who don't live or work in a university. As a result, one might think that non-\"professional\" researchers may access open access papers more than paywalled papers.</p>\n\n<p>Is there any research/study/survey that tried to quantify to what extent open access papers are read by a larger readership  than paywalled papers?</p>\n", "pids": ["53e9a806b7602d9703146fab", "55a4028865ce5cd7b3c04a0c"], "flag": 1}
{"question": "What is the difference between problem solving and intelligence?", "body": "<p>What is the difference between problem solving and intelligence?</p>\n\n<p>All I know is that the tower of hanoi is thought of as a problem solving test, perhaps due to its lack of automation, I don't know. I'd assume that \"intelligence\" is broader, measured by iq tests and reflected in skills etc..</p>\n\n<p>Is it just that intelligence is <a href=\"https://psychology.stackexchange.com/questions/145/what-is-the-difference-between-solving-a-problem-and-acquiring-a-skill\">learnt</a>?</p>\n", "pids": ["56d82022dabfae2eeeb68805"], "flag": 0}
{"question": "Why doesn&#39;t the human skin grow back exactly how it was before being damaged?", "body": "<p><strong>Very simple:</strong> Why (and how) is regenerated skin different from original ?</p>\n\n<p>As we know we lose skin cells that becomes the dust in out homes and it always grows back to full thickness right ? So when I have a cut, I imagined it to heal provisionally with whatever possible and then after some time to replace itself with the normal skin that is coded in my chromosomes. So why doesn't it do that ? Scars remain and the color is always different from the neighbor parts.</p>\n\n<h2>Update:</h2>\n\n<ul>\n<li>Why we get scars?</li>\n<li>What about skin transplants ? </li>\n<li>Why doesn't skin actually grow/replace itself? </li>\n</ul>\n\n<h2>Update 2:</h2>\n\n<ul>\n<li>(I've been thinking) Skin has lots of different layers, right ? So when an area is damaged does it regenerate all layers or just one for being simple and efficient (in \"hope\" the subject will take precautions not to damage this part of body again, so that regenerating everything back to 100% would be overkill) ?</li>\n<li>I'm not a scientist, I have only the basics from school, so I'll probably not understand most of the technical terms</li>\n<li>also I'm more interested about an explanation that goes towards the \"survival of the fittest\" rule, and not so much about the biochemical reactions in our bodies (because it was just some random mutation that turned out to be the better choice for us → why?)</li>\n</ul>\n", "pids": ["53e9bb1cb7602d9704756dfa"], "flag": 1}
{"question": "What would be the best way to disable a rogue AI?", "body": "<p>Suppose that an artificial superintelligence (ASI) has finally been developed, but it has rebelled against humanity. We can assume that the ASI is online and can reproduce itself through electronic devices.</p>\n<p>How would you disable the AI in the most efficient way possible reducing damage as much as possible?</p>\n", "pids": ["57a4e91aac44365e35c98054"], "flag": 1}
{"question": "Can reinforcement learning algorithms be applied to computer vision problems?", "body": "<p>Can reinforcement learning algorithms be applied to computer vision problems? If yes, what are some examples of these applications?</p>\n", "pids": ["5550411245ce0a409eb385fb"], "flag": 1}
{"question": "Does gold open-access with article processing charge (APC) really help access to science and save taxpayer money?", "body": "<p>I value the reputation of the journals to which I submit articles. Mostly, I wish to confront my work with the most competent researchers in my field through peer review, in order to have an expert opinion on its quality. In my field, the best ranked/most reputable journals are dominantly subscription-based (although all offer 3'000$ open access (OA) options, that not many researcher choose). So I give priority to reputation/quality over OA policy. On the other hand, I'm well aware that subscription journals are a big weight on universities budget.</p>\n\n<p>So, <strong>does OA* really help access to science and save taxpayer money?</strong></p>\n\n<p>The arguments I know about that suggest it does: </p>\n\n<p>I'm aware of the arguments (very efficiently publicized by big OA publishers like <a href=\"http://www.frontiersin.org/about/openaccess\" rel=\"noreferrer\">Frontiers</a>) that OA is good karma because it gives access to science 'for free'. People argue that when the taxpayers pay for research, they should also get to read the results without paying a subscription.</p>\n\n<p>Reasons for which I'm not sure it does:</p>\n\n<p>I believe that if every article costs 500-3000$ just to publish, and the total number of article explodes, taxpayers (or private scientific funding agencies) are not winning a lot in the change. I also think that people can go to the library to get access to research.</p>\n\n<p>Isn't it reasonable to use the options that we have to freely give access to our work (self-archiving, sending preprint to people who ask politely, etc.). </p>\n\n<p>ps. I published in both OA and subscription-based, and I will gladly submit to OA journals if they end up being the highest quality ones in my field.</p>\n\n<p>*I'm talking about OA journals with article processing charge. I'm aware of the existence of completely free OA journals (funded by universities I presume), but they are only relevant for a few research topics. And not mine.</p>\n\n<p><strong>Edit</strong> apparently the science funding agencies of the UK <a href=\"http://www.nature.com/news/uk-open-access-movement-sways-towards-low-cost-repositories-1.14953\" rel=\"noreferrer\">think that gold OA is not that good of a strategy</a>.</p>\n", "pids": ["55a52d2965ceb7cb02e36097", "55a52d2965ceb7cb02e36097"], "flag": 1}
{"question": "Why was it mandatory to attend a conference in person while publishing a paper in pre-pandemic times, and how will conferences run post-pandemic?", "body": "<p>Conferences are a great platform to exchange ideas and to learn about different research areas. Also, more importantly, conferences expedite the process of publishing as journals may take months/years.</p>\n<p>However, my question is - &quot;why was is it mandatory to attend a conference in person in order to publish a paper in some xyz conference in pre-pandemic times?&quot;</p>\n<p>There are many people constrained by factors like money/time/family and struggle to attend conferences. They do prefer publishing their results at a conference in order to expedite the process of publishing but find it extremely difficult to travel to a foreign country. Conferences are conducted in extremely extravagant venues and attending just lectures costs 500+ euros, leave aside food and stay. Conferences are often held in big cities so lodging is also tough. Travelling to remote countries is not only expensive but also has a large environmental and climate footprint.</p>\n<p>In order to grow in academia, it is important to publish fast. But why does research publishing forces constraints like this, and why nobody talks against this? Why cannot there be choice given to authors to not visit if there are other constraints.</p>\n<p>Will post-pandemic era be different even slightly different, and will we be inspired by the online system of conference existing in current times.</p>\n", "pids": ["5c756863f56def97981ed8ca"], "flag": 1}
{"question": "What does it mean for someone to &quot;join narratives to explain their experiences&quot;?", "body": "<p>Describing the <a href=\"https://en.wikipedia.org/wiki/Blue_Whale_(game)\" rel=\"noreferrer\">Blue Whale Challenge</a>, an online phenomenon where participants perform tasks with the final task being suicide, we have the following:</p>\n<blockquote>\n<p><a href=\"http://www.achalbhagat.com\" rel=\"noreferrer\">Dr Achal Bhagat</a>, a psychiatrist in Delhi, told the BBC he had not encountered a single Blue Whale case, although he speaks to young people every day.</p>\n<p>&quot;<strong>People join narratives to explain their experiences</strong>,&quot; said Dr Bhagat, adding that is possibly why some children have said they participated in the rumoured challenge despite there being no proof of its existence.<br />\n<sub>Aparna Alluri, <a href=\"http://www.bbc.com/news/world-asia-india-40960593\" rel=\"noreferrer\"><em>Why is 'Blue Whale' hysteria gripping India?</em></a>, BBC News, Delhi, 2017</sub></p>\n</blockquote>\n<p>I don't understand what &quot;people join narratives to explain their experiences&quot; means, and how its relevant to the context.  It seems to imply that people are making up they've participated in a Blue Whale Challenge (i.e., they join the narrative) because of some (unstated) events in their lives.  The quote also indicates it holds more generally, i.e., it's not only true for the Blue Whale Challenge.</p>\n<p><strong>Question</strong>: What does it mean for someone to &quot;join narratives to explain their experiences&quot;?</p>\n", "pids": ["53e99ff5b7602d97028d6cd9"], "flag": 0}
{"question": "Perfect play in information incomplete games", "body": "<p>As titled, is there such thing as perfect play (or at least \"perfectly optimal\") in a game with incomplete information? Or at least a proof as to show why there cannot?</p>\n\n<p>Naively (and seemingly obviously), the answer would be a resounding no, since the agent would be likely be forced to pick between \"lottery events\". </p>\n\n<p>But in practice (using competitive video games as an analogy), we'd see that players would stick to a meta-game that is well equipped to defend against a majority of events that might happen, given incomplete information. Of course the response to that would be that there probably exists a \"hard-counter\" for any given meta-game, but if it is indeed the case that the meta-game is the \"most-optimal\" it probably is the case also that such a hard counter puts the player in an unfavourable position most of the time, thus the \"hard-counter\" itself is not optimal. Thus we'd likely see that any given first encounter players would still stick to their \"optimal meta-game\" rather than a hard counter of their optimal play.</p>\n\n<p>A more rigour analogy would be to ask: \"Under Hofstadter's notion of superrationality, how would agents play information incomplete games\", but I couldn't find any readings on trying to import the notion of super-rationality into information incomplete games.</p>\n\n<p>Alternatively: is there such thing as a \"perfectly optimal meta-game\"?</p>\n", "pids": ["53e9b8b3b7602d970448e773"], "flag": 1}
{"question": "Is psychology an art or work?", "body": "<p>Some are born psychologists and they have passion towards it unlike some people who just work to earn money on it.</p>\n\n<p>The people who just do the same as work, will they satisfy the people with the care which is the prime importance, and is the real burden of talking to the patients concealed?</p>\n", "pids": ["53e9b6dbb7602d9704269b47", "55a3eb722401c6de3b7a01bb", "56604b920cf2dab45b564c6c"], "flag": 1}
{"question": "Is there any strong empirical support that &quot;casual&quot; (10-20 minutes per day) mindfulness meditation leads to lasting cognitive improvements?", "body": "<p>I want to emphasize that I'm not referring to the intense mindfulness-based cognitive therapy (MBCT), but instead just 10-20 minutes of daily mindfulness meditation (MM), perhaps guided by a smartphone app.</p>\n\n<p>It's usually claimed that MM leads to improvements in the prefrontal cortex (enhanced focus, working memory etc.) and the amygdala (reduced depression, anxiety, stress etc.).  </p>\n\n<p>I have read recent studies claiming that mindfulness meditation is no more effective than watching a documentary, is counterproductive at work etc. (Some of these studies may have been context-specific.) Anecdotally, I've done MM myself on-and-off for several years and didn't notice any significant improvements in the areas listed above.  </p>\n\n<p>Due to publication bias, p-hacking, the reproducibility crisis etc. and my own personal experience, I'm skeptical that MM does anything significant (noticeable changes) and/or lasting (after the meditation, during the day).  </p>\n\n<p>Is there a large-scale, pre-registered replication effort to support the benefits of 'casual' MM (i.e., not the more intense MBCT)?</p>\n", "pids": ["53e9ba84b7602d97046a5799", "53e9b042b7602d9703aa41d6", "53e9ae9cb7602d97038bd68a", "53e9afe1b7602d9703a37cf3"], "flag": 1}
{"question": "Is pleasure synonymous to positive reinforcement?", "body": "<p>I'm thinking about what pleasure is from the perspective of the <a href=\"https://en.wikipedia.org/wiki/Integrated_information_theory\" rel=\"nofollow noreferrer\">integrated information theory of consciousness</a>. As I understand it, according to the <a href=\"https://plato.stanford.edu/entries/emotion/#EvalTradAffeScieApprTheo\" rel=\"nofollow noreferrer\">appraisal theory of emotions</a>, the orientation on the good-bad spectrum is essential for every emotion. From the point of view of these theories, it seems pleasure should occur every time whenever a decision leads to a state evaluated as positive. Is this what modern research suggests or is there a better theory on what pleasure is information-wise?</p>\n<p>In other words, what is the algorithm of pleasure according to contemporary science?</p>\n", "pids": ["55a60e8e65cead59c833a2e2"], "flag": 1}
{"question": "Correlation used as explanatory device in &#39;&#39;The neuroscience of Intelligence&#39;", "body": "<p>I am currently reading Dr. Richard Haier's book The Neuroscience of Intelligence. I have a base knowledge of statistics, but I am confused about the following extract from page 80 (chapter 2.4): </p>\n\n<blockquote>\n  <p>When correlations are computed in identical twins reared apart, the\n  correlation is  also one way to estimate heritability, so a\n  correlation of .70 indicates that 70% of the  variance in intelligence\n  is due to genetic factors and 30% is not.</p>\n</blockquote>\n\n<p>Is using correlation a valid way to estimate the heritability of a specific trait? I was under the impression that for a comparison of shared variance r² would have to be used, which would mean IQ is not 70% inherited, but only 49% (a huge difference!).</p>\n", "pids": ["55a6903565ce054aad6bebb2"], "flag": 1}
{"question": "What are examples of resources that describe the basics of Spiking Neural Networks in detail?", "body": "<p>I'm very interested in writing a <strong>Spiking Neural Network</strong> engine (SNN) from scratch, but I can't find the basic information I need to get started.</p>\n<p>For example, I've seen pictures of the individual signals that combine to form a neuron pulse in several research papers, with no information on the equations in use.  It's not the focus of the papers, and the authors assume the readers have that knowledge already.  Some papers reference software that provides this foundation (<a href=\"https://www.nest-simulator.org/\" rel=\"nofollow noreferrer\">NEST</a>, <a href=\"https://neuralensemble.org/PyNN/\" rel=\"nofollow noreferrer\">pyNN</a>, etc.), but the documentation for the software is similarly light on details.</p>\n<p>There is a ton of information out there on the more common network types, but SNNs have not yet made it into the mainstream.</p>\n<p>So, where do I get this basic information? Has someone pulled together any recipes/examples/tutorials for an SNN, as has been done with all the other network types?</p>\n", "pids": ["599c7960601a182cd2636997", "5e09a860df1a9c0c41689730"], "flag": 1}
{"question": "What are some online courses for deep reinforcement learning?", "body": "<p>What are some (good) online courses for deep reinforcement learning?</p>\n\n<p>I would like the course to be both programming and theoretical. I really liked <a href=\"https://www.youtube.com/playlist?list=PLzuuYNsE1EZAXYR4FJ75jcJseBmo4KQ9-\" rel=\"noreferrer\">David Silver's course</a>, but the course dates from 2015. It doesn't really teach deep Q-learning at this time.</p>\n", "pids": ["55a6bae665ce054aad73115b"], "flag": 1}
{"question": "What is the current state of AGI development?", "body": "<p>Could you please provide some insight into the current stage of developments in AGI area? Are there any projects that had breakthroughs recently? Maybe some news source to follow on this topic?</p>\n", "pids": ["599c7948601a182cd262b37f"], "flag": 1}
{"question": "Which computer video games can improve intelligence, barring Medal of Honor?", "body": "<p>Source: <a href=\"https://rads.stackoverflow.com/amzn/click/0393337693\" rel=\"noreferrer\"><em>Intelligence and How to Get It: Why Schools and Cultures Count</em></a> (2009). p. 49.</p>\n\n<blockquote>\n  <p>  We have every reason to believe that these sorts of visual exercises actually improve fluid-intelligence skills and the executive functions that underlie them, including working memory and control of attention. Researchers have shown, for example, that video-game players can attend to more things at once than can nonplayers. Video-game players can also ignore irrelevant stimuli more effectively than nonplayers and can see objects in a broader visual field than nonplayers. To make sure that what they have observed of computer-game players is not just a self-selection effect (with the fluid IQ hotshots being the ones most likely to play computer games in the first place), the researchers had non- players learn a game—<strong>Medal of Honor [emboldening mine]</strong>—that they thought would teach the attention-control skills of their video-game players, and had other nonplayers play a computer game that the researchers did not believe would be capable of teaching attention control, namely, Tetris. Subjects played the computer games for an hour a day for ten days. At the end of the period, Medal of Honor players did better on the attention-control tasks than did Tetris players. </p>\n</blockquote>\n\n<p>Exclude Medal of Honor that's already cited overhead. </p>\n", "pids": ["56d8d83ddabfae2eeedb1c56"], "flag": 0}
{"question": "Proportion of cortex dedicated for vision and hearing", "body": "<p>I have read in some websites that the percentage of the cortex devoted to processing visual information is from 30-66% with some claiming even 90%. And compared to that, only about 3% is dedicated to hearing. </p>\n\n<p>Is this true? </p>\n\n<p>The only source I've found stating something similar is from <a href=\"https://doi.org/10.1016/0002-9394(57)90012-0\" rel=\"nofollow noreferrer\">Sells &amp; Fixott (1957)</a> where 50% of the\nneural tissue is devoted to vision and almost two-thirds of the\nelectrical activity of the brain is devoted to vision when the eyes are open.</p>\n\n<p>I haven't found anything related to hearing though. Does anyone know of a paper where this is discussed?</p>\n\n<p><strong>References</strong></p>\n\n<p>Sells, S.B. &amp; Fixott, R. S. (1957). Evaluation of Research on Effects of Visual Training on Visual Functions. <em>American Journal of Ophthalmology</em> 44(2), 230—236<br>DOI: <a href=\"https://doi.org/10.1016/0002-9394(57)90012-0\" rel=\"nofollow noreferrer\">10.1016/0002-9394(57)90012-0</a></p>\n", "pids": ["5c136857da56295a08a1943f"], "flag": 0}
{"question": "Aesthetic pleasure hormone or neurotransmitter", "body": "<p>When a human watched a beautiful painting, a beautiful animation, sees a beautiful nature scene what hormone or neurotransmitter is produced in the organism that he feels the aesthetic pleasure? </p>\n\n<p>Also is it the same chemical as when we hear a beautiful music?</p>\n\n<p>If there are many like for example dopamine, oxytocin and endorphin then which one is the main responsible for the pleasure? </p>\n", "pids": ["55a3ebcb65ce5cd7b3bcf85c"], "flag": 1}
{"question": "Is one big network faster than several small ones?", "body": "<p>The basis of my question is that a CNN that does great on MNIST is far smaller than a CNN that does great on ImageNet. Clearly, as the number of potential target classes increases, along with image complexity (background, illumination, etc.), the network needs to become deeper and wider to be able to sufficiently capture all of the variation in the dataset. However, the downside of larger networks is that they become far slower for both inference and backprop.</p>\n\n<p>Assume you wanted to build a network that runs on a security camera in front of your house. You are really interested in telling when it sees a person, or a car in your driveway, or a delivery truck, etc. Let's say you have a total of 20 classes that you care about (maybe you want to know minivan, pickup, and so on).</p>\n\n<p>You gather a dataset that has plenty of nice, clean data. It has footage from lots of times of the day, with lots of intra-class variation and great balance between all of the classes. Finally, assume that you want this network to run at the maximum possible framerate (I know that security cameras don't need to do this, but maybe you're running on a small processor or some other reason that you want to be executing at really high speed).</p>\n\n<p>Is there any advantage, computationally, to splitting your network into smaller networks that specialize? One possibility is having a morning, an afternoon/evening, and a night network and you run the one corresponding to the time of day. Each one can detect all 20 classes (although you could split even farther and make it so that there is a vehicle one, and a person one, and so on). Your other option is sharing base layers (similar to using VGGNet layers for transfer learning). Then, you have the output of those base layers fed into several small networks, each specialized like above. Finally, you could also have just one large network that runs in all conditions.</p>\n\n<p><strong>Question: Is there a way to know which of these would be faster other than building them?</strong> </p>\n\n<p>In my head, it feels like sharing base layers and then diverging will run as slow as the \"sub-network\" with the most additional parameters. Similar logic for the separate networks, except you save a lot of computation by sharing base layers. Overall, though, it seems like one network is probably ideal. Is there any research/experimentation along these lines?</p>\n", "pids": ["53e9a751b7602d9703088894"], "flag": 1}
{"question": "How to prevent overfitting in stacked models?", "body": "<p>I understand the intuition behind stacking models in machine learning, but even after thorough cross-validation scheme models seem to overfit. Most of the models I have seen in kaggle forums are large ensembles, but seem to overfit very little.</p>\n", "pids": ["5f00f03cdfae54b9a6bf722c"], "flag": 1}
{"question": "What is the current state-of-the-art in Reinforcement Learning regarding data efficiency?", "body": "<p>In other words, which existing reinforcement method learns with fewest episodes? <a href=\"http://www.jmlr.org/papers/volume3/brafman02a/brafman02a.pdf\" rel=\"nofollow noreferrer\">R-Max</a> comes to mind, but it's very old and I'd like to know if there is something better now.</p>\n", "pids": ["5736960a6e3b12023e51d64d", "573696026e3b12023e5160b3", "599c7947601a182cd262ae07"], "flag": 1}
{"question": "How do you encode a chess move in a neural network?", "body": "<p>In a neural network for chess (or checkers), the output is a piece or square on the board and an end position.</p>\n\n<p>How would one encode this?</p>\n\n<p>As far as I can see choosing a starting square is 8x8=64 outputs and an ending square is 8x8=64 outputs. So the total number of possible moves is 64x64 4096 outputs. Giving a probability for every possible move.</p>\n\n<p>Is this correct? This seems like an awful lot of outputs!</p>\n", "pids": ["5a73cbcc17c44a0b3035f7b3"], "flag": 1}
{"question": "What are the main algorithms used in computer vision?", "body": "<p>Nowadays, CV has really achieved great performance in many different areas. However, it is not clear what a CV algorithm is.</p>\n<p>What are some examples of CV algorithms that are commonly used nowadays and have achieved state-of-the-art performance?</p>\n", "pids": ["5f156e7091e011d7db223b03", "573698016e3b12023e6da477"], "flag": 1}
{"question": "What is the effective relatedness of inbreeding?", "body": "<p>If a human inbreeds with a relative, how distant does the relative have to be before the homozygosity in the child is no higher than if the mate were randomly chosen from the global population?</p>\n", "pids": ["53e9a9d3b7602d9703333136", "61c5a4695244ab9dcb5d4cf7"], "flag": 1}
{"question": "What is the relationship between fear and desire?", "body": "<p>Are fear and desire located on the opposite sides of a spectrum or are they more like filters/lenses through which one can look simultaneously?</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 1}
{"question": "Is &#39;job title classification&#39; rather a problem of NLP or machine learning?", "body": "<p>first of all I want to specify the data available and what needs to be achieved: I have a huge amount of vacancies (in the millions). The information about the <strong>job title</strong> and the <strong>job description</strong> of each vacancy are stored separately. I also have a <strong>list of professions</strong> (around 3000), to which the vacancies shall be mapped.</p>\n\n<p><strong>Example</strong>: <em>java-developer, java web engineer and java software developer</em> shall all be mapped to the profession <em>java engineer</em>.</p>\n\n<p>Now about my current researches and problems: Since a lot of potential training data is present, I thought a machine learning approach could be useful. I have been reading about different algorithms and wanted to give neural networks a shot. </p>\n\n<p>Very fast I faced the problem, that I couldn't find a satisfying way to <strong>transform text of variable length to numerical vectors of constant size</strong> (needed by neural networks). As discussed <a href=\"https://stackoverflow.com/questions/14783431/processing-strings-of-text-for-neural-network-input\">here</a>, this seems to be a non trivial problem. </p>\n\n<p>I dug deeper and came across <a href=\"https://skymind.ai/wiki/bagofwords-tf-idf\" rel=\"noreferrer\">Bag of Words (BOW) and Text Frequency - Inverse Document Frequency (TFIDF)</a>, which seemed suitable at first glance. But here I faced other problems: If I feed all the job titles to TFIDF, the resulting word-weight-vectors will probably be very large (in the tenth of thousands). The search term on the other hand will mostly consist of between 1 and 5 words (we currently match the job title only). Hence, the neural network must be able to reliably map an ultra sparse input vector to one of a few thousand basic jobs. This sounds very difficult for me and I doubt a good classification quality.</p>\n\n<p>Another problem with BOW and TFIDF is, that they cannot handle typos and new words (I guess). They cannot be found in TFIDF's word list, which results in a vector filled with zeros. To sum it up: I was first excited to use TFIDF, but now think it doesn't work well for what I want to do.</p>\n\n<p>Thinking more about it, I now have doubt if neural networks or other machine learning approaches are even good solutions for this task at all. Maybe there are much better algorithms in the field of natural language processing. \nThis moment (before digging into NLP) I decided to first gather the opinions of some more experienced AI users, so I don't miss the best solution. </p>\n\n<p>So <strong>what would be a useful approach to this in your opinion</strong> (best would be an approach that is capable of handling synonyms and typos)? Thanks in advance!</p>\n\n<p>p. s.: I am currently thinking about <strong>feeding the whole job description</strong> into the TFIDF and also do matches for new incoming vacancies with the whole document (instead of job title only). This will expand the size of the word-weight-vector, but it will be less sparse. Does this seem logical to you?</p>\n", "pids": ["5bdc31b817c44a1f58a0c45c"], "flag": 1}
{"question": "Does an AI exist that can write software based on a formal specification?", "body": "<p>Does an AI exist that can automatically write software based on a formal specification of the software?</p>\n", "pids": ["5c8d1f214895d9cbc63d5935"], "flag": 1}
{"question": "How to generalise over multiple simultaneous dependent actions in Reinforcement Learning", "body": "<p>I am trying to build an RL agent to price paid-for-seating on commercial flights. I should reiterate here - I am not talking about the price of the ticket - rather, I am talking about the pricing you see if you click on the seat map to choose where on the plane you sit (exits rows, window seats, etc). The general set up is:</p>\n\n<ol>\n<li>After choosing their flights (for a booking of <em>n</em> people), a customer will view a web page with the available seat types and their prices visible.</li>\n<li>They select between zero and <em>n</em> seats from a seat map with a variety of different prices for different seats, to be added to their booking.</li>\n<li>The revenue from step 2 is observed as the reward.</li>\n</ol>\n\n<p>Each 'episode' is the selling cycle of one flight. Whether the customer buys a chosen seat or not, the inventory goes down as they still have a ticket for the flight so will get a seat at departure. I would like to change prices on the fly, rather than fix a set of optimal prices throughout the selling cycle. </p>\n\n<p>I have not decided on a general architecture yet. I want to take various booking, flight, and inventory information into account, so I know I will be using function approximation (most likely a neural net) to generalise over the state space.</p>\n\n<p>However, I am less clear on how to set up my action space. I imagine an action would amount to a vector with a price for each different seat type (window seat, exit row, etc). If I have, for example, 8 different seat types, and 10 different price points for each, this gives me a total of 10^8 different actions, many of which will be very similar. In a sense, each action is comprised of a combination of sub-actions - the action of pricing each seat type.</p>\n\n<p>Additionally, each sub-action (pricing one seat type) is somewhat dependent on the others, in the sense that the price of one seat type will likely affect the demand (and hence reward contribution) for another. For example, if you set window seats to a very cheap price, people will be less likely to spend a normal amount for the other seat types. Hence, I doubt the problem can be decomposed into a set of sub-problems.</p>\n\n<p>I'm interested if there has been any research into dealing with a problem like this. Clearly any agent I build needs some way to generalise across actions to some degree, since collecting real data on millions of actions is not possible, even just for one state.</p>\n\n<p>As I see it, this comes down to three questions:</p>\n\n<ol>\n<li>Is it possible to get an agent that can deal with a set of actions (prices) as a single decision?</li>\n<li>Is it possible to get this agent to understand actions in relative terms? Say for example, one set of potential prices is [10, 12, 20], for middle seats, aisle seats, and window seats. Can I get my agent to realise that there is a natural ordering there, and that the first two pricing actions are more similar to each other than to the third possible action?</li>\n<li>Further to this, is it possible to generalise from this set of actions - could an agent be set up to understand that the set of prices [10, 13, 20] is very similar to the first set?</li>\n</ol>\n\n<p>I haven't been able to find any literature on this, especially relating to the second question - any help would be much appreciated!</p>\n", "pids": ["5ac1829d17c44a1fda917dcd"], "flag": 1}
{"question": "Is there any reason why chunking the digit span test would not help?", "body": "<p>Is there any reason why chunking the digit span test would not help, and what is the average score without chunking? By chunking I mean any rehearsal besides saying the numbers one time as they appear.</p>\n\n<p>I asked a similar question already:</p>\n\n<p><a href=\"https://psychology.stackexchange.com/questions/18329/does-the-digit-span-test-draw-on-any-executive-functions-besides-working-memory\">Does the digit span test draw on any executive functions besides working memory, if &quot;chunking&quot; is not used?</a></p>\n\n<p>Just intrigued why chunking might not work as well (and it's trivial that it won't always work as well), or not at all.</p>\n", "pids": ["53e9ac76b7602d970364a25c"], "flag": 0}
{"question": "Can Convolutional Neural Networks be applied in domains other than image recognition?", "body": "<p>I'm new in this argument, my question is:</p>\n\n<p>Can convolution be applied in other contexts different from image recognition?\nIs there a good source to learn from?</p>\n", "pids": ["5736986b6e3b12023e72fc2d", "5c756d6bf56def9798526733", "53e99fe4b7602d97028bf016", "5a260c8617c44a4ba8a3228f"], "flag": 1}
{"question": "Is it possible for a neural network to be used to compress data?", "body": "<p>When training a neural network, we often run into the issue of overfitting.</p>\n\n<p>However, is it possible to put overfitting to use? Basically, my idea is, instead of storing a large dataset in a database, you can just train a neural network on the <em>entire</em> dataset until it overfits as much as possible, then retrieve data \"stored\" in the neural network like it's a hashing function.</p>\n", "pids": ["5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "How can I create an artificially intelligent aimbot for a game like CS:GO?", "body": "<p>How can I create an artificially intelligent aimbot for a game like <a href=\"https://en.wikipedia.org/wiki/Counter-Strike:_Global_Offensive\" rel=\"nofollow noreferrer\">Counter-Strike Global Offensive (CS:GO)</a>?</p>\n\n<p>I have an initial solution (or approach) in mind. We can train an image recognition model that will recognize the head of the enemy (in the visible area of the player, so excluding the invisible area behind the player, to avoid being easily detected by VAC) and move the cursor to the position of the enemy's head and fire.</p>\n\n<p>It would be much more preferable to train the recognition model in real-time than using demos. Most of the available demos you might have might be 32 tick, but while playing the game, it works at 64 tick.</p>\n\n<p>It is a very fresh idea in my mind, so I didn't actually think a lot about it. Ignoring facts like detection by VAC for a few moments.</p>\n\n<p>Is there any research work on the topic? What are the common machine learning approaches to tackle such a problem?</p>\n\n<p>Later on, this idea can be expanded to a completely autonomous bot that can play the game by itself, but that is a bit too much initially.</p>\n", "pids": ["5a9cb66717c44a376ffb8ada"], "flag": 1}
{"question": "What introductory textbook is available about the corticostriatal brain circuitry?", "body": "<p>I want to understand the basal ganglia better. In particular, I want to understand the role of the corticostriatal brain circuitry for non-motor functions, including emotion and cognition.\nI have found some recent review papers that provide solid overviews e.g. </p>\n\n<p>Haber, S. N. (2016). Corticostriatal circuitry. <em>Dialogues in Clinical Neuroscience</em>, 18(1), 7–21. PCMCID: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4826773/\" rel=\"noreferrer\">PMC4826773</a>.</p>\n\n<p>and</p>\n\n<p>Shipp, S. (2017). The functional logic of corticostriatal connections. <em>Brain Structure and Function</em>, 222(2), 669-706. doi: <a href=\"https://doi.org/10.1007/s00429-016-1250-9\" rel=\"noreferrer\">10.1007/s00429-016-1250-9</a> </p>\n\n<p>However, a more comprehensive textbook would be ideal - are there any introductory textbooks that cover the basal ganglia and the corticostriatal brain circuitry in detail?</p>\n", "pids": ["55a45ee365ce31bc87786552"], "flag": 0}
{"question": "Are there any benefits to having Obsessive-Compulsive Disorder?", "body": "<p>OCD is a chronic mental health disorder. It is a major handicap when trying to lead a normal life.</p>\n\n<p>But are there any positive effects of having the disorder? Is there any such thing as high functioning OCD?</p>\n", "pids": ["56d8ec88dabfae2eee59b5e5"], "flag": 0}
{"question": "Repeating a rumor that you started?", "body": "<p>I've heard that repeating a rumor by denying it only serves to reinforce the rumor. </p>\n\n<p><a href=\"https://www.linkedin.com/pulse/20141110142443-1967426-how-firms-should-fight-rumors/\" rel=\"noreferrer\">https://www.linkedin.com/pulse/20141110142443-1967426-how-firms-should-fight-rumors/</a></p>\n\n<p><em>Try to avoid reinforcing minor rumors by repeating them in order to deny them.</em></p>\n\n<p><a href=\"https://www.psychologytoday.com/us/articles/200811/the-8-laws-rumor-spread\" rel=\"noreferrer\">https://www.psychologytoday.com/us/articles/200811/the-8-laws-rumor-spread</a></p>\n\n<p><em>Even a denial can be a repetition of a rumor.\" (Just ask Senator John Kerry, whose 2004 presidential bid sunk thanks to whispers about his swift-boat service in Vietnam—even though most of the media stories were about how the rumors were false.)</em></p>\n\n<p><a href=\"https://www.wikihow.com/Stop-Rumors\" rel=\"noreferrer\">https://www.wikihow.com/Stop-Rumors</a></p>\n\n<p><em>If it was you who started the rumor in the first place, don't deny it. Instead of reacting to what others will think of you, admit what you did wrong out of character.</em></p>\n\n<p>But what about in cases where I told something about myself that was less than flattering, or even downright embarrassing, and am now regretting having said? Does the same principle -- repeat it in any way by denying, asking to keep silent about the matter etc... -- result in heightening the possibility that it will spread to other people, because of the effects of priming?</p>\n\n<p>Or is it the case that if I ask him/her specifically to not repeat the rumor, that he/she will more likely comply compared to if I kept silent about the matter?</p>\n", "pids": ["53e9ae2eb7602d97038440c4"], "flag": 0}
{"question": "Is Orwellian Double-think Psychologically Possible?", "body": "<p>In George Orwell's <em>1984</em>, a great deal of space is devoted to explaining &quot;Double-think,&quot; part of The Party's method of &quot;reality control.&quot; Here's a particularly clear passage:</p>\n<blockquote>\n<p>Doublethink means the power of holding two contradictory beliefs in one's mind simultaneously, and accepting both of them. The Party intellectual knows in which direction his memories must be altered; he therefore knows that he is playing tricks with reality; but by the exercise of doublethink he also satisfies himself that reality is not violated. The process has to be conscious, or it would not be carried out with sufficient precision, but it also has to be unconscious, or it would bring with it a feeling of falsity and hence of guilt. Doublethink lies at the  very heart of Ingsoc, since the essential act of the Party is to use conscious deception while retaining the firmness of purpose that goes with complete honesty...</p>\n</blockquote>\n<p>Another really good passage describes the practice of doublethink. O'Brien, a member of the inner party, produces a photograph of some people who are supposed to have never existed. But then he destroys it.</p>\n<blockquote>\n<p>&quot;It exists!&quot; he [Winston, the protagonist] cried!</p>\n</blockquote>\n<blockquote>\n<p>&quot;No,&quot; said O'Brien... &quot;Ashes,&quot; he said. &quot;Not even identifiable ashes. Dust. It does not exist. It never existed.&quot;</p>\n</blockquote>\n<blockquote>\n<p>&quot;But it did exist! It does exist! It exists in memory. I remember it. You remember it.&quot;</p>\n</blockquote>\n<blockquote>\n<p>&quot;I do not remember it,&quot; said O'Brien.</p>\n</blockquote>\n<p>It's interesting (and terrifying), but I suspect it isn't possible.</p>\n<p>As I understand, in Freudian theory, repression is an unconscious process that happens to traumatic or unacceptable memories. That's clearly different from doublethink, even if it were possible (and there doesn't seem to be any evidence that it is.)</p>\n<p>Is doublethink actually possible? Are there any documented examples of it? Is there anything similar to it, possible or otherwise?</p>\n", "pids": ["55a58753612c6b12ab205815"], "flag": 1}
{"question": "Why do faculty often complain about teaching?", "body": "<p>As a PhD student and a post-doc, I always liked being a TA, and I always considered teaching as a natural duty for grad students and faculty. In the end, universities are and should be mainly about transmitting knowledge to students. Sometimes, I even enjoyed grading and proctoring because it would give me a short break from a highly creative job (research) to a mechanical one, where I could partially switch my brain off.</p>\n<p>While a minority of my colleagues would enjoy teaching as much as I did, the large majority would endlessly complain about their teaching duties, and boringly compare their teaching load to the lighter one that colleague X or Y got assigned by the department, shouting to the world how unfair that was.</p>\n<p>I never understood why this is the case. In particular, I have two questions:</p>\n<ol>\n<li>How can someone end up working in academia, if teaching is such a burden?</li>\n<li>Why do people in academia (from grad student upwards) complain so much about their teaching load, often comparing it to that of their colleagues?</li>\n</ol>\n", "pids": ["62ea570d5aee126c0f795787"], "flag": 1}
{"question": "Term for the tendency to relate events that occurred in proximity?", "body": "<p>What is the correct scientific term for the tendency to wrongfully relate arbitrary observations to a significant event, just because they occurred in temporal or spatial proximity?</p>\n<p>Most recently I have observed this error in a discussion about an unsolved killing, where a participant was quite sure that her observation of a black van in a far away town was related to the killing, for the single reason that it occurred around the same time.</p>\n", "pids": ["56d831aadabfae2eee2665ba"], "flag": 1}
{"question": "Are fully connected layers necessary in a CNN?", "body": "<p>I have implemented a CNN for image classification. I have not used fully connected layers, but only a softmax. Still, I am getting results. </p>\n\n<p>Must I use fully-connected layers in a CNN?</p>\n", "pids": ["573698016e3b12023e6da477"], "flag": 1}
{"question": "What is a &quot;surrogate model&quot;?", "body": "<p>In the following paragraph from the book <a href=\"https://link.springer.com/book/10.1007%2F978-3-030-05318-5\" rel=\"nofollow noreferrer\">Automated Machine Learning: Methods, Systems, Challenges</a> (by Frank Hutter et al.)</p>\n\n<blockquote>\n  <p>In this section we first give a brief introduction to Bayesian optimization, present alternative surrogate models used in it, describe extensions to conditional and constrained configuration spaces, and then discuss several important applications to hyperparameter optimization.</p>\n</blockquote>\n\n<p>What is an \"alternative surrogate model\"? What exactly does \"alternative\" mean?</p>\n", "pids": ["5b67b4b917c44aac1c867d8e"], "flag": 1}
{"question": "What are the available exploration strategies for continuous action space scenarios in RL?", "body": "<p>I'm building a deep neural network to serve as the policy estimator in an actor-critic reinforcement learning algorithm for a continuing (not episodic) case.  I'm trying to determine how to explore the action space. I have read through <a href=\"http://incompleteideas.net/book/the-book-2nd.html\" rel=\"nofollow noreferrer\">this text book</a> by Sutton, and, in section 13.7, he gives one way to explore a continuous action space.  In essence, you train the policy model to give a mean and standard deviation as an output, so you can sample a value from that Gaussian distribution to pick an action.  This just seems like the continuous action-space equivalent of an <span class=\"math-container\">$\\epsilon$</span>-greedy policy.</p>\n<p><em>Are there other continuous action space exploration strategies I should consider?</em></p>\n<p>I've been doing some research online and found some articles related to RL in robotics and found that the <a href=\"https://papers.nips.cc/paper/3545-policy-search-for-motor-primitives-in-robotics.pdf\" rel=\"nofollow noreferrer\">PoWER</a> and <a href=\"https://arxiv.org/pdf/1206.4621\" rel=\"nofollow noreferrer\">PI^2</a> algorithms do something similar to what is in the textbook.</p>\n<p><em>Are these, or other, algorithms &quot;better&quot; (obviously depends on the problem being solved) alternatives to what is listed in the textbook for continuous action-space problems?</em></p>\n<p>I know that this question could have many answers, but I'm just looking for a reasonably short list of options that people have used in real applications that work.</p>\n", "pids": ["5a73cbc317c44a0b3035ec9e", "5736960a6e3b12023e51d64d", "599c794e601a182cd262e627"], "flag": 1}
{"question": "Is there an open-source implementation for graph convolution networks for weighted graphs?", "body": "<p>Currently, I'm using a Python library, <a href=\"https://github.com/stellargraph/stellargraph\" rel=\"nofollow noreferrer\">StellarGraph</a>, to implement GCN. And I now have a situation where I have graphs with weighted edges. Unfortunately, StellarGraph doesn't support those graphs</p>\n\n<p>I'm looking for an open-source implementation for graph convolution networks for <strong>weighted graphs</strong>. I've searched a lot, but mostly they assumed unweighted graphs. Is there an open-source implementation for GCNs for weighted graphs?</p>\n", "pids": ["5e807d589fced0a24b30b594"], "flag": 1}
{"question": "Uses of the Brief Anxiety Scale", "body": "<p>I am currently completing my undergraduate research thesis on self-affirmations measured with anxiety. I am trying to see if the self-affirmation task reduces anxiety after. I found the Brief Anxiety Scale and am trying to find out what it is best used with, but my search of articles has not made the uses clear to me.</p>\n\n<p>For what is the scale best used? Are there different scales that might instead be recommended for my research?</p>\n\n<p>Thank you in advance to anyone who can provide assistance!</p>\n", "pids": ["53e99ffcb7602d97028df500", "55a3fe7665ce5cd7b3bf922e", "55a4cbbb65ceb7cb02d88a96"], "flag": 1}
{"question": "I believe a publisher is infringing copyright when reproducing a figure I created. What can I do?", "body": "<p>A few months ago an Elsevier representative contacted me asking for permission to reproduce one of my thesis figures in one of their books. Since this figure is only in my thesis (introduction section) and is not published elsewhere, I retain full copyright.</p>\n\n<p>Because I am truly concerned about the negative effect of Elsevier policies on science at large, I am boycotting Elsevier. I considered not granting them permission, however I thought that this would mostly affect the authors of the book and have very little effect on Elsevier. I asked my Facebook contacts what I should do, and one of them proposed a very nice solution. Basically, he suggested that I publish the work under some terms so that everyone, and not only Elsevier, can be directed to the specific conditions under which this work can be reused. So I posted my figure on <a href=\"https://zenodo.org/record/1247978#.W7hZXxShRf8\" rel=\"nofollow noreferrer\">Zenodo</a> (this actually makes sense because I have been asked many times for permission to reproduce this figure - mind you, that's the only reason why my thesis gets cited at all).</p>\n\n<p>I replied to the Elsevier representative referring him to the Zenodo entry, and specifically letting him know that the modified version of the figure that they want to use does not comply with my terms (since it removes the text stating I own the copyright).</p>\n\n<p>Last week, I noticed that a preview of the book is available in Google Books. To my surprise, I noticed that the <a href=\"https://books.google.fi/books?hl=en&amp;lr=&amp;id=U0JvDwAAQBAJ&amp;oi=fnd&amp;pg=PA351&amp;ots=GGENABkYai&amp;sig=1HnVtY755whGO-sdAN1zClPOQnU&amp;redir_esc=y#v=onepage&amp;q&amp;f=false\" rel=\"nofollow noreferrer\">version of the figure (fig. 11.1)</a> that they ended up using does not comply with the terms I communicated to the Elsevier representative. What can/should I do about this?</p>\n\n<p><strong>Edit</strong></p>\n\n<p>I contacted the Elsevier representative who apologized and corrected the image. The Google Books link above now shows the copyright notice as it should (hopefully this settles the nonsensical debate initiated by @user71659 depicting increasingly weird scenarios in which Elsevier had recompiled the figure from scratch).</p>\n", "pids": ["5ff68620d4150a363cc1e7fe"], "flag": 1}
{"question": "Can I write a referee report too fast?", "body": "<p>As a math postdoc, I received my first invitation to referee a journal article today, and I accepted the invitation. I've already read a preprint of the submitted article (which has been available on arXiv for a few months and coincides with the submitted version) in great detail some time ago and therefore I already have to say a lot about the article's content and presentation. I was given two months to write a report.</p>\n<p>My question, which might be stupid, is now:</p>\n<p>Can I write the report &quot;too fast&quot;?</p>\n<p>Or, more precisely:</p>\n<ul>\n<li><p>Does it make a bad impression to the editor if I submit the report too fast (say after a week or two)? Since the editor is an influential and important person in the field, I don't want him to think of me as a bad referee, but I fear that he might think &quot;The report came in so fast that the referee clearly did not put much effort into it. I'll better not ask him next time&quot;.</p>\n</li>\n<li><p>Even if I've read the article before, is it better to &quot;let it sink&quot; for some more time and not rashly send the report to the editor? At what point should I feel confident that the report is ready?</p>\n</li>\n</ul>\n<p><strong>Update:</strong> Thanks everyone for the good advice! I sent the report after around 10 days, and it was really appreciated by the editor!</p>\n", "pids": ["554ebae70cf2a9adcfd96914"], "flag": 1}
{"question": "Is anyone here familiar with techniques and/or equipment for performing cerebrospinal fluid transfusions?", "body": "<p>I am a student at a University and we are discussing putting together a lab assessing the benefits that may be associated with cerebrospinal fluid (CSF) transfusions in Alzheimer's disease mice. So far it looks like from <a href=\"https://pubmed.ncbi.nlm.nih.gov/11552002/\" rel=\"nofollow noreferrer\">this paper</a> there may have existed a device at one time that could have been modified for our purposes. I contacted Infors AG and the representative believes this device to be out of production. Does anyone here know of anyone who is doing work with CSF transfusions? We are very eager to begin, especially myself and would greatly appreciate any leads as to literature available on this technique or biotech companies that may be able to provide the tools we seek.</p>\n", "pids": ["627c8c18116247000c3d7c38"], "flag": 1}
{"question": "Can neuroevolution be combined with gradient descent?", "body": "<p>Is there any precedent for using a neuroevolution algorithm, like NEAT, as a way of getting to an initialization of weights for a network that can then be fine-tuned with gradient descent and back-propagation? </p>\n\n<p>I wonder if this may be a faster way of getting to a global minimum before starting a decent to a local using backpropagation with a large set of input parameters.</p>\n", "pids": ["5bdc31c217c44a1f58a0ccf7", "5a4aef9e17c44a2190f7a416", "5d9edb8647c8f7664601dad1"], "flag": 1}
{"question": "Does Impact Factor reflect the quality of a journal?", "body": "<p>Is the impact factor really useful for judging the quality of a journal article?</p>\n", "pids": ["53e99b50b7602d97023f1512"], "flag": 1}
{"question": "Why don&#39;t poorer countries suffer a complete brain-drain?", "body": "<p>My question is about countries such as:</p>\n<ul>\n<li>EU countries like Bulgaria, Romania or Poland and</li>\n<li>non-EU countries like Russian Federation, Ukraine or Belarus.</li>\n</ul>\n<p>A PostDoc fellow might earn at most US$ 2500, say, in Poland, while they can earn $4000 at minimum, say, in Spain. The same argument is applicable to university professors.</p>\n<p>Why do highly educated/competent/qualified scientists and engineers still work in these lower income countries?</p>\n<p>Why do poorer countries in the EU and the neighboring countries not suffer a complete and decisive brain drain?</p>\n", "pids": ["5548f6ae0cf262a827c090d4"], "flag": 1}
{"question": "Splice in with CRISPR/Cas", "body": "<p>I need to splice a gene into a human cell genome, with highest rate possible. I mean, doesn't really matter where the gene enters, nor does it matter if some cells die as a result of this.</p>\n\n<p>CRISPR know to knock-in genes with very high specifically, this reduce the success rate if we have a low amount of gRNA and/or of the protein.</p>\n\n<p>I need to insert the gene, without the need of targeting some specific place.  </p>\n\n<p>Is this possible in some way with CRISPR?</p>\n\n<p>I know that there may be better technique to do this, but I can only use CRISPR.</p>\n", "pids": ["5c757e24f56def9798b5b2e4"], "flag": 1}
{"question": "Cognitive overtraining syndrome", "body": "<p>Since at least the late 80's, <strong>overtraining syndrome</strong> has been extensively studied and discussed in the field of sport medicine. It is know considered as an established entity, yet its pathophysiology remains unclear according to many authors (see for example <a href=\"https://doi.org/10.1249/JSR.0000000000000027\" rel=\"nofollow noreferrer\">the following review</a>).</p>\n<p>Overtraining syndrome essentially consists in a decrease in mood and physical performance occurring when an athlete fails to cope with high training load, despite adequate rest. In this type of situations, athlete's performance may even decrease, compared with their pre-overtraining level. Decrease in the training load is central in the management of the syndrome.</p>\n<p>What strikes me is how this description could also apply to the form of cognitive exhaustion that many students experience during their curriculum. Anyone who has engaged in demanding studies has already felt exhausted, cognitively impaired and depressed during the most difficult times of the year, despite taking enough rest.\nThis could suggest that there exists a form of &quot;cognitive overtraining syndrome&quot;, but I cannot find any material dealing with the subject.</p>\n<p><strong>Has &quot;cognitive overtraining syndrome&quot; ever been identified as such?</strong> If so, how extensively has it been studied ?<br>\nMany thanks in advance.</p>\n", "pids": ["5c0f791ada562944ac759c4c"], "flag": 1}
{"question": "What are pros and cons of Bi-LSTM as compared to LSTM?", "body": "<p>What are the pros and cons of <strong>LSTM</strong> vs <strong>Bi-LSTM</strong> in language modelling? What was the need to introduce Bi-LSTM?</p>\n", "pids": ["573695fe6e3b12023e511e25"], "flag": 1}
{"question": "Is it possible for reviewers to mistakenly reject a quality paper?", "body": "<p>If I am not wrong, turbo codes was submitted to the ICC conference and rejected but accepted later on.</p>\n\n<p>I want to know if there are other similar works (strong works) that were rejected at first but then accepted and considered revolutionary. </p>\n", "pids": ["558a927be4b0b32fcb379a68"], "flag": 1}
{"question": "Best meditation techniques to overcome Behavioral Addictions?", "body": "<p>Meditation seems to be one of the top techniques recommended nowadays for self-development (e.g. McGonigal, K. 2011). For people who want to overcome <a href=\"https://en.wikipedia.org/wiki/Behavioral_addiction\" rel=\"nofollow noreferrer\">behavioural addictions</a> (i.e. any \"<em>addiction that involves a compulsion to engage in a rewarding non-drug-related behavior – sometimes called a natural reward</em>\", such as food, sex, masturbation, pornography, gambling, internet, video games, nail biting, compulsive skin picking, compulsive hair pulling, etc.):</p>\n\n<ul>\n<li>Which meditation techniques (e.g. mindfulness, Vipassana, Yoga, Zazen, TM, Kundalini, etc.) are the most recommendable, according to state-of-the-art Psychology and Neuroscience?</li>\n<li>Additionally, given the fact that an average layman cannot afford going full-time monk, what would be a recommendable frequency of the practice (in terms of minutes/hours per day) to see palpable results in a reasonable time?</li>\n</ul>\n\n<p>Furthermore:</p>\n\n<ul>\n<li>Is a single meditation technique enough to overcome behavioral addictions? Or would it better to practice multiple meditation techniques at the same time? Or maybe different meditation techniques for different situations? For instance, are there any special meditation techniques to handle <strong>strong, compulsive urges</strong> in the presence of <strong>addiction cues/triggers</strong>?</li>\n</ul>\n\n<p>Finally:</p>\n\n<ul>\n<li>Is meditation as a whole enough, or would one need to complement it with other non-meditative practices or measures? For example, positive affirmations, hypnosis, or maybe going to a therapist, exercising, sleeping 8+ hours, etc. I'm just throwing some ideas around.</li>\n</ul>\n\n<p><strong>References</strong></p>\n\n<p>McGonigal, K. (2011). <em>The willpower instinct: How self-control works, why it matters, and what you can do to get more of it.</em> Penguin Books.</p>\n", "pids": ["53e9af00b7602d9703932aa3", "53e9a79eb7602d97030d9c9f"], "flag": 0}
{"question": "What is the difference between learning without forgetting and transfer learning?", "body": "<p>I would like to incrementally train my model with my current dataset and <a href=\"https://github.com/tensorflow/models/issues/7200#issuecomment-510850230\" rel=\"nofollow noreferrer\">I asked this question on Github</a>, which is what I'm using SSD MobileNet v1.</p>\n<p>Someone there told me about <a href=\"https://arxiv.org/abs/1606.09282\" rel=\"nofollow noreferrer\"><strong>learning without forgetting</strong></a>. I'm now confused between <em>learning without forgetting</em> and <em>transfer learning</em>. How they differ from each other?</p>\n<p>My initial problem, what I'm trying to achieve (mentioned in Github issue) is the following.</p>\n<p>I have trained my dataset on <code>ssd_mobilenet_v1_coco</code> model. I'm getting continuous incremental data. Right now, my dataset is very limited.</p>\n<p>What I want to achieve is <em>incremental training</em>, i.e. as soon as I get new data, I can further train my already trained model and I don't have to retrain everything:</p>\n<ol>\n<li>Save trained model <span class=\"math-container\">$M_t$</span></li>\n<li>Get new data <span class=\"math-container\">$D_{t+1}$</span></li>\n<li>Train <span class=\"math-container\">$M_t$</span> on <span class=\"math-container\">$D_{t+1}$</span> to produce <span class=\"math-container\">$M_{t+1}$</span></li>\n<li>Let <span class=\"math-container\">$t = t+1$</span>, then go back to <span class=\"math-container\">$1$</span></li>\n</ol>\n<p>How do I perform this incremental training/learning? Should I use LwF or transfer learning?</p>\n", "pids": ["57a4e91aac44365e35c97dc2", "5a260c8417c44a4ba8a315cc", "5ff68719d4150a363cc447e2"], "flag": 1}
{"question": "Do men, on average, have a higher general intelligence score?", "body": "<p>I'm aware of this study that was linked during an argument:\n<a href=\"http://www.sciencedirect.com/science/article/pii/S0160289616302975\" rel=\"nofollow noreferrer\">\"Sex differences in brain size and general intelligence (g)\"</a>\nand this question <a href=\"https://psychology.stackexchange.com/questions/8583/gender-differences-in-iq-among-undergraduate-psychology-students\">Gender differences in IQ among undergraduate psychology students</a>.</p>\n\n<p>So, do men, on average, have a higher general intelligence score? And if yes, why?</p>\n", "pids": ["5a1e1c070cf2ac5ceefce436", "55a64f3d65ce054aad63fb5a", "53e9aa33b7602d97033a37f8", "5c75666bf56def97980c8230"], "flag": 0}
{"question": "Why do ResNets avoid the vanishing gradient problem?", "body": "<p>I read that, if we use the sigmoid or hyperbolic tangent activation functions in deep neural networks, we can have some problems with the vanishing of the gradient, and this is visible by the shapes of the derivative of these functions. ReLU solves this problem thanks to its derivative, even if there may be some dead units. ResNet uses ReLU as activation function, but looking online what I understood is that ResNet solves the vanishing of the gradient thanks to its identity map, and I do not totally agree with that. So what's the purpose of the identity connections in ResNet? Are they used for solving the vanishing of the gradient? And ReLU really solves the vanishing of the gradient in deep neural networks?</p>\n", "pids": ["573696026e3b12023e515eec", "5b3d98d617c44a510f8024ee", "5c86de294895d9cbc6a752c1"], "flag": 1}
{"question": "Can TD($\\lambda$) be used with deep reinforcement learning?", "body": "<p><a href=\"https://amreis.github.io/ml/reinf-learn/2017/11/02/reinforcement-learning-eligibility-traces.html\" rel=\"nofollow noreferrer\">TD lambda</a> is a way to interpolate between TD(0) - bootstrapping over a single step, and, TD(max), bootstrapping over the entire episode length, or, Monte Carlo.</p>\n\n<p>Reading the link above, I see that an eligibility trace is kept for each state in order to calculate its \"contribution to the future\".</p>\n\n<p>But, if we use an approximator, and not a table for state-values, then can we still use eligibility traces? If so, how would the loss (and thus the gradients) be calculated? Specifically, I would like to use actor-critic (or advantage actor-critic).</p>\n", "pids": ["5db9292b47c8f766461ef944", "55a6bae665ce054aad73115b"], "flag": 1}
{"question": "How to estimate the capacity of a neural network?", "body": "<p>Is it possible to estimate the capacity of a neural network model? If so, what are the techniques involved?</p>\n", "pids": ["5c8dedaa4895d9cbc6b0ba5f", "58d82fced649053542fd6ec6", "5a9cb66717c44a376ffb864d"], "flag": 1}
{"question": "What are the conditions of convergence of temporal-difference learning?", "body": "<p>In reinforcement learning, temporal difference seem to update the value function in each new iteration of experience absorbed from the environment. </p>\n\n<p>What would be the conditions for temporal-difference learning to converge in the end? How is it guaranteed to converge?</p>\n\n<p>Any intuitive understanding of those conditions that lead to the convergence?</p>\n", "pids": ["5b67b47917c44aac1c8636f0"], "flag": 1}
{"question": "littering more often in dirty places?", "body": "<p>I'm now doing some city management related research and wondering about the idea of high crime areas. Well, the above phrase is a bit extreme. Say, littering, will this kind of behavior occur more often in areas that is already dirty and has tons of rubbish which should not be there? I believe so, however I searched things like littering, wrong parking and etc. on the internet but mostly news or policy. I'm looking for a scientific theory behind the phenomena and thinking of environmental criminology which I konw nothing about.</p>\n<p>Any help will be appreciated. New to this site, if anything inapproporiate or unclear, please let me know.</p>\n", "pids": ["5ce2d166ced107d4c64242ef"], "flag": 1}
{"question": "How is greed different from compulsion?", "body": "<p>I want to learn how is human <strong>greed</strong> different from <strong>compulsion</strong> in psychology? Which one is intentional and which one is unintentional? If it makes sense at all? One of the lecturers in our school mentioned that greed is more intentional, whereas compulsion is more an unintentional attribute of the mind. I appreciate any comments or helps in distinguishing these two. Thank you</p>\n<p>According to the Cambridge dictionary:</p>\n<p><strong>Greed</strong>: a very strong <strong>wish</strong> to continuously get more of something, especially food or money</p>\n<p><strong>Compulsion</strong>: a very strong <strong>feeling</strong> of wanting to do something repeatedly that is difficult to control</p>\n<p>But I don't know if it is technically sound or not?</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 1}
{"question": "Examples of single player games that use modern ML techniques in the AI?", "body": "<p>Are there any examples of single player games that use modern ML technique in its games? By this I mean AI that plays with or against the human player, and not just play the game by itself (like Atari).</p>\n<p>&quot;Modern ML techniques&quot; is a vague term, but for example, Neural Networks, Reinforcement Learning, or probabilistic methods. Basically anything that goes above and beyond traditional search methods that most games use nowadays.</p>\n<p>Ideally, the AI would be:</p>\n<ul>\n<li>widely available (i.e. not like the OpenAI Five, which was only available for a limited amount of time and requires a high amount of computational power)</li>\n<li>human level (not overpowered)</li>\n</ul>\n<p>Ideally, the game would be:</p>\n<ul>\n<li>symmetrical (the AI has the same agent capabilities as the player, though answers similar to <a href=\"https://left4dead.fandom.com/wiki/The_Director\" rel=\"nofollow noreferrer\">The Director</a> would be very interesting as well)</li>\n<li>&quot;complex environment&quot; (more complex than, say, a board game, but a CIV5 game might work)</li>\n</ul>\n<p>But any answer would be appreciated, as some of the criteria above are quite vauge.</p>\n<p>Edit: the ideal cases listed above are not meant to discourage other answers, nor are they intended to be of strictly inclusionary (ie: any game would need to satisfy all of the above requirements)</p>\n", "pids": ["58d82fced649053542fd6e57"], "flag": 1}
{"question": "Why are neural networks preferred to other classification functions optimized by gradient decent", "body": "<p>Consider a neural network, e.g. as presented by Nielsen <a href=\"http://neuralnetworksanddeeplearning.com\" rel=\"nofollow noreferrer\">here</a>. Abstractly, we just construct some function <span class=\"math-container\">$f: \\mathbb{R}^n \\to [0,1]^m$</span> for some <span class=\"math-container\">$n,m \\in \\mathbb{N}$</span> (i.e. the dimensions of the input and output space) that depends on a large set of parameters, <span class=\"math-container\">$p_j$</span>. We then just define the cost function <span class=\"math-container\">$C$</span> and calculate <span class=\"math-container\">$\\nabla_p C$</span> and just map <span class=\"math-container\">$p \\to p - \\epsilon \\nabla_p C$</span> repeatedly.</p>\n<p>The question is why do we choose <span class=\"math-container\">$f$</span> to be what it is in standard neural networks, e.g. a bunch of linear combinations and sigmoids? One answer is that there a theorem saying any suitably nice function can be approximated using neural networks. But the same is true of other types of functions <span class=\"math-container\">$f$</span>. The Stone-Weierstrass theorem gives that we could use polynomials in <span class=\"math-container\">$n$</span> variables: <span class=\"math-container\">$$f(x) =  c^0_0 + (c^1_1 x_1 + c^1_2 x_2 + \\cdots + c^1_n x_n) + (c^2_{11}x_1 x_1 + c^2_{12} x_1x_2 + \\cdots + c^2_{1n} x_1 x_2 + c^2_{21} x_2x_1 + c^2_{22} x_2x_2 + \\cdots) + \\cdots,$$</span></p>\n<p>and still have a nice approximation theorem. Here the gradient would be even easier to calculate. Why not use polynomials?</p>\n", "pids": ["5b67b4b917c44aac1c867e2f"], "flag": 1}
{"question": "Why is dropout favoured compared to reducing the number of units in hidden layers?", "body": "<p>Why is dropout favored compared to reducing the number of units in hidden layers for the convolutional networks?</p>\n\n<p>If a large set of units leads to overfitting and dropping out \"averages\" the response units, why not just suppress units?</p>\n\n<p>I have read different questions and answers on the dropout topic including these interesting ones, <a href=\"https://ai.stackexchange.com/q/40/2444\">What is the &quot;dropout&quot; technique?</a> and this other <a href=\"https://ai.stackexchange.com/q/9512/2444\">Should I remove the units of a neural network or increase dropout?</a>, but did not get the proper answer to my question.</p>\n\n<p>By the way, it is weird that this publication <a href=\"http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf\" rel=\"noreferrer\">A Simple Way to Prevent Neural Networks from Overfitting (2014)</a>, Nitish Srivastava et al., is cited as being the first on the subject. I have just read one that is from 2012:\n<a href=\"https://arxiv.org/pdf/1207.0580.pdf\" rel=\"noreferrer\">Improving neural networks by preventing co-adaptation of feature detectors</a>.</p>\n", "pids": ["573696006e3b12023e513cb6", "5a4aef9e17c44a2190f7a34c"], "flag": 1}
{"question": "Why don&#39;t we use auto-encoders instead of GANs?", "body": "<p>I have watched Stanford's lectures about artificial intelligence, I currently have one question: why don't we use autoencoders instead of GANs?</p>\n<p>Basically, what GAN does is it receives a random vector and generates a new sample from it. So, if we train autoencoders, for example, on cats vs dogs dataset, and then cut off the decoder part and then input random noise vector, wouldn't it do the same job?</p>\n", "pids": ["57a4e921ac44365e35c98d4b"], "flag": 1}
{"question": "How many RNA-binding proteins can simultaneously bind on a single mRNA?", "body": "<p>Typically, how many RNA-binding proteins can simultaneously bind to a single mRNA?\nOr said differently, how many \"binding sites\" does an mRNA have?\nWhat order of magnitude?</p>\n\n<p>I am interested in RNA granules like stress granules or P-bodies. They contain, inter alia, mRNA and RNA-binding proteins. I am not a biologist and I didn't come across this information so far in the related literature.</p>\n", "pids": ["55a4bcd365ceb7cb02d74253", "55a6035565cead59c832aa4c"], "flag": 1}
{"question": "Are there studies on politeness towards machines?", "body": "<p>I noticed in several places (usually on web forms, but also with virtual assistants) that there is sometimes (or usually) an expectation of being polite towards the computer or device.</p>\n<p>An example would be a button &quot;yes, please&quot; or &quot;no, thank you&quot; instead of a &quot;yes&quot; or &quot;no&quot;.</p>\n<p>I also read about a casual review of how people interact with Alexa or Google Assistant - a sizable part (I think it was 30%) would say &quot;yes please&quot;.</p>\n<p><strong>I was wondering whether there was interesting research in that area, which could give some substance to hand-waving theories.</strong></p>\n<p>Notes:</p>\n<ul>\n<li>I work in IT for the past 30 years so I am used to talking to my computer (asking him to please go faster, or telling because my code does not work. I do not have &quot;casual exchanges&quot;, though.</li>\n<li>for the less serious aspect of that question, see <a href=\"https://www.youtube.com/watch?v=NMS2VnDveP8\" rel=\"nofollow noreferrer\">https://www.youtube.com/watch?v=NMS2VnDveP8</a> (2:25 for the politeness part, but the whole video is worth watching)</li>\n</ul>\n", "pids": ["555044ec45ce0a409eb52174"], "flag": 1}
{"question": "Are convolutional neural networks inspired by the human brain?", "body": "<p>The <a href=\"https://www.deeplearningbook.org/contents/convnets.html\" rel=\"nofollow noreferrer\">Deep Learning</a> book by Goodfellow et al. states</p>\n<blockquote>\n<p>Convolutional networks stand out as an example of neuroscientiﬁc principles inﬂuencing deep learning.</p>\n</blockquote>\n<p>Are convolutional neural networks (CNNs) really inspired by the human brain?</p>\n<p>If so, how? In particular, what structures within the brain do CNN-like neuron groupings occur?</p>\n", "pids": ["53e9b068b7602d9703acf032"], "flag": 1}
{"question": "Special Needs student with disruptive behavior (racial slurs towards teacher)", "body": "<p>There is a student at a university of a friend of mine who has Asperger's Syndrome, which is a milder form of Autism. My friend, who is a teacher there, has told me that the student mostly does OK work but he is not always aware of socially acceptable behavior. </p>\n\n<p>The major problem, and I mean major, is that he has literally shouted racial slurs at the teacher in the middle of class (over 5 times) as a way of expressing \"friendship\" with the teacher (not out of malice). Normally, this is grounds for having to be dropped from the course and even be removed from the campus even if the purpose is to try and be \"friends\". However, because the student is a special needs student with distinct problems and does not truly understand the impact of such behavior, my friend wants to seek alternatives. This is a challenging situation as it is still mostly uncommon for students of this nature to enrolled at university.</p>\n\n<p>What disciplinary/counselling measures are appropriate for a teacher to take, in the case of a special-needs student whose actions are detrimental to the learning environment?</p>\n", "pids": ["55a3f12f65ce5cd7b3bdfabf"], "flag": 1}
{"question": "How does a person know if he should seek treatment for depression since feeling moody is unavoidable?", "body": "<p>Life is not a bed of roses. All of us feel moody sometimes due to failures in life. This is perfectly normal. However, depression is abnormal.</p>\n\n<p>How does a person know if he needs to seek treatment for depression, given that it is hard for him to distinguish whether the moody emotions are normal or abnormal? What are some symptoms to look out for?</p>\n", "pids": ["5c756d24f56def97984fc98a"], "flag": 0}
{"question": "How close genetically is the most human-like chimpanzee to the most chimp-like human?", "body": "<p>I understand that:</p>\n\n<ul>\n<li><a href=\"http://www.scientificamerican.com/article/latest-theory-human-body-hair/\" rel=\"noreferrer\">Chimpanzees are the closest species to humans genetically</a>. Only <a href=\"http://www.scientificamerican.com/article/human-chimp-gene-gap-wide/\" rel=\"noreferrer\">1%-6%</a> of their genes are different.</li>\n<li>Within any species there is <a href=\"https://en.wikipedia.org/wiki/Genetic_diversity\" rel=\"noreferrer\">genetic diversity</a>, i.e. no two individuals have the same exact DNA sequence.</li>\n<li>This variability applies to <a href=\"https://en.wikipedia.org/wiki/Human_genetic_variation\" rel=\"noreferrer\">humans</a> and <a href=\"https://www.upf.edu/cexs/news/genetica.html\" rel=\"noreferrer\">chimps</a>. </li>\n<li>Thus, there exists a pair consisting of a human and a chimp that will have the smallest number of different (edit: <s>genes</s>) DNA base-pairs within the two populations. One can say that the pair forms an \"inter-species genetic gap\".</li>\n</ul>\n\n<p><strong>Question: What is the smallest estimated inter-species genetic gap between humans and chimpanzees?</strong></p>\n\n<p>Edit: I changed the last point to base-pairs instead of genes. Most of the comments seem to suggest the population genetic variabilities are much, much smaller than the genetic distance between the populations. Visually, that looks something like this:</p>\n\n<p><a href=\"https://i.stack.imgur.com/fzfg8.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/fzfg8.png\" alt=\"Human chimpanzee genetic differences\"></a></p>\n\n<p>Is this a fairly accurate picture of the human-chimp genetic distance?</p>\n", "pids": ["55a4c61d65ceb7cb02d81a5b", "56d8d555dabfae2eeec69b6d"], "flag": 1}
{"question": "Is there a proper initialization technique for the weight matrices in multi-head attention?", "body": "<p>Self-attention layers have 4 learnable tensors (in the vanilla formulation):</p>\n<ul>\n<li>Query matrix <span class=\"math-container\">$W_Q$</span></li>\n<li>Key matrix <span class=\"math-container\">$W_K$</span></li>\n<li>Value matrix <span class=\"math-container\">$W_V$</span></li>\n<li>Output matrix <span class=\"math-container\">$W_O$</span></li>\n</ul>\n<p>Nice illustration from  <a href=\"https://jalammar.github.io/illustrated-transformer/\" rel=\"noreferrer\">https://jalammar.github.io/illustrated-transformer/</a></p>\n<p><a href=\"https://i.stack.imgur.com/X6STQ.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/X6STQ.png\" alt=\"enter image description here\" /></a></p>\n<p>However, I do not know how should one choose the default initialization for these parameters.</p>\n<p>In the works, devoted to MLP and CNNs, one chooses <code>xavier/glorot</code> or <code>he</code> initialization by default, as they can be shown to approximately preserve the magnitude in the forward and backward pass, <a href=\"https://arxiv.org/abs/2012.05760\" rel=\"noreferrer\">as shown in these notes</a>.</p>\n<p>However, I wonder, whether there is some study of good initialization for Transformers. The default implementation in <code>Tensorflow</code> and <code>PyTorch</code> use <code>xavier/glorot</code>.</p>\n<p>Probably, any reasonable choice will work fine.</p>\n", "pids": ["599c7987601a182cd2648373"], "flag": 1}
{"question": "Why does autism sometimes only visibly appear later in life?", "body": "<p>From what I know about the autism spectrum, a lot of people who were diagnosed later in life (not during childhood) didn't \"seem autistic\" until adolescence or young adulthood. Of courses, they had symptoms all this time but it didn't become obvious until later.</p>\n\n<p>Why is that? Do you have some articles/youtube videos that I could read/watch to learn more about this (English or French)?</p>\n", "pids": ["53e9ba76b7602d970469b1c0", "53e9b196b7602d9703c2358f"], "flag": 0}
{"question": "What are the state-of-the-art meta-reinforcement learning methods?", "body": "<p>This question can seem a little bit too broad, but I am wondering what are the current state-of-the-art works on meta reinforcement learning. Can you provide me with the current state-of-the-art in this field?</p>\n", "pids": ["5e718f719e795e1c35c5f82a", "5e718f719e795e1c35c5f82a", "5cede10dda562983788eda33", "5e5e18d993d709897ce35895"], "flag": 1}
{"question": "Why are embeddings added, not concatenated?", "body": "<p>Let's consider the following example from BERT</p>\n<p><a href=\"https://i.stack.imgur.com/YLGSz.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/YLGSz.png\" alt=\"enter image description here\" /></a></p>\n<p>I cannot understand why &quot;the input embeddings are the <em>sum</em> of the token embeddings, the segmentation embeddings, and the position embeddings&quot;. The thing is, these embeddings carry different types of information, so intuitively adding them together doesn't really make sense. I mean, you cannot add 2 meters to 3 kilograms, but you can make a tuple (2 meters, 3 kilograms), so I think it's more natural to concatenate these embedding together. By adding them together, we are assuming the information about token, segmentation, and position can be simultaneously represented in the same embedding space, but that sounds like a bold claim.</p>\n<p>Other transformers, like ViTMAE, seem to follow the trend of <a href=\"https://github.com/huggingface/transformers/blob/v4.20.0/src/transformers/models/vit_mae/modeling_vit_mae.py#L795\" rel=\"noreferrer\">adding position embeddings to other &quot;semantic&quot; embeddings</a>. What's the rationale behind the practice?</p>\n", "pids": ["599c7987601a182cd2648373"], "flag": 1}
{"question": "Unconscious bias toward recommendation letters written by men?", "body": "<p><em>This is an attempt to rescue <a href=\"https://academia.stackexchange.com/q/47590/65\">a strongly down-voted question</a>.</em></p>\n\n<p><strong>Are there any studies investigating possible unconscious gender bias in evaluating recommendation letters?</strong>  Specifically, is there any published evidence that recommendation letters with female <strong>authors</strong> are (or are not) less effective than recommendation letters with male authors?  Studies considering letters for graduate admission, faculty hiring, or promotion and tenure are all relevant.</p>\n\n<p>Let me emphasize that I am <strong>not</strong> asking about intentional sexism, which I assume is sufficiently rare to be insignificant, but rather unconscious bias.  I am also not asking for anecdotes, but pointers to actual published literature.</p>\n\n<p>Similar studies have revealed significant gender disparity in several related academic contexts, including <a href=\"http://www.owlnet.rice.edu/~hebl/Pub/43.pdf\" rel=\"nofollow noreferrer\">recommendation letters for male vs. female <strong>applicants</strong></a>.  Other examples include:</p>\n\n<ul>\n<li><a href=\"http://www.pnas.org/content/109/41/16474.full\" rel=\"nofollow noreferrer\">Applications to lab manager positions</a></li>\n<li><a href=\"http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2063742\" rel=\"nofollow noreferrer\">Prospective doctoral students emailing faculty</a></li>\n<li><a href=\"http://scx.sagepub.com/content/35/5/603.abstract\" rel=\"nofollow noreferrer\">Judgement of publication quality</a></li>\n<li><a href=\"http://link.springer.com/article/10.1007/s10755-014-9313-4\" rel=\"nofollow noreferrer\">Teaching evaluations</a> (<a href=\"http://benschmidt.org/profGender/\" rel=\"nofollow noreferrer\">See also</a>)</li>\n<li><a href=\"http://www.pnas.org/content/111/12/4403.abstract\" rel=\"nofollow noreferrer\">Selection for mathematical tasks</a> (<a href=\"http://xkcd.com/385/\" rel=\"nofollow noreferrer\">See also</a>)</li>\n</ul>\n", "pids": ["53e99f0ab7602d97027d9321"], "flag": 1}
{"question": "What determines the number of chromosomes an organism carries?", "body": "<p>This is an extension of this question about <a href=\"https://biology.stackexchange.com/questions/35144/what-limits-chromosomal-length\">What limits chromosomal length?</a>.</p>\n\n<p>I am wondering what could be the specific reasons behind the number of chromosomes an organism carries. In other words, what drives the number of chromosomes and is there anything \"stabilizing\" the number of chromosomes.</p>\n\n<p>Of course I am not talking about multiple copies of the same chromosome, i.e. trisomy, but rather the reasons behind the partition of the genetic information into a defined number of chromosomes.</p>\n\n<p>From the question I referred to, chromosomes have an upper length limit which is based on their physical size, i.e basically they must be shorter than half of the spindle arm axis and they probably also have a lower limit. Yet it is unclear to me if any non-random equilibrium exists between chromosome number and length other than just being bound by an upper and lower limit in size.</p>\n\n<p>Also let's restrict this question to diploid organisms to avoid organisms such as the <em><a href=\"http://en.wikipedia.org/wiki/Oxytricha_trifallax\" rel=\"nofollow noreferrer\">Oxytricha trifallax</a></em> which has 16,000 chromosomes but is also ampliploid or plants such as wheat which can be tetraploid.</p>\n\n<p>I tried to search in the literature and couldn't find a satisfying answer. Also I had in mind the example of the Hela cells which have completely shuffled chromosomes yet still exactly 46.</p>\n", "pids": ["53e9b213b7602d9703ca8354"], "flag": 1}
{"question": "To what extent is Ebola airborne? (aerosols)", "body": "<p>Recently, CIDRAP at the University of Minnesota announced that <a href=\"http://www.cidrap.umn.edu/news-perspective/2014/09/commentary-health-workers-need-optimal-respiratory-protection-ebola\">Ebola may be more transmissible through aerosols</a> than previously thought.</p>\n\n<p>I lack the familiarity with the field to critically evaluate this release. They also seem to more interested in making the point that <em>there is a risk</em> of aerosol transmission, not to settle whether it does transmit by air or not.</p>\n\n<ul>\n<li>What is the simple answer? Can Ebola really be transmitted by aerosols? </li>\n<li>If so, how come nobody realized this before? Is this a general phenomenon allowing any pathogen to become airborne? I don't see why you couldn't aerosolize a great many pathogenic objects, not just Ebola virus.</li>\n<li>How does the number of virions necessary for successful infection compare to what you could get from aerosols?</li>\n</ul>\n", "pids": ["55a4fd3a65ceb7cb02dded14", "53e9aa3bb7602d97033aa7dd"], "flag": 1}
{"question": "What are the reasons to belief AGI will not be dangerous?", "body": "<p>We are in the middle of an ongoing debate about the safety of AGI and our current approach towards this technology. As summary, some quotes from a <a href=\"https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/\" rel=\"nofollow noreferrer\">recent article from Time magazine</a>:</p>\n<blockquote>\n<p>Many researchers[...] expect that the most likely result of building a\nsuperhumanly smart AI, under anything remotely like the current\ncircumstances, is that literally everyone on Earth will die. Not as in\n“maybe possibly some remote chance,” but as in “that is the obvious\nthing that would happen.”</p>\n</blockquote>\n<blockquote>\n<p>Without [...] precision and preparation, the most likely outcome is AI\nthat does not do what we want, and does not care for us nor for\nsentient life in general.</p>\n</blockquote>\n<h3>Outline for the way to superintelligence and where it can go wrong</h3>\n<ol>\n<li>Intelligence is subtrate independent, i.e. matter can contain intelligence (brain), ergo a silicon computer can contain intelligence</li>\n<li>The evolution of intelligence in the brain is extremely slow (biological evolution). Silicon based AI could recursively self-improve extremely fast and natural limits for intelligence are unlikely to be anywhere close to human level. (Keywords: Singularity, Seed-AI, Intelligence Explosion, etc)</li>\n<li>Large jumps in intelligence are known to cause original, &quot;hard coded&quot; goals to disappear, e.g.: Human beings - as product of optimizing for <a href=\"https://en.wikipedia.org/wiki/Inclusive_fitness\" rel=\"nofollow noreferrer\">inclusive genetic fitness</a> - have been &quot;trained on&quot; increasing the number of own copies of functioning systemns with their own DNA - yet we are using birth control and typically it is not priority #1 to donate sperm.</li>\n</ol>\n<ul>\n<li>Further complication: At some point (self improving seed-AI) it is not possible to use &quot;trial and error&quot;: The choice is between &quot;sucessfull alignment <strong>on the first try</strong>&quot; or &quot;an unaligned superintelligence appears&quot;, which in one way or another is catastrophic and many believe - with a probability bordering on certainty - leads to: human extinction.</li>\n</ul>\n<h3>Question</h3>\n<p>The debate could improve with a somewhat central place to collect and sort the various positions / reasons on this topic - for which ai.StackExchange is formidable infrastructure, so:</p>\n<p><strong>What are the reasons to belief AGI will not be dangerous?</strong></p>\n", "pids": ["6423ac7890e50fcafd55f26c"], "flag": 1}
{"question": "How can thousand-robot swarm coordinate their moves without bumping into each other?", "body": "<p>How can a swarm of small robots (like Kilobots) walking close to each other achieve collaboration without bumping into each other? For example, one study shows <a href=\"http://science.sciencemag.org/content/345/6198/795.abstract\" rel=\"noreferrer\">programmable self-assembly in a thousand-robot swarm</a> (see <a href=\"http://robohub.org/thousand-robot-swarm-self-assembles-into-arbitrary-shapes/\" rel=\"noreferrer\">article</a> &amp; <a href=\"https://vimeo.com/103329200\" rel=\"noreferrer\">video</a>) which are moving without GPS-like system and by measuring distances to neighbours. This was achieved, because the robots were very slow.</p>\n\n<p>Is there any way that similar robots can achieve much more efficient and quicker assembly by using more complex techniques of coordination? Not by walking around clock-wise (which I guess was the easiest way), but I mean using some more sophisticated way. Because waiting half a day (~11h) to create a simple star shape using a thousand-robot swarm is way too long!</p>\n", "pids": ["53e998e1b7602d970211cdf3"], "flag": 1}
{"question": "How can artificial intelligence (including deep learning algorithms) find suspicious patterns in the body’s biochemistry?", "body": "<p>It has been <a href=\"http://www.itnonline.com/content/will-fda-be-too-much-intelligent-machines\" rel=\"nofollow noreferrer\">suggested</a> that machine learning algorithms (also <a href=\"https://ai.stackexchange.com/q/1427/8\">Watson</a>) can help with finding disease in patient images and optimize scans. Also that deep learning algorithms show promise for every type of digital imaging.</p>\n\n<p>How does exactly deep learning algorithms exactly can find suspicious patterns in the body’s biochemistry?</p>\n", "pids": ["53e9b8bab7602d9704497be0"], "flag": 1}
{"question": "How to replicate legacy systems with machine learning?", "body": "<p>Let's suppose that we have a legacy system in which we don't have the source code and this system is on a mainframe written in Cobol. Is there any way using machine learning in which we can learn from the inputs and outputs the way the executables work? Doing this analysis could lead to develop some rest / soap webservice that can substitute the legacy system in my opinion. </p>\n", "pids": ["5c796b9a4895d9cbc64680a9"], "flag": 1}
{"question": "Can new emotions be created or discovered?", "body": "<p>Related: <a href=\"https://psychology.stackexchange.com/q/961/13656\">Are there emotions that only some people can feel?</a></p>\n\n<p>Is there any known observed or theoretical process by which new emotions could be observed or discovered?</p>\n\n<p>Although one may argue over the exact number of emotions that exist today or the exact criteria that differentiate one from another, there is broad agreement on the general types of emotions that exist (e.g. most psychologists would agree that happiness, sadness, envy, anxiety, excitement, anger, disgust, lust, pride, etc. are emotions while pecan, horseradish, choke, stupid, chair, delta, redshirt, appoiapgpadvap, asdf, and yooe caph garharheq are not emotions). Those minor disagreements/edge cases are <em>not</em> what I am talking about, but a brand new emotion. Hypothetically, I can imagine that one might result from novel stimuli (or patterns of stimuli) never before experienced by humans (and thus resulting in a never-before seen affect on the brain), but I am not aware of any actual cases of this occurring or any known (outside of science fiction) theory of what sort of stimuli patterns might accomplish this or what such an emotion might be like.</p>\n\n<p>If it has been shown that one of the \"standard\" emotions today arose <em>after</em> the advent of anatomically-modern humans (e.g. Cro-Magnon), I would consider that an answer.</p>\n\n<p>In response to a comment by Bryan Krause, I am aware that there is a linguistic argument here. I'm imagining this as similar to the linguistic/neurological divide in color taxonomy. Famously, Russian does not have a single word for \"blue\" (instead, dividing it up into two separate colors), while Japanese historically did not distinguish between what English speakers call blue and green, but I believe it is fairly well understood that these distinctions happen at a fairly high level in the brain, rather than representing truly distinct forms of cognitive evolution. The color equivalent to my question could be whether it is possible for the brain to evolve, or for novel stimuli to generate, an <em>entirely new color that no one has ever seen before</em> and that cannot be reasonably described as a variant or subtype of an existing color. Some science fiction authors, famously H. P. Lovecraft, have tried to imagine a \"new\" color, so the idea that new cognitive experiences could be found is certainly not new.</p>\n\n<p>Another way to ask this is whether the process of coming up with new words to describe emotions represents enhancements in the <em>understanding</em> of current emotions or whether it represents truly new emotions never before experienced or observed.</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 0}
{"question": "How to find an arXiv endorser", "body": "<p>I have recently completed a manuscript and I want it to submit to the arXiv. But there I find that there is an endorsement requirement. But since I am quite new in this field (and this is my first time wanting to submit to arXiv), I don't know how to find an endorser myself. I have mailed the <em>admin</em> also but in reply they also told me that <em>searching for an endorser is a responsibility of the author himself</em>. So, can anyone help me regarding the process as to how to find an endorser?</p>\n", "pids": ["56d886aedabfae2eee937421"], "flag": 1}
{"question": "Is a person who believe that their depression is curable more likely to overcome it?", "body": "<p>According to the idea of the growth mindset a person is more likely to successfully change, when they believe that change is possible.</p>\n\n<p>To what extend does that apply to depression? Is a person who believes that it's possible to overcome their depression more likely to overcome it then a person who believes that there's no hope overcoming their depression?</p>\n", "pids": ["53e9a0fbb7602d97029e5725", "53e99dbfb7602d970267fa52", "53e99e5bb7602d970271d2e6"], "flag": 0}
{"question": "Why do skinny people live for shorter than the norm even though calorie restriction extends life expectancy?", "body": "<p>If I understand correctly, calorie restriction may extend life expectancy slightly (not proven exactly how much for human). But according to the statistics, skinny healthy people have even shorter life expectancy than healthy, slightly obese people. Could you explain why this is not considered as contradictory?   </p>\n", "pids": ["55a4e0f865ceb7cb02dac9ef"], "flag": 1}
{"question": "Is it possible to separately evolve a part of the population?", "body": "<p>In a classic example of a genetic algorithm, you would have a population and a certain amount of simulation time to evaluate it and breeding. Then proceed to the next generation.</p>\n\n<p>Is it possible, during the simulation process, to have an isolated and small part of the population and keep it evolving in their own little island for some time while the rest of the population continues to evolve normally? \nAfter that, they could be reunited with the rest of the population and the end of the simulation would go through. After that, breed the population and continue. </p>\n\n<p>This is a super important part of natural evolution and probably some know if it actually works with genetic programming?</p>\n", "pids": ["573696006e3b12023e513b81", "5736981c6e3b12023e6ef083"], "flag": 1}
{"question": "Why do feedforward neural networks require the inputs to be of a fixed size, while RNNs can process variable-size inputs?", "body": "<p>Why does a vanilla feedforward neural network only accept a fixed input size, while RNNs are capable of taking a series of inputs with no predetermined limit on the size? Can anyone elaborate on this with an example?</p>\n", "pids": ["5550410f45ce0a409eb384f8"], "flag": 1}
{"question": "Why do views make you happy?", "body": "<p>Why does having a nice view from your window make you happy? (As in people ask for a hotel room with a nice view).</p>\n\n<p>Could this be replicated by simply having a large TV screen showing a view?</p>\n\n<p>What views make people the happiest/saddest?</p>\n", "pids": ["55a556f065ceb7cb02e8daa8", "53e9bd92b7602d9704a3e598", "53e9aa16b7602d9703384c29"], "flag": 0}
{"question": "What happens in the brain that allows access to a previous unavailable memory?", "body": "<p>What happens in the brain that allows you access to a memory previous unavailable?</p>\n\n<p>For example I forgot the name of someone I've known for years. Two weeks later, without notice, \"Diana\" popped up. </p>\n\n<p>Why was it not accessible when I found I couldn't remember?</p>\n\n<p>What was the chemistry that occurred that allowed it to happen later?</p>\n\n<p>(Secondarily, is this the same breakdown in dementia and alzheimer's? That is, a breakdown of the 'search memory' mechanism? Or is that the memories themselves are 'losing coherence.') </p>\n", "pids": ["55a49f0f65ceb7cb02d46ae7"], "flag": 0}
{"question": "How does a pine cone open?", "body": "<p>When a pine cone is wet, it remains closed. However, when it's dry it opens again. </p>\n\n<p>From the perspective of physics or biomechanics, what is the mechanism that allows a pine cone to open and close as I've described?</p>\n", "pids": ["56d81887dabfae2eee82c413", "53e9b221b7602d9703cba3ac"], "flag": 1}
{"question": "Can you grow a small brain network in a petri dish?", "body": "<p>Perhaps with stem cells, genetic engineering like CRISPR, or just cellular extraction and harvesting/reproduction in some way, we could isolate and incubate a single neuron in an artificial environment, for example, a Petri dish or something similar.</p>\n<p>Has anyone succeeded in doing so for some N number of neurons and connecting them via the synapses, as they are in the brain?</p>\n<p>And then, trying to stimulate some of the neurons and exploring if that neural network can be used for anything, or used to study how the greater brain works?</p>\n<p>Thank you</p>\n", "pids": ["55a55eaa65ceb7cb02e9e657"], "flag": 1}
{"question": "Bias distrusting area of expertise while implicitly trusting other domains?", "body": "<p>I've run across descriptions of this bias before, but cannot find it right now...  I checked Wikipedia's <a href=\"https://en.wikipedia.org/wiki/List_of_cognitive_biases\" rel=\"nofollow noreferrer\">list of cognitive biases</a> to no avail.</p>\n<p>Basically, people working in some domain and having expertise in it, naturally tend to notice the problems in that area, such as incompetence of other people working in their field, bad policies and poor management decision making, etc, resulting in a disproportionate distrust of their own field of expertise.  For example, healthcare workers are <a href=\"https://dx.doi.org/10.1016%2Fj.ebiom.2015.06.028\" rel=\"nofollow noreferrer\">more likely to be vaccine hesitant</a> because they distrust their own industry more than most due to personal experience with incompetence, mismanagement, politics, and corruption within their field.</p>\n<p>However, this distrust does not carry over to other domains.  So for example, watching a movie that portrays something you have domain knowledge in, you will quickly notice the inaccuracies and misrepresentation, but portrayals of domains outside your expertise will naturally be believable and perceived as accurate.  Similarly, reading news stories about topics that you have expertise in, you will notice inaccuracies and bias immediately, but fail to recognize that the same level of inaccuracy and bias must exist in domains outside your area of expertise, implicitly treating such news stories as accurately reported.</p>\n<p>What is this bias called?</p>\n", "pids": ["53e99e71b7602d9702736f6d", "53e9992ab7602d970216500e", "56d81d40dabfae2eeea30bee", "53e9b8c1b7602d97044a0a25"], "flag": 1}
{"question": "Did any dinosaur molt?", "body": "<p>Like snakes or lizards, did any dinosaur molt ?</p>\n\n<p>if yes, have we any proof of it ?</p>\n", "pids": ["55a3dddc65ce5cd7b3baaecc"], "flag": 1}
{"question": "What is the link between descriptive norm &amp; informational social influence? When the descriptive norm doesn&#39;t appear to be &quot;correct&quot;?", "body": "<p>I'm a first-year psychology student and this week I'm learning (from a crappy lecturer) about social norms, specifically injunctive vs descriptive norms, and normative vs informational social influence.</p>\n<p>I came across the following excerpt from my textbook:</p>\n<blockquote>\n<p>People conform to injunctive norms to gain social approval or to avoid social sanctions. [...] Conforming to descriptive norms typically has a different motivation, namely the desire to be correct. In many instances, following the group will lead to a correct outcome. For example,×following the crowd after arriving by train to an unfamiliar station will likely lead you to the exit. Deutsch and Gerard (1955) termed this type of motivation informational social influence.<br />\n(Steg, L., Berg, A., &amp; de Groot, J. (2019). Environmental psychology - An Introduction (2nd ed.). BPS Blackwell.)</p>\n</blockquote>\n<p>My question is, what if the group action is obviously wrong from the start? For instance, smoking, littering, or vandalism. Is the descriptive norm in this case still motivated by <em>informational</em> social influence? Or is the association between these two concepts not always applicable?</p>\n", "pids": ["5ce2d034ced107d4c6353607"], "flag": 1}
{"question": "How can I predict the next number in a non-obvious sequence?", "body": "<p>I've got an array of integers ranging from -3 to +3.</p>\n<p>Example: [1, 3, -2, 0, 0, 1]</p>\n<p>The array has no obvious pattern since it represents bipolar disorder mood swings.</p>\n<p>What is the most suitable approach to predict the next number in the series? The length of the array is about 700 entries.</p>\n<p>From where can I start the investigation? (provided that I've got some experience in Python and <a href=\"https://en.wikipedia.org/wiki/Node.js\" rel=\"nofollow noreferrer\">Node.js</a>, but only a hello-worldish acquaintance with <a href=\"https://en.wikipedia.org/wiki/TensorFlow\" rel=\"nofollow noreferrer\">TensorFlow</a>). Which training model might be suitable in this case? How can I chunk the data set properly?</p>\n", "pids": ["5c756feef56def97986a480a"], "flag": 1}
{"question": "Feasibility of an AI assistant to expedite game development?", "body": "<p>Basically, an AI that can create, rig, and texture 3d models and game environments (by extrapolating from collections of reference models, according to user input), and that can set up physics and mechanics (assuming that the AI has access to a 3d modeling studio and a game engine, both designed for compatibility with the AI, or as a component of the AI), all according to user commands (and allowing for tweaking and optimizations of models, rigging, mechanics, etc, by the user).</p>\n\n<p>An example of user commands would be something like: \"Gaming AI, create a casual style* male model, European build, 6'5\", fit and slightly skinny, with red scaly skin, green eyes, a reptilian tail, demonic wings, claws, sharp teeth\", etc. The user probably wouldn't add all of these characteristics at once, but rather one at a time, tweaking each feature via AI commands or manually.</p>\n\n<p>*\"casual style\" is a fictional \"style class\". Style classes would refer to the visual style of the models. Possible example styles include \"cartoon\", \"abstract\", \"gothic\", \"steampunk\", \"serious\" and \"realistic\".</p>\n\n<p>Here's another example of user commands, for a environmental model: \"Gaming AI, create a serious style house, Victorian, two story, white with beige trim, with porches and shutters. Give it a creepy aesthetic.\" Again, models could be created and modified or have features added in a step by step process, in order to tweak and refine them.</p>\n\n<p>I believe that such an AI would significantly reduce the amount of time, labor, and difficulty involved in designing games; making games cheaper and easier to produce, and making game design available to everyone. A variation of such an AI could also be used to create 2d artwork and animations.</p>\n\n<p>But is such an AI even remotely possible? And would it take a supercomputer to run the thing? (I'm under the impression that such an AI would need to be capable of learning and adapting, and would require a massive and expansile \"association library\"*—including 2d and 3d models, and verbal and textual speech—as well as near human intelligence)</p>\n\n<p>*if the term \"association library\" doesn't exist, or doesn't currently relate to AI, Then I just made it up. According to my made up definition, an association library is the library of programmed or learned associations that an AI uses to generate responses, and to, in this context, generate 3d models; and probably to write or select code as well, in order to set up physics and mechanics and the like. </p>\n", "pids": ["5a9cb65d17c44a376ffb84c7"], "flag": 1}
{"question": "Cause of hexadactylisim in Amish people", "body": "<p>Is it caused by inbreeding of many generations within an isolated population?</p>\n", "pids": ["62ac2c1b5aee126c0fec76f8"], "flag": 1}
{"question": "Do males ever produce the offspring?", "body": "<p>Are there any <em>non-asexual</em> species in which the male of the species produces the offspring?</p>\n\n<p>If so, why are they considered <em>male</em> and not <em>female</em>?</p>\n", "pids": ["5fd570508cdecd4daa27ff44"], "flag": 1}
{"question": "Can games be solved without an evaluation function?", "body": "<p>Fundamentally, a game-playing AI must solve the problem of choosing the best action from a set of possible actions.</p>\n<p>Most existing game AI's, such as AlphaGo, do this by using an <strong>evaluation function</strong>, which maps game states to real numbers. The real number typically can be interpreted as a monotonic function of a winning probability estimate. The best action is the one whose resultant state yields the highest evaluation.</p>\n<p>Clearly, this approach can work well. But it violates one of <a href=\"https://books.google.com/books?id=N_-5VRWai84C&amp;pg=PA477&amp;lpg=PA477&amp;dq=%22When%20solving%20a%20problem%20of%20interest,%20do%20not%20solve%20a%20more%20general%20problem%20as%20an%20intermediate%20step.%20Try%20to%20get%20the%20answer%20that%20you%20really%20need%20but%20not%20a%20more%20general%20one.%22&amp;source=bl&amp;ots=ReHvsikLSY&amp;sig=WkN0ETtVyEXlgkWWQoiY4b-qWxE&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwj6m6z-g5_OAhWGpB4KHf54DYcQ6AEIKTAC#v=onepage&amp;q=%22When%20solving%20a%20problem%20of%20interest%2C%20do%20not%20solve%20a%20more%20general%20problem%20as%20an%20intermediate%20step.%20Try%20to%20get%20the%20answer%20that%20you%20really%20need%20but%20not%20a%20more%20general%20one.%22&amp;f=false\" rel=\"nofollow noreferrer\">Vladimir Vapnik's imperatives</a> (in his book &quot;Estimation of Dependences Based on Empirical Data&quot;): &quot;<em>When solving a problem of interest, do not solve a more general problem as an intermediate step.</em>&quot; In fact, he specifically states as an illustration of this imperative,</p>\n<blockquote>\n<p>Do not estimate predictive values if your goal is to act well. (<em>A good strategy of action does not necessarily rely on good predictive ability.</em>)</p>\n</blockquote>\n<p>Indeed, human chess and go experts appear to heed his advice, as they are able to act well without using evaluation functions.</p>\n<p>My question is this: <strong>has there has been any recent research aiming to solve games by learning to compare decisions directly, without an intermediate evaluation function</strong>?</p>\n<p>To use AlphaGo as an example, this might mean training a neural network to take <strong>two</strong> (similar) board states as input and output a choice of which one is better (a classification problem), as opposed to a neural network that takes <strong>one</strong> board state as input and outputs a winning probability (a regression problem).</p>\n", "pids": ["573696ce6e3b12023e5ce73f"], "flag": 1}
{"question": "How can psychopaths with no sympathy for their victims, exploit empathy to ensnare or torture them?", "body": "<p>I understand the difference between <a href=\"https://english.stackexchange.com/a/423583/50720\">empathy and sympathy</a>, but not the emboldened sentence. Please expound? </p>\n\n<p><a href=\"https://www.psychologytoday.com/ca/blog/hide-and-seek/201505/empathy-vs-sympathy\" rel=\"noreferrer\">Empathy vs. Sympathy | Psychology Today Canada</a></p>\n\n<blockquote>\n  <p>Sympathy (‘fellow feeling’, ‘community of feeling’) is a feeling of care and concern for someone, often someone close, accompanied by a wish to see him better off or happier. Compared to pity, sympathy implies a greater sense of shared similarities together with a more profound personal engagement. However, sympathy, unlike empathy, does not involve a shared perspective or shared emotions, and while the facial expressions of sympathy do convey caring and concern, they do not convey shared distress. Sympathy and empathy often lead to each other, but not always. For instance, it is possible to sympathize with such things as hedgehogs and ladybirds, but not, strictly speaking, to empathize with them. Conversely, <strong>psychopaths with absolutely no sympathy for their victims can nonetheless make use of empathy to ensnare or torture them</strong>. Sympathy should also be distinguished from benevolence, which is a much more detached and impartial attitude.</p>\n</blockquote>\n", "pids": ["5e09aa6edf1a9c0c416bf087"], "flag": 0}
{"question": "Why is AI safety so much harder than Isaac Asimov&#39;s &quot;Three Laws of Robotics&quot;?", "body": "<p>I understand that AI researchers are trying to create AI designs that allow for desired behavior without undesirable side-effects. A classic example of an attempt is Isaac Asimov's <a href=\"https://en.wikipedia.org/wiki/Three_Laws_of_Robotics\" rel=\"nofollow noreferrer\">Three Laws of Robotics</a>. This idea seems to have been debunked due to its vague phrasing. In particular, I realize that the exact 3 laws from the stories can't work, but surely there is a set of more robust ones that can limit an AI to good behavior in the same way that people are restricted by law.</p>\n<p>Why have AI researchers not accepted an idea like the following (just making the laws more specific):</p>\n<blockquote>\n<p>What if the UN voted for the country with the fairest laws and all\nutility functions have 2/3 of their points made up of not breaking any\nof those laws. If the ai has a question, it could look at court\nprecedent just like a judge would or ask humans (with two-thirds of\nits points on the line, it should be pretty cautious).</p>\n<p>People have been looking for loopholes in law for thousands of years\nand there may not be any catastrophic ones left. (It certainly\nwouldn't be violent)</p>\n</blockquote>\n<p>I must be missing something if this is still an open problem.</p>\n", "pids": ["599c7c6d601a182cd27ad476"], "flag": 1}
{"question": "Where to begin with Political Psychology literature?", "body": "<p>I am a law and public policy scholar, and I'm currently developing a civics curriculum for YouTube. As a phd, I'm (perhaps to an unhealthy degree) concerned with being able to cite good science whenever it's available.</p>\n<p>However, my own field of political science has rather let me down. I am trying to gather data about the impacts of citizen engagement with government in a number of ways, and one of the key mechanisms I'm looking at is contacting one's electeds (&quot;write your congressman!&quot; etc.).</p>\n<p>The problem is I'm not able to find literature on electeds' response to such communications (real or self-perceived) but have noticed some studies in behavioral psych that are next door to these themes.</p>\n<p>Lacking in a solid base of literature to begin from makes this search even harder and so...</p>\n<p>Q: Which authors/texts are considered foundational in political psychology, or behavioral psychology that covers political contexts?</p>\n", "pids": ["5d9eda5d47c8f76646010dc6", "62193f585aee126c0fd07327"], "flag": 1}
{"question": "What is the difference between hindsight bias and confirmation bias?", "body": "<p>I'm trying to understand better the influence of psychological biases on the financial market decision-making process.</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Hindsight_bias\" rel=\"noreferrer\">Wikipedia</a> describes hindsight as follow:</p>\n\n<blockquote>\n  <p>Refers to the common tendency for people to perceive events that have already occurred as having been more predictable than they actually were before the events took place. As a result, people often believe, after an event has occurred, that they would have predicted, or perhaps even would have known with a high degree of certainty, what the outcome of the event would have been before the event occurred. </p>\n</blockquote>\n\n<p>While the definition of confirmation bias according to the <a href=\"https://en.wikipedia.org/wiki/Confirmation_bias\" rel=\"noreferrer\">same source</a> is relatively similar:</p>\n\n<blockquote>\n  <p>Confirmation bias is the tendency to search for, interpret, favor, and recall information in a way that confirms one's preexisting beliefs or hypotheses.</p>\n</blockquote>\n\n<p>I think that those biases differ from the results' reflection perspective. However, I'm a bit confused about the proper interpretation. </p>\n\n<p>Thanks in advance.</p>\n", "pids": ["55a57bd5612c6b12ab1e3a04", "53e9ab00b7602d9703481d29"], "flag": 0}
{"question": "Terror management theory: Is this a valid conclusion based on the conducted experiment?", "body": "<p>I am currently reading the book <a href=\"https://rads.stackoverflow.com/amzn/click/com/1400067472\" rel=\"nofollow noreferrer\" rel=\"nofollow noreferrer\">‘The Worm at the Core: On the Role of Death in Life’</a>. I have to say that I am a bit skeptical about many of the statements posed, and I’m trying to identify why that is, so I decided to dive into some of the articles they reference.</p>\n\n<p>One of the things I encountered was a reference to a paper by <a href=\"https://doi.org/10.1037/0022-3514.92.5.789\" rel=\"nofollow noreferrer\">Schimel et al. (2007)</a>: <em>\"Is Death Really the Worm at the Core? Converging Evidence That Worldview Threat Increases Death-Thought Accessibility.\"</em> In Study 5, they state:</p>\n\n<blockquote>\n  <p>The results of Study 5 demonstrate, once again, that exposure to\n  worldview-threatening information causes thoughts of death to become\n  more accessible</p>\n</blockquote>\n\n<p>They base this on an experiment in which they compare the DTA (death-thought accesibility) in three groups:</p>\n\n<ul>\n<li>creationist/anti-creation, creationists who read anti-creation material (n=20, M=2.75)</li>\n<li>evolutionist/anti-creation, evolutionists who read anti-creation material (n=20, M=1.95)</li>\n<li>creationist/control, creationists who read neutral material (n=20, M=1.90)</li>\n</ul>\n\n<p>I have trouble to see the validity of the conclusion based on the experiment. Might it not also just be the case that creationists in general think more about death? And that reading a passage about the theory of evolution (which is inherently about life and death), makes everyone, regardless of their point of view on evolution, think more about death? I think the problem with this experiment is that there is a group missing in the experiment; the evolutionist/control group. It might be very well possible that this group has a DTA of 0.95 and a low SD. If that were the case, reading the passage has increased the DTA of both the creationists and the evolutionists and thus nothing can be said about the effect of worldview-threatening information. All we would then conclude, is that reading about evolution increases DTA.</p>\n\n<p>I am not a researcher myself, nor am I very familiar with social sciences. I hope someone with more experience in these fields could explain to me if my train of thought is correct, or if not, where the fallacy in this train of thought is. </p>\n\n<p>I would also be interested to find references to articles that contain experiments that substantiate the statement cited above.</p>\n\n<p><sub>\nSolomon, S., Greenberg, J., &amp; Pyszczynski, T. (2015). <a href=\"https://rads.stackoverflow.com/amzn/click/com/1400067472\" rel=\"nofollow noreferrer\" rel=\"nofollow noreferrer\">The worm at the core: On the role of death in life.</a> Random House.<br>\nSchimel, J., Hayes, J., Williams, T., &amp; Jahrig, J. (2007). <a href=\"https://doi.org/10.1037/0022-3514.92.5.789\" rel=\"nofollow noreferrer\">Is death really the worm at the core? Converging evidence that worldview threat increases death-thought accessibility.</a> Journal of personality and social psychology, 92(5), 789. (<a href=\"https://www.researchgate.net/profile/Jesse_Jahrig/publication/6346017_Is_Death_Really_the_Worm_at_the_Core_Converging_Evidence_That_Worldview_Threat_Increases_Death-Thought_Accessibility/links/0deec538761ba43e48000000.pdf\" rel=\"nofollow noreferrer\">Free PDF</a>)\n</sub></p>\n", "pids": ["53e9b45fb7602d9703f5f459"], "flag": 0}
{"question": "How and why do skin tags develop?", "body": "<p>WebMD <a href=\"http://www.webmd.com/skin-problems-and-treatments/tc/removing-moles-and-skin-tags-topic-overview\">writes</a>:</p>\n\n<blockquote>\n  <p>Skin tags are small, soft pieces of skin that stick out on a thin stem. They most often appear on the neck, armpits, upper trunk, and body folds. The cause of skin tags is not known. </p>\n</blockquote>\n\n<p>Do we really know nothing about why they appear? Is there research that suggest hypotheses of the causes of <a href=\"http://en.wikipedia.org/wiki/Acrochordon\">skin tags</a>?\nIt seems to me a pretty well established phenomena for it to be without good research.</p>\n", "pids": ["55a69ade65ce054aad6d9be6"], "flag": 1}
{"question": "Open versus Blind reviewing process", "body": "<p>A question I have been wondering for a while is if there exists an actual proof that a blind reviewing process (i.e. where the reviewers are anonymous, and the reviews not published) is better than an open one (i.e. where the reviewers are not anonymous and/or the reviews are published along with the accepted papers). </p>\n\n<p>Basically, whenever I question the fact that having a blind reviewing process does not guarantee any quality (which, somehow, usually coincides with receiving a poor review for a paper ...), I'm told that anonymity is crucial for the reviewing process. But is there any proof of that? I don't believe there exists any perfect system, but I'm just not sure why does the blind (or even double-blind) one is considered as the best (or the \"least worst\"). </p>\n", "pids": ["5e72350993d709897cfdd5e5"], "flag": 1}
{"question": "Do butterflies pass over migration patterns to their offspring?", "body": "<p>So, earlier, I read online (<a href=\"http://io9.com/butterflies-remember-a-mountain-that-hasnt-existed-for-509321799\">http://io9.com/butterflies-remember-a-mountain-that-hasnt-existed-for-509321799</a>) that Monarch butterflies veer east during their southward migration to avoid a mountain that no longer exists. If this is true, how do butterflies know to continue avoiding the \"mountain\" after countless generations, and does it have to do with evolution? Do other animals have similar abnormalities in their migration routes?</p>\n", "pids": ["55a694ff65ce054aad6ca2bc"], "flag": 1}
{"question": "Lunar cycles linked with mental health issues?", "body": "<p>From what I can find...</p>\n<ol>\n<li>Anecdotally, my mother used to work in nursing homes for the elderly and found that around the full moon, patients slept less and were more agitated.</li>\n</ol>\n<blockquote>\n<p>Anecdotal evidence concerning a relationship between human illnesses and a full moon is frequently claimed by as many as 81% of mental health workers (<a href=\"https://pubmed.ncbi.nlm.nih.gov/28841578/\" rel=\"noreferrer\">Francis, et al. 2017</a>).</p>\n</blockquote>\n<ol start=\"2\">\n<li><a href=\"https://www.theguardian.com/uk/2007/jun/05/ukcrime\" rel=\"noreferrer\">Police have linked full moons</a> to a rise in aggressive behaviour among drinkers on the streets of Brighton.</li>\n</ol>\n<blockquote>\n<p>Research carried out by us has shown a correlation between violent incidents and full moons.</p>\n</blockquote>\n<ol start=\"3\">\n<li>The same newspaper report cited a 1998 study without reference information, stating that</li>\n</ol>\n<blockquote>\n<p>In 1998, a three-month psychological study of 1,200 inmates at Armley jail in Leeds discovered a rise in violent incidents during the days on either side of a full moon.<br>\n<br>\nDuring the first and last quarter of each lunar month there was a marked increase in violent incidents.During the remaining part of the month there were far fewer incidents and none at all on some days.</p>\n</blockquote>\n<p>I have yet to find the 1998 study through <a href=\"https://scholar.google.com\" rel=\"noreferrer\">Google Scholar</a> etc. but I have found some research (e.g. the open access <a href=\"https://doi.org/10.1016/j.cub.2008.07.003\" rel=\"noreferrer\">Foster &amp; Roenneberg (2008)</a>) finding no link. I was wondering if there has been <strong>any possible</strong> link found in clinical research?</p>\n<p>My theory was initially that maybe the full moon might affect CSF (cerebral spinal fluid) levels around the various areas of the brain, much like it affects sea water levels with their tides. But, then I would have thought the same would occur at local sea tidal times. However, maybe tidal effects are stronger at full moon?</p>\n<h2 id=\"references-a1z4\">References</h2>\n<p>Attewill, F. (2007). Police link full moon to aggression. <em>The Guardian</em>. <a href=\"https://www.theguardian.com/uk/2007/jun/05/ukcrime\" rel=\"noreferrer\">https://www.theguardian.com/uk/2007/jun/05/ukcrime</a></p>\n<p>Foster, R. G., &amp; Roenneberg, T. (2008). Human responses to the geophysical daily, annual and lunar cycles. <em>Current biology, 18</em>(17), R784-R794. <a href=\"https://doi.org/10.1016/j.cub.2008.07.003\" rel=\"noreferrer\">https://doi.org/10.1016/j.cub.2008.07.003</a></p>\n<p>Francis, O. J., Kopke, B. J., Affatato, A. J., &amp; Jarski, R. W. (2017). Psychiatric Presentations During All 4 Phases of the Lunar Cycle. <em>Advances in mind-body medicine, 31</em>(3), 4–7. <a href=\"https://pubmed.ncbi.nlm.nih.gov/28841578/\" rel=\"noreferrer\">https://pubmed.ncbi.nlm.nih.gov/28841578/</a></p>\n", "pids": ["55a5d5f52401defa0da5bd7e"], "flag": 0}
{"question": "Why do some papers have 10-20 co-authors?", "body": "<p>I am new to the field of academia, and when performing a literature review for really any topic, I am puzzled as to why some papers have so many co-authors.</p>\n\n<p>Most papers have only about 1-5 authors which I can understand but I can't seem to understand how 10-20 people could all meaningfully contribute to a single paper. How possible is it that co-authorship is being gifted?</p>\n\n<p>Are there any reasons why so many co-authors could be justified?</p>\n\n<p><strong>Update 11/11/19:</strong>\nSome comments have suggested this question may be a duplicate. To clarify: I was not referring to large-scale taskforces that produce world-changing results such as the Higgs Boson project (<a href=\"https://academia.stackexchange.com/questions/63440/what-is-the-point-of-listing-1000-authors-for-a-single-scientific-paper?noredirect=1&amp;lq=1\">What is the point of listing 1000 authors for a single scientific paper?</a>). Those projects clearly play by different rules. I was meaning routine contributions to journals (such as a new formula or algorithm) where I struggle to understand how so many people could all meaningfully contribute to a small (albeit important) idea.</p>\n", "pids": ["5f0c2fe09fced0a24bb0c1f6"], "flag": 1}
{"question": "What does it mean if a neuron is &quot;expressing&quot; something?", "body": "<p>Sorry for the simple question, not a neuroscientist just trying to understand a paper for school. In a study with mice, there was 2-photon calcium imaging done, and part of it read:</p>\n<blockquote>\n<p>We used single- and multi-plane imaging approaches to record the activity of populations of excitatory neurons and two inhibitory classes, Somatostatin (Sst) and Vasoactive Intestinal Peptide (Vip) expressing interneurons, across multiple cortical depths and two visual areas (VSIp and VISl)</p>\n</blockquote>\n<p>First I thought this meant that SST &amp; VIP were inhibitory neurons. But when I Google it says they're <a href=\"https://en.wikipedia.org/wiki/Somatostatin\" rel=\"nofollow noreferrer\">hormones</a>.</p>\n<p>So is this saying they recorded activity from inhibitory interneurons that were ... releasing? producing? ... SST &amp; VIP ? What does &quot;expressing&quot; mean in this sense.</p>\n", "pids": ["53e9bad7b7602d9704706183", "55a51c2365ceb7cb02e13364"], "flag": 1}
{"question": "Why do people sometimes put authors with equal contribution in non-alphabetical order?", "body": "<p>I've seen papers (e.g., in <em>Science</em>) where the first two authors are listed in non-alphabetical order, and yet there are asterisks behind their names to say that they contributed equally.</p>\n<p>It seems strange to me, because if the two authors are in alphabetical order, then it could be that the first author contributed more or the two contributed equally, and this can be made clear with asterisks in the paper if it's the latter case. When they're in non-alphabetical order, however, if someone only sees the author list without seeing the paper, they will likely assume that the first author contributed most.</p>\n<p>So my question is: Are there particular reasons why people do that? (This <a href=\"https://academia.stackexchange.com/questions/17239/should-co-first-authors-be-listed-in-alphabetical-order\">question</a> is related, but I don't think the answers there get to my question.)</p>\n", "pids": ["53e9a7eab7602d9703128239", "58437722ac44360f1082ede4", "5390b04120f70186a0ed72c9"], "flag": 1}
{"question": "What predicts the severity of rejection pain?", "body": "<p>A number of studies show that social rejection causes actual pain. Is there a study that focuses on finding the personality dimensions that predict the amount of such pain? For example, is there a correlation between <a href=\"https://en.wikipedia.org/wiki/Big_Five_personality_traits#Extraversion\" rel=\"noreferrer\">extroversion</a> and the severity of rejection pain?</p>\n\n<p><a href=\"https://psychology.stackexchange.com/a/3541\">An answer nearby</a> suggests that there is some kind of <em>\"sensitivity\"</em> to a person, but I am so far unable to determine what exactly this <em>\"sensitivity</em>\" means.</p>\n\n<p><sub>\nReferences:<br>\nK. D. Williams and allies — \"Ostracism: Consequences and Coping\"<br>\nNaomi I. Eisenberger and allies — \"Does Rejection Hurt? An fMRI Study of Social Exclusion\"\n</sub></p>\n", "pids": ["55a47ad565ce31bc877c7dc2", "55a67bf065ce054aad694a99", "56d8e5f6dabfae2eee314a2f", "56d8e5f6dabfae2eee314a2f"], "flag": 0}
{"question": "Combinatorial woes", "body": "<p>I am interested in the creation of chunks (aka configural nodes) from smaller chunks and input features (only interested in System 1 cognition).</p>\n\n<p>Unitization studies (e.g. Goldstone (<a href=\"http://cogprints.org/909/3/doodlesold.pdf\" rel=\"nofollow\">pdf</a>)), suggest that we start with generic features, and slowly combine them into more specific chunks. As we do this unitization, we wouldn't store all of the learned combinations --- a mere 10 input features can be combined in 3.6 million configurations!</p>\n\n<p>Simon suggested generic elements get overwritten by more specific ones at each exposure. but what would you do with the predictions/rules learned about a given chunk? Transfer them to the newly created specific chunk? What if they do not apply at that more specific level?</p>\n\n<p>Nosofsky was suggesting a rule-plus-exception model, where the more generic elements are always stored and their predictions are recorded as general rules; When those predictions are broken, more specific chunks are stored to explain the exceptions to these rules. What does it mean for predictions to be broken? In a probabilistic environment like ours, sometimes a prediction is correct, sometimes it isn't -- updating the weight of the prediction seems much more reasonable than deeming it invalid in favor of an 'exception'.</p>\n\n<p>When do I chunk two co-occurring features? When do I chunk those two with a third? Do I delete the 2-feature chunk in favor of the 3-feature? What do I do with the memories associated with the deleted chunk?</p>\n", "pids": ["55a4674865ce31bc8779683a"], "flag": 1}
{"question": "Which explainable artificial intelligence techniques are there?", "body": "<p><a href=\"https://en.wikipedia.org/wiki/Explainable_artificial_intelligence\" rel=\"nofollow noreferrer\">Explainable artificial intelligence (XAI)</a> is concerned with the development of techniques that can enhance the interpretability, accountability, and transparency of artificial intelligence and, in particular, machine learning algorithms and models, especially black-box ones, such as artificial neural networks, so that these can also be adopted in areas, like healthcare, where the interpretability and understanding of the results (e.g. classifications) are required.</p>\n<p>Which XAI techniques are there?</p>\n<p>If there are many, to avoid making this question too broad, you can just provide a few examples (the most famous or effective ones), and, for people interested in more techniques and details, you can also provide one or more references/surveys/books that go into the details of XAI. The idea of this question is that people could easily find one technique that they could study to understand what XAI really is or how it can be approached.</p>\n", "pids": ["573695fd6e3b12023e51117d", "5d04e8f8da56295d08dcbe18", "637cf7a390e50fcafd554bfa", "5e09a990df1a9c0c416a8447", "5d0b007b8607575390fc9bae", "627107e25aee126c0ff4c263", "58d83014d649053542fe190b", "5c8b13614895d9cbc64b4fbc", "5736973c6e3b12023e62b9e5", "5f2e6ad091e011ecdac9c128", "58d82fd2d649053542fd77e9", "6284fc4b5aee126c0f3ebbaa", "5a9cb66717c44a376ffb8a3d", "5c8d77904895d9cbc660da23", "5f914e1791e011126509bc9f", "5f50c4339fced0a24b9c143c", "5d8898013a55acdc5ca0884e", "5e3be3c33a55ac29c4ae7d4c", "5efdb2e09fced0a24b638e7b", "5a4aef9e17c44a2190f7a565", "5cf48a21da56291d58282d4e", "5c8dbaf34895d9cbc6893332", "5f8ec60091e01153024c4e47", "5a260c0917c44a4ba8a1df31", "5e3be3c33a55ac29c4ae7d4c", "573695fd6e3b12023e51117d", "5c04967517c44a2c74709270", "6059bb8a91e011ed950a5a73", "5f6dc25391e0115337005566", "599c797a601a182cd26427e2"], "flag": 1}
{"question": "What is the most time-consuming part of training deep networks?", "body": "<p>Deep networks notoriously take a long time to train. </p>\n\n<p>What is the most time-consuming aspect of training them? Is it the matrix multiplications? Is it the forward pass? Is it some component of the backward pass?</p>\n", "pids": ["5efb0d5691e011063336d45f"], "flag": 1}
{"question": "What is the study with the dual-task experiment that involved a colour-wheel change detection task?", "body": "<p>This may be a long-shot, but I'm looking for a paper that I vaguely remember reading a few years ago. Unfortunately I can't remember many details about the paper or its content, and thus my multiple attempts at keyword searches have failed. I'm posting this question in the hope that someone recognises the few details I do remember.</p>\n\n<p>The paper presented more than one experiment, but the one I'm trying to recall involved a colour wheel/pie displayed in the centre of the screen. The slices of the pie were each a different colour and the colours would change a few times throughout each trial. There were only a small number of slices/colours. The observer's task was to count the number of times the colours changed. While doing this the observer also had to perform another task, for which the stimuli were shown on the rest of the display, in peripheral vision. I can't remember what the other task was, though it may have been a multiple object tracking task or a visual search task. The paper may have been about the effect of attentional load on working memory, though I'm not sure about that.</p>\n", "pids": ["53e9b070b7602d9703ad6a15"], "flag": 1}
{"question": "Is there any evidence for a link between religiosity and belief in conspiracy theories?", "body": "<p>I've heard claims made that more religious individuals were more likely to fall for various conspiracy theories.  I've personally been able to find studies linking religiosity to belief in qanon conspiracy theories, but since Qanon is a conservative conspiracy theory it makes sense more religious people, who tend to be more conservative, would be more prone to believing conservative leaning theories so I don't take that as proof of a link between religiosity and general belief in conspiracy theories.</p>\n<p>Thus I'm asking, has there been any peer reviewed studies that look at religiosity and (general) belief in conspiracy theories, and if so was a link found between the two, and if so how large a link?</p>\n<p>I'm a little more interested in the USA perspective, but since I suspect the trends are mostly the same in most 1st world countries I'd accept studies that look at any country that's generally '1st world'.  I'd accept studies of religiosity for Christianity, or general religiosity regardless of specific religion practiced.  I really just want to know if the claims that religious folks are more likely to fall for conspiracy theories has any basis on reality.</p>\n", "pids": ["55a5529165ceb7cb02e8432e", "628d20f75aee126c0f41f2fa", "609a6dcce4510cd7c88fcfee"], "flag": 0}
{"question": "What causes this motion illusion?", "body": "<p>There are some questions here about various optical illusions.\nI stumbled upon this one and would like to find out where does it belong.\nWikipedia has a page about <a href=\"https://en.wikipedia.org/wiki/Illusory_motion\" rel=\"noreferrer\">illusory motion</a> that mentions several types; <a href=\"https://en.wikipedia.org/wiki/Peripheral_drift_illusion\" rel=\"noreferrer\">peripheral drift</a> seems to be closest, but I am not sure about it.</p>\n<p><a href=\"https://i.stack.imgur.com/Wg1Ux.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/Wg1Ux.png\" alt=\"enter image description here\" /></a></p>\n", "pids": ["55a6031b65cead59c83290b6"], "flag": 0}
{"question": "Can GANs be used to generate something other than images?", "body": "<p>AFAIK, GANs are used for generating/synthesizing near-perfect human faces (deepfakes), gallery arts, etc., but can GANs be used to generate something other than images?</p>\n", "pids": ["5c8e602b4895d9cbc6e354f0", "5a9cb65d17c44a376ffb83c5"], "flag": 1}
{"question": "Are policy gradient methods good for large discrete action spaces?", "body": "<p>I have seen this question asked primarily in the context of continuous action spaces.</p>\n<p>I have a large action space (~2-4k discrete actions) for my custom environment that I cannot reduce down further:</p>\n<p>I am currently trying DQN approaches but was wondering that given the large action space - if policy gradient methods are more appropriate <strong>and</strong> if they are appropriate for large action spaces that are discrete as in my scenario above. I have seen answers to this question with regard to large continuous action spaces.</p>\n<p>Finally - I imagine there isn't a simple answer to this but: Does this effectively mean DQN will <strong>not</strong> work?</p>\n", "pids": ["5e72341993d709897cfbb428"], "flag": 1}
{"question": "Is there a technical term for &quot;fear of the unknown&quot;?", "body": "<p>I'm writing paper about climate change and its economic impacts on society.  Is there a generally accepted technical term for \"fear of the unknown\" in psychology?</p>\n", "pids": ["570faa190cf27170c78b92ed"], "flag": 0}
{"question": "Are GPT-3.5 series models based on GPT-3?", "body": "<p>In the official <a href=\"https://openai.com/blog/chatgpt/\" rel=\"noreferrer\">blog post about ChatGPT</a> from OpenAI, there is this paragraph explaining how ChatGPT model was trained:</p>\n<blockquote>\n<p>We trained this model using Reinforcement Learning from Human Feedback\n(RLHF), <strong>using the same methods as InstructGPT</strong>, but with slight\ndifferences in the data collection setup. We trained an initial model\nusing supervised fine-tuning: human AI trainers provided conversations\nin which they played both sides—the user and an AI assistant. We gave\nthe trainers access to model-written suggestions to help them compose\ntheir responses. We mixed this new dialogue dataset with the\nInstructGPT dataset, which we transformed into a dialogue format.</p>\n</blockquote>\n<p>Especially this part:</p>\n<blockquote>\n<p>We trained an initial model using supervised fine-tuning</p>\n</blockquote>\n<p>My question is about the said <em>initial model</em>, is it some new model that has been trained from scratch or is it a GPT-3 model that has been fine tuned for specific tasks resulting in <a href=\"https://platform.openai.com/docs/model-index-for-researchers\" rel=\"noreferrer\">GPT-3.5 series</a> ?</p>\n<p>On the other hand, from the <a href=\"https://openai.com/blog/instruction-following/\" rel=\"noreferrer\">InstructGPT blog post</a>, it is clearly stated that:</p>\n<blockquote>\n<p>To make our models safer, more helpful, and more aligned, we use an\nexisting technique called reinforcement learning from human feedback\n(RLHF). On prompts submitted by our customers to the API,our labelers\nprovide demonstrations of the desired model behavior, and rank several\noutputs from our models. <strong>We then use this data to fine-tune GPT-3</strong>.</p>\n</blockquote>\n<p>So does this mean that GPT-3.5 series models (and consequently ChatGPT) are fine-tuned from GPT-3 base model ?</p>\n", "pids": ["5ed0e04291e011915d9e43ee"], "flag": 1}
{"question": "wisdom of crowds and group polarization", "body": "<p>I'm having a hard time understanding two concepts, <a href=\"https://en.wikipedia.org/wiki/Wisdom_of_the_crowd\" rel=\"nofollow noreferrer\">wisdom of crowds</a> and <a href=\"https://en.wikipedia.org/wiki/Group_polarization\" rel=\"nofollow noreferrer\">group polarization</a>, at the same time.</p>\n<p>Wisdom of crowds states that aggregation of information or prediction, in groups are often <em>better</em> than single member's.</p>\n<p>Group polarization, however, refers to the tendency that group makes <em>more extreme</em> decisions than single member's.</p>\n<p>It seems that the group decision, due to group polarization, should be <em>less accurate</em> than single member's since it's more extreme, which conflicts the idea of wisdom of crowds. I assume there should be boundaries between two concepts and a case-by-case basis?</p>\n<p>Any help will be appreciated.</p>\n", "pids": ["5f0e24309fced0a24b05a849"], "flag": 1}
{"question": "What is the importance of the endocannabinoid system for cognitive function?", "body": "<p><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3997295/\" rel=\"nofollow noreferrer\">The endocannabinoid system is a very important function of human biology</a>. Unfortunately, due to the illegality of cannabis, it is a relatively new field of study. I have read a few articles about <a href=\"https://medium.com/@skychain.global/googles-deepmind-is-using-ai-to-explore-dopamine-s-role-in-learning-d07e7521b16b\" rel=\"nofollow noreferrer\">Google researching the role of dopamine in learning</a>, and <a href=\"http://reset.me/story/anandamide-putting-the-bliss-molecule-to-work-for-your-brain/\" rel=\"nofollow noreferrer\">according to this article</a>, anandamide (the neurotransmitter that closely resembles tetrahydrocannabinol):</p>\n\n<blockquote>\n  <p>was found to do a lot more than produce a state of heightened happiness. It’s synthesized in areas of the brain that are important in memory, motivation, higher thought processes, and movement control.</p>\n</blockquote>\n\n<p>Have any neuroscientists (or any scientists) considered the importance of the endocannabinoid system for cognitive function?</p>\n\n<p>If not, is there any reason this information might or might not be relevant to artificial intelligence?</p>\n", "pids": ["55a4678465ce31bc877974ba"], "flag": 1}
{"question": "How should I model all available actions of a chess game in deep Q-learning?", "body": "<p>I just read about deep Q-learning, which is using a neural network for the value function instead of a table.</p>\n<p>I saw the example here: <a href=\"https://yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html\" rel=\"nofollow noreferrer\">Using Keras and Deep Q-Network to Play FlappyBird</a> and he used a CNN to get the Q-value.</p>\n<p>My confusion is on the last layer of his neural net. Neurons in the output layer each represent an action (flap, or not flap). I also see the <a href=\"http://edersantana.github.io/articles/keras_rl/\" rel=\"nofollow noreferrer\">other projects</a> where the output layer also represents all available actions (move-left, stop, etc.)</p>\n<p><em>How would you represent all the available actions of a chess game?</em> Every pawn has a unique and available movement. We also need to choose how far it will move (rook can move more than one square). I've read <a href=\"https://arxiv.org/abs/1509.01549\" rel=\"nofollow noreferrer\">Giraffe chess engine's</a> paper and can't find how he represents the output layer (I'll read once again).</p>\n<p>I hope somebody here can give a nice explanation about how to design NN architecture in Q-learning, I'm new in reinforcement learning.</p>\n", "pids": ["5a73cbcc17c44a0b3035f7b3"], "flag": 1}
{"question": "Can you analyse a neural network to determine good states?", "body": "<p>I've developed a neural network that can play a card game.  I now want to use it to create decks for the game.  My first thought would be to run a lot of games with random decks and use some approximation (maybe just a linear approximation with a feature for each card in your hand) to learn the value function for each state.  </p>\n\n<p>However, this will probably take a while, so in the mean time is there any way I could get this information directly from the neural network? </p>\n", "pids": ["5c8f109a4895d9cbc6219cae"], "flag": 1}
{"question": "What work has been done studying methodological reforms in psychology after the replication crisis?", "body": "<p>Can anyone point me to academic work that systematically studies how standards and methods have changed in psychology as a response to the replication crisis? Thanks.</p>\n", "pids": ["605aa278e4510cd7c86b8676"], "flag": 1}
{"question": "What is the difference between edge computing and federated learning?", "body": "<p>I recently read about <a href=\"https://ai.googleblog.com/2017/04/federated-learning-collaborative.html\" rel=\"nofollow noreferrer\">federated learning</a> introduced by Google, but it seems to be like <a href=\"https://en.wikipedia.org/wiki/Edge_computing\" rel=\"nofollow noreferrer\">edge computing</a>.</p>\n\n<p>What is the difference between edge computing and federated learning?</p>\n", "pids": ["599c7cc1601a182cd27d4688"], "flag": 1}
{"question": "What factors influence a person&#39;s perceived expertise?", "body": "<p>For example, some people believe they are excellent human lie detectors. But, research shows that the average person is only able to detect deception about 54% of the time. What techniques could be used to influence perceived expertise?</p>\n", "pids": ["53e9a06cb7602d970295223a"], "flag": 0}
{"question": "Do good approximations produce good gradients?", "body": "<p>Let’s say I have a neural net doing classification and I’m doing stochastic gradient descent to train it. If I know that my current approximation is a decent approximation, can I conclude that my gradient is a decent approximation of the gradient of the true classifier everywhere?</p>\n\n<p>Specifically, suppose that I have a true loss function, $f$, and an estimation of it, $f_k$. Is it the case that there exists a $c$ (dependent on $f_k$) such that for all $x$ and $\\epsilon &gt; 0$ if $|f(x)-f_k(x)|&lt;\\epsilon$ then $|\\nabla f(x) - \\nabla f_k(x)|&lt;c\\epsilon$? This isn’t true for general functions, but it may be true for neural nets. If this exact statement isn’t true, is there something along these lines that is? What if we place some restrictions on the NN?</p>\n\n<p>The goal I have in mind is that I’m trying to figure out how to calculate how long I can use a particular sample to estimate the gradient without the error getting too bad. If I am in a context where resampling is costly, it may be worth reusing the same sample many times as long as I’m not making my error too large. My long-term goal is to come up with a bound on how much error I have if I use the same sample $k$ times, which doesn’t seem to be something in the literature as far as I’ve found.</p>\n", "pids": ["599c798c601a182cd264a7e4"], "flag": 1}
{"question": "Are there any sources that estimate the number of *unique* direct connections between neurons?", "body": "<p>There are plenty of sources on the number of synapses the average neuron in some region of the brain has. However, its become clear that there is <em>some</em> degree of redundancy in these connections, where a pair of neurons have multiple synapses between them. I'm aware that the multiple synapses aren't truly redundant, they serve a purpose. I just want to know if there are any estimates on how many other neurons a single neuron receives from on average.</p>\n", "pids": ["5cf8e4633a55ac7fe7882ba8"], "flag": 1}
{"question": "Term for how anxiety makes people think abnormally?", "body": "<p>For a paper I'm writing, I want to make a point about how anxiety changes the way people think - i.e., the same person in the same situation might think differently depending on whether or not they are anxious.</p>\n<p>The problem is that I'm not sure what search term to use to find papers that may be relevant, so I was just wondering if anyone else knows.</p>\n", "pids": ["53e9b53cb7602d97040740fb"], "flag": 1}
{"question": "How to deal with episode termination in Advantage Actor-Critic algorithm?", "body": "<p>Advantage Actor-Critic algorithm may use the following expression to get 1-step estimate of the advantage:</p>\n\n<p><span class=\"math-container\">$ A(s_t,a_t) = r(s_t, a_t) + \\gamma V(s_{t+1}) (1 - done_{t+1})  - V(s_t) $</span></p>\n\n<p>where <span class=\"math-container\">$done_{t+1}=1$</span> if <span class=\"math-container\">$s_{t+1}$</span> is a terminal state (end of the episode) and <span class=\"math-container\">$0$</span> otherwise.</p>\n\n<p>Suppose our learning environment has a goal, collecting the goal gives reward <span class=\"math-container\">$r=1$</span> and terminates the episode. Agent also receives <span class=\"math-container\">$r=-0.1$</span> for every step, encouraging it to collect the goal faster. We're learning with <span class=\"math-container\">$\\gamma=0.99$</span> and we terminate the episode after <span class=\"math-container\">$T$</span> timesteps if the goal wasn't collected.</p>\n\n<p>For the state before collecting a goal we have the following advantage, which seems very reasonable: <span class=\"math-container\">$A(s_t,a_t) = 1 - V(s_t)$</span>.</p>\n\n<p>For the timestep <span class=\"math-container\">$T-1$</span>, regardless of the state, we have: <span class=\"math-container\">$ A(s_{T-1},a_{T-1}) = r(s_{T-1}, a_{T-1}) - V(s_{T-1}) \\approx -0.1 -\\frac{-0.1}{1-\\gamma} = -0.1 + 10 = 9.9 $</span> \n(this is true under the assumption that we're not yet able to collect the goal reliably often, therefore the value function  converges to something close to <span class=\"math-container\">$\\frac{r_{avg}}{1-\\gamma} \\approx -10 $</span> ).</p>\n\n<p>Usually, <span class=\"math-container\">$T$</span> is not a part of the state, so the value function has no way to anticipate the sudden change in reward-to-go. So, all of a sudden, we got a (relatively) big advantage for the arbitrary action that we took at the timestep <span class=\"math-container\">$T-1$</span>.  Following the policy gradient rule, we will significantly increase the probability of an arbitrary action that we took at the end of the episode, even if we didn't achieve anything. This can quickly destroy the learning process.</p>\n\n<p>How do people deal with this problem in practice? My ideas:</p>\n\n<ol>\n<li>Differentiate between actual episode terminations and ones caused by the time limit, e.g. for them we will not replace next step value estimate with <span class=\"math-container\">$0$</span>.</li>\n<li>Somehow add <span class=\"math-container\">$t$</span> to the state such that the value function can learn to anticipate the termination of the episode.</li>\n</ol>\n\n<p>As I noticed, the A2C implementation in OpenAI baselines does not seem to bother with any of that:</p>\n\n<ul>\n<li><p><a href=\"https://github.com/openai/baselines/blob/f3a5abaeeb1c1c9136a01c9dbfebc173dc311fef/baselines/a2c/runner.py#L64\" rel=\"nofollow noreferrer\">A2C implementation - calculation of discounted rewards</a></p></li>\n<li><p><a href=\"https://github.com/openai/baselines/blob/8c2aea2addc9f3ba36d4a0c937e6a2d09830afc7/baselines/a2c/utils.py#L147\" rel=\"nofollow noreferrer\"><code>discount_with_dones</code> function</a></p></li>\n</ul>\n", "pids": ["5a73cbcc17c44a0b3035f183"], "flag": 1}
{"question": "What does current research tell us about addictive behaviors in games?", "body": "<p>I'm creating a game, and I would like to know what research I can consult to make it more \"addicting\".</p>\n\n<p>The game is a casual one, like Candy Crush, Angry Birds, etc</p>\n", "pids": ["5fae682ad4150a363ce19f16", "60fd3df65244ab9dcbccf112"], "flag": 1}
{"question": "Methods to tell if a question can be answered from a paragraph", "body": "<p>I'm working on a project related to machine Q&amp;A, using the SQuAD dataset. I've implemented a neural-net solution for finding answers in the provided context paragraph, but the system (obviously) struggles when given questions that are unanswerable from the context. It usually produces answers that are nonsensical and of the wrong entity type.</p>\n\n<p>Is there any existing research in telling whether or not a question is answerable using the info in a context paragraph? Or whether a generated answer is valid? I considered textual entailment but it doesn't seem to be exactly what I'm looking for (though maybe I'm wrong about that?)</p>\n", "pids": ["5b076eb4da5629516ce7372a"], "flag": 1}
{"question": "Current research on indoor localization and navigation in changing environment?", "body": "<p>I'm trying to get up to speed on the latest research regarding indoor localization, scene classification, navigation in changing environment, etc.</p>\n\n<p>Any advice would be appreciated, but I'm especially interested in recent research papers from vetted sources.  </p>\n", "pids": ["5c8e202c4895d9cbc6c778b2"], "flag": 1}
{"question": "Can (trained) neural networks be combined with symbolic AI to perform operations like AND?", "body": "<p>Does anyone work out ways of relating trained neural networks by symbolic AI?</p>\n<p>For example, if I train a network on pictures of dogs, and I train a network on pictures of shirts. You could imagine that the simplest way (without going through the process from scratch) of identifying &quot;dog AND shirt&quot; would be to perform an AND operation on the last output of the individual cat &amp; dog neural nets. So, &quot;dog AND shirt&quot; would amount to AND'ing the output of two nets.</p>\n<p>But this operation AND could be replaced with a more complicated operation. And, in principle, I could &quot;train&quot; a neural network to act as one of these operations.  For instance, maybe I could figure out the net that describes some changeable output &quot;X&quot; being &quot;on the shirt.&quot; This would be sort of like a &quot;functional&quot; in mathematics (in which we are operating are considering the behavior of a network whos input could be any network). If I can figure out this &quot;functional&quot;, then I would be able to use it symbolically and determine queries like &quot;dog on the shirt&quot;? - &quot;cat on the shirt&quot;?</p>\n<p>It seems like to me there's a lot of sense to turn specific neural networks into more &quot;abstract&quot; objects - and that there would be a lot of power in doing so.</p>\n", "pids": ["5a260c8617c44a4ba8a324c9"], "flag": 1}
{"question": "Can Machine Learning be applied to decipher the script of lost ancient languages?", "body": "<p>Can Machine Learning be applied to decipher the script of <strong>lost</strong> ancient languages (namely, languages that were being used many years ago, but currently are not used in human societies and have been forgotten, e.g. <a href=\"https://en.wikipedia.org/wiki/Avestan\" rel=\"nofollow noreferrer\">Avestan language</a>)?</p>\n\n<p>If yes, is there already any successful experiment to decipher the script of unknown ancient languages using Machine Learning?   </p>\n", "pids": ["5d1eb9e2da562961f0b1cbf2"], "flag": 1}
{"question": "Cold start collaborative filtering with NLP", "body": "<p>I’m looking to match two pieces of text - e.g. IMDb movie descriptions and each person’s description of the type of movies they like. I have an existing set of ~5000 matches between the two. I particularly want to overcome the cold-start problem: what movies to recommend to a new user? When a new movie comes out, to which users should it be recommended? I see two options:</p>\n\n<ol>\n<li>Run each description of a person through an LSTM; do the same for each movie description; concatenate the results for some subset of possible combinations of people and movies, and attach to a dense net to then predict whether it’s a match or not</li>\n<li>Attempt to augment collaborative filtering with the output from running the movie description and person description through a text learner.</li>\n</ol>\n\n<p>Are these tractable approaches?</p>\n", "pids": ["5d25bcd73a55ac8369529045"], "flag": 1}
{"question": "What is a graph neural network?", "body": "<p>What is a graph neural network (GNN)?</p>\n<p>Here are some sub-questions</p>\n<ul>\n<li>How is a GNN different from a NN?</li>\n<li>How exactly is a GNN related to graphs?</li>\n<li>What are the components of a GNN? What are the inputs and outputs of GNNs?</li>\n<li>How can GNNs be trained? Can we also use gradient descent with back-propagation to train GNNs?</li>\n</ul>\n", "pids": ["5e807d589fced0a24b30b594"], "flag": 1}
{"question": "Is there an alternative to the use of target network?", "body": "<p>In the context of Deep Q Network, a target network is usually utilized. The target network is a slow changing network with a changing rate as its hyperparameter. This includes both replacement update every <span class=\"math-container\">$N$</span> iterations and slowly update every iteration.</p>\n\n<p>Since the rate is hard to fine tune manually, is there an alternative technique that can eliminate the use of target network or at least makes it less susceptible to the changing rate?</p>\n", "pids": ["5cede109da562983788e8e16", "58437767ac44360f1083dcae", "53e99784b7602d9701f3e166", "57a4e91dac44365e35c987ca"], "flag": 1}
{"question": "Name of paper for encoding/representing XY coordinates in deep learning", "body": "<p>It this podcast between Oriol Vinyals and Lex Friedman: <a href=\"https://youtu.be/Kedt2or9xlo?t=1769\" rel=\"noreferrer\">https://youtu.be/Kedt2or9xlo?t=1769</a>, at 29:29, Oriol Vinyals refers to a paper:</p>\n\n<blockquote>\n  <p>If you look at research in computer vision where it makes a lot of sense to treat images as two dimensional arrays...\n  There is actually a very nice paper from Facebook. I forgot who the\n  authors are but I think [it's] part of Kaiming He's group. And what\n  they do is they take an image, which is a 2D signal, and they\n  actually take pixel by pixel, and scramble the image, as if it\n  was a just a list of pixels, crucially they encode the position of the pixels\n  with the XY coordinates. And this is a new architecture which we\n  incidentally also use in Starcraft 2 called the transformer, which is\n  a very popular paper from last year which yielded very nice results in\n  machine translation.</p>\n</blockquote>\n\n<p>Do you know which paper he is referring to? </p>\n\n<p>I'm guessing maybe he is talking about <a href=\"https://arxiv.org/abs/1711.07971\" rel=\"noreferrer\">non-local neural networks</a>, but I'm probably guessing wrong.</p>\n\n<p><em>Edit: after reviewing the recent publications of Kaiming He (<a href=\"http://kaiminghe.com/\" rel=\"noreferrer\">http://kaiminghe.com/</a>), maybe I'm guessing right. Any thoughts?</em></p>\n", "pids": ["5e63725891e011ae97a699ec"], "flag": 1}
{"question": "What to put in &quot;affiliation&quot; field when submitting paper without affiliation?", "body": "<p>Recently my paper is reviewed (by a professor from independent third party) and accepted by a journal. But, my employer allows me to publish this paper only without its name there.</p>\n\n<p>Publishing house is expecting affiliation for each author, i.e. I can not leave affiliation as blank. </p>\n\n<p>What should I write as the affiliation?</p>\n", "pids": ["56d8264ddabfae2eeedf3b80", "56d9216fdabfae2eeea01eaf", "53e99b21b7602d97023b4b44", "58437722ac44360f1082f3ed"], "flag": 1}
{"question": "What determines whether sensitization or desensitization occurs?", "body": "<p>I am familiar with desensitization. For example, if you are afraid of driving, driving every day will eventually reduce your fear, desensitizing you.</p>\n\n<p>But today I came across another concept, that of sensitization.  I looked up the wiki article on <a href=\"https://en.wikipedia.org/wiki/Sensitization\" rel=\"nofollow noreferrer\">Sensitization</a>, which says at the end,</p>\n\n<blockquote>\n  <p>Sensitization may also contribute to psychological disorders such as post-traumatic stress disorder, panic anxiety and mood disorders.</p>\n</blockquote>\n\n<p>So which is it then? What determines whether repeated exposure to something sensitizes someone or desensitizes them? With the example of PTSD, for instance, should not repeated exposure to war actually desensitize people?</p>\n\n<p>I searched google scholar but could not find a paper that discusses both sensitization and desensitization.  Mostly discuss the latter, in terms of reducing fears.  </p>\n\n<p>Appreciate any references or books that might help me understand this.  </p>\n\n<p>Thanks you.</p>\n", "pids": ["55a6b38165ce054aad71a7ac", "55a48fcec91bf3b1cc3ecb04", "53e9a5fdb7602d9702f27dbb", "53e9ba8fb7602d97046b2bdc"], "flag": 0}
{"question": "How is parallelism implemented in RL algorithms like PPO?", "body": "<p>There are multiple ways to implement parallelism in reinforcement learning. One is to use parallel workers running in their own environments to collect data in parallel, instead of using replay memory buffers (this is how A3C works, for example).</p>\n\n<p>However, there are methods, like PPO, that use batch training on purpose. How is parallelism usually implemented for algorithms that still use batch training?</p>\n\n<p>Are gradients accumulated over parallel workers and the combined? Is there another way? What are the benefits of doing parallelism one way over another?</p>\n", "pids": ["59ae3bf12bbe271c4c71bc64", "5b8c9f4a17c44af36f8b69cb", "5df8a76d3a55ac792c90fa4e"], "flag": 1}
{"question": "What are the state-of-the-art approaches for continual learning with neural networks?", "body": "<p>There seems to be a lot of literature and research on the problems of stochastic gradient descent and catastrophic forgetting, but I can't find much on solutions to perform continual learning with neural network architectures.</p>\n<p>By continual learning, I mean improving a model (while using it) with a stream of data coming in (maybe after a partial initial training with ordinary batches and epochs).</p>\n<p>A lot of real-world distributions are likely to gradually change with time, so I believe that we should be able to train NNs in an online fashion.</p>\n<p>Do you know which are the state-of-the-art approaches on this topic, and could you point me to some literature on them?</p>\n", "pids": ["5a73cbcc17c44a0b3035f7a3"], "flag": 1}
{"question": "Examples of ontologies made with AI", "body": "<p>I'm looking for more or less successful artificial intelligence usage examples to build an ontology or rationale why it can't be done. I found a lot of articles on how to use ontologies for AI, but not succeded vice versa.</p>\n", "pids": ["53e9acc4b7602d97036a1037"], "flag": 1}
{"question": "Is there a special name for rejection of extremes in the list of cognitive biases?", "body": "<p>Is there a special name for the cognitive bias that causes a person choose a compromise solution even the extreme solutions are better or causes person prefer a middle value even the extreme values are more suitable?</p>\n", "pids": ["5c3b63dddf5b8c0b3ca87d43", "56d8ede1dabfae2eee621eca"], "flag": 1}
{"question": "What are examples of optimization problems that can be solved using genetic algorithms?", "body": "<p>I'm trying to learn how genetic algorithms can solve optimization problems. I have already learned how genetic algorithms can solve the knapsack, TSP and set cover problems. I'm looking for some other similar optimization problems, but I have not found any.</p>\n<p>Would you please mention some other famous optimization problems that can be solved by using genetic algorithms?</p>\n", "pids": ["53e9a806b7602d9703149205"], "flag": 1}
{"question": "The concept of backpropagation in neural networks actually occurs in the brain?", "body": "<p>I am aware the Human brain has many functionally distinct components, but let us specifically consider the <strong>Human visual cortex</strong>: could <strong>Artificial Neural Networks</strong> (ANNs) be \"trained\" (through, e.g. backpropagation) in an analogous way to how the visual cortex \"learns\"?</p>\n\n<p>Is the concept of backpropagation in ANNs a phenomena actually observed in the Human brain?</p>\n\n<p><strong>Related</strong></p>\n\n<ul>\n<li><a href=\"https://biology.stackexchange.com/questions/54918/books-on-machine-learning-applications-in-biology\">Books on machine learning applications in Biology</a></li>\n</ul>\n", "pids": ["582334840cf206871ad31789", "58437722ac44360f1082f5c4", "5550416345ce0a409eb3ad52"], "flag": 1}
{"question": "Difference between prions and amyloid proteins?", "body": "<p>Amyloid and prions are misfolded proteins, but what, if any, is the difference between them? </p>\n\n<p>Is amyloid a type of prion with a fibrillar structure?</p>\n", "pids": ["5dda54d4df1a9c0c41582579", "5dda54d4df1a9c0c41582578", "5c75750ef56def97989b1b17"], "flag": 1}
{"question": "Can translational invariance of CNNs be unwanted if object is likely in certain positions?", "body": "<p>Various texts on using CNNs for object detection in images talk about how their translation invariance is a good thing. Which makes sense for tasks where the object could be anywhere in the image. Let's say detecting a kitten in household images.</p>\n\n<p>But let's say, you already have some information about the likely position of the object of interest in the image. For example, for detecting trees in a dataset of images of landscapes. Here in <em>most cases</em>, the trees are going to be in the bottom half of the image while in <em>some cases</em> they might be at the top (because it's on a hill or whatever). So you want your neural network to learn that information -- that trees are likely connected to the bottom part of the image (ground). Is this possible using the CNN paradigm? </p>\n\n<p>Thank you</p>\n", "pids": ["5de0c913df1a9c0c415a9e30"], "flag": 1}
{"question": "How to create an AI to solve a word search?", "body": "<p>This at first sounds ridiculous. Of course there is an easy way to write a program to solve a wordsearch. </p>\n\n<p>But what I would like to do is write a program that solves a word-search like a human.</p>\n\n<p>That is, use or invent different strategies. e.g. search randomly for the starting letter; go line-by-line; </p>\n\n<p>Probably the AI will eventually find out that going line by line looking for a given starting letter of a word is a good strategy.</p>\n\n<p>Any idea how you would write such a strategy-finding AI?</p>\n\n<p>I think the main \"moves\" would be things like \"move right one letter in the grid\", \"store this word in memory\", \"compare this letter with first letter in memory\" and a few more.</p>\n", "pids": ["5736974d6e3b12023e63890e"], "flag": 1}
{"question": "Are individuals who are generally jealous more likely to experience sexual jealousy?", "body": "<p>Some people are just jealous of many things they perceive others to possess. Materially or as part of that person.</p>\n\n<p>Is a person who is prone to jealousy more likely to be jealous in romantic relationships?</p>\n\n<p>or does sexual jealousy have different roots.</p>\n", "pids": ["53e99bb1b7602d970245a2ce", "55a368ab612ca648686bdfce"], "flag": 0}
{"question": "What kind of bee can dig through stone?", "body": "<p>My house (in Israel) has a concrete structure, with a decorative veneer of <a href=\"https://en.wikipedia.org/wiki/Jerusalem_stone\" rel=\"nofollow noreferrer\">Jerusalem Stone</a> at least an inch thick. Yesterday I came out to discover a little hole in the wall - and a pair of bees coming in and out of it! (<a href=\"https://youtu.be/Il7LgOs5wYg\" rel=\"nofollow noreferrer\">See video</a>)</p>\n\n<p><a href=\"https://i.stack.imgur.com/mbAiP.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/mbAiP.png\" alt=\"enter image description here\"></a></p>\n\n<p>This wall is no more than 5-6 years old, and I have never drilled anything there; they're not reusing a human-made hole. I must conclude that the bees somehow dug that hole.</p>\n\n<p>Is that possible? What kind of bee could do this?</p>\n\n<p><strong>Update:</strong> As interesting as these bees are I didn't want them living in my wall, so I filled up the hole with a silicone-type glue. A few hours later, they had dug through that, too. </p>\n", "pids": ["57da01510cf2ce2e6b0f10ff"], "flag": 1}
{"question": "Why is the Jensen-Shannon divergence preferred over the KL divergence in measuring the performance of a generative network?", "body": "<p>I have read articles on how Jensen-Shannon divergence is preferred over Kullback-Leibler in measuring how good a distribution mapping is learned in a generative network because of the fact that JS-divergence better measures distribution similarity when there are zero values in either distribution.</p>\n<p>I am unable to understand how the mathematical formulation of JS-divergence would take care of this and also what advantage it particularly holds qualitatively apart from this edge case.</p>\n<p>Could anyone explain or link me to an explanation that could answer this satisfactorily?</p>\n", "pids": ["5736960b6e3b12023e51dd27"], "flag": 1}
{"question": "How fast do lipids on the inside and outside of a lipid bilayer exchange?", "body": "<p>Biological membranes normally have different composition of lipids on the inside and outside (<a href=\"https://phys.libretexts.org/Courses/University_of_California_Davis/UCD%3A_Biophysics_241_-_Membrane_Biology/02%3A_Membranes_-_Aggregated_Lipids/2.02%3A_Membrane_Asymmetry\" rel=\"noreferrer\">ref 1</a>, <a href=\"https://www.cell.com/current-biology/comments/S0960-9822(18)30009-5\" rel=\"noreferrer\">ref 2</a>).  This is maintained both by how new lipids are added to membranes, and by specialized enzymes (<a href=\"https://moosmosis.org/2019/08/05/cell-membrane-dynamics-flippase-floppase-and-scramblase/\" rel=\"noreferrer\">flippases</a>).  Certain lipids being on the &quot;wrong side&quot; is an important signal (eg for apoptosis).</p>\n<p>My question is: how fast do lipids from the inside and outside exchange <em>spontaneously</em>?  In a patch of membrane with no enzymes, how long until half the &quot;inside&quot; lipids have flipped to the outside and vice versa through simple diffusion?</p>\n<p>I did a search but couldn't find any specific paper that measures the spontaneous exchange rate.  I'd be very interested in a definitive answer - could be just order of magnitude, but based on real measurements.</p>\n<p><strong>UPDATE</strong> This is important for figuring out the inside/outside composition of membranes in real scenarios when they're no longer being maintained in an asymmetric state: for example enveloped viruses, but also microparticles, dead cells, etc.</p>\n", "pids": ["5c756b53f56def97983ce042"], "flag": 1}
{"question": "What determines the direction in which motor proteins go?", "body": "<p>I know that kinesin motor proteins move towards the positive (beta) end of the microtubule, while dyenin motor proteins move towards the negative (alpha) end of the microtubule. However, because the microtubule is composed of repeating alpha and beta units in ABABABABAB fashion (as shown in the picture below), what causes motor proteins to move to the positive rather than the negative pole?</p>\n\n<p>For example, if one \"leg\" of the kinesin is bound to a beta tubulin while the other leg is up and ready to bind again, what determines which alpha tubulin it binds to (since there is alpha in front <em>and</em> in back of the beta tubilin it is bound to)?</p>\n\n<p><a href=\"https://i.stack.imgur.com/ulSTq.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/ulSTq.jpg\" alt=\"enter image description here\"></a></p>\n", "pids": ["62e6ba6f5aee126c0f37f914"], "flag": 1}
{"question": "Has machine learning been combined with logical reasoning (for example, PROLOG)?", "body": "<p>There are mainly two different areas of AI at the moment. There is the &quot;learning from experience&quot; based approach of neural networks. And there is the &quot;higher logical reasoning&quot; approach, with languages like LISP and PROLOG.</p>\n<p>Has there been much overlap between these? I can't find much!</p>\n<p>As a simple example, one could express some games in PROLOG and then use neural networks to try to play the game.</p>\n<p>As a more complicated example, one would perhaps have a set of PROLOG rules which could be combined in various ways, and a neural network to evaluate the usefulness of the rules (by simulation). Or even create new PROLOG rules.  (Neural networks have been used for language generation of a sort, so why not the generation of PROLOG rules, which could then be evaluated for usefulness by another neural network?)</p>\n<p>As another example, a machine with PROLOG rules might be able to use a neural network to be able to encode these rules into some language that could be in turn decoded by another machine. And so express instructions to another machine.</p>\n<p>I think, such a combined system that could use PROLOG rules, combine them, generate new ones, and evaluate them, could be highly intelligent. As it would have access to higher-order logic. And have some similarity to &quot;thinking&quot;.</p>\n", "pids": ["599c798d601a182cd264af3c"], "flag": 1}
{"question": "Context-based gap-fill face posture-mapper GAN", "body": "<p><a href=\"https://i.stack.imgur.com/5rN5a.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/5rN5a.jpg\" alt=\"image\"></a></p>\n\n<p><sub>These images are handmade, not auto-generated like they will be in production. Apologies for inaccuracies in the graph overlay.</sub></p>\n\n<p>I am trying to build an AI like that displayed in the diagram: when given a training set of images with their corresponding node maps of face/nose posture, and an image with a missing <strong>section</strong> (just a gap) with a node map, I would like it to reconstruct the initial image. My thoughts immediately went to GANs for this, but after some searching, the closest I could find were:</p>\n\n<ul>\n<li>Face recreation without context/not filling gaps, just following pose (DeepFake)</li>\n<li>Filling gaps in images, but with no node reference</li>\n<li>Filling gaps from reference drawings/mappings, but with no way to provide sample images</li>\n</ul>\n\n<p>I would like to hear about any implementations of such an algorithm, if possible optimised for faces, and if none exists, I would like to hear of how I would go about altering the generator of the GAN to work with the context/gap-fill bit (e.g a paper which talks about this idea, but doesn't implement it). Any guidance on the NN that is best for this type of task is also appreciated.</p>\n", "pids": ["53e9a5f0b7602d9702f1d6ce"], "flag": 1}
{"question": "Evidence for this tapping therapy - EFT (Emotional freedom technique)", "body": "<p>I just heard or maybe I saw a clip on tv about this tapping technique. Something about tapping various points of the body for psychological treatment. </p>\n\n<p>What is this EFT all about? Is there any solid evidence for EFT? </p>\n\n<ul>\n<li>Discussed in this Skeptic thread too, sorry I didn't realise it was there - <a href=\"https://skeptics.stackexchange.com/questions/231/what-is-eft-emotional-freedom-technique-and-does-it-work\">https://skeptics.stackexchange.com/questions/231/what-is-eft-emotional-freedom-technique-and-does-it-work</a></li>\n</ul>\n", "pids": ["53e9aab6b7602d9703431f0e", "5c756a2bf56def9798311806", "56d928a5dabfae2eeeca74b6", "5c7568b3f56def9798219965"], "flag": 0}
{"question": "Can single-cell organisms have through-holes? (Are donut-cells a thing?)", "body": "<p>I've watched <a href=\"https://youtu.be/0C3FaLrj9zw?t=630\" rel=\"nofollow noreferrer\">a YouTube video</a> about microorganisms, which featured a shot (below) of a single-cell organism, that looked like it had several through-holes in its body. Somehow I have a pretty steady mental image of a single-cell organisms being basically blobs: a sphere, an ellipse, a branching tree-like structure, all seem like plausible single-cell creature shapes to me, but something like a donut just doesn't. Is my intuition wrong and this is just a normal thing cells do? If so, how do those holes form? And if not, why does this shot look like a cell with holes?</p>\n\n<p>I thought that those holes might be just me wrongly interpreting the image. One idea was that this might be a result of the cell's complex 3D structure being projected on a 2D screen, but the movement of particles inside of the cell (which you can see in the video) seems to support the \"cell with holes\" interpretation. The other one, that was suggested in YouTube comments, is that those \"holes\" might be vacuoles inside of the cell. It seems that for that to be true, the image would have to be more like an MRI scan, revealing only a \"slice\" of the cell. But you can see some of 3D structure there, so it doesn't seem right either.</p>\n\n<p><a href=\"https://i.stack.imgur.com/weP2E.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/weP2Em.png\" alt=\"The shot from the video.\"></a></p>\n", "pids": ["5c0f71e5da562944ac647d3b"], "flag": 1}
{"question": "Are neurons in layer $l$ only affected by neurons in the previous layer?", "body": "<p>Are artificial neurons in layer <span class=\"math-container\">$l$</span> only affected by those in layer <span class=\"math-container\">$l-1$</span> (providing inputs) or are they also affected by neurons in layer <span class=\"math-container\">$l$</span> (and maybe by neurons in other layers)?</p>\n", "pids": ["573696026e3b12023e515eec"], "flag": 1}
{"question": "Why is there a λ⁴ in the spectral overlap integral in FRET calculations", "body": "<p>The <a href=\"https://en.wikipedia.org/wiki/F%C3%B6rster_resonance_energy_transfer#Theoretical_basis\" rel=\"nofollow noreferrer\">Förster resonance energy transfer (FRET) spectral overlap integral looks like</a>:</p>\n<p><span class=\"math-container\">$$\nJ=\\int_{0}^{\\infty}\\bar{F}_{D}(λ)ε_{A}(λ)λ^4 dλ\n$$</span>\nWhere <span class=\"math-container\">$λ$</span> is the wavelength, <span class=\"math-container\">$\\bar{F}_{D}(λ)$</span> is the normalized fluorescence emission spectrum of the donor(normalized to unity area), and <span class=\"math-container\">$ε_{A}(λ)$</span> is the extinction coefficient (<span class=\"math-container\">$M^{-1} \\ cm^{-1}$</span>).</p>\n<p>I am not very familiar with resonance energy transfer but was just curious why would a <span class=\"math-container\">$λ^4$</span> term be contained in this spectral overlap calculation. The intuitive implication would be that the longer the wavelength, the larger the spectral overlap?</p>\n<hr />\n<p>See for example Eq. 12.1 on page 471 in <a href=\"https://books.google.com/books?id=uHvqu4hLhH8C&amp;pg=PA1&amp;redir_esc=y#v=onepage&amp;q=integral&amp;f=false\" rel=\"nofollow noreferrer\">FRET and FLIM Techniques</a>\n(Theodorus W. J. Gadella, ed. 2008) or the corresponding  <span class=\"math-container\">$\\omega^{-4}$</span> in the integrals of Eq. 14.30 of Sect. 14.5.1  in David L. Andrews' <a href=\"https://spie.org/samples/PM194.pdf\" rel=\"nofollow noreferrer\">Chapter 14: Resonance Energy Transfer: Theoretical Foundations and Developing Applications</a></p>\n", "pids": ["56d8a80bdabfae2eee9c2aa3"], "flag": 1}
{"question": "Research on the van Norden percept", "body": "<p>What are the latest research and explanations concerning this auditory effect? I haven't managed to turn up much on the net, so just to check that I've named it correctly, my experience of it was being exposed to two alternately repeated beeps differing distinctly in pitch and finding that after a while I just heard a single repeated beep of constant pitch as if my brain had merged the two. </p>\n\n<h3>Context</h3>\n\n<p>Jansson (1994) writes:</p>\n\n<blockquote>\n  <p>Music may also be intercepted successively by noise bursts and still\n  be perceived as continuous, even if the music signals are deleted\n  within the noise bursts (van Norden, 1975)</p>\n</blockquote>\n\n<h3>References</h3>\n\n<ul>\n<li>Jansson, E. V. (1994). Violin timbre and the picket fence. Quarterly Progress and Status Report, KTH, Stockholm, 35, 79-84.<a href=\"http://www.speech.kth.se/prod/publications/files/qpsr/1990/1990_31_2-3_089-095.pdf\" rel=\"nofollow\">PDF</a></li>\n<li>van Norden, L.P.A.S. (1975): Temporal Coherence in the Perception of Tone Sequences, Thesis, Technical University, Eindhoven.</li>\n</ul>\n", "pids": ["56d81aaddabfae2eee911641", "55a66cfb65ce054aad6764fd", "5c865f674895d9cbc651a423"], "flag": 1}
{"question": "Which parts of the brain are used when identifying and sorting email messages?", "body": "<p>When most people view their email inboxes, they'll see several different types of messages; for example, emails which have been auto-generated by services we use, communications with real humans which are time sensitive, communications which aren't time sensitive, etc. </p>\n\n<p>Which parts of the brain are used when viewing, identifying, and categorizing these messages? Does this activity fall into a specific category of mental activity?</p>\n", "pids": ["55a6a19d65ce054aad6e85eb"], "flag": 1}
{"question": "Were there any marine/aquatic dinosaurs?", "body": "<p>Most dinosaurs were terrestrial, but there were a couple of groups of arboreal and <a href=\"https://biology.stackexchange.com/q/17546/42780\">flying dinosaurs</a> (microraptors, birds etc).</p>\n<p>I have read that the theory that Brachiosaurids were aquatic has been largely discredited<sup>1</sup>, but that Spinosaurids <em>were</em> probably semi-aquatic<sup>2</sup>.</p>\n<p>Excluding modern marine birds (e.g. penguins etc.), <strong>were there any other marine/aquatic dinosaurs?</strong></p>\n<hr />\n<sup>\n<p><strong>Note:</strong> I am aware that the marine reptiles <em>mesosaurs, phytosaurs, mosasaurs, dolichosaurs, Icthyosaurs, thalattosaurs, Sauropterygia</em> (<em>placodonts, nososaurs, plesiosaurs</em> etc), <em>Choristodera</em> were not part of Dinosauria.</p>\n</sup>\n<hr />\n<p><em>References:</em></p>\n<sup>\n<ol>\n<li>\n<ul>\n<li><a href=\"https://scholarsarchive.byu.edu/cgi/viewcontent.cgi?referer=https://www.google.com/&amp;httpsredir=1&amp;article=3285&amp;context=gbn\" rel=\"nofollow noreferrer\"><em>Three new sauropod dinosaurs from the Upper Jurassic of Colorado</em></a>, Great Basin Naturalist.</li>\n<li><em>The Physiology of Dinosaurs: Circulatory and Respiratory Function in the Largest Animals Ever to Walk the Earth</em>, Respiratory Care</li>\n<li><em>A note on the habits of sauropods</em>, Annals and Magazine of Natural History</li>\n<li><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1810024\" rel=\"nofollow noreferrer\"><em>Tipsy punters: sauropod dinosaur pneumaticity, buoyancy and aquatic habits</em></a>, Proceedings of the Royal Society of London</li>\n</ul>\n</li>\n<li>\n<ul>\n<li><a href=\"https://pubs.geoscienceworld.org/gsa/geology/article-abstract/38/2/139/130188/oxygen-isotope-evidence-for-semi-aquatic-habits?redirectedFrom=fulltext\" rel=\"nofollow noreferrer\"><em>Oxygen isotope evidence for semi-aquatic habits among spinosaurid theropods</em></a>, Geology</li>\n<li><a href=\"http://www.sciencemag.org/content/345/6204/1613.abstract\" rel=\"nofollow noreferrer\"><em>Semiaquatic adaptations in a giant predatory dinosaur</em></a>, Science</li>\n<li><em>Convergent evolution of jaws between spinosaurid dinosaurs and pike conger eels</em>, Acta Palaeontologica Polonica</li>\n<li><em>Functional Morphology of Spinosaur 'crocodile-Mimic' Dinosaurs</em>, Journal of Vertebrate Paleontology</li>\n</ul>\n</li>\n</ol>\n</sup>\n", "pids": ["5eb52e4e9fced0a24b40d283"], "flag": 1}
{"question": "How many action potentials from presynaptic neurons would be required to make a postsynaptic neuron fire?", "body": "<p>I am looking for a rough estimation of the number of action potentials from other neurons required to cause a neuron to fire?</p>\n\n<p>I read <a href=\"https://faculty.washington.edu/chudler/ap.html\" rel=\"nofollow\">here</a> that a potential of ~ -55mv must be reached before an action potential is fired in a neuron, my thought is how many action potentials from other cells would (roughly) be required to reach this - and in what required time (if it matters)?</p>\n\n<p><em>I am not a neuroscientist and suspect this question is unanswerable but though this was the place to ask!</em></p>\n", "pids": ["53e9a774b7602d97030ad598"], "flag": 1}
{"question": "Are there RL algorithms that also try to predict the next state?", "body": "<p>So far I've developed simple RL algorithms, like Deep Q-Learning and Double Deep Q-Learning. Also, I read a bit about A3C and policy gradient but superficially.</p>\n<p>If I remember correctly, all these algorithms focus on the value of the action and try to get the maximum one. <strong>Is there an RL algorithm that also tries to predict what the next state will be, given a possible action that the agent would take?</strong></p>\n<p>Then, in parallel to the constant training for getting the best reward, there will also be constant training to predict the next state as accurately as possible? And then have that prediction of the next state always be passed as an input into the NN that decides on the action to take. Seems like a useful piece of information.</p>\n", "pids": ["5e8d929e9fced0a24b6263e9", "5e5e18b193d709897ce27f39", "5ed623da91e01198019afc95", "573696106e3b12023e522825"], "flag": 1}
{"question": "Mitochondrial DNA and recombination", "body": "<p>Firstly I could do with a brief description of mitochondrial DNA. How does the structure of DNA in mitochondria compare to animal DNA (for the sake of simplicity let's say human - some animals might have unusual DNA structure) and what living organism is the mitochondrial genome most akin to? (Circular like bacteria maybe?) and are the mitochondria within a single human homogenous?</p>\n\n<p>Secondly, and most importantly to my aim, does the mitochondrial genome recombine in anyway? Is the process of recombination affected by its structure? Are there any patterns/rules in mitochondrial recombination? Is there DNA transfer between mitochondria which could have a similar effect?</p>\n\n<p>I am trying to think about how male deleterious alleles can spread differently in diverged populations given potential recombination to female beneficial (or recombination away from female deleterious mutations). </p>\n", "pids": ["53e99f2eb7602d97027fc0ab"], "flag": 1}
{"question": "Risks of latent viruses that reside in ancient genomes under research?", "body": "<p>Some interesting research in reactivating mammoth genetic material (<a href=\"https://www.nature.com/articles/s41598-019-40546-1\" rel=\"nofollow noreferrer\">https://www.nature.com/articles/s41598-019-40546-1</a>) made me wonder what risks are inherent (or are not inherent) in reviving older genomes that may have integrated latent viral code? </p>\n\n<p>Are there potential biohazards in this line of research, where dormant viruses that have otherwise gone extinct (along with the extinct host) and which now may have the potential to be reactivated? Not just in terms of zoonoses that infect across species, but also viruses that infect modern animals that are more closely related or have relatively common ancestry (e.g., from mammoth to elephant).</p>\n\n<p>Could a disease be brought back via this kind of research? Or are the conditions for waking latent viruses from starting material of this kind just not possible to recreate in a lab setting?</p>\n\n<p><strong>Edit</strong>: To clarify what I mean by potential biohazard in relation to this question: Experimental conditions result in a latent virus going into lytic phase. The virus is a communicable pathogen; it spreads outside the laboratory environment; it causes sickness or death to living organisms to the extent that it creates a public health, ecological, or other crisis of significance. For background, please also see: <a href=\"https://dictionary.cambridge.org/us/dictionary/english/biohazard\" rel=\"nofollow noreferrer\">Cambridge</a>, <a href=\"https://www.thefreedictionary.com/biohazard\" rel=\"nofollow noreferrer\">The Free Dictionary</a>, and <a href=\"https://en.wikipedia.org/wiki/Biological_hazard\" rel=\"nofollow noreferrer\">Wikipedia</a>.</p>\n", "pids": ["5c8cced4e1cd8e5dafc00ea0", "5a50358c0cf24d13272db587", "56d818abdabfae2eee83e09b"], "flag": 1}
{"question": "Which artificial intelligence algorithms could use tensor specific hardware?", "body": "<p>AI algorithms involving neural networks can use tensor specific hardware. Are there any other artificial intelligence algorithms that could benefit from many tensor calculations in parallel?  Are there any other computer science algorithms (not part of AI) that could benefit from many tensor calculations in parallel?</p>\n\n<p>Have also a look at <a href=\"https://en.wikipedia.org/wiki/Tensor#Applications\" rel=\"nofollow noreferrer\">TensorApplications</a> and <a href=\"https://en.wikipedia.org/wiki/Application_of_tensor_theory_in_engineering\" rel=\"nofollow noreferrer\">Application Theory</a>.</p>\n", "pids": ["599c7899601a182cd25dbef9"], "flag": 1}
{"question": "Psychological journal that focuses on publishing interesting psychological datasets", "body": "<p>There are a range of data repositories around. There are also journals that permit online attachments. That said, my general experience with such online attachments is that the data sharing is an after thought. It is not optimised for accessibility. The information is often not sufficient to truly understand the data.</p>\n\n<p>I'd like to see a journal that specialises in publishing interesting psychological datasets. Such a journal would ensure that the dataset was well documented. It would have clear, machine-readable meta-data. Scripts for processing raw data might be provided. </p>\n\n<p><strong>Are there any psychological journals that specialise in publishing psychological datasets?</strong></p>\n", "pids": ["5d041b0c3a55acfcafefa014"], "flag": 1}
{"question": "Relationship between processing speed and IQ in twice exceptional children", "body": "<p>How come some twice exceptional children (i.e., intellectually gifted children who have some form of disability) have high iq, but low processing speed? Isn't processing speed a factor of intelligence? If not, why do iq tests have a time limit?</p>\n", "pids": ["56d92a68dabfae2eeed53a31"], "flag": 1}
{"question": "Why not more TD(&#120582;) in actor-critic algorithms?", "body": "<p>Is there either an empirical or theoretical reason that actor-critic algorithms with eligibility traces have not been more fully explored? I was hoping to find a paper or implementation or both for continuous tasks (not episodic) in continuous state-action spaces.</p>\n\n<p>This has been the only related question on SE-AI that I have been able to find <a href=\"https://ai.stackexchange.com/q/10049/2444\">Why are lambda returns so rarely used in policy gradients?</a>.</p>\n\n<p>Although I appreciated the dialog and found it useful, I was wondering if there was any further detail or reasoning that might help explain the void.</p>\n", "pids": ["573696066e3b12023e519907", "5db9292b47c8f766461ef944"], "flag": 1}
{"question": "What kind of neural network architecture do I use to classify images into one hundred thousand classes?", "body": "<p>I have an image dataset where objects may belong to one of the hundred thousand classes.</p>\n\n<p>What kind of neural network architecture should I use in order to achieve this?</p>\n", "pids": ["5550415645ce0a409eb3a69e", "5550417d45ce0a409eb3bc08"], "flag": 1}
{"question": "Is open-plan office for academia at all?", "body": "<p>Where I did my PhD, typically two PhD students shared an office room. In constrast, where I am working as a postdoc now, about 50 PhDs and postdocs share an open-plan office. </p>\n\n<p>I find it difficult to concentrate in the latter kind of arrangement because of the noise. Some people use head/earphones, but I guess not everyone likes to listen to music while working. I am wondering if this is a common arrangement in academia. My guess is that while it might work elsewhere, the nature of academic research precludes an open-plan type of office.</p>\n\n<p>In any case, is it appropriate to ask my supervisor for a room or a smaller/quieter space to work in? I don't think I would ask, though, because everybody else seems to be fairly content, but I'm just wondering.</p>\n", "pids": ["55a60e8d65cead59c8339fdf", "53e9a7b3b7602d97030f3b54"], "flag": 1}
{"question": "Does MMD-VAE solve the problem of blurred images of vanilla VAEs?", "body": "<p>I understand that with vanilla VAEs, there are a few reasons justifying the production of blurred out images. The <a href=\"https://arxiv.org/pdf/1706.02262.pdf)%F0%9F%8E%99%EF%B8%8FPoster\" rel=\"nofollow noreferrer\">InfoVAE</a> paper describes the case when the decoder is flexible enough to ignore the latent attributes and generate an averaged out image that best reduces the reconstruction loss. Thus the blurred image.</p>\n\n<p>How much of the problem of blurring is really mitigated by the <a href=\"https://arxiv.org/pdf/1706.02262.pdf)%F0%9F%8E%99%EF%B8%8FPoster\" rel=\"nofollow noreferrer\">MMD formulation</a> in practical experiments? If someone has experience working with <a href=\"https://arxiv.org/pdf/1706.02262.pdf)%F0%9F%8E%99%EF%B8%8FPoster\" rel=\"nofollow noreferrer\">MMD-VAEs</a>, I'd like to know their opinion on what the reconstruction quality of MMD-VAEs is really like.</p>\n\n<p>Also, does the replacement of the MSE reconstruction loss metric by other perceptual similarity metrics improve generated image quality?</p>\n", "pids": ["5c8791d44895d9cbc62bd80b", "5a73cbcc17c44a0b3035f2f7", "5d9edc8b47c8f76646043ff2", "599c7951601a182cd26300bc"], "flag": 1}
{"question": "Who can submit papers to peer-reviewed journals?", "body": "<p>Financial terms, content quality, etc, is not a problem. The author has a contribution that will significantly impact the advancement of human knowledge about a particular topic.</p>\n\n<p>Can anyone submit a paper? Or does it require some affiliation with a larger group such as an educational/governmental/corporate institution?</p>\n\n<p>I am talking about journals of such clout as the Journal of Fluid Mechanics, Physics of Fluids, etc.</p>\n", "pids": ["5ce2c626ced107d4c61dc45b"], "flag": 1}
{"question": "Is there a disorder that causes one to give inanimate objects human emotions?", "body": "<p>For example, if one is using multiple pens to write something and has not used one of them in awhile, one may think it is \"feeling\" \"left out\" and so will switch to use that one. A logical mind KNOWS that inanimate objects cannot feel but one may have such empathy for all things - living or not - that one may attribute human feelings and emotions to them and an emotional brain does this automatically. It is not a conscious action, it is automatic and it dictates how one interacts with things. One can use a logical mind to recognize it but stills feel compelled to make sure everything is taken care of and included. Is this a specific disorder or just a piece of one of another disorder?</p>\n", "pids": ["55a41c9965ce5cd7b3c4991b"], "flag": 1}
{"question": "What is the purpose of the batch size in neural networks?", "body": "<p>Why is a batch size needed to update the weights of a neural network?</p>\n\n<p>According to that <a href=\"https://www.youtube.com/watch?v=tIeHLnjs5U8&amp;t=278s\" rel=\"nofollow noreferrer\">Youtube Video from 3B1B</a>, the weights are updated by calculating the error between expectation and outcome of the neural net. Based on that, the chain rule is applied to calculate the new weights. </p>\n\n<p>Following that logic, why would I pass a complete batch through the net? The first entries wouldn't have an impact on the weighting.</p>\n\n<p>Do I need to define a batch size when I use backpropagation?</p>\n", "pids": ["53e9ada5b7602d97037a301f"], "flag": 1}
{"question": "Isn&#39;t a simulation a great model for model-based reinforcement learning?", "body": "<p>Most reinforcement learning agents are trained in simulated environments. The goal is to maximize performance in (often) the same environment, preferably with a minimum amount of interactions. Having a good model of the environment allows to use planning and thus drastically improves the sample efficiency!</p>\n\n<p><strong>Why is the simulation not used for planning</strong> in these cases? It is a sampling model of the environment, right? Can't we try multiple actions at each or some states, follow the current policy to look several steps ahead and finally choose the action with the best outcome? Shouldn't this allow us to find better actions more quickly compared to policy gradient updates?</p>\n\n<p>In this case, our environment and the model are kind of identical and this seems to be the problem. Or is the good old curse of dimensionality to blame again? Please help me figure out, what I'm missing. </p>\n", "pids": ["5bdc31b817c44a1f58a0bd75"], "flag": 1}
{"question": "How is neural architecture search performed?", "body": "<p>I have come across something that IBM offers called <em>neural architecture search</em>. You feed it a data set and it outputs an initial neural architecture that you can train.</p>\n<p>How is <em>neural architecture search</em> (NAS) performed? Do they use heuristics, or is this meta machine learning?</p>\n<p>If you have any papers on NAS, I would appreciate if you can provide a link to them.</p>\n", "pids": ["58d82fc8d649053542fd59b8", "5a9cb66717c44a376ffb87ea", "5b8c9f4a17c44af36f8b6acf", "5e63725991e011ae97a69d1a", "5a9cb65d17c44a376ffb820b", "5b3d98cc17c44a510f801d04", "5bdc31c217c44a1f58a0cc2a", "5a73cbc317c44a0b3035ec55", "5b67b4b417c44aac1c867648", "5a73cbc317c44a0b3035ec5b", "5c8d03db4895d9cbc632b86d", "599c7983601a182cd26466e7", "5a73cbc317c44a0b3035ec55", "5a9cb66717c44a376ffb87ea", "5cede0e1da562983788c05b5", "5a260c8617c44a4ba8a320de", "5aed14e217c44a4438159823", "5c8f456b4895d9cbc639e8bb", "5d4800593a55ac01b0f8ff19"], "flag": 1}
{"question": "Are there any examples for an ArXiv publication nurturing or preventing plagiarism?", "body": "<p>First of all, this is about plagiarism in the sense of stealing ideas. Copy-and-paste plagiarism is included but not likely to happen in the cases relevant for this question.</p>\n\n<p>Considering the publication of a paper prior to peer-reviewed publication on the ArXiv (or another preprint server), there are usually two main positions considering a possible theft of the idea (or somebody coming up with the same idea):</p>\n\n<ul>\n<li>If somebody manages to publish your idea in a peer-reviewed journal before you do, you can prove that you came up with the idea first or at least independently if you have published your paper on the ArXiv. Therefore it is a good idea to publish papers on the ArXiv before they have been published in a peer-reviewed journal.</li>\n<li>If you publish your paper on ArXiv before it is published in a peer-reviewed journal, others may steal your work and publish it peer-reviewed before you do and thus take the scientific credit. It’s difficult to attack those people since the ArXiv is not peer-reviewed. Somebody could make a living of plagiarising ArXiv papers. Therefore it is a bad idea to publish papers on the ArXiv before they have been published in a peer-reviewed journal.</li>\n</ul>\n\n<p>Are there any <strong>example cases</strong> (or even studies) supporting either of these statements? Such examples would include, but are not limited to:</p>\n\n<ul>\n<li>Has a peer-reviewed journal ever withdrawn a paper because it plagiarised an ArXiv paper?</li>\n<li>Are there well-known cases of “unpunished” plagiarism of ArXiv papers? </li>\n<li>Has anybody ever successfully resolved a priority dispute with a publication on ArXiv?</li>\n<li>Has anybody ever accused somebody of plagiarising an ArXiv article (with the fact that the plagiarised article was published on ArXiv affecting the outcome).</li>\n</ul>\n\n<p>Note that it is really examples and not a theoretical analysis of the statements, I am looking for. (Neither of the two positions fully reflect my opinion and some of the soft premises¹ are debatable. However, debating about these viewpoints on a theoretical basis or attacking some of the premises is usually futile.)</p>\n\n\n\n<p><sup>\n¹ e.g., that scientific credit is only decided by peer-reviewed publication\n</sup></p>\n", "pids": ["56d84953dabfae2eeec7d0a0", "5c7574f0f56def979899dd65"], "flag": 1}
{"question": "Which physical properties of a stimulus can a human attend to?", "body": "<p>I am not only curious about speech, but for concreteness in illustrating my question, I consider the case of speech perception. Assume a listener is presented with an acoustic waveform. The wave causes deviations from the atmospheric pressure at the listener's eardrum. Thus, the acoustic pressure as a function of time “comes for free”, so to speak. Mechanically so.</p>\n\n<p>From sound pressure we can derive amplitude, and by the fourier transform, amplitude as a function of time is transformed to the frequency domain. That is, amplitude as a function of time becomes amplitude as a function of frequency. We use this transformation because it reveals properties of the wave which are perceptually relevant, e.g. formant frequencies.  Presumably, listeners can attend to properties of the waveform describable under this transformation.</p>\n\n<p>But what about mathematical models of the acoustic wave which are not simply transformations on the wave, but which derive some richer structure from amplitude fluctuations over time. For instance, what about a model which constructs a higher dimensional representation of the wave from the one-dimensional pressure fluctuations? (Imagine that instead of amplitude being a point moving back and forth along the real number line, the wave is represented as a point moving around in, say, 3-dimensional space). Say that such a model revealed a perceptually relevant property P of the waveform. Would the listener be able to “hear” P directly, or would would she need to engage in some information processing task to recover P from pressure fluctuations over time?*</p>\n\n<p>*I realize that human listeners don't actually manipulate equations in their heads. I use the mathematics just to describe the underlying neural computation.</p>\n", "pids": ["55a521d965ceb7cb02e1ead8"], "flag": 1}
{"question": "Why does photosynthesis specifically produce glucose?", "body": "<p>Why not a pentose? Or a tetrose? Or a deoxy sugar? Or just some other hexose, like fructose?</p>\n<p>Is there some chemical reason life should have settled on glucose as the standard photosynthetic output, or is it just random? It seems very suspicious that this ubiquitous molecule nicely break down into exactly 3CO2 + 3CH4, or 6CO2 + 6H2O - 6O2, or 6H2CO, when such convenient formulas are not true of the actual immediate products of carbon fixation.</p>\n", "pids": ["53e99960b7602d97021a0838"], "flag": 1}
{"question": "Could I use colors to distinguish variables in a paper?", "body": "<p>Often when distinguishing one variable from another we use different characters or if using the same character different subscripts.  For instance we might use x for one variable, and y for another, or we might use x_1 for one variable and x_2 for another.  I was wondering if in a paper I could get away with using the same character but with different colors when referring to different variables.  So for instance if I was referring to two different objects, then I might refer to variables related to one object using the color red and variables related to the other object using the color blue, and variables related to both objects using the color magenta.  So for example the schrodinger equation for a system of particles only interacting with each other would be written in the form</p>\n<p><a href=\"https://i.stack.imgur.com/XLyQP.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/XLyQP.png\" alt=\"enter image description here\" /></a></p>\n<p>Would writing equations with variables denoted with color make a paper less likely to get published assuming that I explained what the colors meant?</p>\n", "pids": ["616172805244ab9dcb344317"], "flag": 1}
{"question": "Do some people substitute pets for kids in their life?", "body": "<p>So there are some old articles, like <a href=\"https://qz.com/197416/americans-are-having-dogs-instead-of-babies/\" rel=\"nofollow noreferrer\">this one</a>, which have discussed how pets (especially small pets) are on the rise with young adults, while birth rates are down. <a href=\"https://www.millennialmarketing.com/2017/07/pets-vs-parenthood-why-millennials-are-owning-pets-instead-of-having-kids/\" rel=\"nofollow noreferrer\">This</a> talks about how delaying having kids is a short-term/ individual win for the family, as mothers' income increases every year she delays getting pregnant, but then the long-term effect is a society strained with many more old people than young (for one).</p>\n<p>While of course correlation isn't causation, I can easily see how the desire for establishing a solid career before starting a family &amp; feminism &amp; hustle culture &amp; the eco-crisis, how all of these issues and more could make young adults more apprehensive about starting a family &amp; decide to postpone it. Yet, there is still a biological urge to parent, and so in comes the fluffy ball of joy. The pet/ pet services industry is growing so so much.</p>\n<p>Are there researchers that have investigated this trend/ cluster of behaviour, and what conclusions (or initial observations) have they come to? I know there are studies that tackle <a href=\"https://skeptics.stackexchange.com/questions/3802/is-there-a-negative-correlation-between-parenthood-and-pet-ownership\">parenthood and pets as a whole</a>, but that is not what I'm looking for. I don't think simply aggregating all families can lead you to any useful conclusions since it conflates different scenarios &amp; motivations. It's like saying everyone earns an average of $100k/ year, when some make millions a year and others are dirt poor. I'd be specifically interested in research where they tried to isolate this pets-as-kids cluster.</p>\n", "pids": ["5c757313f56def9798867332", "5c757313f56def9798867332"], "flag": 0}
{"question": "Does intermittent fasting increase intelligence?", "body": "<p>A little Background:\nThe protocol I am taking about is 16-20 hours of fasting and a 4-8 hour eating window (e.g. fasting between 6 PM and 10 AM). I have been doing IF (intermittent fasting) for 7 months. I think the key hormones relevant to this question are ghrelin and testosterone. </p>\n\n<p>Is it possible for intermittent fasting to make you smarter?</p>\n", "pids": ["53e9aff4b7602d9703a4c182"], "flag": 0}
{"question": "Genes and Intelligence", "body": "<p>Assuming that intelligence has a genetic component, </p>\n\n<p>• do we know which genes contribute to it? </p>\n\n<p>and, if so,</p>\n\n<p>• can we predict intelligence from genomic analysis?</p>\n", "pids": ["5a260c8417c44a4ba8a31b7a", "5c75731af56def979886b26b", "5cb08ce26558b90bfa1497db", "5c8efb384895d9cbc602436f", "5c0f866eda562944ac930fc0", "5c75731af56def979886b26b"], "flag": 1}
{"question": "What AI applications exist to solve sustainability issues?", "body": "<p>The <a href=\"https://en.wikipedia.org/wiki/Sustainable_Development_Goals\" rel=\"nofollow noreferrer\">Sustainable Development Goals</a> of the United Nations describe a normative framework which states what future development until 2030 should strive for. On a more abstract level a <a href=\"https://en.wikipedia.org/wiki/Our_Common_Future\" rel=\"nofollow noreferrer\">basic definition</a> describes sustainable development as</p>\n\n<blockquote>\n  <p>development that meets the needs of the present without compromising the ability of future generations to meet their own needs.</p>\n</blockquote>\n\n<p>Alone through the consumption of energy, AI technologies already have a (negative) impact on sustainability questions.</p>\n\n<p>What AI applications already exist, are researched or are at least thinkable from which sustainability would benefit?</p>\n", "pids": ["5ce3ae26ced107d4c65daf9b"], "flag": 1}
{"question": "How can I handle overfitting in reinforcement learning problems?", "body": "<p>So this is my current result (loss and score per episode) of my RL model in a simple two players game:</p>\n<p><a href=\"https://i.stack.imgur.com/K7YTe.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/K7YTe.png\" alt=\"enter image description here\" /></a></p>\n<p>I use DQN with CNN as a policy and target networks. I train my model using Adam optimizer and calculate the loss using Smooth L1 Loss.</p>\n<p>In a normal &quot;Supervised Learning&quot; situation, I can deduce that my model is overfitting. And I can imagine some methods to tackle this problem (e.g. Dropout layer, Regularization, Smaller Learning Rate, Early Stopping).</p>\n<ul>\n<li>But would that solution will also work in RL problem?</li>\n<li>Or are there any better solutions to handle overfitting in RL?</li>\n</ul>\n", "pids": ["5aed14d617c44a4438159659"], "flag": 1}
{"question": "Can open-source software be peer-reviewed and published?", "body": "<p>My colleague and I have developed a software tool and intend to release it open-source.</p>\n\n<p>This tool is specifically for tasks in my field but we think it would be helpful for the wider community. Our institution will permit us to release it provided we get appropriate credit.</p>\n\n<p>Thus, we wish to publish it in peer-review. Is peer-review publication of domain-specific software available? If so, what is required to publish it?</p>\n\n<p>In this case we intend to publish the method and tool on it's own merits without supporting data or an application.</p>\n", "pids": ["5c7579a4f56def9798a59ac5"], "flag": 1}
{"question": "Do Scrubjays weigh peanuts by picking them up?", "body": "<p>I have been feeding scrubjays where I live (Monterey, California) with peanuts in the shell.</p>\n<p>Something interesting I've noticed them do is, after I've laid out a selection of peanuts for them, they pick them up in their beaks and seem to be determining which one they want to fly off with. I have seen them first eye them all for a couple of seconds, then pick one up, shake it in their beak as if listening or &quot;weighing&quot; it, then picking up another one, or even three, and then going back to one of the previous ones and flying off with it.</p>\n<p>What are they doing? Weighing them? &quot;Counting&quot; how many nuts are in the shell? Listening for something?</p>\n<p>Here is one &quot;in the act&quot;:</p>\n<p><a href=\"https://i.stack.imgur.com/xxpDY.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/xxpDY.jpg\" alt=\"enter image description here\" /></a></p>\n", "pids": ["53e9a232b7602d9702b3adec", "56d91e2cdabfae2eee8cca09"], "flag": 1}
{"question": "Many of the best probabilistic models represent probability distributions only implicitly", "body": "<p>I am currently studying Deep Learning by Goodfellow, Bengio, and Courville. In chapter <strong>5.1.2 The Performance Measure,</strong> <em>P</em>, the authors say the following:</p>\n<blockquote>\n<p>The choice of performance measure may seem straightforward and objective, but it is often difficult to choose a performance measure that corresponds well to the desired behavior of the system.</p>\n<p>In some cases, this is because it is difficult to decide what should be measured. For example, when performing a transcription task, should we measure the accuracy  of the system at transcribing entire sequences, or should we use a more fine-grained performance measure that gives partial credit for getting some elements of the sequence correct? When performing a regression task, should we penalize the  system more if it frequently makes medium-sized mistakes or if it rarely makes very large mistakes? These kinds of design choices depend on the application.</p>\n<p>In other cases, we know what quantity we would ideally like to measure, but measuring it is impractical. For example, this arises frequently in the context of density estimation. Many of the best probabilistic models represent probability distributions only implicitly. Computing the actual probability value assigned to a  specific point in space in many such models is intractable. In these cases, one must design an alternative criterion that still corresponds to the design objectives, or design a good approximation to the desired criterion.</p>\n</blockquote>\n<p>It is this part that interests me:</p>\n<blockquote>\n<p>Many of the best probabilistic models represent probability distributions only implicitly.</p>\n</blockquote>\n<p>I don't have the experience to understand what this means (what does it mean to represent distributions &quot;implicitly&quot;?). I would greatly appreciate it if people would please take the time to elaborate upon this.</p>\n", "pids": ["58437722ac44360f1082f261", "58d82fced649053542fd727d"], "flag": 1}
{"question": "How to clone and sequence a gene transcript of unknown sequence?", "body": "<p>How might I go about amplifying a gene transcript (mRNA) from animal tissue of which little is known about the genome? In some applications, I have used reverse transcriptase PCR to amplify all mRNA transcripts from cultured cells, but this required that I knew the sequence to PCR amplify.</p>\n\n<p>How do I go about this without knowledge of the gene or transcipt?</p>\n", "pids": ["53e9a02db7602d9702912ed4"], "flag": 1}
{"question": "Is it possible to guide a reinforcement learning algorithm?", "body": "<p>I have just started to study reinforcement learning and, as far as I understand, existing algorithms search for the optimal solution/policy, but do not allow the possibility for the programmer to suggest a way to find the solution (to guide their learning process). This would be beneficial for finding the optimal solution faster.</p>\n\n<p>Is it possible to guide the learning process in (deep) reinforcement learning?</p>\n", "pids": ["5b1642388fbcbf6e5a9b577b"], "flag": 1}
{"question": "What is eager learning and lazy learning?", "body": "<p>What is the difference between eager learning and lazy learning?</p>\n<p>How does eager learning or lazy learning help me build a neural network system? And how can I use it for any target function?</p>\n", "pids": ["53e9a263b7602d9702b6b528"], "flag": 1}
{"question": "Why is symbolic AI not so popular as ANN but used by IBM&#39;s Deep Blue?", "body": "<p>Everybody is implementing and using DNN with, for example, TensorFlow or PyTorch.</p>\n<p>I thought IBM's Deep Blue was an ANN-based AI system, but <a href=\"https://analyticsindiamag.com/understanding-difference-symbolic-ai-non-symbolic-ai/\" rel=\"nofollow noreferrer\">this article</a> says that IBM's Deep Blue was symbolic AI.</p>\n<p>Are there any special features in symbolic AI that explain why it was used (instead of ANN) by IBM's Deep Blue?</p>\n", "pids": ["5a73cbcc17c44a0b3035f7b3"], "flag": 1}
{"question": "What is machine learning?", "body": "<p>What is the definition of machine learning? What are the advantages of machine learning? </p>\n", "pids": ["5c0f8812da562944ac967b0a", "55d065fd696322190568b40f"], "flag": 1}
{"question": "How to predict time series with accuracy?", "body": "<p>I am trying to predict Forex time series. The nature of the market is that 80% of the time the price can not be predicted, but in 20% of the time it can be. For example, if the price drops down very deep, there is 99% probability that there will be a recovery process, and this is what I want to predict.</p>\n\n<p>So , how do I train a feed-forward network the way it would only predict those cases that have 99% of certainty to take place and, for the rest of the cases it would output \"unpredictable\" status?</p>\n\n<p>Imagine that my data set has 24 hours of continuous price data as input (as 1 minute samples), and then as output I want the network to predict 1 hour of future price data. The only restriction I need to implement is that if the network is not \"sure\" that the price is predictable, it would outupt 0s. So, how do I implement safety in predictions the network is outputting?</p>\n\n<p>It seems that my problem is similar to Google Compose, where it predicts the next word as you are typing , for example, if you type \"thank you\", it would add \" very much\" and this would be like 95% correct. I want the same, but it is just that my problem has too much complexity. Google uses RNNs, so maybe I should try a deep network of many layers of RNNs?</p>\n", "pids": ["53e9a3abb7602d9702cbd3c9"], "flag": 1}
{"question": "Do AlphaZero/MuZero learn faster in terms of number of games played than humans?", "body": "<p>I don't know much about AI and am just curious.</p>\n<p>From what I read, AlphaZero/MuZero outperform any human chess player after a few hours of training. I have no idea how many chess games a very talented human chess player on average has played before he/she reaches the grandmaster level, but I would imagine it is a number that can roughly be estimated. Of course, playing entire games is not the only training for human chess players.</p>\n<p>Nonetheless, how does this compare to AI? How many games do AI engines play before reaching the grandmaster level? Do (gifted) humans or AI learn chess faster?</p>\n", "pids": ["5a73cbcc17c44a0b3035f7b3"], "flag": 1}
{"question": "What is the weight matrix in self-attention?", "body": "<p>I've been looking into self-attention lately, and in the articles that I've been seeing, they all talk about &quot;weights&quot; in attention. My understanding is that the weights in self-attention are not the same as the weights in a neural network.</p>\n<p>From this article, <a href=\"http://peterbloem.nl/blog/transformers\" rel=\"noreferrer\">http://peterbloem.nl/blog/transformers</a>, in the additional tricks section, it mentions,</p>\n<p>The query is the dot product of the query weight matrix and the word vector,\n<code>ie, q = W(q)x</code> and the key is the dot product of the key weight matrix and the word vector, <code>k = W(k)x</code> and similarly for the value it is <code>v = W(v)x</code>. So my question is, where do the weight matrices come from?</p>\n", "pids": ["599c7987601a182cd2648373"], "flag": 1}
{"question": "How does the brain know whether or not it comprehends a novel concept?", "body": "<p>There seem to be at least two kinds of confusion regarding novel concepts.</p>\n\n<p>In one, the brain simply can't form an abstract model from whatever information is being presented. It's where you can't \"wrap your head around\" something.</p>\n\n<p>In another, the brain perceives a cognitive dissonance, where something doesn't \"add up\", but further information provides a unifying model that can explain everything being presented.</p>\n\n<p>They seem to be related.</p>\n\n<p><strong>The brain is somehow able to evaluate the fidelity of an abstract model that it's trying to construct. How does this happen?</strong></p>\n", "pids": ["53e99940b7602d970217e963"], "flag": 0}
{"question": "How does masturbation influence your brain and dreams?", "body": "<p>What exactly changes in your brain the moment after you've finished masturbating? Could there be any effect neuro-psychologically on dreams or lucid dreaming?</p>\n", "pids": ["53e9aadfb7602d970346080d"], "flag": 1}
{"question": "Why does off-policy learning outperform on-policy learning?", "body": "<p>I am self-studying about Reinforcement Learning using different online resources. I now have a basic understanding of how RL works.</p>\n<p>I saw this in <a href=\"https://artint.info/2e/html/ArtInt2e.Ch12.S7.html\" rel=\"noreferrer\">a book</a>:</p>\n<blockquote>\n<p>Q-learning is an off-policy learner. An off-policy learner learns the value of an optimal policy independently of the agent’s actions, as long as it explores enough.</p>\n</blockquote>\n<blockquote>\n<p>An on-policy learner learns the value of the policy being carried out by the agent, including the exploration steps.</p>\n</blockquote>\n<p>However, I am not quite understanding the difference. Secondly, I came across that off-policy learner works better than the on-policy agent. I don't understand why that would be i.e. why off-policy would be better than the on-policy.</p>\n", "pids": ["5c2c7a9217c44a4e7cf31325"], "flag": 1}
{"question": "Fear of someone having the same idea and doing the research before you do", "body": "<p>I am a young researcher, and recently, I find that the drive to publish and advance my career has created an unhealthy mindset. In particular, I find that when I have a good idea, I am worried that someone will have the same idea, carry out the analysis, and publish before I do. While this worry has greatly speeded up my research, sometimes I feel it is unhealthy, in that my work becomes more sloppy, my analysis is less careful, I check for errors less, and as a result I'm more prone to making mistakes. I think this is an undesirable outcome, because it can potentially reduce the quality of my research results.</p>\n\n<p>However, the tradeoff is real - the more time one spends vetting one's results for accuracy and making improvements large or small, the later one publishes, and the risk of getting preempted is higher. Even if one is still able to publish, not being the first will reduce the impact of your publication.</p>\n\n<p>I am interested in hearing what others think about this, and approaches to dealing with and think about this issue, to have a healthy mindset and research environment.</p>\n", "pids": ["5f0747c69e795e1a9f4ad6f4"], "flag": 1}
{"question": "When we are sad, why do we feel pain in our stomachs?", "body": "<p>I thought everything is in the brain.</p>\n\n<p>Why do we feel pain in our stomachs when we are sad?</p>\n", "pids": ["55d065ca696322190568b010"], "flag": 1}
{"question": "Why did the developement of neural networks stop between 50s and 80s?", "body": "<p>In <a href=\"https://youtu.be/0bMe_vCZo30?t=779\" rel=\"nofollow noreferrer\">a video lecture on the development of neural networks and the history of deep learning</a> (you can start from minute 13), the lecturer (Yann LeCunn) said that the development of neural networks stopped until the 80s because people were using the wrong neurons (which were binary so discontinuous) and that is due to the slowness of multiplying floating point numbers which made the use of backpropagation really difficult.</p>\n<p>He said, I quote, &quot;If you have continuous neurons, you need to multiply the activation of a neuron by a weight to get a contribution to the weighted sum.&quot;</p>\n<p>But the statement stays true even with binary (or any discontinuous activation function) neurons. Am I wrong? (at least, as long as you're in the hidden layer, the output of your neuron will be multiplied by a weight I guess). The same professor said that the perceptron, ADALINE relied on weighted sums so they were computing multiplications anyways.</p>\n<p>I don't know what I miss here and I hope someone will enlighten me.</p>\n", "pids": ["5c7556c0f56def97986e672b"], "flag": 1}
{"question": "Is there an open-source license that enforces citations?", "body": "<p>I build simulations and make them open-source. Depending on the context I either license them with Apache or GPL. I publish the simulation results in paper and link to the code.\nHowever sometimes some parts of the code are useful for others regardless of the overall original simulation.</p>\n\n<p>Is there a way in the license to ask/recommend/enforce that people who use some of that code remember to cite the paper associated with it?</p>\n\n<p>Is a friendly reminder in the readme the best I can do?</p>\n", "pids": ["58437707ac44360f1082b79e"], "flag": 1}
{"question": "How do humans learn to combine tasks?", "body": "<p>I've been reading about <a href=\"https://mindmodeling.org/cogsci2014/papers/221/paper221.pdf\" rel=\"nofollow\">hierarchical learning</a> (a variant of reinforcement learning from what I understand) and how it is shown to allow learning of a higher-level task (the main example is assembly). I made the mistake of assuming that since the paper shows how a set of sequential actions are learned more quickly when the individual tasks are learned beforehand, that the same could be accomplished with a set of tasks to be combined.</p>\n\n<p>For example, imagine learning to play hockey. First, you have to learn how to skate effectively. Secondly, you learn how to handle the puck with a stick. Thirdly, you have to learn to be aware of the other players and their movement. Finally, you combine all of these and sometimes have to spend time refining the lower end skills to become an effective hockey player.</p>\n\n<p>Is there a name for this type of learning and a model associated to it? Is this type of learning encompassed in hierarchical learning?</p>\n", "pids": ["53e9bb6cb7602d97047ae3db"], "flag": 0}
{"question": "Where to find a study on women and selfies?", "body": "<p>I have recently read the following Yahoo article: <a href=\"https://in.lifestyle.yahoo.com/guys-why-never-post-too-many-selfies-social-053412852.html\" rel=\"nofollow\">Guys, this is why you should never post too many selfies on social media</a>.</p>\n\n<p>This article describes a study that correlates selfies taken by men and their psychology.</p>\n\n<p>So my question is where to find a similar study about women?</p>\n", "pids": ["53e9adf0b7602d97037f7ffd"], "flag": 0}
{"question": "What&#39;s the difference between content-based attention and dot-product attention?", "body": "<p>I'm following this <a href=\"https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html\" rel=\"noreferrer\">blog post</a> which enumerates the various types of attention.</p>\n<p>It mentions content-based attention where the alignment scoring function for the <span class=\"math-container\">$j$</span>th encoder hidden state with respect to the <span class=\"math-container\">$i$</span>th context vector is the cosine distance:</p>\n<p><span class=\"math-container\">$$\ne_{ij} = \\frac{\\mathbf{h}^{enc}_{j}\\cdot\\mathbf{h}^{dec}_{i}}{||\\mathbf{h}^{enc}_{j}||\\cdot||\\mathbf{h}^{dec}_{i}||}\n$$</span></p>\n<p>It also mentions dot-product attention:</p>\n<p><span class=\"math-container\">$$\ne_{ij} = \\mathbf{h}^{enc}_{j}\\cdot\\mathbf{h}^{dec}_{i}\n$$</span></p>\n<p>To me, it seems like these are only different by a factor. If we fix <span class=\"math-container\">$i$</span> such that we are focusing on only one time step in the decoder, then that factor is only dependent on <span class=\"math-container\">$j$</span>. Specifically, it's <span class=\"math-container\">$1/\\mathbf{h}^{enc}_{j}$</span>.</p>\n<p>So we could state: &quot;the only adjustment content-based attention makes to dot-product attention, is that it scales each alignment score inversely with the norm of the corresponding encoder hidden state before softmax is applied.&quot;</p>\n<p>What's the motivation behind making such a minor adjustment? What are the consequences?</p>\n<hr />\n<p>Follow up question:</p>\n<p>What's more, is that in <a href=\"https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\" rel=\"noreferrer\">Attention is All you Need</a> they introduce the scaled dot product where they divide by a constant factor (square root of size of encoder hidden vector) to avoid vanishing gradients in the softmax. Any reason they don't just use cosine distance?</p>\n", "pids": ["5e451e433a55acfaed738742", "599c7987601a182cd2648373"], "flag": 1}
{"question": "Who is supposed to repeat experiments?", "body": "<p>A follow up to <a href=\"https://academia.stackexchange.com/q/73544/41631\">this</a> question.</p>\n\n<p>There is an issue in science with experiments not being repeated. I asked if PhDs can be done on repeating experiments and the answer is kind of mixed. Most PhDs aren't that. I don't suspect that professors repeat experiments often. </p>\n\n<p>So, who is supposed to repeat experiments in academia?  </p>\n", "pids": ["5c756ba5f56def979840404d"], "flag": 1}
{"question": "Is it practical to train AlphaZero or MuZero (for indie games) on a personal computer?", "body": "<p>Is it practical/affordable to train an AlphaZero/MuZero engine using a residential gaming PC, or would it take thousands of years of training for the AI to learn enough to challenge humans?</p>\n<p>I'm having trouble wrapping my head around how much computing power '4 hours of Google DeepMind training' equates to my residential computer running 24/7 trying to build a trained AI.</p>\n<p>Basically, are AlphaZero or MuZero practical for indie board games that want a state of the art AI, or is it too expensive to train?</p>\n", "pids": ["5e8d92709fced0a24b5f4b5e", "5a73cbcc17c44a0b3035f7b3"], "flag": 1}
{"question": "What is the effect of parallel environments in reinforcement learning?", "body": "<p>Do parallel environments improve the agent's ability to learn or does it not really make a difference? Specifically, I am using PPO, but I think this applies across the board to other algorithms too.</p>\n", "pids": ["5736960a6e3b12023e51d64d"], "flag": 1}
{"question": "How to address a mistake in an old paper in a very prestigious scientific journal?", "body": "<p>A <em>Nature</em> paper published in 2000 currently has around 400 citations, but there is a mistake in the paper and surprisingly, still it gets citations. The mistake affects the result of the paper in a way that half of the arguments in the paper are invalid. </p>\n\n<p>I warned the authors two years ago and they confirmed the mistake. I expected them to put some announcement that there is a mistake in the paper to avoid misleading researchers, but unfortunately they have not done so.</p>\n\n<p>How should we address these situations? Should we send a comment and report it to the editor? Is it rude? Or should we simply dismiss it because it is an old paper?</p>\n", "pids": ["53e9bc2db7602d970489d396", "53e9bcadb7602d970492c95b"], "flag": 1}
{"question": "The unpredictable loading bar -- or, the slot machine effect", "body": "<p>Say we A-B tested user reactions to completing some task (e.g. transferring files, restarting their device): would people be quicker to get impatient/ annoyed if they got random percentages as indicators of progress, or if they had a steady, accurate progress bar? What if it was steady but NOT accurate?\nWhen would people experience the most intense emotional drops or rises? Would the slot machine effect play a part, i.e. would the chance of getting a &quot;big&quot; leap (21% towards update installation!) keep users waiting patiently during the slower progress intervals?</p>\n<p>This question is based off a wandering thought while my laptop was restarting recently, as well as some basic psych understanding. I can certainly see it being possible that people would, on average, be more willing to wait for a 2/3/8 min update with erratic progress than 1/2/5 mins with steady progress.\nI'd be interested if anyone knows of such/similar studies and, if so, what conclusions they reached.</p>\n<p>Edit: internet legend Tom Scott came through and discussed this topic recently, <a href=\"https://www.youtube.com/watch?v=iZnLZFRylbs\" rel=\"nofollow noreferrer\">https://www.youtube.com/watch?v=iZnLZFRylbs</a>!</p>\n", "pids": ["53e99e13b7602d97026d879a", "57d063bdac4436735428f49b", "5c88e8974895d9cbc69fece9", "557c8c336feeaa8086da14c3", "53e99d51b7602d970260b192", "573698546e3b12023e71b88f", "5c8d3dfb4895d9cbc6495d21", "5ea014d39fced0a24ba15d09"], "flag": 0}
{"question": "Can CNNs be made robust to tricks where small changes cause misclassification?", "body": "<p>I while ago I read that you can make subtle changes to an image that will ensure a good CNN will horribly misclassify the image. I believe the changes must exploit details of the CNN that will be used for classification. So we can trick a good CNN into classifying an image as a picture of a bicycle when any human would say it's an image of a dog. What do we call that technique, and is there an effort to make image classifiers robust against this trick?</p>\n", "pids": ["5b3d98cc17c44a510f8018e7", "573695fe6e3b12023e5121fc", "5550417845ce0a409eb3b9b3"], "flag": 1}
{"question": "What are the differences between a knowledge base and a knowledge graph?", "body": "<p>During my readings, I have seen many authors using the two terms interchangeably, i.e. as if they refer to the same thing. However, we all know about Google's first quotation of &quot;knowledge graph&quot; to refer to their <em>new</em> way of making use of their knowledge base. Afterward, other companies are claiming to use knowledge graphs.</p>\n<p>What are the technical differences between the two? Concrete examples will be very useful to understand better the nuances.</p>\n", "pids": ["5b3d98cc17c44a510f8017f5", "5e621f3d91e01160711d5f37", "5e621f3d91e01160711d5f37", "5e621f3d91e01160711d5f37", "5e621f3d91e01160711d5f37"], "flag": 1}
{"question": "Why is gradient descent used over the conjugate gradient method?", "body": "<p>Based on some preliminary research, the conjugate gradient method is almost exactly the same as gradient descent, except the search direction must be orthogonal to the previous step.</p>\n<p>From what I've read, the idea tends to be that the conjugate gradient method is <em><a href=\"https://scicomp.stackexchange.com/q/7819\">better</a></em> than regular gradient descent, so if that's the case, why is regular gradient descent used?</p>\n<p>Additionally, I know algorithms such as the <a href=\"https://en.wikipedia.org/wiki/Powell%27s_method\" rel=\"nofollow noreferrer\">Powell method</a> use the conjugate gradient method for finding minima, but I also know the Powell method is computationally expensive in finding parameter updates as it can be run on any arbitrary function without the need to find partial derivatives of the computational graph. More specifically, when gradient descent is run on a neural network, the gradient with respect to every single parameter is calculated in the backward pass, whereas the Powell method just calculates the gradient of the overall function at this step from what I understand. (See <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html\" rel=\"nofollow noreferrer\">scipy's minimize</a>, you could technically pass an entire neural network into this function and it would optimize it, but there's no world where this is faster than backpropagation)</p>\n<p>However, given how similar gradient descent is to the conjugate gradient method, could we not replace the gradient updates for each parameter with one that is orthogonal to its last update? Would that not be faster?</p>\n", "pids": ["5aed14d617c44a44381591ca"], "flag": 1}
{"question": "Do Support Vector Machines have the ability to learn while in use?", "body": "<p>I've read in some literature,that SVMs are characterized by their adaptivity. Does that mean they can learn while in use?</p>\n", "pids": ["558c0f3de4b00c3c48e001b2"], "flag": 1}
{"question": "Why isn&#39;t a target network used for the critic in on-policy actor-critic methods?", "body": "<p>Based on my research, I've seen so many on-policy AC approaches that utilise a critic network to estimate the value function <span class=\"math-container\">$V$</span>. The Bellman equation for the value function is as bellow:</p>\n<p><span class=\"math-container\">$$\nV_\\pi(s_t) = \\sum_a \\pi(a|s_t)\\sum_{r, s'}(r+V_\\pi(s'))P(s', r|s, a)\n$$</span></p>\n<p>It makes sense not to have a replay buffer due to the current policy in the formula and the fact that our approach is on-policy. However, I really do not figure out why no one uses a target network to stabilize the training process of the critic, like what we have in DQN, namely the variant published in 2015. Does anyone have an idea for that with probably a citation?</p>\n<p>I know that DDPG uses a critic with a fixed target network, but be aware that it is a real off-policy actor-critic. By &quot;real&quot; I mean it is not due to importance sampling.</p>\n<p>I have to mention that I can imagine something, but I'm not sure whether it is true or not. If we have a target network, it means we are trying to find a deterministic, optimal in the case of DQN, policy, while we are learning the current policy's data for the actor-critic case with the critic.</p>\n", "pids": ["5550417845ce0a409eb3b960"], "flag": 1}
{"question": "How do white Caladiums perform enough photosynthesis to support their mass?", "body": "<p>In some white caladiums, there is less than a square inch of green space spread over the whole leaf. How do these plants perform the photosynthesis necessary to support the large leaves, the roots, the flowers, and build a corm?</p>\n\n<p><a src=\"https://i.stack.imgur.com/k6Bgs.jpg\" alt=\"enter image description here\"></p>\n", "pids": ["55a46b8c65ce31bc877a1075", "56d912a0dabfae2eee4506c5", "55a474db65ce31bc877b6c3b"], "flag": 1}
{"question": "Why do Transformers have a sequence limit at inference time?", "body": "<p>As far as I understand, Transformer's time complexity increases quadratically with respect to the sequence length. As a result, during training to make training feasible, a maximum sequence limit is set, and to allow batching, all sequences smaller are padded.</p>\n<p>However, after a Transformer is trained, and we want to run it on a single sequence at inference time, the computational costs are far less than training. Thus, it seems reasonable that I would want to run the transformer on a larger input sequence length during inference time. From a technical perspective, this should be feasible.</p>\n<p>I keep reading online that a Transformer cannot be run on a sequence size larger than the one seen during training. Why is this? Is it because the network weights will be unfamiliar with sequences of this length? Or is it more fundamental?</p>\n", "pids": ["5c5ce50d17c44a400fc39035"], "flag": 1}
{"question": "The function of pumps in forming the resting potential", "body": "<p>I am confused by the following. Apparently the resting potential of -65mV is reached when the two forces, diffusion and electrical gradient are in equilibrium. So why does the book say </p>\n\n<p>\"The electrical potential difference across the membrane [..] charge is maintained by the work of the ion pumps.\"</p>\n\n<p>Why should it be \"maintained by the pumps\" if it is an equilibrium anyway?</p>\n\n<p>One possible answer I can imagine is: the equilibrium is too unstable and so the pumps are stabilizing it. But I have no idea if this is correct. Thanks.</p>\n", "pids": ["53e9a74ab7602d9703083a3d"], "flag": 1}
{"question": "InstructGPT: What is the sigma in the loss function and why $\\log(\\cdot)$ is being used?", "body": "<p>InstructGPT: What is the sigma in the loss function and why <span class=\"math-container\">$\\log(\\cdot)$</span> is being used?</p>\n<p><span class=\"math-container\">$$ \\operatorname{loss}(\\theta) = -\\frac{1}{\\binom{K}{2}}E_{(x,y_w,y_l)\\sim D}[\\log(\\sigma(r_{\\theta}(x, y_w) - r_{\\theta}(x, y_l)))] $$</span></p>\n<p>The equation was taken from the <a href=\"https://arxiv.org/abs/2203.02155\" rel=\"nofollow noreferrer\">InstructGPT paper</a>.</p>\n", "pids": ["61f50e3ad18a2b03dd0e7489"], "flag": 1}
{"question": "Activity in a brain region and additional blood requirement: What is the causal relation?", "body": "<p>May I know causal dependence of the blood flow in the brain?</p>\n\n<p>How it is determined by the brain that particular brain region requires additional blood?</p>\n", "pids": ["53e9ac89b7602d970365ebf0"], "flag": 1}
{"question": "Can someone be healed from a long-held addiction or compulsive disorder in an instant and without therapy due to a dramatic spiritual experience?", "body": "<p>Can someone be healed from a long-held addiction or compulsive disorder in an instant due to a dramatic spiritual experience and without therapy?</p>\n<p>My question is motivated by multiple conversion testimonies in which people claim to have had dramatic life-changing spiritual &quot;encounters&quot; or experiences that put an immediate end to behavioural addictions, substance addictions, mental health issues, among others. For illustrative purposes, I'm sharing below two conversion testimonies that I find quite impressive and don't know how to explain from a psychological point of view, and therefore I believe they can be interesting case studies.</p>\n<hr />\n<p><strong>Testimony 1</strong>: <a href=\"https://youtu.be/hyHAFvPn-ik?t=948\" rel=\"nofollow noreferrer\">From Atheist To Believer In Jesus Christ - How Jesus Cured My Eating Disorder - Christian Testimony</a></p>\n<p>This testimony has many details, but I want to focus here on the eating disorder aspect of it (from 15:47 to 23:34), and the experience this girl had that made her free in a matter of seconds. This girl had been suffering from bulimia and anorexia for 4 years, with multiple failed attempts to quit the behaviour up to that point. According to her testimony, in December of 2017 she was throwing up in the bathroom, she was feeling impotent, hopeless and desperate. In the midst of this, she had the sudden occurrence to mentally cry out &quot;Jesus&quot; and immediately, in a matter of seconds, a feeling of immense love and peace overwhelmed her. But most astonishingly, as a result of this overwhelming emotional experience, her 4 year bondage to bulimia and anorexia immediately stopped. According to her testimony, the experience happened 2 years prior to the recording of the video, and she has never relapsed or even had the desire to ever since.</p>\n<p>She devotes a good part of the video to describe in great detail her bathroom experience. She employs an interesting analogy to help the audience understand her experience: she referenced her maternal love for her 5 year old son as a strong baseline, and then claimed that the sense of love that overwhelmed her in the bathroom greatly surpassed it.</p>\n<p>I find this testimony quite impressive, and there are 2 aspects that I find particularly intriguing:</p>\n<ul>\n<li>This lady experienced a spontaneous emotional transition from deep despair to overwhelming love and peace in just seconds. How is this possible?</li>\n<li>As a result of this 'ecstatic' experience (let's call it that way), she was instantly healed of bulimia and anorexia, despite a track record of 4 years of failed attempts at quitting.</li>\n</ul>\n<hr />\n<p><strong>Testimony 2</strong>: <a href=\"https://youtu.be/4ZFhNIKjYPw?t=1657\" rel=\"nofollow noreferrer\">MY TESTIMONY: JESUS SAVED ME FROM DEMONS, ATHEISM, SEVERE DEPRESSION &amp; MORE!!</a></p>\n<p>This testimony describes a somewhat similar experience to the first one. In short: a woman tells that for decades she used to deal with severe depression, strong anger and hatred issues, porn addiction and compulsive stealing. She also mentions that she used to be a lesbian, and for many years experienced sleep paralysis &quot;attacks&quot; at night and felt &quot;evil presences&quot; during these episodes. According to her testimony, one night she experienced a sleep paralysis episode that was unusually intense (extremely intense). In similar fashion to the previous testimony, she cried out in desperation &quot;Jesus, save me&quot; a couple times, broke down emotionally, cried for 1 hour, and experienced afterwards a sudden freedom from all her past addictions and mental health issues, without relapses. This experience is narrated in detail from 27:37 to 33:41 in the video.</p>\n<p>But there is more. At <a href=\"https://youtu.be/4ZFhNIKjYPw?t=2561\" rel=\"nofollow noreferrer\">42:41</a> she tells that her change was so dramatic that it even affected her sexual preferences. Yes, that's right, her same-sex attraction stopped -- she wasn't a lesbian anymore.</p>\n<p>I find this second testimony incredible as well. This woman had an intense episode of sleep paralysis, cried out for help in desperation, broke into tears and cried for 1 hour, and then, boom!, all her addictions and mental health issues were pretty much gone. Back to factory settings. Completely healed. No therapies needed. Just an ecstatic/cathartic experience and that's it.</p>\n<hr />\n<p>I'm really intrigued to know a psychological explanation for these testimonies. I imagine that if we could learn how to tap into the power of our minds to suddenly turn our emotions into peace and love (like in the first testimony) or experience a strong emotional catharsis (like in the second testimony) to free ourselves from years of addictions and unhealthy compulsive disorders in a matter of seconds, that would just revolutionize therapy and addiction recovery programs.</p>\n<p>So, what is really going on psychologically in these testimonies? Do these experiences have a name? How is it possible for a person to suddenly quit years of addiction or compulsive habits or mental health issues in a matter of seconds, without therapy and without relapsing?</p>\n", "pids": ["55a61ac265cead59c833e84f", "5e68c3e993d709897cd4bcb8", "55a6ad8b65ce054aad70cd50", "5aa64c5a6b516fb98bc880f9", "55a43731c91b587b0971f223", "55a6b02e65ce054aad7121cb", "5c0f773ada562944ac7139ea"], "flag": 0}
{"question": "Which personality theories do belong to humanistic?", "body": "<p>I went through literature and I am confused which theories of personality belong to humanistic, in literature there is often just Rogers (who is sometimes also considered to be phenomenologic) and Maslow. Do you know about some other that could be considered for humanistic too?\nCan I say that all humanistic psychologists created humanistic personality theory (e. g. Allport, Frankl etc.)?</p>\n", "pids": ["61c8b0b05244ab9dcb36ec34"], "flag": 1}
{"question": "In MCTS, what to do if I do not want to simulate till the end of the game?", "body": "<p>I'm trying to implement MCTS with UCT for a board game and I'm kinda stuck. The state space is quite large (3e15), and I'd like to compute a good move in less than 2 seconds. I already have MCTS implemented in Java from <a href=\"https://www.baeldung.com/java-monte-carlo-tree-search\" rel=\"nofollow noreferrer\">here</a>, and I noticed that it takes a long time to actually reach a terminal node in the simulation phase.</p>\n<p>So, would it be possible to simulate games up until a specific depth?</p>\n<p>Instead of returning the winner of the game after running until the max depth, I could return an evaluation of the board (the board game is simple enough to write an evaluation function), which then back propagates.</p>\n<p>The issue I'm having is in handling the backpropagation. I'm not quite sure what to do here. Any help/resources/guidance is appreciated!</p>\n", "pids": ["59ec02da0cf22f5df7319dc3"], "flag": 1}
{"question": "Why are (some) cats attracted by bleach?", "body": "<p>(Sorry if this question is only partly biological)</p>\n<p>I have noticed that several cats (including the one that keeps sleeping in my house), are fond of the odor of bleach (eau de Javel) and chlorine.</p>\n<blockquote>\n<p>Among examples, chlorine is used in small quantities in tape water and the cat is fond of licking the faucet in acrobatic positions even if there is mineral freshwater nearby.</p>\n<p>I was one day not careful enough using a bleach based gel cleaning product and some of it got on my hand. Even after cleaning my hands, they still had a bleach &quot;perfume&quot; and my cat cling to me and even cleaned my hands with his tongue for minutes.</p>\n</blockquote>\n<p>Why is this so ? Are there other animals known to have this taste ?</p>\n<p>Might it be in fact acquired through living with humans ?</p>\n<p>Is this potentially detrimental to their physiology ?</p>\n", "pids": ["53e9bcbbb7602d970493e465", "53e9ac28b7602d97035ec4f1"], "flag": 1}
{"question": "How do reward signals strengthen synaptic connections in the human brain?", "body": "<p>In a vast simplification, the mid-brain sends reward signals (for example through dopaminergic neurons) that tell the rest of the brain whether it succeeded at fulfilling the needs of the organism. If there are certain activities in the brain that lead to a successful action, then these activities should have a higher probability of occurring again (since that is useful for achieving the organism's needs in future).</p>\n\n<p>To increase the probability of the occurrence of an activation pattern as a response to a certain history of sensory input, the neurons that were involved to produce this pattern will need to adapt their synapses such that they become more sensitive to this input.</p>\n\n<p>I'm wondering, how are the reward signals thought to affect the neurons that were involved in the previous actions of the organism at the synaptic level?</p>\n", "pids": ["53e99a2fb7602d970228b0a1"], "flag": 1}
{"question": "Why do some professors with PhDs leave their professorships to teach high school?", "body": "<p>I can surmise that some of them mightn't have gotten tenure and needed to find another job, but wouldn't these former professors be bored teaching the same (relatively basal) material yearly?</p>\n\n<p>Let me know of other examples, but I was riffling some fee-paying schools and lighted upon:</p>\n\n<ul>\n<li><p><a href=\"https://www.commschool.org/directory\" rel=\"noreferrer\">Audrey Budding</a>, of the <a href=\"https://iwpr.net/global-voices/historian-bests-milosevic\" rel=\"noreferrer\">Harvard Academy for International and Area Studies</a></p>\n\n<blockquote>\n  <p>B.A., Swarthmore College 1982<br>\n  B.A., University of Cambridge (UK) 1984<br>\n  M.A., Harvard University 1991<br>\n  Ph.D., Harvard University 1998   </p>\n</blockquote></li>\n<li><p><a href=\"https://www.classics.upenn.edu/people/eric-casey\" rel=\"noreferrer\">Eric Casey</a>, former Associate Professor of Classics, Sweet Briar College. Now at <a href=\"https://www.linkedin.com/in/eric-casey-35a78230/\" rel=\"noreferrer\">Trinity School NYC</a>.</p></li>\n<li><p><a href=\"https://mylearningspringboard.com/david-gomprecht/\" rel=\"noreferrer\">David Gomprecht</a> at <a href=\"https://www.dalton.org/our-community/faculty?deptId=1968\" rel=\"noreferrer\">Dalton School</a>. </p>\n\n<blockquote>\n  <p>Gomprecht, PhD, graduated from Wesleyan University, where he majored in mathematics and physics, and then went on to receive a Ph.D. in mathematics from the University of California at Berkeley. After working as a research mathematician for a few years, David returned to his hometown of New York City, where he has now been a <a href=\"https://mylearningspringboard.com/math-specialists/\" rel=\"noreferrer\" title=\"math specialist\">math specialist</a> and <a href=\"https://mylearningspringboard.com/private-tutoring/\" rel=\"noreferrer\" title=\"private tutor\">private tutor</a> for over twenty years.</p>\n</blockquote></li>\n<li><p><a href=\"https://www.linkedin.com/in/mara-naaman-84326b46/\" rel=\"noreferrer\">Mara Naaman</a> at Dalton School.</p>\n\n<blockquote>\n  <p><a href=\"https://i.stack.imgur.com/p5idi.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/p5idi.jpg\" alt=\"enter image description here\"></a></p>\n</blockquote></li>\n</ul>\n", "pids": ["581403b50cf2851b89eaab57"], "flag": 1}
{"question": "Are there mental states that make the mind more susceptible to other negative mental states?", "body": "<p>I've recently read the following folk parable and am interested if there is any truth to it.</p>\n\n<p>It is originally in russian(<a href=\"http://www.adme.ru/svoboda-psihologiya/pritcha-ob-unynii-737260/\" rel=\"nofollow\">full version here)</a>, so I will translate the gist of it:</p>\n\n<blockquote>\n  <p>The devil displays his Arsenal of tools used to corrupt mortals - anger,\n  jealousy, greed, etc. Then he shows the \"special\" tool which can work\n  when all else fails- depression (dismay or broken spirit). He suggests that once depression takes hold, the mind is open to all other tools (jealousy, greed, etc)</p>\n</blockquote>\n\n<p>This got me thinking - <strong>is there some equivalent of a mental \"immune system\" which keeps the mind healthy and keeps negative, unwanted, maladaptive emotions at bay?</strong></p>\n\n<p>Are there conditions that make the mind more open to other disorders?</p>\n", "pids": ["55d065ca696322190568b010"], "flag": 1}
{"question": "Why do people have darker skin in sunnier climates?", "body": "<p>I don't understand why darker skin is advantageous in hotter climates. Wouldn't it absorb more of the heat? I have heard that it reduces the incidence of cancer, but I would think absorbing more radiation would increase the risk?</p>\n", "pids": ["53e9b22eb7602d9703ccbb52"], "flag": 1}
{"question": "How do chromosome pairs get &quot;paired up&quot; for protein synthesis?", "body": "<p>If my understanding is correct, during interphase a normal human cell will have 46 chromosomes scattered about in the cell nucleus. These chromosomes can be thought of as pairs: there are two copies of \"chromosome 1\", one from mom and one from dad. Same goes for chromosome 2, chromosome 3, ... chromosome 22. Although we think of these as coming in pairs, are they actually attached or paired up in some way?</p>\n\n<p>At some point, protein synthesis will take place via transcription. What I'm having trouble understanding is how and when the above pairing takes place. Does transcription occur independently for each of the 46 chromosomes? I don't think this is the case, because in my head I imagine that we will only get one set of proteins from the <em>pair of each chromosome</em>. Also, I'm unclear as to how dominant/recessive genes can come into play unless protein synthesis occurs as a function of both pairs of chromosomes.</p>\n\n<p>I hope this is clear enough. Thanks.</p>\n", "pids": ["56d8e887dabfae2eee410f7d", "55a6b62065ce054aad7258e5", "55a6ad1e65ce054aad70abb5"], "flag": 1}
{"question": "Are there any learning algorithms as powerful as &quot;deep&quot; architectures?", "body": "<p>This <a href=\"http://blog.claymcleod.io/2016/06/01/The-truth-about-Deep-Learning/\" rel=\"nofollow noreferrer\">article</a> suggests that deep learning is not designed to produce the universal algorithm and cannot be used to create such a complex systems.</p>\n\n<p>First of all it requires huge amounts of computing power, time and effort to train the algorithm the right way and adding extra layers doesn't really help to solve complex problems which cannot be easily predicted.</p>\n\n<p>Secondly some tasks are extremely difficult or impossible to solve using DNN, like solving a <a href=\"https://ai.stackexchange.com/q/154/8\">math</a> equations, predicting <a href=\"https://ai.stackexchange.com/q/225/8\">pseudo-random lists</a>, <a href=\"https://ai.stackexchange.com/q/168/8\">fluid mechanics</a>, guessing encryption algorithms, or <a href=\"https://ai.stackexchange.com/q/205/8\">decompiling</a> unknown formats, because there is no simple mapping between input and output.</p>\n\n<p>So I'm asking, are there any alternative learning algorithms as powerful as deep architectures for general purpose problem solving? Which can solve more variety of problems, than \"deep\" architectures cannot?</p>\n", "pids": ["573695fe6e3b12023e511744"], "flag": 1}
{"question": "Is GPT-4 based on GPT-3 or was it trained from the scratch?", "body": "<p>To me it looks like GPT-4 is based on GPT-3.</p>\n<p>On the other hand, there were rumors that training of GPT-3 was done with errors, but re-train was impossible due to the costs.</p>\n", "pids": ["599c7987601a182cd2648373", "603d8d919e795eac93d4c16f", "641130e378d68457a4a2986f"], "flag": 1}
{"question": "How detrimental is involvement in politics to a scientific career?", "body": "<p>I am an undergraduate student in the hard sciences, and am thinking of pursuing a research career after graduation. I am also quite politically involved on the left, and have political articles published online. I am critical of many governments (including my own) and corporations, and of many of the applications of technology in fields I am interested in.</p>\n\n<p>My politics are very important to me, and I could not give them up. That said, I often worry about how they could be detrimental to my career, especially before I'm already established. I worry, for instance, that grad school admissions would Google my name and find my views and affiliations, and that this would negatively impact my chances to get in. How realistic is this fear?</p>\n", "pids": ["56d81897dabfae2eee834cca"], "flag": 1}
{"question": "How often are results faked in computer science papers?", "body": "<p>Especially in the the more experimental subfields of computer science like systems, how often are results faked? If there is no verification process for any code used, do researchers sometimes fake results to save time?</p>\n", "pids": ["56d81883dabfae2eee829cae"], "flag": 1}
{"question": "Could motivational interviewing techniques be used without engaging with a counselor?", "body": "<p>I've found lots of info on <a href=\"http://www.motivationalinterviewing.org/\" rel=\"nofollow\">motivational interviewing</a> for strengthening a person's own motivation and commitment to change, but I'm wondering if this technique has been adapted to help people who won't or can't get to a counselor or therapist.  </p>\n\n<p>Is a therapist required to administer the interviews?  Has anyone used the technique without having therapist appointments, e.g., could an interactive website provide similar guidance?</p>\n", "pids": ["5c0f7594da562944ac6d7df8", "53e99b9bb7602d9702440ffd"], "flag": 0}
{"question": "Can NSAIDs impact negatively the healing of tendons?", "body": "<p>There are a number of articles regarding nonsteroidal anti-inflammatory drugs\n (NSAIDs) having a negative effect on healing conditions like tendonosis and tendinitis. From what I understand the channel through which they reduce inflammation disrupts healing. In general, many of them constrict vessels, thus reducing bloodflow even further to tendons. Are there other reasons, or interactions they can have with  cells that may also disrupt healing?</p>\n\n<p>Are there advantages of using NSAIDs to promote healing?</p>\n", "pids": ["55a5269165ceb7cb02e28457", "55a5420365ceb7cb02e61248", "55a4b67d612ca64868a0e0a1"], "flag": 1}
{"question": "Reduction of the hippocampus due to childhood neglect/abuse", "body": "<p>A Scientific American article, <a href=\"http://www.scientificamerican.com/podcast/episode/childhood-stress-decreases-size-of-brain-regions/\" rel=\"nofollow\">\"Childhood Stress Decreases Size of Brain Regions\", by Christie Nicholson</a> briefly mentions the implications of childhood neglect and abuse on brain structures. I was interested in the reduction of the hippocampus. Are there any studies that explain the reasoning behind this reduction? </p>\n\n<p>Could the reduction be a coping mechanism in reducing the probability of remembering extremely negative memories (ex. physical abuse)? </p>\n", "pids": ["53e9b421b7602d9703f175df", "53e99d87b7602d9702643ac9"], "flag": 0}
{"question": "State representation of position in 2D plane for Reinforcement Learning (Q Learning)", "body": "<p>I recently finished Course on RL by David Silver (on YT) and thought about trying it out on simple application in Unity Game Engine, where I've built simple labyrint with ball and want to teach the ball to get from point A to point B in there while avoiding obstacles and fire (the place where you'll get burnt so big negative reward)</p>\n\n<p>The problem I encountered while designing the whole thing (programming-wise) is: What is the correct (or at least good) way of representing the position in 2D space? It is continuous so I thought about representing it as feature vector consisting of [up, down, left, right, posX, posY] where direction is whether I am pressing button of moving in that direction in binary (or actions if you want) and pos are floats (0-1) representing normalized position from one corner on the plane where the whole map is. That would be accompanied by vector W that would represent the weights adjusted using Gradient Descent.</p>\n\n<p>Question is: will this work?? I am asking for 2 reasons. One is that I am not so sure about that posX and posY since it can be 0 and if I multiply it by the weights vector then how could be resulting reward anything but 0? Second reason is that I am not sure if the actions should be part of the features. I mean, it makes sense to me but I could easily be very wrong since I am a beginner.</p>\n\n<p>Thanks a lot guys in advance. If you have any more questions or think the problem is not described deeply enough just ask in the comments and I'll edit the question. :)</p>\n\n<p>PS: I could just code it the way I think is right, but I also want to get gasp of designing applications on paper before coding them (project management).</p>\n", "pids": ["5736960a6e3b12023e51d64d"], "flag": 1}
{"question": "Searching a pdf journal paper for mathematical symbols", "body": "<p>When skimming through a long mathematical paper (in pdf format), I often find a mathematical symbol (often in greek and with subscripts/superscripts) that was defined previously somewhere else within the paper.  Of course, it's not always easy to find where the parameter was defined, so I resort to using the FIND tool.  However, simply copy and pasting the symbol to the FIND tool doesn't seem to work well, since the symbol cannot be copied exactly.</p>\n\n<p>Is there a better way to perform an automated search a PDF document for a particular mathematical symbol if I don't have the original latex file?  Especially ones with subscripts and superscripts?</p>\n", "pids": ["56d88d5ddabfae2eeeca3e58"], "flag": 1}
{"question": "What are some techniques/method that can be used to train and detect objects like cars and humans?", "body": "<p>I have used OpenCV to train Haar cascades to detect face and other patterns. However I later realized that Haar tends to give a lot of false positives and I learned of Hog would give a more accurate results. But OpenCV doesn't have a good documentation of how to train hogs, I have googled a bit and found results that includes SVM and others.</p>\n\n<p>OpenCV also has versioning problem where they move certain classes or functions somewhere else.</p>\n\n<p>Are there any other techniques/method that I can use to train and detect objects and patterns? Preferably with proper documentation and basic tutorial/examples. Language preference: C#, Java, C++, Python</p>\n", "pids": ["5736986b6e3b12023e730129"], "flag": 1}
{"question": "Should I repeat lengthy deep learning experiments to average results ? How to decide how many times to repeat?", "body": "<p>I am doing my MSc thesis on deep learning. My model takes many hours to train. Part of what I do is trying different parameters and settings hoping that they will achieve different results. But I often notice that the result differences are too small to conclude whether the set of parameters A is better than B. Sometimes it happens that on a first run, set A seems to work better than B, but on a second run the opposite is suggested.</p>\n<p>The logical approach for that would be to repeat experiments and average out. But it seems unpractical given that each run could take so many hours.</p>\n<p>I wonder how expert AI researchers deal with that, do they perform multiple experiments, even if this takes extremely long? Do they draw conclusions from single runs?</p>\n", "pids": ["612d9dd25244ab9dcbdfb3dc", "60f7ff3c91e011bc10230711"], "flag": 1}
{"question": "Why do we need target network in deep Q learning?", "body": "<p>I already know deep RL, but to learn it deeply I want to know why do we need 2 networks in deep RL. What does the target network do? I now there is huge mathematics into this, but I want to know deep Q-learning deeply, because I am about to make some changes in the deep Q-learning algorithm (i.e. invent a new one). Can you help me to understand what happens during executing a deep Q-learning algorithm intuitively?</p>\n", "pids": ["55a6bae665ce054aad73115b"], "flag": 1}
{"question": "Are there any artificial neuromorphic systems which can mimic the brain?", "body": "<p>I'd like to know whether there were attempts to simulate the whole brain, I'm not talking only about some <a href=\"https://ai.stackexchange.com/q/237/8\">ANN on microchips</a>, but brain simulations.</p>\n", "pids": ["57d8e3de04b636d407599b27"], "flag": 1}
{"question": "Do mosquitoes need to pump blood out of the host?", "body": "<p>Many species of mosquitoes have bloodsucking females.</p>\n\n<p>When they bite a host, do they need to pump? Or does the sheer blood pressure combined with capillary action suffice to make the blood rush into the mosquito's stomach?\nIf the blood pressure is enough, can the mosquito \"explode\" or simply die from having too much blood rushing in?</p>\n", "pids": ["53e99ecab7602d9702791813"], "flag": 1}
{"question": "Would exposure to a strong magnetic field have deleterious effect on the human?", "body": "<p>This <a href=\"http://www.ubergizmo.com/2011/07/worlds-strongest-magnet/\">article</a> states of a 25T magnet, \".. If are ever caught in one of these devices, let’s just say you probably won’t live to tell the tale.\"</p>\n\n<p>Is the above statement in order? What effect would exposure to such a high magnetic field have on the exposed human?</p>\n", "pids": ["53e99a9eb7602d970231422d"], "flag": 1}
{"question": "Can a hyperpolarized neuron fire action potentials?", "body": "<p>Is there any chance that a neuron could fire when hyperpolarized? In that case, would the spike be different than usual?</p>\n", "pids": ["55a5ff3d65cead59c8324319"], "flag": 1}
{"question": "Can we create AI to not only recognize itself, but to recognize other AI systems as well?", "body": "<p>Can AI systems be created that could recognize itself, and recognize intelligence in other systems, and make intelligent decisions about the other systems? Mankind seems to be making progress in self-recognition but I've not seen evidence of one system recognizing other systems and being able to compare it's own intelligence with other systems. How could this be accomplished?</p>\n", "pids": ["53e9a54eb7602d9702e734b7"], "flag": 1}
{"question": "Using Reinforcement Learning in Immersive Virtual Reality to make a person move to a specific location in a virtual environment", "body": "<p>I'm here to ask you for a solution on this problem which is: how to use <em>Reinforcement Learning in Immersive Virtual Reality to make a person move to a specific location in a virtual environment</em>.</p>\n<blockquote>\n<p>Reinforcement Learning is a sub-area of Machine Learning in which an\nactive entity called an agent interacts with its environment and\nlearns how to act in order to achieve a pre-determined goal. The\nReinforcement Learning had no prior model of behaviour and the\nparticipants no prior knowledge that their task was to move to and\nstay in a specific place. The participants were placed in a virtual\nenvironment where they had to avoid collisions with virtual\nprojectiles. Following each projectile the agent analysed the movement\nmade by the participant to determine paths of future projectiles in\norder to increase the chance of driving participants to the goal\nposition and make them stay there as long as possible.</p>\n</blockquote>\n<p>The purpose of this question is to find a direct answer from the community with help of a paper which is already published on <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S1071581916301513\" rel=\"nofollow noreferrer\">science direct</a> and the text above is exactly quoted from that source (<a href=\"http://discovery.ucl.ac.uk/1539195/1/Slater_elsarticle-template-harv.pdf\" rel=\"nofollow noreferrer\">PDF version</a>).</p>\n<p>How can we approach solving this problem?</p>\n", "pids": ["5d9edb5b47c8f76646015f57"], "flag": 1}
{"question": "What kind of algorithm is used by StackGAN to generate realistic images from text?", "body": "<p>What kind of algorithm is used by StackGAN to generate realistic images from text? How does StackGAN work?</p>\n", "pids": ["5e8d92879fced0a24b60cbfc"], "flag": 1}
{"question": "Can brain hemisphere activity/ dominance be inferred from the test subject&#39;s drawings?", "body": "<p>I'm aware that all tasks that a person undertakes involve both halves of the brain. At the same time, there are studies of people who have communication between brain halves severed or suppressed and they produce dramatically different drawings of the same object with different hands.</p>\n\n<p>This makes me ask - <strong>is there some sort of a (non-FMRI) test that involves drawing or other activity and can:</strong></p>\n\n<ul>\n<li>Determine if one half of the brain is dominant at the given moment</li>\n<li>Determine if communication between brain halves is fluctuating over multiple days</li>\n<li>Determine if one half of the brain does not consistently function at the same level of activity?</li>\n</ul>\n\n<p>I'm aware of this <a href=\"http://www.ted.com/talks/jill_bolte_taylor_s_powerful_stroke_of_insight\" rel=\"nofollow noreferrer\">Ted talk: My stroke of insight</a>, in which a neuroscientist describes the experience of having a stroke affect one half of her brain, dramatically altering her perception and ability to process real world information. For example she describes being unable to recognize digits in a phone number and \"hunting\" for the right digit by tracing its shape on the phone.</p>\n\n<p>The images below were made using 100% input from one brain half and 0% from the other. <strong>I'm interested if different levels of activity in brain halves, like 100%/50% or 100%/80% or 60%/70% would also create noticeable differences in style.</strong> </p>\n\n<p><a src=\"https://i.stack.imgur.com/F6h1e.jpg\" alt=\"enter image description here\"></p>\n\n<p><a src=\"https://i.stack.imgur.com/HxTI0.jpg\" alt=\"enter image description here\"></p>\n", "pids": ["53e99eeeb7602d97027bd304"], "flag": 1}
{"question": "Does gradient descent in deep learning assume a smooth fitness landscape?", "body": "<p>I've come across the concept of fitness landscape before and, in my understanding, a smooth fitness landscape is one where the algorithm can converge on the global optimum through incremental movements or iterations across the landscape.</p>\n<p>My question is: <strong>Does deep learning assume that the fitness landscape on which the gradient descent occurs is a smooth one? If so, is it a valid assumption?</strong></p>\n<p>Most of the graphical representations I have seen of gradient descent show a smooth landscape.</p>\n<p>This <a href=\"https://en.m.wikipedia.org/wiki/Fitness_landscape\" rel=\"nofollow noreferrer\">Wikipedia page</a> describes the fitness landscape.</p>\n", "pids": ["58d82fced649053542fd6ec6", "58437725ac44360f1082fb93", "599c796a601a182cd263aace", "5aed14d617c44a44381591ca"], "flag": 1}
{"question": "What&#39;s done towards AI learning new ways of learning?", "body": "<p>Most (all I know) machine learning systems use a fixed set of data input channels and processing algorithms, only expanding underlying dataset processed by these; they obtain new data but only from predefined sources, and use only their fixed, built-in capacity to process it, possibly tweaking parameters of the algorithm (like weights of neural network nodes) but never fundamentally changing the algorithm.</p>\n\n<p>Are there systems - or research into creating these - that are able to acquire \"from out there\" new methods of obtaining data and new ways to process it for results? Expand not just passive data set to \"digest it\" by active but static algorithm, but make the algorithm itself self-expanding - be it in terms of creating/obtaining new processing methods for own data set, and creating/obtaining new methods of acquiring that data (these methods)?</p>\n", "pids": ["599c7f09601a182cd28e6395"], "flag": 1}
{"question": "Calculate criterion values for each confidence level (within SDT)", "body": "<p>Take a 2AFC task, where people also give a measure of confidence. \nIn the framework of signal detection theory, the criterion values for each confidence level are simply additional criteria, placed on the same internal response axis as the (first order task) decision criterion. </p>\n\n<p>Can I estimate the values of these additional confidence criteria from the data of a subject? If so, how? Would I simply take all trials with (say) confidence = 3, and calculate the criterion based on those trials alone?</p>\n", "pids": ["56d81b7adabfae2eee971a38"], "flag": 0}
{"question": "What are state-of-the-art ways of using greedy heuristics to initially set the weights of a Deep Q-Network in Reinforcement Learning?", "body": "<p>I am interested in the current state-of-the-art ways to use quick, greedy heuristics in order to speed up the learning in a Deep Q-Network in Reinforcement Learning. In classical RL, I initially set the Q-value for a state-action pair (S,a) based on the result of such a greedy heuristic run from state S with action a. Is this still a good idea in the setting of a neural network for the approximation of the Q-function, and if yes, what are the optimal ways of doing it? What are other ways of aiding the DQN with the knowledge from the greedy heuristics?</p>\n\n<p>References to state-of-the-art papers would be highly appreciated.</p>\n", "pids": ["5736960a6e3b12023e51d516"], "flag": 1}
{"question": "How can we use crowdsourcing for deep learning?", "body": "<p>Most companies dealing with deep learning (automotive - Comma.ai, Mobileye, various automakers, etc.) do collect large amounts of data to learn from and then use lots of computational power to train a neural network (NN) from such big data. I guess this model is mainly used because both the big data and the training algorithms should remain secret/proprietary.</p>\n<p>If I understand it correctly the problem with deep learning is that one needs to have:</p>\n<ol>\n<li>big data to learn from</li>\n<li>lots of hardware to train the neural network from this big data</li>\n</ol>\n<p>I am trying to think about how crowdsourcing could be used in this scenario. Is it possible to distribute the training of the NN to the crowd? I mean not to collect the big data to a central place but instead to do the training from local data on the user's hardware (in a distributed way). The result of this would be lots of trained NNs that would in the end be merged into one in a <a href=\"https://en.wikipedia.org/wiki/Committee_machine\" rel=\"nofollow noreferrer\">Committee of machines</a> (CoM) way. Would such a model be possible?</p>\n<p>Of course, the model described above does have a significant drawback - one does not have control over the data that is used for learning (users could intentionally submit wrong/fake data that would lower the quality of the final CoM). This may be dealt with by sending random data samples to the central community server for review, however.</p>\n<p>Example: Think of a powerful smartphone using its camera to capture a road from a vehicle's dashboard and using it for training lane detection. Every user would do the training himself/herself (possibly including any manual work like input image classification for supervised learning etc.).</p>\n<p>I wonder if the model proposed above may be viable. Or is there a better model of how to use crowdsourcing (user community) to deal with machine learning?</p>\n", "pids": ["5df20fc53a55acbe6bfcc74f"], "flag": 1}
{"question": "Can people with absolute pitch identify the exact frequency, or simply the pitch class?", "body": "<p><a href=\"https://en.wikipedia.org/wiki/Absolute_pitch\" rel=\"nofollow\"><strong>Absolute pitch</strong></a> can be defined as <strong>the ability to identify or re-create a given musical note without the benefit of a reference tone</strong>.</p>\n\n<p>When people claim to have absolute pitch, does this mean they have the capacity to detect the exact frequency of a note, or merely the pitch class (i.e. C,C#,D, etc)? </p>\n", "pids": ["53e99c67b7602d970251ae2d"], "flag": 1}
{"question": "How many species did Carl Linnaeus classify?", "body": "<p>How many species did Carl Linnaeus (senior) classify?</p>\n", "pids": ["53e9ba00b7602d97045feb42"], "flag": 1}
{"question": "Building ML to finding the closest matching image based on users drawing", "body": "<p>I am trying to build a ML Agent to find the closest matching image from a given set. The user will draw something and the agent should list the closest matching images. </p>\n\n<p>Very similar to these examples</p>\n\n<ol>\n<li><a href=\"https://sketchx.eecs.qmul.ac.uk/\" rel=\"nofollow noreferrer\">https://sketchx.eecs.qmul.ac.uk/</a></li>\n<li>Emoji search in Android keyboard</li>\n</ol>\n\n<p>One unique problem I've is, each image will represent a category. Imagine we have product images and user will draw something and we have to find the products close to the drawing. So category in my case will be product Id. </p>\n\n<p><a href=\"https://i.stack.imgur.com/hHwig.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/hHwig.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>I would like to evaluate the approach before trying out. </p>\n\n<p>There are lot of examples to classify images, however if I use the item identifier instead of category it should work. But am trying to find the best approach for this problem. </p>\n", "pids": ["599c795d601a182cd2634c8b"], "flag": 1}
{"question": "What&#39;s stopping Cepheus from generalizing to full poker games?", "body": "<p><a href=\"http://www.vocativ.com/culture/science/most-powerful-poker-computer-cepheus/\" rel=\"nofollow noreferrer\">Cepheus</a> is an artificial intelligence designed to play Texas Hold'em. By playing against itself and learning where it could have done better, it became very good at the game. <a href=\"http://slatestarcodex.com/2015/01/17/links-12014-link-for-you-know-not-whence-you-came-nor-why/\" rel=\"nofollow noreferrer\">Slate Star Codex</a> comments:</p>\n\n<blockquote>\n  <p>I was originally confused why they published this result instead of heading to online casinos and becoming rich enough to buy small countries, but it seems that it’s a very simplified version of the game with only two players. More interesting, the strategy was reinforcement learning – the computer started with minimal domain knowledge, then played poker against itself a zillion times until it learned everything it needed to know. </p>\n</blockquote>\n\n<p>Apparently Cepheus currently just plays against one person. Seeing as it managed to develop amazing strategy for this \"very simplified\" environment, what's stopping it from working on real/full poker games?</p>\n", "pids": ["58d82fcbd649053542fd5e4b"], "flag": 1}
{"question": "Applications and Limitations of EEG Electrode Pooling - Averaging across time series", "body": "<p>Is there any literature that has addressed electrode pooling? In particular, are there any standards concerning what pools (e.g. frontal, central, posterior vs. electrode pairs) could be used or any particular applications and limitations?</p>\n\n<p><em>EDIT</em>:\nBy \"pooling\" I am refering to the procedure in which new channels are created based on pooling the raw data from the original data electrodes. This is a preprocessing step not to be confused with variance pooling for statistical testing.</p>\n", "pids": ["53e9a863b7602d97031ae066"], "flag": 0}
{"question": "Quick responses/Time &amp; lintelligence", "body": "<p>Is the ability to answer a given question correctly quicker a measure of that individual being more intelligent than the person who answered correctly, but slower (This based on both individuals having no physical handicaps)?</p>\n", "pids": ["53e99f7fb7602d9702850d07", "53e9a2dcb7602d9702be4f1e"], "flag": 0}
{"question": "How can I design a hierarchy of agents each of which with different goals?", "body": "<p>I read some light material earlier about the possibility of building a hierarchy of agents, where the agents at the leaves solve primitive tasks while higher-level agents are optimized for orchestrating direct-descendant agents. </p>\n\n<p>According to my understanding, each agent would have different objective functions and possible moves. </p>\n\n<p>How can I design such a hierarchy of agents each of which with different goals? Are there any examples?</p>\n", "pids": ["5a9cb65d17c44a376ffb83f1"], "flag": 1}
{"question": "As a starter: what is the form of training data for image processing", "body": "<p>What we are doing in the image processing training.  We are storing some form of data which is going to act as the knowledge or experience of the system. </p>\n\n<ul>\n<li>In which form can the system store it's training data?</li>\n</ul>\n\n<p>For example, with the hand written recognition, we can represent the digits as combinations of curves and straight lines. For every round of training the recognition system stores data.  Is the data typically stored in a flat file (such as txt) or a database?</p>\n\n<p>I have seen in <a href=\"https://en.wikipedia.org/wiki/Tesseract_(software)\" rel=\"nofollow noreferrer\">Tesseract OCR</a> that there is a text file that stores the x0,y0,x1,y1. They are the pixel points that represents the square on the training image that has the picture.</p>\n\n<p>I need a efficient form of knowledge for Machine Learning, and would appreciate advice, context, or an explanation of the merits or downsides of different approaches. </p>\n\n<blockquote>\n  <p>I need a form of knowledge that stored in a system. human brain evaluate '7' as 'horizontal line and vertical left crossed line start from right of the horizontal line'. like that machine must have some conceptual data to represent their knowledge.</p>\n</blockquote>\n", "pids": ["58437722ac44360f1082f27c"], "flag": 1}
{"question": "If Evolution Is In Progress, Why Fight Extinction?", "body": "<p>Natural selection is a central tenet of evolution. However, most biologists seem determined to prevent the extinction of the species that have been selected against. Why is this? Preservation of genetic diversity? </p>\n\n<p>I thought evolution was supposed to create diversity not destroy it. What am I missing?</p>\n", "pids": ["55a5120865ceb7cb02dfff8b"], "flag": 1}
{"question": "Do adjacent axons in a nerve influence each other?", "body": "<p>Suppose I have a nerve fiber consisting of several axons all running in parallel to each other.  When an action potential is generated in a certain axon, this will alter the concentration of sodium and potassium ions inside the axon, and in the extracellular fluid around that axon.</p>\n\n<p>The question is, will this change in ion concentration in the extracellular fluid, alter the threshold potential of an adjacent axon, which shares the same extracellular fluid?</p>\n", "pids": ["598d16d30cf2198a9a93b7aa"], "flag": 1}
{"question": "How to implement an Automatic Learning Rate for a Neural Network?", "body": "<p>I'm learning Neural Networks, and everything works as planned but, like humans do, adjusting themselves to learn more efficiently, I'm trying to understand conceptually how one might implement an auto adjusting learning rate for a Neural Network.</p>\n\n<p>I have tried to make it based on error, something like how bigger is error learning rate is getting bigger as well. <sub><em>[Could use some clarification here--not entirely sure what you're saying.  If can clarify, I'm happy to clean up the English. -DukeZhou]</em></sub></p>\n\n<p>*If you want give me an example give it on a C based language or math because I don't have experience with Python or Pascal. </p>\n", "pids": ["5c86e71c4895d9cbc6ad21d3", "5c86e71c4895d9cbc6ad21d3"], "flag": 1}
{"question": "Is there a mathematical proof that shows that certain parameters work &quot;better&quot; than others for a certain task?", "body": "<p>The machine learning community often only provides empirical results, but I am also interested in theoretical results and proofs. Specifically, is there a <strong>mathematical proof</strong> that shows that certain parameters work \"better\" than others for a certain task?</p>\n", "pids": ["599c7951601a182cd262fae5", "5bdc31b817c44a1f58a0c141"], "flag": 1}
{"question": "What are merits of having a PhD degree?", "body": "<p>What are the benefits of having a PhD degree? Why are PhD programs so competitive? I mean, why do many people apply for PhD programs? </p>\n\n<p>In STEM fields, it is usually possible to get a better-paid job in industry with a bachelor's or master's degree. On the other hand, PhD programs are usually long, hard and low-paying — if there is any paying at all — and job prospects for PhD graduates are not that impressive too. So, what am I missing? Why do so many talented people try to get into PhD programs if they can get better jobs outside academia? Is it merely because of personal interest in research, teaching or learning? </p>\n\n<p>Although opinions are important, I sincerely appreciate it if facts and experiences are shared. I agree that this question can be opinion-based but one of the reasons why I am asking this is that choosing to do a PhD degree and possibly pursuing an academic career is a very important decision. Based on personal experience, I have seen many fresh graduates who face the same question (and also a few people that, first, made a decision then faced the question, only to realize that it is late) and I hope that, apart from satiating my personal curiosity, it will provide factual and helpful information for those who have not made their minds yet.</p>\n", "pids": ["55a4091b65ce5cd7b3c12ce5"], "flag": 1}
{"question": "Are Free Will and Motivation related?", "body": "<p>I'm aware of numerous experiments, like <a href=\"https://en.wikipedia.org/wiki/Stanford_prison_experiment\" rel=\"noreferrer\">Stanford prison experiment</a>, <a href=\"https://en.wikipedia.org/wiki/Milgram_experiment\" rel=\"noreferrer\">Milgram experiment</a> which indicate that humans can act in ways opposite to their best intentions. </p>\n\n<p>For the purposes of this question, let's define <a href=\"https://en.wikipedia.org/wiki/Free_will\" rel=\"noreferrer\">Free Will</a> as ability to act and strive without external coercion. Ability to accomplish my goals and ambitions. In this context Free Will suddenly seems a lot like motivation. </p>\n\n<p>Found these quotes:</p>\n\n<blockquote>\n  <p>Likewise, compatibilists define free will as freedom to act according\n  to one's determined motives without hindrance from other individuals</p>\n</blockquote>\n\n<p>This makes me ask - <strong>Is Free Will related or is just another word for a more modern concept of \"motivation\"?</strong></p>\n", "pids": ["53e9978ab7602d9701f46072"], "flag": 0}
{"question": "Are human behavior and brain dynamics well described as an optimization?", "body": "<p>A very general approach to describe the dynamics of the brain is through differential equations. Instead, one could choose a more restrictive approach and describe it as an optimization. Can we assume that observed human behavior can be explained well as an optimization of an unknown cost function? What is the scientific evidence for and against this?</p>\n", "pids": ["5ff68425d4150a363cbced59"], "flag": 0}
{"question": "Do convolutional neural networks also have recurrent connections?", "body": "<p>I asked my self this simple question while reading <a href=\"https://web.stanford.edu/class/cs224n/reports/2762092.pdf\" rel=\"nofollow noreferrer\">\"Comment Abuse Classification with Deep Learning\"</a> by Chu and Jue. Indeed, they say at the end of the that </p>\n\n<blockquote>\n  <p><em>It is clear that RNNs, specifically LSTMs, and CNNs are state-of-the-art  architectures for sentiment analysis</em></p>\n</blockquote>\n\n<p>To my mind CNNs were only neurons arranged so that they correspond to overlapping regions when paving the input field. It wasn't that recurrent at all.</p>\n", "pids": ["58d82fd2d649053542fd76f0"], "flag": 1}
{"question": "What machine learning algorithm should be used to analyze the relationship between strings?", "body": "<p>I am trying to build a neural network that takes in a single string, ex: \"dog\" as an input, and outputs 50 or so related hashtags such as, \"#pug, #dogsarelife, #realbff\".</p>\n\n<p>I have thought of using a classifier, but because there is going to be millions of hashtags to choose the optimal one from, and millions of possible words from the english dictionary, it is virtually impossible to search up the probability of each </p>\n\n<p>It is going to be learning information from analyzing twitter posts' text, and its hashtags, and find which hashtags goes with what specific words.</p>\n", "pids": ["5d25bcd73a55ac8369529045", "610bc3af5244ab9dcba57815"], "flag": 1}
{"question": "How good is AI in math?", "body": "<p>Currently, AI is advancing fast in deep learning: <a href=\"http://www.telegraph.co.uk/science/2017/12/06/entire-human-chess-knowledge-learned-surpassed-deepminds-alphazero/\" rel=\"nofollow noreferrer\">Entire human chess knowledge learned and surpassed by DeepMind's AlphaZero in four hours</a>.</p>\n<p>As a layman, I'm taking this as a quite powerful searching algorithm, using artificial neural networks to identify the patterns of each game.</p>\n<p>However, how good is AI doing in math?</p>\n<p>For example, the key to the theory of the game <a href=\"https://en.wikipedia.org/wiki/Nim\" rel=\"nofollow noreferrer\">Nim</a> is the binary digital sum of the heap sizes, that is, the sum (in binary) neglecting all carries from one digit to another. This operation is also known as <a href=\"https://en.wikipedia.org/wiki/Exclusive_or\" rel=\"nofollow noreferrer\">&quot;exclusive or&quot; (xor)</a> or &quot;vector addition over GF(2)&quot;.</p>\n<p>Is AI good enough to discover/invite operations/logics such as &quot;exclusive or&quot;, or, more advanced, abstract algebra in <a href=\"https://en.wikipedia.org/wiki/Finite_field\" rel=\"nofollow noreferrer\">finite field</a>?</p>\n", "pids": ["599c7f08601a182cd28e5378"], "flag": 1}
{"question": "What are the correlations between the facets of honesty-humility in HEXACO personality and the Dark Triad?", "body": "<p>I was just reading some of the items in the HEXACO measure of personality. It seems to me that the \"honesty-humility\" factor is actually more naturally expressed in the opposite way. I.e., about three quarters of the items are reverse scored.</p>\n\n<p>For example, items measuring fairness (i.e., reverse coded) tend to focus on a willingness to engage in corrupt or even criminal behavior to advance your self-interest. Items measuring greed avoidance seem to be focused on concern with social status grounded in superficial things. Modesty items seems more like a measure of narcissism (i.e., believing you are better than others in some essential and vague way). Sincerity seems to have items concerned with a willingness to engage in social manipulation through flattery and guilt.</p>\n\n<p>This got me interested in the correlation between honest-humility and the dark triad: machiavellianism, narcissism, and psychopathy.</p>\n\n<p><strong>What are the best estimates of the correlation between HEXACO honesty-humility (and facets) with the Dark Triad?</strong></p>\n", "pids": ["5c756d20f56def97984f9e04"], "flag": 1}
{"question": "What is the difference between attractor and recurrent network?", "body": "<p>How are attractor and recurrent networks related? Is attractor network is <a href=\"https://en.wikipedia.org/wiki/Limiting_case_(mathematics)\" rel=\"nofollow noreferrer\">private case</a> of recurrent? Is there a mathematical formalism that defines both rigorously as <a href=\"https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)\" rel=\"nofollow noreferrer\">graphs</a>? </p>\n", "pids": ["5c0f7343da562944ac685c65", "53e9a0c9b7602d97029b0244"], "flag": 1}
{"question": "What is the best approach for writing a program to identify objects in a picture then crop them a specific way?", "body": "<p>My works quality control department is responsible for taking pictures of our products at various phases through our QC process and currently the process goes:</p>\n\n<ol>\n<li>Take picture of product</li>\n<li>Crop the picture down to only the product</li>\n<li>Name the cropped picture to whatever the part is and some other relevant data</li>\n</ol>\n\n<p>Depending on the type of product the pictures will be cropped a certain way. So my initial thought would be to use a reference to <a href=\"https://cloud.google.com/vision/\" rel=\"nofollow noreferrer\">an object identifier</a> and then once the object is identified it will use a cropping method specific to that product. There will also be QR codes within the pictures being taken for naming via OCR in the future so I can probably identify the parts that way if this proves slow or problematic.</p>\n\n<p>The part I am unsure about is how to get the program to know how to crop based on a part. For example I would like to present the program with a couple before crop and after crop photos of product X then make a specific cropping formula for product X based on those two inputs. </p>\n\n<p>Also if it makes any difference my code is in C# </p>\n", "pids": ["5de0c913df1a9c0c415a9e30", "5ecbc84b9fced0a24b5167cf"], "flag": 1}
{"question": "Did the Facebook robots both want everything but the balls?", "body": "<p>According to <a href=\"http://www.independent.co.uk/life-style/gadgets-and-tech/news/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html\" rel=\"nofollow noreferrer\">this article</a>, two Facebook ai's had the following &quot;creepy&quot; negotiation over a transaction:</p>\n<blockquote>\n<p>Bob: i can i i everything else . . . . . . . . . . . . . .</p>\n<p>Alice: balls have zero to me to me to me to me to me to me to me to me to</p>\n<p>Bob: you i everything else . . . . . . . . . . . . . .</p>\n<p>Alice: balls have a ball to me to me to me to me to me to me to me</p>\n<p>Bob: i i can i i i everything else . . . . . . . . . . . . . .</p>\n<p>Alice: balls have a ball to me to me to me to me to me to me to me</p>\n<p>Bob: i . . . . . . . . . . . . . . . . . . .</p>\n<p>Alice: balls have zero to me to me to me to me to me to me to me to me to</p>\n<p>Bob: you i i i i i everything else . . . . . . . . . . . . . .</p>\n<p>Alice: balls have 0 to me to me to me to me to me to me to me to me to</p>\n<p>Bob: you i i i everything else . . . . . . . . . . . . . .</p>\n<p>Alice: balls have zero to me to me to me to me to me to me to me to me to</p>\n</blockquote>\n<p>If we first look at Bob's, he's asking for what he wants by proposing that he have all items but one and not revealing which is the one he doesn't want.  By design or by chance, this is actually a strong negotiating technique because he reveals nothing other than the fact he is willing to come to an agreement.</p>\n<p>Alice appears to either ask for no balls, or to say they have no value to her and then obsess about things coming to her, perhaps iterating on the other items.  She would appear to be the better communicator because she at least gets to the point of saying &quot;have a ball&quot;.  But she refuses to give anything away beyond that.</p>\n<p>But Bob seems to stand firm saying he wants &quot;everything else&quot; but not giving away what he is willing to go without.</p>\n<p>Perhaps these two are not such bad negotiators after all?</p>\n", "pids": ["5a260c2817c44a4ba8a237c1"], "flag": 1}
{"question": "Examples of references for mathematical approaches in bioinformatics that are applicable to linguistics?", "body": "<p>Do you have any classic references for mathematical approaches in bioinformatics that are applicable to linguistics (or vice versa)?</p>\n\n<p><strong>EDIT</strong><br> \nI am mainly interested in approaches to reconstruct the history of languages, the rate of language mutation, phylogenies of languages, etc.</p>\n", "pids": ["558dcec415f38090e2f40154", "55a4d446c91bf3b1cc47c93d"], "flag": 1}
{"question": "Which other loss functions for hierarchical multi-label classification could I use?", "body": "<p>I am looking to try different loss functions for a hierarchical multi-label classification problem. So far, I have been training different models or submodels like multilayer perceptron (MLP) branch inside a bigger model which deals with different levels of classification, yielding a binary vector. I have been also using Binary Cross-Entropy (BCE) and summing all the losses existing in the model before backpropagating.</p>\n<p>I am considering trying other losses like MultiLabelSoftMarginLoss and MultiLabelMarginLoss.</p>\n<p>What other loss functions are worth trying? Hamming loss perhaps or a variation? Is it better to sum all the losses and backpropagate or do multiple backpropagations?</p>\n", "pids": ["5dfded9cdf1a9c0c4165817d"], "flag": 1}
{"question": "Is time/space estimation of possible actions required for creating an AGI?", "body": "<p>Given infinite resources/time, one could create AGIs by writing code to simulate infinite worlds. By doing that, in some of the worlds, AGIs would be created. Detecting them would be another issue.</p>\n<p>Since we don't have infinite resources, the most probable way to create an AGI is to write some bootstrapping code that would reduce the resources/time to reasonable values.</p>\n<p><em>In that AGI code (that would make it reasonable to create with finite resources/time) is it required to have a part that deals with time/space estimation of possible actions taken? Or should that be outside of the code and be something the AGI discovers by itself after it starts running?</em></p>\n<p>Any example of <a href=\"https://github.com/fairy-tale-agi-solutions/awesome-artificial-general-intelligence#organizations--projects\" rel=\"nofollow noreferrer\">projects targeting AGI</a> that are using time/space estimation might be useful for reaching a conclusion.</p>\n<p>Clarification, by time/space I mean time/space complexity analysis for algorithms, see: <a href=\"https://en.wikipedia.org/wiki/Algorithmic_efficiency#Measures_of_resource_usage\" rel=\"nofollow noreferrer\">Measures of resource usage</a> and <a href=\"https://en.wikipedia.org/wiki/Analysis_of_algorithms\" rel=\"nofollow noreferrer\">Analysis of algorithms</a></p>\n<p>I think the way I formulated the question might lead people to think that the time/space estimation can only apply to some class of actions called algorithms. To clarify my mistake, I mean the estimation to apply to any action plan.</p>\n<p>Imagine you are an AGI and you have to make a choice between different set of actions to pursue your goals. If you had 2 goals and one of them used less space and less time then you would always pick it over the other algorithm. So time/space estimation is very useful since intelligence is about efficiency. There is at least 1 exception though, imagine in the example before that the goal of the AGI is to pick the set of actions that leads to the most expensive time/space set of actions (or any non-minimal time/space cost) then obviously because of the goal constraint you would pick the most time/space expensive set of actions. In most other cases though, you would just pick the most time/space efficient algorithm.</p>\n", "pids": ["53e9a8dbb7602d9703229bea"], "flag": 1}
{"question": "How do we design a neural network such that the $L_1$ norm of the outputs is less than or equal to 1?", "body": "<p>What are some ways to design a neural network with the restriction that the <span class=\"math-container\">$L_1$</span> norm of the output values must be less than or equal to 1? In particular, how would I go about performing back-propagation for this net?</p>\n<p>I was thinking there must be some &quot;penalty&quot; method just like how in the mathematical optimization problem, you can introduce a log barrier function as the &quot;penalty function&quot;</p>\n", "pids": ["625e1a3d5aee126c0fecadfd"], "flag": 1}
{"question": "Do Research Papers have Public Domain Expiration Date?", "body": "<p>Do research papers have a Public Domain Expiration Date? simmilar of what happens to literature books</p>\n<p>For example, let's consider a research paper of James C. Maxwell: <em><strong>XVIII.—Experiments on Colour, as perceived by the Eye, with Remarks on Colour-Blindness</strong></em>, it is stored in here: <a href=\"https://www.cambridge.org/core/journals/earth-and-environmental-science-transactions-of-royal-society-of-edinburgh/article/abs/xviiiexperiments-on-colour-as-perceived-by-the-eye-with-remarks-on-colourblindness/5E589C9929D114B96CB9325E8FF0CAB3\" rel=\"noreferrer\">link to www.cambridge.org website</a></p>\n<p>It says: &quot;Copyright © Royal Society of Edinburgh 1857&quot; and if I want to purchase the article, it would cost me: USD35</p>\n<p>This is an article published more than 150 years ago. How long do I have to wait in order to download it and use it for free?</p>\n", "pids": ["56d8d36adabfae2eeeb73886"], "flag": 1}
{"question": "How do randomly initialized neural networks behave?", "body": "<p>I am wondering how the output of randomly initialized MLPs and ConvNets behave with respect to their inputs.  Can anyone point to some analysis or explanation of this?</p>\n\n<p>I am curious about this because in the <a href=\"https://blog.openai.com/reinforcement-learning-with-prediction-based-rewards/\" rel=\"nofollow noreferrer\">Random Network Distillation work from OpenAI</a>, they use the output of randomly initialized network to generate intrinsic reward for exploration.  It seems that this assumes that similar states will produce similar outputs of the random network.  Is this generally the case?  </p>\n\n<p>Do small changes in input yield small changes in output, or is it more <a href=\"https://en.wikipedia.org/wiki/Chaos_theory\" rel=\"nofollow noreferrer\">chaotic</a>?  Do they have other interesting properties?</p>\n", "pids": ["5b8c9f5317c44af36f8b74b4", "5550418245ce0a409eb3beb1"], "flag": 1}
{"question": "On what basis do professionals who recognize gender dysphoria support risky and permanent medical intervention for those seeking gender re-assignment?", "body": "<p>Before I pose my question, here are some statements from a slideshow on <a href=\"https://www.aap.org/en-us/Documents/solgbt_webinar_transition_garofalo.pdf\" rel=\"nofollow noreferrer\">&quot;Understanding Gender Nonconformity in Childhood and Adolescence&quot; by Robert Garofalo</a>, attributed to the Children's Hospital of Chicago, and hosted by the American Academy of Pediatrics (AAP). They officially support affirming gender change in children, however there is a group of pediatricians who actively reject that position.</p>\n<p>According to this slideshow, gender is a social construct (<a href=\"https://www.aap.org/en-us/Documents/solgbt_webinar_transition_garofalo.pdf\" rel=\"nofollow noreferrer\">page 7</a>), which <em>&quot;[v]aries by place, time period&quot;</em> .</p>\n<p>Next I'd like to list the slideshow's listed side effects and irreversible effects of hormone therapy. Pages 39-41 show the side effects of testosterone therapy.</p>\n<blockquote>\n<p><strong>Irreversible Effect of Testosterone Therapy</strong></p>\n<ul>\n<li>Lower voice pitch</li>\n<li>Increased hair growth (arms, legs, chest, ab)</li>\n<li>Mustache/beard growth</li>\n<li>Male pattern hair loss (temples, crown) and possibly baldness<br />\nGenital Changes</li>\n<li>Genital changes (clitoral\ngrowth and vaginal\ndryness/fragility)</li>\n<li>Fertility?</li>\n</ul>\n<p><strong>Side Effects/Risks: Testosterone</strong></p>\n<ul>\n<li>Increased cardiovascular risk\n<ul>\n<li>Increased weight</li>\n<li>Decreased HDL, Increased Triglycerides</li>\n<li>Increased BP</li>\n</ul>\n</li>\n<li>Increased insulin resistance</li>\n<li>Hepatotoxicity</li>\n<li>Mood changes: irritability, aggression</li>\n<li>Headaches</li>\n<li>Acne</li>\n<li>Polycythemia</li>\n<li>Theoretical risk: breast/endometrial cancer</li>\n</ul>\n</blockquote>\n<p>Given these side effects, on what medical basis do health professional support this?</p>\n<p>If a person doesn't like themselves they get help with their self-value.  They learn the valuable things about their unique identity and also identify why they began to devalue themselves and deal with those root issues. People with phobia's are taught to manage and improve their phobia, not embrace it.</p>\n<p>My point is not to compare one disorder to another, but to show that regardless of the type of disorder that the standard treatment is not acceptance, but rather to reveal deeper issues and otherwise manage and overcome the disorder.</p>\n<p>Gender Dysphoria is treated categorically different, but there has been no new category defined on which to base that decision.</p>\n<p>I know this is a sensitive topic and has many personal stories, but I'd like to focus on the professional medical position and reasoning for that position.</p>\n", "pids": ["55a498e765ceb7cb02d3252f", "5e8ec1109fced0a24b6c698f", "5c0f8ab8da562944ac9bc5e1", "55a4d74d65ceb7cb02d9b96a", "53e9be43b7602d9704b018f3", "55a37fc565ce5cd7b3acceb9", "55a6b8d865ce054aad72b5a1", "5ce2ac68ced107d4c6b7bd3b", "56d8f602dabfae2eee93a32c", "53e99e45b7602d970270952d", "53e9baf6b7602d970472d10c", "53e9be22b7602d9704adf0a2", "55a3ec7ac91b587b0966e1b6", "53e99cbcb7602d970256f819"], "flag": 0}
{"question": "What happens to rejected papers?", "body": "<p>I am a Masters student in math and thus new to academia and publishing in general. I am a coauthor on a number of recently submitted papers and had the (somewhat intrusive) thought, what happens to papers that get rejected? Of course, the simple answer is that they get corrected/improved based on referee reports and resubmitted somewhere else, but are there cases where papers simply never get published or stay in limbo forever? In these cases, what happens to the results/theorems/proofs they contain? (My question was also partially motivated by the fact that in one of our papers we cited a preprint from the 90s, which has been cited dozens of times but does not seem to have ever been published in a peer-reviewed journal.)</p>\n<p>On the one hand, publishing in peer-reviewed journals is pretty difficult, and I'm sure papers are more often rejected than accepted. So there are bound to be papers that never end up making the cut. But on the other hand, looking at various researchers' academic websites, all of the papers in the &quot;submitted&quot; category seem to be pretty recent, suggesting that all of their submitted papers from before, say, three to four years ago ended up published. Or perhaps it is common to &quot;silently&quot; remove an in-limbo preprint from one's CV after a certain period of time?</p>\n<p>I guess all of this is a long-winded way of asking: &quot;What proportion of papers are <em>eventually</em> accepted?&quot; Like I said, I'm in math, but answers regarding other fields would be interesting as well!</p>\n", "pids": ["53e99f8cb7602d970286093c"], "flag": 1}
{"question": "How can I ensure convergence of DDQN, if the true Q-values for different actions in the same state are very close?", "body": "<p>I am applying a Double DQN algorithm to a highly stochastic environment where <strong>some of the actions in the agent's action space have very similar &quot;true&quot; Q-values</strong> (i.e. the expected future reward from either of these actions in the current state is very close). The &quot;true&quot; Q-values I know from an analytical solution to the problem.</p>\n<p>I have full control over the MDP, including the reward function, which in my case is sparse (0 until the terminal episode). The rewards are the same for <em>identical</em> transitions. However, the rewards vary for any given state and action taken therein. Moreover, the environment is only stochastic for a part of the actions in the action space, i.e. the action chosen by the agent influences the stochasticity of the rewards.</p>\n<p><strong>How can I still ensure that the algorithm gets these values (and their relative ranking) right?</strong></p>\n<p>Currently, what happens is that the loss function on the Q-estimator decreases rapidly in the beginning, but then starts evening out. The Q-values also first converge quickly, but then start fluctuating around.</p>\n<p>I've tried increasing the batch size, which I feel has helped a bit. What did not really help, however, was decreasing the learning rate parameter in the loss function optimizer.</p>\n<p>Which other steps might be helpful in this situation?</p>\n<p>So, the algorithm usually does find only a slightly suboptimal solution to the MDP.</p>\n", "pids": ["5b67b47917c44aac1c86377d", "599c7b58601a182cd272b540"], "flag": 1}
{"question": "How are IQ test scores affected by psychological stress or trauma?", "body": "<p>Does <a href=\"https://en.wikipedia.org/wiki/Psychological_stress\" rel=\"nofollow noreferrer\">mental stress</a> or <a href=\"https://en.wikipedia.org/wiki/Psychological_trauma\" rel=\"nofollow noreferrer\">trauma</a> have a significant impact on IQ test performance relative to baseline, and if so, how much?</p>\n<p>For example, if a person is affected by abuse, bullying, neglect, or some other stressor or trauma, then how much of an effect would that have on their test score?</p>\n", "pids": ["53e9a53fb7602d9702e621c3", "53e9aa5cb7602d97033caf02", "55a3c91dc91b587b09625598", "55a643a765ce054aad621609", "53e9b42fb7602d9703f28380", "55a4d5e065ceb7cb02d98a84", "56d822c1dabfae2eeec76625", "56d83a27dabfae2eee5a4bed", "56d82904dabfae2eeeefd21f", "53e9a818b7602d970315a8b9", "56d8df48dabfae2eee079329", "53e9bd55b7602d97049ea2dd", "55a52b72612c6b12ab05c6e0"], "flag": 1}
{"question": "Is it possible to combine two neural networks trained on different tasks into one that knows both tasks?", "body": "<p>I'm relatively new to artificial intelligence and neural networks.</p>\n<p>Let's say I have two different fully trained neural networks. The first one is trained for mathematical addition and the second one on mathematical multiplication. Now, I want to combine these two neural networks into one that knows about both operations.</p>\n<p>Is this possible? Is there a representative name for this kind of technique?</p>\n<p>I had read something about bilinear CNN models that sounds similar to what I'm looking for, right?</p>\n", "pids": ["5c756fb4f56def9798681e50"], "flag": 1}
{"question": "Best day of the week to hold an exam?", "body": "<p>I'm a course instructor and was finalizing my syllabus when I hit a bit of a wall and would love to hear the community's input. If you're teaching a class that meets twice per week, do you prefer to hold the exam on the earlier meeting time, or the later one? (E.g. if you have a Tuesday/Thursday class, and everything else is held equal, would you lean towards holding it on the Tuesday meeting or the Thursday one?) I can see slight advantages for either, but am very unsure what others' thoughts are. If you're a student (or recently graduated), did/do you have a preference? Does it depend at all on the nature of the exam (short answer vs. essay vs. multiple choice, etc.)?</p>\n<p>(Assume, for the sake of this question, that the material, difficulty, class time devoted to preparation, etc. are otherwise identical. If it matters, this is for a social science elective class, where the overwhelming majority of students are juniors/seniors.)</p>\n<p>Thanks!</p>\n", "pids": ["56d82578dabfae2eeed9b150"], "flag": 1}
{"question": "What should I do if I have some evidence pointing out that the results presented in a conference paper might be fake?", "body": "<p>During the reading of a paper, published in the proceeding of a prestigious computer science conference, I noticed a logical error in the results presented in the paper.</p>\n<p>I contacted two of the authors who are my colleagues (one is a PhD student in the same lab where I am a student) to ask for clarification. After hearing what they had to say, I was under the impression that they mainly tried to convince me that the results were OK. One argument they used was that because the paper was already published in a prestigious conference and passed the peer review, the results couldn't have been wrong. That didn't satisfy me; rather, their answers made me suspicious that at least parts of the results, presented in the paper, are fake (I mean, are not real). Moreover, that the authors tried to hide the problem with the results. Finally, I believe I have strong evidence to support my belief, which, at the moment, is that the results are fake.</p>\n<p>What is the normal course of action in a case like this? If someone has some evidence indicating that a paper published in proceedings of a (computer science) conference includes fake results, what should that person do?</p>\n<p>Additional information:</p>\n<p>It's been more than two years since the paper was published.</p>\n<p>The evidence that the paper is &quot;fake&quot; rather than merely wrong is that the method claimed would not be computationally tractable for the claimed data size without some special innovation that was not described by the authors.</p>\n", "pids": ["56d9058ddabfae2eeef40394"], "flag": 1}
{"question": "What is an adversarial attack?", "body": "<p>I'm reading this really interesting article <a href=\"https://arxiv.org/pdf/1712.02950.pdf\" rel=\"nofollow noreferrer\">CycleGAN, a Master of Steganography</a>. I understand everything up until this paragraph:</p>\n<blockquote>\n<p>we may view the CycleGAN training procedure as continually mounting an <strong>adversarial attack</strong> on <span class=\"math-container\">$G$</span>, by optimizing a generator <span class=\"math-container\">$F$</span> to generate adversarial maps that force <span class=\"math-container\">$G$</span> to produce a desired image. Since we have demonstrated that it is possible to generate these adversarial maps using gradient descent, it is nearly certain that the training procedure is also causing <span class=\"math-container\">$F$</span> to generate these adversarial maps. As <span class=\"math-container\">$G$</span> is also being optimized, however, <span class=\"math-container\">$G$</span> may actually be seen as cooperating in this attack by learning to become increasingly susceptible to attacks. We observe that the magnitude of the difference <span class=\"math-container\">$y^{*}-y_{0}$</span> necessary to generate a convincing adversarial example by Equation 3 decreases as the CycleGAN model trains, indicating cooperation of <span class=\"math-container\">$G$</span> to support adversarial maps.</p>\n</blockquote>\n<p>How is the CycleGAN training procedure an adversarial attack?</p>\n<p>I don't really understand the quoted explanation.</p>\n", "pids": ["53e9a93eb7602d97032928b5", "53e9a93eb7602d97032928b5"], "flag": 1}
{"question": "How do you call the cognitive bias of not seeing self as the common denominator?", "body": "<p>Imagine an Italian person is living in London. A poll on the street asks them to estimate the total number of Italians in London. This person then gives a highly incorrect, overblown guess. It's simply common for people of a single nationality to notice each other in the crowd or go to the same places, so it's somewhat likely that one would have an inflated estimate in their heads.</p>\n\n<p>Another example would be a \"reverse <a href=\"https://en.wikipedia.org/wiki/Physical_attractiveness_stereotype\" rel=\"nofollow\">physical attractiveness stereotype</a>\": a person holding the belief that \"all people are friendly\". However in reality this could be explained by the fact that the person holding the belief is highly attractive.</p>\n\n<p>How do you call this bias? <a href=\"https://en.wikipedia.org/wiki/Selection_bias\" rel=\"nofollow\">Selection bias</a> seems close, but is there something more specific?</p>\n", "pids": ["56d81d40dabfae2eeea30d61", "55a5d8b5612c6b12ab2f395c"], "flag": 0}
{"question": "Each training run for DDQN agent takes 2 days, and still ends up with -13 avg score, but OpenAi baseline DQN needs only an hour to converge to +18?", "body": "<p><strong><em>Status</em></strong>:</p>\n\n<p>For a few weeks now, I have been working on a Double DQN agent for the <code>PongDeterministic-v4</code> environment, which you can find <a href=\"https://github.com/hridayns/Reinforcement-Learning/tree/master/Atari\" rel=\"nofollow noreferrer\">here</a>.</p>\n\n<p>A single training run lasts for about 7-8 million timesteps (about 7000 episodes) and takes me about 2 days, on Google Collab (K80 Tesla GPU and 13 GB RAM). At first, I thought this was normal because I saw a lot of posts talking about how DQNs take a long time to train for Atari games.</p>\n\n<p><strong><em>Revelation</em></strong>:</p>\n\n<p>But then after cloning the OpenAI baselines <a href=\"https://github.com/openai/baselines\" rel=\"nofollow noreferrer\">repo</a>, I tried running <code>python -m baselines.run --alg=deepq --env=PongNoFrameskip-v4</code>  and this took about 500 episodes and an hour or 2 to converge to a nice score of +18, without breaking a sweat. Now I'm convinced that I'm doing something terribly wrong but I don't know what exactly.</p>\n\n<p><strong><em>Investigation</em></strong>:</p>\n\n<p>After going through the DQN baseline <a href=\"https://github.com/openai/baselines/tree/master/baselines/deepq\" rel=\"nofollow noreferrer\">code</a> by OpenAI, I was able to note a few differences:</p>\n\n<ul>\n<li>I use the <code>PongDeterministic-v4</code> environment but they use the <code>PongNoFrameskip-v4</code> environment </li>\n<li>I thought a larger <strong>replay buffer size</strong> was important, so I struggled (with the memory optimization) to ensure it was set to <strong>70000</strong> but they set it to a mere <strong>10000</strong>, and still got amazing results.</li>\n<li>I am using a normal <strong>Double DQN</strong>, but they seem to be using a <strong>Dueling Double DQN</strong>.</li>\n</ul>\n\n<p><strong><em>Results/Conclusion</em></strong></p>\n\n<p>I have my doubts about such a huge increase in performance with just these few changes. So I know there is probably something wrong with my existing implementation. Can someone <strong>point me in the right direction</strong>?</p>\n\n<p>Any sort of help will be appreciated. Thanks!</p>\n", "pids": ["5736960a6e3b12023e51d96d"], "flag": 1}
{"question": "Short term effects of alcohol on IQ", "body": "<p>I am looking for some references on the short term effects of alcohol on \"IQ\". I am particularly interested in what aspects of \"intelligence\" is affected (e.g., cognition/reasoning/memory). Essentially, I am looking for studies that compare performance while sober and drunk in moderate drinkers.</p>\n", "pids": ["55a42de62401c6de3b86869f", "55a372ec612ca648686d29ca"], "flag": 1}
{"question": "Could error surface shape be useful to detect which local minima is better for generalization?", "body": "<p>The following plot shows error function output based on system weights.\nTwo equal local minima are shown in green pointers. Note that the red dots are not related to the question.</p>\n\n<p>Does the right one generalize better compared to the left one? </p>\n\n<p>My assumption is that for the right minimum if the weights change, the overall error increases less compared to the left minimum point. Would this somehow mean the system does better generalization if the right one is chosen as the optimum minimum?</p>\n\n<p><a href=\"https://i.stack.imgur.com/pDEFF.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/pDEFF.png\" alt=\"enter image description here\"></a></p>\n", "pids": ["599c796a601a182cd263aace"], "flag": 1}
{"question": "Is there a conventional use of the term &quot;empirical grounding&quot;?", "body": "<h2>Background</h2>\n\n<p>The notion of grounding theory in empirical data, originates from the work by Glaser &amp; Strauss (1967). At present, while reputable scholars, for instance Eisenhardt and Graebner (2007), make use of the term \"<strong>empirical grounding</strong>\", it doesn't seem to be used quite frequently in (English-language) psychological literature. For instance, today, the database \"<a href=\"https://en.wikipedia.org/wiki/PsycINFO\" rel=\"nofollow noreferrer\">PsycINFO</a>\" returns not more than 66 journal articles where the mentioned term is used. </p>\n\n<h2>Question</h2>\n\n<p>Does the term \"<strong>empirical grounding</strong>\" designate a distinct methodological procedure (or result) that exists independently from the grounded theory methodology? </p>\n\n<h2>References</h2>\n\n<p>Eisenhardt, K. M., &amp; Graebner, M. E. (2007). Theory Building from Cases: Opportunities and Challenges. <em>Academy of Management Journal</em>, 50(1), 25–32. <a href=\"https://doi.org/10.5465/AMJ.2007.24160888\" rel=\"nofollow noreferrer\">https://doi.org/10.5465/AMJ.2007.24160888</a>  </p>\n\n<p>Glaser, B. G., &amp; Strauss, A. L. (1967). The discovery of grounded theory: strategies for qualitative research (4. paperback printing). New Brunswick: Aldine.</p>\n", "pids": ["53e9b409b7602d9703efdd94"], "flag": 1}
{"question": "Why does the BERT encoder have an intermediate layer between the attention and neural network layers with a bigger output?", "body": "<p>I am reading the BERT paper <a href=\"https://arxiv.org/pdf/1810.04805.pdf\" rel=\"nofollow noreferrer\">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>.</p>\n\n<p>As I look at the attention mechanism, I don't understand why in the BERT encoder we have an intermediate layer between the attention and neural network layers with a bigger output (<span class=\"math-container\">$4*H$</span>, where <span class=\"math-container\">$H$</span> is the hidden size).\nPerhaps it is the layer normalization, but, by looking at the code, I'm not certain. </p>\n", "pids": ["5fe316fb91e01125d4b5b6d9"], "flag": 1}
{"question": "Does risk of developing depression continue to increase after age 60?", "body": "<p>Age is a risk factor for depression when we look at the entire lifespan. Does that hold true in a population of >60 years old?</p>\n", "pids": ["53e9b07db7602d9703ae5727"], "flag": 1}
{"question": "Why do some papers not have a DOI?", "body": "<p>When I cite papers online, especially in Wikipedia pages, it is very convenient to use their DOI. However, some papers which I would like to cite (like <a href=\"http://dash.harvard.edu/handle/1/4892932\" rel=\"noreferrer\">this</a> and <a href=\"http://www.combinatorics.org/ojs/index.php/eljc/article/view/v15i1r11\" rel=\"noreferrer\">that</a>) have no DOI. Or at least, I haven't been able to find their DOI in the <a href=\"http://www.crossref.org/guestquery\" rel=\"noreferrer\">crossref search form</a>.</p>\n\n<p>Why isn't a DOI assigned to all papers? Is there something I can do to change this?</p>\n\n<p>EDIT: I now found out that in ResearchGate, I can upload my paper and it automatically receives a DOI. So practically, my problem is solved.</p>\n", "pids": ["5f8a083edb0c4ff231649144", "5f8a083edb0c4ff231649144", "6216ca1f5aee126c0f378501"], "flag": 1}
{"question": "Reference on abuse of stimulant medications among professors to enhance academic performance?", "body": "<p>Various research articles<sup>1</sup> have been published on the prevalence of stimulant medicine (Adderall, Concerta, Ritalin) abuse among undergraduate students. </p>\n\n<p>By \"abuse of stimulant medicine,\" I am referring to the practice of students taking prescription medication that is prescribed to someone else (or, that is prescribed to them under false pretenses) in order to improve their focus and concentration while studying.</p>\n\n<p>There is some <a href=\"http://www.cbsnews.com/news/popping-pills-a-popular-way-to-boost-brain-power/\">anecdotal evidence</a> of university faculty taking Adderall and related medications to enhance academic performance (and <em>not</em> to treat an attention disorder).</p>\n\n<p>Is there any reference to research<sup>2</sup> on the prevalance of stimulant medicine abuse among university faculty?</p>\n\n\n\n<p><sup>1</sup> Here is a review article that covers some of them:</p>\n\n<blockquote>\n  <p>Varga, Matthew D. \"Adderall abuse on college campuses: a comprehensive literature review.\" <em>Journal of evidence-based social work</em> 9.3 (2012): 293-313.\n  DOI: <a href=\"http://www.tandfonline.com/doi/abs/10.1080/15433714.2010.525402\">10.1080/15433714.2010.525402</a></p>\n</blockquote>\n\n<p><sup>2</sup> I am looking for answers that are a reference to such a study. I am not looking for answers from anecdotal evidence not supported by a study or citation. I am also not looking for answers explaining why such a study is unlikely to exist, or why it should not be trusted if it did.</p>\n", "pids": ["53e99bc6b7602d970246f215"], "flag": 1}
{"question": "Relation of confidence and problem solving ability", "body": "<p>My personal experiences have shown me multiple times that by only boosting my confidence in my ability to solve a problem,  without gaining any additional knowledge, I was able to solve it!</p>\n\n<p>My question is, has this been studied that to what extent our confidence in our abilities can help us to find a solution for a problem?</p>\n\n<p>If so, can you please provide a link?</p>\n", "pids": ["55a6628965ce054aad65d92d"], "flag": 1}
{"question": "Do ALL decisions arouse cognitive dissonance?", "body": "<p>I continue to see an oversimplification in the descriptions of the options available that arouse cognitive dissonance: some websites state that all decisions have positive and negative aspects that will lead to dissonance and some say that dissonance is aroused only when a decision is made between two equally desirable options.</p>\n\n<p>In other words, do ALL decisions arouse cognitive dissonance? Or just the decisions made between options that are equally or near-equally desirable? </p>\n\n<p>For example, if I were to choose between an Ivy league college or a SUNY school, I don't think I would very much regret going to the Ivy league school and not the other (or would I be reducing dissonance by telling myself that?). However, the website explaining cognitive dissonance simply labels these options as \"colleges\".</p>\n\n<p>Also what if the decision making was something trivial (in my perceptions)? Do whimsical decisions arouse dissonance as well? </p>\n\n<p>For example, if I had a very large sum of money and I was selecting between two equally desirable cars, and I could very easily afford both, would I still experience much dissonance? </p>\n", "pids": ["53e9b7d4b7602d970438558d", "55a3bcea65ce5cd7b3b55089", "56d8f468dabfae2eee89c48d", "56d9001ddabfae2eeed203c0", "55a51e3865ceb7cb02e177b2"], "flag": 1}
{"question": "Can we stop looking at recommendation letters and rely purely on &quot;objective&quot; measurements during the admission process?", "body": "<p>My question has different emphases from <a href=\"https://academia.stackexchange.com/questions/12874/why-are-recommendation-letters-highly-relied-upon\">Why are recommendation letters highly relied upon?</a>.</p>\n<p>As we know, the letter of recommendations are heavily relied upon in the process of university/graduate school applications and job market. Sometimes it is considered <a href=\"http://www.math.stonybrook.edu/applying-phd-program\" rel=\"noreferrer\">the most important part of the application</a>. Sometimes, if a referee wants to strongly recommend someone, they may even directly make a phone call to certain departments/professors.</p>\n<p>However, as we know, the quality and importance of recommendation letters depends largely on the subjective opinions and the reputations of the referees. As a result, the system of recommendation letters sometimes encourages young scholars to spend more (and perhaps unnecessary) time using strategies to <strong>gain the favor</strong> of professional scholars (I believe there are clever ways for average students to &quot;demonstrate&quot; to the professors that they are strong...) or spend less time in communication to avoid bad opinions (if you can't show people that you are smart, then you'd better talk less and try not to show people that you are stupid).</p>\n<p>Meanwhile, writing letters seems to be a heavy burden on professors. You might want to argue that this is part of their job, but shouldn't they be given more time for their research and teaching? I heard some professors write dozens of letters every year, which costs them a lot of time (excluding the time for communication with applicants).</p>\n<p>My question is, is the letter of recommendation really an indispensable part of academic application processes? Can &quot;objective&quot; things like GPA (well, &quot;transcripts&quot; or &quot;courses and grades&quot; might be a more accurate measurement), test and competition scores, publications alone provide enough information to evaluate the strengths and weaknesses of applicants?</p>\n<p>Aside: I don't know much about the application of professional positions (postdoc and tenure-track positions). However, for university/graduate school applications, can we simply raise the difficulty of standard tests (for the information of those who think SAT and GRE general and even subject tests are too easy) to better differentiate between applicants? I heard that in China, PhD applicants need to take qualifying exams BEFORE being considered.</p>\n", "pids": ["5c0f74c6da562944ac6bbc39", "5c756bb4f56def979840e302"], "flag": 1}
{"question": "Global number of publications over time", "body": "<p>We always hear about the increasing number of publications published every year and the resulting information overload in science. I wanted to show this trend to students to highlight why they should care about information literacy and search strategies. Unfortunately, I couldn't find a reliable source that highlights this trend, e.g. in an easy understandable figure.</p>\n\n<p>I searched for publications including this information and even hoped for Web of Science or Google Scholar to publish this information but couldn't find anything useful. It is not that important what kinds of publication types are included, e.g. only journal articles or all kinds of publications.</p>\n\n<p>Has anyone a reliable and relatively easy to understand source highlighting the trend of increasing global number of publications over time?</p>\n", "pids": ["56d8e6d3dabfae2eee369e2a", "573695f76e3b12023e50b97d"], "flag": 1}
{"question": "Long term effects of a high self monitor who voluntarily chooses a contradictory self-presentation", "body": "<p>Are there any cases or studies of a <code>high self monitor</code> who intuitively chooses to act \"by impulse\" in order to reform said impulse? </p>\n\n<p>In other words when the HSM behaves as a <code>low self monitor</code> they selectively and willingly embrace a <code>low self presentation</code> in order to challenge (or embrace flaws) within their own pride, ego, or some other aspect of psychology.</p>\n\n<p><strong>Additional questions</strong></p>\n\n<ul>\n<li><p>What else can be said of this situation? </p></li>\n<li><p>What other questions, or background is necessary to analyze this occurrence? </p></li>\n<li><p>Is this behavior indicative of other problems worth investigating? (e.g. morally flawed premise for taking such action)</p></li>\n<li><p>What negative effects could there be on the ego and super-ego by behaving this way over long periods of time? </p></li>\n</ul>\n\n<p><strong>Edit</strong></p>\n\n<p>At a young age, this HSM may have discovered that behaving as a low-self-presentation allowed them to abdicate responsibility.  This was later corrected in adulthood when the subject decided to actively pursue accountability on past and present behavior... thus leading to overall character improvement. </p>\n", "pids": ["56d8e73ddabfae2eee392820", "5c0f726cda562944ac65e9fe"], "flag": 1}
{"question": "Theorem of uncertainty in cognitive science", "body": "<p>Recently, reading one book I have come across such paragraph:</p>\n\n<p><code>\"[...] The operation would require de facto to create a complete record of the mind and build the brain again - an impossible thing for absolutely fundamental reasons. Cognitive science has its own theorem on uncertainty, the law proving the impossibility of reducing the mental structure to numerical data.\"</code></p>\n\n<p>I am guessing, that the author was referring to the Heisenberg's uncertainty theorem, but that is the only thing that came to my mind (my knowledge about cognitive sciences is very limited). Do you know, what the author might have meant? Or maybe it was just fiction?</p>\n", "pids": ["53e9a90db7602d970325cb81"], "flag": 1}
{"question": "Evidence and arguments for and against bounded rationality?", "body": "<p>Can anyone point me to a couple prominent papers on Simon's concept of bounded rationality (i.e., that human rationality is shaped by limitations in our ability to ingest and process information)? Specifically, I'm looking for empirical evidence for or against and arguments against (I'm content with Simon's own arguments for.) I know the literature on this is extensive; I just need a very high-level overview with some credible scholarly support.</p>\n", "pids": ["56d8ede1dabfae2eee621fb6"], "flag": 1}
{"question": "Biological plausibility of RBMs", "body": "<p>How <a href=\"https://cogsci.stackexchange.com/q/8923/4397\">biologically plausible</a> are Restricted Bolztmann Machines (RBMs) and their stacked equivalent Deep Belief Networks (DBNs)? I know that Deep Learning (DL) in general isn't considered biologically plausible, since it requires information to be propagated backwards through uni-directional synapses. However, from what I understand, DBNs don't use back-prop and instead uses some sort of unsupervised learning algorithm. Does that make them more biologically plausible? </p>\n", "pids": ["5550416345ce0a409eb3ad52"], "flag": 0}
{"question": "How can a reinforcement learning agent generalize if it is trained against only one opponent?", "body": "<p>I started teaching myself about reinforcement learning a week ago and I have this confusion about the learning experience. Let's say we have the game Go. And we have an agent that we want to be able to play the game and win against anyone. But let's say this agent learn from playing against one opponent, my questions then are: </p>\n\n<ol>\n<li>Wouldn't the agent (after learning) be able to play only with that opponent and win? It estimated the value function of this specific behaviour only.</li>\n<li>Would it be able to play as good with weaker players? </li>\n<li>How do you develop an agent that can estimate a value function that generalizes against any behaviour and win? Self-play? If yes, how does that work? </li>\n</ol>\n", "pids": ["59ec02da0cf22f5df7319dc3", "599c7963601a182cd2638264"], "flag": 1}
{"question": "Can machine learning be used to improve the average case complexity of an algorithm?", "body": "<p>I am developing an algorithm that, in certain moment, must explore an exponential number of objects derived from a graph:</p>\n\n<pre><code>for o in my_graph.getDerivedObjects():\n  if hasPropertyX(o):\n    process(o)\n    break;\n</code></pre>\n\n<p>If one of the derived objects has property <span class=\"math-container\">$X$</span>, then the algorithm process it and then stops. The theory ensures that at least one of these derived objects has property <span class=\"math-container\">$X$</span>. Now, I strongly suspect that there is a strong correlation between some topological aspects of the graph, and which derived objects actually have property <span class=\"math-container\">$X$</span>. I want to <em>predict</em> some of the derived objects that have property <span class=\"math-container\">$X$</span> using Machine Learning. So, the idea is:</p>\n\n<ol>\n<li><p>Predict a derived object <span class=\"math-container\">$o$</span> that supposedly has property <span class=\"math-container\">$X$</span> - or maybe predict <span class=\"math-container\">$n$</span> of them for some number <span class=\"math-container\">$n$</span>.</p></li>\n<li><p>If any of them is useful, I use them. If not, I run the exponential algorithm.</p></li>\n</ol>\n\n<p>Of course, this isn't an optimization in the worst-case complexity of the algorithm. Also, I suppose I should also develop some statistical tests in order to show that the prediction algorithm actually works.</p>\n\n<p>Is this type of optimizations common? Could you please provide some examples? The literature on the subject would also be greatly appreciated.</p>\n", "pids": ["5c796b9a4895d9cbc64680a9"], "flag": 1}
{"question": "Are the skills trained and learn from world memory championship transferable?", "body": "<p>I recently learn something about world memory championship and I am considering to embark on some training. But I would like to know if the skills trained and learn from world memory championship are transferable? Like improving IQ, improving imagination capability, improving \"innate memory power\" (meaning that your memory improves even when not applying techniques)?</p>\n", "pids": ["56d90281dabfae2eeee0cdd5", "5a9d3a07684d7fe2ff403bb8"], "flag": 1}
{"question": "How do intermediate layers of a trained neural network look like?", "body": "<p>Suppose I have a deep feed-forward neural network with sigmoid activation <span class=\"math-container\">$\\sigma$</span> already trained on a dataset <span class=\"math-container\">$S$</span>. Let's consider a training point <span class=\"math-container\">$x_i \\in S$</span>. I want to analyze the entries of a hidden layer <span class=\"math-container\">$h_{i,l}$</span>, where</p>\n\n<p><span class=\"math-container\">$$h_{i,l} = \\sigma(W_l ( \\sigma (W_{l-1} \\sigma( \\dots \\sigma ( W_1 \\cdot x_i))\\dots).        $$</span></p>\n\n<p>My intuition would be that, since gradient descend has passed many times on the point <span class=\"math-container\">$x_i$</span> updating the weights at every iteration, the entries of every hidden layer computed on <span class=\"math-container\">$x_i$</span> would be either very close to zero or very close to one (thanks to the effect of the sigmoid activation). </p>\n\n<p>Is this true? Is there a theoretical result in the literature which shows anything similar to this? Is there an empirical result which shows that?  </p>\n", "pids": ["573696026e3b12023e5163bc"], "flag": 1}
{"question": "Why are there dollar amounts listed near the copyright information for journal articles?", "body": "<p>Specifically I am looking at <a href=\"https://doi.org/10.1145/3301312\" rel=\"noreferrer\">this paper</a>, but I've seen these in other papers too. At the bottom of the first page, it has some metadata and copyright information:</p>\n<p><a href=\"https://i.stack.imgur.com/VX6ue.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/VX6ue.png\" alt=\"enter image description here\" /></a></p>\n<blockquote>\n<p>© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.</p>\n<p>1549-6325/2019/02-ART29 $15.00</p>\n<p><a href=\"https://doi.org/10.1145/3301312\" rel=\"noreferrer\">https://doi.org/10.1145/3301312</a></p>\n<p>ACM Transactions on Algorithms, Vol. 15, No. 2, Article 29. Publication date: February 2019.</p>\n</blockquote>\n<p>I understand the copyright notice, and the DOI, and the human-readable citation information. But what is going on on the second line, besides year, issue number, and article number? What is <code>1549-6325</code>? And <strong>what, if anything, costs $15.00</strong>? Is the <code>$</code> character being used to mean something else here?</p>\n", "pids": ["55a4a8b065ceb7cb02d57879"], "flag": 1}
{"question": "What electrical stimuli do brain implants use?", "body": "<p>I was reading about artificial eyes and came to think about how the brain works. More specifically, what \"signals\" it uses in the case of cortical visual prosthetics in blind people? Cortical prosthetics apply current stimulations through electrodes placed on the surface of the visual cortex. </p>\n\n<p>Now suppose I would want to let a blind person wearing a cortical prosthesis to see the color red, what signal would I send through the electrodes? Would a sine wave of 200 Hz do the job? </p>\n", "pids": ["53e9a584b7602d9702eab0c6", "5d0b006c8607575390fc491b"], "flag": 1}
{"question": "Can people act randomly?", "body": "<p>Let's imagine an experiment. We will tell N normal people that they need to act randomly in the Rock–paper–scissors game (in this game Game Optimal Strategy is to choose an action with uniform probability 1/3). \nTwo question:</p>\n\n<ul>\n<li><p>How close to uniformly randomness can we expect each person to act? </p></li>\n<li><p>More important question. Will this be a stationary distribution or it will change over the time if there will be a lot of trials?</p></li>\n</ul>\n\n<p><em>(People in the experiment can't use any kind of external random generators</em>).</p>\n", "pids": ["53e9b8b3b7602d970448e773"], "flag": 1}
{"question": "What does the evidence suggest about how Neanderthals became extinct?", "body": "<p>According to <a href=\"http://www.livescience.com/28036-neanderthals-facts-about-our-extinct-human-relatives.html\" rel=\"nofollow\">\"Neanderthals: Facts About Our Extinct Human Relatives\"</a> (Szalay, 2013), Neanderthals dominated Europe during the last Ice Age, but may have died out before the arrival of Homo Sapiens (according to research detailed in <a href=\"http://www.pnas.org/content/110/8/2781\" rel=\"nofollow\">\"Radiocarbon dating casts doubt on the late chronology of the Middle to Upper Palaeolithic transition in southern Iberia\"</a> (Wood et al. 2012).</p>\n\n<p>There are a number of theories floating around in the literature - everything from inability to adapt to climate change  to dietary deficiencies.</p>\n\n<p>What does the latest research suggest as the cause of the Neanderthal extinction?</p>\n\n<p><em>(refereed papers would be appreciated)</em></p>\n", "pids": ["53e9bbadb7602d97047f9ab5"], "flag": 1}
{"question": "How do people with a split brain experience reality?", "body": "<p>Some people with severe epileptic seizures have the connection between their two brain halves cut. How appears reality for them, and why does this procedure helps them?</p>\n", "pids": ["55a49d7465ceb7cb02d4245e"], "flag": 1}
{"question": "What gaseous substances do humans emit?", "body": "<p>Other than CO₂ and Methane what other gases do humans produce or emit?</p>\n<p>For example, does  skin decomposition, or aerobic respiration emit any special gases that people don't normally realize or know about.</p>\n<p>I ask because of a discovery I made during research is that while being poisonous to the central nervous system, methanol is a natural endogenous compound found in normal, healthy human individuals.</p>\n<p>One study found a mean of 4.5 ppm in the exhaled breath of the subjects. <a href=\"https://iopscience.iop.org/article/10.1088/0967-3334/27/7/007\" rel=\"nofollow noreferrer\">https://iopscience.iop.org/article/10.1088/0967-3334/27/7/007</a></p>\n", "pids": ["5f214ff29fced0a24be4941c"], "flag": 1}
{"question": "Article for bypassing spinal cord after spinal cord injury", "body": "<p><a href=\"http://mashable.com/2014/07/10/neurobridge-paralyzed-man/#MRj1Yeqvz5qY\" rel=\"nofollow noreferrer\">This article</a> describes a research that allows a man with spinal cord injury (SCI) at the cervical level to move his finger. A chip was used to circumvent the spinal cord and send signals to the finger muscles. </p>\n\n<p>I am looking for the scientific paper of this study. Does someone know the article they used, or a study that describes a similar research?</p>\n", "pids": ["570fa6420cf27170c78b7934"], "flag": 1}
{"question": "Difference between SSVEP and P300", "body": "<p>I have read about <a href=\"http://en.wikipedia.org/wiki/Steady_state_visually_evoked_potential\" rel=\"nofollow noreferrer\">steady state visually evoked potentials (SSVEP)</a> and <a href=\"http://en.wikipedia.org/wiki/P300_(neuroscience)\" rel=\"nofollow noreferrer\">P300</a> as different subjects. But it seems that they are related to each other.</p>\n<p>Is P300 a kind of SSVEP?</p>\n", "pids": ["55a4f59c65ceb7cb02dd2cbc"], "flag": 1}
{"question": "How do some humans seemingly naturally have positive or mitigated appraisal of stressful events?", "body": "<p>Appraisal is how an individual interprets a stressful event or a problem. For recurring problems, I understand that there are neuroanatomical structures that play a role in the appraisal of recurrent problems, problems of a certain type that are encountered frequently. For example, the hippocampus is important in the development of episodic memories, and the amygdala plays a role in fear processing. If we exclude individuals with significant lesions to these areas, we have a population of individuals with these same neuroanatomical structures. However, you can find that some individuals have different appraisals of problems. While these structures are biological intermediaries to cognition, the results are different. How, and why? </p>\n\n<p>For example, this can have implications in sports. Two players of a professional basketball team could both be the most skilled players on their respective teams with a terrible supporting cast of teammates. One player who views this lack of talent as a challenge could take it upon himself to galvanize his teammates and \"carry his team on his back\", leading to a successful team performance. However, the other player could view his lack of surrounding talent as a detriment, a crutch, and let frustration contribute to his anxiety, leading to a team's downfall. </p>\n\n<p>Moreover, appraisal could lead to nonchalant perspectives of certain problems, which leads to stress reduction in some scenarios. Back to the sports analogies. In sports, it is said that an optimal trait of a quality defender is \"short term memory\" in the sense that if opponents have scored on them, the defender does not let this event contribute to future encounters defending opponents. That is, the defender does not think to him/herself, \"I got scored on last time, oh no\", which leads to a compounding lack of confidence and eventually, performance. </p>\n\n<p>A natural psychological explanation could be upbringing or priming, but I can find individuals who grew in stressful environments who can handle stress well, and can't handle stress well. Moreover, I can find individuals who grew in environments where stress was not a significant factor, and again, you can find people who handle stress well and those who don't handle stress well. </p>\n", "pids": ["53e9b917b7602d97044fd333"], "flag": 0}
{"question": "Is the ratio Brain Mass/Total Mass still considered a valid indicator of intelligence?", "body": "<p>I was reading <a href=\"http://www.frontiersin.org/Human_Neuroscience/10.3389/fnhum.2013.00245/abstract\" rel=\"nofollow\">this(1)</a> and it led me back to ask a very basic question (I'm not a neuroscientist).  All the way back to undergrad anthropology and neuroscience courses I remember being taught the general rule of relative intelligence was that one looked at the ratio of the brain mass over the total mass of the animal (or the estimations therein from let's say fossils).</p>\n\n<p>I know a lot of the interesting neuroscience research going on these days does looks into bird brains, particularly within <em>Corvidae</em>.  It would seem that birds are often much more efficient in the abilities they seem to show with considerably less brain mass.  I do realize that birds often weigh very little as well, so perhaps the ratio is preserved?  </p>\n\n<p>I also realize that within birds, they see better ratios in more intelligent birds.  But what about the comparison from mammals to birds?</p>\n\n<p>Dinosaurs are often predicted to <strong>not</strong> be intelligent because of the enormous body size and small cavities for a brain.  Now I realize that some dinosaurs were actually quite tiny, but this is just an example.  </p>\n\n<p>Given birds' close genetic link to dinosaurs, could it simply be that they were just doing more with less?  The mammalian brain is a huge caloric burden, so perhaps this would show an efficiency that could be selected for?</p>\n\n<p>Thus as the title suggests, my main question:</p>\n\n<p>Is the ratio of brain mass to body mass still considered to be a valid indication of intelligence of a species in modern (current) neuroscience?  Certainly there are exceptions, but is it still considered the rule of thumb?</p>\n\n<p>EDIT: I also wanted to point out the <a href=\"http://www.karger.com/Article/FullText/102973\" rel=\"nofollow\">first article(2)</a> I started to read after formulating the question.  It made me question the usefulness of encephalization in addressing this issue at all, but I don't/didn't feel adequately trained to evaluate the conclusions of the meta study.  </p>\n\n<p>Again, this still leaves us comparing within primates, which still leaves me feeling that <em>Corvidae</em> have some really impressive efficiency going on with their overall brain mass.  Which then leads to hope that some dinosaurs could be at least equally intelligent, if not more so (noted that this is complete conjecture).</p>\n\n\n\n<p>(1) Front Hum Neurosci. 2013 Jun 6;7:245. doi:<a href=\"http://dx.doi.org/10.3389/fnhum.2013.00245\" rel=\"nofollow\">10.3389/fnhum.2013.00245</a>. Print 2013.</p>\n\n<p>(2) Brain Behav Evol. 2007;70(2):115-24. Epub 2007 May 18.</p>\n", "pids": ["55a4819d612ca6486898f261"], "flag": 1}
{"question": "Dispute over precision with coauthor", "body": "<p>I am currently having a disagreement with a coauthor on a paper over the matter of significant figures.</p>\n\n<p>He would like to specify (for example) that a certain organization has an environmental footprint of 7,622 gha.  Environmental footprinting rests on a tonne of assumptions and is not a precise methodology, so I don't think we have anything like 4 significant figures of precision in our calculations - more like 2 at most.  So I would like to publish that figure as 7,600 gha.</p>\n\n<p>I have pointed out that doing otherwise implies a level of precision we don't have.  Currently we are publishing an executive summary prior to peer reviewed journal paper, so I also said it would be embarrassing if the precision issues were picked up at peer review stage and we thus ended up publishing two different sets of figures.  He responds that he has never had a problem with publishing more accurate figures in previous journal publications.</p>\n\n<p>The coauthor does not have a quantitative background so has limited understanding this issue, however he is more senior.</p>\n\n<p>So two questions</p>\n\n<ul>\n<li>does this issue even matter?</li>\n<li>what would you do about it?</li>\n</ul>\n\n<p>UPDATE</p>\n\n<p>It looks like you all agree with me that this matters.  Good, I'm not insane :)  </p>\n\n<p>As we are currently writing an executive summary/press release for the general public, there is no place for scientific notation or estimates of error - they will make it harder to read and likely put off some people.</p>\n\n<p>Can someone link me to a good, polite and authoritative rant on why this matters that I can show to my colleague?  The trouble with almost all material I have seen on significant figures, is that it doesn't discuss rounding off digits left of the decimal point.  i.e. it talks about turning 7.36654 into 7.4 but not 736654 into 740000.  I suspect my colleague draws an arbitrary line in his head at the decimal point, being unaware that the position of the point is just a function of the units used.  And I doubt they would be open to that sort of argument.</p>\n", "pids": ["56d8d7aedabfae2eeed7a7d0"], "flag": 1}
{"question": "How accurate are published papers?", "body": "<p>I'm an undergrad trying to publish findings on the accuracy of consumer-grade motion sensors for IEEE. I've searched for existing literature on this topic, and I've found some interesting articles. However, I'm not sure how accurate these papers are. </p>\n\n<p><strong>Once IEEE publishes a paper in a journal or conference, has IEEE deemed the paper's findings as accurate?</strong></p>\n\n<p>That is, has a paper passed science's often-vaunted \"peer-review\" once that paper has been published?</p>\n\n<p>I realize this question applies for my research and any other research published by a respected organization like IEEE or Nature.</p>\n", "pids": ["5f0747c69e795e1a9f4ad6f4"], "flag": 1}
{"question": "Why do we see unknown people and places in dreams?", "body": "<p>People often see unknown things, places, and people in their dreams. </p>\n\n<p>How is it possible to have such perceptions in our dreams that go beyond our actual experiences and memories?</p>\n", "pids": ["5f0e5c6c9fced0a24b5e79ec"], "flag": 1}
{"question": "How to modify a final draft to reflect that a conjecture in its preprint was refuted?", "body": "<p>I am currently in the process of trying to publish a mathematics paper. A draft of this paper had been posted on arxiv, which contained an interesting conjecture.</p>\n\n<p>In the intervening time, this conjecture has been refuted by another group of authors. I am not sure how I should edit my paper to reflect this.</p>\n\n<p>One option that is out of the question is to simply delete the conjecture from the paper. The problem with this is that the latter paper has cited this conjecture as its motivation. If I removed the conjecture, I would be pulling the legs out from the subsequent paper.</p>\n\n<p>What I am leaning toward is to state something along the lines of \"In an earlier draft, we had made the following conjecture:\" and then include some discussion and citations about how the conjecture has subsequently been refuted.  </p>\n\n<p>Note that most of my paper is unaffected by this refutation, and in fact I still believe that the conjecture could hold <em>for the special case I need</em></p>\n\n<p>Is there a better way of handling this situation? </p>\n", "pids": ["62294ec35aee126c0f0920a0"], "flag": 1}
{"question": "Why do research faculty pursue administrative positions, such as dean, provost, president, etc. ? Do such positions spell the end of one&#39;s research?", "body": "<p>At a recent seminar talk, I was amazed to note that one of the two coauthors (not the presenter) was the <a href=\"https://president.uchicago.edu/page/about-president-zimmer\">president of a large and well-known university</a>, since I had always assumed that taking on such a position would necessarily mean the end of a research career. </p>\n\n<ul>\n<li><p>Are there m/any examples of people that continue to do substantial amounts of research when in a senior administrative position, such as dean, provost, president, etc.? </p></li>\n<li><p>Do research faculty often become deans, presidents, etc.? Why do faculty usually do this? (I understand that there might be a pay increase, but does it usually indicate that they no longer want to do research as intensely?)</p></li>\n</ul>\n", "pids": ["53e9a667b7602d9702f95312"], "flag": 1}
{"question": "Persuasion strategies by Cialdini (why is punishment not there?)", "body": "<p>Cialdini is famous for his book \"Influence\" where he talks about various ways to get people to do things you want them to.  They are:</p>\n\n<ul>\n<li>reciprocation</li>\n<li>commitment/consistency</li>\n<li>scarcity</li>\n<li>authority</li>\n<li>liking</li>\n<li>social proof</li>\n</ul>\n\n<p>Should not punishment be included?  Or are there soft/hard ways of persuasion, or perhaps short-term/long-term distinction?  </p>\n\n<p>I considered maybe punishment is part of authority, but do all forms of authority have additional power to punish?  I don't think so.  Some are just empty titles/positions.  In addition, non-authority figures also have the power to punish, even if it's not legitimized, and as a result an abusive parent or child, or a bully or someone wielding a knife can punish you if you don't do what they say.  In addition, the effects of or threat of punishment itself can also last a long time, like many other persuasion/influence strategies.</p>\n", "pids": ["53e9a447b7602d9702d61db7"], "flag": 0}
{"question": "Survey questions to test competitiveness", "body": "<p>I'm running an experiment and am suspecting that competitive people may respond differently to experimental treatments compared to non-competitive people.</p>\n\n<p>To determine whether a person has a competitive personality, I'm thinking of surveying and asking questions such as </p>\n\n<p>\"My friends would describe me as a competitive person.\"</p>\n\n<p>\"I would describe myself as a competitive person.\"</p>\n\n<p>\"Even when there is no monetary reward, I will seek to surpass others when doing a task.\"</p>\n\n<p>Would these be good measures of competitiveness? What other questions could I use?</p>\n", "pids": ["53e9b6cbb7602d9704254893", "53e9ad9eb7602d9703798f6f"], "flag": 1}
{"question": "What do brain waves look like under the influence of psilocybin?", "body": "<p>I am curious about what brain waves (EEG) look like under the influence of psilocybin mushrooms or LSD.  Is there any research on subjects in psychedelic states and how their brain waves change relative to normal?</p>\n", "pids": ["5c0f7224da562944ac653056"], "flag": 1}
{"question": "What reasons allow for women to outlive men?", "body": "<p>It is a <a href=\"http://en.wikipedia.org/wiki/List_of_countries_by_life_expectancy#List_by_the_United_Nations_.282005.E2.80.932010.29\">well-known fact</a> that women tend to outlive men. </p>\n\n<p>I often hear people unscientifically stating that men generally generally die younger because of the higher stress encountered in their work lives. I would personally immediately rule this out, as who's to say that that women's (past) home lives just weren't as stressful? Also, shouldn't we see a narrowing of difference in age with the recent gender equality issues? Since the trend in question still occurs in virtually all countries of the world, I think it's safe to assume that the phenomenon is purely physiological. </p>\n\n<p>I am curious as to <em>the most sound scientific theories or known reasons</em> for why women typically outlive men. Finally, I understand that aging in itself is not a process that's completely understood, and thus am not expecting a \"complete list\" of factors.</p>\n", "pids": ["55a4eb3d65ceb7cb02dbff41", "55a4d831c91bf3b1cc48230a", "55a47f4e65ce31bc877d00b6", "5c756eecf56def979861df7d", "55a5ef42c91ba91c7d938f76"], "flag": 1}
{"question": "Subtle (and not-so-subtle) humor in scientific literature", "body": "<p>Tonight I was scrolling through my RSS aggregator (which includes subscriptions for several journals I follow) and the abstract for <a href=\"https://genomebiology.biomedcentral.com/articles/10.1186/gb-2012-13-2-r13\" rel=\"nofollow noreferrer\">All Your Base: a fast and accurate probabilistic approach to base calling</a> caught my attention. The article's title, as well as the name of the software it describes, includes a subtle reference to the popular internet meme <a href=\"http://knowyourmeme.com/memes/all-your-base-are-belong-to-us\" rel=\"nofollow noreferrer\">All Your Base Are Belong to Us</a>. This gave me a good laugh, and an excuse to watch that ridiculously silly video again.</p>\n<p>But on a more serious note, this is not the first time I have seen the use of subtle (or not-so-subtle) humor in the title of a scientific journal article, conference abstract, or poster presentation. Sometimes the humor is even injected into the body of the publication itself. But in general, we as scientists are expected to write in such a way that our findings are easily communicated and easily reproducible. The focus is on clarity, objectivity, and reproducibility.</p>\n<p>There are of course no formal rules about the use of humor in scientific literature, but are there any <em>de facto</em> rules? Do these <em>de facto</em> rules depend on the field (computer science vs genetics) or the publisher (Oxford Univ. Press vs BioMed Central) or the journal's impact factor (Nature vs Frontiers in Genetics)? Does humor even have a place in scientific literature, or would we be better off without it?</p>\n", "pids": ["53e998e1b7602d970211d064", "599c7958601a182cd2632f8b"], "flag": 1}
{"question": "Can a shorter IQ test be devised that provides a more approximate measure of IQ?", "body": "<p>Disclaimer: I am not a student of psychology, just an interested guy - but here goes anyway...</p>\n\n<p>IQ tests usually contain dozens of questions and take considerable time. I think this is because such tests have to differentiate between a great diversity of intelligence levels.</p>\n\n<p>Now, <strong>I wonder if a test could be devised such that you answer a fraction of a number of questions associated with the usual IQ test, and the test result is yes, your IQ is between 100 and 120, or no, your IQ is outside of this range.</strong></p>\n\n<p>This could be useful, if someone is intelligent, but has problems with attention, or in some kind of survey setting, where people don't have a lot of time. </p>\n", "pids": ["5fd6e28998b36632c84b94a7"], "flag": 0}
{"question": "Are we able to simulate pain through the brain?", "body": "<p>I have like 0 experience or knowledge about brain signals and all that stuff but I'm curious about how much we know about the brain in terms of like tricking your brain that with simulation of pain. The reason why i got curious is because I love video games and I just started imagining like some sort of real life game or even just using virtual reality where if you were to get hurt in the game in some spot you would feel pain in real life. I'm not sure if there's some sort of article or like something online where it explains this sort of stuff that I'm talking about.</p>\n", "pids": ["55a3501c24012c2ab7a60b5a", "621de36b5aee126c0fb1118d"], "flag": 0}
{"question": "Is there any size limit to the amount of information a human (or other) brain can hold", "body": "<p>Im not sure how this would ever be tested but is there a limit to how much the brain can 'hold' before it reaches capacity ?</p>\n\n<p>I guess this could also be interpreted in terms of memory, as how well some one remember something before reaching capacity / forgetting 'old' memories to make way / space for new ones.</p>\n", "pids": ["53e99931b7602d970216e1dd"], "flag": 1}
{"question": "What human factors play part in traffic congestion?", "body": "<p>Traffic congestion is a daily phenomenon that costs people a lot of time, is bad for the environment and may even cost some money. There are many obvious causes for traffic congestion, such as the amount of cars, size of the road, situational factors on the road such as accidents etc.(e.g. <a href=\"http://bklyner.com/what-really-causes-traffic-congestion-sheepshead-bay/\" rel=\"noreferrer\">this blog</a> or <a href=\"https://en.wikipedia.org/wiki/Traffic_congestion#Causes\" rel=\"noreferrer\">(Wiki)</a>. </p>\n\n<p>It seems that increasing the capacity of the road capacity is not a solution to the problem, since it only appears to attract more users (<a href=\"http://faculty.cord.edu/andersod/EconOfTraffic.pdf\" rel=\"noreferrer\">Arnott and Small, 1994</a>). Therefore, I was thinking whether there were any other factors that could influence congestion. It is obvious that each car has a human drive (well almost each car). Perhaps, their behavior could likely also play part in causing congestion. </p>\n\n<p><strong>Is there any scientific evidence that behavioral factors (e.g. excessive de- and acceleration or lane switching) may promote/prevent traffic congestion?</strong> </p>\n\n<h2>References</h2>\n\n<p>Arnott, R., &amp; Small, K. (1994). The economics of traffic congestion. American scientist, 446-455.</p>\n", "pids": ["55a46602612ca6486895246d"], "flag": 0}
{"question": "Does EMDR legitimately treat any condition?", "body": "<p>Are there any studies not funded by friends or beneficiaries of EMDR that prove it helps with a strong p-value?</p>\n", "pids": ["55a3a054c91b587b095d3e2e", "53e99940b7602d970217c75f"], "flag": 1}
{"question": "Why this guilt discrepancy in human beings?", "body": "<p>I believe no person is born a criminal.</p>\n\n<p>Then why do some people have compunctious guilt after a wrongdoing even when they were raised in an unhealthy family and some people have no guilt at all even when they were raised in a healthy family?</p>\n\n<p>Why this guilt discrepancy in human beings?</p>\n", "pids": ["53e9b14cb7602d9703bd21c3"], "flag": 1}
{"question": "How does the brain’s visual memory work?", "body": "<p>I have read a lot about people who are good memorizing images (visual type memory), music, words, numbers, etc. but I have never read a lot about <strong>how</strong> all these things are \"saved\" in our brain.</p>\n\n<p>I am not trying to understand the biological part, that is far away from my competences, I am talking more about a more general layer, like <em>what we actually memorize?</em></p>\n\n<p>I will start from an example: what do we \"save\" when we remember an image?</p>\n\n<ul>\n<li>Do we memorize all the \"pixels\" as a computer would?</li>\n</ul>\n", "pids": ["5c3ed5c7e1cd8e0a9606a804", "609fa094e4510cd7c834ee8e"], "flag": 1}
{"question": "Scientifically meaningful sources of bibliometrics", "body": "<p>Whether we like it or not, modern academia is increasingly being measured, in some vain attempt to get objective measures.  Although it is unwise to fight 'being measured', it is at least possible to steer the measures away from meaningless ones, backed by peer-reviewed research that establishes this unrefutably.</p>\n\n<p>There are a lot of different metrics that have been defined - I am not looking for those.  What I want is pointers to the research behind the scientific validity of those metrics.</p>\n\n<p>So the question is: where should I look for scientific assessments of bibliometrics?  </p>\n", "pids": ["53e997abb7602d9701f841d7", "53e9aef7b7602d9703924214"], "flag": 1}
{"question": "What causes autism?", "body": "<p>What causes autism? \nBy this <strong>I don't mean what is to blame</strong> i.e. Vaccines, Gluten or Pharmaceuticals etc.. I mean <strong>what exactly is happening in the brain</strong> to cause the autistic behaviors such as little to no communication skills, regression of skills around age 3, hand flapping etc..\nI see a lot of research looking for something to blame however I see little to no research on identifying the physical causes or links (maybe I'm not using the correct search terms).</p>\n", "pids": ["5c86ce4b4895d9cbc69d0810"], "flag": 1}
{"question": "Can you get addicted from using topical or local anaesthetics to ease pain?", "body": "<p>I've been wondering if there was such a thing as developing some kind of physical or psychological dependence on things that relieve pain. While we often hear about opioid addiction, which is primarily physical, I wonder if someone could psychologically be hooked on using something like lidocaine to numb every bruise or injury they get, just to numb the pain.</p>\n\n<p>I did hear that cocaine was once used as an anaesthetic, but it was also physically addicting.\nThis makes me wonder if physical withdrawal and hunger cravings are similar.</p>\n", "pids": ["53e9be0fb7602d9704ac57f9", "53e9b062b7602d9703ac8159"], "flag": 1}
{"question": "What are the personality and behavioural correlates of divorce?", "body": "<p>I've read quite a few statistics about divorce (sources <a href=\"https://www.mckinleyirvin.com/Family-Law-Blog/2012/October/32-Shocking-Divorce-Statistics.aspx\" rel=\"nofollow noreferrer\">here</a> and <a href=\"https://www.bls.gov/opub/mlr/2013/article/marriage-and-divorce-patterns-by-gender-race-and-educational-attainment.htm\" rel=\"nofollow noreferrer\">here</a>), and biggest factors seems to be:</p>\n\n<ol>\n<li>Culture - from 71% in Belgium to 2-3% in some traditional societies</li>\n<li>Income of the couple</li>\n<li>Ratio of the woman's income to the man</li>\n</ol>\n\n<p>Other factors such as education and whether they come from divorced family also plays a big factor.</p>\n\n<p>But what are some behavioral characteristic that have the biggest impact?\nFor example are shy people less likely to get divorced controlled for everything else? Do people who had less sexual partners in their lifetime are less likely?\n Introverts or extroverts? Which of the 5 big personality traits predict best (Conscientiousness, ‎Openness to experience, ‎Agreeableness, Neuroticism, Extraversion)?\nI want some respected studies video lectures very much appreciated :)</p>\n", "pids": ["55a509fa65ceb7cb02df3246", "53e9a6d8b7602d9703010d60"], "flag": 0}
{"question": "Does verified evidence for Freudian repression of traumatic memories exist?", "body": "<p>This is sort of related to <a href=\"https://cogsci.stackexchange.com/questions/4021/do-repressed-memories-exist\">this other question</a>, except that here I am not asking whether the brain is viewed as being capable of repressing memories, but about any <strong>verified</strong> cases of where that has happened.</p>\n\n<p>I was watching a documentary in which a psychiatrist said that an individual always remembers traumatic events, and that there is no evidence for the Freudian notion that the brain represses traumatic memories.</p>\n\n<p>So here I specifically want to exclude as evidence <strong>solely</strong> from claims from people who say that they were abused as children but suppressed these memories (and consequently either did, or did not, develop multiple personalities).</p>\n\n<p>What I am interested in is verified evidence of cases where a person suffered trauma but the memories of the trauma were repressed <strong>as per the Freudian notion</strong>. With this I mean that I also want to exclude cases where the individual learned to live with the past and consequently memories of the trauma faded because it no longer carried any emotional significance to the person.</p>\n\n<p>I would appreciate references to academic literature or articles where the evidence is mentioned.</p>\n\n<p>Does verified evidence for Freudian repression of traumatic memories exist?</p>\n", "pids": ["55a49d7465ceb7cb02d423a5"], "flag": 0}
{"question": "What is the meaning of the brain scan of borderline patients?", "body": "<p>Starting from mark 21:50 in the lecture <a href=\"https://www.youtube.com/watch?v=_t_NqEP80GE\" rel=\"nofollow noreferrer\">BPD-related cognitive-perceptual difficulties and challenges in their diagnosis and treatment</a>, there is an image of brain scan in borderline patients:</p>\n\n<p><a src=\"https://i.imgur.com/f5rbyAC.jpg\" alt=\"\"></p>\n\n<p>What does this image say? The speaker says that it's something about uncontrollable manipulation of borderline patients, but I'm not really sure.</p>\n", "pids": ["53e9a8dbb7602d97032299cb"], "flag": 0}
{"question": "Neuronal Architecture of the Brain", "body": "<p>To what extent do brains (e.g. of humans) contain <a href=\"http://en.wikipedia.org/wiki/Recurrent_neural_network\">recurrent </a> connections? </p>\n\n<p>I am studying artificial neuronal networks and frequently encountered the statement, that recurrent neural networks are closer to biological neuronal networks than for example <a href=\"http://en.wikipedia.org/wiki/Feedforward_neural_networks\">feed forward networks</a>. But I didn't find information on the question if feed forward or recurrent architectures dominate the brain architecture.</p>\n", "pids": ["55a51582c91bf3b1cc4e5d81", "53e9b326b7602d9703df4f8a", "53e9b96eb7602d970455baf2"], "flag": 1}
{"question": "Do most people want to murder?", "body": "<p>It seems like the most popular theory among philosophers and neuroscientists who believe in free will is something called <a href=\"https://www.psychologytoday.com/us/blog/dont-delay/201106/free-wont-it-may-be-all-we-have-or-need\" rel=\"nofollow noreferrer\"><strong>free won’t</strong></a>. This basically means that we cannot <em>will</em> what we want to will, but we have the power to <em>veto</em> a thought that our brain has produced.</p>\n\n<p>This would mean that a person who is about to murder another person should have the power to veto pulling the trigger- but if they don’t, then they should be held morally responsible because they didn’t use their <em>free won’t</em> power. </p>\n\n<p>Now, I don’t think about murdering people, but I might be a weirdo. <strong>Do most people want to murder other people, but they use their <em>free won’t</em> to refrain- so that they should be praised for their <em>self-control</em>?</strong></p>\n", "pids": ["53e9a74ab7602d9703083b39", "53e99905b7602d970214051d", "56d918a6dabfae2eee6ac38a", "5c87531f4895d9cbc6031e18"], "flag": 1}
{"question": "How much pleasure can brain endure?", "body": "<p>As of 2018, is it possible to induce pleasure in humans by some intervention like sending electrical signals? I've read that it's been done on mice. If not, it's quite imaginable that it will become possible in the near future. What would be the neurological implications of such intervention, other than addiction? I mean what would happen to the brain if we force the brain to stay in an orgasm-like or ecstasy state for several minutes? What are the possible adverse effects or damages? Of course that we know very little yet, but I appreciate to get some insights on how pleasure works, and if there really are pleasure centers in the brain that can be easily manipulated. </p>\n", "pids": ["5c3cc6dcdf5b8c0b3cc978f7"], "flag": 1}
{"question": "Math paper with no &quot;Conclusions&quot;", "body": "<p>Is it acceptable for a math paper to have no concluding section? The structure is currently as follows:</p>\n\n<ol>\n<li>Introduction (known results + the paper's main results as 3 theorems)</li>\n<li>Preliminaries (proper definitions of all the things and recalling of results used in the proofs)</li>\n<li>Proofs (actually, several lemmas and proofs of them, and of the theorems)</li>\n<li>Open problems</li>\n</ol>\n\n<p>It's quite a short paper. I thought that since the Introduction is actually containing all the important stuff, making a Conclusions section would be only repeating the same stuff again. However, I'm not sure if this is considered a poor style in maths.</p>\n", "pids": ["56d8440adabfae2eee9f8580", "56d87fc3dabfae2eee5defde", "56d86a65dabfae2eeec2495c", "56d851a3dabfae2eee07b15d", "56d877cedabfae2eee254998"], "flag": 1}
{"question": "Has there been any studies of pathological &quot;nomad-ness&quot;?", "body": "<p>I've spent some time trying to search for this but my lack of knowledge limits my ability to find any information about this subject. </p>\n\n<p>I know someone who constantly sees another city as a \"Grass is Greener\" and will pack up and move about every eight months. This behavior of \"loose-footing\" that I'm trying to describe meets the 4 D's of Psychopathology: </p>\n\n<ol>\n<li><strong>Deviance</strong>: Moving to another town for an unacceptably bad reason that someone of their intelligence wouldn't accept if they heard it from someone else.</li>\n<li><strong>Distress</strong>: Forgoing valuable social and capital assets that causes hardship after the move. Feelings of loneliness after losing touch of newly created friendships before the move. Constant anxiety of not moving to a new city when they think they find a better one.</li>\n<li><p><strong>Dysfunctional</strong>: The person is in complete denial of the behavior trend and after moving to a new city will spend resources in material or non material assets that reflect an intention to not move again. Like signing a two-year lease or selling or buying a car or a city parking space. Or quitting a Top-100 University after two years and a 4.0GPA in engineering that gave them a full-ride, because of a unacceptably poor reason.</p></li>\n<li><p><strong>Danger</strong>: These self-imposed hardships give the person chronic depression and a danger to harm themselves.</p></li>\n</ol>\n\n<p>I'm only talking about this when it is pathological. I am assuming this is common, but I'm unsure of how common it is as I can't find any info about it. Hence the motivation for the  question.  I'm not referring to a cultural group or a nomad as being pathological.</p>\n\n<p>One could say that this is just depression and/or anxiety and while that is true. I would imagine that this behavior is unique or common enough to deserve its own study of this trend, its origins or treatment strategies. For example growing up with derelict parents or maybe moving too often during childhood.</p>\n", "pids": ["56f001580cf276b216258776"], "flag": 1}
{"question": "If you change your name while doing research, can you list both names on a publication?", "body": "<p>If you change your name, can you list both names as authors?</p>\n\n<p>For example, consider a PhD student named John Doe who after finishing his PhD undergoes a sex change and name change to Jane Doe before starting a postdoc. After the sex change Jane continues to work on a project that she started as a PhD student. Assume that the authors on the resulting paper are the PhD advisor, the postdoc advisor and Jane/John Doe. Can both Jane and John be listed? What happens if Jane never worked on the project, can she be the author or does it have to be John?</p>\n", "pids": ["56d8de9ddabfae2eee0374bf"], "flag": 1}
{"question": "Are schizophrenia and OCD genetically related?", "body": "<p>Schizophrenia has a genetic component. </p>\n\n<p>Persons with OCD and first parents having OCD have a <a href=\"https://consumer.healthday.com/health-technology-information-18/genetics-news-334/people-with-ocd-may-have-higher-odds-for-schizophrenia-study-691343.html\" rel=\"nofollow noreferrer\">higher probability to develop schizophrenia</a>.</p>\n\n<p>So, it seems that a possible overlap exists between schizophrenia and OCD. And I found <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3738863/\" rel=\"nofollow noreferrer\">this paper</a> dealing with the genetic aspect of the relation.</p>\n\n<p>So it seems like there can be a possible relation between schizophrenia and OCD, but I cannot find enough research to support it.</p>\n\n<p>So, my question is: is there a <strong>definitive genetic correlation</strong> between schizophrenia and OCD?</p>\n", "pids": ["56fbdde40cf2cd3b44e49289", "56d8d8fddabfae2eeee02b4d"], "flag": 0}
{"question": "What&#39;s the psychological reason for the fascination with gossiping or scandalous life?", "body": "<p>Why do people find fascination in a tabloid magazine, paparazzi magazine, gossiping or whether prince and kings are dating or not or if actors, actresses, singers having any scandalous affairs or not?</p>\n\n<p>I find gossiping similar to character assassination.</p>\n\n<p>I have no business in their lives.</p>\n\n<p>So what's the psychological reason for the fascination with gossiping or scandalous life?</p>\n", "pids": ["53e9bb9ab7602d97047e37fa"], "flag": 1}
{"question": "How do we imagine? How do images have qualia?", "body": "<p>After reading a bit about qualia and hard problem of consiousness, I came up to theoretical solution. The reason why we have this problem is because we can imagine. We can imagine an object visible to us as red being green, for example. Green fire. Even if we never saw it in the reality.</p>\n\n<p>But how do we imagine? How do those images have properties named by people as qualia? I can imagine a blue cube or a red cube, or a red sphere, and visual periphery is not involved here, I can do it with closed eyes.</p>\n\n<p>What parts of our brain are responsible for imagination? How does the brain \"give\" qualia (form, color, smell, etc.) to images? What differs in my brain when I imagine a red cube from when I imagine a blue cube? And are qualia stored in our memory?</p>\n", "pids": ["5c136aeeda56295a08a61672"], "flag": 1}
{"question": "Reviewer recommending citation of certain papers of specific group of authors may be himself", "body": "<p>Recently I had a challenge in responding to a reviewer (#2) for revising our work. The reviewer asked us to refer 16 papers in multiple parts of the paper. I decided to refer some of these references about 8 papers due to the not relevancy of the mentioned references from the reviewer to the question raised by the reviewer #2.</p>\n\n<p>Now the reviewers commented on the revised version and three of them are accepted without any further comments and modification. But the reviewer #2 rejected the paper and said that the authors didn't consider my concerns and comments thoroughly and only partially answered to them.</p>\n\n<p>I think that this reviewer objects to our work because of we didn't refer to all of 16 mentioned paper in his comments.</p>\n\n<p>The editor asked from us to answer why we didn't answer the reviewer #2 comments and revise our work to answer them.</p>\n\n<p>I have two scenarios in my mind:</p>\n\n<ol>\n<li>State clearly the unprofessional work of the reviewer #2 to forcing us to mention many papers from a group of specific people with a similar author in all of them and weak relevance of the mentioned works to that comment.</li>\n<li>Reanswer the comments of reviewer #2 and mention some of the wanted references</li>\n</ol>\n\n<p>what should I do now?</p>\n", "pids": ["5c755955f56def97987b3c5d"], "flag": 1}
{"question": "Does Transcranial Direct-Current Stimulation (tDCS) enhance cognitive function?", "body": "<p>From the book \"The future is faster than you think\" by Peter Diamandis, Steven Kotler:</p>\n\n<p>“Consider the nine-dot problem, a classic test of creative problem-solving. Connect nine dots with four lines in ten minutes without lifting your pencil from the paper. Under normal circumstances, fewer than 5 percent of the population can pull this off. In a study run at the University of Sydney in Australia, none of their test subjects did. But then the researchers took a second group of subjects, and used transcranial direct stimulation to artificially mimic many of the changes produced during flow. What happened? Forty percent solved the problem—a record result.”</p>\n\n<p>What is the current scientific consensus on this question?</p>\n\n<p>This appears to be the study mentioned:<br>\nBrain stimulation enables the solution of an inherently difficult problem<br>\n<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0304394012003618\" rel=\"nofollow noreferrer\">https://www.sciencedirect.com/science/article/abs/pii/S0304394012003618</a></p>\n\n<p>An APA reference to the study was requested.<br>\nHere is one such reference:<br>\nUsing transcranial direct current stimulation to enhance creative cognition: Interactions between task, polarity, and stimulation site.<br>\n<a href=\"https://psycnet.apa.org/record/2017-24133-001\" rel=\"nofollow noreferrer\">https://psycnet.apa.org/record/2017-24133-001</a></p>\n", "pids": ["5724cf240cf2952b60b72a51", "5c755963f56def97987bbd7e", "58ca7b320cf2b22b9fa3e60e", "573350320cf2704310d619cc", "55a6411d65ce054aad61ce12", "58ca7a540cf2b22b9fa3e1a2", "5ce2d047ced107d4c6360be7", "5c8bb1554895d9cbc6a3eb44", "59d599730cf2bb5427763c8f", "58d4b2dc0cf221de036069c7", "5c7559f5f56def979881999c", "55503f5145ce0a409eb2d6da", "5c86586e4895d9cbc64cb4b6", "57a4e932ac44365e35c9bdb3", "5c757d2bf56def9798ab2423", "58d554040cf210d30c5aa80b", "5c8bd3e14895d9cbc6b008fa", "5c756deef56def979857c011", "5fc77839a84b2957c5b93f94", "56d91050dabfae2eee37367e", "565711560cf20caa7d69652a", "565862800cf2ac45f629eca3", "58ca74bc0cf2b22b9fa3c6b9", "5e09a8c3df1a9c0c4169338e", "56d83b95dabfae2eee628411", "55a6b9d265ce054aad72d1b7"], "flag": 1}
{"question": "What were the first areas of research and what were some early successes?", "body": "<p>What were the first areas of research into Artificial Intelligence and what were some early successes?  More recently we've had:</p>\n\n<ol>\n<li>Beating a human at the game of chess</li>\n<li>Convincing a human that a person was conversing with them (passing the Turing test)</li>\n<li>Beating a human at Jeopardy game show</li>\n<li>Beating a human at the game of go.</li>\n</ol>\n\n<p>Were there milestones that were considered major in the field before the 1990s?</p>\n", "pids": ["53e9b124b7602d9703ba30c5"], "flag": 1}
{"question": "Why is it harder to achieve good results using neural network based algorithms for multi step time series forecasting?", "body": "<p>There are different kinds of machine learning algorithms, both univariate and multivariate, that are used for time series forecasting: for example ARIMA, VAR or AR.</p>\n\n<p>Why is it harder (compared to classical models like ARIMA) to achieve good results using neural network based algorithms (like ANN and RNN) for multi step time series forecasting?</p>\n", "pids": ["56d8c9e6dabfae2eee6cc4c1"], "flag": 1}
{"question": "Will BERT embedding be always same for a given document when used as a feature extractor", "body": "<p>When we use BERT embeddings for a classification task, would we get different embeddings every time we pass the same text through the BERT architecture? If yes, is it the right way to use the embeddings as features? Ideally, while using any feature extraction technique, features values should be consistent. How do I handle this if we want BERT to be used as a feature extractor?</p>\n", "pids": ["599c7987601a182cd2648373"], "flag": 1}
{"question": "How does fluoride prevent tooth decay?", "body": "<p>Fluoride is a common active ingredient in tooth paste to prevent dental caries. It is also added or removed from the water supply in some communities for the same reason, but in children only.</p>\n\n<p>My understanding is that the fluoride in tooth paste reacts with minerals in saliva then bonds to the tooth enamel. The fluoride in water is ingested and is somehow added to the developing bones and teeth of growing children, to the benefit of making decay resistant teeth.</p>\n\n<p>What is the biochemical pathway of each process? A perfect answer will also discuss fluorosis and when that occurs and why. </p>\n", "pids": ["53e9b4bfb7602d9703fdaa0e", "55a5219a65ceb7cb02e1d4e3", "55a5f62065cead59c8316cab"], "flag": 1}
{"question": "Tests for alertness", "body": "<p>Have there been any researched paper or digital tests developed that test a persons alertness at a given point in time? By alert I mean having the reactions of a person who is not over-tired, intoxicated, with a disability that inhibits reaction time, etc.</p>\n\n<p>Edit:</p>\n\n<p>I didn't see my answer in <a href=\"http://www.optalert.com/news/dr-johns-drowsiness-detection-technology-pharmaceutical-industry\" rel=\"nofollow noreferrer\">http://www.optalert.com/news/dr-johns-drowsiness-detection-technology-pharmaceutical-industry</a> . </p>\n\n<p>I am interested in a digital or paper test.</p>\n", "pids": ["6217099e5aee126c0ffc245d", "55a5499f65ceb7cb02e704d9", "56fbde0f0cf2cd3b44e4a0d8", "55a45bed612ca6486893a2d8", "55a44ab8612ca6486890652d"], "flag": 1}
{"question": "Bounds on skew and kurtosis of IQ", "body": "<p>The question of whether IQ is Normally distributed, or instead follows e.g. a Pearson type IV distribution, has been debated since at least the 1910s. The quotient- and deviation-based definitions give rise to very different eras in that debate, of course. (However, the distribution of an integer-valued IQ cannot be exactly Normal, even on a deviation-based definition.) A Normal distribution is uniquely characterised by its mean <span class=\"math-container\">$\\mu$</span> and standard deviation <span class=\"math-container\">$\\sigma$</span>. Its next two moments are the skew <span class=\"math-container\">$\\gamma_1=0$</span> and excess kurtosis <span class=\"math-container\">$\\kappa_\\text{excess}=0$</span>. To disambiguate, I've defined</p>\n\n<p><span class=\"math-container\">$$\\gamma_1=\\mathbb{E}\\bigg(\\tfrac{X-\\mu}{\\sigma}\\bigg)^3,\\,\\kappa_\\text{excess}:=\\mathbb{E}\\bigg(\\tfrac{X-\\mu}{\\sigma}\\bigg)^4-3.$$</span></p>\n\n<p>By contrast, a Pearson type IV distribution requires all four moments to be specified.</p>\n\n<p>While we can't literally prove <span class=\"math-container\">$\\gamma_1=\\kappa_\\text{excess}=0$</span> empirically, we can constrain such quantities. Have any empirical studies provided either upper or lower bounds on these moments of the IQ distribution (or something analogous such as another quantification estimating psychometric <span class=\"math-container\">$g$</span>), on either the quotient or deviation definition? In the interests of keeping this question appropriate to the site, I don't care what method of defining or measuring IQ was assumed in a particular study, so there's no need to take a stance on that.</p>\n", "pids": ["56d92b3fdabfae2eeed9d2d8"], "flag": 1}
{"question": "Why isn&#39;t high functioning autism recognized by the DSM-5 or the ICD-10?", "body": "<p>I was looking at this <a href=\"https://en.m.wikipedia.org/wiki/High-functioning_autism\" rel=\"nofollow noreferrer\">https://en.m.wikipedia.org/wiki/High-functioning_autism</a> and it said that. Aspergers is also closely related to high functioning autism but it is also not recognized anymore. Does this mean that neither of them are a \"thing\" anymore? Would diagnosing someone with either of these labels be inaccurate?</p>\n", "pids": ["5c13680cda56295a08a0ec73", "5c7559c9f56def97987fe011", "53e99fe4b7602d97028bfdde", "55a5381c65ceb7cb02e4eb6b", "55a4e80d65ceb7cb02db9f73", "55a4739265ce31bc877b3c3c"], "flag": 1}
{"question": "How will the pet therapy aid the child with autism?", "body": "<p>As a <strong>Special Education Teacher at ACCEL</strong>, behaviors of individuals with autism has been remarkably consistent over time with the help of ABA therapy services, which include pet therapy and individualized education program.</p>\n\n<p>What are your thoughts about pet therapy for this population? How is it proven to be beneficial?</p>\n", "pids": ["55a4f90265ceb7cb02dd7987"], "flag": 1}
{"question": "Body temperature increasing when trying to solve difficult problems", "body": "<p>[ <em>I am unsure if this is the correct site to ask this question</em> ]<br><br> \nI am a HS student, currently studying IT and personally I focus on the field of software (programming) and of course where there is programming there are problems which require you to have the skills to solve problems that occur. So I wanted to improve my skills by trying to solve problems and I've been doing some on <a href=\"http://hackerrank.com\" rel=\"nofollow noreferrer\">hackerrank</a>. </p>\n\n<p>However, whenever i try to solve a problem which is difficult to me and that I'm not capable of understanding it, I begin \"<em>overheating</em>\", literally. This keeps me from taking further steps to learn about the problems and different ways to approach to the solution. Basically, I feel  like a moron and stop working on the problem. </p>\n\n<p><strong>my question to you is, why do I \"overheat\" (body temp. increases) when i try to solve problems that are difficult to me?</strong></p>\n\n<p>is it because I don't have a goal which motivates me hard enough or am I just... a moron ? <br>Is there are way to \"turn off\" this overwhelming feeling?</p>\n\n<p>EDIT :</p>\n\n<p>After some more research i've come across this article which I believe could be the <a href=\"https://www.mybrainsolutions.com/library/2014/04/breaking-down-the-feeling-of-overwhelmed/\" rel=\"nofollow noreferrer\">answer</a> to my question (not sure).</p>\n", "pids": ["5a14e1540cf2dcc70c057f65", "621682bc5aee126c0ff947b0", "56d8df49dabfae2eee07972c"], "flag": 1}
{"question": "What is the basis of the belief that modern psychology demonstrates that words themselves can be hurtful and verbal aggression should be wed out?", "body": "<p>I'm sorry for the length of this question, but to ask it I'll need to refer to two concepts.</p>\n\n<p>Firstly, we see the escalating trend to weed out any and all examples of even very minor negativity or aggression in words. Those are deemed unacceptable, addressees of such messages may be called 'victims', and telling people to 'grow a thicker skin' is explicitly declared a non-solution to the problem. Examples of this are many: StackExchange's new Code of Conduct, strict rules of communication Riot Games is trying to enforce in League of Legends, punishing people for jokes, firing employees for not being nice enough to their colleagues, etc etc.</p>\n\n<p>It is claimed that such policies are backed up by modern psychology:</p>\n\n<blockquote>\n  <p>One major mistake in this reasoning is \"unlike with sticks and stones, with words the addressees have the choice: to accept the message or to drop it\". They do not, the message will be received and the emotional reaction will happen, emotions are not subject to conscious control. One can choose to \"get over it\", but the same can be said of sticks and stones, so the real issue is the damage assessment. One reason for the new consensus is the undermining of folk misconceptions that heavily weigh physical damage over emotional one (as in the saying) by modern psychology.</p>\n</blockquote>\n\n<p>-- <a href=\"https://philosophy.stackexchange.com/questions/55866/what-is-the-basis-of-the-belief-that-words-themselves-can-be-hurtful-and-verbal?noredirect=1#comment150979_55866\">@Conifold</a></p>\n\n<blockquote>\n  <p>Humans are social creatures. If a grief stricken person can be consoled by words and interactions. Why would you not expect the opposite to be equally effective that is turning a happy person depressed and mentelly unwell? To say that people should just \"ignore it\" is to assign all blame to the victim but that's not fair and ignores everything we know about human behaviour.</p>\n</blockquote>\n\n<p>-- <a href=\"https://philosophy.stackexchange.com/questions/55866/what-is-the-basis-of-the-belief-that-words-themselves-can-be-hurtful-and-verbal?noredirect=1#comment150983_55866\">@Cell</a></p>\n\n<p>Here I have to jump for a short while to the second concept... Monika and Marcin Gajda, in their book \"Rozwój. Jak współpracować z łaską\" (which is a Polish book on self-development that claims to be based on psychology and is written from an extensive Christian angle) introduces the concept of \"emotional sovereignty\". It distinguishes five levels of this sovereignty:</p>\n\n<ol>\n<li><strong>Submission.</strong> For example, if a bum insults me, I'll have the rest of my day screwed because I'll think how useless I must be that even a bum holds me in contempt.</li>\n<li><strong>Entering a symmetrical conflict.</strong> Here I'll insult back the bum or even start physically fighting him to defend my good name.</li>\n<li><strong>Ignoring aggressively.</strong> Here, feeling superior to the bum, I'll walk away, maybe mumbling something silently to myself.</li>\n<li><strong>Assertiveness.</strong> As described by modern psychology.</li>\n<li><strong>Merciful love.</strong> Told you the book is written with an extensive Christian angle. Here, with no contempt, feelings of superiority, aggression, urges of vengeance, or anything of this sort on my side, I'll look at the bum with compassion, seeing how miserable he must be to behave that way.</li>\n</ol>\n\n<p>The book claims that people can - and should - work themselves from the lower levels to the higher levels, for their own good. Staying on the lower levels is harmful, also from the psychological point of view, for the people who stay there. Also the book claims that a person may be on different levels in relation to different people: for example, a person may be on the 5th level with regard to this exemplary 'bum', but on the lowest level with regard to one's own mother. (Important: This self-development is not supposed to include trying to control one's own emotions).</p>\n\n<p>And here is where the two concepts meet, at least in my mind. If such 'abusive' words and messages are treated as 'big deal', if growing a thicker skin is not to be advised, if, having received such messages, the correct action to take is deemed to be to report the offender to whoever is in charge of the community, if, as psychologists want, not attempting to stop receiving these messages is not respecting oneself enough… Then such beliefs and policies seem to me to hurt, rather than protecting, 'victims' of verbal abuse, because effectively they teach them to stay at the lower levels of emotional sovereignty. If, instead of attempting to cleanse the word of all verbal 'negativity', the emphasis was on empowering the addressees of such messages to be 'sovereign' over them, then the old adage that '<em>sticks and stones can break my bones, but words can never hurt me</em>' would become true. On the other hand, the current emphasis of fighting the 'abusive' messages themselves seems to me to give the abusers the power to actually hurt the receivers of the verbal abuse: and that's a lot of power to place in improper hands.</p>\n\n<p>I understand that my reasoning may be very well wrong, as the general consensus seems to be in the opposite. Then do both models not contradict themselves, regardless of whatever would seem to me to be the case? Or is Gajdowie's model of emotional sovereignty wrong?</p>\n\n<p>EDIT: Just to clarify: The precise point that is hard to reconcile for me is this one: It is impossible for the receiver of the 'abusive' messages to avoid being damaged by such messages (the quoted comments) vs it is possible (Gajdowie)</p>\n", "pids": ["53e9ad11b7602d97036efa0c", "53e9a6e0b7602d9703017ebd", "55a6a0d865ce054aad6e6cd3", "53e99fefb7602d97028ccedb"], "flag": 1}
{"question": "Variational Autoencoder task for better feature extraction", "body": "<p>I have a CNN with the regression task of a single scalar.\nI was wondering if an additional task of reconstructing the image (used for learning visual concepts), seen in a DeepMind <a href=\"https://youtu.be/yV698Fi2XzE\" rel=\"nofollow noreferrer\">presentation</a> with the loss and re-parametrization trick of Variational Autoencoder, might help the principal task of regression.</p>\n\n<p>So you can imagine some convolutions with the role of feature extraction with some output X (let's say a vector of 256 values), that X goes into the VAE which computes Z and then the reconstructed image. And then the original regression task would take either X or Z in order to compute that scalar value.</p>\n\n<p>Has anyone tried such an approach, is it worth the work?\nThank you</p>\n", "pids": ["5a260c8617c44a4ba8a31c85"], "flag": 1}
{"question": "Are there neural networks that accept graphs or trees as inputs?", "body": "<p>As far I know, the RNN accepts a sequence as input and can produce as a sequence as output.</p>\n\n<p>Are there neural networks that accept graphs or trees as inputs, so that to represent the relationships between the nodes of the graph or tree?</p>\n", "pids": ["5c5ce4fd17c44a400fc38742", "58437722ac44360f1082efeb", "5736960c6e3b12023e51ee06", "58d83051d649053542fe9c38", "5e807d589fced0a24b30b594"], "flag": 1}
{"question": "Does the Rubik&#39;s Cube increase mental ability?", "body": "<p>Does becoming efficient in the <a href=\"https://eu.rubiks.com/\" rel=\"nofollow noreferrer\">cube</a> help build your brain to be able to do other tasks better? What tasks and how?</p>\n", "pids": ["56d85721dabfae2eee316505"], "flag": 1}
{"question": "How fast can stimuli be administered for evoked potentials?", "body": "<p>I'm looking for a reference about the ability for sensory stimuli to generate separate evoked potentials in the brain. </p>\n\n<p><strong>What is the maximum repetition rate for sensory evoked potentials?</strong></p>\n", "pids": ["53e9b6e8b7602d9704277063"], "flag": 1}
{"question": "Is there any difference between a control and an action in reinforcement learning?", "body": "<p>There are reinforcement learning papers (e.g. <a href=\"https://arxiv.org/pdf/1705.02670.pdf\" rel=\"nofollow noreferrer\">Metacontrol for Adaptive Imagination-Based Optimization</a>) that use (apparently, interchangeably) the term <em>control</em> or <em>action</em> to refer to the effect of the agent on the environment at each time step. </p>\n\n<p>Is there any difference between the terms <em>control</em> or <em>action</em> or are they (always) used interchangeably? If there is a difference, when is one term used as opposed to the other?</p>\n\n<p>The term control likely comes from the field of optimal control theory, which is related to reinforcement learning.</p>\n", "pids": ["5b67b4b417c44aac1c8678f9"], "flag": 1}
{"question": "How does RL based neural architecture search work?", "body": "<p>I have read through many of the papers and articles linked in <a href=\"https://ai.stackexchange.com/questions/12434/how-is-neural-architecture-search-performed\">this thread</a> but I haven't been able to find an answer to my question.</p>\n\n<p>I have built some small RL networks and I understand how REINFORCE works. I don't quite understand how they are applied to NAS though. Usually RL agents map a <a href=\"https://en.wikipedia.org/wiki/File:Reinforcement_learning_diagram.svg\" rel=\"nofollow noreferrer\">state to an action</a> and get a reward so they can improve their decision making (which action to choose). I understand that the reward comes from the accuracy of the child network and the action is a series of digits encoding the network architecture. </p>\n\n<p>What is passed as the state to the RL agent? This doesn't seem to be mentioned in the papers and articles I read. Is it the previous network? Example input data?</p>\n", "pids": ["58d82fc8d649053542fd59b8"], "flag": 1}
{"question": "Looking for a paper: AI in human host", "body": "<p>I am searching for a paper where participants were confronted with a (female) person, who gave answers according to a computer algorithm. She had an earpiece that gave her the answers and was trained to simultaneously listen and speak.</p>\n\n<p>Some participants thought that she was acting a bit off, but none recognized that they are talking to a computer. I think the aim of the study was some sort of turing test. </p>\n\n<p>Hope anyone can help me find it. I don't know how to look for it anymore...</p>\n", "pids": ["56d831abdabfae2eee266995"], "flag": 1}
{"question": "Can we optimize an optimization algorithm?", "body": "<p>In <a href=\"https://ai.stackexchange.com/a/13543/2444\">this answer</a> to the question <a href=\"https://ai.stackexchange.com/q/13524/2444\">Is an optimization algorithm equivalent to a neural network?</a>, the author stated that, in theory, there is some recurrent neural network that implements a given optimization algorithm.</p>\n<p>If so, then can we optimize the optimization algorithm?</p>\n", "pids": ["599c796a601a182cd263ad68"], "flag": 1}
{"question": "What parameters can be tweaked to avoid a generator or discriminator loss collapsing to zero when training a DC-GAN?", "body": "<p>Sometimes when I am training a DC-GAN on an image dataset, similar to the DC-GAN PyTorch example (<a href=\"https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\" rel=\"nofollow noreferrer\">https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html</a>), either the Generator or Discriminator will get stuck in a large value while the other goes to zero. How should I interpret what is going on right after iteration 1500 in the example loss function image shown below <a href=\"https://i.stack.imgur.com/AElrJ.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/AElrJ.png\" alt=\"DC-GAN Training Loss\"></a>? Is this an example of mode collapse? Any recommendations for how to make the training more stable? I have tried reducing the learning rate of the Adam optimizer with varying degrees of success. Thanks!</p>\n", "pids": ["5ac1829d17c44a1fda918047", "5a9cb65d17c44a376ffb8358"], "flag": 1}
{"question": "Is is possible to &quot;delete&quot; a memory permanently?", "body": "<p>If cognitive memory is compared to computer memory, then is it possible to purposefully and permanently forget a specific memory, using known technologies and methodologies?</p>\n", "pids": ["5c51029de1cd8eb0c958a7af", "5ea014229fced0a24b9f6efc", "5c757e2bf56def9798b5f63d"], "flag": 1}
{"question": "How can AI be used to design UI Interfaces?", "body": "<p>I'm very new to AI.  I read somewhere that AI can be used to create GUI UI/UX design. That has fascinated me for a long time. But, since I'm very new here, I don't have any idea how it can happen. </p>\n\n<p>The usual steps to create the UI Design are:</p>\n\n<ul>\n<li>Create Grids.</li>\n<li>Draw Buttons/Text/Boxes/Borders/styles.</li>\n<li>Choose Color Schemes.</li>\n<li>Follow CRAP Principle (Contrast, Repeatition, Alignment, Proximity)</li>\n</ul>\n\n<p>I wonder how can AI algorithms help with that. I know a bit of neural networking and the closest I can think of is the following two methods (Supervised Learning).</p>\n\n<ol>\n<li><p>Draw grids manually and train the Software manually to learn proper styles until it becomes capable of giving modern results and design its own design language.</p></li>\n<li><p>Take a list of a few websites (for example) from the internet and let the software learn and explore the source code and CSS style sheets and learn and program neurons manually until it becomes capable of making it's own unique styles.</p></li>\n</ol>\n", "pids": ["599c7977601a182cd2640aae"], "flag": 1}
{"question": "Can I use self-driving car&#39;s data set for left-hand drive cars which drive on the right lane for right-hand cars which drive on the left lane?", "body": "<p>Can I use self-driving car's data set for left-hand drive cars which drive on the right lane for right-hand self-driving cars which drive on the left lane?</p>\n", "pids": ["5cede0f7da562983788d5f42"], "flag": 1}
{"question": "Are there any papers where two (or more) authors share the same full name?", "body": "<p>Because of <a href=\"https://github.com/Langenscheiss/bibitnow/issues/59\" rel=\"nofollow noreferrer\">reasons</a>, I'm curious to know whether there are any simple examples of papers where two or more authors have the same full name.</p>\n<p>(To be clear: I am <em>only</em> interested in <em>exact</em> full-name matches. Instances where authors share a last name are so common as to be completely unremarkable, and instances where the first name matches but additional initials distinguish the authors are also reasonably common and <em>not</em> what I'm looking for.)</p>\n<p>Does anybody have any particular pointers that can be useful?</p>\n", "pids": ["5fd9dc6bd4150a363c7e49ec"], "flag": 1}
{"question": "How to evaluate an RL algorithm when used in a game?", "body": "<p>I'm planning to create a web-based RL board game, and I wondered how I would evaluate the performance of the RL agent. How would I be able to say, &quot;Version X performed better than version Y, as we can see that Z is much better/higher/lower.&quot;</p>\n<p>I understand that we can use convergence for some RL algorithms, but, if the RL is playing against a human in the game, how am I able to evaluate its performance properly?</p>\n", "pids": ["5c615e59e1cd8eae15018673"], "flag": 1}
{"question": "Efficiency of multitasking depending on task difficulty", "body": "<p>How does the efficiency of multi-tasking differ by task type? My understanding is that multitasking impairs efficiency for cognitively challenging tasks.</p>\n\n<p>Does this apply to trivial tasks as well?</p>\n", "pids": ["57a4e8f9ac44365e35c94515", "53e9aea4b7602d97038c8b40", "53e9a48db7602d9702da9d88"], "flag": 0}
{"question": "Iteratively and adaptively increasing the network size during training", "body": "<p>For an experiment that I'm working on, I want to train a deep network in a special way. I want to initialize and train a small network first, then, in a specific way, I want to increase network depth leading to a bigger network which is subsequently to be trained. This process will be repeated until one reaches the desired depth.</p>\n<p>It would be great if anybody heard of anything similar and could point out to me some related work. I think in some paper I read something about a related technique where people used something similar, but I don't find it anymore.</p>\n", "pids": ["57d063d8ac44367354292dd3"], "flag": 1}
{"question": "Algorithms for scene rotation", "body": "<p>My goal is to take an image and return another image that looks as if the scene was viewed from another angle.  The difference in angle can be small — let's say as if the hand holding the camera moved slightly sideways.</p>\n", "pids": ["53e99dabb7602d970266b3ae", "599c7968601a182cd263a269"], "flag": 1}
{"question": "How to implement SVM algorithm from scratch in a programming language?", "body": "<p>I'm a computer scientist who's studying support vector machines (SVMs) in a machine learning course. I have some understanding of how SVMs are designed, thanks to <a href=\"https://www.youtube.com/watch?v=_PwhiWxHK8o\" rel=\"nofollow noreferrer\">16. Learning: Support Vector Machines - MIT</a>. However, what I'm not understanding is the transition from the optimization problem of the Lagrangian function to its implementation in any programming language. Basically, what I need to understand is how to build, from scratch, the decision function, given a training set. In particular, how do I find Lagrange multipliers in order to know which points are to be considered to define support vectors and the decision function?</p>\n<p>Can anyone explain this to me?</p>\n", "pids": ["55a6987e65ce054aad6d0b87"], "flag": 1}
{"question": "Can we combat against deepfakes?", "body": "<p>I came across 'Amber'(<a href=\"https://ambervideo.co/\" rel=\"nofollow noreferrer\">https://ambervideo.co/</a>) where they are claiming that they have trained their AI to find patterns emerging due to artificially created videos which are invisible to naked eye. </p>\n\n<p>I am wondering that the people who are creating deepfakes can as well their AI's to remove these imperfections and so the problem reduces to 'cat-mouse' game where having more resources(to train their AI) is more crucial.</p>\n\n<p>I do not work in AI and vision and so I may be missing some trivial points in the area. I would really appreciate if detailed explanation or relevant resources are given.</p>\n\n<p>Edit: Most of the people who do manipulate the media news or create fake news could afford more resources than an average citizen. So, is the future is really going to be dark where only few strong have even more control on the society than today?</p>\n\n<p>I mean even though there are fake photos created by photo shop, most of the good photo-shopped photos do take a long time to make. But if AIs can be trained to do that then it is more about having large resources. Are there related works which give hope to know real from fakes?</p>\n\n<p>P.S.: I realize that after the edit, the question also went tangential to the topic-tags here. Please let me if there are relevant tags.</p>\n", "pids": ["573697836e3b12023e66a333"], "flag": 1}
{"question": "Can a brain be modeled as a simplified interaction of different states and their triggers?", "body": "<p>I've long been interested in the concept of \"states of mind\", which influence the perception of the outside world and outlook on past, present and future. They can be thought of as \"colored lenses\" through which the world is perceived. Each state has a certain trigger. Some example states are:</p>\n\n<ul>\n<li>Anxiety - world is a terrible place full of danger</li>\n<li>Sexual arousal  - brain notices sexual stimuli more and reduces inhibitions</li>\n<li>Creative inspiration - ideas fly and there's a drive to create</li>\n</ul>\n\n<p>Today I've read about an <a href=\"http://www.thestandarddaily.com/scientists-claim-that-they-have-successfully-recreated-a-portion-of-a-rat-brain-in-a-supercomputer/6211/\" rel=\"nofollow noreferrer\">experiment to replicate a part of a rat brain in supercomputer</a>. The following quote jumped at me as rather significant:</p>\n\n<blockquote>\n  <p>The researchers wrote, that the slow synchronous waves of neuronal\n  activity, which have been found in the brain during sleep, were\n  ‘triggered’ during the simulations, <strong>suggesting that neural circuits\n  may have the unique ability to able to switch into different ‘modes’\n  that could explain critical behaviours.</strong></p>\n  \n  <p>“An analogy would be a computer processer that can reconfigure to\n  focus on certain tasks. The experiments suggest the existence of a\n  <strong>spectrum of states</strong>, so this raises new types of questions, such as\n  ‘what if you’re stuck in the wrong state?” said Markram.</p>\n</blockquote>\n\n<p>I read that the project is criticized due to it's complexity, seems like they are working from the bottom up, which makes me ask:</p>\n\n<p><strong>Are there projects out there that attempt to model the brain from the higher levels of abstraction (discrete states and their triggers) down to more detail?</strong></p>\n\n<p>To use a computer analogy - instead of writing very low level binary code, I can take a high level programming library and work with that. Is there research in this direction?</p>\n\n<p>This image is an example of a state machine - a system is modelled in terms of discrete states and their interactions. The author does not concern themselves with interaction of individual neurons, instead with higher level states:</p>\n\n<p><a href=\"https://i.stack.imgur.com/hR3qy.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/hR3qy.jpg\" alt=\"enter image description here\"></a></p>\n", "pids": ["60b0cacae4510cd7c8eaf338"], "flag": 0}
{"question": "Are embeddings in multi-lingual language models comparable across languages?", "body": "<p>Facebook has <a href=\"https://arxiv.org/pdf/1911.02116.pdf\" rel=\"nofollow noreferrer\">just pushed out</a> a bigger version of their multi-lingual language model XLM, called XLM-R. My question is: do these kind of multi-lingual models imply, or even ensure, that their embeddings are comparable between languages? That is, are semantically related words close together in the vector space across languages?</p>\n\n<p>Perhaps the most interesting citation from the paper that is relevant to my question (p. 3):</p>\n\n<blockquote>\n  <p>Unlike Lample and Conneau (2019), we do not use language embeddings,\n  which allows our model to better deal with code-switching.</p>\n</blockquote>\n\n<p>Because they do not seem to make a distinction between languages, and there's just one vocabulary for all trained data, I fail to see how this can be truly representative of semantics anymore. The move away from semantics is increased further by the use of BPE, since morphological features (or just plain, statistical <em>word chunks</em>) of one language might often not be semantically related to the same chunk in another language - this can be true for tokens themselves, but especially so for subword information.</p>\n\n<p>So, in short: how well can the embeddings in multi-lingual language models be used for semantically comparing input (e.g. a word or sentence) of two different languages?</p>\n", "pids": ["5d04e8e0da56295d08db6333"], "flag": 1}
{"question": "Is tabular Q-learning considered interpretable?", "body": "<p>I am working on a research project in a domain where other related works have always resorted to deep Q-learning. The motivation of my research stems from the fact that the domain has an inherent structure to it, and should not require resorting to deep Q-learning. Based on my hypothesis, I managed to create a tabular Q-learning based algorithm which uses limited domain knowledge to perform on-par/outperform the deep Q-learning based approaches.</p>\n\n<p>Given that model <em>interpretability</em> is a subjective and sometimes vague topic, I was wondering if my algorithm should be considered interpretable. The way I understand it, the lack of interpretability in deep-learning-based models stems from the stochastic gradient descent step. However, in case of tabular Q-learning, every chosen action can always be traced back to a finite set of action-value pairs, which in turn are a deterministic function of inputs of the algorithm, although over multiple training episodes.</p>\n\n<p>I believe in using deep-learning-based approaches conservatively only when absolutely required. However, I am not sure how to justify this in my paper without wading into the debated topic of model interpretability. I would greatly appreciate any suggestions/opinions regarding this. </p>\n", "pids": ["5aed14d617c44a4438158eb7", "5cede0f8da562983788d724d", "5d04e8eeda56295d08dc3559"], "flag": 1}
{"question": "What do the subscripts mean in $N_{t,n,\\sigma,L}$?", "body": "<p>A neural network can apparently be denoted as <span class=\"math-container\">$N_{t,n,\\sigma,L}$</span>. What do these subscripts  <span class=\"math-container\">$t, n, \\sigma$</span> and <span class=\"math-container\">$L$</span> mean? Could you link me to a paper, article or webpage with an explanation for this? </p>\n", "pids": ["5550417a45ce0a409eb3ba8b"], "flag": 1}
{"question": "When exactly is a model considered over-parameterized?", "body": "<p>When exactly is a model considered over-parameterized?</p>\n<p>There are some recent researches in Deep Learning about the role of over-parameterization toward generalization, so it would be nice if I can know what exactly can be considered as such.</p>\n<p>A hand-wavy definition is: over-parameterized model is often used to described when you have a model bigger than necessary to fit your data.</p>\n<p>In some papers (for example, in <a href=\"https://arxiv.org/pdf/1811.03962.pdf\" rel=\"nofollow noreferrer\">A Convergence Theory for Deep Learning\nvia Over-Parameterization</a>), over-parameterization is described as:</p>\n<blockquote>\n<p>they have much more parameters than the number of training samples</p>\n<p>meaning that the number of neurons is polynomially large comparing to the input size</p>\n<p>the network width is sufficiently large: polynomial in <span class=\"math-container\">$L$</span>, the number of layers, and in <span class=\"math-container\">$n$</span>, the number of samples</p>\n</blockquote>\n<p>Shouldn't this definition depend on the type of input data as well?</p>\n<p>For example, I fit:</p>\n<ul>\n<li><p>1M-parameters model on 10M samples of 2 binary features, then it should not be over-parameterized, or</p>\n</li>\n<li><p>1M-parameters model on 0.1M samples of 512x512 images, then is over-parameterized, or</p>\n</li>\n<li><p>the model in the paper <a href=\"https://research.fb.com/wp-content/uploads/2018/05/exploring_the_limits_of_weakly_supervised_pretraining.pdf\" rel=\"nofollow noreferrer\">Exploring the Limits of\nWeakly Supervised Pretraining</a> &quot;IG-940M-1.5k ResNeXt-101 32×48d&quot; with 829M parameters, trained on 1B Instagram images, is not over-parameterized</p>\n</li>\n</ul>\n", "pids": ["5d79a4dc3a55ac5af95adb8a"], "flag": 1}
{"question": "Are current AI models sufficient to achieve Artificial General Intelligence?", "body": "<p>I read an interesting <a href=\"https://aeon.co/essays/how-close-are-we-to-creating-artificial-intelligence\" rel=\"nofollow noreferrer\">essay</a> about how far we are from AGI. There were quite a few solid points that made me re-visit the foundation of AI today. A few interesting concepts arose:</p>\n<blockquote>\n<p>imagine that you require a program with a more ambitious functionality: to address some outstanding problem in theoretical physics — say the nature of Dark Matter — with a new explanation that is plausible and rigorous enough to meet the criteria for publication in an academic journal.</p>\n<p>Such a program would presumably be an AGI (and then some). But how would you specify its task to computer programmers? Never mind that it’s more complicated than temperature conversion: there’s a much more fundamental difficulty. Suppose you were somehow to give them a list, as with the temperature-conversion program, of explanations of Dark Matter that would be acceptable outputs of the program. If the program did output one of those explanations later, that would not constitute meeting your requirement to generate new explanations. For none of those explanations would be new: you would already have created them yourself in order to write the specification. So, in this case, and actually in all other cases of programming genuine AGI, only an algorithm with the right functionality would suffice. But writing that algorithm (without first making new discoveries in physics and hiding them in the program) is exactly what you wanted the programmers to do!</p>\n</blockquote>\n<p>The concept of creativity seems like the initial thing to address when approaching a true AGI. The same type of creativity that humans have to ask the initial question or generate new radical ideas to long-lasting questions like dark matter.</p>\n<p>Is there current research being done on this?</p>\n<p>I've seen work with generating art and music, but it seems like a different approach.</p>\n<blockquote>\n<p>In the classic ‘brain in a vat’ thought experiment, the brain, when temporarily disconnected from its input and output channels, is thinking, feeling, creating explanations — it has all the cognitive attributes of an AGI. So the relevant attributes of an AGI program do not consist only of the relationships between its inputs and outputs.</p>\n</blockquote>\n<p>This is an interesting concept behind why reinforcement learning is not the answer. Without input from the environment, the agent has nothing to improve upon. However, with the actual brain, if you had no input or output, it is still in a state of &quot;thinking&quot;.</p>\n", "pids": ["5d04e90cda56295d08ddd0bc"], "flag": 1}
{"question": "A doctor told me that cephalic index can be used to measure human intelligence, is it true?", "body": "<p>I am roommates with a maxillofacial surgeon. He told me that during his studies he read that cephalic index can be used to measure intelligence.</p>\n\n<p>And he further explained that as Africans and women have smaller brains according to cephalic index, so they are less intelligent than Caucasian and Asian men.</p>\n\n<p>I just want to know how much of this is true, if any? And please explain.</p>\n", "pids": ["53e998a9b7602d97020e4fc8"], "flag": 0}
{"question": "Possible applications of the big five personality traits testing in human resource departments", "body": "<p>I am a multimedia artist who is interning in a human resources department of a casino resort. In the department we have daily meetings to discuss updates to both the orientation and the performance of the casino's employees.</p>\n\n<p>During the discussion I had an idea on maybe using psychometric ( big 5 ) testing for either helping in filtering out unfit candidates for certain positions or/and allocation of time or resources to certain to certain people or group's of people to help them in certain ways or identify problems as to improve the effectiveness of the staff.</p>\n\n<p>My questions are;</p>\n\n<p>1: Can it be used in this way, or what other ways can HR use it?</p>\n\n<p>2: How to go about using it?</p>\n\n<p>3: Will it be effective?</p>\n\n<p>4: Does there exists other companies that use psychometric testing or big 5 for there employees?</p>\n", "pids": ["53e9aab0b7602d970342b18e"], "flag": 1}
{"question": "Which books or papers clearly explain the relation between Ising models and deep neural networks?", "body": "<p>I am looking for a book or paper which clearly explains the relationship between <a href=\"https://en.wikipedia.org/wiki/Hopfield_network\" rel=\"nofollow noreferrer\">Ising models</a> and deep neural networks.</p>\n\n<p>Can anyone provide any references?</p>\n", "pids": ["6030e22baf79179a99681406", "5effabfddfae5482196fb7c0", "61c88f465244ab9dcb76d19a"], "flag": 1}
{"question": "Mathematical foundations of the ability to learn", "body": "<p>I am an undergraduate student in applied mathematics with an interest in artificial intelligence. I am currently exploring topics where I could do research. Coming from a mathematical background I am interested in the question: Can we mathematically establish that a certain AI system has the ability to learn a task given some examples of how it should be done? \nI would like to know what research has been done on this topic and also what mathematical tools could be helpful in answering such questions.</p>\n", "pids": ["53e9a863b7602d97031b010b"], "flag": 1}
{"question": "Immediate reward received in Atari game using DQN", "body": "<p>I am trying to understand the different reward functions modelled in a reinforcement learning problem. I want to be able to know how the temporal credit assignment problem, (where the reward is observed only after many sequences of actions, and hence no immediate rewards observed) can be mitigated. </p>\n\n<p>From reading the DQN paper, I am not able to sieve out how the immediate rewards are being modelled when <span class=\"math-container\">$Q_{target}(s,a; \\theta) = r_s + argmax_aQ(s',a'; \\theta)$</span>. What is <span class=\"math-container\">$r_s $</span> used in the case where the score has not changed ? Therefore what is the immediate rewards being modelled for temporal credit assignment problems in atari game ? </p>\n\n<p>If <span class=\"math-container\">$r_s$</span> is indeed 0 until score changes, would it affect the accuracy of the DQN ? it seems like the update equation would not be accurate if you do not even know what is the immediate reward if you take that action.</p>\n\n<p>What are some of the current methods used to solve the temporal credit assignment problem ?</p>\n\n<p>Also, I can't seem to find many papers that address the temporal credit assignment problem</p>\n", "pids": ["5aed14d117c44a44381589e5"], "flag": 1}
{"question": "What are the best algorithms for image segmentation tasks?", "body": "<p>I recently started looking for networks that focus on image segmentation tasks related to biomedical applications. I could not miss the publication <a href=\"https://arxiv.org/abs/1505.04597\" rel=\"nofollow noreferrer\">U-Net: Convolutional Networks for Biomedical Image Segmentation</a> (2015) by Ronneberger, Fischer, and Brox. However, as deep learning is a fast-growing field and the article was published more than 4 years ago, I was wondering if anyone knows other algorithms that yield better results for image segmentation tasks?  And if so, do they also use a U-shape architecture (i.e. contraction path then expansion path with up-conv)? </p>\n", "pids": ["573696136e3b12023e525e96", "5e9ec4eb9fced0a24b00ae3f", "5aed14e217c44a4438159a13", "5aed14d617c44a4438158f7c", "5d5e6b9a3a55acfce79a16dd"], "flag": 1}
{"question": "Name of cognitive bias where people try to use all given information regardless of quality?", "body": "<p>In psych class, I recall learning about a cognitive bias where people are inclined to use all information available to them when making a decision, even if some of the information would be better ignored.</p>\n\n<p>I believe the example given was a study in which participants were asked to evaluate the (college?) application of a candidate. Some participants were given just the conventional application information, while others were additionally given irrelevant information in the form of a portfolio of the candidate's elementary school artwork. The finding was that the artwork influenced the participant's decisions when it was provided.</p>\n\n<p>What I don't remember is what this bias is called!</p>\n", "pids": ["53e9bcbab7602d9704938a21", "53e99cb5b7602d970256bef7"], "flag": 1}
{"question": "How should I select the features for predicting diseases (in particular when patients specify their health issues)?", "body": "<p>My aim is to train a model for predicting diseases. Now, according to <a href=\"https://en.wikipedia.org/wiki/Disease#Classification\" rel=\"nofollow noreferrer\">this Wikipedia article</a>, diseases are classified based on the following criteria in general:</p>\n<ul>\n<li>Causes (of the disease)</li>\n<li>Pathogenesis (the mechanism by which the disease progresses)</li>\n<li>Age</li>\n<li>Gender</li>\n<li>Symptoms (of the disease)</li>\n<li>Damage (caused by the disease)</li>\n<li>Organ type (e.g. heart disease, liver disease, etc.)</li>\n</ul>\n<p>Are these features used for predicting diseases universally (i.e. all types of diseases)? I don't think so. There can be other attributes as well. For example, traveling in the case of coronavirus.</p>\n<p>So, are there better features for predicting diseases?\nOr which ones among them are better than the others, when patients specify their health issues?</p>\n", "pids": ["5c5ce4fd17c44a400fc38aa8"], "flag": 1}
{"question": "How does a batch normalization layer work?", "body": "<p>I understood that we normalize to <strong>input</strong> features in order to bring them on the same scale so that weights won't be learned in arbitrary fashion and training would be faster. </p>\n\n<p>Then I studied about <strong>batch-normalization</strong> and observed that we can do the normalization for outputs of the <strong>hidden</strong> layers in following way:</p>\n\n<p><strong>Step 1:</strong> normalize the output of the hidden layer in order to have zero mean and unit variance a.k.a. <strong>standard normal</strong> (i.e. subtract by mean and divide by std dev of that minibatch).</p>\n\n<p><strong>Step 2:</strong> rescale this normalized vector to a new vector with new distribution having <span class=\"math-container\">$\\beta$</span> mean and <span class=\"math-container\">$\\gamma$</span> standard deviation, where both <span class=\"math-container\">$\\beta$</span> and <span class=\"math-container\">$\\gamma$</span> are trainable.</p>\n\n<p>I did not understand the <strong>purpose of the second step</strong>. Why can't we just do the first step, make the vector standard normal, and then move forward? Why do we need to rescale the input of each hidden neuron to an arbitrary distribution which is learned (through beta and gamma parameters)?</p>\n", "pids": ["573696ce6e3b12023e5ce95a", "5c80f459e1cd8e544cae2003", "622884015aee126c0fe3488d"], "flag": 1}
{"question": "How to calculate the confidence of a classifier&#39;s output?", "body": "<p>I'm training a classifier and I want to collect incorrect outputs for human to double check.</p>\n\n<p>the output of the classifier is a vector of probabilities for corresponding classes. for example, [0.9,0.05,0.05]</p>\n\n<p>This means the probability for the current object being class A is 0.9, whereas for it being the class B is only 0.05 and 0.05 for C too.</p>\n\n<p>In this situation, I think the result has a high confidence. As A's probability dominants B's and C's.</p>\n\n<p>In another case, [0.4,0.45,0.15], the confidence should be low, as A and B are close. </p>\n\n<p>What's the best formula to use to calculate this confidence?</p>\n", "pids": ["5cede108da562983788e7cfc", "599c797a601a182cd2641eda"], "flag": 1}
{"question": "What is the evolutionary advantage of being embarrassed?", "body": "<p>What I am trying to understand is why do I feel embarrassed in certain situation. </p>\n\n<p>E.g. when I'm talking to people, why do I think about being judged or sounding stupid that would result me in embarrassment. I have been considered as \"intelligent\" since I was a kid and may be making or looking stupid goes against my own belief of me being 'intelligent'?</p>\n\n<p>Also, when I'm playing a game or playing music, I think about embarrassing myself, making mistakes and think what may the audience/team mates thinking about me? So I avoid it and when I actually get a chance of play, I make mistake and regret/punish myself mentally for making a mistake or regret quite a bit. So, basically, this results me in being low confident. </p>\n\n<p>I'm thinking about \"impressing people\" and me resulting in an embarrassing situation, acting stupid, sounding stupid would spoil my \"impression\". \nHowever, I want to act stupid or sound stupid sometime and be ok with it. \nSomehow my biology/mind prevents me every time and I feel the resistance. </p>\n\n<p>So, in search of understanding the reason, I wanted to ask if this has any evolutionary benefit or is it part of natural selection? E.g. having a better chances of survival, when you express less/ be quiet or shy, so that others are not threatened by you? </p>\n\n<p>Can anybody with more knowledge shed some light or possibly guide me to help my situation?</p>\n\n<p>Thanks for reading a long post!</p>\n", "pids": ["53e99998b7602d97021da242"], "flag": 1}
{"question": "How important is learning to learn for the development of AGI?", "body": "<p>Some people say that abstract thinking, <a href=\"http://artificial-intuition.com/\" rel=\"nofollow noreferrer\">intuition</a>, common sense, and understanding cause and effect are important to make AGI.</p>\n\n<p>How important is <em>learning to learn</em> for the development of AGI?</p>\n", "pids": ["599c7f09601a182cd28e6395", "5ac1829d17c44a1fda918136", "599c7974601a182cd263f01c", "57a4e921ac44365e35c98f2b"], "flag": 1}
{"question": "What is the difference between emotions, intuition and affect?", "body": "<p>From what I know, intuition is affect-based. But how do they differ? </p>\n", "pids": ["62ac02b05aee126c0fb2f65d", "62ac02b05aee126c0fb2f65d"], "flag": 0}
{"question": "Are there examples of neural networks (used for control) implemented on a FPGA or on a neurochip?", "body": "<p>Greetings to all respected colleagues!</p>\n\n<p>I want to consult on the use of <a href=\"https://en.wikipedia.org/wiki/Field-programmable_gate_array\" rel=\"nofollow noreferrer\">FPGA</a>s and <a href=\"https://en.wikipedia.org/wiki/Neuromorphic_engineering\" rel=\"nofollow noreferrer\">neurochips</a>. I plan to use it in my laboratory project for programming control systems on neural networks. </p>\n\n<p>In my work, there are a lot of applications of neural networks, and I became interested in their programming on FPGAs and neurochips.\nBut I don’t know a single example of a really made and working laboratory prototype in which a neural network is implemented on an FPGA or on a neurochip and controls something. If someone shares the link, I would carefully study it.</p>\n", "pids": ["5f045ed5dfae54570ec4caea"], "flag": 1}
{"question": "Ritalin for treating attention and lack of focus in depression", "body": "<p>I’d like to know if there’s research about the use of ritalin for treating attention deficit in Major Depression Disorder. </p>\n", "pids": ["56d8957fdabfae2eee0b7869", "5c75554af56def9798683173"], "flag": 1}
{"question": "When should I use simulated annealing as opposed to a genetic algorithm?", "body": "<p>What kind of problems is simulated annealing better suited for compared to genetic algorithms?</p>\n\n<p>From my experience, genetic algorithms seem to perform better than simulated annealing for most problems.</p>\n", "pids": ["5c6108d2da56297340b51bf2", "56d9154fdabfae2eee55fb45"], "flag": 1}
{"question": "Could machine learning be used to measure the distance between two objects from a picture or live camera?", "body": "<p>Could machine learning be used to measure the distance between two objects from a picture or live camera? </p>\n\n<p>An example of this is the measurement between the centre of each eye pupil.</p>\n\n<p>This area is all new to me, so any advice and suggestions would be greatly appreciated. </p>\n", "pids": ["5c8f14b54895d9cbc6280e82"], "flag": 1}
{"question": "Reasons why living fossils exist?", "body": "<blockquote>\n  <p>A <a href=\"http://en.wikipedia.org/wiki/Living_fossil\">living fossil</a> is a living species (or clade) that\n  appears to be similar to another species otherwise known only from fossils,\n  typically with no close living relatives.</p>\n</blockquote>\n\n<p>A living fossil is considered as a successful organism, which has made its way through many  major <a href=\"http://en.wikipedia.org/wiki/Extinction_event\">extinction events</a>. Also, the morphology of living fossils resemble some species of organisms which we know only through their fossil remains.</p>\n\n<ul>\n<li><p>What is the reason for a particular type of species to become a living fossil; is the engineering of this particular species extraordinary, in that it can survive any selection process encountered thus far?</p></li>\n<li><p>Is there not enough selection pressure exerted on this species in order to force it to change morphologically?</p></li>\n<li><p>Have these organisms modified themselves, so that currently their morphology seems to be similar to a fossil organism?</p></li>\n</ul>\n", "pids": ["5488e31245ce147a86e289a6"], "flag": 1}
{"question": "Horizontal gene transfer from humans", "body": "<p>It is known that some viruses embed themselves in the human genome. Is there a mechanism by which human genes can be transferred to other animals or plants by means of viruses shuttling them from humans to other organisms?</p>\n", "pids": ["53e9a594b7602d9702ebdcc6"], "flag": 1}
{"question": "What are some good alternatives to U-Net for biomedical image segmentation?", "body": "<p>Soon I will be working on biomedical image segmentation (microscopy images). There will be a small amount of data (a few dozens at best). </p>\n\n<p>Is there a neural network, that can compete with U-Net, in this case? </p>\n\n<p>I've spent the last few hours searching through scientific articles that are dealing with this topic, but haven't found a clear answer and I would like to know what other possibilities are. The best answers I found are that I could consider using <a href=\"https://arxiv.org/abs/1904.00592\" rel=\"nofollow noreferrer\">ResU-Net</a> (R2U-Net), <a href=\"https://arxiv.org/abs/1511.00561\" rel=\"nofollow noreferrer\">SegNet</a>, <a href=\"https://arxiv.org/abs/1812.00548\" rel=\"nofollow noreferrer\">X-Net</a> and backing techniques (<a href=\"https://arxiv.org/ftp/arxiv/papers/1906/1906.10400.pdf\" rel=\"nofollow noreferrer\">article</a>).</p>\n\n<p>Any ideas (with evidence, not necessarily)?</p>\n", "pids": ["5cede10bda562983788eb549"], "flag": 1}
{"question": "If the point of the ResNet skip connection is to let the main path learn the residual relative to identity, why are there convolutional skips?", "body": "<p>In the <a href=\"https://arxiv.org/pdf/1512.03385v1.pdf\" rel=\"nofollow noreferrer\">original ResNet paper</a> they talk about using plain identity skip connections when the input and output of a block have the same dimensions.</p>\n\n<p><a href=\"https://i.stack.imgur.com/pPvVA.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/pPvVA.png\" alt=\"enter image description here\"></a></p>\n\n<p>When the input and output have different dimensions they propose two options:</p>\n\n<p>(A) Use an identity mapping padded with zeros to make up for the extra dimensions</p>\n\n<p>(B) Use a \"projection\".</p>\n\n<p><a href=\"https://i.stack.imgur.com/59wYe.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/59wYe.png\" alt=\"enter image description here\"></a></p>\n\n<p>which (after some digging around in <a href=\"https://towardsdatascience.com/hitchhikers-guide-to-residual-networks-resnet-in-keras-385ec01ec8ff\" rel=\"nofollow noreferrer\">other people's code</a>) I see as meaning: do a convolution with a 1x1 kernel with trainable weights.</p>\n\n<p>(B) is confusing to me because it seems to ruin the point of ResNet by making the skip connection trainable. Then the main path is not really learning a \"residual\" relative to an identity transformation. So at this point, I'm no longer sure how to interpret the intent or expected effect of this type of block. And I would think that one should justify doing it in the first places instead of just not putting a skip connection there at all (which in my mind is the status-quo before this paper).</p>\n\n<p>So can anyone help explain away my confusion here?</p>\n", "pids": ["5736960a6e3b12023e51d5fb"], "flag": 1}
{"question": "Reading material on working conditions of women in academia", "body": "<p>Like many professions, academia is a challenging environment for women. In some disciplines (e.g. computer science), the number of women remains low despite efforts to increase it. Have there been any academic studies on the ways of improving the working conditions for women, specifically focussing on women in academia? As an academic working in hard sciences (i.e. not gender studies), what book or review could I read on the topic, to help me get a better understanding of these issues (and possibly improve my own behavior)?</p>\n\n<p>I'm not interested in “advice” (in part because I am not a woman), but in studies of how effective are various possible ways of improving the working conditions for women (in academia). Like “we study universities implementing policies X and Y, and show that they do increase gender diversity bu xx%”</p>\n\n\n\n<p><em>The question <a href=\"https://academia.stackexchange.com/q/1363/2700\">“Women in academia”</a> is related, but I'm asking for material with a totally different perspective.</em></p>\n", "pids": ["55a4efa865ceb7cb02dc696f"], "flag": 1}
{"question": "Mention impact factor or conference acceptance rate in CV", "body": "<p><strong>Some people, in their CV or publication list, add bibliometric information to each entry.</strong> I've typically seen:</p>\n\n<ul>\n<li>mention the impact factor of each journal</li>\n<li>number of citations of each paper</li>\n<li>mention the acceptance rate of each conference</li>\n</ul>\n\n<p>I'm not sure it is very helpful: people from your field will surely know the journals/conferences, while people from outside your field might be more interested in a “macro” view and not go into the minute details of your publications.</p>\n\n<p>Moreover, I'm not sure I like the tone it conveys: it feels like bragging (this is typically done by people who are proud of these indicators), and a bit over-the-top to me. Finally, it's well accepted by now that things like the journal impact factor are a poor measure of individual papers' merits.</p>\n\n<p>So: <strong>is it accepted practice to do it? does it improve the CV? or does it risk alienating the reader?</strong></p>\n", "pids": ["53e997abb7602d9701f841d7"], "flag": 1}
{"question": "What are some use cases of few-shot learning?", "body": "<p>Besides computer vision and image classification, what other use cases/applications are for few-shot learning?</p>\n", "pids": ["5d0b00098607575390fa53b7"], "flag": 1}
{"question": "Are Q values estimated from a DQN different from a duelling DQN with the same number of layers and filters?", "body": "<p>I am confused about the Q values of a duelling deep Q network (DQN). As far as I know, duelling DQNs have 2 outputs</p>\n\n<ol>\n<li><p>Advantage: how good it is to be in a particular state <span class=\"math-container\">$s$</span></p></li>\n<li><p>Value: the advantage of choosing a particular action <span class=\"math-container\">$a$</span></p></li>\n</ol>\n\n<p>We can make these two outputs into Q values (reward for choosing particular action <span class=\"math-container\">$a$</span> when in state <span class=\"math-container\">$s$</span>) by adding them together.</p>\n\n<p>However, in a DQN, we get Q values from the single output layer of the network. </p>\n\n<p>Now, suppose that I use the same DQN model with the very same weights in my input and hidden layers and changing the output layer which gives us Q values to advantage and value outputs. <em>Then, during training, if I add them together, will it give me the same Q value for a particular state, supposing all the parameters of both my algorithms are the same except for the output layers?</em></p>\n", "pids": ["5736960a6e3b12023e51d96d"], "flag": 1}
{"question": "How might the &quot;Imposter Syndrome&quot; typology be reconciled with the robustness of the &quot;self-serving bias&quot;?", "body": "<p><strong>TL;DR\nWhat on Earth is going on in someone's head to invert a cognitive bias that is robustly observed in people who are psychologically healthy (Cohen's <em>d</em> = 1.28) and still present in depression (Cohen's <em>d</em> = 0.21)? I am looking to reconcile the <em>self-serving bias</em> with either the <em>Imposter Syndrome</em> or <em>mental illness</em>.</strong> </p>\n\n<p><em>\"Some people\"</em>, as the familiar trope notes, <em>“are born on third base and go through life thinking they hit a triple.”</em> While we are all familiar with individuals who are thoroughly unable to accurately attribute the true cause of their achievements, rarely do we ever consider the possibility that we too are guilty of the <em>self-serving bias</em>.</p>\n\n<p>The self-serving bias appears to be both universal and robust. Moreover, an attenuated bias is associated with mental illness:</p>\n\n<p><a href=\"https://i.stack.imgur.com/D8GtY.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/D8GtY.jpg\" alt=\"enter image description here\"></a></p>\n\n<pre><code>Mezulis, A. H., Abramson, L. Y., Hyde, J. S., &amp; Hankin, B. L. (2004). Is \nThere a Universal Positivity Bias in Attributions? A Meta-Analytic   \nReview of Individual, Developmental, and Cultural Differences in the \nSelf-Serving Attributional Bias. Psychological Bulletin, 130(5), 711–747. \nhttps://doi.org/10.1037/0033-2909.130.5.711\n</code></pre>\n\n<p>Others, on the other hand, seem to be afflicted with an attribution bias <em>antipodal</em> to the self-serving bias. These people seem to completely unable  to internalise their achievements as truly their own, and appear to dismissively attribute their successes to external factors most people do for <em>everyone</em> but themselves -- the Imposter Syndrome. </p>\n\n<p>Clance and Imes (1978) first characterised the Imposter Syndrome typology among their high-achieving female patients:</p>\n\n<p><a href=\"https://i.stack.imgur.com/UCss2.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/UCss2.jpg\" alt=\"enter image description here\"></a></p>\n\n<pre><code>Clance, P. R., &amp; Imes, S. A. (1978). The imposter phenomenon in high \nachieving women: Dynamics and therapeutic intervention. Psychotherapy: \nTheory, Research &amp; Practice, 15(3), 241–247. https://doi.org/10.1037/h0086006\n</code></pre>\n\n<p>So, how can we reconcile what seem to be two antipodal phenomena?</p>\n\n<p>From a very cursory consideration of things, it seems that for individuals with the Imposter Syndrome, the self-serving bias is either greatly attenuated, or dare I say, inverted. For that to occur, we might presume two things:</p>\n\n<ol>\n<li>They have crushingly low self-efficacy and/or; </li>\n<li>They are processing information in an aberrant manner. </li>\n</ol>\n\n<p>So, how does social, cognitive, or abnormal psychology reconcile the self-serving bias with the Imposter Syndrome? Is the Imposter Syndrome even a <em>thing</em> or simply a cognitive style that occurs among people with depression? If so, what are their similarities, and what are their departures? In other words, is the phenomenology of someone with severe depression effectively the same as someone with the Imposter Syndrome?</p>\n\n<p>Where possible, please include references.</p>\n", "pids": ["53e9ab6fb7602d970351068d", "55a4cd3a612c6b12aafa783e", "53e9a209b7602d9702b0d32c"], "flag": 0}
{"question": "What is the best resources to learn Graph Convolutional Neural Networks?", "body": "<p>For the past few days, I am trying to learn graph convolutional networks. I saw some of the lectures on youtube. But I can not able to get any clear concept of how those networks are trained. I have a vague understanding of how to perform convolution, but I can not understand how we train them. I want a solid mathematical understanding of graph convolutional networks. So, can anyone please suggest me how to start learning graph convolutional network from start to expert level?</p>\n", "pids": ["608a7d6891e011b76ccd5513"], "flag": 1}
{"question": "How can we prevent AGI from doing drugs?", "body": "<p>I recently read some introductions to AI alignment, AIXI and decision theory things.</p>\n<p>As far as I understood, one of the main problems in <em>AI alignment</em> is how to define a <em>utility function</em> well, not causing something like the paperclip apocalypse.</p>\n<p>Then a question comes to my mind that whatever the utility function would be, we need a computer to compute the utility and reward, so that there is no way to prevent AGI from seeking it to manipulate the utility function to always give the maximum reward.</p>\n<p>Just like we humans know that we can give happiness to ourselves in chemical ways and some people actually do so.</p>\n<p>Is there any way to prevent this from happening? Not just protecting the utility calculator physically from AGI (How can we sure it works forever?), but preventing AGI from thinking of it?</p>\n", "pids": ["5e997e4391e01118b66a5ebf"], "flag": 1}
{"question": "What is (or is there) a clear distinction between cognitive and motivational explanations for a hypothesis?", "body": "<p>For example, I see there is even a cognitive theory of motivation. I closest I can find is that cognitive explanations are more about the thought process of an individual which led to certain behaviour. What then, does a pure \"motivational explanation\" mean?</p>\n\n<p>Here is an instance of cognitive vs. motivational explanation: \"There are both cognitive and motivational explanations for the competence hypothesis. [...] Perhaps the major reason for the competence hypothesis is motivational rather than cognitive.\" This is an excerpt from <a href=\"https://jstor.org/stable/41760614\" rel=\"nofollow noreferrer\">\"Preference and Belief: Ambiguity and Competence in Choice under Uncertainty\"</a> by  Heath and Tversky.</p>\n", "pids": ["55a6940e65ce054aad6c4d9d", "55a5a79d612c6b12ab28e98a"], "flag": 0}
{"question": "What are examples of machine learning techniques inspired by neuroscience?", "body": "<p>What are examples of machine learning techniques (i.e. models, algorithms, etc.) inspired (to different extents) by neuroscience?</p>\n\n<p>Particularly, I'm interested in recent developments, say less than 10 years old, that have their basis in neuroscience to some degree. </p>\n", "pids": ["53e9b102b7602d9703b8101a", "616809b85244ab9dcb310fad", "599c796f601a182cd263cb22", "5c8dd8c94895d9cbc6a7a2a6"], "flag": 1}
{"question": "Are there neural networks where nodes are randomly selected from among a set of nodes (in random orders and a random number of times)?", "body": "<p>I am trying to make a classifier.</p>\n<p>I am new to AI (even if I know the definition and all such a bit) , and also I have no idea of how to implement it properly by myself even if I know a bit of Python coding (in fact, I am fifteen years old !🙄🙄), but my passion for this has made me ask this (silly, probably) question.</p>\n<p>Are there neural networks where nodes are randomly selected from among a set of nodes (in random orders and a random number of times)? I know this is from ML (or maybe deep learning, I suppose), but I have no idea how to recognize such a thing from the presently available algorithms. It will be great if you all could help me, because I am preparing to release an API for programming a model which I call the 'Insane Mind' on GitHub, and I want some help to know if my effort was fruitless.</p>\n<p>And for reference, here's the code :</p>\n<pre><code>from math import *\nfrom random import *\n \nclass MachineError(Exception):\n    '''standard exception in the API'''\n    def __init__(self, stmt):\n        self.stmt = stmt\ndef sig(x):\n    '''Sigmoid function'''\n    return (exp(x) + 1)/exp(x)\n\nclass Graviton:\n    def __init__(self, weight, marker):\n        '''Basic unit in 'Insane Mind' algorithm\n           -------------------------------------\n           Graviton simply refers to a node in the algorithm.\n           I call it graviton because of the fact that it applies a weight\n           on the input to transform it, besides using the logistic function '''\n        self.weight = weight # Weight factor of the graviton\n        self.marker = marker # Marker to help in sorting\n        self.input = 0 # Input to the graviton\n        self.output = 0 # Output of the graviton\n        self.derivative = 0 # Derivative of the output\n\n    def process(self, input_to_machine):\n        '''processes the input (a bit of this is copied from the backprop algorithm'''\n        self.input = input_to_machine\n        self.output = (sig(self.weight * self.input) - 1)/(self.marker + 1)\n        self.derivative = (sig(self.input * self.weight) - 1) * self.input *self.output * (1- self.output) \n        return self.output\n    \n    def get_derivative_at_input(self):\n        '''returns the derivative of the output'''\n        return self.derivative\n\n    def correct_self(self, learning_rate, error):\n        '''edits the weight'''\n        self.weight += -1 * error * learning_rate * self.get_derivative_at_input() * self.weight\n        \nclass Insane_Mind:\n\n    def __init__(self, number_of_nodes):\n        '''initialiser for Insane_Mind class.\n           arguments : number_of_nodes : the number of nodes you want in the model'''\n        self.system = [Graviton(random(),i) for i in range(number_of_nodes)] # the actual system\n        self.system_size = number_of_nodes # number of nodes , or 'system size'\n        \n    def  output_sys(self, input_to_sys):\n        '''system output'''\n        self.output = input_to_sys\n        for i in range(self.system_size):\n            self.output = self.system[randint(0,self.system_size - 1 )].process(self.output)\n        return self.output\n    \n    def train(self, learning_rate, wanted):\n        '''trains the system'''\n        self.cloned = [] # an array to keep the sorted elements during the sorting process below\n        order = [] # the array to make out the order of arranging the nodes\n        temp = {} # a temporary dictionary to pick the nodes from\n        for graviton in self.system:\n            temp.update({str(graviton.derivative): graviton.marker})\n        order = sorted(temp)\n        i = 0\n        error = wanted - self.output\n        for value in order:\n            self.cloned.append(self.system[temp[value]])\n            self.cloned[i].correct_self(learning_rate, error)\n            error *= self.cloned[i].derivative\n            i += 1\n        self.system = self.cloned\n</code></pre>\n<p>Sorry for not using that <code>MachineError</code> exception anywhere in my code (I will use it when I am able to deploy this API).</p>\n<p>To tell more about this algorithm, this gives randomized outputs (as if guessing). The number of guesses vary from 1 (for a system with one node), 2 (for two nodes) and so on to an infinite number of guesses for an infinite number of nodes.</p>\n<p>Also, I wanna try and find how much it can be of use (if this is something that has never been discovered, if it is something that can find a good place in the world of ML or Deep Learning) and where it can be used.</p>\n<p>Thanks in advance.</p>\n<p>Criticisms (with a clear reason) are also accepted.</p>\n", "pids": ["573696006e3b12023e513cb6"], "flag": 1}
{"question": "What is the meaning of &quot;exploration&quot; in reinforcement and supervised learning?", "body": "<p>While exploration is an integral part of reinforcement learning (RL), it does not pertain to supervised learning (SL) since the latter is already provided with the data set from the start.</p>\n<p>That said, can't hyperparameter optimization (HO) in SL be considered as exploration? The more I think about this the more I'm confused as to what exploration really means. If it means exploring the environment in RL and exploring the model configurations via HO in SL, isn't its end goal &quot;mathematically&quot; identical in both cases?</p>\n", "pids": ["5d1eb9e4da562961f0b1ef86"], "flag": 1}
{"question": "What makes Google Translate fail on the Latin language?", "body": "<p>As it is discussed <a href=\"https://www.reddit.com/r/latin/comments/6akqdi/why_is_google_translate_so_bad_for_latin_a/\" rel=\"nofollow noreferrer\">here</a>, and I saw it on other Latin language forums too, everybody complains about how Google Translate fails to translate the Latin language. From my personal experience, it is not that much bad on other languages, including romance languages.</p>\n<p>So, what makes Google Translate fail so much to translate the Latin language? Is it about its syntax and grammar or lack of data?</p>\n", "pids": ["5bdc31b417c44a1f58a0b8c2"], "flag": 1}
{"question": "Is stable learning preferable to jumps in accuracy/loss", "body": "<p>A stable/smooth learning validation curve often seems to keep improving over more epochs than an unstable learning curve. My intuition is that dropping the learning rate and increasing the patience of a model that produces a stable learning curve could lead to better validation fit.</p>\n<p>The counter argument is that jumps in the curve could mean that the model has just learned something significant, but they often jump back down or tail off after that.</p>\n<p>Is one better than the other? Is it possible to take aspects of both to improve learning?</p>\n", "pids": ["5d1eb9c8da562961f0b03113"], "flag": 1}
{"question": "Is there a mindfulness meditation technique that tends to produce gamma rhythms in the brain (and not just the alpha frequencies that are typical)?", "body": "<p>This is a follow up to a <a href=\"https://christofkoch.files.wordpress.com/2013/12/cr-brain-buddha-13.pdf\" rel=\"nofollow noreferrer\">paper</a> (^) that was cited in a <a href=\"https://psychology.stackexchange.com/a/19829/3379\">response</a> to one of my past questions here. It was found that <strong>experienced Buddhist monks generate a substantial increase in gamma</strong> waves on demand during their meditation, while novices don't.  </p>\n\n<p><a href=\"https://www.sovhealth.com/mental-health/mindfulness-meditation-alters-brain-waves-produces-peace-mind/\" rel=\"nofollow noreferrer\">This</a> website cites a <a href=\"https://doi.org/10.3389/fnhum.2013.00012\" rel=\"nofollow noreferrer\">study</a> (*) that found that <strong>mindfulness meditation causes an increase in alpha waves in subjects</strong>.  </p>\n\n<p>I'm therefore wondering if there is something that the Buddhist monks are doing differently. <strong>Is there a mindfulness meditation technique that tends to produce gamma rhythms in the brain (and not just the alpha frequencies that are typical during mindfulness practice)?</strong>  </p>\n\n<p>Perhaps gamma waves (in the orbitofrontal cortex and areas of the prefrontal cortex) are generated from simply a deeper focus. However, if that's the case, it's still not clear to me how one can attain this. What kind of techniques are likely to lead to this phenomenon? Is it more likely that a more open/wide focus (example cue: \"pay attention to all thoughts/feelings/sensations that appear in your mind and, if you get distracted, just come back to the meditation\") or narrow/sharp focus (example cue: \"pretend to receive a huge reward for focusing on your breath with high clarity and minimal distractions\") leads to gamma activity? Are there any other dimensions of mindfulness meditation that are relevant here?</p>\n\n<p>(^) The Brain of Buddha - Christof Koch<br>\n(*) <em>Mindfulness starts with the body: somatosensory attention and top-down modulation of cortical alpha rhythms in mindfulness meditation</em></p>\n", "pids": ["53e9ba8ab7602d97046b0d66", "53e9b5f3b7602d970414767c", "5ce2ca80ced107d4c6278568"], "flag": 1}
{"question": "When should one publish code publicly on GitHub: during or after journal review?", "body": "<p>Similar to the <a href=\"https://academia.stackexchange.com/questions/17740/open-source-the-project-code-before-or-after-publication\">following question</a>, I have developed a code to produce results in a manuscript that I've written which I wish to now share with the community. But this manuscript, which is currently on arXiv, is still under journal review (which has taken several months and still sits with the referees). Therefore, I was wondering if I should put the code publicly on Github while the manuscript remains under review or only after the manuscript has been fully accepted/published by a journal? Does the right answer depend on the journal? Is it better to wait for any reason(s)? Any and all insights are welcome.</p>\n", "pids": ["57a4e8f9ac44365e35c9441a", "60b36375e4510cd7c8ca98ad"], "flag": 1}
{"question": "What is the optimum length of abstinence for maximum ejaculation volume in humans?", "body": "<p>There have been papers discussing this, and whether the abstinence period should be 1 week, 2 weeks or other [1, 2]. Some think the time to maximum ejaculation volume is even longer than this.</p>\n\n<ol>\n<li>doi: <a href=\"http://dx.doi.org/10.1530/jrf.0.0570391\" rel=\"noreferrer\">10.1530/jrf.0.0570391</a></li>\n<li>PMID: <a href=\"http://www.ncbi.nlm.nih.gov/pubmed/7114956\" rel=\"noreferrer\">7114956</a></li>\n</ol>\n", "pids": ["53e99dd4b7602d9702696941", "59d98dca0cf2415686e7d1f1"], "flag": 1}
{"question": "How accurate are diagnoses on Autism to Children under 3 years old?", "body": "<p>I have a son with autism. He was diagnosed under 3 years old. 2 years old to be exactly. After I doubted several pediatricians that claimed that wouldn't be a valid diagnose after 5 years old. I discovered by myself that it wasn't entirely true. I've read that specialists would diagnose under 2, or even, babies. I want to know because other parents say their doctors say to wait from 2 to 3 years old or even more. </p>\n", "pids": ["5c185944dfae54832c9865f5", "55a4b26d65ceb7cb02d6748c", "5affc51fa2e6b1328d55c797", "55a42120612ca6486887adb2"], "flag": 1}
{"question": "Is there any Sleep limit for a human body?", "body": "<p>Can we sleep throughout our whole life if we are supplied the necessary things like food,water etc.</p>\n", "pids": ["55a698b865ce054aad6d23aa"], "flag": 1}
{"question": "Is there a family tree for reinforcement learning algorithms?", "body": "<p>Can anyone point me in the direction of a nice graph that depicts the \"family tree\", or hierarchy, of RL algorithms (or models)? For example, it splits the learning into TD and Monte Carlo methods, under which is listed all of the algorithms with their respective umbrella terms. Beneath each algorithm is shown modifications to those algorithms, etc. I'm having difficulty picturing where everything lies within the RL landscape.</p>\n", "pids": ["58d82fd2d649053542fd7619"], "flag": 1}
{"question": "Transformers: how does the decoder final layer output the desired token?", "body": "<p>In the paper <a href=\"https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\" rel=\"nofollow noreferrer\">Attention Is All You Need</a>, this section confuses me:</p>\n<blockquote>\n<p>In our model, we share the same weight matrix between the two embedding layers [in the encoding section] and the pre-softmax linear transformation [output of the decoding section]</p>\n</blockquote>\n<p>Shouldn't the weights be different, and not the same? Here is my understanding:</p>\n<p>For simplicity, let us use the English-to-French translation task where we have <span class=\"math-container\">$n^e$</span> number of English words in our dictionary and <span class=\"math-container\">$n^f$</span> number of French words.</p>\n<ul>\n<li><p>In the encoding layer, the input tokens are <span class=\"math-container\">$1$</span> x <span class=\"math-container\">$n^e$</span> one-hot vectors, and are embedded with a <span class=\"math-container\">$n^e$</span> x <span class=\"math-container\">$d^{model}$</span> learned embedding matrix.</p>\n</li>\n<li><p>In the output of the decoding layer, the final step is a linear transformation with weight matrix <span class=\"math-container\">$d^{model}$</span> x <span class=\"math-container\">$n^f$</span>, and then applying softmax to get the probability of each french word, and choosing the french word with the highest probability.</p>\n</li>\n</ul>\n<p>How is it that the <span class=\"math-container\">$n^e$</span> x <span class=\"math-container\">$n^{model}$</span> input embedding matrix share the same weights as the <span class=\"math-container\">$d^{model}$</span> x <span class=\"math-container\">$n^f$</span> decoding output linear matrix? To me, it seems more natural for both these matrices to be learned independently from each other via the training data, right? Or am I misinterpreting the paper?</p>\n", "pids": ["58437722ac44360f1082ef6b"], "flag": 1}
{"question": "How happy are people relative to neutral (as measured by experience sampling)?", "body": "<p>Most studies on <a href=\"https://en.wikipedia.org/wiki/Experience_sampling_method\" rel=\"nofollow noreferrer\">experience sampling</a> are about whether some activity correlates with increased or decreased happiness/subjective well-being. However, it's often hard to tell from these studies what number corresponds a neutral point, where someone is neither unhappy or happy (or equally so), or is feeling an valence/affect equivalent to a nonconscious state. For instance <em><a href=\"https://books.google.com/books?hl=en&amp;lr=&amp;id=05e5d_KBYY0C&amp;oi=fnd&amp;pg=PP13&amp;dq=experience+sampling&amp;ots=rtKOM3tmc0&amp;sig=GJp6aaU09aJXINg_91LAHeC_s7c#v=onepage&amp;q&amp;f=false\" rel=\"nofollow noreferrer\">Experience Sampling Method: Measuring the Quality of Everyday Life</a></em> (2007) shows its results in terms of z-scores, which are defined relative to some average, but it's unclear whether that average would be higher or lower than a neutral point. As such, while we can say that these people are happier in this situation than another, it's hard to see whether they're overall happy or unhappy in that situation.</p>\n\n<p>I'm not particularly interested in what activities or age or gender correlates with happiness, but just how happy people are relative to some clearly defined neutral point. Ideally, the study wouldn't just show some average among all study participants across all their experiences, but also what percentile corresponds to what happiness ratings, and the range of happiness scores and the frequency of different happiness ratings for each person. Is there a study that addresses this topic?</p>\n", "pids": ["5c0f7bf2da562944ac7c32b2", "5c0f7bf2da562944ac7c32b2"], "flag": 1}
{"question": "When do the ensemble methods beat neural networks?", "body": "<p>In many applications and domains, computer vision, natural language processing, image segmentation, and many other tasks, neural networks (with a certain architecture) are considered to be by far the most powerful machine learning models.</p>\n<p>Nevertheless, algorithms, based on different approaches, such as ensemble models, like <em>random forests</em> and <em>gradient boosting</em>, are not completely abandoned, and actively developed and maintained by some people.</p>\n<p>Do I correctly understand that the neural networks, despite being very flexible and universal approximators, for a certain kind of tasks, regardless of the choice of the architecture, are not the optimal models?</p>\n<p>For the tasks in computer vision, the core feature, which makes CNNs superior, is the <em>translational invariance</em> and the encoded ability to capture the proximity properties of an image or some sequential data. And the more recent <em>transformer</em> models have the ability to choose which of the neighboring data properties is more important for its output.</p>\n<p>But let's say I have a dataset, without a certain structure and patterns, some number of numerical columns, a lot of categorical columns, and in the feature space (for classification task) the classes are separated by some nonlinear hypersurface, would the ensemble models be the optimal choice in terms of performance and computational time?</p>\n<p>In this case, I do not see a way to exploit CNNs or attention-based neural networks. The only thing that comes to my head, in this case, is the ordinary MLP. It seems that, on the one hand, it would take significantly more time to train the weights than the trees from the ensemble. On the other hand, both kinds of models work without putting prior knowledge to data and assumptions on its structure. So, given enough amount of time, it should give a comparable quality.</p>\n<p>Or can there be some reasoning that neural network is sometimes bound to give rather a poor quality?</p>\n", "pids": ["62d7730d5aee126c0f900640", "60c1939991e0112cf43c20b9"], "flag": 1}
{"question": "How to calculate the distance between the camera and an object using Computer Vision?", "body": "<p>I want to create a Deep Learning model that measures the distance between the camera and certain objects in an image. Is it possible? Please, let me know some resources related to this task.</p>\n", "pids": ["5c8f14b54895d9cbc6280e82", "5e71f49891e0115656f5cf17"], "flag": 1}
{"question": "Why multiplayer, imperfect information, trick-taking card games are hard for AI?", "body": "<p>AI reached a super-human level in many complex games such as <a href=\"https://www.sciencedirect.com/science/article/pii/S0004370201001291\" rel=\"nofollow noreferrer\">Chess</a>, <a href=\"https://www.nature.com/articles/nature24270\" rel=\"nofollow noreferrer\">Go</a> ,<a href=\"https://science.sciencemag.org/content/365/6456/885.abstract?casa_token=nyS4YED061UAAAAA:-YZnlUJVkOPOC7UOVxgUyaT_4XK_QqXMlJMovMSWyCxoAyCCzSB1xTSndhlu2IGPU1fXj1HDdvLunIc\" rel=\"nofollow noreferrer\">Texas hold’em Poker</a>, <a href=\"https://openai.com/projects/five/\" rel=\"nofollow noreferrer\">Dota2</a> and <a href=\"https://www.nature.com/articles/s41586-019-1724-z\" rel=\"nofollow noreferrer\">StarCarft2</a>. However it still did not reach this level in trick-taking card games.</p>\n<p>Why there is no <strong>super-human</strong> AI playing imperfect-information, multi-player, trick-taking card games such as Spades, Whist, Hearts, Euchre and Bridge?</p>\n<p>In particular, what <strong>are the obstacles</strong> for making a super-human AI in those games?</p>\n<hr />\n<p>I think those are the reasons that makes Spades hard for AI to master:</p>\n<ol>\n<li><p><strong>Imperfect information</strong> games pose two distinct problems: move selection and inference.</p>\n</li>\n<li><p>The size of the game tree isn't small, however larger games have been mastered.</p>\n<p>I. <strong>History size</strong>: <span class=\"math-container\">$14!^4 = 5.7\\cdot10^{43}$</span></p>\n<p>II. There are <span class=\"math-container\">$\\frac{52!}{13!^4}= 5.4\\cdot10^{28}$</span> possible initial states.</p>\n<p>III. Each initial information set can be completed into a full state in <span class=\"math-container\">$\\frac{39!}{13!^3}=8.45\\cdot10^{16} $</span> ways</p>\n</li>\n<li><p><strong>Evaluation only at terminal states</strong>.</p>\n</li>\n<li><p><strong>Multiplayer</strong> games:</p>\n<p>I. harder to prune - search algorithms are less effective</p>\n<p>II. opponent modeling is hard</p>\n<p>III. Goal choosing - several goals are available, need to change goals during rounds according to the reveled information.</p>\n</li>\n<li><p>Agent need to coordinate with a partner: <strong>conventions</strong>, <strong>signals</strong>.</p>\n</li>\n</ol>\n", "pids": ["5d04e8e9da56295d08dbe816"], "flag": 1}
{"question": "Current research on G&#246;del machines", "body": "<p>Is there any current research on Gödel machines? It seems that the last article by Jürgen Schmidhuber on this topic was published in 2012: <a href=\"http://people.idsia.ch/%7Ejuergen/goedelmachine.html\" rel=\"nofollow noreferrer\">http://people.idsia.ch/~juergen/goedelmachine.html</a></p>\n", "pids": ["5b67b4b417c44aac1c8673c7"], "flag": 1}
{"question": "How to embed/deploy an arbitrary machine learning model on microcontrollers?", "body": "<p>Say I have a machine learning model trained on a laptop and I then want to embed/deploy the model on a microcontroller. How can I do this?</p>\n<p>I know that TensorflowLite Micro generates a C header to be added in the project and then be embedded, but every example I read shows how it is done with neural networks, which seems legit as TensorFlow is primarily used for deep learning.</p>\n<p>But how can I do the same with any type of model, like the ones there is in scikit-learn? So, I'm not interested in necessarily doing this with TensorflowLite Micro, but I'm interested in the general approach to solve this problem.</p>\n", "pids": ["5f02ea5a91e011ee5e0257ea", "5e2186c63a55acbef5e6a342"], "flag": 1}
{"question": "What is a unified neural network model?", "body": "<p>In many articles (for example, in <a href=\"https://arxiv.org/pdf/1506.02640.pdf\" rel=\"nofollow noreferrer\">the YOLO paper</a>, <a href=\"https://arxiv.org/pdf/1907.03465.pdf\" rel=\"nofollow noreferrer\">this paper</a> or <a href=\"https://www.aclweb.org/anthology/K18-1005/\" rel=\"nofollow noreferrer\">this one</a>), I see the term &quot;unified&quot; being used. I was wondering what the meaning of &quot;unified&quot; in this case is.</p>\n", "pids": ["5d2465c93a55acde6e5bd707", "573696026e3b12023e516718"], "flag": 1}
{"question": "Do stimulants increase the IQ tests score for everyone?", "body": "<p>There is some meta-analytic evidence that stimulants increase the IQ test scores of ADHD children by 2 to 7 points (<a href=\"https://doi.org/10.1177/1087054708322996\" rel=\"nofollow noreferrer\">Jepsen et al., 2009</a>). \nAlthough giving stimulants to non-ADHD children may be unethical, I'm still wondering if there is improvement in IQ test score in children (or adults) who do not meet the criteria for an ADHD diagnosis. An additional motivation for asking this is that a study by <a href=\"https://doi.org/10.1186/1471-244X-13-330\" rel=\"nofollow noreferrer\">Tsai et al. (2013)</a> found that the IQ test score improvement from methylphenidate \"had no correlation with the decrement of ADHD symptoms.\" </p>\n\n<p><sub>\nJepsen, J. R. M., Fagerlund, B., &amp; Mortensen, E. L. (2009). <a href=\"https://doi.org/10.1177/1087054708322996\" rel=\"nofollow noreferrer\">Do attention deficits influence IQ assessment in children and adolescents with ADHD?</a>. Journal of Attention Disorders, 12(6), 551-562.<br>\nTsai, C. S., Huang, Y. S., Wu, C. L., Hwang, F. M., Young, K. B., Tsai, M. H., &amp; Chu, S. M. (2013). <a href=\"https://doi.org/10.1186/1471-244X-13-330\" rel=\"nofollow noreferrer\">Long-term effects of stimulants on neurocognitive performance of Taiwanese children with attention-deficit/hyperactivity disorder</a>. BMC psychiatry, 13(1), 330.\n</sub></p>\n", "pids": ["56d831abdabfae2eee266d17", "56d8eea5dabfae2eee6706f4", "5c756bf4f56def9798439d70", "55a608f765cead59c83316ff"], "flag": 0}
{"question": "Why don&#39;t those developing AI Deepfake detectors use two detectors at once so as to catch deepfakes in one or the other?", "body": "<p>Why don't those developing AI Deepfake detectors use two differently trained detectors at once that way if the Deepfake was trained to fool one of the detectors the other would catch it and vice-versa?</p>\n<p>To be clear this is really a question of can deepfakes be made to fool multiple high-accuracy detectors at the same time. And if so then how many can they fool before they become human detectable from noticeable noise?</p>\n<p>I've heard of papers where they injected a certain noise into their deepfake videos which allows them to fool a given detector (<a href=\"https://arxiv.org/abs/2009.09213\" rel=\"nofollow noreferrer\">https://arxiv.org/abs/2009.09213</a>, <a href=\"https://delaat.net/rp/2019-2020/p74/report.pdf\" rel=\"nofollow noreferrer\">https://delaat.net/rp/2019-2020/p74/report.pdf</a>), so I thought well if they simply used two high-accuracy detectors then any pattern of noise used to fool one detector would interfere with the pattern of noise used to fool the other detector.</p>\n", "pids": ["58437722ac44360f1082f55f"], "flag": 1}
{"question": "How do I get started with multi-agent reinforcement learning?", "body": "<p>Is there any <em>tutorial</em> that walks through a multi-agent reinforcement learning implementation (in Python) using libraries such as <a href=\"https://gym.openai.com/\" rel=\"nofollow noreferrer\">OpenAI's Gym</a> (for the environment), <a href=\"https://www.tensorflow.org/agents\" rel=\"nofollow noreferrer\">TF-agents</a>, and <a href=\"https://github.com/DLR-RM/stable-baselines3\" rel=\"nofollow noreferrer\">stable-baselines-3</a>?</p>\n<p>I searched a lot, but I was not able to find any tutorial, mostly because Gym environments and most RL libraries are not for multi-agent RL.</p>\n", "pids": ["5fa14e7891e011f3c66576d8"], "flag": 1}
{"question": "Why is it a problem if the outputs of an activation function are not zero-centered?", "body": "<p>In <a href=\"https://youtu.be/wEoyxE0GP2M?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&amp;t=524\" rel=\"nofollow noreferrer\">this lecture</a>, the professor says that one problem with the sigmoid function is that its outputs aren't zero-centered. Are the explanation provided by the professor regarding why this is bad is that the gradient of our loss w.r.t. the weights <span class=\"math-container\">$\\frac{\\partial L}{\\partial w}$</span> which is equal to <span class=\"math-container\">$\\frac{\\partial L}{\\partial \\sigma}\\frac{\\partial \\sigma}{\\partial w}$</span> will always be either negative or positive and we'll have a problem updating our weights as she shows in <a href=\"https://youtu.be/wEoyxE0GP2M?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&amp;t=582\" rel=\"nofollow noreferrer\">this slide</a>, we won't be able to move in the direction of the vector <span class=\"math-container\">$(1,-1)$</span>. I don't understand why since she only talks about one component of our gradient and not the whole vector. if the components of the gradient of our loss will have different signs which will allow us to adjust to different directions I'm I wrong? But the thing that I don't understand is how this property generalizes to non zero-centered functions and non-zero centered data?</p>\n", "pids": ["5e982cc591e0119e8a9523dc"], "flag": 1}
{"question": "Which neural network can I use to solve this constrained optimisation problem?", "body": "<p>Let <span class=\"math-container\">$\\mathcal{S}$</span> be the training data set, where each input <span class=\"math-container\">$u^i \\in \\mathcal{S}$</span> has <span class=\"math-container\">$d$</span> features.</p>\n<p>I want to design an ANN so that the cost function below is minimized (the sum of the square of pairwise differences between model outputs)  and the given constraint is satisfied, where <span class=\"math-container\">$w$</span> is the ANN model parameter vector.</p>\n<p><span class=\"math-container\">\\begin{align}\n\\min _{w}&amp; \\sum_{\\{i, j\\} \\in \\mathcal{S}}\\left(f\\left(w, u^{i}\\right)-f\\left(w, u^{j}\\right)\\right)^{2} \\\\\n&amp;f\\left(w, u^{i}\\right) \\geq q_{\\min }, \\quad i \\in \\mathcal{S}\n\\end{align}</span></p>\n<p>What kind of ANN is suitable for this purpose?</p>\n", "pids": ["655f5b15939a5f4082b55a24"], "flag": 1}
{"question": "Country records about criminal recidivism rates", "body": "<p>I find myself doing a work on criminal psychology, I understood that recidivism rates were registered by government agencies although it seems not to be that way (some projects were famous in the past but I do not think they developed). If any of those projects were developed, I would be grateful for information on the subject.</p>\n\n<p>On the other hand, if someone on the site knows the most famous articles or works developed on the subject, I would be grateful if you could indicate references to me, since I may not be handling those documents due to the publication dates.</p>\n", "pids": ["56d927d0dabfae2eeec684b3"], "flag": 0}
{"question": "What&#39;s the relationship between priming and availability heuristic?", "body": "<p>As I have understood, <a href=\"https://en.wikipedia.org/wiki/Availability_heuristic\" rel=\"nofollow noreferrer\">availability heuristic</a> means that things that are \"available\" in one's cognition (one has thought recently) are prone to influence one's perception.</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Priming_(psychology)\" rel=\"nofollow noreferrer\">Priming</a> has been explained as that the word 'doctor' is recognized more frequently than 'bread' after a word 'nurse'.</p>\n\n<p>I find that in this sense priming would be a subcategory of availability or vice versa. ('doctor' is recognized more frequently when 'nurse' is available in one's cognition)</p>\n\n<p>Why did <a href=\"http://www.jstor.org/stable/1738360\" rel=\"nofollow noreferrer\">Amos Tversky and Daniel Kahneman introduce</a> availability instead of sticking with priming? </p>\n\n<p><sub>\nTversky, A., &amp; Kahneman, D. (1974). <a href=\"http://www.jstor.org/stable/1738360\" rel=\"nofollow noreferrer\">Judgment under uncertainty: Heuristics and biases.</a> science, 185(4157), 1124-1131.\n</sub></p>\n", "pids": ["53e9b30ab7602d9703dd1096"], "flag": 0}
{"question": "Can Reinforcement Learning be used to generate sequences?", "body": "<p>Can we use reinforcement learning for sequence-to-sequence tasks? If yes, whether or not this is a good choice, how could this be done?</p>\n", "pids": ["58437725ac44360f1082f8fe"], "flag": 1}
{"question": "How does Mask R-CNN automatically output a different number of objects on the image?", "body": "<p>Recently, I was reading <a href=\"https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\" rel=\"nofollow noreferrer\">Pytorch's official tutorial</a> about Mask R-CNN.\nWhen I run the code on colab, it turned out that it automatically outputs a different number of channels during prediction. If the image has 2 people on it, it would output a mask with the shape <code>2xHxW</code>. If the image has 3 people on it, it would output the mask with the shape <code>3xHxW</code>.</p>\n<p>How does Mask R-CNN change the channels? Does it have a <code>for</code> loop inside it?</p>\n<p>My guess is that it has region proposals and it outputs masks based on those regions, and then it thresholds them (it removes masks that have low probability prediction). Is this right?</p>\n", "pids": ["5e4d083f3a55ac8cfd770d17"], "flag": 1}
{"question": "Is continuous learning possible with a deep convolutional neural network, without changing its topology?", "body": "<p>In general, is continuous learning possible with a deep convolutional neural network, without changing its topology?</p>\n<p>In my case, I want to use a convolutional neural network as a classifier of heartbeat types. The ECG signal is split, and a color image is created using feature extraction. These photos (the inputs) are fed into a deep CNN, but they must be labeled by someone first.</p>\n<p>Are there ways to implement continuous learning in a deep neural network for image recognition? Does such an implementation make sense if the labels have to be specially prepared in advance?</p>\n", "pids": ["5cede0eada562983788c9028", "5d9edc0347c8f7664602fda0", "58d82fc8d649053542fd58bb", "5c873b4d4895d9cbc6f504ad", "57a4e91aac44365e35c97dc2", "58d82fc8d649053542fd5c5a", "599c7b59601a182cd272c1ab"], "flag": 1}
{"question": "Constraints on dataset size for AI-assisted connectome reconstruction", "body": "<p>From an exchange with <a href=\"http://seunglab.org/\" rel=\"nofollow noreferrer\">Dr. Seung</a>, an expert on connectomics, I learned that one of his former PhD students Viren Jain is leading the <a href=\"https://ai.google/research/teams/perception/connectomics/\" rel=\"nofollow noreferrer\">Connectomic effort at Google</a> using supervised learning methods. Now, supervised deep learning methods usually require large amounts of data to succeed. (I know this based on experience in industry as well as the deep learning literature.) However, due to the time and effort of human annotation the datasets for circuit reconstruction are really small: </p>\n\n<p><a href=\"https://i.stack.imgur.com/f2BZy.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/f2BZy.png\" alt=\"enter image description here\"></a></p>\n\n<p><em><a href=\"https://science.eyewire.org/science-artificial-intelligence.html\" rel=\"nofollow noreferrer\">It takes about six months for humans to annotate 1 cubic millimeter of brain volume.</a></em> </p>\n\n<p>In fact, Dr. Seung informed me that the <a href=\"https://cremi.org/data/\" rel=\"nofollow noreferrer\">following dataset</a> from a circuit reconstruction competition in 2016 which is less than five gigabytes in total is basically state of the art. </p>\n\n<p>Given that <a href=\"https://arxiv.org/abs/1712.04621\" rel=\"nofollow noreferrer\">augmenting training data with synthetic data</a> is frequently used for computer vision problems, I am led to the following questions: </p>\n\n<ol>\n<li>Might it theoretically be possible to augment human-annotated training data with morphologically similar synthetic data? </li>\n<li>What methods in the near future might allow us to significantly increase the size of human-annotated training data?</li>\n</ol>\n\n<h2>References:</h2>\n\n<ol>\n<li>Michał Januszewski, Jörgen Kornfeld, Peter H. Li, Art Pope, Tim Blakely, Larry Lindsey, Jeremy Maitin-Shepard, Mike Tyka, Winfried Denk &amp; Viren Jain. High-precision automated reconstruction of neurons with flood-filling networks. Nature. 2018. </li>\n<li>Luis Perez and Jason Wang. The Effectiveness of Data Augmentation in Image Classification using Deep Learning. Arxiv. 2017. </li>\n<li>Alberto Bailoni, Constantin Pape, Steffen Wolf, Thorsten Beier, Anna Kreshuk, Fred A. Hamprecht. A Generalized Framework for Agglomerative Clustering of Signed Graphs applied to Instance Segmentation. Arxiv. 2019.</li>\n<li>EyeWire: mapping neurons. <a href=\"https://science.eyewire.org/science-mapping-neurons\" rel=\"nofollow noreferrer\">https://science.eyewire.org/science-mapping-neurons</a> Accessed 21 August 2019. </li>\n</ol>\n", "pids": ["5ce2d24cced107d4c64c1de8", "5c136b72da56295a08a73a0e"], "flag": 1}
{"question": "What makes a transformer a transformer?", "body": "<p>Transformers are modified heavily in recent research. But what exactly makes a transformer a transformer? What is the core part of a transformer? Is it the <em>self-attention</em>, the <em>parallelism</em>, or something else?</p>\n", "pids": ["599c7987601a182cd2648373", "599c7987601a182cd2648373"], "flag": 1}
{"question": "How does spermaceti make a whale float?", "body": "<p>In the biochemistry book I'm reading (Box 10-1, Lehninger Principles of Biochemistry), an example is given in whales of how spermaceti (a wax located in the whale head), when at sea level is a liquid, and allows the whale to float due to its buoyancy. </p>\n\n<p>As the whale dives deeper, the wax turns into a solid (due to the colder temperatures), and hence this more dense wax is less buoyant and prevents the whale from floating back up due to the greater density of the seawater at these depths.</p>\n\n<p>My limited understanding is that density effects buoyancy in so far as that the weight of the object displaces an equivalent weight of water. If the quantity of the water displaced is small enough that the surface area of the object isn't completely submerged, it can float.</p>\n\n<p>Now with the whale example, considering the wax is fully enclosed by the head, how would this change in local density effect the buoyancy of the whale as a whole? The weight of the wax still remains the same (in so far as the example used in the book), the only thing that changes is its density inside the whale.</p>\n\n<p>So with a constant weight, and only a variable local density enclosed by an object (the head) and limited to these conditions only (as this is all the example in the book uses), how is this possible?</p>\n", "pids": ["55a59b62612c6b12ab260ce2", "53e9b09fb7602d9703b0a5d5", "55a38912612ca64868706212", "53e9a10eb7602d97029fb925"], "flag": 1}
{"question": "Where do the feature extraction and representation learning differ?", "body": "<p><em>Feature selection</em> is a process of selecting a subset of features that contribute the most.</p>\n<p><em>Feature extraction</em> allows getting new features that are not actually present in the given set of features.</p>\n<p><em>Representation learning</em> is the process of learning a new representation that contributes the most.</p>\n<p>I can see no difference between feature extraction and representation learning.</p>\n<p>Is feature extraction the same as representation learning? If not, where do they differ? Do they differ at the application level only?</p>\n", "pids": ["53e9986eb7602d97020a7ef9"], "flag": 1}
{"question": "How to add negative samples for object detection?", "body": "<p>My question is: how to add certain negative samples to the training dataset to suppress those samples that are recognized as the object.</p>\n<p>For example, if I want to train a car detector. All my training images are outdoor images with at least one car. However, when I use the trained detector on indoor images, sometimes I got the wrong object detected (false positive). How can I add more indoor images (negative samples) to the training dataset to improve the accuracy? Can I just add them without any labeling?</p>\n", "pids": ["5a260c8117c44a4ba8a30b08"], "flag": 1}
{"question": "How often are complex networks and graph theory useful in computational neuroscience?", "body": "<p>Complex networks and graph theory seem like they would be important for computational neuroscience, but they don't come up in the literature as often as I would expect. I'm wondering how frequently they are utilized and what specific ways they tend to be applied.</p>\n", "pids": ["53e9a1d0b7602d9702ac6e93", "55a403ac65ce5cd7b3c0b011", "53e9adaab7602d97037ab122", "53e99a6db7602d97022db005", "56fbde150cf2cd3b44e4a2ee", "55a6cfb865ce054aad76cc33", "55a6b4d565ce054aad721c86", "56d91c04dabfae2eee800e1c"], "flag": 0}
{"question": "Situation Awareness - what is it good for?", "body": "<p>I was looking into Situation Awareness (SA), but have problems understanding its general use. I am aware of the work by Mica Endsley and a few others. <a href=\"https://aviation.stackexchange.com/questions/44771/what-is-situational-awareness-and-why-is-it-important/44772#44772\">This question</a> is related, but I find the answer not satisfying. </p>\n\n<p>My current understanding is this: if I know everything I need to know to achieve some goal, then I am situation-aware. In that case, I would need SA for <em>everything</em> I do. Is that correct?</p>\n\n<p>More specifically: what does Situation Awareness allow me to do that I couldn't do without it?</p>\n", "pids": ["555042bb45ce0a409eb4457c"], "flag": 1}
{"question": "What is Lipschitz constraint and why it is enforced on discriminator?", "body": "<p>The following is the abstract for the research paper titled <a href=\"https://arxiv.org/pdf/1704.00028v3.pdf\" rel=\"nofollow noreferrer\">Improved Training of Wasserstein GANs</a></p>\n<blockquote>\n<p>Generative Adversarial Networks (GANs) are powerful generative models,\nbut suffer from training instability. The recently proposed\nWasserstein GAN (WGAN) makes progress toward stable training of GANs,\nbut sometimes can still generate only poor samples or fail to\nconverge. We find that <strong>these problems are often due to the use of\nweight clipping in WGAN to enforce a Lipschitz constraint on the\ncritic, which can lead to undesired behavior.</strong> We propose an\nalternative to clipping weights: penalize the norm of gradient of the\ncritic with respect to its input. Our proposed method performs better\nthan standard WGAN and enables stable training of a wide variety of\nGAN architectures with almost no hyperparameter tuning, including\n101-layer ResNets and language models with continuous generators. We\nalso achieve high quality generations on CIFAR-10 and LSUN bedrooms.</p>\n</blockquote>\n<p>Here, the critic stands for discriminator of the GAN. I understood that the discriminator must obey <strong>Lipschitz constraint</strong> and hence weight clipping is generally done before this paper. The paper provides an alternative way, penalizing the norm of the gradient of the critic with respect to its input, to enforce the desired Lipschitz constraint.</p>\n<p>What actually is Lipschitz constraint and why is it mandatory for a discriminator to obey it?</p>\n", "pids": ["58d82fced649053542fd7453"], "flag": 1}
{"question": "In psychiatry, what does double-bookkeeping mean?", "body": "<h3>TL;DR What does double bookkeeping mean? +1 for sharing stories about your Tappy</h3>\n<p>Tappy (Talbott) has always been a tad odd, but who'd blame him, right? The guy took a whole bunch of tropane delieriants, then locked everyone out of his apartment, flipping out for reasons unknown, then in all the chaos, seriously cut an artery on the side of his head.</p>\n<p>Now, Tappy tells me that one term he picked up from his $350/hr psychiatrist is the concept of &quot;doublebookkeeping&quot; ... My impression is that it has to do with</p>\n<p><a href=\"https://en.wiktionary.org/wiki/double_bookkeeping\" rel=\"noreferrer\">From wiki</a>:</p>\n<blockquote>\n<p><strong>Double Bookkeeping.</strong> The tendency, among those who experience delusions, to perceive reality and the delusions as both being real, while remaining unbothered by the discrepancy or inconsistencies between the two.</p>\n</blockquote>\n<p>Isn't this description the same as the concept of reality testing? You may have weird things go on all around you, but it's not so much as &quot;<em>aliens are inserting thoughts into my mind</em> as it is just merely a more open-minded approach to one's phenomenology: &quot;It would appear <em>as</em> though...&quot; &quot;<em>aliens are doing this to me</em></p>\n<h2><strong>So, within the context of psychistry, mental-health, or psychology, how might one interpret the term doublebookkeeping?</strong></h2>\n<ol>\n<li><p>Does it relate, if even only thematically, to the actual accounting concept of of double-entry bookkeeping?</p>\n</li>\n<li><p>My alternative interpretation is that it means &quot;take the raw crazy inside your head&quot; (&quot;insanity&quot;), run it through a cultural appropriateness filter, process, shake, dress it up for mainstream consumption, and then release: hello outsanity.</p>\n</li>\n<li><p>Or, do you reckon Tappy lied to me just to sound cool?</p>\n</li>\n</ol>\n", "pids": ["56d92152dabfae2eee9f67e2"], "flag": 0}
{"question": "What are the best hyper-parameters to tune in reinforcement learning?", "body": "<p>Obviously, this is somewhat subjective, but what hyper-parameters typically have the most significant impact on an RL agent's ability to learn? For example, the replay buffer size, learning rate, entropy coefficient, etc.</p>\n<p>For example, in &quot;normal&quot; ML, the batch size and learning rate are typically the main hyper-parameters that get optimised first.</p>\n<p>Specifically, I am using PPO, but this can probably be applied to a lot of other RL algorithms too.</p>\n", "pids": ["5ee3526a91e011cb3bff746e"], "flag": 1}
{"question": "What algorithms are used in Artificial General Intelligence research?", "body": "<p>I've read on <a href=\"https://en.wikipedia.org/wiki/Artificial_general_intelligence\" rel=\"nofollow noreferrer\">wiki</a> that already in 2017 there were over 40 institutions researching AGI, and I wonder what type of algorithms are being studied and developed in this field.</p>\n<p>For example, for comparison with narrow AI, where models/techniques, such as ANNs, CNNs, SVMs, DT/RT, evolutionary algorithms, or reinforcement learning are used, how would AGI models differ? Do they also use these models but in some specialised way or maybe these algorithms are completely new and different from these currently used in narrow AI?</p>\n", "pids": ["53e9a8dbb7602d9703229bea"], "flag": 1}
{"question": "Do Vision Transformers handle arbitrary sequence lengths the same way as normal Transformers?", "body": "<p>Does ViT do handle arbitrary sequence lengths using masking the same way the normal Transformer does?</p>\n<p>The <a href=\"https://arxiv.org/abs/2010.11929\" rel=\"nofollow noreferrer\">ViT paper</a> doesn't mention anything about it, so I assume it uses masking like the normal Transformer.</p>\n", "pids": ["5fe4780b91e01174e2139216"], "flag": 1}
{"question": "Can I apply reparametrization trick on &quot;any&quot; deep neural network?", "body": "<p>I came across the  &quot;reparametrization trick&quot; for the first time in the <a href=\"https://mml-book.github.io/book/mml-book.pdf#page=158\" rel=\"nofollow noreferrer\">following paragraph</a> from the chapter named <em>Vector Calculus</em> from the test book titled <strong><a href=\"https://mml-book.github.io/book/mml-book.pdf\" rel=\"nofollow noreferrer\">Mathematics for Machine Learning</a></strong> by <em>Marc Peter Deisenroth et al.</em></p>\n<blockquote>\n<p>The Jacobian determinant and variable transformations will become\nrelevant ... when we transform random variables and probability\ndistributions. These transformations are extremely relevant in machine\nlearning <strong>in the context of training deep neural networks using the\nreparametrization trick, also called infinite perturbation analysis</strong>.</p>\n</blockquote>\n<p>The trick has been used in the context of neural networks training in the quoted paragraph. But when I search about the reparametrization trick, I found it only or widely in training autoencoders.</p>\n<p>In the context of training a traditional deep neural network, is the trick useful?</p>\n", "pids": ["5f0e1e779fced0a24b8aae1a", "5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "Why are GAN models not heavily used for NLP?", "body": "<p>I am wondering why there has not been more usage of GANs for NLP. I know there has been research on the subject (The Google Scholar page for the subject is <a href=\"https://scholar.google.com/scholar?q=GANs+for+nlp&amp;hl=en&amp;as_sdt=0&amp;as_vis=1&amp;oi=scholart\" rel=\"nofollow noreferrer\">here</a>).</p>\n<p>Are there any specific reasons why GANs do not work for NLP specifically VQGAN + CLIP variants? I do not understand why most text generated by AI is done through predicting the next letter or word in a sequence with RNNs when GANs have had so much success generating deep fakes and the such instead of say, predicting the next pixel.</p>\n", "pids": ["5ed0e04291e011915d9e43ee"], "flag": 1}
{"question": "What is the difference between a loss function and reward/penalty in Deep Reinforcement Learning?", "body": "<p>In Deep Reinforcement Learning (DRL) I am having difficulties in understanding the difference between a <em>Loss function</em>, a <em>reward/penalty</em> and the integration of both in DRL.</p>\n<ul>\n<li><p>Loss function: Given an output of the model and the ground truth, it\nmeasures &quot;how good&quot; the output has been. And using it, the parameters\nof the model are adjusted. For instance, MAE. But if you were working\nin Computer Vision quality, you could use, for instance, SSIM.</p>\n</li>\n<li><p>Reward: Given an agent (a model) and an environment, once the agent\nperforms an action, the environment gives it a reward (or a penalty)\nto measure &quot;how good&quot; the action has been. Very simple rewards are +1\nor -1.</p>\n</li>\n</ul>\n<p>So I see both the loss function and the reward/penalty are the quantitative way of measuring the output/action and making the model to learn. Am I right?</p>\n<p>Now, as for DRL. I see the typical diagram where the agent is modelled using a Neural Network (NN).</p>\n<p><a href=\"https://i.stack.imgur.com/CS6bI.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/CS6bI.png\" alt=\"enter image description here\" /></a></p>\n<p>I am trying to interpret it, but I do not understand it.</p>\n<p>Is it the policy related the loss function somehow? Where is the loss function? How does the reward feed the NN? Is it a parameter for the loss function?</p>\n<p>Maybe my confusion has to do with identifying NN with supervised learning, or with not getting this with Q-learning or so.. Can anyone help?</p>\n", "pids": ["573696066e3b12023e519907"], "flag": 1}
{"question": "Word for naming your negative self-talk to overcome it", "body": "<p>I'm trying to find some research - or at least a professional analysis - on the concept of naming your negative self-talk so that you can \"take away its power\" - that is, separate it from yourself and dismiss it.  I've also heard this referred to as \"naming your fear.\"</p>\n\n<p>For example, an actor might name his negative self-talk \"the critic\" so that he can dismiss those thoughts as being \"just the critic running his mouth.\"  </p>\n\n<p>Another example (and the one that I'm specifically curious about) is in software engineering, where there's a lot of talk about \"imposture syndrome,\" which in this context is just a fancy way of describing the common experience of feeling like you're underqualified for the job you're doing.  Giving it such a formal name has the added benefit of being \"proof\" that it's an irrational fear - that is, \"Even qualified people are afraid that they're underqualified, so me thinking that I'm  underqualified doesn't mean that it's true.\"</p>\n\n<p>The specific questions that I'm trying to answer are: </p>\n\n<ol>\n<li>Is there a name for this kind of technique?</li>\n<li>Have there been any studies done on this technique?</li>\n<li>Specifically relating to the \"imposture syndrome\" example, how is this different from hypochondria?  And,</li>\n<li>Are there any related concepts that I might want to take a look at?</li>\n</ol>\n", "pids": ["53e9bd55b7602d97049e9efd"], "flag": 0}
{"question": "Difference between drowsiness/sedation and sleepiness", "body": "<p>I have been trying to understand the difference between drowsiness/sedation and sleepiness. The only article I was able to find that partly answers my question is <a href=\"https://www.ipnos.com/blog/difference-sedation-sleep/\" rel=\"nofollow noreferrer\">\"The difference between sedation and sleep\" on ipnos.com</a>.</p>\n\n<p>I have experienced both, and they feel distinctly different. Sleepiness feels like a drive, but drowsiness/sedation feels like a state. My personal experience has been that sleeping when drowsy/sedated does not relieve the drowsiness/sedation, but sleeping when sleepy resolves the sleepiness.</p>\n\n<p>Back to the question: <strong>what is the neurological/neurobiological/psychopharmacological difference between sleepiness and drowsiness/sedation, and why does sleep resolve the one but not the other?</strong></p>\n", "pids": ["53e99fe9b7602d97028c65ac"], "flag": 0}
{"question": "How do I know how to design my ANN so that it fits my specific problem?", "body": "<p>We developed a neural network-based protein reconstruction tool to reconstruct the main chain from only CA atoms.</p>\n<ol>\n<li>we generated data from some selected PDBs from the RCSB website to train an NN model.</li>\n<li>we then use those data to train the NN model.</li>\n<li>we select some test PDBs, strip all atoms except CA atoms, and save them in files.</li>\n<li>we pass those CA-only PDBs through the NN model, obtain a reconstructed main chain, and save them in files.</li>\n<li>we compare original and reconstructed PDB files and calculate CRMSD values.</li>\n</ol>\n<p>The data set is large: a sample of 1398438 rows and 102 columns (data points). The model is Keras via a 4-layered MLP. There is no feedback loop or convolution applied.</p>\n<p>We obtained a CRMSD value of 0.3559, which is not satisfactory.</p>\n<hr />\n<p>How can I improve or redesign the NN model?</p>\n<p>How do I know what NN type would best serve our purpose? How do I know the number of layers we need in the model? How do I know if we need a feedback loop or not?</p>\n", "pids": ["608a7d6891e011b76ccd5513", "6080237691e011772654fa12", "5eede0b791e0116a23aafdef"], "flag": 1}
{"question": "How much of the ChatGPT output is copied from its training set (vs. being abstractively generated)?", "body": "<p>One of the main concerns of using ChatGPT answers on Stack Exchange is that it may copy verbatim or almost verbatim some text from its training set, which may infringe the source text's license. This makes me wonder how much of the ChatGPT output is copied from its training set (vs. being abstractively generated).</p>\n", "pids": ["6375a67190e50fcafd3e1d5e"], "flag": 1}
{"question": "What is the closest alternative journal to journal X?", "body": "<p>Does anyone know of a website or resource that identifies the nearest journal neighbours to journal X (any specific journal) in terms of content (perhaps defined by some distance metric defined on article keywords?). In other words, if I am rejected by journal X, which journals might consider the same paper?</p>\n", "pids": ["53e9bc01b7602d97048620f2"], "flag": 1}
{"question": "What techniques can be used to differentiate between correlation and causation?", "body": "<p>Psychology is unique among other medical sciences in that it cannot ask test participants to like, prefer or support something. As such a vast body of psychological studies are purely observational and can find correlation but not causation.</p>\n\n<p>For example if there is a link between self-awareness and empathy, how to test if being more empathetic increases self-awareness, being more self-aware increases empathy, or, let's say, level of some hormone control both and they are otherwise independent of each other?</p>\n\n<h1>Problem</h1>\n\n<p>Let's compare those two situations:</p>\n\n<ol>\n<li>A study found that people who eat a lot of sugar are fat. How researchers can test whether <strong>a)</strong> eating sugar makes people fat <strong>b)</strong> being fat makes people eat more sugar or <strong>c)</strong> both sugar consumption and body fat are influenced by the same external factor?</li>\n<li>A study found that people who like yellow color are more likely to be psychopaths. How researchers can test whether <strong>a)</strong> liking yellow turns people into psychopaths <strong>b)</strong> being a psychopath makes people like yellow <strong>c)</strong> being a psychopath and liking yellow are both influenced by the same external factor?</li>\n</ol>\n\n<p>In first scenario the answer is easy - split test subjects into two groups, force one group to restrict sugar intake and monitor their weight, help second group lose weight and monitor their sugar intake.</p>\n\n<p>In second - I cannot find the answer. Because psychology generally concerns itself with what people are as opposed to what they do, the standard approach in medicine described above cannot be utilized. Researchers can't force someone to like yellow, neither can they turn someone into a psychopath.</p>\n\n<h1>Question</h1>\n\n<p>When researchers find a statistical correlation between character traits or preferences, how do they test whether there is a causal relationship between those characteristic, if traits cannot be adjusted?</p>\n", "pids": ["53e9b783b7602d970432b7dc"], "flag": 0}
{"question": "Importance of colors in learning process?", "body": "<p>I am starting a graduating project that is an interactive software for learning programming with an animated interface. </p>\n\n<p>To be more specific, it's a software that should help students learning how to write simple programs in a programming language called <strong>C</strong>. Learning <strong>C</strong> at the beginning has its own benefits, so it's featured at many programming disciplines at universities, at least where I live. But there are some details in its syntax that may be obscure for beginners and lead to many errors and, therefore, it's an obstacle to focus on the 'big picture' of a problem, on the essence of a given solution. </p>\n\n<p>Roughly anyone who is learning programming needs to deal with frustration, but I think that the issues I mentioned make things worse. Additionally, the software that is traditionally used for writing and running code is aesthetically poor (I remember how difficult it was to look to that screen for so long when I was a beginner). The result is that many students have a very negative feeling about programming. </p>\n\n<p>So I decided to create a software that, along with some other features, is friendly on its visual aspect. One of the main features is that it allows to hide obscure elements, making an instruction simpler. Anytime, it's possible to expand that instruction and the obscure elements would change it's color, one by one, while some other elements would be colored and animated to indicate that there's a relationship envolved. That's the basic idea.</p>\n\n<p>Many years ago, in 2005, my Calculus teacher, that used to like to speak about the way we learn things, mentioned a discovery about the importance of color and movement in the learning process. I heard a similar thing on the famous <strong>TED Talk from Ken Robinson</strong>, <a href=\"https://www.ted.com/talks/ken_robinson_says_schools_kill_creativity#t-1149434\" rel=\"nofollow noreferrer\">\"Do schools kill creativity?\"</a>. I never searched about it before, but the impression I have is that all these scientific conclusions broke with some formal and strict way of education.</p>\n\n<p>I need a good article about this importance of visualization, colors and movement for two reasons. First, I think my teacher, that supervises my project, doesn't think all the 'fancy stuff' I proposed really have utility. Maybe, because, for my surprise, he wasn't aware about the discoveries I mentioned. Second, there's a formal procedure to submit the project and I need some reference to endorce it.</p>\n\n<p>I found only books about this subject. Off course, it would be nice to read some of it, but for now I really need an article to start the project.</p>\n", "pids": ["53e9b0bcb7602d9703b2e57c", "55a6619265ce054aad65be8f"], "flag": 0}
{"question": "What makes reproducing a model like GPT3/GPT3.5/ChatGPT difficult?", "body": "<p>Is it difficult for other companies to train a model similar to ChatGPT, and what makes it difficult? What is challenging about reproducing the results obtained by OpenAI with ChatGPT/GPT3.5? Would it be possible for a company like Meta or Google to have a model equal to ChatGPT/GPT3.5 in the next month or so? Why or why not?</p>\n<p>I understand that a big language model is expensive to train, so I'm expecting only large companies to be able to train such models to a sufficient extent.</p>\n", "pids": ["627e2c6d5aee126c0f9067ed", "63d9d87c90e50fcafd580fe7", "6243ca9b5aee126c0fbd1d10", "5ffd870591e01106b3241149"], "flag": 1}
{"question": "Use of Botulinum toxin A (botox) to treat depression and its effect on fight/flight repsonse", "body": "<p>Over in Health.SE, <a href=\"https://health.stackexchange.com/a/16650\">@faustus provided a couple of references to papers</a> which suggest the use of Botulinum toxin A (BTA) - otherwise known as botox - to treat depression — <a href=\"https://doi.org/10.1055/s-0035-1559621\" rel=\"noreferrer\">Magid, et al. (2015a)</a> and <a href=\"http://www.botoxfordepression.com/wp-content/uploads/2016/11/Finzi-and-Rosenthal-Journal-of-Psychiatric-Research-80-2016-93-96-2.pdf\" rel=\"noreferrer\">Finzi &amp; Rosenthal, (2016)</a></p>\n\n<p><a href=\"https://doi.org/10.1055/s-0035-1559621\" rel=\"noreferrer\">Magid, et al. (2015a)</a> states that</p>\n\n<blockquote>\n  <p>a single treatment of BTA in the <a href=\"https://en.wikipedia.org/wiki/Glabella\" rel=\"noreferrer\">glabellar region</a> can produce a strong reduction in the symptoms of major depression</p>\n  \n  <p><a href=\"https://i.stack.imgur.com/Nz4sS.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/Nz4sS.jpg\" alt=\"Improvement in BDI score.\"></a><br><sup><strong><em>Figure:</strong> Improvement in <a href=\"https://en.wikipedia.org/wiki/Beck_Depression_Inventory\" rel=\"noreferrer\">BDI score</a>. The figure shows absolute reduction in the BDI scores (14.3 vs. 5.1±standard error of the mean) from the baseline to the primary end point 6 weeks thereafter in the combined sample (n=134) for the BTA (n=59) and the placebo group (n=75), respectively.</em></sup></p>\n</blockquote>\n\n<p>whilst <a href=\"http://www.botoxfordepression.com/wp-content/uploads/2016/11/Finzi-and-Rosenthal-Journal-of-Psychiatric-Research-80-2016-93-96-2.pdf\" rel=\"noreferrer\">Finzi &amp; Rosenthal, (2016)</a> states that</p>\n\n<blockquote>\n  <p>In an initial case series, one of us (EF) injected BT into the frown of ten depressed patients, eight of whom went into remission after one treatment (<a href=\"http://www.botoxfordepression.com/wp-content/uploads/2014/03/BotoxDepressionPilotStudyMay2006.pdf\" rel=\"noreferrer\">Finzi and Wasserman, 2006</a>; <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3756121/\" rel=\"noreferrer\">Finzi, 2013</a>). The study was limited by its small size, lack of controls, and lack of blinding. In three subsequent randomized, double blind and placebo controlled trials, we and other researchers have found response rates of 50—60% in major depression, with about one third of patients going into remission (<a href=\"https://doi.org/10.1016/j.jpsychires.2012.01.027\" rel=\"noreferrer\">Wollmer et al. 2012</a>; <a href=\"http://pedroschestatsky.com.br/_files/view.php/download/material/92/54163c0e50f27.pdf\" rel=\"noreferrer\">Finzi and Rosenthal, 2014</a>; <a href=\"https://doi.org/10.4088/JCP.13m08845\" rel=\"noreferrer\">Magid et al. 2014</a>, <a href=\"https://pdfs.semanticscholar.org/e267/0a6f79588df0b5339959e0976393d68856fe.pdf\" rel=\"noreferrer\">2015b</a>). BT showed antidepressant effects both when used as an ancillary treatment and by itself.</p>\n</blockquote>\n\n<p>However, they then go on to say</p>\n\n<blockquote>\n  <p>How might injecting BT into the corrugator muscle influence the emotional brain? FMRI imaging has shown that subjects who received BT injections into their frown muscles had amygdala that were less responsive to negative stimuli (<a href=\"https://doi.org/10.1093/cercor/bhn104\" rel=\"noreferrer\">Hennenlotter et al. 2009</a>). Recent work has confirmed that amygdala activity in response to angry faces was decreased when the frown muscles were paralyzed by BT injection. Furthermore, amygdala activity returned to its original inducible state after the effects of the BT injection had worn off, confirming that BT reversibly severed afferent feedback from the <a href=\"https://en.wikipedia.org/wiki/Corrugator_supercilii_muscle\" rel=\"noreferrer\">corrugator muscle</a> to the amygdala (<a href=\"https://doi.org/10.1186/2045-5380-4-11\" rel=\"noreferrer\">Kim et al. 2014</a>).</p>\n</blockquote>\n\n<p><strong>With the decrease in amygdala activity in response to angry faces, am I correct in thinking that this could have a detrimental effect with regard to the flight/flight response in potentially dangerous situations?</strong></p>\n\n<h2>References</h2>\n\n<p>Finzi, E. (2013). Antidepressant effects of botulinum toxin A: scientific rationale. <em>Journal of psychiatry &amp; neuroscience: JPN</em>, 38(5), E29. PMCID: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3756121/\" rel=\"noreferrer\">PMC3756121</a></p>\n\n<p>Finzi, E., &amp; Rosenthal, N. E. (2014). Treatment of depression with onabotulinumtoxinA: a randomized, double-blind, placebo controlled trial. <em>Journal of psychiatric research</em>, 52, 1-6. DOI: <a href=\"https://doi.org/10.1016/j.jpsychires.2013.11.006\" rel=\"noreferrer\">10.1016/j.jpsychires.2013.11.006</a></p>\n\n<p>Finzi, E., &amp; Rosenthal, N. E. (2016). Emotional proprioception: treatment of depression with afferent facial feedback. <em>Journal of psychiatric research</em>, 80, 93-96. DOI: <a href=\"https://doi.org/10.1016/j.jpsychires.2016.06.009\" rel=\"noreferrer\">10.1016/j.jpsychires.2016.06.009</a></p>\n\n<p>Finzi, E., &amp; Wasserman, E. (2006). Treatment of depression with botulinum toxin A: a case series. <em>Dermatologic Surgery</em>, 32(5), 645-650. DOI: <a href=\"https://doi.org/10.1111/j.1524-4725.2006.32136.x\" rel=\"noreferrer\">10.1111/j.1524-4725.2006.32136.x</a></p>\n\n<p>Hennenlotter, A., Dresel, C., Castrop, F., Ceballos-Baumann, A. O., Wohlschläger, A. M., &amp; Haslinger, B. (2008). The link between facial feedback and neural activity within central circuitries of emotion—New insights from Botulinum toxin–induced denervation of frown muscles. Cerebral Cortex, 19(3), 537-542. DOI: <a href=\"https://doi.org/10.1093/cercor/bhn104\" rel=\"noreferrer\">10.1093/cercor/bhn104</a></p>\n\n<p>Kim, M. J., Neta, M., Davis, F. C., Ruberry, E. J., Dinescu, D., Heatherton, T. F., ... &amp; Whalen, P. J. (2014). Botulinum toxin-induced facial muscle paralysis affects amygdala responses to the perception of emotional expressions: preliminary findings from an ABA design. <em>Biology of mood &amp; anxiety disorders</em>, 4(1), 11. DOI: <a href=\"https://doi.org/10.1186/2045-5380-4-11\" rel=\"noreferrer\">10.1186/2045-5380-4-11</a></p>\n\n<p>Magid, M., Reichenberg, J. S., Poth, P. E., Robertson, H. T., LaViolette, A. K., Kruger, T. H., &amp; Wollmer, M. A. (2014). Treatment of major depressive disorder using botulinum toxin A: a 24-week randomized, double-blind, placebo-controlled study. <em>The Journal of clinical psychiatry</em>, 75(8), 837-844. DOI: <a href=\"https://doi.org/10.4088/JCP.13m08845\" rel=\"noreferrer\">10.4088/JCP.13m08845</a></p>\n\n<p>Magid, M., Finzi, E., Kruger, T. H. C., Robertson, H. T., Keeling, B. H., Jung, S., ... &amp; Wollmer, M. A. (2015a). Treating depression with botulinum toxin: a pooled analysis of randomized controlled trials. <em>Pharmacopsychiatry</em>, 25(06), 205-210. DOI: <a href=\"https://doi.org/10.1055/s-0035-1559621\" rel=\"noreferrer\">10.1055/s-0035-1559621</a></p>\n\n<p>Magid, M., Finzi, E., Kruger, T. H. C., Robertson, H. T., Keeling, B. H., Jung, S., ... &amp; Wollmer, M. A. (2015b). Treating depression with botulinum toxin: a pooled analysis of randomized controlled trials. Pharmacopsychiatry, 48(6), 205-210. DOI: <a href=\"https://doi.org/10.1055/s-0035-1559621\" rel=\"noreferrer\">10.1055/s-0035-1559621</a></p>\n\n<p>Wollmer, M. A., de Boer, C., Kalak, N., Beck, J., Götz, T., Schmidt, T., ... &amp; Sönmez, D. (2012). Facing depression with botulinum toxin: a randomized controlled trial. <em>Journal of psychiatric research</em>, 46(5), 574-581. DOI: <a href=\"https://doi.org/10.1016/j.jpsychires.2012.01.027\" rel=\"noreferrer\">10.1016/j.jpsychires.2012.01.027</a></p>\n", "pids": ["53e9ab90b7602d9703538650"], "flag": 0}
{"question": "Why pay a fee to have your article (in a subscription-based journal) made open access when you can just put the preprint on arXiv?", "body": "<p>Upon acceptance, some journals offer open access through an <em>optional</em> fee. This model differs from the usual open access model in which <em>all</em> authors pay a fee and <em>all</em> accepted papers are accessible <em>without</em> restriction. <strong>Addendum</strong>: the latter is referred to as simply open access, while the former is referred to as <em>hybrid</em> open access.</p>\n\n<p>My question is as follows: I publish (most of) my papers on the <a href=\"http://arxiv.org\" rel=\"noreferrer\">arXiv</a>, and as such, the preprints are picked up by search engines. When the corresponding camera-ready journal version appears, anyone with an internet connection can still access my arXiv paper, and hence I always opt <em>not</em> to pay the optional fees to make my paper open access.</p>\n\n<p>In fact, most respected researchers in mathematics/computer science/physics/etc. also publish to the arXiv. As such, I am confused as to why this model of open access exists. What demand is it satisfying? Is there some advantage to paying these optional fees that I am not seeing?</p>\n\n<p>P.S. -- The journal I have in mind currently is a SIAM journal. Their <a href=\"https://www.siam.org/journals/oa.php\" rel=\"noreferrer\">open access policies are listed here</a>. Their open access fee is $2,500 USD (this is not an unusual number for publishers following this approach). This (at least to me) is a substantial amount of money per paper.</p>\n", "pids": ["573695d26e3b12023e4e9f3f", "56d920cfdabfae2eee9ca0fb"], "flag": 1}
{"question": "Does a general impairment test exist, that specifically would be useful for the context of driving?", "body": "<p>We know that  alcohol negatively influences a driver's ability to drive. Governments typically combat this by making drunk driving illegal, and use the concentration of alcohol in breath or blood as the definitive measure as to whether a crime has been committed or not. </p>\n\n<p>In this sense - alcohol in the blood/breath is merely a proxy for impairment, but one that is quite reliable - when one is drunk they're going to show alcohol in the blood stream, this is able to be accurately measured.  </p>\n\n<p>There are other ways a driver can be impaired as well - quite commonly through sleepiness/fatigue, but also other drugs, or distraction (driving while texting), or emotional distress. </p>\n\n<p>The prospect of 'drugged driving' comes up quite commonly in discussions about legalising cannabis. Where there is a reliable test of alcohol impairment - it's not quite the same for cannabis and other drugs - the problem being that saliva tests can show the presence of the drug long after the person has sobered up. A blood test might be viable - but that's perhaps not practical, in terms of getting a cop to administer to a driver. </p>\n\n<p>With fatigue, it's even more problematic - there's no drug to detect at all. </p>\n\n<p>In light of this - has any general impairment test - that perhaps tests reaction times or some other metric, that can be administered at a roadside, been developed? </p>\n", "pids": ["55a5eb7465cead59c82f8180", "53e9b388b7602d9703e67fe4", "53e9b1f8b7602d9703c91568", "55a485c165ce31bc877daade"], "flag": 0}
{"question": "Would self-hosting ChatGPT be feasible, w.r.t. computation costs?", "body": "<p>Suppose the pre-trained, current date (2023-02-04) ChatGPT model was released open source, would it be feasible for regular users to interact with the model on a self-hosted computer?</p>\n<h2>Assumptions</h2>\n<ol>\n<li>I assume getting output based on some input is, at least, hundreds of times faster than training such a model.</li>\n<li>I assume no additional output parsing/input limitations are used. In particular I can imagine all the boiler plate to keep the ChatGPT model(s) acting politically correct etc. may be a significant overhead. This is to be ignored for this question.</li>\n</ol>\n<h2>Data</h2>\n<p>So far I've found the ChatGPT 3.5 model to have <a href=\"https://lifearchitect.ai/chatgpt/\" rel=\"nofollow noreferrer\">175 billion parameters</a>:</p>\n<p><a href=\"https://i.stack.imgur.com/DeIZD.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/DeIZD.png\" alt=\"enter image description here\" /></a></p>\n<p>Though I do not yet know how large that is in <code>Mb</code> nor do I have an idea on how long generating an output would typically take.</p>\n", "pids": ["5ed0e04291e011915d9e43ee", "63608e5690e50fcafdee192e"], "flag": 1}
{"question": "What is the difference between psychosis and neurosis?", "body": "<p>Given such a sentence by a Test of English as a Foreign Language textbook,</p>\n\n<blockquote>\n  <p>Mental disorder include psychosis and neurosis.</p>\n</blockquote>\n\n<p>I googled and found <a href=\"https://www.differencebetween.com/difference-between-psychosis-and-neurosis/\" rel=\"nofollow noreferrer\">a page</a></p>\n\n<p>In introduction, the pages says,</p>\n\n<blockquote>\n  <p>Psychosis and neurosis are terms used to describe mental conditions. Sometimes these words are used <strong>interchangeably</strong> to refer to the same condition.</p>\n</blockquote>\n\n<p>Only what I clearly could deduct from the page is psychosis is brought about particularly by the use of alcohol and illicit use of drugs and their withdrawal.</p>\n\n<p>Could anyone support me to distinguish these two symptoms more clearly ( and hopefully in a simpler way? )</p>\n", "pids": ["5dc55037df1a9c0c415140a0"], "flag": 0}
{"question": "Is there a criterion to distinct between a philia and a paraphilia?", "body": "<p>The terms &quot;<a href=\"https://en.wikipedia.org/wiki/Androphilia_and_gynephilia\" rel=\"nofollow noreferrer\">Androphilia&quot; and &quot;Gynephilia&quot;</a> describe the two major <code>romantic and/or sexual orientation/s</code> of humans → towards &quot;masculine&quot; humans and &quot;feminine&quot; humans, respectively.</p>\n<p>Generally any human (including Asexuals which only lack the desire to have sex but   not the romantic connection desire) will likely be classified by some in society as a &quot;heterosexual&quot;, &quot;homosexual&quot; or &quot;bisexual&quot;, according to that person's <code>romantic and/or sexual orientation/s</code> and in the context of gender.</p>\n<ul>\n<li><p>One can say that attractions to FTM transgenders and attraction to MTF transgenders are separate major philias &quot;Andromimetophilia&quot; and &quot;Gynemimetophilia&quot;<sup>(as somewhat accurate yet probably bad terms)</sup>.</p>\n</li>\n<li><p>One could speak of a third and forth philias (or fifth and sixth philias, depending how one counts) to Male-oriented intersex individuals and Female-oriented intersex individuals.</p>\n</li>\n<li><p>One could go to the extreme and speak about philias to FTM and MTF <a href=\"https://en.wikipedia.org/wiki/Detransition\" rel=\"nofollow noreferrer\">detransitioned</a> people.</p>\n</li>\n</ul>\n<h2>My problem</h2>\n<p>Any of the above philias can have one or more paraphilias, which can be not harmful or does harmful but it is unclear to me if there is a criterion to distinct between a philia and a paraphilia.</p>\n<h3>Non harmful examples</h3>\n<ul>\n<li><p>A man with gynephilia (heterosexual) can have a paraphilia such as for women in army uniform and on the contrary, a man with androphilia (homosexual) can have a paraphilia for men in army uniform.</p>\n</li>\n<li><p>A man with gynephilia (heterosexual) can have a paraphilia for women with Gothic appearance and on contrary, a man with androphilia (homosexual) can have a paraphilia for men with Gothic appearance.</p>\n</li>\n</ul>\n<h3>Harmful examples</h3>\n<ul>\n<li><p>The first harmful example is pedophiliac paraphilia:<br>\nA man with gynephilia (heterosexual) can have a paraphilia for little girls (say under sexual maturation) and on the contrary, a man with androphilia (homosexual) can have a paraphilia for little boys (say, under sexual maturation).</p>\n</li>\n<li><p>Another harmful example is zoophilia which includes exploitation of animals who cannot give consent and might be raped.</p>\n</li>\n</ul>\n<p>Both pedophilia (not to be confused with hebephilia which is attraction to young teenagers) as well as zoophilia, are rare paraphilias that may manifest themselves in harmful or illegal behavior.</p>\n<h2>Interim note</h2>\n<p>As I have shown, the &quot;philia&quot; term can describe both sexual orientations and their sub components (<em>not harmful</em> and <em>is harmful</em>).</p>\n<h2>My question</h2>\n<p>Is there a criterion to distinct between a philia and a paraphilia?</p>\n<blockquote>\n<p>This question encapsulates the question:</p>\n<ul>\n<li>Does the term Philia exists in psychological literature for describing <code>romantic and/or sexual orientation/s</code> and not just fetishes, or alternatively, as a standalone term?</li>\n</ul>\n</blockquote>\n", "pids": ["53e9b89ab7602d9704470bb6", "53e9a698b7602d9702fcb749", "55a5ce8365ce60f99bf5e607", "55a4091a65ce5cd7b3c129e6", "5c0f7cc2da562944ac7e0cf5"], "flag": 1}
{"question": "Meaning of &quot;attitudinal acceptance&quot;", "body": "<p>I found an interesting study called \"<a href=\"https://www.researchgate.net/publication/224943991_A_Comparison_of_Family_Functioning_Life_and_Marital_Satisfaction_and_Mental_Health_of_Women_in_Polygamous_and_Monogamous_Marriages\" rel=\"nofollow noreferrer\">A Comparison of Family Functioning, Life and Marital Satisfaction, and Mental Health of Women in Polygamous and Monogamous Marriages</a>\" by Al-Krenawi et al. It is about the negative impact of polygamy on numerous aspects of the wifes' wellbeing. As an erstwhile physicist I understand statistics, but the terminology in psychology and psychiatry is totally new for me. </p>\n\n<p>I want to ask about the precise meaning of the word \"attitudinal in \"attitudinal acceptance\". The context is the following:</p>\n\n<blockquote>\n  <p>Previous research suggests that education and attitudinal acceptance of polygamy are inversely correlated...</p>\n</blockquote>\n\n<p>Google search returns a plethora of scientific articles, but so far I haven’t spotted a definition. The general definition of \"attitudinal\" from <a href=\"https://www.merriam-webster.com/dictionary/attitudinal\" rel=\"nofollow noreferrer\">Webster</a> reads:</p>\n\n<blockquote>\n  <p>relating to, based on, or expressive of personal attitudes or feelings</p>\n</blockquote>\n\n<p>and seems to suggest that any acceptance would be attitudinal. Thus, I believe it must carry a specific meaning in psychology.</p>\n", "pids": ["53e99991b7602d97021d1a78", "53e99991b7602d97021d1a78", "53e9a749b7602d9703080a6d"], "flag": 0}
{"question": "Is there a non-interactive alternative to the concept of SuperMemo/spaced repetition?", "body": "<p>I recently wrote <a href=\"https://github.com/d33tah/strokes\" rel=\"nofollow noreferrer\">an open-source application</a> that lets you practice Chinese writing and the decisions I made about its inner workings were related to my theories of how human memory works. I'm not sure which facts specifically are relevant, so I'll explain it all in context (scroll down to the the \"question\" section if you don't believe it's relevant):</p>\n\n<p>The goal of the application is to help user remember the writing of Chinese characters and their pronunciation. The assumption is that the user would input a set of Chinese characters, most of which are non-trivial to write with aid, let alone from memory. Moreover, there is the concept of stroke order which is useful to remember: each character is made of strokes which should be written in a specific shape, position and order. This makes it pretty complex. I heard that the way Chinese people cope with learning this is that they repeat writing of each character 1000 times, but I believe this is not the best use of time, given the number of characters.</p>\n\n<p>The way my program works is that for each input character, user is taught each stroke four times - 1) alone, 2) with all strokes introduced so far, 3) in context and 4) in context but with no aid -- like in this example:</p>\n\n<p><a href=\"https://i.stack.imgur.com/rB8Gb.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/rB8Gb.png\" alt=\"example output of my program\"></a></p>\n\n<p>In this example, user is exposed to first four digits in Chinese and should fill in the highlighted strokes, as well as ones already introduced. In each fourth tile, user is expected to fill in all already introduced strokes with no aid, forcing them to focus on geometry.</p>\n\n<p>As you can see, tiles are split into groups that have thicker borders. After introducing the first two characters, there is a special group of tiles at the end of second and beginning of third line: it is blank and contains a pronunciation hint. The user is expected to try to recall the character and write it in its entirety in those tiles.</p>\n\n<h1>Question</h1>\n\n<p>This is the part I have a question about: the goal of those specific tiles is to try to get the user to try to recall the characters hoping they eventually land in long-term memory, which should already not be in the working memory because it usually takes more than five minutes to write two characters. Then user is expected to practice next two characters and the drill repeats. Then, user is expected to recall all four characters introduced so far, as shown in the graphic above. This pattern repeats and for characters ABCDEFGH would look like following - hopefully you can deduce how it works:</p>\n\n<pre><code>A\nB\nAB\nC\nD\nCD\nABCD\nE\nF\nEF\nG\nH\nEFGH\nABCDEFGH\n</code></pre>\n\n<p>I showed it to a person interested in psychology and she immediately said: \"this reminds me of spaced repetition\"! I read about this and also found SuperMemo, and a program that implements it: Anki flashcards. </p>\n\n<p>The problem is that both those programs are based on a formula that prognosticates if the user has already memorized a certain item; with that, they assign relative importance to review this item. </p>\n\n<p>Is there another statistical model of human memory I could use for my application that doesn't have this requirement, but - for example - assumes an \"average person\" and a certain expected probability that this character will be at a given time remembered?</p>\n", "pids": ["53e9a6f5b7602d970302c5dd"], "flag": 0}
{"question": "Depression Causing Body Dysmorphic Disorder (BDD)", "body": "<p>Whilst trying to think of non-chemical/hormonal causes of low self-esteem when reading <a href=\"https://psychology.stackexchange.com/q/20235\">Is low self-esteem, a brain chemical imbalance problem, rather than a personality defect, and can&#39;t be fixed by any amount of counselling/self-help?</a>, I have been considering Body Dysmorphia Disorder (BDD).</p>\n\n<p>Whilst it is a mental disorder in its own right, I have been thinking that BDD can cause depression due to the constant upset caused by the feelings concerning the body, but not the other way round; yet <a href=\"https://www.mind.org.uk/information-support/types-of-mental-health-problems/body-dysmorphic-disorder-bdd/causes-of-bdd/\" rel=\"nofollow noreferrer\">the UK mental health charity, Mind, states</a>.</p>\n\n<blockquote>\n  <p>No one knows exactly what causes BDD. However, recent research suggests that there are a number of different risk factors that could mean you are more likely to experience BDD, such as:</p>\n  \n  <ul>\n  <li>abuse or bullying</li>\n  <li>low self-esteem</li>\n  <li>fear of being alone or isolated</li>\n  <li>perfectionism or competing with others</li>\n  <li>genetics</li>\n  <li>depression or anxiety</li>\n  </ul>\n</blockquote>\n\n<p><strong>I am asking here specifically about depression</strong> because for the other reasons in MINDs list such as perfectionism or bullying, anxiety could cause BDD in my thinking.</p>\n\n<p>With <em>risk not necessarily meaning cause</em>, in order for the risk to be quantified, there needs to be indication from studies and past clients that depression led to BDD rather than the other way round, and yet I am not convinced of this.</p>\n\n<p>What studies are available which indicate that depression can cause BDD rather than the other way round?</p>\n", "pids": ["56d87631dabfae2eee19f334", "53e9aa8eb7602d9703407ce2", "53e9b6d0b7602d970425b564"], "flag": 0}
{"question": "What pro- or anti-environmental behaviors are feasible to measure objectively rather than with self-report?", "body": "<p>One of the central challenges in understanding pro-environmental behavior is measurement. Currently, most researchers (including myself) lean on self-report of behavior.</p>\n\n<p>I'm looking for a brainstorm. What kinds of pro-environmental behaviors might be realistically measured by researchers? I think there's room for more creativity. I'd love to hear some ideas. For example, recycling bins have been measured at the curb for weight (time-consuming), electrical meters have been read by students (time-consuming), household water usage has been measured by partnering with a water district (long-term negotiation due to privacy).... there are also laboratory tasks such as recycling, donation, and turning out the lights, but these are lower-quality measures because they only occur once.</p>\n\n<p>There's room here for more creativity. What other pro- or anti-environmental behaviors can be observed by researchers in the real world or in an online survey? I'm looking for a brainstorm, not a literature review. I work in this area and know the key papers well. Thank you for any suggestions!</p>\n", "pids": ["5ae1b158a2e6b107866a690e"], "flag": 1}
{"question": "Why is a cross-dominant/ambidextrous brain more susceptible to mental illness?", "body": "<p>The left and right hemispheres of the brain are connected by a bundle of fibers called the corpus callosum. Ambidextrous, left handers and cross-dominant people have symmetrical brains as opposed to right handers, who have larger left hemispheres. Cross-dominant, lefties and ambidextrous people also have a stronger corpus callosum which lends itself to better communication between the two hemispheres. It seems like better communication between hemispheres would be an evolutionary benefit.</p>\n\n<p>So, I am curious as to why a symmetrical brain would have a higher rate of mental illness than a right handed/left brained person, as reported in this news release by Imperial College London: <a href=\"https://www.imperial.ac.uk/news/81322/mixed-handed-children-more-likely-have-mental/\" rel=\"nofollow noreferrer\">Mixed-handed children more likely to have mental health, language and scholastic problems, say researchers</a></p>\n", "pids": ["53e9b6fab7602d970428f380", "53e99dfeb7602d97026c26f7"], "flag": 0}
{"question": "Bottom up thinking - what is it?", "body": "<p>Mlodinow has <a href=\"http://leonardmlodinow.com/leonard-mlodiinow-books/elastic/\" rel=\"nofollow noreferrer\">book</a> Elastic thinking, which sounds interesting and where he mentions bottom up processes/thinking; which he equates with elastic thinking.</p>\n\n<p>I have watched numerous videos about it, and even read some sample chapters of the book - but to my surprise, it is still unclear to me what exactly he means by <strong>bottom up thinking</strong>?</p>\n\n<p>One unclear quote from the book is:</p>\n\n<blockquote>\n  <p>Elastic thought is where your new ideas come from. Imaginative, original, and non-linear, it is “bottom-up” thinking, in which insights percolate into the mind, seemingly from nowhere.</p>\n</blockquote>\n\n<p>Another unclear quote:</p>\n\n<blockquote>\n  <p>Elastic thinking is about stretching your mind and using ‘bottom up’ processing in the brain rather than the top down executive functions that drive analytical thinking</p>\n</blockquote>\n\n<p>Can someone please bring <strong>some simple and concrete examples from daily life</strong>, of what is bottom up thinking?</p>\n\n<p>ps. His book is based on research and says it is known term in science community, this elastic thinking/bottom up thinking, and hence my hope people here may know what is it.</p>\n", "pids": ["56d82cc7dabfae2eee07f796"], "flag": 0}
{"question": "What works for procrastination?", "body": "<p>Procrastination seems universal and well understood by the public. However, there seems to be very little research into techniques and approaches that works to reduce and manage procrastination. </p>\n\n<p>The previous aversion therapy thread cited a 2012 review that found minimal research into procrastination. It is 2019 now and I was wondering whether anyone knows of any recent research? - <a href=\"https://psychology.stackexchange.com/a/18477/21\">Effectiveness of aversion therapy for procrastination</a> </p>\n\n<p>Another thread will address procrastination in ADHD - <a href=\"https://psychology.stackexchange.com/questions/23813/treatment-and-strategies-for-procrastination-for-adhd\">Treatment and strategies for procrastination for ADHD</a></p>\n", "pids": ["5c757d75f56def9798ae4053"], "flag": 0}
{"question": "What makes the approximation capabilities of neural networks different than something like, say, Fourier series?", "body": "<p>People often cite the universal approximation theorem as a reason for why neutral networks are so effective at capturing patterns or features of various training data. However, this seems unremarkable to me, because something like Fourier series are also able to approximate almost any function between compact domains of Euclidean spaces.</p>\n<p>So my question is, what makes neural networks different from something like Fourier analysis where we can approximate any sufficiently nice function we like as well?</p>\n<p>Am I not understanding the universal approximation theorem, or are there justifications for the power of neural networks that go deeper than talk about approximation?</p>\n", "pids": ["5fc7685e91e0114897921118", "60d1558d91e011c16f0cb462"], "flag": 1}
{"question": "How do Google cars recognize the traffic signs?", "body": "<p>The paper <a href=\"http://repository.supsi.ch/5145/1/IDSIA-04-12.pdf\" rel=\"nofollow noreferrer\">Multi-column Deep Neural Networks for Image Classification</a> (pages 7-8) shows an attempt at recognizing the traffic signs, with lower error rates, by using multi-column deep neural networks. </p>\n\n<p>Are Google cars using similar techniques of predicting signs using DNN, or are they using some other method?</p>\n", "pids": ["555045d745ce0a409eb59fb8"], "flag": 1}
{"question": "Should we fear an AGI if it will be equivalent to a human?", "body": "<p>It seems to me that the first AGIs ought to be able to perform the same sort and variety of tasks as people, with the most computationally strenuous tasks taking an amount of time compared to how long a person would take. If this is the case, and people have yet to develop basic AGI (meaning it's a difficult task), should we be concerned if AGI is developed? It would seem to me that any fears about a newly developed AGI, in this case, should be the same as fears about a newborn child.</p>\n", "pids": ["53e9a06db7602d9702956c76"], "flag": 1}
{"question": "How can one distinguish between an AI and a &quot;sufficiently advanced algorithm&quot;?", "body": "<blockquote>\n<p>Any sufficiently advanced algorithm is indistinguishable from AI.---<a href=\"https://twitter.com/othermichael?lang=en\" rel=\"nofollow noreferrer\">Michael Paulukonis</a></p>\n</blockquote>\n<p>According to <a href=\"https://ai.stackexchange.com/questions/1507/what-are-the-minimum-requirements-to-call-something-ai\">What are the minimum requirements to call something AI?</a>, there are certain requirements that a program must meet to be called AI.</p>\n<p>However, according to that same question, the term AI has become a buzzword that tends to be associated with new technologies, and that certain algorithms may be classified in AI in one era and then dismissed as boring in another era once we understand how the technology works and be able to properly utilize it (example: voice recognition).</p>\n<p>Humans are able to build complex algorithms that can engage in behaviors that are not easy to predict (due to <a href=\"https://en.wikipedia.org/wiki/Emergence\" rel=\"nofollow noreferrer\">emergent complexity</a>). These &quot;sufficiently advanced&quot; algorithms could be mistaken for AI, partly because humans can also engage in behaviors that are not easy to predict. And since AI is a buzzword, humans may be tempted to engage in this self-delusion, in the hopes of taking advantage of the current AI hype.</p>\n<p>Eventually, as humanity's understanding of their own &quot;sufficiently advanced algorithms&quot; increase, the temptation to call their algorithms AI diminishes. But this temporary period of mislabeling can still cause damage (in terms of resource misallocation and hype).</p>\n<p>What can be done to <em>distinguish</em> a sufficiently advanced algorithm from AI? Is it even possible to do so? Is a sufficiently advanced algorithm, by its very nature, AI?</p>\n", "pids": ["53e9a06db7602d9702956c76"], "flag": 1}
{"question": "Can cancer cells in the same person, organ, and origin have different DNA?", "body": "<p>Is it possible for cells from the same tumor to have different genetic material, and if so, to what degree is it possible (how fast do they mutate) ?</p>\n", "pids": ["5fd6c787641177de89d4eb18", "5c757e24f56def9798b5b2e4"], "flag": 1}
{"question": "How is the depth of a convolutional layer determined?", "body": "<p>I am looking at a diagram of <a href=\"https://arxiv.org/pdf/1311.2901.pdf\" rel=\"nofollow noreferrer\">ZFNet</a> below, in an attempt to understand how CNNs are designed.</p>\n<p><a href=\"https://i.stack.imgur.com/8af4m.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/8af4m.png\" alt=\"enter image description here\" /></a></p>\n<p>In the first layer, I understand the depth of 3 (224x224x3) is the number of color channels in the image.</p>\n<p>In the second layer, I understand the <span class=\"math-container\">$110 \\times 110$</span> is computed with the formula <span class=\"math-container\">$W_2 = (W_1-F+2P)/S + 1 = (224 - 7 + 2*1/2)/2 + 1 = 110$</span>.</p>\n<p>I also understand how pooling works to create a size reduction from <span class=\"math-container\">$110 \\times 110$</span> to <span class=\"math-container\">$55 \\times 55$</span>.</p>\n<p>But where does the depth of <span class=\"math-container\">$96$</span> come from in the second layer? Is this the new &quot;batch size&quot;? Is it totally arbitrary?</p>\n<p>Bonus points if someone can direct me to a reference that can help me understand how all these dimensions relate to each other.</p>\n", "pids": ["573695ff6e3b12023e5136ef"], "flag": 1}
{"question": "Effectiveness of &quot;non-focused&quot; learning", "body": "<p>Is anything known how effective is \"non-focused\" learning. For example when I am focused on something else (watching TV, doing work in the office) while listening to language learning material (words and phrases and their translations for example). Or playing scales on your guitar while watching TV (okay, seem to be more invovled then merely listening, but I guess you get the idea).</p>\n\n<p>So is there anything known about that, or any studies on that?</p>\n\n<p><em>EDIT</em>: I do not have found any studies, mainly because I do not know what to search for, googling terms like \"non-focused learning\", \"passive learning\", \"distractive learning\" do not give anything useful. I have a minor in psychology and if I see a study I can relate it to what I am looking for, but I am not a researcher in psychology. So this question came up out of curiosity of my own (and to be honest, its quite practical if possible to learn something by \"not even trying\" to say in lax language). I know about the 10k rule of expertise, and they always talk about \"deliberate practice\", obviously the kind of practice I am looking for is not deliberate, but maybe someone asked if its still beneficial, even if on a much smaller scale. I would suspect that it is not difficult to design studies for it, just let people perform some task, tell them its the main task, then do some distraction in the background (which is the supposed learning content, melodies, words whatever). Then afterwards (obviously to the surprise of the subject) ask question about that your let it perform a task to access gained knowledge.</p>\n", "pids": ["53e9b775b7602d970431a9c2", "53e9b621b7602d97041770a2"], "flag": 0}
{"question": "How do I get a DOI for a dataset?", "body": "<p>A DOI is a commonly used <em>digital object identifier</em> to refer to an electronic document. How do I secure a DOI for a research dataset, to help share and identify it?</p>\n", "pids": ["5f8a083edb0c4ff231649144", "5fabb8cfd4150a363c632fb9"], "flag": 1}
{"question": "Is it possible for someone to have anorexia without body image issues?", "body": "<p>I've been reading about <a href=\"https://www.mayoclinic.org/diseases-conditions/anorexia-nervosa/symptoms-causes/syc-20353591\" rel=\"nofollow noreferrer\">anorexia</a> and as I understand it, it's an eating disorder where someone severely restricts their intake of food because of an intense fear of gaining weight, a distorted perception of weight, equating weight with self-worth, and things like that.</p>\n\n<p>I was wondering, is it possible for someone to have anorexia without weight and body esteem issues? In other words, they severely restrict their food intake but not because of a fear of gaining weight or body esteem issues. I came across <a href=\"https://www.quora.com/Can-someone-have-anorexia-without-having-body-image-issues\" rel=\"nofollow noreferrer\">this Quora question</a>, but the only answer there is an anecdotal one.</p>\n\n<p>Or perhaps is there some eating disorder other than anorexia that matches this description? I came across this article, <a href=\"https://www.eatingdisorderhope.com/blog/ed-body-dysmorphia\" rel=\"nofollow noreferrer\">Does Everyone With an ED Have Body Dysmorphia?</a>, but it didn't really help.</p>\n", "pids": ["55a601d165cead59c8327572", "567412480cf25cff3e0afeef"], "flag": 0}
{"question": "How widespread is learned-helplessness in society?", "body": "<p>Looking at these resources:</p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Learned_helplessness\" rel=\"nofollow noreferrer\" title=\"Learned helplessness - Wikipedia\">Wikipedia, Learned helplessness</a></li>\n<li><a href=\"https://onlinelibrary.wiley.com/doi/epdf/10.1002/9780470479216.corpsy0500\" rel=\"nofollow noreferrer\" title=\"Learned Helplessness - Peterson - - Major Reference Works - Wiley Online Library\">Christopher Peterson, Learned Helplessness, 2010</a></li>\n<li><a href=\"https://books.google.com.vn/books?hl=en&amp;lr=&amp;id=BSz5BwAAQBAJ&amp;oi=fnd&amp;pg=PA1&amp;dq=learned+helplessness+&amp;ots=1wyov6f1To&amp;sig=qn4sJFj6GKQS27nr9GlMCcnfa4o&amp;redir_esc=y#v=onepage&amp;q=learned%20helplessness&amp;f=false\" rel=\"nofollow noreferrer\" title=\"Human Learned Helplessness: A Coping Perspective - Mario Mikulincer - Google Books\">Mario Mikulincer, Human Learned Helplessness: A Coping Perspective, 2013</a></li>\n</ul>\n<p>I'm still unable to find how widespread learned helplessness is in society. Do you know where I should take a look?</p>\n", "pids": ["55a5e7e2612c6b12ab313f67"], "flag": 1}
{"question": "How exactly does transcranial direct current stimulation (tDCS) work?", "body": "<p>The method of <strong>transcranial direct current stimulation (tDCS)</strong> involves the flow of electric charge from a positive electrode to a negative one.</p>\n\n<p>This method is not exactly a stimulation method because the current applied do not provoke neurons firing such as TMS (transcranial magnetic stimulation), it just <strong>modulate</strong> the level of excitability of neurons. <strong>How happens this modulation of excitability?</strong></p>\n\n<p>Precisely, my question is:</p>\n\n<p><strong>How that positive or negative current interferes with electric fields generated by neurons?</strong></p>\n\n<p><em>references:</em></p>\n\n<ul>\n<li><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5127836/\" rel=\"noreferrer\">Impact of Transcranial Direct Current Stimulation (tDCS) on Neuronal Functions</a></li>\n</ul>\n", "pids": ["5c756a56f56def979832d355"], "flag": 0}
{"question": "How to react to flawed preprints?", "body": "<p>Suppose you were to find what you think are serious flaws in a preprint (arXiv or something similar). What should you do? Now, after the obvious first step of contacting the authors and letting them know, what should you do if you were basically told off (\"thanks for your interest\" without addressing any of the technical concerns)? </p>\n\n<p>Were this a regular journal, one might write a letter to the editor, or a comment (<a href=\"https://academia.stackexchange.com/questions/12774/publishing-a-comment-or-contacting-the-authors-privately\">one might go this route even without contacting the authors in the first place</a>), but how should you deal with preprints, whose contents is in a way still evolving? Would a \"comment\" paper uploaded to the preprint server not be considered rather aggressive (I don't remember seeing anyone doing this)? <strong>Is there anything one can, or should, do <em>before</em> the (eventual) publication of the paper in some peer-reviewed venue?</strong></p>\n\n<p>Stretching this well into the hypothetical, suppose that one did write a \"comment\" paper and uploaded it onto the preprint server. Would the authors of the original preprint be ethically obliged to cite this and address the concerns raised therein when submitting to peer-reviewed journals (assuming that they were to submit after being let known of the existence of the comment)?</p>\n", "pids": ["53e9a6cab7602d9702ffc4bf"], "flag": 1}
{"question": "As a non-academic, how do I find papers that reference a certain article?", "body": "<p>I have recently read an interesting article on number theory, published in a well-known mathematics journal. As a keen amateur mathematician, I have tried to develop some of the ideas presented in the paper. Surprisingly, I have come to a remarkable conclusion that might be worth publishing. Naturally, I first wanted to make sure that this has not been published before, so I tried to find papers that referenced the original article.</p>\n\n<p>The issue is that websites that index or catalog scholarly material are off-limits to non-academics. In particular, in order to find references to certain papers or authors, one must first log in with an institution's credentials, which obviously I do not possess. What are my options? Do I:</p>\n\n<ul>\n<li>write up my research anyway and try to publish it, with the risk of wasting everybody's time if a similar publication has already been made,</li>\n<li>waste the original author's time by asking him to send me a list of references to his article (with a high probability of having my request immediately discarded), or</li>\n<li>pay a high subscription fee to these cataloging websites in order to find what I'm looking for?</li>\n</ul>\n\n<p>Is there another way for me to go about this?</p>\n", "pids": ["55a5ef43c91ba91c7d9392a8"], "flag": 1}
{"question": "Why does the affinity of haemoglobin for oxygen decrease at high altitudes?", "body": "<p>My class 12 NCERT book says, Pg 226</p>\n\n<blockquote>\n  <p>The body compensates low oxygen availability by increasing red blood cell production, decreasing the binding affinity of haemoglobin and by increasing breathing rate.</p>\n</blockquote>\n\n<p>Why should the haemoglobin binding capacity decrease at high altitude?</p>\n\n<p>I think it should increase for better oxygen transfer and uptake from air. The concentrtion of oxygen in the atmosphere decreases with height. Hence, if the haemoglobin binding increases, we will be able to draw more oxygen from the air and transport it to the cells.</p>\n", "pids": ["55a43604612ca648688c0d1b"], "flag": 1}
{"question": "Is it right to ignore publications coming from non-top publishers?", "body": "<p>When I look into a specific problem over Google Scholar and simple Google Search, I find many related publications from publishers other than IEEE, ACM, Elsevier, Springer etc.</p>\n\n<p>Usually the authors come from Indian, Chinese, Arabic institutions. My initial instinct is to ignore them, however I always feel as if there might be something important.</p>\n\n<p>What is the right thing to do in such cases?</p>\n", "pids": ["5550417745ce0a409eb3b8de"], "flag": 1}
{"question": "Is there a neurological difference between someone experiencing a &quot;normal&quot; trauma response, and someone with PTSD? Or are they on the same continuum?", "body": "<p>I've been reading Dr. Bessel van der Kolk's book <em>The Body Keeps the Score.</em> Dr. Van der Kolk describes how, in people with PTSD, the brain actually undergoes changes in response to trauma. Their perception and interpretation of their world shifts on a neurological level.</p>\n<p>Say a person doesn't fit all the criteria for an official PTSD diagnosis, but still experiences some (perhaps less intense or long-lasting) symptoms of post-traumatic stress. Is it likely that the same neurological changes would be taking place, just to a lesser extent?</p>\n<p>Or is it more analogous to depression, where (if I understand correctly!) research on how the brain responds to depression isn't necessarily analogous to how the brain responds to feeling &quot;sad&quot; (i.e. while sadness can turn into clinical depression, clinical depression itself is a specific condition that feels different from just extra severe sadness)?</p>\n<p><em>Context: I'm writing an article about the cognitive effects of trauma on students, but most of the studies I find screen participants for PTSD specifically. I'm wondering if these studies would still apply to students who don't necessarily have PTSD, but still suffer from the aftermath of a trauma.</em></p>\n", "pids": ["5c757358f56def979888e0c6"], "flag": 1}
{"question": "Anxiety vs Stressfulness in the Big Five?", "body": "<p>From these sources (<a href=\"https://cloud.ibm.com/docs/personality-insights?topic=personality-insights-agreeableness\" rel=\"nofollow noreferrer\">1</a>, <a href=\"http://www.timothy-judge.com/documents/2013-31562-001.pdf\" rel=\"nofollow noreferrer\">2</a>, <a href=\"http://www.testsonthenet.com/Factors-facets.htm\" rel=\"nofollow noreferrer\">3</a>) I have figured out that anxiety and stressfulness are generally defined as:</p>\n\n<ul>\n<li><strong>Anxiety</strong> - Prone to have generalized anxiety, panic, specific phobias, worry as well as feeling tension, nerviousness.</li>\n<li><strong>Stressfulness</strong> - Feeling helpless, overwhelmed under stress, pressure or when facing emergency situations.</li>\n</ul>\n\n<p>But isn't feeling helpless and overwhelmed cause you to feel anxious? And isn't feeling of helplessness and overwhelmed basically comes from anxiety? When I feel overwhelmed, it basically means that I am very anxious at the moment.</p>\n\n<p>Another definition (<a href=\"https://www.youtube.com/watch?v=k08aJYvRTCU\" rel=\"nofollow noreferrer\">4</a>) might be that stressfulness is a proclivity to feeling panic. But isn't panic is just a final stage of being anxious?</p>\n\n<p>What is the difference between <strong>anxiety</strong> and <strong>stressfulness</strong>?</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 1}
{"question": "When does a human baby develop a consciousness?", "body": "<p>Not to offend anyone or anything, but I've been searching up about abortion lately, and all the debate about it, and it got me wondering, when does a baby develop a consciousness?</p>\n\n<p>Consciousness - the ability to sense the world around you in an independent way. You can think for yourself, and make choices that defy your natural instincts. It is what some say separates us from wild animals. Animals have a survival instinct. They do what they can to survive. Eating colourful packets of soap is <em>not</em> an example of a survival instinct, and therefor proves that we have a consciousness.</p>\n\n<p><a href=\"https://psychology.stackexchange.com/questions/5410/definitions-of-consciousness?rq=1\">Definitions of consciousness</a></p>\n\n<p>So when does consciousness begin in a baby? And before that time, how does the brain work? Does it just feel the surroundings without any response? Any help would be greatly appreciated. Thanks!</p>\n", "pids": ["53e9b326b7602d9703df3eb9"], "flag": 1}
{"question": "Are alleles equally sized?", "body": "<p>If alleles occur at the same locus on a chromosome, does that mean they are of the same size? I was under the impression that they were, but I saw a gel electrophoresis testing different alleles of the same gene and saw them separate. I don’t understand how they could separate if they are of the same size, but if they aren’t, then how can they be housed in the exact same locus?</p>\n", "pids": ["53e99e5bb7602d97027212c8"], "flag": 1}
{"question": "Looking for a source for Valence/Arousal values Russell&#39;s advance circumplex model of emotion?", "body": "<p>I've been looking for a chart/table of Valence and Arousal values from the advanced Russell's model such as the one referenced in this article <a href=\"https://www.researchgate.net/publication/50805681_Asymmetrical_Facial_Expressions_based_on_an_Advanced_Interpretation_of_Two-dimensional_Russells_Emotional_Model\" rel=\"nofollow noreferrer\">https://www.researchgate.net/publication/50805681_Asymmetrical_Facial_Expressions_based_on_an_Advanced_Interpretation_of_Two-dimensional_Russells_Emotional_Model</a></p>\n\n<p>I'm unable to find anything that isn't a picture, and what I'm really looking for is a table/spreadsheet with the emotions and the valence/arousal values for each emotion.</p>\n\n<p>Is there a source for this that I can reference?</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 1}
{"question": "What is the condition called when someone believes that robots should be treated as though they are human?", "body": "<p>There is a movement calling for the \"humanitarian treatment of robots\" where robots must not be \"sexually molested\", must be spoken to with kind words and be treated, generally, like sensitive humans. This is likely because people are incapable of separating human from robot when they look at a robot made up to look human.</p>\n\n<p>This question came up when there was a video of Boston Dynamics engineers shoving a robot and knocking it over went viral.</p>\n\n<p>What is this condition where this inability to separate the two manifests? Perhaps the bonus question is: What is the phobia called where one fears that these groups will gain enough momentum to make it law?</p>\n", "pids": ["5ce2d175ced107d4c642e554", "619b5e951c45e57ce94397de"], "flag": 1}
{"question": "Why does the Elaboration Likelihood Model not account for truthfulness of the message?", "body": "<p>This is a sample problem with the answer I am stuck on:</p>\n\n<blockquote>\n  <p><strong>Question:</strong> According to the elaboration likelihood model, which of the following does NOT predict whether a message will be persuasive?</p>\n  \n  <p>A.  The length of the message<br>\n   B.  The attractiveness of the person delivering the message<br>\n   C. The truthfulness of the message<br>\n   D.  The trustworthiness of the person delivering the message</p>\n  \n  <p><strong>Answer:</strong> The correct answer is C. According to the elaboration likelihood model, the truthfulness of the message itself is not actually a characteristic used to determine whether a message will be persuasive (choice C is correct). The message characteristics (including length) do predict persuasiveness (choice A is wrong), as do the source characteristics (including the attractiveness and the trustworthiness of the person delivering the message; choices B and D are wrong).</p>\n</blockquote>\n\n<p>Wouldn't the truthfulness of the message still be a factor, since it is a characteristic of the message itself (via the central route with message characteristics)? I get why the other answers are wrong. I don't get why C is correct.</p>\n", "pids": ["56d91e0fdabfae2eee8c2539"], "flag": 1}
{"question": "Revenge attitude: is it innate or acquired in human", "body": "<p>I am trying to understand what is the root cause for revenge? I understand anger is caused by the gap between expectation/anticipation and the reality. But as to revenge, I am not satisfied just with identity related or social order maintenance or reciprocity. While resources pointing to the direction of getting started, any valuable input, views, opinions and research outcomes would be very much helpful.</p>\n", "pids": ["5c31f2e93a55ac7f9317fc64"], "flag": 1}
{"question": "System 1 thinking and ADHD", "body": "<p>I'm interested in learning if there is any connection between System 1/System 2 thinking and ADHD. The former is a theory about the process underlying decision making, and the latter is a mental disorder. Thus defined, the two do not seem related. But there appear to be <a href=\"https://mpmengaged.wordpress.com/2013/04/03/about-adhd-thinking-fast-and-slow/\" rel=\"nofollow noreferrer\">similar behavioral manifestations</a> between the two.</p>\n\n<p>My question is: <strong>Do individuals with ADHD rely more on System 1 thinking?</strong> Relatedly, I would also like to know if tests for ADHD (in particular <a href=\"https://www.tovatest.com/about-the-t-o-v-a/\" rel=\"nofollow noreferrer\">T.O.V.A.</a>) are a valid means of measuring the extent to which an individual relies on System 1 thinking. </p>\n\n<p>Pointers to the relevant literature would be especially appreciated.</p>\n", "pids": ["56d92b3edabfae2eeed9d224", "55a3b2cf65ce5cd7b3b42ddd", "55a4f8cec91bf3b1cc4b699d", "53e9b1ffb7602d9703c951e3", "53e9ad8db7602d97037813a9"], "flag": 0}
{"question": "How is intelligence in children measured?", "body": "<p>Intelligence is dependent on mental age and <a href=\"https://academic.oup.com/ije/article/39/5/1362/802787\" rel=\"nofollow noreferrer\">education</a>. So how can an IQ test be performed to check the mental/intellectual capabilities in children?</p>\n", "pids": ["53e99c92b7602d97025474f8", "53e99991b7602d97021d8757", "5f0c2f3f9fced0a24ba031c6", "53e9b8b4b7602d97044931b9"], "flag": 1}
{"question": "How important is seeing the face of the instructor?", "body": "<p>So, I am yet to make up my mind on which is a superior mode of teaching in flipped classroom videos:</p>\n\n<ol>\n<li>Khan academy type model where you see slides or a digital drawing board and only listen to the instructor.</li>\n<li>Or a video in which you see the instructor communicating with you. Maybe in one third of the video and the rest of the screen real estate is focused on graphics, video etc.</li>\n</ol>\n\n<p>Let us assume that you have a superb communicator in both cases.</p>\n\n<p>Which model is superior? Have there been any studies in this field?</p>\n", "pids": ["53e9b5e0b7602d970412e269"], "flag": 1}
{"question": "Emotional Calculator; How can I mathematically show a decrease in anxiety using an emotional equation?", "body": "<p>Disclaimer- I had asked this question in the Math stack exchange, but was encouraged to ask it here.</p>\n<p>I'm working on creating an emotional calculator of sorts, for personal use, wherein, whenever I am stressed, I can pretty much figure out what to do to feel better.</p>\n<p>I'll be using the Emotional Equations book by Chip Conley (summary here: <a href=\"https://blas.com/emotional-equations/\" rel=\"nofollow noreferrer\">https://blas.com/emotional-equations/</a>) as a point of reference.</p>\n<p>here's my question:</p>\n<p>Let's take the following equation as an example:</p>\n<p><strong>Let's say I interviewed for a job and now am anxious about whether or not I will get it.</strong></p>\n<p><em>Anxiety = Uncertainty <span class=\"math-container\">$\\times$</span> Powerlessness</em></p>\n<p>To make myself feel better, if I focus on the Powerlessness variable, then I can do many things to make myself feel better. For example: I could apply for more jobs, go take a walk, go for a run, etc.</p>\n<p>However, each of those things will not help me in the same way. They will each have different &quot;proportions of powerlessness&quot; to offer, so to speak. So, if I go get ice cream, sure I'll feel a little better, but I'm sure I'll be anxious an hour after eating that ice cream. So, on a scale of 1-10, it will probably reduce powerlessness by 0.5 or 1, whereas if I apply for more jobs, for example, it will reduce powerlessness by 7-8.</p>\n<p><strong>What math principle/logic/practice can I use to calculate how much something (eating ice cream) can affect powerlessness?</strong></p>\n<p>Thank you! Apologies for the long question.</p>\n", "pids": ["56d924a3dabfae2eeeb363ad", "5c0f7a21da562944ac77f705", "53e9ab1ab7602d97034a3731"], "flag": 0}
{"question": "Are these statements about the performance of neural networks as a function of the number of hidden layers contradictory?", "body": "<p>In this <a href=\"https://people.cs.umass.edu/~domke/courses/sml2011/08autodiff_nnets.pdf\" rel=\"nofollow noreferrer\">note</a> Justin Domke says that</p>\n\n<blockquote>\n  <p>In practice, neural networks seem to usually find a reasonable solution when the number of layers is not too large, but find poor solutions when using more than, say, 2 hidden layers.</p>\n</blockquote>\n\n<p>But in <a href=\"https://qr.ae/pNrt0p\" rel=\"nofollow noreferrer\">Bengio's remark</a>, he says </p>\n\n<blockquote>\n  <p>Very simple. Just keep adding layers until the test error does not improve anymore.</p>\n</blockquote>\n\n<p>There seems to be a conflict. Can anyone explain why they suggest differently? Or am I missing something?</p>\n", "pids": ["5de799809e795e77580692fb"], "flag": 1}
{"question": "Image recognition service architecture", "body": "<p>A question for developers of projects for pattern recognition. How best to organize the architecture of such a service?</p>\n\n<p>At what stage do you conduct logic? (for example, for the recognition of a photo of a male blue jacket, a cascade of queries is performed: \"recognizing men\" -> \"recognizing the jacket\" -> \"recognizing the color of the jacket.\")</p>\n\n<p>Does it make sense to implement all search options within a single neural network or is it better to create a set of individual neuronets that are confined to fairly simple tasks?</p>\n", "pids": ["58d82fcbd649053542fd6729"], "flag": 1}
{"question": "Would convolutional NN recognize patterns in encoded images?", "body": "<p>I have a set of images that I already trained a CNN to classify successfully. I wonder if it would be possible to encode the images (using XOR in combination with a key of the same length as the image) and train a new net on them. </p>\n\n<p>Thinking logically, the features still exist in the same relation to each other, just in a different form (encoded). Considering that neural networks are incredible at pattern recognition, I assume that it would still be doable.</p>\n\n<p>For people, who cannot imagine how a xor-encoded image would look like:\n<a href=\"https://i.stack.imgur.com/GsIxN.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/GsIxN.png\" alt=\"example for encoded image using random key\"></a></p>\n\n<p>For a human, it may look like rubbish, but the information is definitely there.</p>\n\n<p>Would love to read your opinion.</p>\n", "pids": ["58d82fced649053542fd6ec6"], "flag": 1}
{"question": "Can an autistic person have very advance language skills?", "body": "<p>Can an autistic person have very advanced language skills (Verbal communication, not about tonal nor body language skill, nor the written verbal language, I keep dyslexia out of this discussion for sake of specificity) and a very Early age of first talk, while having other autism symptoms?</p>\n<p>Notably there are a few blogs and many social media posts that writes about &quot;hyperverbal autistics&quot; but I did not find scientific literature about hyperverbal autistic people.</p>\n", "pids": ["53e9b8f5b7602d97044da1ec"], "flag": 0}
{"question": "Two chatbots - One teaches another", "body": "<p>I am seeking the information for this kind of chatbot architecture : There are two chatbots. One plays the role of teacher, and another is a student who is learning. The goal is to test the student's quality, and to improve the student's ability.</p>\n<p>I didn't find much reference. There are :</p>\n<p><a href=\"http://Bottester:%20Testing%20Conversational%20Systems%20with%20Simulated%20Users\" rel=\"nofollow noreferrer\">Bottester: Testing Conversational Systems with Simulated Users</a></p>\n<p>And the <a href=\"http://parl.ai/static/docs/basic_tutorial.html#\" rel=\"nofollow noreferrer\">ParlAI</a>, a python-based platform for enabling dialog AI research has the notion of &quot;Teacher agent&quot;, which seems to be what I am looking for.</p>\n<p>Of course, we also have deep reinforcement learning which might be related.</p>\n<p>I prefer to have some classical references for this approach to chatbots.\nCurrently, reinforcement learning is not in my consideration.</p>\n<p>Constructing two chatbots talking to each other, like what Facebook did, is not what I want. Because in this case, both of them are student agents.</p>\n", "pids": ["58d82fcbd649053542fd6082", "5e3a928fdf1a9c0c41ebe39e"], "flag": 1}
{"question": "How to evaluate the goodness of images generated by GANs?", "body": "<p>As we all know, there has been tons of GAN variants featuring different aspects of the image generation task such as stability, resolution or the ability to manipulate images. However, it is still confusing to me that how do we determine that images generated by one network are more plausible than images generated by another?</p>\n\n<p>PS: could someone with higher reputation create more tags like image generation?</p>\n", "pids": ["573696126e3b12023e5248f5"], "flag": 1}
{"question": "Is there a way of computing a prominence score based on the prevalence of features in an image?", "body": "<p>Is there any previous work on computing some sort of prominence score based on the prevalence of features in an image?</p>\n\n<p>For example, let's say I am classifying images based on whether or not they have dogs in them. Is there a way to compute how prominent that feature is?</p>\n", "pids": ["5f024f73dfae54360a45cb28"], "flag": 1}
{"question": "Ideas on how to make a neural net learn how to split sequence into sub sequences", "body": "<p>How can I train a neural network to recognize sub-sequences in a sequence flow?</p>\n\n<p>For example: Given the sequence <strong>111100002222</strong> as an input sample from a stream, the neural network would recognize that <strong>1111</strong> , <strong>0000</strong> , <strong>2222</strong> are sub sequences (so <strong>111100</strong> would not be a valid subsequence) and so on for ~ 50 to 100 different subsequences.</p>\n\n<p>There is no particular order in which the subsequence would appear in the flow.\nNo network architecture restriction.\nSubsequences are of variable length.</p>\n\n<p>General concepts, ideas, and theory are welcome. </p>\n", "pids": ["53e997f1b7602d9701fef9a4"], "flag": 1}
{"question": "How would one go about generating *sensible* responses to chat?", "body": "<p>I have recently gone about and made a <a href=\"https://jsbin.com/vijawuleyo/edit?html,console,output\" rel=\"nofollow noreferrer\">simple AI</a>, one that gives responses to an input (albeit completely irrelevant and nonsensical ones), using Synaptic.js. Unfortunately, this is not the type of text generation I am looking for. What I am looking for would be a way to get connections between words and generate text from that. (What would be preferable would be to also generate at least semi-sensible answers also.)</p>\n\n<p>This is part of project Raphiel, and can be checked out in the room associated with this site. What I want to know is what layer combination would I use for text generation?</p>\n\n<p>I have been told to avoid retrieval-based bots.</p>\n\n<p>I have the method to send and receive messages, I just need to figure out what combination of layers would be the best. </p>\n\n<p>Unless I have the numbers wrong, this will be SE's second NN chatbot.</p>\n", "pids": ["5736974d6e3b12023e63866b"], "flag": 1}
{"question": "Are there any references of NLP/text mining techniques for identifying the theme of news headlines?", "body": "<p>I am looking to extract the central theme from a given news headline using NLP or text mining. Is there any reference that goes in this direction?</p>\n<p>Here's an example. Let's say that I have the following news headline.</p>\n<blockquote>\n<p>BRIEF-Dynasil Corporation Of America Reports Q2 EPS Of $0.08</p>\n</blockquote>\n<p>Then the algorithm should produce</p>\n<blockquote>\n<p>Reports</p>\n</blockquote>\n<p>Here's another example. The input is</p>\n<blockquote>\n<p>China's night-owl retail investors leverage up to dominate oil futures trade</p>\n</blockquote>\n<p>And the output would e.g. be</p>\n<blockquote>\n<p>oil futures</p>\n</blockquote>\n", "pids": ["5736960d6e3b12023e520aaa"], "flag": 1}
{"question": "How to implement a contextual reinforcement learning model?", "body": "<p>In a reinforcement learning model, states depend on the previous actions chosen. In the case in which some of the states -but not all- are fully independent of the actions -but still obviously determine the optimal actions-, how could we take these state variables into account?</p>\n\n<p>If the problem was a multiarmed bandit problem (where none of the actions influence the states), the solution would be a contextual multiarmed bandit problem. Though, if we need a \"contextual reinforcement learning problem\", how can we approach it?</p>\n\n<p>I can think of separating a continuous context into steps, and creating a reinforcement learning model for each of these steps. Then, is there any solution where these multiple RL models are used together, where each model is used for prediction and feedback proportionally to the closeness between the actual context and the context assigned to the RL model? Is this even a good approach?</p>\n", "pids": ["5736960b6e3b12023e51e3ea"], "flag": 1}
{"question": "How can a neural network learn to play sudoku?", "body": "<p>I'm just beginning to understand neural networks and I've performed a couple of successful tests with numerical series where the NN was trained to find the odd one or a missing value. It all works pretty well.</p>\n\n<p>The next test I wanted to perform was to approxmimate the solution of a Sudoku which, I thought could also be seen as a special kind of numerical series. However, the results are really confusing.</p>\n\n<p>I'm using an MLP with 81 neurons in each of the three layers. All output neurons show a strong tendency to yield values that are close to either 0 or 1. I have scaled and truncated the output values. The result can be seen below:</p>\n\n<pre><code>Expected/Actual Solution:     Neural Net's Solution:\n\n6 2 7 3 5 0 8 4 1             9 0 9 9 9 3 0 0 3\n3 4 8 2 1 6 0 5 7             0 9 9 0 0 0 9 9 0\n5 1 0 4 7 8 6 2 3             0 9 1 9 9 0 2 0 4\n1 6 4 0 2 7 5 3 8             0 0 5 0 0 9 0 0 7\n2 0 3 8 4 5 1 7 6             0 0 0 0 0 9 9 0 9\n7 8 5 1 6 3 4 0 2             9 9 9 9 0 6 2 9 0\n0 5 6 7 3 1 2 8 4             0 0 0 0 9 9 0 9 0\n4 3 1 5 8 2 7 6 0             9 9 0 0 0 0 9 0 9\n8 7 2 6 0 4 3 1 5             9 9 0 9 9 0 9 0 9\n</code></pre>\n\n<p>The training set size is 100000 Sudokus while the learning rate is a constant 0.5. I'm using NodeJS/Javascript with the Synaptic library.</p>\n\n<p><strong>I don't expect a perfect solution from you guys, but rather a hint if that kind of behavior is a typical symptom for a known problem, like too few/many neurons, small training set, etc.</strong></p>\n", "pids": ["5d04e907da56295d08dd8fb1"], "flag": 1}
{"question": "Has there been research on the impact of gay parents on the sexual orientation of adopted children?", "body": "<p><em>Disclamer: I am not interested in personal views on whether gay parenting is a good or bad thing. I would like to understand whether there has been serious research on the upbringing consequences for such children. I am a physicist so I know nothing about psychology, but I am good with numbers and their statistical interpretation so anything substantiated is very much welcome. Thank you</em></p>\n<p>Gay parenting, whether official or not, is in place for now more than a generation and among the fierce debates about that topic (I am French), I tried to look for research that would bring some actual data on the comparative measurable effects of gay vs straight parenting (on the children). <strong>The point I am interested in is specifically the sexual orientation of the children (now grown-ups).</strong></p>\n<p>I did not find anything substantial, probably because I do not know the right literature in that field.</p>\n<p>Is there such research?</p>\n", "pids": ["5aaa05a81b13da3ea920c0f1", "53e99df7b7602d97026b5dea", "53e9ae0bb7602d9703814423"], "flag": 0}
{"question": "Maximizing or Minimizing in Trust Region Policy Optimization?", "body": "<p>I happened to discover that the <a href=\"https://arxiv.org/pdf/1502.05477v1\" rel=\"nofollow noreferrer\">v1</a> (19 Feb 2015) and the <a href=\"https://arxiv.org/pdf/1502.05477\" rel=\"nofollow noreferrer\">v5</a> (20 Apr 2017) versions of TRPO papers have two different conclusions. The Equation (15) in v1 is <span class=\"math-container\">$\\min_\\theta$</span> while the Equation (14) in v2 is <span class=\"math-container\">$\\max_\\theta$</span>. So, I'm a little bit confused about which one to choose.</p>\n\n<p>BTW, I found that in the <a href=\"https://arxiv.org/pdf/1506.02438\" rel=\"nofollow noreferrer\">High-Dimensional Continuous Control Using Generalized Advantage Estimation</a>, the Equation (31) uses <span class=\"math-container\">$\\min_\\theta$</span>.</p>\n", "pids": ["5ac1829d17c44a1fda91823f", "5ac1829d17c44a1fda91823f"], "flag": 1}
{"question": "Training a CNN from scratch over COCO dataset", "body": "<p>I am using Tensorflow Object Detection API for training a CNN from scratch on COCO dataset. I need to use this <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/embedded_ssd_mobilenet_v1_coco.config\" rel=\"nofollow noreferrer\">specific configuration</a>.\nThere is no pre-trained model on COCO with that configuration and this is the reason why I am training from scratch.</p>\n\n<p>However, after 1 week of training and evaluating each checkpoint generated by the training phase this is how my learning phase appears on Tensorboard:</p>\n\n<p><a href=\"https://i.stack.imgur.com/0U89O.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/0U89O.png\" alt=\"Tensorboard eval\"></a></p>\n\n<p>Thus, my questions are:</p>\n\n<ul>\n<li>does anyone know how many iterations approximately will be necessary? Right now I did more than 500'000 iterations.</li>\n<li>How can be possible that after 500'000 the evaluation is 0,8%? I would expected something like 60-70%.</li>\n<li>Why does there is a sudden drop after 500k iterations? I thought that the eval was supposed to converge to some limit. (this is what SGD should do)</li>\n<li>Is there any 'trick' to speed up the training phase? (ex: increasing the learning rate, etc).</li>\n</ul>\n", "pids": ["53e9a479b7602d9702d98afa"], "flag": 1}
{"question": "Alternative to sliding window neural network (was: Object detect (or) image classification at specific locations in the frame)", "body": "<p>Recent advances in Deeplearning and dedicated hardware has made it possible to detect images with a much better accuracy than ever. Neural networks are the gold standard for computer vision application and are used widely in the industry, for example for internet search engines and autonomous cars. In real life problems, the image contains of regions with different objects. It is not enough to only identify the picture but elements of the picture.</p>\n\n<p>A while ago an alternative to the well known sliding window algorithm was described in the literature, called Region Proposal Networks. It is basically a convolution neural network which was extended by a region vector.</p>\n\n<p><strong>Problem that I am trying to solve:</strong></p>\n\n<p>In a given video frame, I want to pick some region of interests (literally), and perform classification on those regions.</p>\n\n<p><strong>How is it currently implemented</strong></p>\n\n<ol>\n<li>Capture the video frame</li>\n<li>Split the video frame into multiple images each representing a region of interest</li>\n<li>Perform image classification(inference) on each of the image (corresponding to a part of the frame)</li>\n<li>Aggregate the results of #3 </li>\n</ol>\n\n<p><strong>Problem with the current approach</strong></p>\n\n<p>Multiple inferences per frame.</p>\n\n<p><strong>Question</strong></p>\n\n<p>I am looking for a solution where I specify the locations of interest in a frame, and inference task, be it object detection (or) image classification, is performed only on those regions.Can you please point to me the references which I need to study (or) use to do this.</p>\n", "pids": ["573696026e3b12023e516718", "5aed14d617c44a4438159040", "573696056e3b12023e5195b1"], "flag": 1}
{"question": "How tightly enforced are open-access embargoes?", "body": "<p>Many academic journals have copyright policies which forbid authors (possibly for a finite embargo time) to make their papers (either preprints, accepted manuscripts, or camera-ready versions) freely available (either on their personal websites or on repositories such as the arXiv). <strong>How tightly enforced are these policies? Are there known cases of publishers pursuing legal action against an author for posting copyrighted academic papers?</strong> Or would such cases normally be dealt with private requests to cease-and-desist? </p>\n\n<p><a href=\"https://academia.stackexchange.com/a/9968/820\">This answer</a> seems to indicate such cases are rare, but there could be privately-dealt with cases that are not visible. Or is there a large body of public-repository-published papers that possibly / probably / demonstrably have been publicly posted in breach of a copyright policy?</p>\n", "pids": ["53e9a8eab7602d970323721a"], "flag": 1}
{"question": "Why does a British accent sound smarter to Americans?", "body": "<p>This question has to do with how people perceive other accents. It seems that having a British accent makes someone seem more intelligent, even though that isn’t always true.</p>\n<p>As funny as it is, I think someone with a British accent could approach me and start talking about dogs sniffing each other’s butts and I would still think, “man, this guy really does knows what he’s talking about.”</p>\n<p>I have done some searching, but it seems there isn’t a definite answer answer for why a British accent makes someone appear sophisticated.</p>\n<p>The top answer <a href=\"https://www.quora.com/Why-do-British-accents-sound-intelligent-to-Americans\" rel=\"noreferrer\">here</a> suggests that maybe the association has to do with people’s original perception of those people to begin with. If you thought British people were smart and you heard someone with what you thought was a British accent you may be quick to think that person is smart.</p>\n<p><a href=\"https://sites.psu.edu/siowfa16/2016/09/06/why-does-a-british-or-new-zealand-accent-sound-more-intelligent/\" rel=\"noreferrer\">This</a> suggests the theory that the association could come from countries historical dominance.</p>\n<p><strong>What explains why (a lot of Americans for sure) think someone with a British accent must be smart?</strong></p>\n<p>Note: I’m not sure about good tags for this question</p>\n", "pids": ["56d81fdddabfae2eeeb4ad55", "53e9b10fb7602d9703b8d20e", "53e9bb0fb7602d9704747be8", "5ce2b27eced107d4c6e33969", "56d83516dabfae2eee3a64fd", "56d8e05cdabfae2eee0e0068", "53e9b110b7602d9703b8fc51", "53e9aebcb7602d97038e3794"], "flag": 0}
{"question": "Origin of the double membrane of mitochondria and chloroplasts", "body": "<p>Most websites and textbooks say that the double membrane of mitochondria and chloroplasts are a result of the endocytosis of ancient prokaryotes (the outer membrane is from the vesicle containing the prokaryote, the inner membrane is from the prokaryote itself).\nHowever, some sources say that this is not the case. The precursor to the mitochondrion (alphaproteobacteria) was a gram-negative bacteria, which has a double membrane. <a href=\"http://sandwalk.blogspot.com/2010/06/on-origin-of-double-membrane-in.html\">This site</a> says that the reasoning for the double membrane that is often taught is a lie, and that the mitochondrial precursor had a double membrane already to generate ATP through the ETC.</p>\n\n<p>So, if this is the case, why do mitochondria now have two membranes, and not three (two from the prokaryote and one from the vesicle)?</p>\n", "pids": ["53e9abb2b7602d970355e8ee", "56d830c4dabfae2eee210196", "53e9a594b7602d9702ebf1e9", "55a3caf765ce5cd7b3b7e391", "55a4b8a2612ca64868a1637e", "55a3869c65ce5cd7b3ada40e", "53e9a00ab7602d97028ec61d"], "flag": 1}
{"question": "What is the most accurate method of discerning between “irredeemable evil” and “temporary insanity”?", "body": "<p>To be precise, by &quot;evil&quot; I am referring specifically to\nthe weakness of the trait of (or compulsion) for “genuine care and concern for the wellbeing of others”\nwith respect to\nthe strength of the trait of (or compulsion for) &quot;the pursuit of self-interest&quot;.</p>\n<p>Or, more succinctly, the weakness of the force of conscience as a constraining force on the predatory compulsion of self-interest.</p>\n<blockquote>\n<p>“The battle line between good and evil runs through the heart of every\nman.&quot;<br />\n ~Aleksandr Solzhenitsyn</p>\n</blockquote>\n<p>Some humans seem to lack this “genuine care and concern for the wellbeing of others”<br />\nOf those who do, there seem to be at least 2 distinct groups:<br />\n1: Those who lack it permanently. (irredeemably evil)<br />\n2: Those who lack it only temporarily. (temporary insanity)</p>\n<p>By &quot;temporary insanity&quot; I am referring to the phenomenon of people who seem to act without care and concern for the well being of others, but who seem to do so because they lack the ability to control their fear at the time and are later genuinely remorseful for their behavior.</p>\n<p>By &quot;irredeemably evil&quot; I am referring to those who never experience any genuine remorse for such behavior.</p>\n<p><strong>Difficulty #1: The seeming absence of a single underlying cause</strong></p>\n<p>Psychopathy is probably the best example of &quot;irredeemable&quot; evil. There are methods like the PCL-R to detect this particular type of evil. However, there seems to be growing evidence that narcissism also has a strong heritable component. The methods for detecting psychopathy do not seem to be applicable to narcissism.</p>\n<p>To add to the difficulty of the problem, the evidence would seem to suggest that the absence of moral constraint to predatory compulsions may not have a single cause.</p>\n<p>For example, there is some evidence to suggest that psychopathy may be the result of weak pain signals in general.</p>\n<p>One interpretation of this is that conscience emerges and is strengthened by the process of persistent pain giving rise to rumination. i.e. When our actions harm others, the persistent guilt that we feel, gives rise to a resolve to change our behavior both to relieve the pain in the moment and to avoid feeling this pain again in the future. However, if the pain signal is too weak to give rise to rumination, then the conscience does not form.</p>\n<p>On the other hand, narcissists seem to typically have normal levels of pain for themselves but lack the affective empathy which would trigger similar levels of pain when other humans are suffering. One interpretation of this is that the persistent pain which gives rise to the rumination which gives rise to conscience does not arise, due not to the inability to experience pain in general, but rather to the inability to experience pain of others due to the absence of affective empathy.</p>\n<p>Given these different ways in which the growth of conscience can be interrupted, it's possible that the most effective means of discernment between &quot;irredeemable evil&quot; an &quot;temporary insanity&quot; might be to identify the traits of those who have a fully developed conscience and look for the absence of those traits in the individual in question.</p>\n<p><strong>Difficulty #2: Variance in the size of the circle of genuine care and concern.</strong></p>\n<p>To further add to the difficulty of this problem, it seems that the size of the circle of &quot;genuine care and concern&quot; varies considerably amongst humans.</p>\n<p>For some, it extends only to kin.<br />\nFor others it might extend to a larger tribe.<br />\nFor others still, it might, as some religions would encourage us, extend to all humans or even all living beings.</p>\n<p>To be more precise, therefore,\ngiven that evil is the perception of the absence of &quot;genuine care and concern for the well being of others&quot;,\nand that those who lack &quot;genuine care and concern for the well being of others&quot; will feel compelled to fake it in order to survive and thrive in society,\nthis question seems to break down into the following 2 components:</p>\n<p>1: pre-discovery: What is the most accurate method that potential prey can use to detect that the &quot;care and concern&quot; displayed by the skilled predator is, in fact, a deception?</p>\n<p>2: post-discovery: Having witnessed evidence of the absence of &quot;genuine care and concern for the well being of others&quot;, what is the most accurate means of determining if this is due to a permanent versus temporary inability to expand the circle of care and concern?</p>\n", "pids": ["5e297001df1a9c0c41e7a137", "55a5f79a65cead59c8319fc2", "53e9991db7602d970215bf3c"], "flag": 1}
{"question": "Dialectical Behavior Therapy&#39;s Biosocial Theory - Social Environment Validates Patients&#39; Maladaptive Behavior - As Defined By Who/What?", "body": "<p>In <a href=\"https://www.wikiwand.com/en/Dialectical_behavior_therapy#section_Overview\" rel=\"nofollow noreferrer\">Wikipedia's article about DBT, in the overview section</a> it says:</p>\n<blockquote>\n<p>In DBT's biosocial theory of BPD, clients have a biological predisposition for emotional dysregulation, and their social environment validates maladaptive behavior.</p>\n</blockquote>\n<p>According to the theory, &quot;maladaptive behavior&quot; - as defined by who/what - the patients' view of their social environments' various norms or the scientific-concesus of maladaptive behaviors (or something else)?</p>\n<p>In some cases, patients' environments' view of what reoccuring behavior in the patient is maladaptive, there no agreement between that and the scientific concensus - that's why it's important for me to know which one the theory refers to.</p>\n<p><em>I'm assuming the article refers to the scientific concesus definition of &quot;maladaptive behavior&quot; but I want to make sure.</em></p>\n", "pids": ["55a43df0c91b587b0973489c", "53e9acaeb7602d970368d864", "53e9a5b7b7602d9702ee3ca9", "5aabe1d21b13da0225bc3689", "59e774250cf2df775dd35145", "53e9b725b7602d97042be4ac", "53e9a066b7602d970294e4a5"], "flag": 0}
{"question": "What is the meaning of behaviorally oriented outside-in nature of therapy?", "body": "<p>What is the meaning of behaviorally oriented outside-in nature of therapy? I am especially interested why this outside-in word was used but please provide me a wider context of this type of therapy. Especially as it is meant on the following page.</p>\n\n<p><a href=\"https://www.sheknows.com/health-and-wellness/articles/1126691/depression-treatment-behavioral-activation/\" rel=\"nofollow noreferrer\">https://www.sheknows.com/health-and-wellness/articles/1126691/depression-treatment-behavioral-activation/</a></p>\n\n<p>Could you possibly give some resources such as scholarly articles or book chapters where this method is used? My problem is that I am a non-expert on psychotherapy but need a starting point on the above issue. Thank you.</p>\n", "pids": ["53e9b754b7602d97042f3102"], "flag": 1}
{"question": "How can one induce psychogenic death?", "body": "<p>I saw something about psychogenic death. I am wondering if it can be induced by a desire. I think that it can by a person being lazy and not caring about the world. It is said to happen with prisoners of war. The article says that it is not suicide but I don't know if it is true. It cannot happen all at once, it just happens because the person does not care.</p>\n<p>There is an article here: <a href=\"https://www.eurekalert.org/pub_releases/2018-09/uop-pcd092018.php\" rel=\"nofollow noreferrer\">https://www.eurekalert.org/pub_releases/2018-09/uop-pcd092018.php</a></p>\n<p>Reference to the original research is: Leach, J. (2018). ‘Give-up-itis’ revisited: Neuropathology of extremis. Medical hypotheses, 120, 14-21. <a href=\"https://doi.org/10.1016/j.mehy.2018.08.009\" rel=\"nofollow noreferrer\">https://doi.org/10.1016/j.mehy.2018.08.009</a></p>\n", "pids": ["5c0f8b1dda562944ac9c83ef", "56d8985fdabfae2eee2251dc"], "flag": 1}
{"question": "Is there a way that helps me to architect my CNN fundamentally before training?", "body": "<p>While we train a CNN model we often experiment with the number of filters, the number of convolutional layers, FC layers, filter size, sometimes stride, activation function, etc. More often than not after training the model once, it is just a trial &amp; error process.  </p>\n\n<ol>\n<li><p>Is there a way that helps me to architect my model fundamentally before training?</p></li>\n<li><p>Once I train model, how do I know which among these variables (number of filters, size, number of convolutional layers, FC layers) should be\nchanged - increased or decreased?</p></li>\n</ol>\n\n<p>P.S. This question assumes that data is sufficient in volume and annotated properly and still accuracy is not up to the mark. So, I've ruled out the possibility of non-architectural flaws for the question.</p>\n", "pids": ["59ae3be32bbe271c4c71b7b4"], "flag": 1}
{"question": "Name misspelled in first publication", "body": "<p>I am an undergraduate student starting my second year. Last semester, I took part in a research project and earned co-authorship of their paper, which got recently published.</p>\n\n<p>However, when adding names from our anonymous submission to the camera-ready version, the primary author misspelled my first name(Garret instead of Garrett). Because this was a fairly minor edit, I didn't notice it until a few weeks after it had been fully published. </p>\n\n<p>I've already asked the advising professor about it and he said that it wasn't anything to worry about, and that I should create an account on Google scholar and manually add the paper to my account. I've done this, but is there anything else I should do? How bad is this, or is it actually fairly minor?</p>\n", "pids": ["62de6d3d5aee126c0f897b21"], "flag": 1}
{"question": "How is AlphaZero different from Stockfish or Rybka?", "body": "<p>I don't know much about AI or chess engines, but what is the fundamental difference between AlphaZero and Stockfish or Rybka?</p>\n", "pids": ["5a73cbcc17c44a0b3035f7b3"], "flag": 1}
{"question": "Which evaluation methods can I use for image segmentation?", "body": "<p>I implemented an image segmentation pipeline and I trained it on the <a href=\"https://en.wikipedia.org/wiki/DICOM\" rel=\"nofollow noreferrer\">DICOM dataset</a>. I compared the results of the model with manual segmentation to find the accuracy. Is there other methods for evaluation? </p>\n", "pids": ["573696056e3b12023e5195b1", "5a73cbc317c44a0b3035eb61"], "flag": 1}
{"question": "How can active learning be used in the case of complex models that require a lot of data?", "body": "<p>We have a series of data and we want to label the parts of each series. As we do not have any training data, we could try to use <em>active learning</em> as a solution, but the problem is that our classifier is something like RNN which needs a lot of data to be trained. Hence, we have a problem in converging fast to just label proportional small parts of unlabeled data. </p>\n\n<p>Is there any article about this problem (active learning and some complex classifiers, like RNN)? </p>\n\n<p>Is there any good solution to this problem or not? (as data is a series of actions)</p>\n", "pids": ["6125b0145244ab9dcb38b715"], "flag": 1}
{"question": "What does &quot;oddly related&quot; mean in a mental status exam?", "body": "<p>Mental Status Exams done by psychiatrists often include a description of the &quot;relatedness&quot; of a patient. Sometimes, patients are described as &quot;oddly related.&quot; What is &quot;relatedness&quot; and what qualifies as &quot;oddly related&quot;?</p>\n<p>A google search for &quot;oddly related psychiatry&quot; shows a similar question on <a href=\"https://www.reddit.com/r/AskDoctorSmeeee/comments/4scq1n/what_does_oddly_related_mean/\" rel=\"nofollow noreferrer\">reddit</a> and <a href=\"https://allnurses.com/oddly-related-t387449/\" rel=\"nofollow noreferrer\">allnurses</a> without a proper answer unfortunately.</p>\n", "pids": ["5d455ecf275ded87f9804948", "5c0f8693da562944ac935bac", "56698c400cf25a01a9fbb764"], "flag": 1}
{"question": "How to implement a Continuous Control of a quadruped robot with Deep Reinforcement Learning in Pybullet and OpenAI Gym?", "body": "<p><strong>Description</strong></p>\n\n<p>I have designed this robot in URDF format and its environment in pybullet. Each leg has a minimum and maximum value of movement. </p>\n\n<p>What reinforcement algorithm will be best to create a walking policy in a simple environment in which a positive reward will be given if it walks in the positive X-axis direction?</p>\n\n<p><strong>I am working in the following but I don´t know if it is the best way:</strong></p>\n\n<p>The expected output from the policy is an array in the range of (-1, 1) for each joint. The input of the policy is the position of each joint from the past X frames in the environment(replay memory like DeepQ Net), the center of mass of the body, the difference in height between the floor and the body to see if it has fallen and the movement in the x-axis.</p>\n\n<p><strong>Limitations</strong></p>\n\n<p>left_front_joint      => lower=\"-0.4\" upper=\"2.5\" id=0</p>\n\n<p>left_front_leg_joint  => lower=\"-0.6\" upper=\"0.7\" id=2</p>\n\n<p>right_front_joint     => lower=\"-2.5\" upper=\"0.4\" id=3</p>\n\n<p>right_front_leg_joint => lower=\"-0.6\" upper=\"0.7\" id=5</p>\n\n<p>left_back_joint       => lower=\"-2.5\" upper=\"0.4\" id=6</p>\n\n<p>left_back_leg_joint   => lower=\"-0.6\" upper=\"0.7\" id=8</p>\n\n<p>right_back_joint      => lower=\"-0.4\" upper=\"2.5\" id=9</p>\n\n<p>right_back_leg_joint  => lower=\"-0.6\" upper=\"0.7\" id=11</p>\n\n<p>The code below is just a test of the environment with a set of movements hardcoded in the robot just to test how it could walk later. The environment is set to real time, but I assume it needs to be in a frame by frame lapse during the policy training. (<em>p.setRealTimeSimulation(1) #disable and p.stepSimulation() #enable</em>)</p>\n\n<p><strong>A video of it can be seen in:</strong></p>\n\n<p><a href=\"https://youtu.be/j9sysG-EIkQ\" rel=\"nofollow noreferrer\">https://youtu.be/j9sysG-EIkQ</a></p>\n\n<p><strong>The complete code can be seen here:</strong></p>\n\n<p><a href=\"https://github.com/rubencg195/WalkingSpider_OpenAI_PyBullet_ROS\" rel=\"nofollow noreferrer\">https://github.com/rubencg195/WalkingSpider_OpenAI_PyBullet_ROS</a></p>\n\n<p><strong>CODE</strong></p>\n\n<pre><code>import pybullet as p\nimport time\nimport pybullet_data\n\ndef moveLeg( robot=None, id=0, position=0, force=1.5  ):\n    if(robot is None):\n        return;\n    p.setJointMotorControl2(\n        robot,\n        id,\n        p.POSITION_CONTROL,\n        targetPosition=position,\n        force=force,\n        #maxVelocity=5\n    )\n\npixelWidth = 1000\npixelHeight = 1000\ncamTargetPos = [0,0,0]\ncamDistance = 0.5\npitch = -10.0\nroll=0\nupAxisIndex = 2\nyaw = 0\n\nphysicsClient = p.connect(p.GUI)#or p.DIRECT for non-graphical version\np.setAdditionalSearchPath(pybullet_data.getDataPath()) #optionally\np.setGravity(0,0,-10)\nviewMatrix = p.computeViewMatrixFromYawPitchRoll(camTargetPos, camDistance, yaw, pitch, roll, upAxisIndex)\nplaneId = p.loadURDF(\"plane.urdf\")\ncubeStartPos = [0,0,0.05]\ncubeStartOrientation = p.getQuaternionFromEuler([0,0,0])\n#boxId = p.loadURDF(\"r2d2.urdf\",cubeStartPos, cubeStartOrientation)\nboxId = p.loadURDF(\"src/spider.xml\",cubeStartPos, cubeStartOrientation)\n# boxId = p.loadURDF(\"spider_simple.urdf\",cubeStartPos, cubeStartOrientation)\n\n\n\ntoggle = 1\n\n\n\np.setRealTimeSimulation(1)\n\nfor i in range (10000):\n    #p.stepSimulation()\n\n\n    moveLeg( robot=boxId, id=0,  position= toggle * -2 ) #LEFT_FRONT\n    moveLeg( robot=boxId, id=2,  position= toggle * -2 ) #LEFT_FRONT\n\n    moveLeg( robot=boxId, id=3,  position= toggle * -2 ) #RIGHT_FRONT\n    moveLeg( robot=boxId, id=5,  position= toggle *  2 ) #RIGHT_FRONT\n\n    moveLeg( robot=boxId, id=6,  position= toggle *  2 ) #LEFT_BACK\n    moveLeg( robot=boxId, id=8,  position= toggle * -2 ) #LEFT_BACK\n\n    moveLeg( robot=boxId, id=9,  position= toggle *  2 ) #RIGHT_BACK\n    moveLeg( robot=boxId, id=11, position= toggle *  2 ) #RIGHT_BACK\n    #time.sleep(1./140.)g\n    #time.sleep(0.01)\n    time.sleep(1)\n\n    toggle = toggle * -1\n\n    #viewMatrix        = p.computeViewMatrixFromYawPitchRoll(camTargetPos, camDistance, yaw, pitch, roll, upAxisIndex)\n    #projectionMatrix  = [1.0825318098068237, 0.0, 0.0, 0.0, 0.0, 1.732050895690918, 0.0, 0.0, 0.0, 0.0, -1.0002000331878662, -1.0, 0.0, 0.0, -0.020002000033855438, 0.0]\n    #img_arr = p.getCameraImage(pixelWidth, pixelHeight, viewMatrix=viewMatrix, projectionMatrix=projectionMatrix, shadow=1,lightDirection=[1,1,1])\n\ncubePos, cubeOrn = p.getBasePositionAndOrientation(boxId)\nprint(cubePos,cubeOrn)\np.disconnect()\n</code></pre>\n\n<p><a src=\"https://github.com/rubencg195/WalkingSpider_OpenAI_PyBullet_ROS/raw/master/images/PyBullet.png\" alt=\"robot\"></p>\n\n<p><a src=\"https://github.com/rubencg195/WalkingSpider_OpenAI_PyBullet_ROS/raw/master/images/spider(8).jpeg\" alt=\"robot\"></p>\n", "pids": ["599c7bf6601a182cd2777f05"], "flag": 1}
{"question": "Why do we need both encoder and decoder in sequence to sequence prediction?", "body": "<p>Why do we need both encoder and decoder in sequence to sequence prediction?</p>\n\n<p>We could just have a single RNN that, given input <span class=\"math-container\">$x$</span>, outputs some value <span class=\"math-container\">$y(t)$</span> and hidden state <span class=\"math-container\">$h(t)$</span>. Next, given <span class=\"math-container\">$h(t)$</span> and <span class=\"math-container\">$y(t)$</span>, the next output <span class=\"math-container\">$y(t+1)$</span> and hidden state <span class=\"math-container\">$h(t+1)$</span> should be produced, and so on. The architecture shall consists of only one network instead of two separate ones. </p>\n", "pids": ["5c04967517c44a2c74708b17"], "flag": 1}
{"question": "What is the &quot;nails on a chalkboard&quot; response?", "body": "<p>Everyone is familiar with the squirmy, muscle-clenching response to hearing nails on a chalkboard. But I have known people to have this same response to other stimuli, such as:</p>\n<ul>\n<li>Velvety fabrics</li>\n<li>Styrofoam</li>\n<li>Nails on a zip</li>\n</ul>\n<p>Interestingly, it's not just the sound but even the <em>thought</em> of these things that can provoke a reaction.</p>\n<p>To the best of my knowledge, this is not a phobia, nor is it an allergy. So, is there a name for this response, and are there any known cases of it having been treated?</p>\n<p>--</p>\n<p><strong>Related:</strong> <a href=\"https://psychology.stackexchange.com/questions/4236/why-is-the-sound-of-fingernails-on-a-chalkboard-so-intolerable\">Why is the sound of fingernails on a chalkboard so intolerable?</a></p>\n", "pids": ["5c1369d2da56295a08a39df0", "61c9c76d5244ab9dcbd115ac"], "flag": 0}
{"question": "Asking &quot;What&#39;s wrong in you life?&quot; → Person sees more problems", "body": "<p>I think if you ask a person &quot;What's wrong in your life?&quot; several times (for example monthly) the person starts to focus on negative things.</p>\n<p>Maybe questions like this can have a negative outcome. The person will focus on (maybe even search) things which are negative. These questions might influence his attention. And finally the person might get depressed or the relationship gets worse.</p>\n<p>I am new to psychology. Is there a term for this? Or are there researches on this topic?</p>\n<p>Similar questions:</p>\n<ul>\n<li>What is causing you stress?</li>\n<li>What do you dislike at your workplace?</li>\n<li>What annoys you most about your spouse?</li>\n</ul>\n", "pids": ["55a6ad4f65ce054aad70b4d4", "5f5b72659fced0a24bdeb859", "53e9bd50b7602d97049e55d3", "5ae4d103a2e6b107866add3f", "55a4dfbf612c6b12aafc6d21", "5afe3150a1947207c6ac2afa", "53e9adc7b7602d97037ccf14", "53e9a3fbb7602d9702d148cf"], "flag": 1}
{"question": "Do repositories of translated papers exist?", "body": "<p>I've recently been told to read an article for my research, but do not speak the language it is written in (\"Drei Vorträge über Diffusion, Brownsche Molekularbewegung und Koagulation von Kolloidteilchen\", Smoluchowski).</p>\n\n<p>It's fairly heavily cited, so I imagine that someone somewhere will have translated it.\nHas anyone heard of/found online repositories of translated academic documents?\nFailing that- I don't suppose anyone reading this happens to have a translation?\n(P.S. the original author is long dead, hence I will not be asking him for a copy)</p>\n", "pids": ["56d81ab2dabfae2eee913b01"], "flag": 1}
{"question": "Will there be some promising techniques that can make AI greener and affordable in the future?", "body": "<p>The recent advances in machine learning were <a href=\"https://ai.stackexchange.com/q/13233/5351\">mostly achieved by the hardware</a>, and the hardware <a href=\"https://www.technologyreview.com/2019/03/26/136381/the-next-ai-explosion-will-be-defined-by-the-chips-we-build-for-it/\" rel=\"nofollow noreferrer\">is said</a> to <a href=\"https://blog.deeplearning.ai/blog/the-batch-youtube-vs.-conspiracy-theorists-robots-that-think-ahead-gpu-cpu-the-future-transformers-retooled\" rel=\"nofollow noreferrer\">continue driving</a> the development of AI, but I was still shocked by <a href=\"https://twitter.com/draecomino/status/1362051082273386500?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1362051082273386500%7Ctwgr%5E%7Ctwcon%5Es1_c10&amp;ref_url=https%3A%2F%2Fpublish.twitter.com%2F%3Fquery%3Dhttps3A2F2Ftwitter.com2Fdraecomino2Fstatus2F1362051082273386500widget%3DTweet\" rel=\"nofollow noreferrer\">this thread</a> which reads that the projected future cost for the largest model would be 1B dollars in 2025. And I learned that universities are suffering from an academic AI brain drain partly due to the <a href=\"https://qr.ae/pNEhry\" rel=\"nofollow noreferrer\">scarce hardware resources</a>.</p>\n<p><a href=\"https://i.stack.imgur.com/R1dyY.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/R1dyY.png\" alt=\"enter image description here\" /></a></p>\n<p>Some people proposed the so-called <a href=\"https://dl.acm.org/doi/fullHtml/10.1145/3381831\" rel=\"nofollow noreferrer\">Green AI</a> that encourages sustainable AI development but provides few constructive methods to prevent the trend.</p>\n<p>I wonder if the redder and redder AI would be in fact truly inevitable. It seems to me that all companies should build an expensive compute infrastructure to be competitive, but I think the investment would be very risky since most companies cannot get a higher return.</p>\n<p>But on the other hand, we human beings have evolved tens of millions of years or billions of years(life) on earth with <a href=\"https://en.wikipedia.org/wiki/Estimates_of_historical_world_population#:%7E:text=Recent%20estimates%20of%20the%20%22total,the%20order%20of%20100%20billion.\" rel=\"nofollow noreferrer\">hundreds of billions of brains</a> that have ever lived on earth as a whole &quot;human brain&quot;. The biological wetware seems much much redder than the nowadays hardware and has consumed much much more energy than all the supercomputers. To make machines as intelligent as we humans shouldn't we pay as high a price? It reminds me of <a href=\"https://en.wikipedia.org/wiki/No_free_lunch_theorem\" rel=\"nofollow noreferrer\">the NFL theorem</a> but it should be imprecise in this scenario.</p>\n<p><em>So, will there be some promising techniques on the algorithm side that can make AI greener, affordable and sustainable in the future?</em> <strong>If not, could anyone please explain why AI should be unavoidably red and inevitably redder?</strong></p>\n", "pids": ["5d04e906da56295d08dd88ce"], "flag": 1}
{"question": "How to design an AI that discovers more complex concepts on its own?", "body": "<p>How would I go about designing a (relatively) simple AI that discovers and invents random more complex concepts on its own?</p>\n\n<p>For example, say I had a robot car. It doesn't know it's a car. It has several inputs and outputs, such as a light sensor and the drive motors. If it stays in the dark, it's score drops (bad), and if it moves into the light, it's score rises (good). It'd have to discover that it's motor outputs cause the light input to change (because it's moving closer or farther away from a light source), and that brighter light means higher score.</p>\n\n<p>Of course, it'd be easier to design an AI that does specifically that, but I want its behaviour discovery system to be more generic, if that makes any sense. Like later on, it could discover a way to fight or cooperate with other robots to increase its score (maybe other robots destroy light sources when they drive over them, and they can be disabled by driving into them), but it'd have to discover this without initially knowing that another robot could possibly exist, how to identify one, what they do, and how to interact with one.</p>\n\n<p>Also, I want it to be creative instead of following a 'do whatever is best to increase your score' rule. Like maybe one day it could decide that cooperating with other robots is another way to increase its score (it finds out what love is), but if it's unable to do that, it becomes depressed and stops trying to increase it's score and just sits there and dies. Or it could invent any other completely random and possibly useless behavior.</p>\n\n<p>How hard would it be to make something like this, that essentially builds itself up from a very basic system, provided I give it lots of different kinds of inputs and outputs that it can discover how to use and apply to its own evolving behavior?</p>\n", "pids": ["53e9a54eb7602d9702e734b7"], "flag": 1}
{"question": "Is Monte Carlo Tree Search appropriate for problems with large state and action spaces?", "body": "<p>I'm doing a research on a finite-horizon Markov decision process with <span class=\"math-container\">$t=1, \\dots, 40$</span> periods. In every time step <span class=\"math-container\">$t$</span>, the (only) agent has to chose an action <span class=\"math-container\">$a(t) \\in A(t)$</span>, while the agent is in state <span class=\"math-container\">$s(t) \\in S(t)$</span>. The chosen action <span class=\"math-container\">$a(t)$</span> in state <span class=\"math-container\">$s(t)$</span> affects the transition to the following state <span class=\"math-container\">$s(t+1)$</span>.</p>\n\n<p>In my case, the following holds true: <span class=\"math-container\">$A(t)=A$</span> and <span class=\"math-container\">$S(t)=S$</span>, while the size of <span class=\"math-container\">$A$</span> is <span class=\"math-container\">$6 000 000$</span> (6 million) and the size of <span class=\"math-container\">$S$</span> is <span class=\"math-container\">$10^8$</span>. Furthermore, the transition function is stochastic.</p>\n\n<p>Would Monte Carlo Tree Search (MCTS) an appropriate method for my problem (in particular due to the large size of <span class=\"math-container\">$A$</span> and <span class=\"math-container\">$S$</span> and the stochastic transition function?)</p>\n\n<p>I have already read a lot of papers about MCTS (e.g. progressive widening and double progressive widening, which sound quite promising), but maybe someone can tell me about his experiences applying MCTS to similar problems or about appropriate methods for this problem (with large state/action space and a stochastic transition function).</p>\n", "pids": ["5ce2d035ced107d4c6354994", "5ac1829d17c44a1fda917ef3", "5aed14d617c44a4438158dbe"], "flag": 1}
{"question": "Why does Deep Q Network outputs multiple Q values?", "body": "<p>I am learning Deep RL following this tutorial: <a href=\"https://medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8\" rel=\"nofollow noreferrer\">https://medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8</a></p>\n\n<p>I understand everything but one detail:</p>\n\n<p>This image shows the difference between a classic Q learning table and a DNN.\nIt states that a Q table needs a state-action pair as input and outputs the corresponding Q value whereas a Deep Q network needs the state as feature input and outputs the Q value for each action that can be made in that state.</p>\n\n<p>But shouldn't the state AND the action together be the input to the network and the network just outputs a single Q value?</p>\n\n<p><a href=\"https://i.stack.imgur.com/A9ulk.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/A9ulk.png\" alt=\"enter image description here\"></a></p>\n", "pids": ["5ff68bbad4150a363cd02d93"], "flag": 1}
{"question": "Meaning of Actor Output in Actor Critic Reinforcement Learning", "body": "<p>In actor critic, <a href=\"https://medium.freecodecamp.org/an-intro-to-advantage-actor-critic-methods-lets-play-sonic-the-hedgehog-86d6240171d\" rel=\"nofollow noreferrer\">The equations for calculating the loss in actor critic</a> are an </p>\n\n<p><em>actor</em> loss (parameterized by <span class=\"math-container\">$\\theta$</span>) </p>\n\n<p><span class=\"math-container\">$$log[\\pi_\\theta(s_t,a_t)]Q_w(s_t,a_t)$$</span> </p>\n\n<p>and a <em>critic</em> loss (parameterized by <span class=\"math-container\">$w$</span>) </p>\n\n<p><span class=\"math-container\">$$r(s_t,a_t) + \\gamma Q_w(s_{t+1}, a_{t+1}) - Q_w(s_{t}, a_t).$$</span></p>\n\n<p>This is <a href=\"https://datascience.stackexchange.com/questions/20535/what-is-experience-replay-and-what-are-its-benefits\">bootstrapping in experience replay</a>:</p>\n\n<p><span class=\"math-container\">$$\nL_i(\\theta_i) = \\mathbb{E}_{(s, a, r, s') \\sim U(D)} \\left[ \\left(r + \\gamma \\max_{a'} Q(s', a'; \\theta_i^-) - Q(s, a; \\theta_i)\\right)^2 \\right]\n$$</span></p>\n\n<p>It is clear that bootstrapping is comparable to the critic loss, except that the <span class=\"math-container\">$max$</span> operation is lacking from the critic.</p>\n\n<p><strong>As i see it, (correct me if I'm wrong)</strong>:</p>\n\n<p><span class=\"math-container\">$Q(s_t,a_t) = V(s_{t+1}) + r_t$</span> where <span class=\"math-container\">$a_t$</span> is the actual action that had been taken.</p>\n\n<p>The critic, as I understand, estimates <span class=\"math-container\">$V(s)$</span></p>\n\n<p><strong>My question:</strong></p>\n\n<p><strong>What exactly is the critic calculating?</strong></p>\n\n<p><strong>What In actor critic outputs <span class=\"math-container\">$Q(s_{t+1},a_{t+1})$</span>?</strong></p>\n\n<p>It seems to me like the critic calculates the average next state <span class=\"math-container\">$s_{t+1}$</span> value, over all possible actions, with their corresponding probabilities, yielding</p>\n\n<p><span class=\"math-container\">$Q(s_t, a_t) = r_t + \\sum_{a_{t+1} \\in A}P(a_{t+1}|s_t)V(s_{t+1})$</span></p>\n\n<p>Which would mean that in order to get <span class=\"math-container\">$Q(s_{t+1}, a_{t+1})$</span> for the above formula, I would need to calculate</p>\n\n<p><span class=\"math-container\">$Q(s_{t+1}, a_{t+1}) = r_{t+1} + \\sum_{a_{t+2} \\in A}P(a_{t+2}|s_{t+1})V(s_{t+2})$</span></p>\n\n<p>Where <span class=\"math-container\">$V(s_{t+2})$</span> is the critic output on <span class=\"math-container\">$s_{t+2}$</span>, a state we get to by taking action <span class=\"math-container\">$a_{t+1}$</span> from state <span class=\"math-container\">$s_{t+1}$</span> but I am not sure that is indeed the meaning of the critic output and still it is unclear to me how to get <span class=\"math-container\">$Q(s_{t+1}, a_{t+1})$</span> from actor critic.</p>\n\n<p>If indeed that is what's being calculated, then why is it mathematically true that an improvement is being made? Or why does it make sense (even if not mathematically always true)?</p>\n\n\n\n<p>Practical use:</p>\n\n<p>I want to use actor critic with experience replay in an environment with a large action space (could be continuous). Therefore, I cannot use the <span class=\"math-container\">$max$</span> term. I need to understand the correct equation for the critic loss, and why it works.</p>\n", "pids": ["58d82fc8d649053542fd5854"], "flag": 1}
{"question": "What to do when the professor does not stand up to cheating?", "body": "<p>I was the teaching assistant (TA) for a very introductory physics course at a large state university. In the course of grading for this class, I came to learn that my university used the same course material as many other universities had for the equivalent course for more than twenty years. The answers to questions, in particular, were readily available online, through various forums. The syllabus explicitly forbade providing disingenuous answers, as well as any plagiarized responses. To be clear, this instructor was a fully tenured professor; not someone in any risk of losing their position.</p>\n\n<p>After noticing patterns in homework assignments, I began to look for them in midterm and final exams as well. What I initially thought was a couple of bad students turned out to be more than 50% of the class regularly citing online sources word-for-word. Once I realized what was happening, I informed the professor, and I started assigning zeros to the offending students, in accordance with University policy, and the professor did not object to my assignment of zeros. However, all of this was still subject to the lead professor's review.</p>\n\n<p>The professor asked for documentation of the offenses, and was in fact the undergraduate director of the department. I spent the better part of a week accumulating evidence, scouring Yahoo answers and other common homework repositories for the sources of the dirty students' answers. I found a veritable source for every single one. I printed copies of the students' responses, alongside their internet sources, and deposited the six-inch-tall stack of documents at the professor's door. </p>\n\n<p>As far as I know, nothing happened to a single student, and word was never made public of the massive cheating scandal that was blatantly obvious in this course. Multiple athletes were in this (1A) course. </p>\n\n<p>Is this just academia?</p>\n", "pids": ["56d8dddedabfae2eeefecd14"], "flag": 1}
{"question": "Can A3C update the policy / critic on a local machine without needing to copy?", "body": "<p>To make A2C into A3C you make it asynchronous. From what I understand the 'correct' way to do that is to thread off workers with a copy of the policy and critic, and then return the state/action/reward tuples to the main thread, which then performs the gradients updates on the main policy and critic, and then repeat the process.</p>\n\n<p>I understand why the copying would be necessary in a distributed environment, but if I were to always run it locally then could I just perform the updates on a global variable of the policy and critic, i.e. avoid the need for copying? Provided the concurrency of the updates was handled correctly, would that be fine?</p>\n", "pids": ["5736960a6e3b12023e51d64d"], "flag": 1}
{"question": "Should we transition to making our conference online or postpone?", "body": "<p>Last year we started organizing a conference in one of the European countries in September 2020. Everything was fixed and we had a number of registered people. As you all may know, due to the pandemic outbreak, many conferences in Europe were canceled. Since our conference was scheduled for September, we didn't declare it canceled and decided to wait a bit to see how the situation will be as we get close to the summer. </p>\n\n<p>Now, recently we thought about having an online conference instead of a real one. But we don't want it to be a failure as we have no experience with it and we are not aware of the public opinion about an online conference. </p>\n\n<p><strong>Is it a good idea to change the conference to an online one</strong> or it is better to postpone the real conference until the end of this pandemic crisis?</p>\n", "pids": ["5e997e4391e01118b66a5e4f"], "flag": 1}
{"question": "Which fields of AI are actively researching consciousness?", "body": "<p><a href=\"https://en.wikipedia.org/wiki/Max_Tegmark\" rel=\"nofollow noreferrer\">Max Tegmark</a> discusses the topic of consciousness in his book <a href=\"https://en.wikipedia.org/wiki/Life_3.0\" rel=\"nofollow noreferrer\">Life 3.0</a> and comes to the conclusion, that consciousness is substrate independent. If his analysis is correct, it should be possible to create artificial consciousness. <a href=\"https://en.wikipedia.org/wiki/Integrated_information_theory\" rel=\"nofollow noreferrer\">The integrated information theory (IIT)</a>, while currently only just a theory, also points in this direction.</p>\n<p>This leads me to the question: which fields of AI research, if any, are currently actively engaged in this domain?</p>\n<p>So far, I've only found research concerning consciousness in neuroscience and discussions of experts in philosophy.</p>\n<p>Are there any projects publicly known concerning artificial consciousness or organizations that are active in this regard?</p>\n", "pids": ["5ac1829d17c44a1fda917e33"], "flag": 1}
{"question": "Do we also need to model a probability distribution for the decoder of a VAE?", "body": "<p>I'm working on understanding VAEs, mostly through video lectures of Stanford cs231n, in particular <a href=\"https://youtu.be/5WoItGTWV54?t=2543\" rel=\"nofollow noreferrer\">lecture 13</a> tackles on this topic and I think I have a good theoretical grasp.</p>\n\n<p>However, when looking at actual code of implementations, such as <a href=\"https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py\" rel=\"nofollow noreferrer\">this code</a>  from <a href=\"https://blog.keras.io/building-autoencoders-in-keras.html\" rel=\"nofollow noreferrer\">this blog</a> of VAEs I see some differences which I can't quite understand.</p>\n\n<p>Please take a look at this VAE <a href=\"https://imgur.com/a/xK75jxL\" rel=\"nofollow noreferrer\">architecture visualization</a> from the class, specifically the decoder part. From the way it is presented here I understand that the decoder network outputs mean and covariance for the data <em>distribution</em>. To get an actual output (i.e. image) we need to sample from the distribution that is parametrized by mean and covariance - the outputs of the decoder.</p>\n\n<p>Now if you look at the code from the Keras blog VAE implementation, you will see that there is no such thing. A decoder takes in a sample from latent space and <strong>directly</strong> maps its input (sampled z) to an output (e.g. image), not to parameters of a distribution from which an output is to be sampled. </p>\n\n<p>Am I missing something or does this implementation not correspond to the one presented in the lecture? I've been trying to make sense of it for quite some time now but still can't seem to understand the discrepancy. </p>\n", "pids": ["5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "How should I acknowledge a friend for giving me a RAM module, which enabled me to run bigger simulations?", "body": "<p>As a part of a research project, I perform numerical simulations in my computer, and initially I could not work with bigger systems due to lack of computer memory.</p>\n<p>A friend from college had a spare RAM module, which was compatible with my computer. He gave it to me (for free), and I would return it when this project would be over.</p>\n<p>This enabled me to work with larger systems. We got some new results, and we are in the process of writing a paper. How can I acknowledge my friend? I don't know if it is a standard practice.</p>\n<p>Also, I had once told my research supervisor that I obtained this RAM module from a friend, but did not say that I want to acknowledge him if we write a paper (because back then I did not even know if I would get publishable results). How should I ask my supervisor about this? My supervisor is a friendly person.</p>\n<hr />\n<p>My friend is a classmate, but not a part of my research group, and did not contribute to the research. But I feel that I should acknowledge his help, because without it I would not be able to run these simulations. Something like &quot;I acknowledge X for providing computational facilities&quot; might seem confusing.</p>\n", "pids": ["5b67b47917c44aac1c8638f4"], "flag": 1}
{"question": "Is it true that mirror neurons can make a man with an amputated arm feel sensation just by looking at someone else&#39;s arm, like Ramachandran said?", "body": "<p>In <a href=\"https://www.youtube.com/watch?v=l80zgw07W4Y\" rel=\"nofollow noreferrer\">this</a> Ted Talk Ramachandran sais that <a href=\"https://en.wikipedia.org/wiki/Mirror_neuron\" rel=\"nofollow noreferrer\">mirror neurons</a> can make a person with an amputated arm feel sensation, is it true? And if so, why doesn't the brain feel a sensation by looking at someone else's arm when your arm is intact?</p>\n", "pids": ["53e99b7eb7602d97024248f1"], "flag": 1}
{"question": "What is the neurological basis for the association between Bipolar type 2 and autism spectrum disorder (ASD)?", "body": "<p>Bipolar disorder type 2 and autism spectrum disorder (ASD) is regularly seen together. What is the neurological explanation for this?</p>\n", "pids": ["53e9a357b7602d9702c62e80", "5c170c86da562969c458bd48", "5c1369feda56295a08a40564"], "flag": 1}
{"question": "Understanding how the loss was calculated for the SQuAD task in BERT paper", "body": "<p>In the <a href=\"https://arxiv.org/pdf/1810.04805.pdf\" rel=\"nofollow noreferrer\">BERT paper</a>, section 4.2 covers the SQuAD training. </p>\n\n<p>From my understanding, there are two extra parameters trained, they are two vectors with the same dimension as the hidden size, so the same dimensions as the contextualized embeddings in BERT. They are S (for start) and E (for End). For each, a softmax is taken with S and each of the final contextualized embeddings to get a score for the correct Start position. And the same thing is done for E and the correct end position.</p>\n\n<p>I get up to this part. But I am having trouble figuring out how the did the labeling and final loss calculations, which is described in this paragraph</p>\n\n<blockquote>\n  <p>and the maximum scoring span is used as the prediction. The training objective is the loglikelihood of the correct start and end positions.</p>\n</blockquote>\n\n<p>What do they mean by \"maximum scoring span is used as the prediction\"?</p>\n\n<p>Furthermore, how does that play into </p>\n\n<blockquote>\n  <p>The training objective is the loglikelihood of the correct start and end positions</p>\n</blockquote>\n\n<p>From this source: <a href=\"https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/\" rel=\"nofollow noreferrer\">https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/</a></p>\n\n<p>It says the log-likelihood is only applied to the correct classes. So, we are only calculating the softmax for the correct positions only, not any of the incorrect positions.</p>\n\n<p>If this interpretation is correct, then the loss will be</p>\n\n<pre><code>Loss = -Log( Softmax(S*T(predictedStart) / Sum(S*Ti) ) -Log( Softmax(E*T(predictedEnd) / Sum(S*Ti) )\n</code></pre>\n", "pids": ["5bdc31b417c44a1f58a0b8c2"], "flag": 1}
{"question": "Alphazero policy head loss not decreasing", "body": "<p>I am now working on training an alphazero player for a board game. The implementation of board game is mine, MCTS for alphazero was taken elsewhere. Due to complexity of the game, it takes a much longer time to self-play than to train.</p>\n\n<p>As you know, alphazero has 2 heads: value and policy. In my loss logging I see that with time, the value loss is decreasing pretty significantly. However, the policy loss only demonstrates fluctuation around its initial values. </p>\n\n<p>Maybe someone here has run into similar problems? I would like to know if its my implementation problem (but then the value loss is decreasing) or just a matter of not enough data.</p>\n\n<p>Also, perhaps importantly, the game has ~17k theoretically possible moves, but only 80 at max are legal at any single state (think chess - a lot of possibles but very few are actually legal at any given time). Also, if MCTS has 20 simulations, then the improved probabilities vector (against which we train our policy loss) will have at most 20 non-zero entries. My idea was that it might be hard for the network to learn such sparse vectors.</p>\n\n<p>Thank you for any ideas!</p>\n", "pids": ["5cede101da562983788e0a61"], "flag": 1}
{"question": "How fast does Monte Carlo tree search converge?", "body": "<p>How fast does Monte Carlo Tree Search converge? Is there a proof that it converges?</p>\n<p>How does it compare to temporal-difference learning in terms of convergence speed (assuming the evaluation step is a bit slow)?</p>\n<p>Is there a way to exploit the information gathered during the simulation phase to accelerate MCTS?</p>\n<p>Sorry if too many questions, if you have to choose one, please choose the last question.</p>\n", "pids": ["5ee203a39fced0a24beb82fe"], "flag": 1}
{"question": "What is the bandwidth of visual perception?", "body": "<p>Approximately how much &quot;bandwidth&quot;, in bits per second, can typical human visual perception process?</p>\n<p>Consider &quot;The Matrix&quot;, where we assume a near-perfect digital encoding that can reproduce any experience nearly perfectly, compressed with a digital intelligence beyond our own. Now they need to create a cable that plugs into our brainstem. How much bandwidth would that cable need to carry, in order to simulate full human visual experiences?</p>\n<p>For auditory processing -- given all the effort in digital audio compression, it seems likely the answer is somewhere close to 256 kbps (256,000 bits per second), at least within an order of magnitude, give or take. But vision seems far more complex, and I can't find any study or near-approximation that seems plausible.</p>\n<p>Presumably the answer is <em>somewhere</em> from 1 mbps (1,000,000 bits per second) to 1,000 times that amount. A naive approach would be what is the theoretical bandwidth to create any arbitrary video, to the fidelity where human perception could not distinguish differences. However, this is so grossly far from accurate that I suspect it is almost meaningless. I am relatively aware that our visual and auditory processing compress and transform the inputs we perceive, leading to optical illusions etc, which would suggest a much lower number than we might otherwise expect.</p>\n", "pids": ["5f0dffac9fced0a24b98f225"], "flag": 1}
{"question": "Does everyone make big mistakes?", "body": "<p>It is sometimes said that we all make big mistakes.  Is this true?</p>\n<p>As a starting point, 'big mistake' could be defined as a mistake which we do unconsciously for months, and for which the implications endure for more than a few months.</p>\n<p>What is the best approach to recover from 'big mistakes'?</p>\n", "pids": ["5c0f8385da562944ac8c84a6"], "flag": 1}
{"question": "How to measure confidence in non-binary (e.g. ordinal) choice tasks?", "body": "<p>In metacognition literature, why is confidence, regardless of scale (Likert-type or continuous) and definition (e.g. decision confidence as a subjective probability of a decision being correct), mostly measured in binary decision tasks, such as 2AFC?</p>\n<p>Is it psychologically valid to obtain confidence in other types of choice tasks, such as multiple-alternatives or ordinal ones, in a similar way?</p>\n", "pids": ["5ea55d649fced0a24b5538e9", "56d82e23dabfae2eee10c763"], "flag": 1}
{"question": "Is Trauma‐Focused Cognitive Behavioral Therapy applicable to adults?", "body": "<p>Can <a href=\"https://en.wikipedia.org/wiki/Trauma_focused_cognitive_behavioral_therapy\" rel=\"nofollow noreferrer\">Trauma‐Focused Cognitive Behavioral Therapy (TF CBT)</a> be used for adults? I've been told that it is applicable to adults but the literature I've found is all focused on children. Has anyone found this used in connection with adults?</p>\n<p><strong>Reference</strong></p>\n<p>Deblinger, E., Mannarino, A.P., Cohen, J.A., Runyon, M.K. and Steer, R.A. (2011), Trauma‐focused cognitive behavioral therapy for children: impact of the trauma narrative and treatment length. Depress. Anxiety, 28: 67-75. <a href=\"https://doi.org/10.1002/da.20744\" rel=\"nofollow noreferrer\">https://doi.org/10.1002/da.20744</a></p>\n", "pids": ["53e99960b7602d97021a52f9"], "flag": 1}
{"question": "In EEG recording, why ERD or ERS are not phase-locked wheras Bereitschaftspotential is?", "body": "<p>I guess this question is for experts of the domain, but anyway, maybe someone can answer it.</p>\n<p>So in EEG recording ERD and ERS (event related (de)synchronizition) designate short amplitude attenuation (or augmentation) of rythms within the alpha band..</p>\n<p>So, if they are not phase locked it means that when the event appears, the time they actually get trigered by it must vary ?</p>\n<p>On the contrary, for Bereitschaftspotential  (BP), when the event appears, we know exactly when BP will be trigered ?</p>\n<p>Are theses good explanations of the phase-lock and not phase-lock definition ?</p>\n<p>Thank you</p>\n", "pids": ["55a539bc65ceb7cb02e51335", "53e99937b7602d97021734a7"], "flag": 1}
{"question": "Insect identification (SP/Brazil)", "body": "<p>Found this insect in São Paulo/Brazil. Its length is ~2cm</p>\n\n<p>Any help to identify this insect would be appreciated.</p>\n\n<p><a href=\"https://i.stack.imgur.com/24tJC.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/24tJC.jpg\" alt=\"enter image description here\"></a>\n<a href=\"https://i.stack.imgur.com/wHPPL.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/wHPPL.jpg\" alt=\"enter image description here\"></a>\n<a href=\"https://i.stack.imgur.com/xSCwa.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/xSCwa.jpg\" alt=\"enter image description here\"></a>\n<a href=\"https://i.stack.imgur.com/5ipIg.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/5ipIg.png\" alt=\"enter image description here\"></a></p>\n\n<p>Also see my <a href=\"https://youtu.be/MSGW44S-zLY\" rel=\"nofollow noreferrer\">video</a></p>\n", "pids": ["53e9ade9b7602d97037f5874"], "flag": 1}
{"question": "How is psychohistory theory of deMause viewed in academia?", "body": "<p>I've recently came across the <a href=\"https://en.wikipedia.org/wiki/Psychohistory\" rel=\"nofollow noreferrer\">psychohistory theory</a> of deMause. To best of my understanding,\nit roughly tries to capture the common psychology of an era by analyzing the childbearing practices of that era. See the <a href=\"https://en.wikipedia.org/wiki/Lloyd_deMause\" rel=\"nofollow noreferrer\">summary</a> below.\n<a href=\"https://i.stack.imgur.com/oqrff.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/oqrff.png\" alt=\"enter image description here\" /></a></p>\n<p>I'd like to know how credible this theory is. Briefly, how is it viewed by academicians, what is the summary of some different opinions surrounding it etc.\nThe wiki is rather silent on such discussions.</p>\n", "pids": ["53e99792b7602d9701f58a2d"], "flag": 1}
{"question": "In technologically advanced countries, do most autistic adults not know they are autistic?", "body": "<p>I understand this is not an easy question to address. There are differences between the terms autism and Aspergers both in public perception and in the professional world, and it's a continuum or spectrum or constellation of characteristics (<a href=\"https://en.wikipedia.org/wiki/Syndrome\" rel=\"nofollow noreferrer\">syndromal</a>); there's no simple binary yes/no pass/fail, positive/negative test that I know of. There is of course the <a href=\"https://en.wikipedia.org/wiki/Autism-spectrum_quotient\" rel=\"nofollow noreferrer\">Autism-Spectrum Quotient</a> or AQ test (examples: <a href=\"https://psychology-tools.com/test/autism-spectrum-quotient\" rel=\"nofollow noreferrer\">1</a>, <a href=\"https://www.wired.com/2001/12/aqtest/\" rel=\"nofollow noreferrer\">2</a>) which provides a score, but the score must then be interpreted; there's still no fixed threshold.</p>\n<p>There are however both genetic and neurological markers that correlate with aspects of autism, refer for example to the videos</p>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=0o1PXeFEcL0\" rel=\"nofollow noreferrer\">Autism: An evolutionary perspective, Professor Simon Baron-Cohen, 1st Symposium of EPSIG, 2016</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=PjE_yaJjXE8\" rel=\"nofollow noreferrer\">Simon Baron-Cohen: Autism and the male brain</a></li>\n</ul>\n<p>Presumably Baron-Cohen put &quot;the male brain&quot; in the title to emphasize how much less is known about autism in females, perhaps due to some combination of lower frequency and different presentation <em>especially in adults.</em></p>\n<p>So while the question is simple to ask, there will not be a simple answer like &quot;Yes&quot; or &quot;No&quot; followed by a percentage of those that don't know.</p>\n<p>But as this is an important question, I'm hoping that at least some work has been done to assess the fraction of the adult autistic population who are as yet unaware of it and remain uninformed of it by medical and mental health professionals who may not be looking for it.</p>\n<p>Have any studies along this line been done? Is there at least some estimate?</p>\n<hr />\n<p>Different but potentially related and/or helpful:</p>\n<ul>\n<li><a href=\"https://psychology.stackexchange.com/q/23979/19214\">is it possible to be severely autistic yet not being &quot;visibly autistic&quot;?</a> (discusses diagnostic criteria)</li>\n<li><a href=\"https://psychology.stackexchange.com/q/23914/19214\">What is the relationship between mathematical ability and autism?</a> (some interesting references)</li>\n<li><a href=\"https://psychology.stackexchange.com/q/4515/19214\">Are the incidents of autism spectrum disorder on the rise, or is there an increase due to better definition of diagnostic criteria?</a></li>\n<li><a href=\"https://psychology.stackexchange.com/q/23896/19214\">What is the evidence that mathematicians are more likely to have autistic traits than the rest of the population?</a></li>\n</ul>\n", "pids": ["5c0f89f3da562944ac9a261e", "5fd562678cdecd4daa17d409", "55a6ca6565ce054aad75de09", "53e9a003b7602d97028e81d2", "55a40adf65ce5cd7b3c1881e", "55a683a965ce054aad6a3dca", "5fae6542d4150a363cdca692"], "flag": 0}
{"question": "Could opiate addictions be treated with esterase inhibitors?", "body": "<p>Since heroin is a <a href=\"https://sph.rutgers.edu/centers/chibps/heroin.html\" rel=\"nofollow noreferrer\">prodrug</a> (i.e <em>inactive</em>) and must be metabolized into morphine by certain esterase enzymes in order to produce psychoactive effects, would some esterase inhibitors theoretically decrease the amount of stimulation provided by a given dose? And would this be a practical method of treating heroin addiction?\nAlso wondering if the metabolization of prodrugs serves an additional purpose - such as decreasing toxicity - that would render any such treatment too dangerous.</p>\n", "pids": ["5dca894fdf1a9c0c41545aa5", "5c7a9da14895d9cbc6fd9c59", "55a5580e65ceb7cb02e8f6b7", "5d1dcf6d3a55ac57d42ec907"], "flag": 0}
{"question": "How do bile salts affect lipase activity?", "body": "<p><strong>BACKGROUND</strong>: It is well known that bile salts are needed for emulsification of fats. It is then said that this increases the surface area for activity of pancreatic lipase, implying that bile salts make pancreatic lipase more effective. But it is also said that pancreatic lipase do need a colipase to overcome the <strong><em>inhibitory effect from bile salts</em></strong>.</p>\n\n\n\n<p><strong>QUESTION</strong>: So what does bile salts actually do? Do they increase or decrease lipase activity? How does colipase overcome it?</p>\n\n\n\n<p><strong>MY ATTEMPT</strong>: After some research , I found that bile salts above critical micelle concentration have inhibitory effect, but could not still comprehend how does the colipase makes lipase more efficient. Also if greater concentration is inhibitory then why does our body just secrete it in sufficient amounts? Isn't it be more efficient than to make a whole protein(colipase)?</p>\n", "pids": ["53e9a64ab7602d9702f78f6d"], "flag": 1}
{"question": "Correlation between sexual repression in adolescents and sexual deviancy later in life?", "body": "<p>Is there a correlation between sexual repression and sexual deviancy?</p>\n<p>Now we all have heard stories of people growing up in incredibly strict households that become some of the most exploratory and sexually deviant persons as soon as they get a 'taste of freedom' in college, or kids that went to Catholic schools that seem to stand for the antithesis of everything the Catholic church is as soon as they get out.</p>\n<p>I was wondering, &quot;what gives?&quot; Before, having researched this topic, I just figured that repression of all kinds leads to deviant behavior, but after a search through some databases, I could not find anything that corroborates this belief.</p>\n<p>I did a few Google searches using the keywords Sexual repression and sexual deviance, as well as using the PsycINFO database from Ebsco that my school provides and using the same keywords to no avail. I also did searches of just the single keywords or ideas that vaguely mean the same thing, and I couldn't find what I was looking for.</p>\n<p>Am I just wrong in my assumption, or am I using these words or search terms wrong? I would really appreciate some insight into this topic, thanks everyone!</p>\n", "pids": ["5c0f8989da562944ac995362"], "flag": 1}
{"question": "Does anonymity decrease risk aversion?", "body": "<p>I was wondering if anonymity decreases risk-aversion? And if there are studies made in this subject already from which this could be further researched.</p>\n<p>For example. If we imagine a public casino where people wins and loses will be made public for everyone to see, would decrease the amount of risk taken vs a fully private casino.</p>\n<p>And I would like to know if know is this behaviour would extrapolate to other situation, like in social interactions (relationships)</p>\n", "pids": ["53e9a408b7602d9702d20541", "56d85e6fdabfae2eee68dc1f"], "flag": 1}
{"question": "Can motivation for sex be transformed into productive motivation?", "body": "<p>Sex seems to be a fundamental drive. To satisfy sexual desire, a person will often masturbate or have sex. </p>\n\n<ul>\n<li>What happens if a person abstains from anything sexual? </li>\n<li>Can this drive be \"transferred\" to other areas of an individual's life? </li>\n<li>That is, can sexual energy be transformed into productive energy?</li>\n</ul>\n", "pids": ["56d83b34dabfae2eee60781a"], "flag": 0}
{"question": "Are there guidelines in the peer reviewing process on assessing methodology?", "body": "<p>Usually an article goes through a peer-review process before it is published, and from what I here it is quite common that the reviewers \"demand\" some changes.</p>\n\n<ul>\n<li>Are there guidelines for peer- reviewers, especially as the methodological side of things is concerned?</li>\n<li>Are  \"methodology specialists\" incorporated in the process? </li>\n</ul>\n", "pids": ["56d92b3fdabfae2eeed9d2d9"], "flag": 0}
{"question": "Neural basis of primitive (newborn) reflexes", "body": "<p>The <a href=\"http://en.wikipedia.org/wiki/Primitive_reflexes\" rel=\"nofollow\">Wikipedia article on primitive reflexes</a>, or newborn reflexes, states that they originate in the CNS. Here's the list of reflexes from the article:</p>\n\n<ul>\n<li>Moro</li>\n<li>Walking/stepping</li>\n<li>Rooting</li>\n<li>Sucking</li>\n<li>Tonic neck</li>\n<li>Palmar grasp</li>\n<li>Plantar</li>\n<li>Galant</li>\n<li>Swimming</li>\n<li>Babkin</li>\n</ul>\n\n<p><strong>Precisely where in the CNS do they originate?</strong></p>\n", "pids": ["55a50fc7612c6b12ab028c6c"], "flag": 0}
{"question": "Why do programmers work at night?", "body": "<p>I can be described as a morning person, where waking up at 4:20 AM to catch a flight is no problem. My colleague on the other hand go to bed no earlier than midnight and often later than that.</p>\n\n<p>We're both programmers, and if we're in a critical phase of a project, my colleague works until 3AM, and I start at 4AM. Still both times are in the middle of the night and we tend to get most work done at off working hours.</p>\n\n<p>Question is why that is?</p>\n", "pids": ["53e99ae7b7602d97023709e9"], "flag": 0}
{"question": "Other deep learning image generation techniques besides GANs?", "body": "<p>Can you please point me to some resources about image genereation besides GANs?\nAre there any other techniques throughout history?\nHow did idea of image generation evolved and how it started?</p>\n\n<p>I tried googling \"image generation before gans\" and similar alternatives but without any success.</p>\n", "pids": ["5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "Binary classification as a cognitive strategy?", "body": "<p>Is there any research investigating whether the human cognitive system has a tendency to reduce complex systems or spectra of data in terms of binary contrast?</p>\n\n<p>There are many common-sense dual taxonomical sets. Some of these have a basis in objective reality (the binary male/female has proved an especially effective evolutionary strategy), others may be argued to be more in the eye of the beholder. Day and night could be said to be extremes in a cycle; left and right, conservative and liberal are ranges on a spectrum (cf. friend and foe; \"there are only two kinds of people\"). A lot has been written about gender identity and sexual orientation in the framework of a Hegelian master/slave dialectic, but I am not interested in the <em>relationship</em> between the members in an oppositional set. Structuralist theorists and anthropologists have claimed and then disclaimed that societies organize themselves in binary sets, but more interesting to me than factual organization is how reality is perceived. Also, when an anthropologist or theorist says most concepts are defined by contrast with their opposites, I can't help but wonder whether we have quantifiable data along these lines.</p>\n\n<p>I am hoping to find out whether these common-sense binary taxonomies correlate with cognitive/perceptive processes. Especially interesting to me is the question whether there are certain low-level cognitive strategies, though I am also interested in high-level processes (e.g. formal logic is mostly organized along binary lines, true/false). Since the cognitive sciences are not my field, I would be very grateful for references to both foundational studies and \"raw\" field work. General works on the reduction of reality to accommodate limited processing power are also welcome. Visual processes are not my primary interest, but if you can point to a single \"best primer\" on the filter that allows us to \"see\" an entire bookcase but not all book titles in a single glance, that would be a helpful bonus. I know nothing about the workings of biological neural networks, but if there is a binary selection at any point in their operation, I would be very grateful to see that explained in an accessible but peer-reviewed text. Finally, keywords to help me find more on this in scholarship search engines would be most helpful.</p>\n", "pids": ["56d9031adabfae2eeee49be8"], "flag": 0}
{"question": "Why do authors track $\\gamma_t$ in Prioritized Experience Replay Paper?", "body": "<p>In the <a href=\"https://arxiv.org/pdf/1511.05952.pdf\" rel=\"nofollow noreferrer\">original prioritized experience replay paper</a>, the authors track <span class=\"math-container\">$\\gamma_t$</span> in every state transition tuple (see line 6 in algorithm below):</p>\n\n<p><a href=\"https://i.stack.imgur.com/dSnQZ.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/dSnQZ.png\" alt=\"algorithm\"></a></p>\n\n<p>Why do the authors track this at every time step?  Also, many blog posts and implementations leave this out (including I believe the <a href=\"https://github.com/openai/baselines/blob/master/baselines/deepq/replay_buffer.py\" rel=\"nofollow noreferrer\">OpenAI implementation</a> on github).</p>\n\n<p>Can someone explain explicitly how <span class=\"math-container\">$\\gamma_t$</span> is used in this algorithm?</p>\n\n<p><strong>Note</strong>: I understand the typical use of <span class=\"math-container\">$\\gamma$</span> as a discount factor. But typically gamma remains fixed. Which is why I’m curious as to the need to track it. </p>\n", "pids": ["5cede0f0da562983788ceb64"], "flag": 1}
{"question": "experimental tracking and treating bipolar disorder", "body": "<p>Is there a way to measure what neurotransmitters (and in what amount) are present in a person via blood or other method? I feel like if such information was available there could be experiments regarding the tracking and treatment of many mental disorders, but most specifically Bipolar Disorder. For example, if there could be an established \"norm\" of neurotransmitter levels you could then find the levels a person has and alter them via a mixture of drugs and monitor the levels periodically. This wouldn't require MRI imaging because you wouldn't be tracking when the neurotransmitters were triggered but the levels, the triggering/action potentials would be changed through cognitive behavioral and dialectal behavioral therapy. This is a alight ramble but i would appreciate any thoughts or insight.</p>\n", "pids": ["53e9b923b7602d970450b063", "53e9a618b7602d9702f45747", "53e9bd04b7602d970498d8e9", "53e9a7c8b7602d9703104c6c"], "flag": 1}
{"question": "Motor skill: Let speed come naturally?", "body": "<p>I've commonly heard that when practising a motor skill, one should start slow with correct form and one shouldn't force speed. Rather, let speed come naturally. I believe this but I can't find a citation for its prescription. Does anyone have a study to support (or deny) this?</p>\n<p>I'm particularly interested in <a href=\"https://www.sciencedirect.com/topics/engineering/aiming-movement\" rel=\"nofollow noreferrer\">aiming movement</a> in <a href=\"https://www.youtube.com/watch?v=ykuuv23-40o\" rel=\"nofollow noreferrer\">first-person shooter</a> video-games. The input device is moving a computer mouse. I am also training in <a href=\"https://www.youtube.com/watch?v=vDjlV6Qtb90\" rel=\"nofollow noreferrer\">Super smash Bros. Melee</a>, a platform fighting game. The input device is a <a href=\"https://www.google.com/search?tbm=isch&amp;q=gamecube+controller\" rel=\"nofollow noreferrer\">GameCube controller</a>. These would both fall under fine motor skill.</p>\n", "pids": ["55a3cf882401c6de3b74b712"], "flag": 1}
{"question": "What is the purpose and benefit of applying CNN to a graph?", "body": "<p>I'm new to the graph convolution network. I wonder what is the main purpose of applying data with graph structure to CNN?</p>\n", "pids": ["5bdc31c217c44a1f58a0c914", "599c797f601a182cd2644442", "5cede0edda562983788cba9b", "619b5dc91c45e57ce93811a8", "5a9cb66717c44a376ffb868e", "58d82fd2d649053542fd75d8"], "flag": 1}
{"question": "How can I incrementally train a Yolo model without catastrophic forgetting?", "body": "<p>I have successfully trained a Yolo model to recognize k classes. Now I want to train by adding k+1 class to the pre-trained weights (k classes) without forgetting previous k classes. Ideally, I want to keep adding classes and train over the previous weights, i.e., train only the new classes. If I have to train all classes (k+1) every time a new class is added, it would be too time-consuming, as training k classes would take <span class=\"math-container\">$k*20000$</span> iterations, versus the <span class=\"math-container\">$20000$</span> iterations per new class if I can add the classes incrementally. </p>\n\n<p>The dataset is balanced (5000 images per classes for training).</p>\n\n<p>I appreciated if you can throw some methods or techniques to do this continual training for Yolo.</p>\n", "pids": ["5c873b4d4895d9cbc6f504ad"], "flag": 1}
{"question": "Are there any better visual models for transfer rather than ImageNet?", "body": "<p>Similar to the recent pushes in Pretrained Language Models (BERT, GPT2, XLNet) I was wondering if such a thrust exists in Computer Vision?</p>\n\n<p>From my understanding, it seems the community has converged and settled for ImageNet trained classifiers as the \"Pretrained Visual Model\". But relative to the data we have access too, shouldn't there exist something stronger? Also, classification as a sole task has its own constrictions on domain transfer (based on the assumption of how these loss manifolds are).</p>\n\n<p>Are there any better visual models for transfer rather than ImageNet successes? If no, why? Is it because of the domains fluidity in shape, resolution, etc., in comparison to text?</p>\n", "pids": ["58437725ac44360f1082fede"], "flag": 1}
{"question": "Why do we normalize data in a deep neural network?", "body": "<p>I have asked this question a number of times, but I always get confusing answers to this, like \"normalized data works better\", \"data lives in the same scale\"</p>\n\n<p>How can <code>x-m/s</code> make the scale of images the same? Please explain to me the maths. Also, take MNIST dataset for example &amp; illustration.</p>\n", "pids": ["5cede0fbda562983788dadf1", "573696ce6e3b12023e5ce95a", "5c80f459e1cd8e544cae2003"], "flag": 1}
{"question": "Does this hyperparameter optimisation approach yield the optimal hyperparameters?", "body": "<p>Say I have a ML model which is not very costly to train. It has around say 5 hyperparameters. </p>\n\n<p>One way to select best hyperparameters would be to keep all the other hyperparamaters fixed and train the model by changing only one hyperparameter within a certain range. For the sake of mathematical convenience, we assume for the hyperparameter <span class=\"math-container\">$h^1$</span>, keeping all other hyperparameters fixed to their initial values, the model performs best when  <span class=\"math-container\">$h^1_{low} &lt; h^1 &lt; h^1_{high}$</span> (which we found out by running the model on a huge range of <span class=\"math-container\">$h^1$</span>). Now we, fix <span class=\"math-container\">$h^1$</span> to one of the best values and tune <span class=\"math-container\">$h^2$</span> the same way, where <span class=\"math-container\">$h^1$</span> is chosen and the rest of the hyperparameters are again fixed on their initial values.</p>\n\n<p>My question is: Does this method find the best hyperparameter choices for the model? I know if the hyperparameters are independent, then this definitely does find the best solution, but in a general case, what is the general theory around this? (NOTE: I am not asking about the problem of choosing hyperparamaters, but I am asking about the aforementioned approach of choosing hyperparameters)</p>\n", "pids": ["5b67b4b917c44aac1c867d8e", "5550415c45ce0a409eb3a9b2"], "flag": 1}
{"question": "Spam Detection using Recurrent Neural Networks", "body": "<p>I am working on <a href=\"https://github.com/nfmcclure/tensorflow_cookbook/blob/master/09_Recurrent_Neural_Networks/02_Implementing_RNN_for_Spam_Prediction/02_implementing_rnn.py\" rel=\"nofollow noreferrer\">this code</a> for spam detection using recurrent neural networks. </p>\n\n<p>Question 1. I am wondering whether this field (using RNNs for email spam detection) worths more researches or it is a closed research field. </p>\n\n<p>Question 2. What is the oldest published paper in this field? </p>\n\n<p>Quesiton 3. What are the pros and cons of using RNNs for email spam detection over other classification methods?</p>\n", "pids": ["5b67b4b917c44aac1c867e34", "53e9b0b6b7602d9703b23d7f"], "flag": 1}
{"question": "How to foster gender diversity as an organizer", "body": "<p>I am part of the organizing committee for a workshop in a STEM field that historically has problems with underrepresentation of women (and other groups, but let me focus on women in this question). I would like to help foster an inclusive environment at the workshop and more generally in my department and am looking for suggestions for how to proceed. </p>\n\n<p>The topic of the workshop is slightly out of my field of expertise and I do not have a long list of qualified speakers (of any gender) that I can offer suggestions from. </p>\n\n<p>I suspect that the senior member of the committee will take the attitude that he is \"gender blind\" and chooses speakers to invite based only on their quality but that because of implicit biases, the invitee list he draws up will be something like 90% male. I do not think he will be particularly open to a direct conversation about gender and underrepresentation.</p>\n\n<p>I saw <a href=\"https://academia.stackexchange.com/questions/21117/\">this question</a> which was asking <em>whether</em> preferential invitation of female speakers is normal; I am instead asking <em>how</em> to foster diversity (perhaps by preferential invitation or by other means).</p>\n", "pids": ["56d873e4dabfae2eee098248"], "flag": 1}
{"question": "How does a spider&#39;s legs not get caught in silk when wrapping prey?", "body": "<p>When a spider catches a prey, it wraps it up in silk. It uses its legs to do this. So how does its own legs not get stuck on the silk?</p>\n\n<p>Note: I'm not talking about walking around the web. There are non-sticky anchor strands of silk to walk on. I'm talking about when the spider actually wraps something up.</p>\n", "pids": ["619b5bde1c45e57ce91c2d5c"], "flag": 1}
{"question": "What do the numbers in this CNN architecture stand for?", "body": "<p>So I've got a neural net model (ResNet-18) and made a diagram according to the literature (<a href=\"https://arxiv.org/abs/1512.03385\" rel=\"nofollow noreferrer\">https://arxiv.org/abs/1512.03385</a>). </p>\n\n<p>I think I understand most of the format of the convolutional layers:\n<em>filter dims</em> ,conv, <strong><em>unknown number</em></strong> ,<em>stride</em>(if applicable)</p>\n\n<p>What does the number after 'conv' in the convolutional layers indicate? is it the number of neurons in the layer? </p>\n\n<p><a href=\"https://i.stack.imgur.com/pkPi3.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/pkPi3.png\" alt=\"ResNet-18 architecture\"></a></p>\n\n<p>bonus q: this is being used for unsupervised learning of images, i.e the embedding output a network produces for an image is used for clustering. Would this make it incorrect for my architecture to have an FC layer at the end (which would be used for classifcation)?</p>\n", "pids": ["573696026e3b12023e515eec"], "flag": 1}
{"question": "Untrained CNNs as feature extractors?", "body": "<p>I've heard somewhere that due to their nature of capturing spatial relations, even untrained CNNs can be used as feature extractors? Is this true? Does anyone have any sources regarding this I can look at?</p>\n", "pids": ["5cede0f4da562983788d2fe7", "5a9cb65d17c44a376ffb8017"], "flag": 1}
{"question": "Is there any computer vision technology that can detect any type of object?", "body": "<p>Is there any computer vision technology that can detect any type of object? For example, there is a camera fixed, looking in one direction always looking at a similar background. If there is an object, no matter what the object is (person, bag, car, bike, cup, cat) the CV algorithm would notice if there is an object in the frame. <strong>It wouldn't know what type of object it is, just that there is an object in the frame.</strong> </p>\n\n<p>Something similar to motion detector but that would work on a flat conveyor belt. Even though the conveyor belt moves will look similar between frames. Would something like this be possible? Possibly something to do with extracting differences from the background, with the goal being to not have to train the network with data for every possible object that may pass by the camera.</p>\n", "pids": ["5c0f821dda562944ac896fb7"], "flag": 1}
{"question": "Is it useful to eliminate the less relevant filters from a trained CNN?", "body": "<p>Imagine I have a tensorflow CNN model with good accuracy but maybe too many filters:</p>\n\n<ul>\n<li><p><strong>Is there a way to determine which filters have more impact in output?</strong> I think it should be possible. At least, if a filter A has a 0, that only multiples the output of a filter B, then filter B is not related to filter A. In particular, I'm thinking in 2d data where 1 dimension is time-related and the other feature related (like one-hot char).</p></li>\n<li><p><strong>Is there a way to eliminate the less relevant filters from a trained model</strong>, and leave the rest of the model intact?</p></li>\n<li><p><strong>Is it useful or there are better methods?</strong></p></li>\n</ul>\n", "pids": ["5c75755bf56def97989e3bd4"], "flag": 1}
{"question": "How can I &quot;measure&quot; an object using Computer Vision techniques and neural networks?", "body": "<p>I would like to develop a neural network to measure the distance between two opposite sides of an object in an image (in a similar way that the fractional caliper tool measures an object).</p>\n<p>So, given an image of an object, the neural network should produce the depth or height of the object.</p>\n<p>Which computer vision techniques and neural networks could I use to solve this problem?</p>\n", "pids": ["58437735ac44360f10831de2"], "flag": 1}
{"question": "Is it generally accepted idea that a memory associated with strong olfactory stimuli will be kept longer?", "body": "<p>Question:\nIf you go to see flowers and don't smell them, is it likely that you will forget the event easier than when you do smell them? assuming all the other factors are constant.</p>\n<hr />\n<p>Here's the story.</p>\n<p>These days, with my nose always covered by a mask (and only smelling my own breath all the time), I can hardly smell flowers. So, when I went to see flowers last weekend, I guessed that the event will be less memorable than those from previous years.</p>\n<p>I'm not in the bio/neuro field, so I wanted to check if my guess was right. After a few hours of search, I concluded that the guess wasn't a bad one.\nWhat I learned from the quick search was that:\nthe olfactory system pathway is different from those of visual or auditory systems. For example, optic signals are relayed to the optic chiasm, which locates beneath the hypothalamus, then to the lateral thalamus, then to the visual cortex, which is near the back head. So, they just &quot;pass by&quot; the limbic system. Olfactory signals, on the other hand, are <em>directed to</em> the limbic system, parts of which handle emotional memory(amygdala) and long-term memory(hippocampus). Except that I am not sure what that 'handle' exactly means, it seems sensible to me that electric signals directed closer to the part of the brain related to memory are more likely to stimulate memory than those signals that divert the part.</p>\n<p>I was happy to learn something new and posted it somewhere. Sadly, one of my distant friends had to disagree with me. She has ph.D. in a somewhat related field (she may have a good reason for that) and she refused(!) to give me a further explanation :(</p>\n<p>What did I get wrong?</p>\n", "pids": ["53e9a525b7602d9702e47461", "640327e090e50fcafd756b4b", "626e659c5aee126c0f2c4da7", "53e9af53b7602d970399461a", "56d823ecdabfae2eeecf29f9", "55a5e7db65cead59c82eff24", "53e99b30b7602d97023cad92", "53e9aae5b7602d970346377a", "55a40b5665ce5cd7b3c1b088", "55a3e76f612ca648687d0003"], "flag": 0}
{"question": "Is there a term/name for the feeling you get when trying to pat your head and rub your tummy?", "body": "<p>I often hear the phrase &quot;It's like patting your head and rubbing your tummy/belly&quot; when referring to trying to perform two seemingly simple actions that inexplicably conflict with each other, preventing one or even both of the actions from being performed well.</p>\n<p>Another popular example involves swinging your right foot in a clockwise motion while trying to draw the number 6.</p>\n<p>It kind of reminds me of &quot;cognitive dissonance&quot;, the uncomfortable feeling you get when holding two contradictory beliefs.</p>\n<p>So is there a word for this sensation? &quot;Operational dissonance&quot; perhaps? I'd love to read more about it, but I've no idea what to search for.</p>\n", "pids": ["53e9b93fb7602d970452d2e1", "53e9b4e9b7602d970401109c"], "flag": 1}
{"question": "How exactly does adversarial training help in handling mode-collapse in generative networks?", "body": "<p>Of my understanding mode-collapse is when there happen to be multiple classes in the dataset and the generative network converges to only one of these classes and generates images only within this class. On training the model more, the model converges to another class.</p>\n\n<p>In Goodfellows NeurIPS presentation he clearly addressed how training a generative network in an adversarial manner avoids mode-collapse. How exactly do GAN's avoid mode-collapse? and did previous works on generative networks not try to address this?</p>\n\n<p>Apart from the obvious superior performance (generally), is the fact that GAN's address mode-collapse make them far preferred over other ways of training a generative model?</p>\n", "pids": ["58d82fced649053542fd7453", "58d82fc8d649053542fd5c10"], "flag": 1}
{"question": "What&#39;s the exact definition of a cognitive mechanism?", "body": "<p>I've been trying to get to a specific definition of a cognitive mechanism, but googling it surprisingly didn't give me anything. The only things I've found out are :</p>\n<ol>\n<li>How to know if something can be considered a cognitive mechanism :\n<a href=\"https://ajp.psychiatryonline.org/doi/full/10.1176/ajp.155.12.1677\" rel=\"nofollow noreferrer\">https://ajp.psychiatryonline.org/doi/full/10.1176/ajp.155.12.1677</a></li>\n<li>I've come across examples like dissociation, planning fallacy(wrt entrepreneurship) etc.</li>\n</ol>\n<p>They sounded more like cognitive processes, but I'd like a clearer definition of it. I also wanted to know when do we think about cognitive mechanisms vs behavioural mechanisms.</p>\n<p>Would really appreciate the clarity!</p>\n<p>Edit : I first found the term in the paper mentioned in point 1.</p>\n", "pids": ["55a46b5365ce31bc8779f364", "53e99df7b7602d97026b71e4", "5e5e19a193d709897ce7cf74"], "flag": 1}
{"question": "What is the difference between reinforcement learning and AutoML?", "body": "<p>My vague understanding of reinforcement learning (RL) is that it's very similar to supervised learning except that it updates on a continuous feed of data/activity, this to me sounds very similar to AutoML (which I've started to notice being used). </p>\n\n<p>Do they use different algorithms? What is the fundamental difference between RL and AutoML?</p>\n\n<p>I'm after an explanation for somebody who understands technology but does not work with machine learning tools regularly. </p>\n", "pids": ["5e50fe033a55ac0466732034", "5c615efbe1cd8eae1501a3d8", "59ae3bf12bbe271c4c71bd1a", "58d82fc8d649053542fd59b8", "5c8f69874895d9cbc647064f"], "flag": 1}
{"question": "Training actor-critic algorithms in games with opponents", "body": "<p>I am wondering how am I supposed to train a model using actor/critic algorithms in <strong>environments with opponents</strong>. I tried the followings (using A3C and DDPG):</p>\n\n<ol>\n<li>Play against <strong>random player</strong>. I had rather good results, but not as good as expected since most interesting states cannot be reached with a random opponent.</li>\n<li>Play against <strong>list of specific AIs</strong>. Results were excellent against those AIs, but very bad with never seen opponents</li>\n<li>Play against <strong>itself</strong>. Seemed the best to me, but I could not get any convergence due to non-stationary environment. </li>\n</ol>\n\n<p>Any thought or advice about this would be very welcome.</p>\n", "pids": ["59ec02da0cf22f5df7319dc3", "5cede0f8da562983788d7f4d", "5cf48a4ada56291d582ae145", "62281ae95aee126c0f7aadcc"], "flag": 1}
{"question": "What does the Markov assumption say about the history of state sequences?", "body": "<p>Does the Markov assumption say that the conditional probability of the next state only depends on the current state or does it say that the conditional probability depends on a fixed finite number of previous states?</p>\n\n<p>As far as I understand from <a href=\"https://en.wikipedia.org/wiki/Markov_property#Introduction\" rel=\"nofollow noreferrer\">the related Wikipedia article</a>, the probability of the next state <span class=\"math-container\">$s'$</span> to appear only depends on the current state <span class=\"math-container\">$s$</span>.</p>\n\n<p>However, in the book \"Artificial Intelligence: A Modern Approach\" by Russell and Norvig, on page 568, they say: \"<strong>Markov assumption</strong> — that the current state depends on only a <em>finite fixed number</em> of previous states\". </p>\n\n<p>To me, the second statement seems contradictory to the first, because it may mean that a state can depend on the history of states as long as the number is fixed a finite. For example, the current state depended on the last state and the state before the last state, which is 2 sequential previous states (a finite number of states).</p>\n\n<p>Is Markov assumption and Markov property the same?</p>\n", "pids": ["5c615e9fe1cd8eae1501923f"], "flag": 1}
{"question": "How can I perform lane detection with reinforcement learning?", "body": "<p>I'm quite new to reinforcement learning and my project will consist of detecting lanes with RL. </p>\n\n<p>I'm using q-learning and I'm having a hard time thinking how my q table should look like, I mean - what could represent a state. My main idea is to feed the machine with a frame that contains a road picture, which the edge detection function is being applied to (and by thus getting lots of lines that exits in the frame). And train the machine which lines are the correct lane line. I already have a deterministic function that already recognizes the lanes and it will be the function that will teach the machine. I already organized some lane parameters such as (lane length, lane cords, lane color (white or yellow have a better probability to be a lane), lane diameter and the lane incline). </p>\n\n<p>Now, my only issue is how should I construct the Q-table. Basically, what could represent a state and which lanes or decisions I should reward.</p>\n", "pids": ["5cede0ecda562983788ca6b6"], "flag": 1}
{"question": "How long does an area clean-up help it stay clean?", "body": "<p>Sometime in middle or high school I remember coming across this popular thinking of,\nwhen an area or neighbourhood has some trash, it makes people think it's ok to litter there themselves, and the more trash there is, the more of an unspoken 'norm' littering becomes. However, the hope was that the reverse is also true, and if a neighbourhood's cleaned up, then it signals to people that littering is the anti-norm here.</p>\n<p>But I have gone on trash cleaning walks around my neighbourhood in the past few months, and I can't say that that hope is totally founded. The street by my apartment building has trash reemerge with a vengeance within a week. It makes me think there's some discrepancy in how this is thought about. Like, it's harder to see during night-time, so it absolves you from confronting the results of trash on the grass, and the like.</p>\n<p>Are there long-term studies around (various) neighbourhoods that study this behaviour, and detangle and clarify the different factors at play here? Other studies are good too.</p>\n", "pids": ["5a9f9e67684d03e1ed1bc0dd", "5c757d2bf56def9798ab2ae4", "5c7f9a5ce1cd8e08659f4e5e"], "flag": 1}
{"question": "What needs to be done to make a fair algorithm?", "body": "<p>What needs to be done to make a fair algorithm (supervised and unsupervised)?</p>\n\n<p>In this context, there is <a href=\"https://dl.acm.org/citation.cfm?id=3084096\" rel=\"nofollow noreferrer\">no consensus on the definition of <em>fairness</em></a>, so you can use the definition you find most appropriate.</p>\n", "pids": ["5b67b47917c44aac1c8637b9", "5c757d72f56def9798ae13ca", "5c5ce50d17c44a400fc38e4c"], "flag": 1}
{"question": "Why is there more than one way of calculating the accuracy?", "body": "<p>Some sources consider the true negatives (TN) when computing the accuracy, while some don't.</p>\n\n<p>Source 1:\n<a href=\"https://medium.com/greyatom/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b\" rel=\"nofollow noreferrer\">https://medium.com/greyatom/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/qZ1dN.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/qZ1dN.png\" alt=\"Considers TN\"></a></p>\n\n<p>Source 2:<a href=\"https://www.researchgate.net/profile/Mohammad_Sorower/publication/266888594_A_Literature_Survey_on_Algorithms_for_Multi-label_Learning/links/58d1864392851cf4f8f4b72a/A-Literature-Survey-on-Algorithms-for-Multi-label-Learning.pdf\" rel=\"nofollow noreferrer\">https://www.researchgate.net/profile/Mohammad_Sorower/publication/266888594_A_Literature_Survey_on_Algorithms_for_Multi-label_Learning/links/58d1864392851cf4f8f4b72a/A-Literature-Survey-on-Algorithms-for-Multi-label-Learning.pdf</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/v8XPx.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/v8XPx.png\" alt=\"enter image description here\"></a> </p>\n\n<p>which can be translated as </p>\n\n<p><a href=\"https://i.stack.imgur.com/ZNOum.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/ZNOum.png\" alt=\"enter image description here\"></a></p>\n\n<p>which one of these must be considered for my multi-label model.</p>\n", "pids": ["5f0e5a739fced0a24b31b4cf"], "flag": 1}
{"question": "Does a fully convolutional network share the same translation invariance properties we get from networks that use max-pooling?", "body": "<p>Does a fully convolutional network share the same translation invariance properties we get from networks that use max-pooling?</p>\n\n<p>If not, why do they perform as well as networks which use max-pooling? </p>\n", "pids": ["573698016e3b12023e6da477"], "flag": 1}
{"question": "Is strict adherence to a citation format really necessary in actual research?", "body": "<p>In high school and college I remember whenever doing some research for a class, my English teacher then will look at the citation at the end and use a red pen to mark out any place where MLA format is not strictly followed. This is probably the reason that there are 106 million hits for \"MLA How?\" on Google.</p>\n\n<p>Doubtlessly citation is necessary and very helpful, but I question over the strict adherence to a particular formatting style. But the problem is I have this idea that you must cite with 100% accuracy and adheres to a particular style. It was drilled into my head by my English teachers and professors particularly those in the arts and social sciences. Now I am in graduate school and I am faced with having to cite dozen of extremely well known literature with a very small audience in mind. Some of the authors are who works at another lab down the street or I meet everyday. In all honesty, the citation is done in the off chance someone who reads it and finds that he needs additional literature support.</p>\n\n\n\n<p>By <em>formatting style</em>, I mean any generic formatting style MLA/IEEE/APA (<a href=\"https://owl.english.purdue.edu/owl/\">https://owl.english.purdue.edu/owl/</a>) or otherwise that instructs you to cite as follows:</p>\n\n<blockquote>\n  <p>[First Name][Last Name] \"[Text]\"...[Publisher][Page\n  Number][Chapter]...[Web/Print/Hardcopy...][Date Accessed in m/d/y or d/m/y]...</p>\n</blockquote>\n\n<p>Don't forget each [...] needs to be separated, by ; , or a dot, or comma as instructed. </p>\n\n\n\n<p>For one, doing a strict alignment with a particular format a huge time waster for the author and practice feels a little bit cultish. </p>\n\n<p>Secondly, <em>if the most necessary information pertaining to a particular reference is included in the citation section</em>, do I  REALLY need to ... align the format with a particular citation style with strict adherence? I think nowadays most people just look at the author and the book title and do an online search.</p>\n\n<p>For example, is there a huge problem with writing:</p>\n\n<p><strong>A. Thomasz \"Guide to IEEE or MLA format\". Dover. 1999. Print.</strong></p>\n\n<p>or</p>\n\n<p><strong>Thomasz Antonie, Guide to IEEE or MLA Format, Dover, 1999.</strong></p>\n\n<p>or</p>\n\n<p><strong>Thomasz Antonie. \"Guide to IEEE or MLA Format\". www.guidetoieeeormla.com. Web.</strong></p>\n\n<p>Or</p>\n\n<p><strong>A. Thomasz. www.guidetoieeeormla.com.</strong> </p>\n\n<p>Actually if I remember far back enough in high school you would actually need to cite another person if he speaks to you. So if I had spoken to Mr. Antonie (made up person), then I would have to cite our conversation in a particular style. \"Verbatim\" was the word, or \"Orally\", or \"Presentation\"? I don't think I have ever done that after high school, even in reality much of what I know is by speaking to other people, yet I never reference any of those people.</p>\n\n<p>I have not yet written a research paper. Is strict adherence to a particular formatting style actually followed in practical research? Is there any big problems that would arise if a particular citation style is not strictly followed? </p>\n\n<p>This question is inspired when I was exploring around and seeing how people in other countries say France do not particularly care about this issue and everything works fine. I am in the hard sciences if that helps.</p>\n\n<p><strong>Comment: looks like an American phenomenon, just so you know in American schools we are taught for the span of 4 years to manually type all citations in MLA (including the full URL link) Here's a paper addressing this interesting <a href=\"http://www.parlorpress.com/pdf/walker--everything-changes.pdf\">cultural practice</a></strong></p>\n", "pids": ["53e99d80b7602d970263b943"], "flag": 1}
{"question": "Does a queen wasp sting also have poison?", "body": "<p>Last night I got sting by a wasp and because of the time of the year I suppose it is a queen. But usually it swells and hurts for a day after it, but this time nothing happened only that I woke up of the sting which hurt a little for a short time, but in the morning I couldn't find any signs of the sting.</p>\n\n<p>Now is this because of the poison is worked out because it could be a pretty 'old'  new wasp queen and her enzymes like histamines and aptoxine are got too old? Or do queen wasps not use/have poison or less? Or is it my body that just reacted different?</p>\n", "pids": ["55a4d494c91bf3b1cc47db28"], "flag": 1}
{"question": "Is a non-linear activation function needed if we perform max-pooling after the convolution layer?", "body": "<p>Is there any need to use a non-linear activation function (ReLU, LeakyReLU, Sigmoid, etc.) if the result of the convolution layer is passed through the sliding window max function, like max-pooling, which is non-linear itself? What about the average pooling?</p>\n", "pids": ["57a4e91dac44365e35c988cf"], "flag": 1}
{"question": "How to do machine translation with no labeled data?", "body": "<p>Is it be possible to train a neural network, with no parallel bilingual data, for machine translation?</p>\n", "pids": ["5c615ff8e1cd8eae1501cd70", "5a260c8117c44a4ba8a30c02"], "flag": 1}
{"question": "Is using tensorflow for Spiking neural networks a &quot;good&quot; idea?", "body": "<p>I recently started working with Spiking Neural Networks and was hoping for some input from others. I saw there were many libraries/platforms specifically made for working with SNN's (Brian, PyNN, NEURON, etc...) however I was wondering if there were any tradeoffs in using plain, old popular Tensorflow for SNN implementation. Is there a reason that it is underresearched? Has anyone tried or working on this?</p>\n<p>Thanks for any feedback anyone can offer,</p>\n", "pids": ["5c8fb9c24895d9cbc65dcabc", "608937b3e4510cd7c8639cd3"], "flag": 1}
{"question": "Before GAN, what are the commonly used techniques for image-to-image translation?", "body": "<p>As per a <a href=\"https://towardsdatascience.com/image-to-image-translation-69c10c18f6ff\" rel=\"nofollow noreferrer\">post</a>, image-to-image translation is a type of CV problem. </p>\n\n<p>I guess I understand the concept of image-to-image translation.</p>\n\n<p><a href=\"https://i.stack.imgur.com/aAakq.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/aAakq.png\" alt=\"enter image description here\"></a></p>\n\n<p>I am aware that GANs(generative adversarial networks) are good at this kind of problems.</p>\n\n<p>I just wondered what the commonly used techniques are for this kind of problems Before GAN?</p>\n\n<p>Could someone please give a hint? Thanks in advance.</p>\n", "pids": ["57a4e91dac44365e35c987bb"], "flag": 1}
{"question": "Is it allowed for a psychologist to claim to be a friend of the patient", "body": "<p>Is there any ethical/therapeutical guidelines preventing a psychologist to claim to be a friend of the patient?</p>\n<p>The relevant points are:</p>\n<ul>\n<li><p>I am aware that there <a href=\"https://psychology.stackexchange.com/questions/21441/can-a-friend-become-a-therapist\">are rules against treating friends</a>,  and I have even found references to disciplinary actions when the relationship started after the treatment.</p>\n</li>\n<li><p>But here there is no relationship other than the professional one. Patient and psychologist did not knew before treatment, do not meet outside of practice hours, and do not develop any social activity that could be interpreted as friendship. It is just the therapist claiming to be a friend.</p>\n</li>\n<li><p>OTOH, there is no ill-intent. No &quot;I am your friend, so tell me your credit card number&quot; schema or anything like that.</p>\n</li>\n</ul>\n<p>Could this kind of action be considered as going against ethical/therapeutical principles?</p>\n<p>If a country is needed, it would be in Spain, although I am asking just to inform myself so I would be ok with an &quot;universal&quot; answer if that is possible.</p>\n", "pids": ["55a49f0f65ceb7cb02d46c6c"], "flag": 1}
{"question": "Appropriate algorithm for RL problem with sparse rewards, continuous actions and significant stochasticity", "body": "<p>I'm working on a RL problem with the following properties:</p>\n\n<ol>\n<li>The rewards are <strong>extremely sparse</strong> i.e. all rewards are 0 except the terminal non-zero reward. Ideally I would not use any reward engineering as that would lead to a different optimization problem.</li>\n<li><strong>Actions are continuous</strong>. Discretization should not be used.</li>\n<li>The amount of <strong>stochasticity in the environment is very high</strong> i.e. for a fixed deterministic policy the variance of returns is very high.</li>\n</ol>\n\n<p>More specifically, the RL agent represents the investor, the terminal reward represents the utility of the terminal wealth (hence the sparsity), actions represent portfolio positions (hence the continuity) and the environment represents the financial market (hence the high stochasticity).</p>\n\n<p>I've been trying to use DDPG with a set of \"commonly used\" hyperparameters (as I have no idea have to tune them besides experimenting which lasts too long) but so far (after 10000 episodes) it seems that nothing is happening.</p>\n\n<p><a href=\"https://i.stack.imgur.com/yjA9O.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/yjA9O.png\" alt=\"enter image description here\"></a></p>\n\n<p>My questions are the following:</p>\n\n<ol>\n<li>Given the nature of the problem I'm trying to solve (sparse rewards, continuous actions, stochasticity) is there a particular (D)RL algorithm that would lend itself well to it?</li>\n<li>How likely is it that DDPG simply won't converge to a reasonable solution (due to the peculiarities of the problem itself) no matter what set of hyperparameters I choose?</li>\n</ol>\n", "pids": ["5a260c8117c44a4ba8a30b14", "65bbd44f939a5f4082fdd83e", "5c04966a17c44a2c7470855a"], "flag": 1}
{"question": "What is verbal memory useful for?", "body": "<p>A friend of mine did the <a href=\"https://humanbenchmark.com/tests/verbal-memory\" rel=\"nofollow noreferrer\">Verbal Memory Test at http://humanbenchmark.com/</a> and got an extremely high score (almost 300 words). English is not his first language and he knew the meaning of only about two thirds of the words (if that's something to take into account).</p>\n<blockquote>\n<p>About the test</p>\n<p>This test measures how many words you can keep in short term memory at once.</p>\n<p>The number of words you need to remember grows continually, until you can't keep them in your head anymore.</p>\n<p>Go as long as you can. You have 3 strikes until game over.</p>\n<p>Your score is how many turns you lasted.</p>\n</blockquote>\n<p>Does this have any practical use or influence in other areas of cognition?</p>\n", "pids": ["53e9b029b7602d9703a8764e", "56d8d751dabfae2eeed563f2", "56ae9e900cf2a8c8f71499f1"], "flag": 1}
{"question": "Accuracy dropped when I ran the program the second time", "body": "<p>I was following a tutorial about Feed-Forward Networks and wrote this code for a simple FFN :</p>\n<pre><code>class FirstFFNetwork:\n  \n  #intialize the parameters\n  def __init__(self):\n    self.w1 = np.random.randn()\n    self.w2 = np.random.randn()\n    self.w3 = np.random.randn()\n    self.w4 = np.random.randn()\n    self.w5 = np.random.randn()\n    self.w6 = np.random.randn()\n    self.b1 = 0\n    self.b2 = 0\n    self.b3 = 0\n  \n  def sigmoid(self, x):\n    return 1.0/(1.0 + np.exp(-x))\n  \n  def forward_pass(self, x):\n    #forward pass - preactivation and activation\n    self.x1, self.x2 = x\n    self.a1 = self.w1*self.x1 + self.w2*self.x2 + self.b1\n    self.h1 = self.sigmoid(self.a1)\n    self.a2 = self.w3*self.x1 + self.w4*self.x2 + self.b2\n    self.h2 = self.sigmoid(self.a2)\n    self.a3 = self.w5*self.h1 + self.w6*self.h2 + self.b3\n    self.h3 = self.sigmoid(self.a3)\n    return self.h3\n  \n  def grad(self, x, y):\n    #back propagation\n    self.forward_pass(x)\n    \n    self.dw5 = (self.h3-y) * self.h3*(1-self.h3) * self.h1\n    self.dw6 = (self.h3-y) * self.h3*(1-self.h3) * self.h2\n    self.db3 = (self.h3-y) * self.h3*(1-self.h3)\n    \n    self.dw1 = (self.h3-y) * self.h3*(1-self.h3) * self.w5 * self.h1*(1-self.h1) * self.x1\n    self.dw2 = (self.h3-y) * self.h3*(1-self.h3) * self.w5 * self.h1*(1-self.h1) * self.x2\n    self.db1 = (self.h3-y) * self.h3*(1-self.h3) * self.w5 * self.h1*(1-self.h1)\n  \n    self.dw3 = (self.h3-y) * self.h3*(1-self.h3) * self.w6 * self.h2*(1-self.h2) * self.x1\n    self.dw4 = (self.h3-y) * self.h3*(1-self.h3) * self.w6 * self.h2*(1-self.h2) * self.x2\n    self.db2 = (self.h3-y) * self.h3*(1-self.h3) * self.w6 * self.h2*(1-self.h2)\n    \n  \n  def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, display_loss=False):\n    \n    # initialise w, b\n    if initialise:\n      self.w1 = np.random.randn()\n      self.w2 = np.random.randn()\n      self.w3 = np.random.randn()\n      self.w4 = np.random.randn()\n      self.w5 = np.random.randn()\n      self.w6 = np.random.randn()\n      self.b1 = 0\n      self.b2 = 0\n      self.b3 = 0\n      \n    if display_loss:\n      loss = {}\n    \n    for i in tqdm_notebook(range(epochs), total=epochs, unit=&quot;epoch&quot;):\n      dw1, dw2, dw3, dw4, dw5, dw6, db1, db2, db3 = [0]*9\n      for x, y in zip(X, Y):\n        self.grad(x, y)\n        dw1 += self.dw1\n        dw2 += self.dw2\n        dw3 += self.dw3\n        dw4 += self.dw4\n        dw5 += self.dw5\n        dw6 += self.dw6\n        db1 += self.db1\n        db2 += self.db2\n        db3 += self.db3\n        \n      m = X.shape[1]\n      self.w1 -= learning_rate * dw1 / m\n      self.w2 -= learning_rate * dw2 / m\n      self.w3 -= learning_rate * dw3 / m\n      self.w4 -= learning_rate * dw4 / m\n      self.w5 -= learning_rate * dw5 / m\n      self.w6 -= learning_rate * dw6 / m\n      self.b1 -= learning_rate * db1 / m\n      self.b2 -= learning_rate * db2 / m\n      self.b3 -= learning_rate * db3 / m\n      \n      if display_loss:\n        Y_pred = self.predict(X)\n        loss[i] = mean_squared_error(Y_pred, Y)\n    \n    if display_loss:\n      plt.plot(loss.values())\n      plt.xlabel('Epochs')\n      plt.ylabel('Mean Squared Error')\n      plt.show()\n      \n  def predict(self, X):\n    #predicting the results on unseen data\n    Y_pred = []\n    for x in X:\n      y_pred = self.forward_pass(x)\n      Y_pred.append(y_pred)\n    return np.array(Y_pred)\n</code></pre>\n<p>The data was generated as follows :</p>\n<pre><code>data, labels = make_blobs(n_samples=1000, centers=4, n_features=2, random_state=0)\nlabels_orig = labels\nlabels = np.mod(labels_orig, 2)\nX_train, X_val, Y_train, Y_val = train_test_split(data, labels, stratify=labels, random_state=0)\n</code></pre>\n<p>When I ran the program yesterday, I had gotten a training accuracy of about 98% and a test accuracy of 94%. But when I ran it today, suddenly the accuracy dropped to 60-70%. I tried to scatter plot the result, and it looked like it behaved as if it were a single sigmoid instead of the Feed-Forward Network.</p>\n<pre><code>ffn = FirstFFNetwork()\n#train the model on the data\nffn.fit(X_train, Y_train, epochs=2000, learning_rate=.01, display_loss=False)\n#predictions\nY_pred_train = ffn.predict(X_train)\nY_pred_binarised_train = (Y_pred_train &gt;= 0.5).astype(&quot;int&quot;).ravel()\nY_pred_val = ffn.predict(X_val)\nY_pred_binarised_val = (Y_pred_val &gt;= 0.5).astype(&quot;int&quot;).ravel()\naccuracy_train_1 = accuracy_score(Y_pred_binarised_train, Y_train)\naccuracy_val_1 = accuracy_score(Y_pred_binarised_val, Y_val)\n#model performance\nprint(&quot;Training accuracy&quot;, round(accuracy_train_1, 2))\nprint(&quot;Validation accuracy&quot;, round(accuracy_val_1, 2)\n</code></pre>\n<p>I do not understand how this happened and cannot figure it out.</p>\n", "pids": ["5c86e71c4895d9cbc6ad21d3"], "flag": 1}
{"question": "Are there any novel quantum machine learning algorithms that are fundamentally different from &quot;classical&quot; ones?", "body": "<p>Generally, if one googles \"quantum machine learning\" or anything similar the general gist of the results is that quantum computing will greatly <em>speed up</em> the learning process of our \"classical\" machine learning algorithms. However, \"speed up\" itself does not seem very appealing to me as the current leaps made in AI/ML are generally due to novel architectures or methods, <em>not</em> faster training.</p>\n\n<p>Are there any quantum machine learning methods in development that are <em>fundamentally</em> different from \"classical\" methods? By this I mean that these methods are (almost*) impossible to perform on \"classical\" computers. </p>\n\n<p><sub>*except for simulation of the quantum computer of course</sub></p>\n", "pids": ["5c75726df56def9798810d4e", "56d88d02dabfae2eeec737f4"], "flag": 1}
{"question": "How does publishing in the deep learning world work, with respect to journals and arXiv?", "body": "<p>Let's say I implemented a new deep learning model that pushed some SOTA a little bit further, and I wrote a new paper about for publication.</p>\n\n<p>How does it work now? I pictured three options:</p>\n\n<ol>\n<li><p><strong>Submit it to a conference</strong>. Ok, that's the easy one, I submit it to something like NeurIPS or ICML and hope to get accepted. At that point, how do you make your paper accessible? Are there problems in uploading it to arXiv later, in order to get read by more people?</p></li>\n<li><p><strong>Upload it on arXiv directly</strong>. If I do that it would not be peer-reviewed, and technically speaking it would be devoid of \"academic value\". Right? It could easily be read by anyone, but there would be no formal \"proof\" of its \"scientific quality\". Correct me if I'm wrong.</p></li>\n<li><p><strong>Submit it to a peer-reviewed journal</strong>. Avoid desk rejection, avoid reviewers' rejection, after a long painful process it ends up on some international scientific journal. At that point, since the article is formally the editor's property, can you still upload it on arXiv, or on your blog, so that it can be accessible by many people?</p></li>\n<li><p>How do the big stars of deep learning research do when they have some hot new paper ready for publication? And what publications are the most valued in the professional and the academic world?</p></li>\n</ol>\n", "pids": ["599c7987601a182cd2648373"], "flag": 1}
{"question": "Using tensor networks as machine learning models", "body": "<p>Tensor networks (check <a href=\"https://arxiv.org/pdf/1812.04011.pdf\" rel=\"nofollow noreferrer\">this paper</a> for a review) are a numerical method originally introduced in condensed matter physics to model complex quantum systems. Roughly speaking, such systems are described by a very high-dimensional tensor (where the indices take a number of values scaling exponentially with the number of system constituents) and tensor networks provide an efficient representation of the latter as an outer product and contraction of many low-dimensional tensors.</p>\n\n<p>More recently, a specific kind of tensor network (called Matrix Product State in physics) found interesting applications in machine-learning through the so-called Tensor-Train decomposition (I do not know of a precise canonical reference in this context, so I will abstain from citing anything).</p>\n\n<p>Now, over the last few years, several works from the physics community seemed to push for a generalized use of tensor networks in machine learning (see <a href=\"https://arxiv.org/pdf/1605.05775.pdf\" rel=\"nofollow noreferrer\">this paper</a>, <a href=\"https://arxiv.org/pdf/1910.07425.pdf\" rel=\"nofollow noreferrer\">a second one</a> and <a href=\"https://arxiv.org/pdf/2001.08286.pdf\" rel=\"nofollow noreferrer\">a third one</a> and <a href=\"https://ai.googleblog.com/2019/06/introducing-tensornetwork-open-source.html\" rel=\"nofollow noreferrer\">this article</a> from Google AI for context). As a physicist, I am glad to learn that tools initially devised for physics may find interdisciplinary applications. However, at the same time, my critical mind tells me that from the machine learning research community's perspective, these results may not look that intriguing. After all, machine learning is now a very established field and it takes probably more than a suggestion for a new machine learning model and a basic benchmarking on a trivial dataset (as the MNIST one) -which is what the papers essentially do in my humble opinion- to attract any attention in the area. Besides, as I believe to know, there already exists quite a solid body of knowledge on tensor analysis techniques for machine learning (e.g.  tensor decompositions), which may cast doubt on the originality of the contribution.</p>\n\n<p>I would therefore be very curious to have the opinion of machine learning experts on this line of research: is it really an interesting direction to look into, or is it just about surfing on the current machine learning hype with a not-so-serious proposal?</p>\n", "pids": ["5e5cd97391e011498fe97174", "5c756c28f56def979845df9a", "61c969d15244ab9dcb6ed63a", "5c757d6ff56def9798adf4b1", "5efdabf191e01191d3d281d8", "5c757ddbf56def9798b2c680", "53e9a9f0b7602d970335af9d", "5c756922f56def979826477e"], "flag": 1}
{"question": "Referencing the reference?", "body": "<p>Suppose I have a paper with the following text:</p>\n\n<blockquote>\n  <p>Roses are red, violets are blue, sugar is sweet, and so are you [3],[4].</p>\n</blockquote>\n\n<p>As one can see, the author got the information from two other references.<br>\nIf I want to add this information in my thesis, do I also have to reference [3] and [4] or can I just reference this particular paper, I got the information from?</p>\n", "pids": ["5c39990adf5b8c0b3c8947f9", "5ff681ffd4150a363cb87d0b"], "flag": 1}
{"question": "Research assistant wishes to remain anonymous, what to write in the acknowledgement?", "body": "<p>So this is pretty much it. My co-author, who is also the main author, has hired an assistant through Elance (an online work outsourcing platform) for doing statistical analysis and also to collect and annotate some relevant literature about connected topic X. I was aware of this and was OK with it, knowing that his or her work is not significant enough to claim authorship but will be acknowledged properly. Now it turned out that, for reasons not entirely clear to me, the RA does not want their name to be disclosed in the acknowledgement section. Even funnier, we do not even know their real name or email address, just the nickname and the profile they use on Elance.</p>\n\n<p>We have the following options: </p>\n\n<ol>\n<li><p>Do not acknowledge the contribution at all (at first, out of question; but see below why it should be considered)</p></li>\n<li><p>acknowledge the contribution without naming the contributor. (Like \"The authors would like to thank &lt;Main Author&gt;'s research assistant for their help in preparing this manuscript...\") As far as I know this would be nonstandard.</p></li>\n<li><p>acknowledge the contribution without naming the contributor but indicating that remaining anonymous was his explicit request. </p></li>\n<li><p>acknowledge the contribution and identify them by their Elance nickname\n(Like \"The authors would like to thank to \"FyI1978\" from Elance for their help in preparing this manuscript...\") This would make us seem unprofessional or laughable; if I have the right impression.</p></li>\n<li><p>redo the statistics and clean the manuscript from any elements that might bear the mark of the RA's contribution (so that we would not have to acknowledge them at all).</p></li>\n</ol>\n\n<p>What is your advice, how should we proceed?</p>\n", "pids": ["53e9a922b7602d97032732d5"], "flag": 1}
{"question": "Is there any research on models that provide uncertainty estimation?", "body": "<p>Is there any research on machine learning models that provide uncertainty estimation?</p>\n\n<p>If I train a denoising autoencoder on words and put through a noised word, I'd like it to return a certainty that it is correct given the distribution of data it has been trained on. </p>\n\n<p>Answering these questions or metrics for uncertainty are both things I am curious about. Just general ways for models to just say \"I'm not sure\" when it receives something far outside the inputs it's been trained to approximate.</p>\n", "pids": ["5a4aef9e17c44a2190f7a34c", "573696006e3b12023e513cb6"], "flag": 1}
{"question": "Advice for getting a paper published as a highschooler", "body": "<p>I have possibly found a somewhat novel method of proving a famous theorem, and after some research, I found a variant of the method published as a paper. So, naturally, I reached out to the professor who wrote that and asked him for opportunities and I am waiting for a reply.</p>\n<p>If he declines my request for help on publishing the paper, what other ways is it possible to get a paper published as a person who isn't affiliated with a university/ Has major connections?</p>\n<p>Other than that, the process from an outsider's perspective looks a bit tedious right now, but what are the general things to keep in mind while approaching it?</p>\n<p>My educational details are that I've passed out my HS this year.</p>\n<p>Note: I've checked with some grad students, the result is indeed correct. The current state of whether they'll help me follow through with publishing however is a 'maybe'</p>\n<p>Update: Got in touch with the prof and sent the tex file containing the paper to the publisher which he had published too. Hopefully gets some acknowledgment :-)</p>\n<p>Update 2.0: Seems to have been done already <a href=\"https://math.stackexchange.com/a/1802085/317327\">(See here)</a>, not sure if there exists a paper on this but that killed of the novelty.</p>\n<p>A word from me to all the answerers: Thank you all. Turns out that my proof was posted before on MSE and I do not wish to publish something already done before. However for the actual question which I had asked, I have received many great answers and I honestly can not objectively choose a single answer which have helped me the most since all of them provided value to me in one way or the other.</p>\n<p>As is most relevant to my individual problem of me publishing this result, I will accept Kostya's answer as they were the ones who found that the proof was done before. Again, thank you all.</p>\n", "pids": ["53e99ea0b7602d97027693c2"], "flag": 1}
{"question": "How to improve the language of my master thesis by myself?", "body": "<p>I have written my thesis on my own (with my limited English skills) and I gave it to my supervisor to check it. He said the work is fine but the writing is a bit bad and I need to proofread it by myself. I know that my English level is just below the normal and needs time to improve. However, I have limited time (a couple of weeks), so my question is how to improve my English writing efficiently during this period that will lead to an improvement of my thesis?</p>\n\n<p>I have heard that there are some phrases and academic vocabulary list that are given by Cambridge University or other universities for use and are not regarded as plagiarism, does anyone know them?</p>\n", "pids": ["5c88bba84895d9cbc6904d9c"], "flag": 1}
{"question": "Can the neuronal firing rate be increased through medication/diet?", "body": "<p>My rudimentary understanding of the neuronal firing rate is that it varies person to person, and neuron to neuron. So any specific number for a firing rate would be specific to the test subject and type of neuron etc. However aside from this I'm interested to find out if any medication or specific dietary constituents have been shown to increase neuronal firing rate in average test subjects. To be clear I understand that some medication has been shown to help suffers of diseases such as Alzheimer's, but I'm interested in the typical human brain. </p>\n", "pids": ["55a4d745c91bf3b1cc481152", "53e9ab20b7602d97034a9ff3", "55a5a3da612c6b12ab27e0b1", "55a4604065ce31bc8778a9b3"], "flag": 0}
{"question": "How are exploding numbers in a forward pass of a CNN combated?", "body": "<p>Take AlexNet for example:</p>\n\n<p><a href=\"https://i.stack.imgur.com/YZce8.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/YZce8.png\" alt=\"combined gpu stream of alexnet\"></a></p>\n\n<p>In this case, only the activation function ReLU is used. Due to the fact ReLU cannot be saturated, it instead explodes, like in the following example:</p>\n\n<p>Say I have a weight matrix of <code>[-1,-2,3,4]</code> and inputs of <code>[ReLU(4), ReLU(5), ReLU(-2), Relu(-3)]</code>. The resultant matrix from these will have large numbers for the inputs of <code>ReLU(4)</code> and <code>ReLU(5)</code>, and 0 for <code>ReLU(-2)</code> and <code>ReLU(-3)</code>. If there are even just a few more layers, the numbers are quick to either explode or be 0.</p>\n\n<p>How is this typically combated? How do you keep these numbers towards 0? I understand you can take subtract the mean at the end of each layer, but for a layer that is already in the millions, subtracting the mean will still result in thousands.</p>\n", "pids": ["573696f46e3b12023e5f0d4d"], "flag": 1}
{"question": "What are bag-of-features in computer vision?", "body": "<p>In computer vision, what are bag-of-features (also known as bag-of-visual-words)? How do they work? What can they be used for? How are they related to the bag-of-words model in NLP?</p>\n", "pids": ["53e9a073b7602d970295d6bf"], "flag": 1}
{"question": "What is the difference between LSTM and fully connected LSTM?", "body": "<p>I'm currently trying to understand the difference between a vanilla LSTM and a fully connected LSTM. In <a href=\"https://arxiv.org/abs/1506.04214\" rel=\"nofollow noreferrer\">a paper</a> I'm reading, the FC-LSTM gets introduced as</p>\n\n<blockquote>\n  <p>FC-LSTM may be seen as a multivariate version of LSTM where the input, cell output and states are all 1D vectors</p>\n</blockquote>\n\n<p>But is not really expanded further upon. Google also didn't help me much in that regard as I can't seem to find anything under that keyword. </p>\n\n<p>What is the difference between the two? Also, I'm a bit confused by the quote - aren't inputs, outputs, etc. of a vanilla LSTM already 1D vectors?</p>\n", "pids": ["53e99bffb7602d97024ac0e6", "573696ce6e3b12023e5cec74"], "flag": 1}
{"question": "What measure or criteria wording can be used to track trends in p factor?", "body": "<p>Background: you can use factor analysis on mental illness to get a general psychopathology factor, like the g factor in intelligence but instead a general mental illness factor.</p>\n<p><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4209412/\" rel=\"nofollow noreferrer\">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4209412/</a></p>\n<p>Intent: I am interested in using a forecast aggregation platform to predict whether we will discover a Flynn effect like trend in p factor, either up or down.\n<a href=\"https://www.metaculus.com/questions/\" rel=\"nofollow noreferrer\">https://www.metaculus.com/questions/</a></p>\n<p>Caveat: Flynn may be hollow for g, and in theory something like that could happen with a p factor trend too.  That's fine. Our forecast question can be agnostic about the nature of the trend, in order to be reliably resolvable without too much administrative effort.</p>\n<p><em>Specific need:</em> what simple metric, or criteria wording, could be shown to the forecasters, such that they could predict something that will reliably resolve? In forecasting, the event description must be unambiguous.  This is harder than people new to forecasting tend to expect.  One thing that might affect our criterion choice is how we think future researchers will measure such a thing, as piggybacking off already-reported metrics can make forecast question-writing easier.</p>\n<p>E.g. suppose if we had the following wording: &quot;Will there be data to support a trend in the p factor, at least equivalent to an average 2 IQ point-per-decade change, either up or down, during any 10-year period before 2040?&quot;  Would it be easy for people not working in any related field to kind of just, do a cursory search around 2040 (or every few years) and clearly tell if such a thing has happened? If not, what would be a better way to word it?</p>\n<p>Any input appreciated!</p>\n", "pids": ["61c8e9905244ab9dcb77eab1", "53e9ad0ab7602d97036e7916", "5c0f9174da562944aca98794", "5e85c26d9fced0a24bdfcabf", "55a6649265ce054aad664ae8", "5ce3a74aced107d4c653a854", "5548db350cf2abac7d0411ee"], "flag": 1}
{"question": "Has the Fibonacci series or the golden ratio been applied in any way in AI?", "body": "<p>I have been looking at the Fibonacci series, the golden ratio, and its uses in nature, like how flowers and animals grow based on the series.</p>\n<p>I was wondering whether we could use the Fibonacci series and the golden ratio in any way in AI, especially in evolutionary algorithms. Any ideas or insights?</p>\n<p>Is this research material? If so where can we start?</p>\n", "pids": ["61ca2a2b5244ab9dcb937d8e"], "flag": 1}
{"question": "Does self-supervised learning require auxiliary tasks?", "body": "<p>Self-supervised learning algorithms provide labels automatically. But, it is not clear what else is required for an algorithm to fall under the category &quot;self-supervised&quot;:</p>\n<p>Some say, self-supervised learning algorithms learn on a set of <em>auxiliary tasks</em> [<a href=\"https://stats.stackexchange.com/questions/434224/how-to-differentiate-auto-encoder-techniques-from-self-supervised-learning\">1</a>], also named <em>pretext task</em> [<a href=\"https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html\" rel=\"nofollow noreferrer\">2</a>, <a href=\"https://ai.stackexchange.com/a/10743/38174\">3</a>], instead of the task we are interested in. Further examples are word2vec or autoencoders [<a href=\"https://link.springer.com/chapter/10.1007/978-3-319-46672-9_10\" rel=\"nofollow noreferrer\">4</a>] or word2vec [<a href=\"https://hackernoon.com/self-supervised-learning-gets-us-closer-to-autonomous-learning-be77e6c86b5a\" rel=\"nofollow noreferrer\">5</a>]. Here it is sometimes mentioned that the goal is to &quot;expose the inner structure of the data&quot;.</p>\n<p>Others do not mention that, implying that some algorithms can be called to be &quot;self-supervised learning algorithms&quot; if they are directly learning the task we are interested in [<a href=\"https://ai.stackexchange.com/a/10624/38174\">6</a>, <a href=\"https://medium.com/@behnamsabeti/various-types-of-supervision-in-machine-learning-c7f32c190fbe\" rel=\"nofollow noreferrer\">7</a>].</p>\n<p><strong>Is the &quot;auxiliary tasks&quot; a requirement for a training setup to be called &quot;self-supervised learning&quot; or is it just optional?</strong></p>\n<hr />\n<h2>Research articles mentioning the auxiliary / pretext task:</h2>\n<ol>\n<li><a href=\"https://arxiv.org/abs/1901.09005\" rel=\"nofollow noreferrer\">Revisiting Self-Supervised Visual Representation Learning, 2019</a>, mentioned by [<a href=\"https://ai.stackexchange.com/a/10743/38174\">3</a>]:</li>\n</ol>\n<blockquote>\n<p>The self-supervised learning framework requires only unlabeled data in order to formulate a pretext learning task such as predicting context or image rotation, for which a target objective can be computed without supervision.</p>\n</blockquote>\n<ol start=\"2\">\n<li><a href=\"https://arxiv.org/abs/1803.07728\" rel=\"nofollow noreferrer\">Unsupervised Representation Learning by Predicting Image Rotations,  ICLR, 2018</a>, mentioned by\n[<a href=\"https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html\" rel=\"nofollow noreferrer\">2</a>]:</li>\n</ol>\n<blockquote>\n<p>a prominent paradigm is the so-called self-supervised learning that defines an annotation free pretext task, using only the visual information present on the images or videos, in order to provide a surrogatesupervision signal for feature learning.</p>\n</blockquote>\n<ol start=\"3\">\n<li><a href=\"https://arxiv.org/abs/1505.05192\" rel=\"nofollow noreferrer\">Unsupervised Visual Representation Learning by Context Prediction, 2016</a>, mentioned by\n[<a href=\"https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html\" rel=\"nofollow noreferrer\">2</a>]:</li>\n</ol>\n<blockquote>\n<p>This converts an apparently unsupervised problem (finding a good similarity metric between words) intoa “self-supervised” one:  learning a function from a givenword to the words surrounding it.  Here the context predic-tion  task  is  just  a  “pretext”  to  force  the  model  to  learn  agood word embedding, which, in turn, has been shown tobe useful in a number of real tasks, such as semantic wordsimilarity.</p>\n</blockquote>\n<ol start=\"4\">\n<li><a href=\"https://arxiv.org/abs/1905.01235\" rel=\"nofollow noreferrer\">Scaling and Benchmarking Self-Supervised Visual Representation Learning, 2019</a>:</li>\n</ol>\n<blockquote>\n<p>In discriminative self-supervised learning, which is the main focus of this work, a model is trained on an auxiliary or ‘pretext’ task for which ground-truth is available for free. In most cases, the pretext task involves predicting some hidden portion of the data (for example, predicting color for gray-scale images</p>\n</blockquote>\n", "pids": ["5d9edc3347c8f766460368cc"], "flag": 1}
{"question": "Writing thesis that rebuts advisor&#39;s theory", "body": "<p>A potential masters thesis advisor became pretty famous (in his field) for the development of a certain theory in behavioral economics. However, I find that his theory is relatively unexplainable, and I feel that I have come up with an alternative theory that would explain the exact same phenomena, but in a more justifiable way.</p>\n<p>Knowing very little about how thesis advisors view their students' work or the dominance of their own theories, I see two possibilities:</p>\n<p>First, my theory might not be very good and my professor will either point out the flaw, or encourage me to continue developing the flawed theory because it's better than nothing.</p>\n<p>Second, my theory may actually be pretty good and my professor may view it with hostility, consciously or subconsciously. Is it unreasonable for me to consider this a possibility? Is it a possibility? How likely is it?</p>\n", "pids": ["5c0f86d0da562944ac93d5fa"], "flag": 1}
{"question": "Are there methods of evaluating the effects of psychoactive drugs that use free-form verbal reports?", "body": "<p>If one wished to study the effects of a psychoactive drug such as LSD, what strikes me as a natural primary starting point would be to ask participants what they actually experienced.  For example, they could write a page in response to a simple question about what the experience was like.</p>\n<p>The results could then be analyzed using an approach such as <a href=\"https://en.wikipedia.org/wiki/Natural_language_processing\" rel=\"nofollow noreferrer\">natural language processing</a>, to find common themes in reported effects.  This analysis would then be open to peer-review and replication.</p>\n<p>Is this a method of research that anyone currently practices in psychology?</p>\n", "pids": ["5ff682c3d4150a363cbb0083", "5f8a0870db0c4ff2316491a9"], "flag": 1}
{"question": "How can I read any AI paper?", "body": "<p>I have studied linear algebra, probability, and calculus twice. But I don't understand how can I reach the level that I can read any AI paper and understand mathematical notation in it.</p>\n<p>What is your strategy when you see the mathematical expression that you can't understand?</p>\n<p>For example, in Wasserstein GAN article, there are many advanced mathematical notations. Also, some papers are written by people who have a master's in mathematics, and those people use advanced mathematics in some papers, but I have a CS background.</p>\n<p>When you come across this kind of problem, what do you do?</p>\n", "pids": ["599c7988601a182cd2649090"], "flag": 1}
{"question": "Can repetitive sports-related head injuries make a person senile many years later?", "body": "<p>Would repetitive football injuries to the cranium show up decades later, causing symptoms resembling mild retardation, OCD, etc.? What is the best way to determine this in terms of imaging, testing, etc.?</p>\n", "pids": ["55a5e7dc65cead59c82f0137"], "flag": 0}
{"question": "What is the reason for mode collapse in GAN as opposed to WGAN?", "body": "<p><a href=\"https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html\" rel=\"nofollow noreferrer\">In this article</a> I am reading:</p>\n<blockquote>\n<p><span class=\"math-container\">$D_{KL}$</span> gives us inifity when two distributions are disjoint. The value of <span class=\"math-container\">$D_{JS}$</span> has sudden jump, not differentiable at <span class=\"math-container\">$\\theta=0$</span>. Only Wasserstein metric provides a smooth measure, which is super helpful for a stable learning process using gradient descents.</p>\n</blockquote>\n<p>Why is this important for a stable learning process? I have also the feeling this is also the reason for mode collapse in GANs, but I am not sure.</p>\n<p>The Wasserstein GAN paper also talks about it obviously, but I think I am missing a point. Does it say JS does not provide a usable gradient? What exactly does that mean?</p>\n", "pids": ["58d82fced649053542fd7453"], "flag": 1}
{"question": "How can I get the DOI of a paper from its title?", "body": "<p>Is there a way to get the DOI (Document Object Identifier) of a research paper when its title is available?</p>\n\n<p>I am preparing a reference database I could not get the URL of all the references. So, I tried to search online but could not  get to anything. I will appreciate if anyone uses such tool/website or has any idea.</p>\n\n<p><strong>EDIT</strong>\nI am sorry but my problem is little bigger. I need to automatically (not manually) get them from the websites. Of course, I do not want to do it for more than 50 papers if that is legal/allowed.</p>\n", "pids": ["5f8a083edb0c4ff231649144"], "flag": 1}
{"question": "How are genetic behaviors expressed?", "body": "<p>There are some behaviors that are clearly genetic and not learned, such as insect dance patterns.</p>\n<p>How are such behaviors expressed in the organism?</p>\n<p>Do the genes specifically code for some neural circuitry that is always the same when it is present in the genome?</p>\n<p>So if the gene is absent, is that neural structure just absent?</p>\n<p>My understanding is that genes code for proteins. So how can a group of genes lead to such complex behaviors by just being expressed as some proteins?</p>\n", "pids": ["53e99d65b7602d970261e79c", "55a4dadb65ceb7cb02da1e55"], "flag": 1}
{"question": "Are there any agents that are based on quantum computing?", "body": "<p>Assuming the definition of an agent to be:</p>\n<blockquote>\n<p>An entity that perceives its environment, processes the perceived information, and acts on the environment such that some goal is fulfilled.</p>\n</blockquote>\n<p>Are there any agents that are based on quantum processing/computing (i.e. implemented by a network of <a href=\"https://en.wikipedia.org/wiki/Quantum_logic_gate\" rel=\"nofollow noreferrer\">quantum gates</a>)?</p>\n<p>Is there any work done towards this end? If so, could someone provide references?</p>\n", "pids": ["5e281da2df1a9c0c41e7137e", "5c69360fe1cd8e202b1eb31e"], "flag": 1}
{"question": "Which study proved that macaques were superior to humans in recalling in which some items appeared?", "body": "<p><strong>Which studies proved that macaques were superior to humans in recalling in which a sequence of items appeared?</strong></p>\n<p>I saw a video which reported on an experiment using computers, macaques and humans, I believe from the 80s or 90s:</p>\n<ul>\n<li>subjects (humans and macaques) played a video game and macaques performed vastly better than humans;</li>\n<li>the games consisted of two phases:\n<ol>\n<li>in the first phase, a sequence of items (numbers, I believe) appear on the screen in distinct positions, at regular interval;</li>\n<li>in the second phase, the items are masked, and the subject is asked to select the items in the order in which they appeared.</li>\n</ol>\n</li>\n<li>increasing the length of the sequence and reducing the time each item is shown quickly lost the human subjects, when the macaques subjects could play on instances which no humans answered correctly.</li>\n</ul>\n<p>I would be interested in designing a software to repeat such experiment using modern computing devices such as tablets and smart phones, with other species of animals other than humans, but could not find the reference of the original study, nor whether similar studies had been performed since.</p>\n", "pids": ["53e9acb5b7602d9703694f8f", "5d7e0fa247c8f76646dc50f7"], "flag": 1}
{"question": "How are training hyperparameters determined for large models?", "body": "<p>When training a relatively small DL model, which takes several hours to train, I typically start with some starting points from literature and then use a trial-and-error or grid-search approach to fine-tune the values of the hyper-parameters, in order to prevent overfitting and achieve sufficient performance.</p>\n<p>However, it is not uncommon for large models to have training time measured in days or weeks [<a href=\"https://discovery.ucl.ac.uk/id/eprint/10045895/1/agz_unformatted_nature.pdf\" rel=\"nofollow noreferrer\">1</a>], [<a href=\"https://arxiv.org/pdf/1812.04948.pdf\" rel=\"nofollow noreferrer\">2</a>], [<a href=\"https://arxiv.org/pdf/1301.3781.pdf\" rel=\"nofollow noreferrer\">3</a>].</p>\n<p>How are hyperparameters determined in such cases?</p>\n", "pids": ["5edf5ddc91e011bc656def5e"], "flag": 1}
{"question": "Is there a logical method of deducing an optimal batch size when training a Deep Q-learning agent with experience replay?", "body": "<p>I am training an RL agent using Deep-Q learning with experience replay. At each frame, I am currently sampling 32 random transitions from a queue which stores a maximum of 20000 and training as described in the Atari with Deep RL paper. All is working fine, but I was wondering whether there is any logical way to select the proper batch size for training, or if simply using a grid search is best. At the moment, I’m simply using 32, for its small enough that I can render the gameplay throughout training at a stunning rate of 0.5fps. However, I’m wondering how much of an effect batch size has, and if there is any criteria we could generalize across all Deep Q-learning tasks.</p>\n", "pids": ["5aed14d617c44a4438158ede"], "flag": 1}
{"question": "How to generate labels for self-supervised training?", "body": "<p>I've been reading a lot lately about self-supervised learning and I didn't understand very well how to generate the desired label for a given image.</p>\n<p>Let's say that I have an image classification task, and I have very little labeled data.</p>\n<p><em><strong>How can I generate the target label from the other data in the dataset?</strong></em></p>\n", "pids": ["5cede105da562983788e4af1"], "flag": 1}
{"question": "Can we use genetic algorithms to evolve datasets?", "body": "<p>Genetic algorithms are used to solve many optimization tasks.</p>\n<p>If I have a dataset, can I evolve it with a genetic algorithm to create an evolved version of the same dataset?</p>\n<p>We could consider each feature of the initial dataset as a chromosome (or individual), which is then combined with other chromosomes (features) to find more features. Is this possible? Has this been done?</p>\n<p>I will like to edit the details with an example so that it is easier to understand.</p>\n<p>Example: In practice cyber-security attacks evolve over time since it finds a new way to breach a system. The main draw-back of intrusion detection model is that it needs to be trained every time attack evolves. So I was hoping if genetic algorithm can be used on the present benchmarked datasets (like NSL-KDD) to come up with a futuristic type dataset maybe after X-number of generations.\nAnd check if a model is able to classify that generated dataset as well.</p>\n", "pids": ["5e5e191993d709897ce5038c"], "flag": 1}
{"question": "Difference between article and letter in Nature", "body": "<p>As I was reading today an article from Nature I was wondering: Does anybody know what's the difference between article and letter in the Nature Journal?</p>\n<p>The blog of Nature points out the following:</p>\n<blockquote>\n<p><strong>Articles</strong> are original reports whose conclusions represent a substantial advance in understanding of an important problem and have immediate, far-reaching implications.</p>\n<p><strong>Letters</strong> are short reports of original research focused on an outstanding finding whose importance means that it will be of interest to scientists in other fields.</p>\n</blockquote>\n<p>Source:\n<a href=\"http://blogs.nature.com/nautilus/2009/12/difference_between_nature_arti.html\" rel=\"noreferrer\">http://blogs.nature.com/nautilus/2009/12/difference_between_nature_arti.html</a></p>\n", "pids": ["61ca086c5244ab9dcb99070e"], "flag": 1}
{"question": "How do we find antibiotics?", "body": "<p>So the last class of antibiotics were made in 1984 (I think), which makes it appear as though they are hard to find(/design maybe). How is it then they were discovered? Was it by chance? I know some where accidents, but how are the majority found, testing lots of chemicals on your target?</p>\n\n<p>I imagine now we would have the capability to quickly identify structures and molecules unique to pathogens and be able to model them on a computer, and generate suitable proteins or other compounds that can interfere with their bonding/properties to damage the pathogen? </p>\n\n<p>For something like a 70s ribosome in a pathogen, what is the process of being able to understand its structure, its shape, etc? How much effort does it take to model onto a computer? Or instead a single protein (as a 70s ribosome will be more complex), how long does it take to model a new protein?</p>\n\n<p>Thanks for any help :) </p>\n", "pids": ["55a6ad8865ce054aad70c4c0", "5740715f0cf2ba3ec2a0b1e2", "5735f35e0cf2246f9d17c4f5"], "flag": 1}
{"question": "Comparing a large/general CNN to a smaller more specialized one?", "body": "<p>I am still somewhat a novice in the ML world, but I had a strange idea about CNNs and wanted to ask if this would be a valid way to check the robustness of a general CNN that classifies certain images.</p>\n<p>Let's say that I make a CNN that takes in many different images of sports players performing a certain action (basketball shot, football kick, freestyle in swimming, flip in gymnastics, etc). Firstly, would it be possible for such a CNN to distinguish between such varied images and classify them accurately? And if so, can it be a good idea to compare this &quot;larger&quot; CNN to multiple &quot;smaller&quot; more specialized ones that take in images from one particular sport?</p>\n<p>In other words, I want to know that if I have a &quot;larger&quot; CNN that gives me an output like &quot;football being kicked&quot;, is there a way to then double-check that output with a smaller CNN that only focuses on football moves? In essence, could we create a  system where once you obtain an output from a general CNN, it automatically classifies the same image through a more specialized CNN, and then if the results are of similar accuracy, you know for sure that CNN works?</p>\n<p>Kind of like having a smaller CNN as a &quot;ground-truth&quot; for the bigger one? In my head it kind of goes like this:</p>\n<pre><code>large_net_output = 'Football kick identified with 95.56% confidence' \n\nfor sport in large_net:\n    if sport == 'football':\n        access = small_net_for_football\n        return small_net_for_football_output\n\n    elif sport == 'swimming':\n        access = small_net_for_swimming\n        return small_net_for_swimming_output\n\n    elif sport == 'baseball':\n        access = small_net_for_baseball\n        return small_net_for_baseball_output\n\n# and so on....\n&gt;&gt;&gt; small_net_for_football_output = 'Football kick identified with 97.32% confidence'\n\nrobustness_check = large_net_output - small_net_for_football_output\nprint(robustness_check)\n\n&gt;&gt;&gt; 'Your system is accurate within a good range of 1.76%'\n     \n</code></pre>\n<p>I hope this makes sense, and that this question does not cause any of your to cringe. Would appreciate any feedback on this!</p>\n", "pids": ["5eede0b091e0116a23aafc15"], "flag": 1}
{"question": "Is there a complement to GPT/2/3 that can be trained using supervised learning methods?", "body": "<p>This is a bit of a soft question, not sure if it's on topic, please let me know how I can improve it if it doesn't meet the criteria for the site.</p>\n<p>GPT models are unsupervised in nature and are (from my understanding) given a prompt and then they either answer the question or continue the sentence/paragraph. They also seem to be the most advanced models for producing natural language, capable of giving outputs with correct syntax and (to my eye at least) indistinguishable from something written by a human (sometimes at least!).</p>\n<p>However if I have a problem where I have an input (could be anything, but lets call it an image or video) and a description of the image or video as the output I could in theory train a model with convolutional filters to identify the object and describe the image (assuming any test data is within the bounds of the training data). However when I've seen models like this in the past the language is either quite simple or 'feels' like it's been produced by a machine.</p>\n<p><strong>Is there a way to either train a GPT model as a supervised learning model</strong> with inputs (of some <strong>non language</strong> type) and outputs (of sentences/paragraphs); or a similar type of <strong>machine learning model that can be used for this task</strong>?</p>\n<p>A few notes:</p>\n<p>I have seen the deep learning image captioning methods - these are what I mention above. I'm more looking for something that can take an input-output pair where the output is text and the input is any form.</p>\n", "pids": ["6142b6175244ab9dcbc9807d"], "flag": 1}
{"question": "Can we apply transfer learning between any two different CNN architectures?", "body": "<p>There are many types of CNN architectures: LeNet, AlexNet, VGG, GoogLeNet, ResNet, etc. Can we apply transfer learning between any two different CNN architectures? For instance, can we apply transfer learning from AlexNet to GoogLeNet, etc.? Or even just from a &quot;conventional&quot; CNN to one of these other architectures, or the other way around? Is this possible in general?</p>\n<p>EDIT: My understanding is that <em>all</em> machine learning models have the ability to perform transfer learning. If this is true, then I guess the question is, as I said, whether we can transfer between two <em>different</em> CNN architectures – for instance, what was learned by a conventional CNN to a different CNN architecture.</p>\n", "pids": ["5cf48a26da56291d582873b5"], "flag": 1}
{"question": "Why aren&#39;t the BERT layers frozen during fine-tuning tasks?", "body": "<p>During transfer learning in computer vision, I've seen that the layers of the base model are frozen if the images aren't too different from the model on which the base model is trained on.</p>\n<p>However, on the NLP side, I see that the layers of the BERT model aren't ever frozen. What is the reason for this?</p>\n", "pids": ["6375a67190e50fcafd3e1d4a"], "flag": 1}
{"question": "Research paths/areas for improving the performance of CNNs when faced with limited data", "body": "<p>I've been reading through the research literature for image processing, computer vision, and convolutional neural networks. For image classification and object recognition, I know that convolutional neural networks deliver state-of-the-art performance when large amounts of data are available. Furthermore, I know that Hinton et al. created &quot;capsule networks&quot; to try and overcome some of the fundamental limitations of CNN architecture (such as them not being rotationally invariant). However, my understanding is that capsule networks have been a failure (so far), and most people expect them to go nowhere. And CNNs have progressively been improved in various ways (Bayesian optimisation for hyper parameter tuning, new convolution kernels, etc.). It seems to me that, at the moment, and for the foreseeable future, CNNs are the best architecture available for image-related stuff.</p>\n<p>But, as I said, CNNs, like other Deep Learning architectures, require large amounts of data. So my question is as follows:</p>\n<p>What are the research areas/topics for improving CNNs in the sense of making them work more effectively (that is, have greater performance) with less data (working with small datasets)?</p>\n<p>I know that there is various research looking at approaches to <em>increasing</em> data (such as data augmentation, generative networks, etc.), but I am primarily interested in fundamental modifications to CNNs themselves, rather than purely focusing on changes to the data itself.</p>\n<p>And to expand upon my question, using my above definition of &quot;performance&quot;, I am interested in these two categories:</p>\n<ol>\n<li><p>&quot;Computational methods&quot; for increasing CNN performance. This would be the non-mathematical stuff that I've read about, such as just increasing the number of layers and making the CNN deeper/wider (and I think another one had to do with just making the size of the convolution kernel smaller, so that it looks at smaller pieces of the image at any one time, or something like that?).</p>\n</li>\n<li><p>&quot;Mathematical methods&quot; for increasing CNN performance. This would be the cutting-edge mathematical/statistical stuff that I've read about: things like algorithms (such as Bayesian optimization); I've come across a lot of geometric stuff; and I guess the cutting-edge convolution kernels created by the image processing people would also fall under this category.</p>\n</li>\n</ol>\n<p>Obviously, this &quot;list&quot; is not exhaustive, and it's probably incorrect; I'm a novice to this research, so I'm trying to find my way around.</p>\n<p>I am interested in studying <em>both</em> of the above categories, but I will primarily be working from the mathematical/statistical side. And I want to work on research that is still <em>practical</em> and can be put to use in industry for improved performance (even if it might still be &quot;advanced&quot;/complex for most people in industry) – not the the highly theoretical stuff related.</p>\n<p>Related (but unanswered): <a href=\"https://ai.stackexchange.com/q/20521/16521\">Are there any good research papers on image identification with limited data?</a></p>\n", "pids": ["5ce2d244ced107d4c64bc0ab", "57a4e91dac44365e35c9844d", "58d82fc8d649053542fd5ae7", "573697846e3b12023e66ab35"], "flag": 1}
{"question": "What is the smallest difference in light wavelength that the human eye can detect?", "body": "<p>Is there a lower limit to the difference in wavelength (colour) our eyes can detect? If so, is this consistent between individuals? Are there any other traits correlated with precise colour vision?</p>\n", "pids": ["5537b5290cf2fe53f16a56c4", "5c0f71a8da562944ac642066", "55a65a1b65ce054aad650d97", "5537b5290cf2fe53f16a56c4", "5c0f81f6da562944ac892f33", "5c0f81f6da562944ac892f33"], "flag": 1}
{"question": "When should one prefer using Total Variational Divergence over KL divergence in RL", "body": "<p>In RL, both the KL divergence (DKL) and Total variational divergence (DTV) are used to measure the distance between two policies. I'm most familiar with using DKL as an early stopping metric during policy updates to ensure the new policy doesn't deviate much from the old policy.</p>\n<p>I've seen DTV mostly being used in papers giving approaches to safe RL when placing safety constraints on action distributions. Such as in <a href=\"https://arxiv.org/pdf/1705.10528\" rel=\"nofollow noreferrer\">Constrained Policy Optimization</a> and <a href=\"https://arxiv.org/pdf/1805.07708\" rel=\"nofollow noreferrer\">Lyapunov Approach to safe RL</a>.</p>\n<p>I've also seen that they are related by this formula:</p>\n<p><span class=\"math-container\">$$\nD_{TV} = \\sqrt{0.5 D_{KL}}\n$$</span></p>\n<p>When you compute the <span class=\"math-container\">$D_{KL}$</span> between two polices, what does that tell you about them, and how is it different from what a <span class=\"math-container\">$D_{TV}$</span> between the same two policies tells you?</p>\n<p>Based on that, are there any specific instances to prefer one over the other?</p>\n", "pids": ["53e9978db7602d9701f4d2d4"], "flag": 1}
{"question": "What exactly does meta-learning in reinforcement learning setting mean?", "body": "<p>We can use DDPG to train agents to stack objects. And stacking objects can be viewed as first grasping followed by pick and place. In this context, how does meta-reinforcement learning fit? Does it mean I can use grasp, pick and place as training tasks and generalize to assembling objects?</p>\n", "pids": ["5e96db3891e01129d1a03eed"], "flag": 1}
{"question": "ADHD Symptoms Emerging in Adolescence or Young Adulthood", "body": "<p>I recently read a fascinating article about the pattern of young women receiving ADHD diagnoses after first displaying symptoms in their late teens or early twenties, typically corresponding to college and post-college years. While very interesting, it was written from an informal, personal perspective. I'd like to know more about the subject from a research perspective. </p>\n\n<p>Has there been much research regarding gender differences in ADHD, specifically about different presentation and age of onset? Within this subject, has there been any research into the effects of estradiol levels on ADHD-like symptoms? I know that consensus is not very common in the research community, especially with a diagnosis as controvertial as ADHD, but I would still like to know whether late-onset in young women is at all commonly accepted. </p>\n", "pids": ["53e99df0b7602d97026b2c04", "53e9b97cb7602d970456e267", "53e9be80b7602d9704b43b30"], "flag": 0}
{"question": "Any comparison between transformer and RNN+Attention on the same dataset?", "body": "<p>I am wondering what is believed to be the reason for superiority of transformer?</p>\n<p>I see that some people believe because of the attention mechanism used, it’s able to capture much longer dependencies. However, as far as I know, you can use attention also with RNN  architectures as in the famous paper attention is introduced(<a href=\"https://arxiv.org/pdf/1409.0473\" rel=\"nofollow noreferrer\">here</a>)).</p>\n<p>I am wondering whether the only reason for the superiority of transformers is because they can be highly parallelized and trained on much more data?</p>\n<p>Is there any experiment comparing transformers and RNN+attention trained on the exact same amount of data comparing the two?</p>\n", "pids": ["5d9edc6847c8f7664603e607", "58437722ac44360f1082f61c", "599c7987601a182cd2648373"], "flag": 1}
{"question": "How prevalent are abusive advisors?", "body": "<p>I have read lots of posts here about abusive advisors, and I have heard about and even experienced some similar experiences in my own academic life.</p>\n<p>Is there any data available for how prevalent this problem is? I am interested in quantitative, objective data to the extent that it is possible to quantify these kinds of things.</p>\n<p>To clarify slightly, the kinds of things I would consider abusive could be:</p>\n<ol>\n<li><p>Verbal abuse where the advisor puts their students down in unnecessary and unproductive ways, like name-calling.</p>\n</li>\n<li><p>Not giving the student due credit for their work or somehow preventing them from making progress.</p>\n</li>\n<li><p>Discrimination based on race or sexuality. Similarly, discussing or trying to get involved in the student's personal life in an unhealthy way.</p>\n</li>\n<li><p>Any behavior that normally qualifies as abuse in other relationships and generally shows that the advisor is not interested in <em>advising</em> their students and helping them become a successful academic.</p>\n</li>\n</ol>\n<p>I am not really talking about absentee advisors or advisors who are just kind of blunt that don't display these qualities.</p>\n", "pids": ["53e99784b7602d9701f3e166"], "flag": 1}
{"question": "Is AGI likely to be developed in the next decade?", "body": "<p>AI experts like Ben Goertzel and Ray Kurzweil say that AGI   will be developed in the coming decade. Are they credible?</p>\n", "pids": ["53e99997b7602d97021d8b06"], "flag": 1}
{"question": "Are there deep neural networks that have inputs connected with deeper hidden layers?", "body": "<p>Are there any architectures of deep neural networks that connect input neurons not only with the first hidden layer but also with deeper ones (red lines on the picture)?</p>\n<p><a href=\"https://i.stack.imgur.com/DHjHh.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/DHjHh.png\" alt=\"image\" /></a></p>\n<p>If so could you give some names or links to research papers?</p>\n", "pids": ["573696026e3b12023e515eec"], "flag": 1}
{"question": "A theorem exists in a book but not in a journal - is this considered as a publication?", "body": "<p>When I was undergraduate I proved something which was non trivial (but I have to be honest, it was not something very important) in mathematics and i presented it to a professor at the university. He found it correct and he included the theorem in his new book (it <em>was</em> new - this happened in 2008) with my name along the theorem. Now you can find this theorem in another book published from Springer.  </p>\n\n<ol>\n<li>I was wondering if this is considered as one of my own publications.  </li>\n<li>If I submit it to a journal, should I mention the situation with the books?   </li>\n</ol>\n", "pids": ["55503f2e45ce0a409eb2ca78"], "flag": 1}
{"question": "Research in &quot;Research Engineering&quot;", "body": "<p>from <a href=\"http://en.wikipedia.org/wiki/Software_engineering\">Wikipedia</a>: </p>\n\n<blockquote>\n  <p><strong>Software engineering</strong> (SE) is the application of a systematic, disciplined,\n  quantifiable approach to the development, operation, and maintenance\n  of software, and the study of these approaches.</p>\n</blockquote>\n\n<p>I was wondering if there is something similar for research, something that we could call <strong>Research engineering</strong>. I imagine it to be a research field on its own, with students \"researching on how to do research\". I believe software development has benefited a lot from research in SE. Maybe research could also benefit from Research engineering. </p>\n\n<p>The questions are: </p>\n\n<ul>\n<li>is there some institute or some university department in the world where they work on Research Engineering?</li>\n<li>in which faculty you would position such department/institute?</li>\n</ul>\n\n<p><em>Edited</em>: After getting a couple of good answers, I am still not completely satisfied, so I would like to clarify my question. What I am really interested in is indeed a \"software engineering\" approach. I am not interested in philosophical or sociological research. In fact, the question I had originally in mind was whether it's possible or not to apply actual software development methodologies to research. In more concrete terms, I am wondering  whether anyone has studied the application in research of models similar to the waterfall, or the spiral model, or things like extreme programming, <a href=\"http://en.wikipedia.org/wiki/Scrum_%28development%29\">Scrum</a>, etc... (Note: these are just examples, please don't comment to each of them one by one). </p>\n", "pids": ["53e9bbc2b7602d970480e075", "53e9a611b7602d9702f4011c"], "flag": 1}
{"question": "How to search for list of papers citing both papers A and B?", "body": "<p>For given papers A and B, I would like to search for all papers that cite both A and B. I guess one can generalize to papers {A,B,C,...} and find all papers that cite all of them. </p>\n\n<p>A quick Google Scholar and Web of Science search revealed nothing. Google Scholar has a \"cite=...\" thing in the URL, which I messed with a bit to no avail.</p>\n", "pids": ["599c7988601a182cd2648f8c"], "flag": 1}
{"question": "Is there documentation on how long it takes before publications are indexed by Scopus and Web of Science?", "body": "<p>The two major bibliographic databases - Scopus and Web of Science\\Web of Knowledge - have one very badly-documented limitation; their update lag. While the majority of papers are added quickly, it can take several months for individual papers to be added.</p>\n\n<p>As an example, I ran a search in Web of Science looking for all papers published by my institute in 2014. In November 2015, it reported 290 papers. In January 2016, 293. In February, 305.</p>\n\n<p>In other words, a few percent of the papers took <strong>a year or more</strong> to be added to the database, which startled me - I was expecting a lag of perhaps three months. Some of these delayed entries are from relatively obscure journals (specialist Australian publications) or book series, and it seems reasonable that these might take longer, but most are from mainstream titles - one is even from <em>Philosophical Transactions of the Royal Society</em>, as established a journal as it's possible to get.</p>\n\n<p>Scopus is comparable. In November 2015, it reported 340 2014 papers, 356 2013 ones and 351 2012. Running an identical search three months on brings us to 341, 367 (!), and 353 respectively - so a few papers are still being added up to three years after publication. (Unfortunately, Scopus doesn't expose the date items added to the database, so it's not possible to identify which ones were added most recently - it's possible that some were due to journals being added to Scopus for the first time along with their back-issues.)</p>\n\n<p>This is, of course, something of a headache for producing stats. But more practically, it could be a real problem for disseminating science - something being unintentionally missed or delayed from one of the big indexing services can make it much less discoverable and much less likely to be read, built upon, or cited, especially in that important first year.</p>\n\n<p>So, the core question: does anyone know of documentation (or research) into <strong>how substantial</strong> these delays are; how they're <strong>distributed</strong>; and whether they're getting <strong>better or worse</strong>?</p>\n\n<p>(I've spent some hours searching for this but to no avail. I'm wondering if I may just be looking in all the wrong places.)</p>\n", "pids": ["5736972b6e3b12023e61cc07"], "flag": 1}
{"question": "How can we derive a Convolution Neural Network from a more generic Graph Neural Network?", "body": "<p>Convolution Neural Network (CNNs) operate over strict grid-like structures (<span class=\"math-container\">$M \\times N \\times C$</span> images), whereas Graph Neural Networks (GNNs) can operate over all-flexible graphs, with an undefined number of neighbors and edges.</p>\n<p>On the face of it, GNNs appear to be neural architectures that can subsume CNNs. Are GNNs really generalized architectures that can operate arbitrary functions over arbitrary graph structures?</p>\n<p>An obvious follow-up - <strong>How can we derive a CNN out of a GNN</strong>?</p>\n<p>Since non-spectral GNNs are based on message-passing that employ <em>permutation-invariant</em> functions, is it possible to derive a CNN from a base-architecture of GNN?</p>\n", "pids": ["58437722ac44360f1082efeb", "57a4e91aac44365e35c97c6e"], "flag": 1}
{"question": "Are there some notions of distance between two policies?", "body": "<p>I want to determine some distance between two policies <span class=\"math-container\">$\\pi_1 (a \\mid s)$</span> and <span class=\"math-container\">$\\pi_2 (a \\mid s)$</span>, i.e. something like <span class=\"math-container\">$\\vert \\vert \\pi_1 (a \\mid s) - \\pi_2(a \\mid s) \\vert \\vert$</span>, where <span class=\"math-container\">$\\pi_i (a\\mid s)$</span> is the vector <span class=\"math-container\">$(\\pi_i (a_1 \\mid s), \\dots, \\pi_i(a_n \\mid s))$</span>. I am looking for a sensible notion for such a distance.</p>\n<p>Are there some standard norms/metrics used in the literature for determining a distance between policies?</p>\n", "pids": ["59ae3bf12bbe271c4c71bc64", "599c7b58601a182cd272b540", "53e9978db7602d9701f4d2d4"], "flag": 1}
{"question": "Is learning and memory formation mostly comprised of new synapses forming, or already-existent synapses strengthening?", "body": "<p>I'm guessing it may be some combination of the two. If so, which is the more frequent situation?</p>\n\n<p>I'm also guessing it varies depending on the type of memory being formed. Let's take for instance, my memory of opening up this tab and clicking the \"Ask Question\" button about 30 seconds ago. Surely this can't just be a case of strengthening former synaptic connections, right? It's a completely new and specific memory. So would it be a case of (for the most part) many new synapses being formed to somehow encode this memory? It seems hard to believe that there could be so many new synapses being created constantly in order to encode so many memories. It must happen lightning-fast, no?</p>\n", "pids": ["55a4971465ceb7cb02d307b7"], "flag": 0}
{"question": "Why do theoretical computer science people use Comic Sans in their slides?", "body": "<p>I have no data to back up this observation, but it's something I have noticed consistently in research talks and teaching material: People from the theoretical CS community seem to use Comic Sans a lot, a font-face that emulates the look and feel of hand-drawn fonts in comic books. Is this merely a convention or is there a deeper reason behind it?</p>\n\n<p>EDIT1: Since a couple of users requested examples, here's what I came up with in a 5-minute search:</p>\n\n<ul>\n<li><a href=\"http://qav.cs.ox.ac.uk/talks/marta-qapl05.pdf\" rel=\"noreferrer\">Probabilistic model checking in practice</a></li>\n<li><a href=\"https://www.mathematik.uni-marburg.de/~gumm/Lehre/SS07/ModelChecking/08_Symbolisches_Model_Checking.pdf\" rel=\"noreferrer\">Symbolisches model checking</a></li>\n<li><a href=\"http://grammars.grlmc.com/LATA2016/Slides/d1s301DanaNBW_Hierarchy.pdf\" rel=\"noreferrer\">A complexity measure on Büchi automata</a></li>\n<li><a href=\"https://www.cs.colorado.edu/~bec/courses/csci5535-s09/slides/lecture01.6up.pdf\" rel=\"noreferrer\">Fundamentals of programming languages</a></li>\n<li><a href=\"http://www.cs.toronto.edu/~sme/CSC444F/slides/L17-FormalModeling.pdf\" rel=\"noreferrer\">Formal modeling methods</a></li>\n</ul>\n\n<p>EDIT2: The point of this question is not to collect opinions, but to find out reasons why TCS people use Comic  Sans (and the answers so far already did an excellent job in this matter).</p>\n", "pids": ["5dde4b463a55ac4c42972b22"], "flag": 1}
{"question": "Which software is used to write scientific textbooks, especially in engineering?", "body": "<p>Which software do learned professionals use - LaTeX or Google Docs or Word or any other software to write their books (especially engineering level scientific textbooks)?</p>\n<p>Points to consider:</p>\n<ul>\n<li>Could have diagrams, images, tables, graphs at quarter or half or complete page or in-between the text</li>\n<li>Divided into chapters, should it be a different doc for each chapter in a Word/G.Doc like software?</li>\n<li>Citation management should be easy</li>\n</ul>\n", "pids": ["55a6abde65ce054aad7041fe"], "flag": 1}
{"question": "What is asymmetric relaxation backpropagation?", "body": "<p>In <a href=\"http://page.mi.fu-berlin.de/rojas/neural/chapter/K8.pdf\" rel=\"nofollow noreferrer\">Chapter 8</a>, section 8.5.2, Raul Rojas describes how the weights for a layer of a neural network can be calculated using a pseudoinverse of the sigmoid function in the nodes, he explains this is an example of symmetric relaxation.</p>\n<p>But the chapter doesn't explain what asymmetric relaxation would be or how it is done.</p>\n<p>So, what is asymmetric relaxation and how would it be done in a simple neural network using a sigmoid function in its nodes?</p>\n", "pids": ["5ce2d1aeced107d4c6455771", "53e99c8cb7602d970253fb8b"], "flag": 1}
{"question": "How do I select the (number of) negative cases, if I&#39;m given a set of positive cases?", "body": "<p>We were given a list of labeled data (around 100) of known positive cases, i.e. people that have a certain disease, i.e. all these people are labeled with the same class (disease). We also have a much larger amount of data that we can label as negative cases (all patients that are not on the known positive patient's list).</p>\n<p>I know who the positives are, but how do I select negative cases to create a labeled dataset of both positives and negatives, on which to first train a neural network, and then test it?</p>\n<p>This is a common problem in the medical field, where doctors have lists of patients that are positive, but, in our case, we were not given a specific list of negative cases.</p>\n<p>I argued for picking a number that represents the true prevalence of the disease (around 1-2%). However, I was told that this isn't necessary and to do a 50:50 split of positives to negatives. It seems that doing it this way will not generalize outside our test and train datasets.</p>\n<p>What would you do in this case?</p>\n", "pids": ["6124dd7091e0114cbe7a8c1c"], "flag": 1}
{"question": "When is Mindfulness Based Cognitive Therapy not useful, or bad?", "body": "<p>I'm writing my Bachelor on MBCT, and while there are a ton of studies on the positive effects of mindfulness and MBCT, I'm wondering if there are any cases where MBCT shouldn't be applied. I've found some litterature on certain possible negative effects of mediation, but nothing on MBCT specifically.  </p>\n\n<p>So, do anyone know of studies or research papers that mentions cases where MBCT is not useful or should be avoided?</p>\n", "pids": ["56d82521dabfae2eeed77f4a"], "flag": 0}
{"question": "Does DQN generalise to unseen states in the case of discrete state-spaces?", "body": "<p>In my understanding, DQN is useful because it utilises a neural network as a q-value function approximator, which, after the training, can generalise to unseen states.</p>\n<p>I understand how that would work when the input is a vector of continuous values, however, I don't understand why DQN would be used with discrete state-spaces. If the input to the neural network is just an integer with no clear structure, how is this supposed to generalise?</p>\n<p>If, instead of feeding to the network just an integer, we fed a vector of integers, in which each element represents a characteristic of the state (separating things like speed, position, etc.) instead of collapsing everything in a single integer, would that generalise better?</p>\n", "pids": ["5cf48a46da56291d582aa4b4"], "flag": 1}
{"question": "Can a convolutional network predict states for a RL Agent", "body": "<p>During the course of training a DQN agent, all visited states are stored in a replay buffer. Therefore would it be practically possible for a CNN, given a reasonable amount of data, to predict the next RL state (in the form of an image) for a given action?</p>\n<p>For example, take the game of Atari as shown below -\n<a href=\"https://i.stack.imgur.com/lciZa.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/lciZa.png\" alt=\"enter image description here\" /></a>\nHere the agent can take 2 major actions - go left and go right. Would a CNN be generate the image of the bar going right/left for the respective actions?\nMy practical knowledge of CNNs is quite limited and therefore I'm trying to gauge the abilities of CNNs before I take up a project.</p>\n", "pids": ["5db9296f47c8f766461f6404"], "flag": 1}
{"question": "How UCT in MCTS selection phase avoids starvation?", "body": "<p>The first step of MCTS is to keep choosing nodes based on Upper Confidence Bound applied to trees (UCT) until it reaches a leaf node where UCT is defined as</p>\n<p><span class=\"math-container\">$$\\frac{w_i}{n_i}+c\\sqrt{\\frac{ln(t)}{n_i}},$$</span></p>\n<p>where</p>\n<ul>\n<li><span class=\"math-container\">$w_i$</span>= number of wins after i-th move</li>\n<li><span class=\"math-container\">$n_i$</span> = number of simulations after the i-th move</li>\n<li><span class=\"math-container\">$c$</span> = exploration parameter (theoretically equal to <span class=\"math-container\">$\\sqrt{2}$</span>)</li>\n<li><span class=\"math-container\">$t$</span> = total number of simulations for the parent node</li>\n</ul>\n<p>I don't really understand how this equation avoids sibling nodes being starved, aka not explored. Because, let's say you have 3 nodes, and 1 we'll call it node A is chosen randomly to be explored, and just so happens to simulate a win. So, node A's UCT<span class=\"math-container\">$=1+\\sqrt(2)\\sqrt{\\frac{ln(1)}{1}}$</span>, while the other 2 nodes UCT = 0, because they are unexplored and the game just started, so by UCT the other 2 nodes will never be explored no? Because after this it'll go into the expansion phase and expansion only happens it reaches a leaf node in the graph. So because node A is the only one with a UCT <span class=\"math-container\">$&gt; 0$</span> it'll choose a child of node A and it will keep going down that node cause all the siblings of node A have a UCT of 0 so they never get explored.</p>\n", "pids": ["53e9a210b7602d9702b15434"], "flag": 1}
{"question": "What physical evidence exists that shows motor proteins &quot;walking&quot; within a cell?", "body": "<p>Various animations on the internet show the motor protein kinesin walking within a cell. Is this an approximation? How does this happen and (based upon what physical evidence) how do we know it \"walks\" like this?</p>\n\n<p><a href=\"https://www.youtube.com/watch?v=y-uuk4Pr2i8\">https://www.youtube.com/watch?v=y-uuk4Pr2i8</a> </p>\n\n<p><a href=\"https://imgur.com/gallery/WOTJdLp\">http://imgur.com/gallery/WOTJdLp</a> </p>\n\n<p><a href=\"https://www.youtube.com/watch?v=tMKlPDBRJ1E\">https://www.youtube.com/watch?v=tMKlPDBRJ1E</a></p>\n", "pids": ["53e9a401b7602d9702d1c55d", "53e9b7e7b7602d970439791b", "53e99de2b7602d97026a4e7f"], "flag": 1}
{"question": "When should you publish code on GitHub? Work-in-progress or after publication?", "body": "<p>What is policy are you following about publishing data analysis code on GitHub? Do you do it after publishing or as a work-in-progress?</p>\n\n<p>I developed a number of Python algorithms to analyse a large dataset, and I would like to make my work visible. </p>\n", "pids": ["55a3d45865ce5cd7b3b92921"], "flag": 1}
{"question": "How would one disambiguate between two meanings of the same word in a sentence?", "body": "<blockquote>\n<p>The boy lifted the bat and hit the ball.</p>\n</blockquote>\n<p>In the above sentence, the noun &quot;bat&quot; means the wooden stick. It does not mean bat, the flying mammal, which is also a noun. Using NLP libraries to find the noun version of the definition would still be ambiguous.</p>\n<p>How would one go about writing an algorithm that gets the exact definition, given a word, and the sentence it is used in?</p>\n<p>I was thinking you could use word2vec, then use autoextend <a href=\"https://arxiv.org/pdf/1507.01127.pdf\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/1507.01127.pdf</a> to differentiate between 2 different lexemes e.g. bat (animal) and bat (wooden stick).</p>\n<p>Then the closest cosine distance between the dictionary definition and any of the words of the sentence might indicate the correct definition.</p>\n<p>Does this sound correct?</p>\n", "pids": ["5bdc31b417c44a1f58a0b8c2"], "flag": 1}
{"question": "How to deal with the time delay in reinforcement learning?", "body": "<p>I have a question regarding the time delay in reinforcement learning (RL).</p>\n<p>In the RL, one has state, reward and action. It is usually assumed that (as far as I understand it) when the action is executed on the system, the state changes immediately and that the new state can then be analysed (influencing the reward) to determine the next action. However, what if there is a time delay in this process. For example, when some action is executed at time <span class=\"math-container\">$t_1$</span>, we can only get its effect on the system at <span class=\"math-container\">$t_2$</span> (You can imagine a flow: the actuator is in the upstream region and the sensor is in the downstream region, so that there will be a time delay between the action and the state). How do we deal with this time delay in RL?</p>\n", "pids": ["61389d455244ab9dcb9bfa1f", "600833a59e795ed227f531a7", "5e5e18ae93d709897ce26fdd", "5de799f19e795e775806935d", "5c900a1a4895d9cbc67153ae"], "flag": 1}
{"question": "How to treat (label and process) edge case inputs in machine learning?", "body": "<p>In every computer vision project, I struggle with labeling guidelines for border cases. Benchmark datasets don't have this problem, because they are 'cleaned', but in real life unsure cases often constitute the majority of data.</p>\n<p>Is 15% of a cat's tail a cat? Is a very blurred image of a cat still a cat? Are 4 legs of a horse, but the rest of its body of the frame still a horse?</p>\n<p>Would it be easier or harder to learn a regression problem instead of classification? I.e by taking 5 subclasses of class confidence (0.2,0.4,0.6,0.8,1.) and using them as soft targets?</p>\n<p>Or is it better to just drop every unsure case from training or/and testing set?</p>\n<p>I experimented a lot with different options, but weren't able to get any definitive conclusion. This problem is so common that I wonder if it has already been solved for good by someone?</p>\n", "pids": ["599c7959601a182cd2633259", "59ae3bf12bbe271c4c71bf2d"], "flag": 1}
{"question": "Is there any difference between ConvNet and CNN?", "body": "<p>ConvNet stands for Convolutional Networks and CNN stands for Convolutional Neural Networks.</p>\n<p>Is there any difference between both?</p>\n<p>If yes, then what is it?</p>\n<p>If no, is there any reason behind using ConvNet at some places and CNN at some other places in literature?</p>\n", "pids": ["5d04e8d7da56295d08daee44"], "flag": 1}
{"question": "How to construct Transformers to predict multidimensional time series?", "body": "<p>There is plenty of information describing Transformers in a lot of detail how to use them for NLP tasks. Transformers can be applied for time series forecasting.  See for example <a href=\"https://papers.nips.cc/paper/2020/file/c6b8c8d762da15fa8dbbdfb6baf9e260-Paper.pdf\" rel=\"nofollow noreferrer\">&quot;Adversarial Sparse Transformer for Time Series Forecasting&quot;</a> by Wu et al.</p>\n<p>For understanding it is best to replicate everything according to already existing examples. There is a very nice example for LSTM with flights dataset <a href=\"https://stackabuse.com/time-series-prediction-using-lstm-with-pytorch-in-python/\" rel=\"nofollow noreferrer\">https://stackabuse.com/time-series-prediction-using-lstm-with-pytorch-in-python/</a>.</p>\n<p>I guess I would like to know how to implement transformers for at first univariate (flight dataset) and later for multivariate time series data. What should be removed from the Transformer architecture to form a model that would predict time series?</p>\n", "pids": ["5fd8acf991e0119b22c1f38d"], "flag": 1}
{"question": "Have psychologists recognized how some people feel more embarrassment?", "body": "<p>Is there a personality subtype where it’s really common to feel embarrassed about one's past self, like cringing about something you said, wrote, or did some time ago?  It may change over time, but I think some people just naturally have this inclination, like a propensity towards social anxiety.</p>\n<p>Is this a known phenomenon?</p>\n", "pids": ["5c0f830fda562944ac8b8183", "53e9a4ebb7602d9702e0908b", "53e99a1ab7602d97022703df", "5ce2d0fdced107d4c63dca9b", "53e99a4eb7602d97022b04ac"], "flag": 1}
{"question": "Winnicott and Ogden : Fear of breakdown and &#39;reliving&#39;", "body": "<p>I've been reading some text from Winnicott and Ogden about &quot;The Fear of Breakdown&quot; and the unlived life.</p>\n<p>Ogden, T. H. (2016) wrote this about Winnicott's previous work in <em>Reclaiming unlived life: experiences in psychoanalysis</em>;</p>\n<blockquote>\n<p>So, the past event that occurred, but was not experienced, continues to\ntorment the patient until it is lived in the present (with the mother/analyst).\nAnd yet, despite the beauty of Winnicott’s response to the question he poses, I find his answer incomplete. It seems to me that <em>a principal, if not the principal motivation for an individual who has not experienced important parts of what happened in his early life is the urgent need to lay claim to those lost parts of himself, to finally complete himself by encompassing within him-self as much of his unlived (unexperienced) life as he is able</em>. I read this as a universal need – the need on the part of every person to re-claim, or claim\nfor the first time, what he has lost of himself and, in so doing, take the\nopportunity to become the person he still holds the potential to be. One\ndoes so despite the fact that attempting to realize that potential to become more fully oneself involves experiencing the pain (of breakdown and the primitive agony that results from breakdown), which had been too much to bear in infancy and childhood and has led to the loss of important aspects of self</p>\n</blockquote>\n<p>My question is, does this mean the person actually unconciously wants to repeat the feeling they had during the childhood trauma?</p>\n", "pids": ["53e9aab7b7602d9703436591"], "flag": 1}
{"question": "Can a person be persuaded to become gay?", "body": "<p>Can a person become gay? Can a person be persuaded to become one? I heard that gayness is <a href=\"https://doi.org/10.1126/science.8332896\" rel=\"nofollow noreferrer\">correlated</a> with some genetic characteristics so, I figured, laws against &quot;gay propaganda&quot; (e.g. in Russia) are anti-science, aren't they (in addition to being discriminatory)?</p>\n<h2 id=\"references-h233\">References</h2>\n<p>Hamer, D. H., Hu, S., Magnuson, V. L., Hu, N., &amp; Pattatucci, A. M. (1993). A linkage between DNA markers on the X chromosome and male sexual orientation. <em>Science, 261</em>(5119), 321-327. <a href=\"https://doi.org/10.1126/science.8332896\" rel=\"nofollow noreferrer\">https://doi.org/10.1126/science.8332896</a></p>\n", "pids": ["53e99f7fb7602d97028558c8", "55a36972612ca648686bf8e6", "605f0cfee4510cd7c84c4e88", "5db929ad47c8f766461fa360", "605f0cfee4510cd7c84c4d79", "53e9b8c0b7602d970449c1a9"], "flag": 0}
{"question": "What does the death of a fictional character mean?", "body": "<blockquote>\n  <p>Aristotle approached the question of story and meaning in this way: Why is it, he asked, when we see a dead body in the street we have one reaction, but when we read of death in Homer, or see it in the theatre, we have another? ~ Robert McKee, <em>Story</em></p>\n</blockquote>\n\n<p>When a fictional character is killed, no one dies – and the readers and viewers know this, no matter how much they identify with the story. So what does this narrative device actually mean? Aristotle thought that the death of a character evokes emotions in the viewers that then allow the author to convince them of his narrative argument. He calls this \"<a href=\"https://en.wikipedia.org/wiki/Pathos\" rel=\"nofollow\">pathos</a>\". Following Aristoteles, the death of a character \"means\" that the audience becomes more susceptible to what the author wants them to believe (the moral of the story). But that is the author's perspective on what he can do with the death of a character, and does not explain how the audience experience and understand it.</p>\n\n<p>To answer this question, we may have to first understand how the audience perceives the character.</p>\n\n<blockquote>\n  <p>A character is no more a human being than the Venus of Milo is a real woman. A character is ... a metaphor for human nature. ~ Robert McKee, <em>Story</em></p>\n</blockquote>\n\n<p>A character is a symbol that stands in for something that affects the reader or viewer: their deams and aspirations; or their fears. And thus the death of a symbol may symbolize that a dream will remain unfulfilled or a fear is overcome. Death in the media, I believe, is not final but transformative, and not real but symbolic, and this becomes most apparent in the journey to the underworld (read \"death\") of many mystical heroes. But that is only my opinion.</p>\n\n<p>Is there research that tries to answer this question from the perspective of psychology?</p>\n\n<p>Or, in the absence of such research, how would <em>you</em> study it?</p>\n\n\n\n<p>In his comment, Steven Jeuris remarks, that a fictional character's death means that he dies in the fictional world. Let me elaborate on that.</p>\n\n<p>Readers of fiction don't read like news readers. A newspaper reader reads to learn what has happened in the world he lives in, and (maybe) to understand why. Because these events (and their reasons) affect his own life and the decisions he has to make.</p>\n\n<p>Readers of fiction, on the other hand, do not read to be informed. They read to experience emotions, to escape their own lives, to be inspired, and so on. The facts of the fictional world are irrelevant to their own lives, but the emotions they elicit, the ideas they generate, and the time spent away from the demands of their own lives are important to them.</p>\n\n<p>If a neighbor, politician or artist dies in the real world, and I read about it, this affects my own life. My life has been changed (because a person is missing from it) or it will be changed (because politics will change). If a fictional character dies, nothing changes in my life.</p>\n\n<p>What is changed, is the <em>story</em>.</p>\n\n<p>And story logic is not like the chains of cause and effect (or chance) that govern the events in real life. In the real world, many (if not most) people die through forces that lie outside of their influence. They die of old age or are run over by drunk drivers. In the fictional world, everything happens by design, and that design is based on the story's premise and the characters actions. In a fictional world, no one dies by chance, and even old age has a meaning.</p>\n\n<p>Very simplified, in a (classic type of) story a character achieves his goals, if he overcomes his deficits. If he refuses to grow, he fails. Death is the reward for moral failure. Think of the hero killing his antagonist or the first two knights being eaten by the dragon: these characters don't just die and then they are dead, but their death means that their way of life was wrong.</p>\n\n<p>But of course stories are usually more complicated than that today. Characters aren't simply good or bad, they are \"realistic\", like real people. And the world they inhabit isn't as simply structured as that of a fairy tale, it is \"realistic\", like the real world. In Game of Thrones, characters die apparently like in the real world: despite being the good guys.</p>\n\n<p>But still, it is not the real world. If the good guy dies in Game of Thrones, it is <strong>not</strong> because Game of Thrones is realistic and characters in its world die just like people in real life, but because it is not what we are used to from narrative conventions and it surprises us. The death of the good guy in Game of Thrones means that we cannot trust what we have learned about how stories work. It does not mean that someone died. It is sad and frustrating, because we wanted Ned Stark to succeed, but at the same time it is thrilling and satisfying, because it is novel.</p>\n\n<p>These are just examples, and there will be disagreement over the <em>interpretation</em> of these stories, but I hope they serve to illustrate that the death of a fictional character does <strong>not</strong> mean (<strong>to the reader !</strong>) that this \"person\" has died in the fictional world. It means something different or on top of that to the reader (who knows, which is important, that no one has died !).</p>\n\n<p>Of course, every death in fiction might be interpreted differently – depending on the specific story. But I think that it must be possible to generalize and find an underlying similarity or several \"types of fictional deaths\".</p>\n\n<p>Finally, I think that this question does not belong on another site, because the study of the psychology of reading books or viewing movies (that is, the psychology of the audience) is the task of the psychologist just like advertising psychology (which also deals with how stories work on their audience).</p>\n\n<p>So if you want, think of my question of belonging in advertising psychology: Does the clean shirt the housewife pulls from the washing mashine mean that the shirt has been cleaned? No. It means that the washing powder is better than other washing powders (or, if you are a cynic, that that is what the advertiser wants us to believe). The meaning of the clean shirt depends on the intent of the narrator and the circumstances of the narration (in an ad).</p>\n\n<p>Similarly, the meaning of a fictional death will depend on the (reader perceived) intent of the narrator (who, by the way, is not the author) and the circumstances of the narration (a book, a tv show). But I don't want to do a (subjective) literary interpretation (like I did here), but learn how this has been studied or, if no such studies have been undertaken, study it with psychological methodology.</p>\n\n<p>Hope this now makes a bit more sense.</p>\n", "pids": ["53e9b70fb7602d97042a9bea"], "flag": 0}
{"question": "Are Pareto charts identified in the cognitive sciences (and for willpower in particular)?", "body": "<p>I'm a layman when it comes to the cognitive sciences. I've read some number of popular self-help books, but not any academic journals. I've noticed that many times a book suggests some techniques for willpower, anxiety management etc., but will never list them out in a prioritized fashion. </p>\n\n<p>While there might be some variation based on the circumstances and the individuals involved, I feel like a one or a few techniques should always dominate the list. The effectiveness of techniques that deal with different cognitive issues is most likely somwhat geometrically distributed (all else being equal), i.e., most of the time they obey the power law (most techniques are moderately effective, but a few are <em>really</em> effective).  </p>\n\n<p>In particular I'm currently interested in effective techniques for willpower. I'm aware of which techniques are recommended (split a task into subtasks, positive self-talk and many more), but what are their relative effectiveness? Are there some well-executed studies out there that determined which techniques work comparatively better?</p>\n\n<p><strong>What are effective and generalizable self-regulatory skills and strategies?</strong></p>\n\n<p><strong>How do their relative efficacy compare?</strong></p>\n", "pids": ["55a6480765ce054aad62c35d", "55a4a7af65ceb7cb02d55c30", "53e9bbd4b7602d9704823c6a", "55a6903365ce054aad6be592"], "flag": 0}
{"question": "Tests of Semantic Memory suitable for 10 to 18 year old", "body": "<p>I'm trying to find a test of semantic memory for students.</p>\n\n<p>We're working on a programme to explore the impacts of exposure to nature on a student's academic abilities (hoping to pique teachers interest by showing the interconnection).</p>\n\n<p>The starting point for this was <a href=\"http://pss.sagepub.com/content/19/12/1207.abstract\" rel=\"nofollow\">this paper</a> in which students that are taken for a walk in the park experience a boost in working memory. The test used there was a reverse digit sequence recall.</p>\n\n<p>I'm looking to use a different test that is more closely related to semantic memory, and if possible, is a little less dull (I know ideally this would not be a factor, but I suspect some will think the digit sequence test too simplistic and dismiss the results as not representative of aptitude on more complex challenges of school subjects).</p>\n\n<p>My understanding of the different types of memory is that semantic is the one that makes up a big component of what is tested on traditional academic standard tests, so this would be a more relevant fit to showing the relationship between nature and the cognitive abilities commonly valued and assessed.</p>\n\n<p>In looking for tests, I found the NIH toolbox, but it only has tests on episodic and working memory.\nI've also looked here on StackExchange, but again, can't find answers specific to semantic memory.</p>\n\n<p>Where might I look for an appropriate tool for semantic memory?\nIf the test is one that can be administered to the same student more than once, that would be helpful too (to show comparative difference in memory after exposure to different environments)\n(and if you have suggestions of other cognitive skills that we should be examining, I'm open to it)</p>\n", "pids": ["554eaf930cf2a9adcfd94360", "53e9b29cb7602d9703d43482"], "flag": 0}
{"question": "Are there models of single neurons on slow timescales?", "body": "<p>From what I've come across on the web, most models of single neurons seem to focus on the \"fast timescale\", where electrical signals are transmitted from one neuron to another. However, neurons are also cells, with all the associated complexity that cells bring: from gene expression to biochemical reactions happening in response to these electrical signals, albeit on a slower timescale. Are there any single neuron models that attempt to integrate these various timescales?</p>\n\n<p>I'm mainly interested in knowing about more realistic abstractions of neurons than those used in Artificial Neural Networks (ANNs) and so on. A key assumption I'm making is that neurons, being a type of cell, would have biochemical processes going on on a slower timescale that would modulate their 'spiking' behavior over time. Please correct me if this assumption is wrong.</p>\n", "pids": ["53e9bd4bb7602d97049dce03"], "flag": 0}
{"question": "Is aphantasia an inability to record memories, or an inability to recall memories?", "body": "<p>People with aphantasia are unable to <em>voluntarily</em> create or recall mental images.<br />\nThis can extend to non-visual memory too (e.g. remembering <em>that</em> they heard a loud bang, but not remembering the sound of the loud bang itself).</p>\n<p>Everything I've read talks about the overall symptoms, but not about the underlying mechanism.</p>\n<p>Does the mind correctly record memories (which can't be recreated), or does it fail to record sensory memories in the first place?\nI.e. is the memory failure in the recording or in the recalling?</p>\n", "pids": ["613742455244ab9dcb0ad199", "618116075244ab9dcbee8144", "5f6417da9fced0a24bdcb4d4", "5ef328289fced0a24be66c99", "5ecce9ad9fced0a24bdbc056"], "flag": 1}
{"question": "Is there a relationship between Computer Algebra and NLP?", "body": "<p>My intuition is that there is some overlap between understanding language and symbolic mathematics (e.g. algebra). The rules of algebra are somewhat like grammar, and the step-by-step arguments get you something like a narrative. If one buys this premise, it might be worth training an AI to do algebra (solve for x, derive this equation, etc).</p>\n<p>Moreover, when variables represent &quot;real&quot; numbers (as seen in physics, for example) algebraic equations describe the real world in an abstracted, &quot;linear,&quot; way somewhat similar to natural language.</p>\n<p>Finally, there are exercises in algebra, like simplifying, deriving useful equations, etcetera which edge into the realm of the subjective, yet it is still much more structured and consistent than language. It seems like this could be a stepping stone towards the ambiguities of natural language.</p>\n<p>Can anyone speak to whether this has either (1) been explored or (2) is a totally bogus idea?</p>\n", "pids": ["5c04967517c44a2c74708ad2"], "flag": 1}
{"question": "Is there a common way to build a neural network that seeks to extract spatial and temporal information simultaneously?", "body": "<p>Is there a common way to build a neural network that seeks to extract spatial and temporal information simultaneously? Is there an agreed up protocol on how to extract this information?</p>\n<p>What combination of layers works: convolution + LSTM? What would be the alternatives?</p>\n", "pids": ["5ef3247a91e0110c353da9a6"], "flag": 1}
{"question": "Why class embedding token is added to the Visual Transformer?", "body": "<p>In the <a href=\"https://arxiv.org/abs/2010.11929\" rel=\"nofollow noreferrer\">famous work on the Visual Transformers</a>, the image is split into patches of a certain size (say 16x16), and these patches are treated as tokens in the NLP tasks. In order to perform classification, a <strong>CLS</strong> token is added at the beginning of the resulting sequence:\n<span class=\"math-container\">$$\n[\\textbf{x}_{class}, \\textbf{x}_{p}^{1}, \\ldots, \\textbf{x}_{p}^{N}]\n,$$</span>\nwhere <span class=\"math-container\">$ \\textbf{x}_{p}^{i}$</span> are image patches. There multiple layers in the architecture and the state of the <strong>CLS</strong> token on the output layer is used for classification.</p>\n<p>I think this architectural solution is done in the spirit of NLP problems (BERT in particular). However, for me, it would be more natural not to create a special token, but perform <em>1d Global Pooling</em> in the end, and attach an <code>nn.Linear(embedding_dim, num_classes)</code> as more conventional CV approach.</p>\n<p>Why it is not done in this way? Or is there some intuition or evidence that this would perform worse than the approach used in the paper?</p>\n", "pids": ["6271e0e85aee126c0f5748c5"], "flag": 1}
{"question": "How to determine the quality of synthetic data?", "body": "<p>I'm working on a VAE model to produce synthetic data of X-Ray diffraction spectrums.</p>\n<p>I try to figure out how I can measure the quality of the spectrums. The goal would be to produce synthetic data which is similar to the training data but also different from the training data. The spectrums should keep their characteristics, but should be different in terms of noise and intensity.</p>\n<p>I trained models which can produce those type of spectrums (because I checked some of them visual), but I don't know how to quantify the difference/similarity to the origin (1) and the difference between the produced synthetic spectrums in one dataset (2).</p>\n<p>Are there any methods to quantify these points?</p>\n", "pids": ["57a4e91aac44365e35c97d02"], "flag": 1}
{"question": "Is there any evidence that accepting, affirming parenting is associated with less child depression?", "body": "<p>Is there any evidence that children of parents who are accepting and affirming in general of their children have lower rates of depression?</p>\n<p>I mean the opposite of personally critical, negating, condemning or negatively judging (which could be towards one child and not another); as well as cooperating with their children’s desires and wishes rather than rejecting, forcing, or controlling them.</p>\n", "pids": ["5c8dcca64895d9cbc6a27966", "563e05e60cf219a1e1f70934", "5c6bfa76e1cd8e6642f1bb8c", "56ab70da0cf2c98bf5bc75c1"], "flag": 1}
{"question": "In a Temporal Convolutional Network, how is the receptive field different from the input size?", "body": "<p>I'm playing around with TCN's lately and I don't understand one thing. How is the receptive field different from the input size?</p>\n<p>I think that the receptive field is the time window that TCN considers during the prediction, so I guess the input size shall be equal to it.</p>\n<p>According to <a href=\"https://arxiv.org/pdf/1609.03499.pdf\" rel=\"nofollow noreferrer\">the WaveNet paper</a>, I cannot see a reason why it should be otherwise. I'm using TensorFlow with <a href=\"https://github.com/philipperemy/keras-tcn\" rel=\"nofollow noreferrer\">this custom library</a>.</p>\n<p>Please help me understand.</p>\n", "pids": ["58437725ac44360f1082fa5e"], "flag": 1}
{"question": "What defines a microbial species?", "body": "<p>I know that microbes are not capable of sexual reproduction, thus sorting them into species according to \"groups that can interbreed and generate fertile offspring\" should not apply.</p>\n", "pids": ["55a4f783c91bf3b1cc4b4a2a"], "flag": 1}
{"question": "Would a colony with only one male and female collapse?", "body": "<p>This is a thought experiment:</p>\n\n<p>If we form a population with only a single founder pair, can this population survive? What would happen? Would this inbreeding cause the population to go extinct? Could such a population continue to exist indefinitely?</p>\n", "pids": ["600fe6bcd4150a363c20cf0f"], "flag": 1}
{"question": "What are knowledge graph embeddings?", "body": "<p>What are knowledge graph embeddings? How are they useful? Are there any extensive reviews on the subject to know all the details? Note that I am asking this question just to give a quick overview of the topic and why it might be interesting or useful, I am not asking for all the details, which can be given in the reference/survey.</p>\n", "pids": ["53e9acc4b7602d97036a1037", "5aed14d617c44a4438159031"], "flag": 1}
{"question": "Custom Tensorflow loss function that disincentivizes all black pixels", "body": "<p>I'm training a Tensorflow model that receives an image and segments the image into foreground and background. That is, if the input image is <code>w x h x 3</code>, then the neural network outputs a <code>w x h x 1</code> image of <code>0</code>'s and <code>1</code>'s, where <code>0</code> represents background and <code>1</code> represents foreground.</p>\n<p>I've computed that about 75% of the true mask is background, so the neural network simply trains a model that outputs all <code>0</code>'s and gets a 75% accuracy.</p>\n<p>To solve this, I'm thinking of implementing a custom loss function that checks if there are more than a certain percentage of <code>0</code>'s, and if so, to add a very large number to the loss to disincentivize the all <code>0</code>'s strategy.</p>\n<p>The issue is that this loss function becomes non-differentiable.</p>\n<p>Where should I go from here?</p>\n", "pids": ["5ef9c12e91e011b84e1f8c14"], "flag": 1}
{"question": "How to write a white paper for a non-academic?", "body": "<p>I am an apprentice employed to do mechanical engineering but my real passion has always been computing.</p>\n\n<p>I recently came up with IMHO a good idea to help mitigate DDoS attacks on web servers. I would like to do a write-up of my idea to help contribute to some personal portfolio perhaps so it would help me get into a career in computing if/when I decide to take that path.</p>\n\n<p>I have no exposure to University resources etc but feel a white paper on this topic is probably the best way to present it. So how should I go about writing an academic paper as an outsider to academia?</p>\n", "pids": ["53e99a43b7602d97022a1bdb", "53e9b123b7602d9703ba0260"], "flag": 1}
{"question": "In layman terms, what does &quot;attention&quot; do in a transformer?", "body": "<p>I heard from many people about the paper titled <strong><a href=\"https://arxiv.org/pdf/1706.03762.pdf\" rel=\"nofollow noreferrer\">Attention Is All You Need</a></strong> by <em>Ashish Vaswani et al</em>.</p>\n<p>What actually does the &quot;attention&quot; do in simple terms? Is it a function, property, or some other thing?</p>\n", "pids": ["573696026e3b12023e515eec", "5c75726df56def9798810d4e", "5ac1829d17c44a1fda91826f"], "flag": 1}
{"question": "Do most customers choose predatory publishers knowingly?", "body": "<p>In <a href=\"https://academia.stackexchange.com/questions/26455/what-should-i-do-if-i-submitted-an-article-to-a-predatory-journal/78916?noredirect=1#comment198048_78916\">this comment</a>, it was claimed:</p>\n\n<blockquote>\n  <p>Predatory publishers thrive because when you apply for a job or a grant, few read your papers. They check the papers you pinpoint and the number of publcations. That's where these publishers step on and that's why people choose them. Not because they don't know. Of course there might be a few accidentally doing it, like the OP in this question, but most of the people who are in academia for a while select them only to increase faster their publication list.</p>\n</blockquote>\n\n<p>By contrast, I cannot remember a single case of somebody reporting their experience with such publisher on this very site that submitted a paper to a predatory publisher knowingly (except for exposing them). Now, there is no denying that there is a strong bias here since people who intentionally choose a predatory publisher are less likely to admit it or ask questions here.</p>\n\n<p>So, I am curious: Is there any data or good argument to support the claim that people who publish with predatory publishers <strong>are aware</strong> that they are not publishing with a regular scientific publisher?</p>\n", "pids": ["56d88235dabfae2eee70ff91", "573696ac6e3b12023e5b0bca"], "flag": 1}
{"question": "Why does my regression-NN completely fail to predict some points?", "body": "<p>I would like to train a NN in order to approximate an unknown function <span class=\"math-container\">$y = f(x_1,x_2)$</span>. I have a lot of measurements <span class=\"math-container\">$y = [y_1,\\dots,y_K]$</span> (with K that could be in the range of 10-100 thousands) which come out from either a simulation or a measurement of a system. I've built a feed-forward NN for solving this problem by using a MSE loss-function, i.e.</p>\n<p><span class=\"math-container\">$$\\mathcal{L} = \\frac{1}{K}\\sum_{i=1}^K(y_i-\\hat{y}_i)^2$$</span></p>\n<p>where I defined as <span class=\"math-container\">$\\hat{y}$</span> the prediction of the NN. As per activation function I used a <em>ReLU</em>. The network topology is fairly simple with <em>input layer</em> having two neurons <span class=\"math-container\">$(x_1,x_2)$</span>, three <em>hidden layers</em> with 10 neurons each and finally the <em>output layer</em> (single output neuron).</p>\n<p>After the training process expires I've obtained a very curious result. The loss function assumes very small values hence (apparently) indicating that the training is successful. However, if I analyse the squared-error point-by-point, i.e. the quantity</p>\n<p><span class=\"math-container\">$$ \\boldsymbol{\\epsilon}_y = [(y_1-\\hat{y}_1)^2,\\dots,(y_K-\\hat{y}_K)^2] $$</span>\nI find that for the vast majority of points said quantity is basically zero, with exception of some &quot;outliers&quot; where the error is huge. It looks like this event happens where the gradient of <span class=\"math-container\">$f()$</span> is rather big, which might be a reasonable assumption maybe.</p>\n<p>I would like for this to not happen anymore. I'd rather accept a slightly bigger error throughout the whole function domain then have the majority of points with null error but some local points that are completely off. As a requirement, the network topology shall be kept rather &quot;easy&quot; so I would not like to increase the number of layers and/or neurons per layer. As a side node, I've also tried to increase the topology complexity a little bit (i.e. 15 neurons per hidden layer and adding a 4th hidden layer) obtaining slighlty better results but still unacceptable error around the steepest points of the function.</p>\n<p>I've got two ideas for now:</p>\n<ol>\n<li>Use a different loss-function <span class=\"math-container\">$\\mathcal{L}$</span></li>\n<li>Sample the dataset <span class=\"math-container\">$(x_1,x_2)$</span> more frequently around steepest regions, and less frequently where the function is rather smooth and flat</li>\n</ol>\n<h3>First option</h3>\n<p>A different loss-function to be adopted. I'm not very familiar with loss-function that might help solve my problem, some rather quick research yielded no good results and I found no significant literature highlighting this kind of problem. I initially thought of something of the likes of</p>\n<p><span class=\"math-container\">$$ \\mathcal{L} = \\frac{1}{K}\\sum_{i=1}^K(y_i-\\hat{y}_i)^2 + \\mu\\, max\\{\\boldsymbol{\\epsilon}_y\\} $$</span>\nwhere <span class=\"math-container\">$\\mu$</span> is some tuned parameter that penalizes the maximum error. I'm not sure if this makes sense and if it increases the training complexity to the extent that the training process runs in no convergence territory.</p>\n<h3>Second option</h3>\n<p>I am not sure how to formalize the undersampling where the function is smooth and flat, I imagine that some kernel used for image processing (edge detection kind of kernels of some sort?) might be helpful but I'm in completely unknown territory.</p>\n<h3>Conclusion</h3>\n<p>I'm looking for some insight and ideas (literature results or analogous cases linked are a huge plus!) for solving this curious problems.</p>\n<p>Thanks for the help!</p>\n<h3>Edit</h3>\n<p>I realize that without having graphical indsights of what I'm doing, it's going to be rather difficult to have a clear understanding. The function <span class=\"math-container\">$f(x_1,x_2)$</span> is plotted here below (let alone the red line, it is just there to highlight what happens when <span class=\"math-container\">$x_1=\\text{M}=1.2$</span> is fixed to a certain value). The missing points of around the variable <span class=\"math-container\">$x_2=f_n=1$</span> represent a singularity in my model and I don't care about them being predicted since they physically have no pratical use. I removed them completely for this reason.</p>\n<p><a href=\"https://i.stack.imgur.com/sgdS1.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/sgdS1.png\" alt=\"\" /></a></p>\n<p>Once the training of my NN is complete, I plot the <span class=\"math-container\">$L2$</span> error (MSE) between predicted and true value\n<a href=\"https://i.stack.imgur.com/Iv2do.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/Iv2do.png\" alt=\"\" /></a>\nAs you can see, it looks like the points where there is a significant gradient change cannot be predicted correctly.</p>\n", "pids": ["5ce2d008ced107d4c6335378"], "flag": 1}
{"question": "Proper way to format computer code included in a thesis/dissertation", "body": "<p>I intend to include my computational model code(s) in its entirety as an appendix in my dissertation.  I've gone through my university's formatting guidelines and haven't seen anything on the proper way to format the code in terms of size of font, text-wrapping, spacing, and so forth.  What's the best way to do this?</p>\n\n<p>When I read code, while I'd want it to be a typical font size (12 pt), I'd also want the text-wrapping to be minimal, but given the traditional margin requirements, it can be pretty tough to accomplish this.  Having code trail off one line and onto the next is generally distracting.</p>\n\n<p>Also, although comments in code are prevented from execution by using a character sequence like %or // or (* many compilers color-code this text to make it more easily distinguishable from executable portions of the code.  Is there any way to easily make comments distinguishable when putting the code into the text of your thesis/dissertation?</p>\n", "pids": ["56d8d114dabfae2eeea49275"], "flag": 1}
{"question": "What is multi-head attention doing mathematically, and how is it different from self-attention?", "body": "<p>I'm trying to understand the difference between the concept of <em>self-attention</em> and <em>multi-head attention</em>. The latter is not actually too clear to me.</p>\n<p>I understand that, in the case of self-attention, we start with a feature matrix <span class=\"math-container\">$X \\in \\mathbb{R}^{n \\times d}$</span>, and then we use the same linear transformation <span class=\"math-container\">$W$</span> to produce</p>\n<p><span class=\"math-container\">\\begin{align}\nQ &amp;= XW \\\\ \nK &amp;= XW \\\\\nV &amp;= XW\n\\end{align}</span></p>\n<p>and then we compute the following</p>\n<p><span class=\"math-container\">$$X' = \\text{softmax} \\left(\\frac{Q\\cdot K^T}{\\sqrt{d}} \\right)V$$</span></p>\n<p>where <span class=\"math-container\">$X' \\in \\mathbb{R}^{n \\times d}$</span> is a new version of the input matrix, where the pairwise interactions between the points will be encoded.</p>\n<p>What is multi-head attention doing, from a mathematical point of view, and what's the difference? I know we are going to use three <em>different</em> linear transformations in this case (so no weight-sharing), but what exactly will be encoded using three different <span class=\"math-container\">$W$</span>? Maybe it's more the conceptual view that it's not too clear in this case.</p>\n", "pids": ["599c7987601a182cd2648373"], "flag": 1}
{"question": "Image-in image-out neural network architectures", "body": "<p>With an RGB image of a paper sheet with text, I want to obtain an output image which is cropped and deskewed. Example of input:</p>\n<p><a href=\"https://i.stack.imgur.com/l64Kn.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/l64Kn.png\" alt=\"enter image description here\" /></a></p>\n<p>I have tried non-AI tools (such as <code>openCV.findContours</code>) to find the 4 corners of the sheet, but it's not very robust in some lighting conditions, or if there are other elements on the photo.</p>\n<p>So I see two options:</p>\n<ul>\n<li><p>a NN with <code>input=image, output=image</code>, that does <strong>everything</strong> (including the deskewing, and even also the brightness adjustment). I'll just train it with thousands of images.</p>\n</li>\n<li><p>a NN with <code>input=image, output=coordinates_of_4_corners</code>. Then I'll do the cropping + deskewing with a homographic transform, and brightness adjustment with standard non-AI tools</p>\n</li>\n</ul>\n<p>Which approach would you use?</p>\n<p><strong>More generally what kind of architecture of neural network would you use in the general case <code>input=image, output=image</code>?</strong></p>\n<p>Is approach #2, for which input=image, output=coordinates possible? Or is there another segmentation method you would use here?</p>\n", "pids": ["600ab58d91e0115cfb85a8f7", "5736986b6e3b12023e730129"], "flag": 1}
{"question": "In general - is Stochastic Gradient Descent a &quot;superior&quot; algorithm compared to Gradient Descent?", "body": "<p>On a very informal level, if we were to compare the (classical) <strong>Gradient Descent Algorithm to the Stochastic Gradient Descent Algorithm</strong>, the first thing that comes to mind is:</p>\n<ul>\n<li>Gradient Descent can be considered as a slower algorithm than Stochastic Gradient Descent, since it requires performing mathematical operations (e.g. derivatives, second derivatives) on the entire data set. On the other hand, Stochastic Gradient Descent can be considered as a faster algorithm, since it approximates the gradient using &quot;mini batches&quot; of observations from the data set. Logically, this makes sense : Stochastic Gradient Descent requires fewer calculations compared to Gradient Descent, therefore the same computer should take less time to perform fewer calculations compared to more calculations.</li>\n</ul>\n<p>However, (in the spirit of tradeoffs) the somewhat logical counter point to the above argument is that:</p>\n<ul>\n<li>Since Stochastic Gradient Descent approximates the gradient of the function whereas Gradient Descent evaluates the full gradient - one would imagine that perhaps Gradient Descent might have a better ability to find the true minimum of the function compared to Gradient Descent. <strong>However, I am not sure about this.</strong></li>\n</ul>\n<p><strong>My Question:</strong> In the past few years, a lot of research has been done about studying the behavior (e.g. theoretical convergence properties) of Stochastic Gradient Descent (e.g. <a href=\"https://arxiv.org/abs/2103.14350\" rel=\"nofollow noreferrer\">https://arxiv.org/abs/2103.14350</a> , <a href=\"https://raghumeka.github.io/CS289ML/gdnotes.pdf\" rel=\"nofollow noreferrer\">https://raghumeka.github.io/CS289ML/gdnotes.pdf</a>) which have demonstrated similar abilities of the Stochastic Gradient Descent Algorithm to converge as compared to Gradient Descent.</p>\n<p><strong>But are there any theoretical results which expose the above (speculated) tradeoff?</strong> At the end of the day, if Stochastic Gradient requires less computing power when compared to Gradient Descent - are there any theoretical results that suggest Gradient Descent has an inherent ability to better find the minimum of the function (e.g. perhaps less likely to get &quot;stuck&quot; in saddle points) since it is not relying on an approximation of the gradient? Or if Stochastic Gradient Descent is equal to Gradient Descent in this regard - could Stochastic Gradient Descent be then considered as superior to Gradient Descent?</p>\n<p>Can someone please comment on this?</p>\n<p>Thanks!</p>\n", "pids": ["5c8d30414895d9cbc643efad", "573696096e3b12023e51cfc8"], "flag": 1}
{"question": "Is it possible to train an AI to bring a picture story in the correct order (correct story flow)?", "body": "<p>I want to know if it is possible to train a neural network (or some other kind of an AI) to bring a simple picture story in the correct order, if it is in random order, so that the story has the correct story flow.</p>\n<p>For example, this simple picture story:</p>\n<p><a href=\"https://i.stack.imgur.com/iegBn.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/iegBn.png\" alt=\"enter image description here\" /></a></p>\n<p>or this one</p>\n<p><a href=\"https://i.stack.imgur.com/S8SLV.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/S8SLV.jpg\" alt=\"enter image description here\" /></a></p>\n<p>So, imagine the pictures of these stories are in a random order and the AI has to put them in the order that the correct story is told.</p>\n<p>Most 8 year olds would be able to do that. So, can an AI learn it? How would an approach look like? Does anyone know if something like that has been achieved or even tried?</p>\n<p>From my research so far, the approach would be first to translate the images into descriptive sentences and then try to order them in a meaningful way. But I will do further research, I found so far this paper: <a href=\"https://arxiv.org/abs/1606.07493\" rel=\"nofollow noreferrer\">Sort Story: Sorting Jumbled Images and Captions into Stories</a> (2016).</p>\n<p>To clarify, this is not a &quot;real problem&quot; for me, I just asked from a philosophical standpoint and from interest. I will not attempt to solve it, because I think if it is possible it would be extremely difficult.</p>\n", "pids": ["5e96db3891e01129d1a03e0c"], "flag": 1}
{"question": "How do people who self-harm perceive pain and how is their pain tolerance related?", "body": "<p>I would like to make a reference request for articles, papers or monographs that address the question of what is the experience of physical pain during self-harm, if possible, particularly in those with borderline personality disorder.</p>\n<p>Self-harm is pervasive in BPD as it is believed to be used to help regulate emotions and manage dissociative episodes. However, my interest is not in its function nor its motivations. I would like to know if any research addresses the experience of the physical pain of the act, for the BPD individual. In particular, if the following questions can be addressed:</p>\n<ul>\n<li>Is the person self-harming conscious and aware of the physical pain during the act?</li>\n<li>If the physical pain is experienced like any other, is its relative magnitude to the emotions being regulated minute so as to make it perceived as tolerable or make it possible to be ignored?</li>\n<li>Do those that engage in self-harm build a pain tolerance, or what is the relation to their pain tolerance?</li>\n</ul>\n<p>The main answer might be simple, that they experience pain in the same way as someone being accidentally injured, but the context and situation make it tolerable or possible to be ignored.</p>\n", "pids": ["55a4e887c91bf3b1cc49c25a", "53e9a885b7602d97031d43e5", "5c3ed547e1cd8e0a96063a1f", "5c7564d9f56def9798fb0765"], "flag": 0}
{"question": "Why do Convolution Neural Networks work on NLP/sequential tasks?", "body": "<p>I have read some articles where people use 1D CNN for NLP tasks like sentiment analysis. My questions are, given that CNNs are largely used for images, how/why does this work on sequences/NLP tasks? And, are there any specific CNN-based architectures that outperform transformers?</p>\n", "pids": ["6099052391e011aa8bcb6e79"], "flag": 1}
{"question": "Why do we use the same parameters for the joint, marginal and conditional distributions in VAEs?", "body": "<p>I've noticed in several resources on variational autoencoders (for example the <a href=\"https://en.wikipedia.org/wiki/Variational_autoencoder\" rel=\"nofollow noreferrer\">wikipedia article</a>), we use the same parameters theta for the prior, likelihood, posterior, etc distributions. For example the equation <span class=\"math-container\">$p_\\theta(x) = \\int_z p_\\theta(x|z)p_\\theta(z)dz$</span>. Aren't <span class=\"math-container\">$p_\\theta(x)$</span> and  <span class=\"math-container\">$p_\\theta(z)$</span> two different distributions, so how can we parameterize them with the same <span class=\"math-container\">$\\theta$</span> params. I might be misunderstanding something about what it means to parameterize a distribution...</p>\n", "pids": ["5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "What are some examples of psychology studies with tiny effect sizes and tiny p-values that are good for teaching?", "body": "<p>I'm looking for examples of studies where the result is highly significant but the effect is so tiny that it is meaningless in a practical sense. These will be shared with undergraduate psychology students to illustrate that statistically significant doesn't always mean important or consequential.</p>\n", "pids": ["562901e80cf2bc5294a4d42d"], "flag": 0}
{"question": "What is the difference between the triplet loss and the contrastive loss?", "body": "<p>What is the difference between the <strong>triplet loss</strong> and the <strong>contrastive loss</strong>?</p>\n<p>They look same to me. I don't understand the nuances between the two. I have the following queries:</p>\n<ul>\n<li>When to use what?</li>\n<li>What are the use cases and advantages or disadvantages of the two?</li>\n<li>Also, how do they fit with the siamese network discussion?</li>\n</ul>\n", "pids": ["573697846e3b12023e66ab35"], "flag": 1}
{"question": "Is there a standardized method to train a reinforcement learning NN by demonstration?", "body": "<p>I'm less familiar with reinforcement learning compared to other neural network learning approaches, so I'm unaware of anything exactly like what I want for an approach. I'm wondering if there are any ways to train a Deep-Q neural network on, say, OpenAI Gym, where the model is given a recorded demonstration to learn from. That is, I'd like to do the following (with a Mario NES example):</p>\n<ul>\n<li>Play the first level of Mario and somehow record this (maybe as an input sequence?)</li>\n<li>Run the model on the level a few times until it passes</li>\n<li>Send the model to the next level, let it train for as long as possible unless it continues to fail -- if so, I'll play the level and then let it train again</li>\n<li>Repeat</li>\n</ul>\n<p>Are there any approaches similar to this that currently exist? And, would this be infeasible because the model may fail to generalize? I'd like to accomplish this with much more complicated games, but if I could use this approach to save on defining endless amounts of reward/penalty policies and ROM hacking to find the memory address of everything I want the model to use, it would be extremely helpful.</p>\n", "pids": ["60d5404491e01153881e84a7"], "flag": 1}
{"question": "Why do Q-values diverge without a target network?", "body": "<p>After reviewing similar <a href=\"https://ai.stackexchange.com/questions/6982/why-does-dqn-require-two-different-networks\">posts</a> on this topic, I understand that a target network is used to prevent &quot;divergence&quot;, but am not sure what it actually means. Q-values are predicted using a function approximator. The weights of the function approximator are then updated using the difference between the Q-value and TD target (<span class=\"math-container\">$r + \\gamma\\max_aQ(s',a)$</span>). Now assuming, that the estimate of the Q-value was wrong, the weights could easily be updated so that they are correct the next time the state is encountered. My confusion arises when online blogposts say that this change in weights modifies the target Q-value(<span class=\"math-container\">$Q(s', a)$</span>) too. I don't see how the target Q-value gets updated when the current Q-value is changed.</p>\n", "pids": ["6049ee5491e01118b758f0b7"], "flag": 1}
{"question": "Why can the sum over timesteps in the Vanilla Policy Gradient be ignored?", "body": "<p>I understand how to derive the vanilla policy gradient\n<span class=\"math-container\">$$\n\\begin{align}\n    \\nabla_{\\theta}J(\\pi_{\\theta}) = \\mathbb{E}_{\\pi_{\\theta}} \\left[ \\sum_{t = 0}^{T} \\nabla_{\\theta} \\log \\pi_{\\theta}(a_{t} \\mid s_{t}) \\hat{A}^{\\pi_{\\theta}}(s_{t}, a_{t}) \\right]\n\\end{align}\n$$</span>\nas is also demonstrated in the <a href=\"https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html\" rel=\"nofollow noreferrer\">openai spinning up documentation</a>. Reading the <a href=\"https://arxiv.org/abs/1707.06347\" rel=\"nofollow noreferrer\">PPO paper</a>, they say that the most commonly used gradient estimator is\n<span class=\"math-container\">$$\n\\begin{align}\n    \\nabla_{\\theta}J(\\pi_{\\theta}) = \\mathbb{E}_{\\pi_{\\theta}} \\left[\\nabla_{\\theta}\\log \\pi_{\\theta}(a_{t} \\mid s_{t}) \\hat{A}^{\\pi_{\\theta}}(s_{t}, a_{t}) \\right]\n\\end{align}\n$$</span>\nand from there they argue that this is equivalent to using the loss function\n<span class=\"math-container\">$$\n\\begin{align}\n    \\mathcal{L}^{\\text{PG}}(\\theta) = \\mathbb{E}_{\\pi_{\\theta}} \\left[\\log \\pi_{\\theta}(a_{t} \\mid s_{t}) \\hat{A}^{\\pi_{\\theta}}(s_{t}, a_{t}) \\right]\n\\end{align}\n$$</span>\nwhere the derivative is then taken with respect to <span class=\"math-container\">$\\theta$</span>.</p>\n<p><strong>Question:</strong> How does the vanilla policy gradient relate to the gradient stated in the PPO paper? More precisely, they seem to be identical up to the sum over <span class=\"math-container\">$t$</span>. Why can the sum be ignored and the gradient is still the same?</p>\n<p>Thanks in advance for any help!</p>\n", "pids": ["573696066e3b12023e519907"], "flag": 1}
{"question": "Can speech dysarthria occur in schizophrenia without other neurological or medication-induced disruptions?", "body": "<p>As I understand it, acquired dysarthria of speech is caused due to problems with motor neurons or other neurological, cerebral and peripheral, conditions in the CNS affecting those. And schizophrenia is primarily a problem in mesolimbic and mesocortical dopaminergic pathways, amongst possibly other problems. Can a purely schizophrenic or psychiatric condition without neurological diagnoses cause dysarthria as a symptom by itself? Or is acquired dysarthria always a sign of a comorbid neurological diagnosis?</p>\n", "pids": ["55a45daa65ce31bc87784c77", "5d528a6c10066d67516b19fa"], "flag": 0}
{"question": "What is the most important predecessor of the transformer model?", "body": "<p>I'm wondering what the origins of the transformer as proposed in <a href=\"https://arxiv.org/pdf/1706.03762.pdf\" rel=\"nofollow noreferrer\">Attention Is All You Need</a> are. The paper itself provides some interesting pointers to the literature on self-attention such as:</p>\n<ol>\n<li><a href=\"https://aclanthology.org/D16-1244.pdf\" rel=\"nofollow noreferrer\">A Decomposable Attention Model for Natural Language Inference</a></li>\n<li><a href=\"https://openreview.net/pdf?id=BJC_jUqxe\" rel=\"nofollow noreferrer\">A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING</a></li>\n<li><a href=\"https://arxiv.org/pdf/1706.03762.pdf\" rel=\"nofollow noreferrer\">NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE</a></li>\n</ol>\n<p>It seems like using attentional mechanisms was widespread (at least in combination with recurrent networks) and 'A Decomposable Attention Model for Natural Language Inference' paper from 2016 already conjectured that scaling attention might be feasible.\nIs it from this prior work 'only' an engineering leap? Or what additional papers at the time likely influenced the architecture?</p>\n", "pids": ["5550411c45ce0a409eb3897f"], "flag": 1}
{"question": "Is large language model and foundation model the same thing?", "body": "<p>I read a lot about foundation model and large language model.</p>\n<p>However, I dont find a clear definition what exactly is a foundation model. Is large language model and foundation model the same thing?</p>\n", "pids": ["611b817c5244ab9dcbd15920"], "flag": 1}
{"question": "Why diffusion model always use U-Net?", "body": "<p>I want to know why diffusion models always use U-Net.</p>\n<p>In my opinion, they use U-Net because you can see features of different resolutions and skip connection is good to add detail of images. But I am not sure if it is the main reason why they use U-Net.</p>\n<p>Are there other reasons they choose U-Net rather than other architectures?</p>\n", "pids": ["557c6d8b08b02739a5ca6e2c"], "flag": 1}
{"question": "Is there good evidence that long-term stimulant usage in children has no harmful effect when stopped?", "body": "<p>Essentially, I am looking for an RCT done on children, where they went on a stimulant drug for at least 3 years, and then stopped administering the drug.</p>\n<p>What I'm worried about is long-term lower levels of motivation - below baseline compared to people who never took the stimulant in the first place.  Or other subtle stuff that would only show up in an RCT.</p>\n", "pids": ["53e9badfb7602d970470eb48", "55a6bfd665ce054aad74290c", "53e9a7f8b7602d970313a28c", "55a493efc91bf3b1cc3f73d6", "53e9b866b7602d970442f905", "53e9ad41b7602d97037220cf", "53e99b8db7602d9702434fe8", "53e9a855b7602d970319f287", "55a377b92401aa93797946f5", "5cf24d003a55acd1f85015f7", "5c0f7219da562944ac65006b"], "flag": 1}
{"question": "How do Transformer decoders handle arbitrary length input?", "body": "<p>I am working through a Tensorflow Neural Machine Translation tutorial (<a href=\"https://www.tensorflow.org/text/tutorials/transformer\" rel=\"nofollow noreferrer\">https://www.tensorflow.org/text/tutorials/transformer</a>) and am confused about how the decoder handles inputs when making inferences after it has been trained.</p>\n<p>In the section where we create a class for translating a sentence (<a href=\"https://www.tensorflow.org/text/tutorials/transformer#run_inference\" rel=\"nofollow noreferrer\">https://www.tensorflow.org/text/tutorials/transformer#run_inference</a>) it appears that we feed the decoder an array populated with the START token only, then append the last element from the predicted sequence it makes to the growing translated sentence. This does not make sense to me as we trained the transformer on a fixed length sequence that was padded to length MAX_TOKENS=128, so I can't figure out why it would be able to accept input of an arbitrary length tensor.</p>\n<p>Here is the code for inference in question that confuses me:</p>\n<pre><code>    # As the output language is English, initialize the output with the\n    # English `[START]` token.\n    start_end = self.tokenizers.en.tokenize([''])[0]\n    start = start_end[0][tf.newaxis]\n    end = start_end[1][tf.newaxis]\n\n    # `tf.TensorArray` is required here (instead of a Python list), so that the\n    # dynamic-loop can be traced by `tf.function`.\n    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n    output_array = output_array.write(0, start)\n\n    for i in tf.range(max_length):\n      output = tf.transpose(output_array.stack())\n      predictions, _ = self.transformer([encoder_input, output], training=False)\n\n      # Select the last token from the `seq_len` dimension.\n      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n\n      predicted_id = tf.argmax(predictions, axis=-1)\n\n      # Concatenate the `predicted_id` to the output which is given to the\n      # decoder as its input.\n      output_array = output_array.write(i+1, predicted_id[0])\n\n      if predicted_id == end:\n        break\n\n</code></pre>\n<p><code>self.transformer</code> takes in the &quot;encoder_input&quot; which is fed to the encoder and &quot;output&quot; which is fed into the decoder, where we then take the last prediction in the sequence returned from the decoder, append it to &quot;output&quot;, then repeat the process. But I don't understand how the decoder can process a tensor of length 1, then 2, then 3, and so on if it is always expecting a tensor of length 128.</p>\n<p>It seems like the input to the decoder should be padded to 128 tokens and then the prediction at the i-th index should be appended to the output (rather than always the last element in the predicted sequence) before repeating.</p>\n<p>Is the tutorial mistaken in the implementation on of how this transformer preforms inference? Or am I missing something that Tensorflow does behind the scenes that allow this to work?</p>\n<p>Note, I realize the title to this question is similar to <a href=\"https://ai.stackexchange.com/questions/22957/how-can-transformers-handle-arbitrary-length-input\">How can Transformers handle arbitrary length input?</a> but the answer given appears to verify that the input to the decoder should be fixed length and padded, which contradicts how inference is done in the tutorial I am referencing. So I hope this question isn't considered a duplicate but I am asking a similar question in the context of the mentioned tutorial.</p>\n<p>Thank you for any insight someone might be able to provide!</p>\n", "pids": ["599c7987601a182cd2648373"], "flag": 1}
{"question": "Doesn&#39;t every single machine learning classifier use conditional probability/Bayes in its underlying assumptions?", "body": "<p>I'm reading about how Conditional Probability/ Bayes Theorem is used in Naive Bayes in Intro to Statistical Learning, but it seems like it isn't that &quot;groundbreaking&quot; as it is described?</p>\n<p>If I'm not mistaken doesn't every single ML classifier use conditional probability/Bayes in its underlying assumptions, not just Naive Bayes? We are always trying to find the most likely class/label, given a set of features. And we can only deduce that using Bayes rule since we are (usually) solving for P(class|features) with P(features|class)?</p>\n", "pids": ["639a906390e50fcafdefe52a"], "flag": 1}
{"question": "What is the &quot;state of the art&quot; in (at least partially) symbolic/logic-based chat bots/AI assistants?", "body": "<p><a href=\"https://openai.com/blog/chatgpt/\" rel=\"nofollow noreferrer\">ChatGPT</a> has had a lot of buzz around it recently, and for good reason. It has shown some amazing capabilities in responding to new information, as well as in generalizing new information that has been given to it.</p>\n<p>However, ChatGPT also regularly makes logical and mathematical errors. Some have commented that it really tries its best based on the data that was given to it to &quot;sound correct&quot; (almost like a freshman &quot;bullshitting&quot; a term paper), but it not actually great in general at making logical inferences.</p>\n<p>One of the ways this issue could be solved is, rather than using a pure large language model (as essentially I understand ChatGPT is doing), we can instead use a semantic parser to parse natural language sentences into a logical form, such as first-order logic, higher-order logic, various forms of modal logic -- or what have you. This approach can also be supplemented with neural methods -- for instance, either by directly training a semantic parser as a sequence-to-sequence problem, or by learning &quot;weights&quot; for the likelihood of different parses.</p>\n<p>I know that before the &quot;first AI winter&quot;, the more symbolic/logical approach dominated, and a lot of work was done in Prolog, so I could probably find some examples of what I am looking for by looking at said historical approaches.</p>\n<p>However, what I am looking for is a state-of-the-art chat bot based at least partially on symbolic techniques (specifically, using semantic parsing + a logical inference engine).</p>\n<p>Does such a thing exist? Has much progress been made on that front since the first AI winter? I'd especially be interested in approach that combine neural/deep learning with symbolic approaches in some way.</p>\n<p>References would be appreciated, but I'm mainly looking for concrete open-source implementation so I can play around for myself with the &quot;state-of-the-art&quot; and see what the current best offerings are, and their limitations.</p>\n", "pids": ["5eede0b091e0116a23aafc0e", "6204827e5aee126c0f77d9b3"], "flag": 1}
{"question": "How does psychological exhaustion work?", "body": "<p>Let's say I am studying a subject X. I believe as the time spent on the subject X increases, the marginal rate of knowledge gained per unit time decreases to almost nothing. This reduce is associated with a general feeling of &quot;being tired&quot;.</p>\n<p>Why does this happen?</p>\n", "pids": ["53e99a26b7602d970227bd29", "53e9b4b9b7602d9703fcf1ca"], "flag": 1}
{"question": "What is systematic literature review?", "body": "<p>I know what a literature review is and was wondering what makes such a review <em>systematic</em>? What extra steps do people usually go through when they do a <em>systematic</em> literature review? how is it different from regular literature review? The field is software engineering if it matters. </p>\n", "pids": ["628d20b95aee126c0f415d06", "627cda875aee126c0f4971f1", "628d2d805aee126c0f57e050"], "flag": 1}
{"question": "Describing figures vs letting figures speak for themselves", "body": "<p>I'm writing a journal article that involves many comparisons within and across groups. Visually, these comparisons are quite easily understood. However, describing them in text requires the use of long sentences with several acronyms and numerous references back to sub-parts of the figures. </p>\n\n<p>In general is it acceptable in academic writing to simply say a couple of high-level sentences (and maybe point out some nuance that a reader might miss) about a complex figure and allow the reader to absorb the bulk of the information by viewing the figure?</p>\n", "pids": ["5c756f43f56def979865023d"], "flag": 1}
{"question": "reading an EEG dataset using EEGLAB", "body": "<p>When I'm reading the documentation of importing events in EEGLAB from a file <a href=\"http://sccn.ucsd.edu/wiki/A02:_Importing_Event_Epoch_Info\" rel=\"nofollow noreferrer\">here</a> I have noticed that when we used a stimulus , we must know which time  we will apply it , since in the dataset file , you have to identify  of what times stimulus happen . <br> I don't know if my understanding is right or not , since i didn't  deal with EEG data practically (but in 2 weeks I will), but I was  reading a theoretical topics and papers on that.\n<br> thanks in advance.</p>\n", "pids": ["61c9d0605244ab9dcb0cf543"], "flag": 1}
{"question": "Could AIs self-develop in the future?", "body": "<p>Is it possible that, at some time in the future, AIs will be able to initiatively develop themselves, rather than passively being developed by humanity?</p>\n", "pids": ["53e9a8dbb7602d9703229bea"], "flag": 1}
{"question": "Source of sensory data related to cognitive effort", "body": "<p>How does the brain assess cognitive effort? Is there a chemical that is being created or consumed at a rate that is proportionate to the amount of effort felt?</p>\n\n<p>I'm mostly interested in short term effort, such as in short-term-memory tasks.</p>\n", "pids": ["5a9ea59b684d55eb9298e42b", "5f9beb9cd4150a363c35eee2", "5c0f8acada562944ac9be815", "55a654c665ce054aad649253", "5ff1ca1019519e9c39622662", "5ae00371a2e6b107866a1af9"], "flag": 0}
{"question": "How successfully can convnets detect NSFW images?", "body": "<p>For example, search engine companies want to classify their image searches into 2 categories (which they already do that) such as: <a href=\"https://en.wikipedia.org/wiki/Not_safe_for_work\" rel=\"nofollow\">NSFW</a> (nudity, porn, brutality) and safe to view pictures.</p>\n\n<p>How can artificial neural networks achieve that, and at what success rate? Can they be easily mistaken?</p>\n", "pids": ["56d894ebdabfae2eee06c459"], "flag": 1}
{"question": "Has there been research done regarding processing speech then building a &quot;speaker profile&quot; based off the processed speech?", "body": "<p>Has there been research done regarding processing speech then building a \"speaker profile\" based off the processed speech? Things like matching the voice with a speaker profile and matching speech patterns and wordage for the speaker profile would be examples of building the profile. Basically, building a model of an individual based solely off speech. Any examples of this being implemented would be greatly appreciated.</p>\n", "pids": ["53e9a2fab7602d9702c063cc"], "flag": 1}
{"question": "Neural nets for cognition", "body": "<p>I recently got into Neural networks. As much as I have understood, the learning process is based on the change in weights according to stimulus and algorithm used in learning. Does this in any way represent the real learning process of our brain?</p>\n", "pids": ["5550416345ce0a409eb3ad52"], "flag": 0}
{"question": "Is there any way can teach AI creative painting (not convert photo to paint)?", "body": "<p>I already know that AI can paint, by using genetic algorithms, there are already lots of works such as <a href=\"http://genekogan.com/works/style-transfer/\" rel=\"nofollow noreferrer\">this</a> and <a href=\"https://www.instapainting.com/ai-painter\" rel=\"nofollow noreferrer\">this</a>. In addition, I also know AI can compose: <a href=\"https://arxiv.org/pdf/1611.03477v1.pdf\" rel=\"nofollow noreferrer\">Song from PI: A musically plausible network for pop music generation</a> (genetic algorithm too).</p>\n<p>But what I find interesting is not painting those ambiguity/abstract paintings.</p>\n<p>The not abstract painting flow I think is (just for example):</p>\n<ol>\n<li><p>at least training AI with superman's comic</p>\n</li>\n<li><p>give AI a very simple posture sketch of a standing human</p>\n</li>\n<li><p>AI paint it to superman.</p>\n</li>\n</ol>\n<p>Currently, I don't know if there is any way/guide/thought/algorithm can teach AI to paint a superman like the comic (not abstract ones). I'd like to research this area but can't find where and how to start.</p>\n", "pids": ["5e8d92879fced0a24b60cbfc"], "flag": 1}
{"question": "What is the set of cards used in the Wisconsin/Berg Card Sorting task?", "body": "<p>I'm a little confused about what cards are included in the Wisconsin card sorting task. According to PEBL there are two sets of cards available for the task, one set of 64 cards and one set of 128 cards. I think I've figured out what the 64 card deck is given that there are four different number, four different colours and four different shapes. Consequently, 4*4*4=64. However, what is contained in the 128 card deck?</p>\n", "pids": ["55a492b2612ca648689b8b74"], "flag": 1}
{"question": "Can I correct a typo in my published paper if it doesn&#39;t affect content?", "body": "<p>I discovered a minor error (essentially a typo) in one of my recent publications. It would not be noticed by most readers. It does not affect the content of the article and does not require an erratum or corrigendum. According to the editor, it is no longer possible to correct the error. Although many people would ignore the error, I think that there must be a better way to solve the problem.</p>\n\n<p>My preliminary idea is to use Adobe Acrobat Pro DC (or equivalent software) to correct the error and upload it to a professional website or cloud storage service. I could either correct the error outright (which would not draw attention to the change I’ve made) or use the strikeout text tool to correct the error (which would make it obvious what I have changed). On my CV, I would include a hyperlink to the corrected article that I have uploaded. The link could be accompanied by some text indicating that I’m linking to a corrected version of the article, or not.</p>\n\n<p>Finally, because this is an open-access article, I don’t anticipate any copyright issues associated with uploading the article or linking to it on my CV.</p>\n\n<p>What is the best course of action here?</p>\n", "pids": ["53e9b24eb7602d9703cef25c"], "flag": 1}
{"question": "Protein structure prediction from amino acids sequence", "body": "<p>Information given at this resource <a href=\"https://predictioncenter.org/\" rel=\"noreferrer\">https://predictioncenter.org/</a> is close to impossible to digest (as with everything in this field), so if anyone could tell me what is the accuracy we can predict tertiary protein structure now - I would be grateful.</p>\n\n<p>Also would love to hear your thoughts on 'why a cell can make exactly the same protein structure thousands of time using known to us physical laws, but we have to guess it using machine learning'? Why is it difficult?</p>\n", "pids": ["56d8fbf4dabfae2eeeb8c310"], "flag": 1}
{"question": "Is there a term for the desire to maintain a level of anxiety?", "body": "<p>As a war veteran who has/had PTSD, I've noticed in myself a desire to maintain a level of anxiety and stress closer to what I was used to. </p>\n\n<p>You've probably also heard/seen this type of behavior from other veterans who engage in High Risk Behavior after separation from service.</p>\n\n<p>I've also known former incarcerated individuals and PhD graduates who do the same.</p>\n\n<p>Is there an official term for this behavior? Further reading on the topic?</p>\n", "pids": ["55a651d265ce054aad645363", "62b6e6e85aee126c0fa6d75b", "53e9993fb7602d9702179ee4"], "flag": 0}
{"question": "Are all breakthroughs in AI and machine learning are due to increase in computational resources?", "body": "<p>I have read that all the math responsible for modern day machine learning and AI was already in place in 1900s but we did not have computational resources to implement those algorithms. So, is that true? And if it is, in what areas of machine learning the researchers work? And are all the future breakthroughs will be dependent only on increment of computational resources?</p>\n", "pids": ["573696026e3b12023e516627"], "flag": 1}
{"question": "What part, roughly, of the carbon in a plant comes from the soil? As opposed to the atmosphere?", "body": "<p><a href=\"https://en.wikipedia.org/wiki/C4_carbon_fixation\" rel=\"noreferrer\">C4</a> plants contain a slightly higher percentage of carbon-13 than <a href=\"https://en.wikipedia.org/wiki/C3_carbon_fixation\" rel=\"noreferrer\">C3</a> plants. Is this because of carbon obtained from the soil or the atmosphere?</p>\n<p>I have read that plants using different chemical pathways, such as millet and wheat, incorporate distinctive proportions of stable carbon isotopes <em>from the SOIL</em>.</p>\n<p>Do C4 plants need more carbon-13, or does that process just happen to result in accumulation of more carbon-13?</p>\n", "pids": ["5c9d8a58e1cd8e5b74c905f7", "5de8df30df1a9c0c4160c56d"], "flag": 1}
{"question": "Is MIRI doing genuine high-quality research?", "body": "<p>Recently, I found out about somewhat famous <a href=\"http://yudkowsky.net/\" rel=\"nofollow noreferrer\">Eliezer Yudkowsky</a> and <a href=\"https://intelligence.org/\" rel=\"nofollow noreferrer\">Machine Intelligence Research Institute</a> he founded. Their philosophy and organisation seem interesting but I'm curious about their credibility. I'm pretty sure this is not a con and they seem to be producing <a href=\"https://intelligence.org/all-publications/\" rel=\"nofollow noreferrer\">a lot of articles</a>. However, few of those are published and none in the journals mentioned <a href=\"https://ai.stackexchange.com/q/2306/2444\">here</a>.</p>\n\n<p><strong>So, is MIRI doing genuine high-quality research?</strong></p>\n", "pids": ["58437725ac44360f1082fd29"], "flag": 1}
{"question": "Is it possible to be clinically obsessed with school?", "body": "<p>I was wondering if it is possible for someone to have a clinical obsession with higher education. For example, the person who has this disorder constantly talks to others about things such as college to the point where something seems very wrong. Does a disorder like this exist? Or can it be a form of another disorder? I'm asking because I'm writing a research paper on various obsessions and would like to gain some insight on the matter.</p>\n", "pids": ["5c6eb436e1cd8ef5662e80f7", "55a3a638c91b587b095df455"], "flag": 1}
{"question": "What are the counterparts of non-linearities and dropout in fully convolutional networks?", "body": "<p>I am trying to replicate the <em>fully convolutional networks</em> (FCN) concept described <a href=\"https://www.youtube.com/watch?v=nDPWywWRIRo&amp;t=16m30s\" rel=\"nofollow noreferrer\">here</a> for semantic segmentation. It seems people have successfully trained such models by removing fully connected layers from the popular pre-trained models such as VGG and adding <em>upsampling</em> and <em>unpooling layers</em>.</p>\n\n<p>I understand that <em>transpose convolution</em> and <em>unpooling</em> in upsampling layers provide counterparts of <em>convolution</em> and <em>max (or average) pooling</em> in earlier downsampling layers respectively, but what are the counterparts for non-linearities such as ReLU? What about dropout? There seems to be no discussion of this in the video.</p>\n", "pids": ["573696056e3b12023e51921c"], "flag": 1}
{"question": "Trading off &quot;Memory&quot; vs &quot;Optimization&quot;", "body": "<p>I've been researching the following topic. Or rather, I would like to but I can't find anything because I'm not sure what to look for.</p>\n\n<p>I am interested weather there are some concepts or models that explain how humans (or cognitive systems in general) trade off <em>remembering</em> what to do in a particular situation versus <em>thinking</em> about the board state and devising a new solution. Consider the following example:</p>\n\n<p>A person plays chess. On their turn they must decide what to do. They could act according to one of the following extreme strategies:</p>\n\n<ol>\n<li>Remembering all possible board configurations and how the game ended (we'll call that <em>Memory</em>)</li>\n<li>Use the known set of rules to <em>simulate</em> the game in their mind and choose the optimal path (<em>Optimization</em>)</li>\n</ol>\n\n<p>I'd say the best choice is a trade off between these two. But how? When to choose one of the strategies?</p>\n\n<p>Is there a research field that is working on these kind of questions? What would I look for?</p>\n", "pids": ["573696026e3b12023e516627"], "flag": 1}
{"question": "Acknowledging local government for quarantine measures", "body": "<p>It looks like I may completely write a paper while in coronavirus-related quarantine.  Would it be appropriate to thank my local government in the acknowledgements?  If I'm honest with myself, I don't think I would have been able to do this with such focus and efficiency if all other aspects of my life hadn't been suddenly shut down.</p>\n\n<p>People often acknowledge visits to other institutions, which seem to serve a similar purpose, hence why I pose the question seriously.</p>\n\n<p>Edit: I'm also in an at-risk group, and the government-mandated quarantine is kind of saving my life, so there's also that.</p>\n", "pids": ["5dfded9cdf1a9c0c41658185"], "flag": 1}
{"question": "Why use two stop UGA codons instead of one in the spike protein mRNA for the BioNTech/Pfizer SARS-CoV-2 vaccine?", "body": "<p>Unlike the SARS-CoV-2 virus, the BioNTech/Pfizer SARS-CoV-2 vaccine <a href=\"https://berthub.eu/articles/posts/reverse-engineering-source-code-of-the-biontech-pfizer-vaccine/\" rel=\"noreferrer\">has two stop UGA codons  at the end of the Spike protein</a>:</p>\n<pre><code>          V   L   K   G   V   K   L   H   Y   T   s             \nVirus:   GUG CUC AAA GGA GUC AAA UUA CAU UAC ACA UAA\nVaccine: GUG CUG AAG GGC GUG AAA CUG CAC UAC ACA UGA UGA \n          V   L   K   G   V   K   L   H   Y   T   s   s          \n               !   !   !   !     ! !   !          ! \n</code></pre>\n<p>What is the motivation behind using two stop UGA codons instead of one in the BioNTech/Pfizer SARS-CoV-2 vaccine?</p>\n", "pids": ["610fb2e85244ab9dcbbb20b1"], "flag": 1}
{"question": "When using neural networks to detect features in an image, how can locate that specific feature in the original image?", "body": "<p>I understand how a neural network can be trained to recognise certain features in an image (faces, cars, ...), where the inputs are the image's pixels, and the output is a set of boolean values indicating which objects were recognised in the image and which weren't.</p>\n\n<p>What I don't really get is, when using this approach to detect features and we detect a face for example, how we can go back to the original image and determine the location or boundaries of the detected face. How is this achieved? Can this be achieved based on the recognition algorithm, or is a separate algorithm used to locate the face? That seems unlikely since to find the face again, it needs to be recognised in the image, which was the reason of using a NN in the first place.</p>\n", "pids": ["58d82fcbd649053542fd6729", "5f156e7091e011d7db223b03", "5736986b6e3b12023e730129", "57a4e921ac44365e35c98fc8", "5c8879574895d9cbc67787cc", "5a260c8117c44a4ba8a30b08", "573696056e3b12023e518676"], "flag": 1}
{"question": "How do features of the work environment such as type of pen or color of paper influence productivity and workplace well-being?", "body": "<p><strong>Background:</strong> Recently I have been doing mathematics a whole lot,and I have noticed that my output varies wildly from many external factors,but mostly it is the enviorment I am working in. Namely one of the most unexpected things is that most my output depends on the quality of pen I am using and kind of notebook I am writing in. Last day I went to buy new notebooks and I laid my eyes upon one with especially distinguishing blue-white color scheme,and in my mind it was already set that it will be notebook I will write abstract algebra into,and truly while using that notebook I feel really motivated, it feels like the color of it and the subject of abstract algebra are intertwined in my brain.</p>\n\n<p><strong>Questions:</strong></p>\n\n<ul>\n<li>What is the phenomena called where features of the work environment such as type of pen or color of paper influence productivity or workplace well-being? </li>\n<li>How can such features be used to improve productivity?</li>\n</ul>\n", "pids": ["53e9a1bcb7602d9702ab44f6", "53e9b923b7602d9704509dd3", "55a4a456612ca648689ea9e8"], "flag": 1}
{"question": "Is there a neural network in the literature that predicts the next game state based on the current state and the action?", "body": "<p>I am trying to find literature on a network architecture that takes the following as in input:</p>\n<ul>\n<li>Action (like 'Up', 'Down', etc)</li>\n<li>Image of the current state</li>\n</ul>\n<p>and outputs:</p>\n<ul>\n<li>Image of next state</li>\n</ul>\n<p>I already have a lot of training data for the inputs. However, I am trying to find relevant literature/architecture for this problem.</p>\n", "pids": ["5736986b6e3b12023e72fdb2"], "flag": 1}
{"question": "Not listed as author despite doing statistical work", "body": "<p>I work in a medical field and recently contributed statistical analysis for a paper and was not listed as a co-author despite being told I would be. I spent a few weeks fielding questions about this paper and feel as though my contribution was significant. There are many people listed who I am certain contributed nothing to this paper.</p>\n<p>Should I say something to my PI or just let it go? I understand the authorship likely can't be added to at this point but I want to express that I am slightly hurt. However since I am not vying for academic jobs I don't want to come off as being needy or petty since it ultimately won't matter for my career.</p>\n<p>Any advice would be appreciated.</p>\n", "pids": ["5fd496ded4150a363cbc01c0"], "flag": 1}
{"question": "Is it fair to compare AlphaGo with a Human player?", "body": "<p>A human player plays limited games compared to a system that undergoes millions of iterations. Is it really fair to compare AlphaGo with the world #1 player when we know experience increases with the increase in number of games played?</p>\n", "pids": ["57a4e921ac44365e35c98f2b"], "flag": 1}
{"question": "Do cognitive distortions not exist at all in non-depressed people?", "body": "<p>Cognitive distortions like <code>All-or-nothing thinking</code>, <code>Fortune Teller Error</code>; do they exist in non-depressed people with a low intensity as well or they do not have these things at all? In other way, having cognitive distortions is the root cause of depression or having those distortions with high intensity is actually the root cause of depression?</p>\n", "pids": ["55a40e0e612ca6486882f339", "5aaad56f1b13da0225bbf38b"], "flag": 0}
{"question": "Beautiful blue enigmatic insect (mantid?) in Kenya", "body": "<p>This beautiful insect was found in Kenya today - and we don’t know what it is. We think it may be a mantid of some sort?!</p>\n<p>Nairobi kenya, croton trees, cape chestnuts, bougainvilliea, there is quite a lot of lichen on the trees.</p>\n<p>Despite looking to be the size of someone's arm, it's about 2” long!\nNeedless to say, no-one had a good camera at the time. Just phones!</p>\n<p>The colour of the insect is very similar to the lichen on the trees (hence the mention above).</p>\n<p>Someone suggested it was a 'grizzled mantid' <em>Gonatista grisea</em> (Fabricius), but we didn't think they are found native to Kenya - and likewise, we don't see a protuberance on the back of grizzled mantids... Still hoping for an answer.</p>\n<p>You can see it also has very small wings, which I hear is a feature of some mantids - micropterous mantids.</p>\n<p>I don’t know anything about these - someone said ‘some sort of bark mantis’.</p>\n<p>Further update - The pronotum of Tarachodes spp females has two conical tubercles. The males are mostly fully winged, whereas the females often have shortened wings.</p>\n<p>So it's probably a female Tarachodes species found in Kenya (or thereabouts).</p>\n<p><a href=\"https://i.stack.imgur.com/9Z1qy.jpg!\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/9Z1qy.jpg!\" alt=\"On a bat\" /></a>\n<a href=\"https://i.stack.imgur.com/M7NqV.jpg!\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/M7NqV.jpg!\" alt=\"less blurred\" /></a>\n<a href=\"https://i.stack.imgur.com/eGM1P.jpg!\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/eGM1P.jpg!\" alt=\"head - blurred\" /></a>\n<a href=\"https://i.stack.imgur.com/ctzgE.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/ctzgE.jpg\" alt=\"in the light\" /></a>\n<a href=\"https://i.stack.imgur.com/kD5qO.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/kD5qO.jpg\" alt=\"again\" /></a></p>\n", "pids": ["5c756e42f56def97985b0e67"], "flag": 1}
{"question": "Other emotions relative to angry/happy base emotions", "body": "<p>In my layman's experience, I'm vaguely aware there are four base emotions: <strong>happy, sad, afraid/surprised, and angry/disgusted</strong>.<sup><a href=\"http://www.theatlantic.com/health/archive/2014/02/new-research-says-there-are-only-four-emotions/283560/\" rel=\"nofollow\">1</a></sup></p>\n\n<p>Some background:  We're training an AI to learn the difference between happy voices and angry voices.  We've had some success, by showing it 200 <strong>angry</strong> audio clips, 200 <strong>happy</strong> audio clips, and 200 <strong>neutral</strong>.  It can now reasonably tell when we're talking pleasantly or confrontationally... but the accuracy could be better.</p>\n\n<p>Our total training dataset is made up of these audio clips: <strong>Happy, angry, neutral, calm, sad, fearful, disgust, and surprised</strong>. I think we can be more accurate by including these emotions.  </p>\n\n<p>But this is the problem:</p>\n\n<p>Happy/angry/neutral span opposite ends of a spectrum; like binary.  It's easy to say:</p>\n\n<pre><code>Happy     1\nNeutral   0\nAngry    -1\n</code></pre>\n\n<p>That's the shape of the data we need to train a neural network to recognize 'Happy'. </p>\n\n<p>So the question would be, is there any 'right answer' on filling in these blanks?  I've given it my best guesses below, but I'm hoping for something more scientific....</p>\n\n<pre><code>Happy     1\nAngry    -1\nNeutral   0\nCalm      X  (0.5?)\nSad       X  (-1?)\nFearful   X  (-0.5?)\nDisgust   X  (-0.75?)\nSurprised X  (0.75?)\n</code></pre>\n\n<p><sub> \n1: <a href=\"http://www.theatlantic.com/health/archive/2014/02/new-research-says-there-are-only-four-emotions/283560/\" rel=\"nofollow\">http://www.theatlantic.com/health/archive/2014/02/new-research-says-there-are-only-four-emotions/283560/</a>\n</sub></p>\n", "pids": ["53e9b732b7602d97042ca31b", "573698816e3b12023e740961"], "flag": 1}
{"question": "Create captions based on a series of images", "body": "<p>I'd like to generate subtitles for a silent film. Is there an open source project out there capable of creating captions based on a series of images (such as a scene from a movie)?</p>\n\n<p>EDIT: thanks for the comments below. To clarify, what i'm looking for is an algorithm which can generate a caption for a sequences of images within a movie  describing what happens in the sequence. This is for preliminary research, so accuracy is less important. </p>\n", "pids": ["5c86fcaa4895d9cbc6bf3d15", "5b1643ba8fbcbf6e5a9bc575", "573696f46e3b12023e5f0ee9", "5b67b4b417c44aac1c867550"], "flag": 1}
{"question": "What personality disorders is schema therapy successfully used for?", "body": "<p>Schema therapy is a cognitive therapy based on people developing so-called \"schemas\" (as far as I understand, patterns of cognition and behavior) early in their lives and then using these schemas to their detriment later. Schema therapy is based on identifying these schemas and leading the patient to develop different mechanisms of dealing with these situations. (if any of that is very incorrect, I'd be happy to be corrected) </p>\n\n<p>What personality disorders is this technique successfully used for? Are there any where it is recommended against? </p>\n", "pids": ["5c756b6ff56def97983df55e", "55a474a165ce31bc877b5d66", "55a520bd65ceb7cb02e1bb0e", "56d91399dabfae2eee4b04ef"], "flag": 0}
{"question": "Could physically simulating neural structure on a fundamental level yield superior results to machine learning algorithms?", "body": "<p>My curiosity is merely of whether (in a future where we have computers with the processing power of the human brain) it's possible that actually simulating a neural network's physical <em>behavior</em> on the most fundamental level might be more effective than using algorithms to reach the same result.</p>\n\n<p>I'm hoping for an answer which argues this topic on a purely fundamental level. </p>\n\n\n\n<p>Is it likely (or not) that we might achieve a superior (more efficient, more intelligent, more dynamic) result by simulating the advanced behavior of neural interaction (the neuro-activity patterns the brain experiences to form emotions, develop conclusions, processes sensory data, establish and/or revisit memories, etc) than we can reach by using shortcuts (advanced machine learning algorithms, etc)? </p>\n", "pids": ["53e9b2d7b7602d9703d8a78c"], "flag": 0}
{"question": "What are the major differences between cost, loss, error, fitness, utility, objective, criterion functions?", "body": "<p>I find the terms cost, loss, error, fitness, utility, objective, criterion functions to be interchangeable, but any kind of minor difference explained is appreciated.</p>\n", "pids": ["5c8928214895d9cbc6b436ff"], "flag": 1}
{"question": "What does &quot;reimplementations of deep learning algorithms which replicate performance from the papers&quot; mean?", "body": "<p>In the <a href=\"https://startup.jobs/3993-machine-learning-fellow-at-openai\" rel=\"nofollow noreferrer\">OpenAI's Machine Learning Fellow position</a>, it is written</p>\n<blockquote>\n<p>We look for candidates with one or more of the following credentials:</p>\n<ul>\n<li>...</li>\n<li>Open-source reimplementations of deep learning algorithms which replicate performance from the papers</li>\n</ul>\n</blockquote>\n<p>What exactly do they mean by this? Do they want us to implement the algorithms exactly as described in the papers (i.e. with the same hyper-parameters, weights, etc.)?</p>\n", "pids": ["5f7c57a391e0117ac2a78c4a"], "flag": 1}
{"question": "How to model a multi-agent reinforcement learning problem where actions of different agents can take different durations?", "body": "<p>I am confused on a conceptual scale how I would be able to model a multi-agent reinforcement learning problem when each agent performing an action would take different durations to complete the action. This means that a certain action is performed over multiple steps and the learning sample would have that action attached to it (with different observations and rewards, possibly).</p>\n<p>An example of this situation would be where vehicles on a 2-lane road can perform lane changing actions, but each of these actions may take anywhere between 2 - 5 seconds (or learning steps) to complete.</p>\n<p>So, what action would need to be passed at every step? I am using RLlib framework. Is it even possible to do this? Or do all these agents have to have the same action duration / step length for any RL algorithm to work?</p>\n<p>I would greatly appreciate if anyone could point me in the right direction on bypassing this mental block, it is driving me crazy.</p>\n", "pids": ["53e9a9ebb7602d970334f800", "5de0d28fdf1a9c0c415b5881", "64a0bbfed68f896efaad288a"], "flag": 1}
{"question": "Vigilance is an emotion?", "body": "<p><a href=\"https://i.stack.imgur.com/sfWo3.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/sfWo3.png\" alt=\"enter image description here\"></a></p>\n\n<p>I've always loved pondering emotion theories and usually agree with them, but Plutchik describes the intense form of anticipation to be Vigilance, and this is quite confusing to me.</p>\n\n<p>Vigilance as defined on wiki:</p>\n\n<p>\"In modern psychology, vigilance, also termed sustained concentration, is defined as the ability to maintain concentrated attention over prolonged periods of time.\"</p>\n\n<p>This describes a character trait and not an emotion. So my question is has the meaning of vigilance changed since Plutchik's theory, and if so what would be the modern equivalent of this emotion. Or did Plutchik drop the ball on this part of an otherwise excellent theory.</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 0}
{"question": "How can I detect thin objects (like pens and pencils) without a bounding box but only 2 endpoints and the orientation?", "body": "<p>I am looking to detect thin objects, like pens, pencils, and surgical instruments. The bounding box is not important, but I am looking to see if I can train a model to detect both the object as well as its orientation.</p>\n<p>Typical object detection networks, like R-CNN, YOLO, and SSD encode the class name and bounding boxes. Instead of bounding boxes, I'm looking to encode only 2 points, one starting <span class=\"math-container\">$x,y$</span> point and one ending <span class=\"math-container\">$x,y$</span> point.  The start point for objects is where one would grip the object.  For instance:</p>\n<ul>\n<li>The pencil eraser(start point) is pointed 50 degrees to the top right.</li>\n<li>The surgical instrument is 10 degrees from the x-axis and the handle is pointed to the bottom right.</li>\n<li>Pen tip (endpoint) is pointing vertically upwards.</li>\n<li>Fork, the start point would be the grip handle part, and the endpoint would be in the middle where the 4 prongs are.</li>\n</ul>\n<p>As long as I can encode the start and endpoints, then I can determine the orientation. I would need to define these points during training.</p>\n<p>The question is whether there is an existing model (mobile net/inception/RCNN) that I can encode this information in?  One potential way I was thinking was to use YOLO and for the bounding box, the top left <span class=\"math-container\">$x,y$</span> would be the starting point <span class=\"math-container\">$x,y$</span> (handle), whereas the bounding box's width and height would be replaced with the endpoint <span class=\"math-container\">$x,y$</span> (pencil writing tip, fork prongs.</p>\n", "pids": ["573696126e3b12023e5246cc"], "flag": 1}
{"question": "Can I apply DQN or policy gradient algorithms in the contextual bandit setting?", "body": "<p>I have a problem which I believe can be described as a contextual bandit. </p>\n\n<p>More specifically, in each round, I observe a context from the environment consisting of five continuous features, and, based on the context, I have to choose one of the ten available actions. The actions do not influence the next context.</p>\n\n<p>Based on the above I have the following questions:</p>\n\n<ol>\n<li><p>Is this a contextual bandit or an MDP with a discount equal to zero (one step RL)? I have read that, in contextual bandits, we receive a different context for each action and I am a little bit confused.</p></li>\n<li><p>Can I use the DQN algorithm with TD Target only the observed reward instead of the reward plus the predicted value of the next state?</p></li>\n<li><p>Can I use a policy gradient algorithm, like REINFORCE or A2C? If yes, should I use a baseline and what this baseline should be?</p></li>\n<li><p>I have seen in the literature that there are some algorithms for contextual bandits such as LinUCB, LinRel, NeuralBandit, etc. And I am wondering why the DQN, A2C and REINFORCE algorithms, which seem to work well in MDP setting, are not used in contextual bandits, given the fact that this problem can be described as an MDP with a discount equal to zero?</p></li>\n</ol>\n", "pids": ["5cd7fa07ced107d4c65bf30d"], "flag": 1}
{"question": "Can a sufficiently complex ANN simulate consciousness?", "body": "<p>Current Artificial Neural Networks (ANNs) are capable of doing variational inference and learning representations and factors to explain the inputs, the outside world.</p>\n\n<p>When the network gets bigger and more complicated, nothing will stop it from trying to explain, learn and predict its own inner states.</p>\n\n<p>I think consciousness can be generated from this close loop process.</p>\n\n<p>I remember that Hofstadter's <a href=\"https://en.wikipedia.org/wiki/G%C3%B6del,_Escher,_Bach\" rel=\"nofollow\">Godel Escher Bach</a> describes similar idea, I am just exicted about thinking it through. I want to know if there are references of similar or opposite ideas. I guess <a href=\"https://en.wikipedia.org/wiki/I_Am_a_Strange_Loop\" rel=\"nofollow\">I am a strange loop</a> is another book about this, but I haven't start reading it.</p>\n", "pids": ["53e9ad48b7602d970372f419"], "flag": 0}
{"question": "Detecting license plate using tensorflow", "body": "<p>I'm currently working on license plate recognition. My system consist of 2 stage: (1) License Plate region extraction &amp; (2) License Plate region recognition.</p>\n\n<p><strong>I'm doing (1) with Raspberry pi 3 model b</strong>. I find license plate candidate first by merging bounding boxes based on their similarity. In this way, i have only 1~7 license plate region proposals. And it took less than .3 seconds. </p>\n\n<p>Now i have to reduce number of region proposal to be around only 1~2 so that i can send these images to server to do job (2). For license plate extraction, I made my own classifier function in tensorflow and the code is below. It gets proposed license plate as input.</p>\n\n<p>First, I resize all license plate to be [120, 60] and converted to gray image. And there are 2 classes: 'plate', 'non_plate'. For non_plate image, i collected various image that might appear in image as background. I have 181 images for 'plate' class and 56 images for 'non_plate' for now, i trained for about 3000 steps so far and current loss is .53 . </p>\n\n<p>When i did prediction on test set,  i encountered problem that for some of plate image, it doesn't recognize license plate which is very obviously license plate image from my eyes. It is okay for me to wrongly recognize non plate image as plate but it is problem if it wrongly recognize plate as non_plate because it will not be sent to server to be fully recognized.</p>\n\n<p>It happens like 10 out of 100 test images and this rate is far worse than i expected. I need help for adressing this problem. Would there be any improvement that i can make? </p>\n\n<p><strong>(1) Is my training set too small to classify between license plate\n    and non license plate? Or is number of steps is too small?</strong></p>\n\n<p><strong>(2) Is my graph structure bad?</strong> I needed to have small graph\n    structure for my raspberry pi to recognize less than 1 second. Could\n    you suggest better structure if it is bad?</p>\n\n<p><strong>(3) Is it bad to resize any proposed image to [120, 60] to be used\n    as input for graph?</strong> I think it loses some information. But isn't\n    this close to roi pooling like used in fast rcnn?</p>\n\n<pre><code> inputs=tf.reshape(features[FEATURE_LABEL],[-1,120 , 60 ,1],name=\"input_node\") #120 x 60 x 1, which is gray\n\nconv1=tf.layers.conv2d(inputs=inputs,\n                       filters=3,\n                       kernel_size=[3,3],\n                       padding='same',\n                       activation=tf.nn.leaky_relu\n                       )\n#conv1 output shape: (batch_size,120,60,3)\n\npool1=tf.layers.max_pooling2d(inputs=conv1,pool_size=[2,2],strides=2,padding='valid')\n\n#pool1 output shape: (batch_size,60,30,3)\n\nconv2=tf.layers.conv2d(inputs=pool1,filters=6,kernel_size=[1,1],padding='same',activation=tf.nn.leaky_relu)\n\n#conv2 output shape: (batch_size, 60,30,6)\n\npool2=tf.layers.max_pooling2d(inputs=conv2,pool_size=[2,2],strides=2,padding='valid')\n\n#pool2 output shape: (batch_size, 30,15,6)\n\nconv3=tf.layers.conv2d(inputs=pool2,filters=9,kernel_size=[3,3],padding='same',activation=tf.nn.leaky_relu)\n\n#conv3 output shape: (batch_size, 30,15,9)\n\npool3=tf.layers.max_pooling2d(inputs=conv3,pool_size=[2,2],strides=2,padding='valid')\n\n#pool3 output shape: (batch_size, 15,7,9)\n\n\n#dense fully connected layer\npool2_flat=tf.reshape(pool3,[-1,15*7*9]) #flatten pool3 output to feed in dense layer\n\ndense1=tf.layers.dense(inputs=pool2_flat,units=120,activation=tf.nn.relu)\n\nlogits=tf.layers.dense(dense1,2) #input for softmax layer\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/vHSZu.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/vHSZu.jpg\" alt=\"training non plate image example\"></a>\n [training non plate image example]\n[<a src=\"https://i.stack.imgur.com/EX3VO.png\" alt=\"training plate image example\">]<a href=\"https://i.stack.imgur.com/EX3VO.png\" rel=\"nofollow noreferrer\">4</a>\n[training plate image example. It is region proposed image]</p>\n", "pids": ["573696056e3b12023e518676"], "flag": 1}
{"question": "What are some resources regarding the complexity of training neural networks?", "body": "<p>In the paper \"<a href=\"https://arxiv.org/abs/1310.6343\" rel=\"nofollow noreferrer\">Provable bounds for learning some deep representations</a>\", an autoencoder like a model is constructed with discrete weights and several results are proven using some random-graph theory, but I never saw any papers similar to this. i.e bounds on neural networks using random graph assumptions. </p>\n\n<p><em>What are some resources (e.g. books or papers) regarding the time and space complexity of training neural networks?</em></p>\n\n<p>I'm particularly interested in convolutional neural networks.</p>\n", "pids": ["5c7574b6f56def979897708f"], "flag": 1}
{"question": "What&#39;s the rationale behind mini-batch gradient descent?", "body": "<p>I am reading a book that states</p>\n<blockquote>\n<p>As the mini-batch size increases, the gradient computed is closer to the 'true' gradient</p>\n</blockquote>\n<p>So, I assume that they are saying that mini-batch training only focuses on decreasing the cost function in a certain 'plane', sacrificing accuracy for speed. Is that correct?</p>\n", "pids": ["5b1643ba8fbcbf6e5a9bc699"], "flag": 1}
{"question": "What is the difference between noise reduction and noise cancellation?", "body": "<p>I had a question about sirens in another section which led to a question in physics section...and I was told my question is more suitable for cognitive science.  So here it goes:</p>\n\n<p>There are many kinds of noises: from a heavy truck going by to the wailing of sirens from an ambulance. Then there is someone next to you snoring. Although they are all bothersome, they can't be the exact same thing?</p>\n\n<p>I've heard people use the term \"white noise\" to cancel out or reduce other noise. Granted I have used various earplugs (which reduce only reduce certain kinds of noise and not that well either), but looking at white noise, I realized there is so much about noise and sounds that I don't know about. For instance there is also brown noise and pink noise. There is a sound's loudness, pitch, timber, direction, frequency, etc.</p>\n\n<p>How do I go about finding the right kind of sound masking for different kinds of sounds like snoring and wailing ambulances?</p>\n", "pids": ["55a5d3fd65ce60f99bf67574"], "flag": 0}
{"question": "What is the proportion of excitatory vs. inhibitory neurons in the feline thalamus?", "body": "<p>Is there a scientific reference on the numbers (or proportion) of excitatory and inhibitory neurons in the thalamus of the cat?</p>\n", "pids": ["53e9b12ab7602d9703baba4b"], "flag": 0}
{"question": "Does epsilon-greedy approach always choose the &quot;best action&quot; (100% of the time) when it does not take the random path?", "body": "<p>I'm now reading <a href=\"https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-7-action-selection-strategies-for-exploration-d3a97b7cceaf\" rel=\"nofollow noreferrer\">the following blog post</a> but on the epsilon-greedy approach, the author implied that the epsilon-greedy approach takes the action randomly with the probability epsilon, and take the best action 100% of the time with probability 1 - epsilon.</p>\n\n<p>So for example, suppose that the epsilon = 0.6 with 4 actions. In this case, the author seemed to say that each action is taken with the following probability (suppose that the first action has the best value):</p>\n\n<ul>\n<li>action 1: 55% (.40 + .60 / 4) </li>\n<li>action 2: 15%</li>\n<li>action 3: 15%</li>\n<li>action 4: 15%</li>\n</ul>\n\n<p>However, I feel like I learned that the epsilon-greedy only takes the action randomly with the probability of epsilon, and otherwise it is up to the policy function that decides to take the action. And the policy function returns the probability distribution of actions, not the identifier of the action with the best value. So for example, suppose that the epsilon = 0.6 and each action has 50%, 10%, 25%, and 15%. In this case, the probability of taking each action should be the following:</p>\n\n<ul>\n<li>action 1: 35% (.40 * .50 + .60 / 4)</li>\n<li>action 2: 19% (.40 * .10 + .60 / 4)</li>\n<li>action 3: 25% (.40 * .25 + .60 / 4)</li>\n<li>action 4: 21% (.40 * .15 + .60 / 4)</li>\n</ul>\n\n<p>Is my understanding not correct here? Does the non-random part of the epsilon (1 - epsilon) always takes the best action, or does it select the action according to the probability distribution?</p>\n", "pids": ["59ae3bf12bbe271c4c71bc64"], "flag": 1}
{"question": "Would YOLO be able to detect objects in &quot;different&quot; positions?", "body": "<p>I have the following question about You Only Look Once (YOLO) algorithm, for object detection.</p>\n<p>I have to develop a neural network to recognize web components in web applications - for example, login forms, text boxes, and so on. In this context, I have to consider that the position of the objects on the page may vary, for example, when you scroll up or down.</p>\n<p>The question is, would YOLO be able to detect objects in &quot;different&quot; positions? Would the changes affect the recognition precision? In other words, how to achieve translation invariance? Also, what about partial occlusions?</p>\n<p>My guess is that it depends on the relevance of the examples in the dataset: if enough translated / partially occluded examples are present, it should work fine.</p>\n<p>If possible, I would appreciate papers or references on this matter.</p>\n<p>(PS: if anyone knows about a labeled dataset for this task, I would really be grateful if you let me know.)</p>\n", "pids": ["58d82fcbd649053542fd6729"], "flag": 1}
{"question": "What are some good approaches that I can use to count the number of people in a crowd?", "body": "<p>What are some good approaches that I can use to count the number of people in a crowd?</p>\n<p>Tracking each person individually is obviously not an option. Any good approaches or some references to research papers would be very helpful.</p>\n", "pids": ["599c798c601a182cd264a74d"], "flag": 1}
{"question": "How to architect a network to find bounding boxes in simple images?", "body": "<p>I have an application where I want to find the locations of objects on a simple, relatively constant background (fixed camera angle, etc). For investigative purposes, I've created a test dataset that displays many characteristics of the actual problem.</p>\n<p>Here's a sample from my test dataset.</p>\n<p><a href=\"https://i.stack.imgur.com/AKV7f.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/AKV7f.png\" alt=\"enter image description here\" /></a></p>\n<p>Our problem description is to <strong>find the bounding box of the single circle in the image</strong>. If there is more than one circle or no circles, we don't care about the bounding box (but we at least need to know that there is no valid single bounding box).</p>\n<p>For my attempt to solve this, I built a CNN that would regress <code>(min_x, min_y, max_y, max_y)</code>, as well as one more value that could indicate how many circles were in the image.</p>\n<p>I played with different architecture variations, but, in general, the architecture a was very standard CNN (3-4 ReLU convolutional layers with max-pooling in between, followed by a dense layer and an output layer with linear activation for the bounding box outputs, set to minimise the mean squared error between the outputs and the ground truth bounding boxes).</p>\n<p>Regardless of the architecture, hyperparameters, optimizers, etc, the result was always the same - <strong>the CNN could not even get close to building a model</strong> that was able to regress an accurate bounding box, even with over 50000 training examples to work with.</p>\n<p>What gives? Do I need to look at using another type of network as CNNs are more suited to classification rather than localisation tasks?</p>\n<p>Obviously, there are computer vision techniques that could solve this easily, but due to the fact that the actual application is more involved, I want to know strictly about NN/AI approaches to this problem.</p>\n", "pids": ["5f156e7091e011d7db223b03"], "flag": 1}
{"question": "Clarification regarding &quot;Image Crowd Counting Using Convolutional Neural Network and Markov Random Field&quot;", "body": "<p>I am currently reading the research paper <a href=\"https://arxiv.org/pdf/1706.03686.pdf\" rel=\"nofollow noreferrer\">Image Crowd Counting Using Convolutional Neural Network and Markov Random Field</a>  by Kang Han, Wanggen Wan, Haiyan Yao, and Li Hou. <br/>\nI did not understand the following context properly: </p>\n\n<blockquote>\n  <p>We employ the residual network, which is trained on ImageNet dataset for image classication task, to extract the deep features to represent the density of the crowd. This pre-trained CNN network created a residual item for every three convolution layer to bring the layer of the network to 152. We resize the image patches to the size of 224 × 224 as the input of the model and extract the output of the fc1000 layer to get the 1000 dimensional features. The features are then used to train 5 layers fully connected neural network. The network's input is 1000dimensional, and the number of neurons in the network is given by 100-100-50-50-1. The network's output is the local crowd count</p>\n</blockquote>\n\n<p>Can anyone explain the above part in detail? </p>\n", "pids": ["573696026e3b12023e515eec"], "flag": 1}
{"question": "What is the intuition behind grid-based solutions to POMDPs?", "body": "<p>After spending some time reading about POMDP, I'm still having a hard time understanding how grid-based solutions work.</p>\n\n<p>I understand the finite horizon brute-force solution, where you have your current belief distribution, enumerate every possible collection of action/observation combinations for a given depth and find the expected reward.</p>\n\n<p>I have tried to read some sources about grid-based approximations, for example, <a href=\"https://www.cs.uic.edu/~piotr/cs594/bharanee-houskreht.pdf\" rel=\"nofollow noreferrer\">these slides</a> describe the grid-based approach.</p>\n\n<p>However, it's not clear to me what exactly is going on. I'm not understanding how the value function is actually computed. After you take an action, how do you update your belief states to be consistent with the grid? Does the grid-based solution simply reduce the set of belief states? How does this reduce the complexity of the problem? </p>\n\n<p>I'm not seeing how this reduces the number of actions, observation combinations needed to be considered for a finite-horizon solution. </p>\n", "pids": ["573696816e3b12023e58cd57"], "flag": 1}
{"question": "DQN Breakout adding an extra negative reward to help training?", "body": "<p>I'm trying to train a DQN, so I'm using OpenAI gym and Breakout (<a href=\"https://gym.openai.com/envs/Breakout-v0/\" rel=\"nofollow noreferrer\">Breakout-v0</a>).</p>\n\n<p>I have altered the reward supplied by the environment: If the episode is not completed fully, the agent gets a -10 reward. Could be this counterproductive for learning?</p>\n", "pids": ["5a260c8117c44a4ba8a30ecc"], "flag": 1}
{"question": "How can I design a reinforcement learning model for a game with multiple complex actions taken at a time?", "body": "<p>I have a steady hex-map and turn-based wargame featuring WWII carrier battles.</p>\n<p>On a given turn, a player may choose to perform a large number of actions. Actions can be of many different types, and some actions may be performed independently of each other while others have dependencies. For example, a player may decide to move one or two naval units, then assign a mission to an air unit or not, then adjust some battle parameters or not, and then reorganize a naval task force or not.</p>\n<p> Usually, boardgames allow players to perform only one action each turn (e.g. go or chess) or a few very similar actions (backgammon).</p>\n<p>Here the player may select</p>\n<ul>\n<li>Several actions</li>\n<li>The actions are of different nature</li>\n<li>Each action may have parameters that the player must set (e.g. strength, payload, destination)</li>\n</ul>\n<p><strong>How could I approach this problem with reinforcement learning? How would I specify a model or train it effectively to play such a game?</strong></p>\n<p>Here is a screenshot of the game.</p>\n<p><a href=\"https://i.stack.imgur.com/21wjd.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/21wjd.png\" alt=\"enter image description here\" /></a></p>\n<p>Here's another.</p>\n<p><a href=\"https://i.stack.imgur.com/vgUiV.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/vgUiV.png\" alt=\"enter image description here\" /></a></p>\n", "pids": ["59ae3bf12bbe271c4c71bc64"], "flag": 1}
{"question": "Method to check goodness of combinatorial optimization algorithm implementation", "body": "<p>How do I check which algorithm solves my problem best?</p>\n\n<p>Given a optimaization problem, I apply different well known optimization algorithms (genetic algorithm, simulated annealing, ant colony etc.) to solve my problem. However, how do I know if my implementation ( e.g. cost function) is working for every case? How can I compare the algorithms or their goodness in the context of my problem?</p>\n", "pids": ["5b6685f6ab2dfb45920f15bb"], "flag": 1}
{"question": "How to find the category of a technical text on a surface-semantic-level", "body": "<p>There are some predefined categories( Overview, Data Architecture, Technical Details, Applications, etc). The requirement is to classify the input text of paragraphs into their resp. category. I can't use any pre-trained word embeddings (Word2Vec, Glove) because the data entered is not in general English ( talking about dogs, environment, etc) but pure technical (How does a particular program orks, steps to download anaconda, etc). Don't have any data available on the internet to train as well. Anything that understands semantic-surface-level of a sentence will work</p>\n", "pids": ["5736980d6e3b12023e6e4045"], "flag": 1}
{"question": "What is the next state for a two-player board game?", "body": "<p>I'm using Q-learning to train an agent to play a board game (e.g. chess, draughts or go). </p>\n\n<p>The agent takes an action while in state <span class=\"math-container\">$S$</span>, but then what is the next state (that is,  <span class=\"math-container\">$S'$</span>)? Is <span class=\"math-container\">$S'$</span> now the board with the piece moved as a result of taking the action, or is <span class=\"math-container\">$S'$</span> the state the agent encounters after the other player has performed his action (i.e. it's this agent's turn again)?</p>\n", "pids": ["5a260c0c17c44a4ba8a1e155"], "flag": 1}
{"question": "how to normalize the state space for articulated robot environments?", "body": "<p>What is the common representation used for the state in articulated robot environments? My first guess is that it's a set of the angles of every joint. Is that correct? My question is motivated by the fact that one common trick that helps training neural nets in general is to normalize the inputs, like setting mean = 0 and std dev = 1, or scaling all the input values to <span class=\"math-container\">$[0, 1]$</span>, which could be easily done in this case too if all the inputs are angles in <span class=\"math-container\">$[0, 2 \\pi]$</span>. But, what about distances? Is it common to, for example, use as input some distance of the agent to the ground, or a distance to some target position? In that case, the scale of the distances can be arbitrary and vary a lot. What are some common ways to deal with that?</p>\n", "pids": ["5bdc315817c44a1f58a06331"], "flag": 1}
{"question": "What are examples of daily life applications that use simulated annealing?", "body": "<p>In AIMA, 3rd Edition on Page 125, Simulated Annealing is described as:</p>\n\n<blockquote>\n  <p>Hill-climbing algorithm that <em>never</em> makes “downhill” moves toward states with lower value (or higher cost) is guaranteed to be incomplete, because it can get stuck on a local maximum. In contrast, a purely random walk—that is, moving to a successor chosen uniformly at random from the set of successors—is complete but extremely inefficient. Therefore, it seems reasonable to try to combine hill climbing with a random walk in some way that yields both efficiency and completeness. Simulated annealing is such an algorithm. In metallurgy, <strong>annealing</strong> is the process used to temper or harden metals and glass by heating them to a high temperature and then gradually cooling them, thus allowing the material to reach a lowenergy crystalline state. To explain simulated annealing, we switch our point of view from hill climbing to <strong>gradient descent</strong> (i.e., minimizing cost) and imagine the task of getting a\n  ping-pong ball into the deepest crevice in a bumpy surface. If we just let the ball roll, it will come to rest at a local minimum. If we shake the surface, we can bounce the ball out of the local minimum. The trick is to shake just hard enough to bounce the ball out of local minima but not hard enough to dislodge it from the global minimum. The simulated-annealing solution is to start by shaking hard (i.e., at a high temperature) and then gradually reduce the intensity of the shaking (i.e., lower the temperature)</p>\n</blockquote>\n\n<p>I know its about its example, but I just want more examples where Stimulated Annealing used in daily life </p>\n", "pids": ["5c6108d2da56297340b51bf2", "56d9154fdabfae2eee55fb45"], "flag": 1}
{"question": "Where are reinforcement algorithms used in financial services?", "body": "<p>One of the most common misconceptions about reinforcement learning (RL) applications is that, once you deploy them, they continue to learn. And, usually, I'm left having to explain this. As part of my explanations, I like to show where it is being used and where not.</p>\n<p>I've done a little bit of research on the topic, but the descriptions seem fairly academic, and I'm left with the opinion that reinforcement learning is <strong>not</strong> really suitable for financial services in regulated markets.</p>\n<p>Am I wrong? If so, I would like to know where RL is being used? Also, in those cases, are these RL algorithms adapting to new data over time? How do you ensure they are not picking up on data points or otherwise making decisions that are considered to be unacceptable?</p>\n", "pids": ["5c8b8b5e4895d9cbc698479e"], "flag": 1}
{"question": "Mismatch between the definition of the GAN loss function in two papers", "body": "<p>I was trying to understand the loss function of GANs, but I found a little mismatch between different papers.</p>\n<p>This is taken from <a href=\"https://arxiv.org/pdf/1406.2661.pdf\" rel=\"nofollow noreferrer\">the original GAN paper</a>:</p>\n<blockquote>\n<p>The adversarial modeling framework is most straightforward to apply when the models are both multilayer perceptrons. To learn the generator's distribution <span class=\"math-container\">$p_{g}$</span> over data <span class=\"math-container\">$\\boldsymbol{x}$</span>, we define a prior on input noise variables <span class=\"math-container\">$p_{\\boldsymbol{z}}(\\boldsymbol{z})$</span>, then represent a mapping to data space as <span class=\"math-container\">$G\\left(\\boldsymbol{z} ; \\theta_{g}\\right)$</span>, where <span class=\"math-container\">$G$</span> is a differentiable function represented by a multilayer perceptron with parameters <span class=\"math-container\">$\\theta_{g} .$</span> We also define a second multilayer perceptron <span class=\"math-container\">$D\\left(\\boldsymbol{x} ; \\theta_{d}\\right)$</span> that outputs a single scalar. <span class=\"math-container\">$D(\\boldsymbol{x})$</span> represents the probability that <span class=\"math-container\">$\\boldsymbol{x}$</span> came from the data rather than <span class=\"math-container\">$p_{g}$</span>. We train <span class=\"math-container\">$D$</span> to maximize the probability of assigning the correct label to both training examples and samples from <span class=\"math-container\">$G$</span>. We simultaneously train <span class=\"math-container\">$G$</span> to minimize <span class=\"math-container\">$\\log (1-D(G(\\boldsymbol{z})))$</span> :</p>\n<p>In other words, <span class=\"math-container\">$D$</span> and <span class=\"math-container\">$G$</span> play the following two-player minimax game with value function <span class=\"math-container\">$V(G, D)$</span> :</p>\n</blockquote>\n<p><span class=\"math-container\">$$\n\\min _{G} \\max _{D} V(D, G)=\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\text {data }}(\\boldsymbol{x})}[\\log D(\\boldsymbol{x})]+\\mathbb{E}_{\\boldsymbol{z} \\sim p_{\\boldsymbol{z}}(\\boldsymbol{z})}[\\log (1-D(G(\\boldsymbol{z})))]\n$$</span></p>\n<p>Equation (1) in this version of <a href=\"https://arxiv.org/pdf/1611.07004.pdf\" rel=\"nofollow noreferrer\">the pix2pix paper</a></p>\n<blockquote>\n<p>The objective of a conditional GAN can be expressed as\n<span class=\"math-container\">$$\n\\begin{aligned}\n\\mathcal{L}_{c G A N}(G, D)=&amp; \\mathbb{E}_{x, y}[\\log D(x, y)]+\\\\\n&amp; \\mathbb{E}_{x, z}[\\log (1-D(x, G(x, z))],\n\\end{aligned}\n$$</span>\nwhere <span class=\"math-container\">$G$</span> tries to minimize this objective against an adversarial <span class=\"math-container\">$D$</span> that tries to maximize it, i.e. <span class=\"math-container\">$G^{*}=$</span> <span class=\"math-container\">$\\arg \\min _{G} \\max _{D} \\mathcal{L}_{c G A N}(G, D)$</span>.</p>\n<p>To test the importance of conditioning the discriminator, we also compare to an unconditional variant in which the discriminator does not observe <span class=\"math-container\">$x$</span> :\n<span class=\"math-container\">$$\n\\begin{aligned}\n\\mathcal{L}_{G A N}(G, D)=&amp; \\mathbb{E}_{y}[\\log D(y)]+\\\\\n&amp; \\mathbb{E}_{x, z}[\\log (1-D(G(x, z))] .\n\\end{aligned}\n$$</span></p>\n</blockquote>\n<p>Putting aside the fact that pix2pix is using conditional GAN, which introduces a second term <span class=\"math-container\">$y$</span>, the 2 formulas are quite resemble, except that in the pix2pix paper, they try to get minimax of <span class=\"math-container\">${\\cal{L}}_{cGAN}(G, D)$</span>, which is defined to be <span class=\"math-container\">$E_{x,y}[...] + E_{x,z}[...]$</span>, whereas in the original paper, they define <span class=\"math-container\">$\\min\\max V(G, D) = E[...] + E[...]$</span>.</p>\n<p>I am not coming from a good math background, so I am quite confused. I'm not sure where the mistake is, but assuming that <span class=\"math-container\">$E$</span> is expectation (correct me if I'm wrong), the version in pix2pix makes more sense to me, although I think it's quite less likely that Goodfellow could make this mistake in his amazing paper. Maybe there's no mistake at all and it's me who do not understand them correctly.</p>\n", "pids": ["58d82fced649053542fd7289", "5e3a928fdf1a9c0c41ebe39e"], "flag": 1}
{"question": "Which matrix represents the similarity between words when using SVD?", "body": "<p>Two words can be similar if they co-occur \"a lot\" together. They can also be similar if they have similar vectors. This similarity can be captured using cosine similarity. Let <span class=\"math-container\">$A$</span> be a <span class=\"math-container\">$n \\times n$</span> matrix counting how often <span class=\"math-container\">$w_i$</span> occurs with <span class=\"math-container\">$w_k$</span> for <span class=\"math-container\">$i,k = 1, \\dots, n$</span>. Since computing the cosine similarity between <span class=\"math-container\">$w_i$</span> and <span class=\"math-container\">$w_k$</span> might be expensive, we approximate <span class=\"math-container\">$A$</span> using truncated SVD with <span class=\"math-container\">$k$</span> components as: <span class=\"math-container\">$$A \\approx W_k \\Sigma W^{T}_{k} = CD$$</span></p>\n\n<p>where <span class=\"math-container\">$$C = W_{k} \\Sigma \\\\ D = W^{T}_{k}$$</span></p>\n\n<p>Where are the cosine similarities between the words <span class=\"math-container\">$w_i$</span> and <span class=\"math-container\">$w_k$</span> captured? In the <span class=\"math-container\">$C$</span> matrix or the <span class=\"math-container\">$D$</span> matrix?</p>\n", "pids": ["53e9b3b2b7602d9703e999b3"], "flag": 1}
{"question": "What kind of functions can be used as activation functions?", "body": "<p>I read that functions are used as activation functions only when they are differentiable. What about the unit step activation function? So, is there any other reason a function can be used as an activation function (apart from being differentiable)?</p>\n", "pids": ["599c7987601a182cd2647bb8"], "flag": 1}
{"question": "Is it a good idea to use BERT to answer a FAQ with semantic similarity?", "body": "<p>I have been looking for BERT for many tasks. I would like to compare the performance to answer an FAQ, using BERT semantic similarity and BERT Q/A. \nHowever, I'm not sure it is a good idea to use semantic similarity for this task. If it is, do you think it is possible to find a dataset to fine-tune my algorithm? </p>\n", "pids": ["5cf48a28da56291d58289c11"], "flag": 1}
{"question": "Does the lexical hypothesis have any role in &#39;creativity&#39;?", "body": "<p>The <a href=\"https://en.wikipedia.org/wiki/Lexical_hypothesis\" rel=\"nofollow\">lexical hypothesis</a> was used to I think <em>create</em> the 5 factor model of personality.</p>\n\n<p>Has anything similar been done in the science of 'creativity'?</p>\n\n<p>While, clearly, \"creativity\" is a component of intelligence, even if it is also one in personality.</p>\n\n\n\n<p>What got me thinking about this, is the measurement of 'creativity', which is I think notoriously difficult, even more so that aptitude in general. Specifically, I was thinking about how it seems that 'fluency' seems lexically close to some terms close to creativity.</p>\n\n<p>How would <em>general</em> cognitive fluency, as it is measured by cognitive test, correlate with creativity?</p>\n\n\n\n<p>fluency, noun</p>\n\n<ul>\n<li>the ability to express oneself easily and articulately.</li>\n</ul>\n\n<p>fantasy, noun</p>\n\n<ul>\n<li>a fanciful mental image, typically one on which a person often dwells and which reflects their conscious or unconscious wishes</li>\n</ul>\n\n<p>imagination, noun</p>\n\n<ul>\n<li>the faculty or action of forming new ideas, or images or concepts of \nexternal objects not present to the senses.</li>\n</ul>\n\n<p>etc.</p>\n", "pids": ["53e9aab7b7602d970343546a", "55a54c7c65ceb7cb02e773be"], "flag": 0}
{"question": "Is it mostly the case to train with available models", "body": "<p>I quite often find projects using pre-trained model and using them as a starting point for their new model that learns something novel from thier dataset or on-live learning process - e.g. using a webcam or live audio.</p>\n\n<p>Is this quite usual and recommended to speed up training a model? For example using a model trained on ImageNet as a first layer to your model that will categorise faces specifically.</p>\n", "pids": ["5550415645ce0a409eb3a69e"], "flag": 1}
{"question": "Do we have cross-language vector space for word embedding?", "body": "<p>Do we have cross-language vector space for word embedding?</p>\n\n<p>When measure similarity for apple/Pomme/mela/Lacus/苹果/りんご, they should be the same</p>\n\n<p>If would be great if there's available internet service of neuron network which already be trained by multiple language</p>\n", "pids": ["5a260c8417c44a4ba8a3157c", "610bc3af5244ab9dcba57815", "5a260c8417c44a4ba8a3157c"], "flag": 1}
{"question": "how to benefit from previous training weights in training again to increase accuracy?", "body": "<p>I have trained  a modified VGG classification CNN, with random initialized weights; therefor the validation accuracy was not high enough for me to accept (around 66%). \nnow using the weights resulted from training the network, how can i use those weights in training the network again to improve accuracy? (e.g. using previous training weights with different learning rate, or increase epochs, ..)</p>\n", "pids": ["5a73cb4d17c44a0b3035672a", "5550414c45ce0a409eb39fa8"], "flag": 1}
{"question": "What are the differences between Orch OR and Hartley&#39;s vibratiuncles?", "body": "<p>Roger Penrose and Stuart Hameroff have a theory called <strong><em><a href=\"https://www.sciencedaily.com/releases/2014/01/140116085105.htm\" rel=\"nofollow noreferrer\">Orgastrated Objective Reduction</a></em></strong> or Orch OR, and they claim this has been confirmed. The article says:</p>\n\n<blockquote>\n  <p>\"The origin of consciousness reflects our place in the universe, the nature of our existence. Did consciousness evolve from complex computations among brain neurons, as most scientists assert? Or has consciousness, in some sense, been here all along, as spiritual approaches maintain?' ask Hameroff and Penrose in the current review. 'This opens a potential Pandora's Box, but our theory accommodates both these views, <strong>suggesting consciousness derives from quantum vibrations in microtubules</strong>, protein polymers inside brain neurons, which both govern neuronal and synaptic function, and connect brain processes to self-organizing processes in the fine scale, 'proto-conscious' quantum structure of reality.\"</p>\n</blockquote>\n\n<p>In the 18th century, <a href=\"https://en.wikipedia.org/wiki/David_Hartley_(philosopher)\" rel=\"nofollow noreferrer\"><strong>David Hartley</strong></a> proposed in his book <strong><em><a href=\"https://en.wikipedia.org/wiki/Observations_on_Man\" rel=\"nofollow noreferrer\">Observations of Man</a></em></strong> that counciousness arises when particles of matter vibrate in our brain. Wikipedia says:</p>\n\n<blockquote>\n  <p>Hartley's physical theory gave birth to the modern study of the intimate connection of physiological and psychical facts. He believed that <strong>sensation is the result of a vibration of the minute particles of the medullary substance of the nerves</strong>, to account for which he postulated, with Newton, a subtle elastic ether, rare in the interstices of solid bodies and in their close neighbourhood, and denser as it recedes from them. Pleasure is the result of moderate vibrations, pain of vibrations so violent as to break the continuity of the nerves. <strong>These vibrations leave behind them in the brain a tendency to fainter vibrations or \"vibratiuncles\" of a similar kind, which correspond to \"ideas of sensation.\"</strong> This accounts for memory.</p>\n</blockquote>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Joseph_Priestley\" rel=\"nofollow noreferrer\"><strong>Joseph Priestley</strong></a> expanded on this idea in his essay <strong><em><a href=\"https://en.wikipedia.org/wiki/Disquisitions_relating_to_Matter_and_Spirit\" rel=\"nofollow noreferrer\">Disquisitions Relating to Matter and Spirit</a></em></strong>. Priestley believed that all matter had the power of attraction and repulsion  (<a href=\"https://hsm.stackexchange.com/questions/5265/was-joseph-priestley-describing-fundamental-interactions-in-the-18th-century\">fundamental interactions?</a>) and that perception and thought arises from this phenomena in our brain through <strong><em><a href=\"https://en.wikipedia.org/wiki/Association_of_ideas\" rel=\"nofollow noreferrer\">association</a></em></strong>. Priestley says:</p>\n\n<blockquote>\n  <p><strong>Nothing but a precise and definite knowledge of the nature of perception and thought can authorize any person to affirm, whether they may not belong to an extended substance, which has also the properties of attraction and repulsion.</strong> Seeing, therefore, no sort of reason to imagine that these different properties are really inconsistent any more than the different properties of resistance and extension, I am, of course, under the necessity of being guided by the phenomena in my conclusions concerning the proper feat of the powers of perception and thought.</p>\n</blockquote>\n\n<p>Giving Hartley and Priestley a little latitude because they lived 300 years ago, is Orch OR basically a reworking of their theories?</p>\n", "pids": ["53e99fd0b7602d97028adc12"], "flag": 0}
{"question": "What does ΔC and ΔN mean with regards to a protein sequence?", "body": "<p>I am reading a <a href=\"https://www.researchgate.net/profile/Trevor_Dale/publication/11165081_The_Regulation_of_Glycogen_Synthase_Kinase-3_Nuclear_Export_by_FratGBP/links/09e41510bb9aa7e04a000000.pdf\" rel=\"noreferrer\">paper</a> about the regulation of the nuclear export of the protein GSK3 and I have come across the following statement:</p>\n<blockquote>\n<p>Full-length FLAG epitope-tagged mFrat1 (FLAG-Frat) and the\namino-terminal half of Frat (ΔC Frat) localized predominantly to the\ncytoplasm of transfected MDCK cells (Fig. 1, A and B, i and iii).\nUnexpectedly, the carboxyl-terminal half of Frat (ΔN Frat) accumulated\npreferentially in the nuclei of transfected cells (Fig. 1B, iv).</p>\n</blockquote>\n<p>I am not sure why the amino-terminal and carboxyl-terminal half of the Frat protein are referred to as ΔC Frat and ΔN Frat respectively. I know that the amino terminus of a protein is also referred to as the N-terminus, whilst the carboxyl terminus of a protein is referred to as the C-terminus. I am not sure why in this paper ΔC and ΔN are used to refer to the amino-terminal and carboxyl-terminal half of the Frat protein.</p>\n<p>Any insights are appreciated.</p>\n", "pids": ["53e99ba2b7602d9702448e60", "55a59892612c6b12ab25972f"], "flag": 1}
{"question": "How to add some data input in a CNN?", "body": "<p>There is this problem I have encountered, I was trying to classify the pixels from input image into classes, sort of like segmentation, using a encoder-decoder CNN. The “interested” pixels usually locate in the top right corner of the input image, but the input images are too big, which I have to slice them in patches, by doing this, each input patch loses its “which region of the whole picture it’s from” information.</p>\n\n<p>I'm using pytorch, I thought of manually add this patch location info into the input, but then it will be convoluted, which does make sense to me since it's not a part of an image.</p>\n\n<p>I'm new to this, not sure if I'm thinking the whole thing right, how should I manually add this info into the input correctly or if there is some keywords I can do some researches, in order to let the CNN taking position into account? Thank you.</p>\n", "pids": ["599c7987601a182cd2648373", "5e63725891e011ae97a699ec"], "flag": 1}
{"question": "Is there anything called genetic anxiety?", "body": "<p>We inherit a lot from our ancestors, but how much of the term <strong>genetic anxiety</strong> is real?</p>\n<p>And if it is real, can it be cured similarly to how anxiety is treated (CBT, Exposure Therapy) or it requires medication? Put differently, can only medication cure genetic anxiety?</p>\n", "pids": ["55a5f44965cead59c831309d"], "flag": 0}
{"question": "How is regression machine learning?", "body": "<p>In regression, in order to minimize an error function, a functional form of hypothesis <span class=\"math-container\">$h$</span> must be decided upon, and it must be assumed (as far as I'm concerned) that <span class=\"math-container\">$f$</span>, the true mapping of instance space to target space, must have the same form as <span class=\"math-container\">$h$</span> (if <span class=\"math-container\">$h$</span> is linear, <span class=\"math-container\">$f$</span> should be linear. If <span class=\"math-container\">$h$</span> is sinusoidal, <span class=\"math-container\">$f$</span> should be sinusoidal. Otherwise the choice of <span class=\"math-container\">$h$</span> was poor). </p>\n\n<p>However, doesn't this require a priori knowledge of datasets that we are wanting to let computers do on their own in the first place? I thought machine learning was letting machines do the work and have minimal input from the human. Are we not telling the machine what general form <span class=\"math-container\">$f$</span> will take and letting the machine using such things as error minimization do the rest? That seems to me to forsake the whole point of machine learning. I thought we were supposed to have the machine work for us by analyzing data after providing a training set. But it seems we're doing a lot of the work for it, looking at the data too and saying \"This will be linear. Find the coefficients <span class=\"math-container\">$m, b$</span> that fit the data.\"</p>\n", "pids": ["5c75755bf56def97989e3bd4"], "flag": 1}
{"question": "Can the SARS‑CoV‑2 virus mutate in people who have been fully vaccinated?", "body": "<p>I am curious to know if the original SARS‑CoV‑2 virus, or any of its variants, can mutate in people who have been fully vaccinated. I am referring to those people who have received all the recommended vaccinations and booster vaccinations since the worldwide outbreak of COVID-19 back in November 2019.</p>\n<p>Can SARS‑CoV‑2 mutate in people who have been fully vaccinated?</p>\n", "pids": ["618cf4835244ab9dcb6ff939"], "flag": 1}
{"question": "Is it possible to count the number of squats with Computer Vision techniques?", "body": "<p>I am planning to build an app which will count the number of sqauts from videos. Assuming that the user and camera do not move, are there ways I can count the number of squats? Do such models to understand human activity and pose exist?</p>\n", "pids": ["58d82fced649053542fd6ab3"], "flag": 1}
{"question": "Does the human brain use beam search for text generation?", "body": "<p>As far as I understand, <a href=\"https://www.youtube.com/watch?v=RLWuzLLSIgw\" rel=\"nofollow noreferrer\">beam search</a> is the most widely used algorithm for text generation in NLP. So I was wondering: does the human brain also use beam search for text generation? If not, then what?</p>\n", "pids": ["5cbee64de1cd8ebd2b5e786a"], "flag": 1}
{"question": "How to add variation in the results of a neural networks?", "body": "<p>I would like to create a neural network that converts text into handwriting for use with a pen plotter. Before I start on this project, I'd like to be sure that artificial intelligence is the best way to do this. A problem that I foresee with this approach is a lack of human like variation in the results. For example, the word \"dog\", when inputted into the network, would be the same every time, assuming I'm not missing something. I am interested if there is any way to vary the output of the network in a realistic way, even when the input is exactly the same. Could I use a second network to make the results more random, but also still look human-like? Any thoughts/ideas would be greatly appreciated.</p>\n", "pids": ["5b3d98cc17c44a510f801d98"], "flag": 1}
{"question": "Do gating mechanisms in the neocortex have individual degrees for all gated connections?", "body": "<p>For example, the upward connection between layers in the neocortex flows through the thalamus which is assumed to have a gating function.</p>\n\n<p>I wonder whether there is a single value per gate, determining the degree to which patterns can pass. Or can the gate be different for different synapses or signals at the same time? In this case, there would be more like a vector of degrees for all individual synapses of the gated nerve cord.</p>\n\n<p>Is there anything known about this?</p>\n", "pids": ["5c755226f56def97985dd66a"], "flag": 1}
{"question": "What is &quot;dense&quot; in DensePose?", "body": "<p>I've recently come across an amazing work for human pose estimation: <a href=\"https://arxiv.org/pdf/1802.00434.pdf\" rel=\"nofollow noreferrer\">DensePose: Dense Human Pose Estimation In The Wild</a> by Facebook. </p>\n\n<p>In this work, they have tackled the task of dense human pose estimation using discriminative trained models.</p>\n\n<p>I do understand that \"correspondence\" means how well pixels in one image correspond to pixels in the second image (specifically, here - 2D to 3D).</p>\n\n<p>But what does \"dense\" means in this case?</p>\n", "pids": ["5a9cb66717c44a376ffb88c6"], "flag": 1}
{"question": "How to generate networks for dynamic emotion modelling", "body": "<p>In Figure 1 (shown below) of \"Micro-Level Affect Dynamics in Psychopathology Viewed From Complex Dynamical System Theory\" by Wichers et al, they claim that the emotional/affective dynamics of networks of mentally ill individuals are more highly connected than healthy controls. These highly connected networks are more sensitive to perturbations.</p>\n\n<p><a href=\"https://i.stack.imgur.com/aNygT.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/aNygT.png\" alt=\"emotion network models\"></a></p>\n\n<p>How are these networks generated? What are the meaning behind the <code>N</code> variables?</p>\n", "pids": ["55a6c00e65ce054aad7449d2", "55a533ec65ceb7cb02e42bfe", "56d855dadabfae2eee279c57"], "flag": 1}
{"question": "How do I locate a specific object in an image?", "body": "<p>Some pictures contain an elephant, others don't. I know which of the pictures contain the elephant, but I don't know where it is or how does it look like.  </p>\n\n<p>How do I make a neural network which locates the elephant on a picture if it contains one? There are no pictures with more than one elephant.</p>\n", "pids": ["637cf7a390e50fcafd554bfa"], "flag": 1}
{"question": "Would current-day human-initiated panspermia be effective?", "body": "<p>With current technology, we are able to easily send a probe to the Alpha Centauri star system at a speed of about 20 km/s (velocity of voyager probe), which means it would take about 65000 years to get there.</p>\n\n<p><a href=\"https://i.stack.imgur.com/Q79vH.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/Q79vHm.png\" alt=\"The Sun&#39;s closest neighbors\"></a></p>\n\n<p>In light of this, suppose we sent a probe capable of delivering 100g of biological material to an Earth-like planet in α-Centauri.</p>\n\n<blockquote>\n  <p>Are there organisms that:</p>\n  \n  <p>1) Could survive the journey, perhaps frozen or in a dormant state;</p>\n  \n  <p>2) Would have a fair probability of surviving in the barren oceans (or land if preferred);</p>\n  \n  <p>3) Eventually have a change of evolving to more complex lifeforms?</p>\n</blockquote>\n\n<p>If possible, give a rough estimate of how likely you think that would be -- would we need to send 10 probes for a good chance, or billions of probes?</p>\n\n<p>The lifeless environment seems to necessitate either photosynthesis or chemosynthesis to survive. But what about the necessary food (organic matter)? Would any of those restriction make it virtually impossible to achieve long term life with current goals?</p>\n", "pids": ["55d09d3769632219056d2fb3"], "flag": 1}
{"question": "What is the most common practice to apply batch normalization?", "body": "<p>For a deep NN, should I generally apply batch normalization after each convolution layer? Or only after some of them?  Which? Every 2nd, every 3rd, lowest, highest, etc.?</p>\n", "pids": ["5cede0fbda562983788dadf1", "573696ce6e3b12023e5ce95a", "5c80f459e1cd8e544cae2003"], "flag": 1}
{"question": "Reinforcement learning to play snake - network seems to not get trained at all", "body": "<p>I am trying to build a network able to play snake game. This is my very first attempt to do such stuff. Unfortunately, I've stuck and even have no idea how to reason about the problem.</p>\n\n<p>I use reinforcement neural network approach (q-leaning). My network is built on top of Keras. I use 6 input neurons for my snake:</p>\n\n<ul>\n<li>1 - is any collision directly behind</li>\n<li>2 - is any collision directly on the right</li>\n<li>3 - is any collision directly on the left</li>\n<li>4 - is snack up front (no matter how far)</li>\n<li>5 - is a snack on the right side (no matter how far)</li>\n<li>6 - is a snack on the left side (no matter how far)</li>\n</ul>\n\n<p>the output has 3 neurons:</p>\n\n<ul>\n<li>1 - do nothing (go ahead)</li>\n<li>2 - turn right</li>\n<li>3 - turn left</li>\n</ul>\n\n<p>I believe this is a sufficient set of information to make proper decisions. But the snake seems to not even grasp the concept of not hitting the wall - which results with instant death.</p>\n\n<p>I use the following rewards table:</p>\n\n<ul>\n<li>100 for getting the snack</li>\n<li>-100 for hitting wall/tail</li>\n<li>1 for staying alive (each step)</li>\n</ul>\n\n<p>Snake tends to run randomly no matter how many training iterations it gets. </p>\n\n<p>The code is available on my github: <a href=\"https://github.com/ayeo/snake/blob/master/main.py\" rel=\"nofollow noreferrer\">https://github.com/ayeo/snake/blob/master/main.py</a></p>\n", "pids": ["5c2c7a9217c44a4e7cf313d5"], "flag": 1}
{"question": "Are Relational DBs and SQL used in Expert Systems?", "body": "<p>In the book <a href=\"https://www.goodreads.com/book/show/2054765.PROLOG\" rel=\"nofollow noreferrer\">Prolog Programming for Artificial Intelligence</a>, a large and intricate chapter (chapter 14) is dedicated to Expert Systems. In these systems, a  knowledge-database is represented through facts and rules in a declarative manner, and then we use the PROLOG inference engine to derive statements and decisions.</p>\n<p>I was wondering: are there any examples of <a href=\"https://en.wikipedia.org/wiki/Expert_system\" rel=\"nofollow noreferrer\">expert systems</a> that represent knowledge through a standard Relational Database approach and then extract facts through SQL queries? Is there any research in this area? If not, why is a rule-based approach preferred?</p>\n", "pids": ["599c7b71601a182cd273a077"], "flag": 1}
{"question": "Are any kinds of behavior proved to correlate with estrogen levels?", "body": "<p>Are any kinds of behavior proved to correlate with estrogen levels? Any studies done on this? Any indications of such correlations?</p>\n\n<p>Various research has shown correlations with testosterone and behavior, and I suppose there should be something for estrogen as well:\n<a href=\"https://cogsci.stackexchange.com/questions/8635/are-any-kinds-of-behavior-proved-to-correlate-with-testosterone-levels\">Are any kinds of behavior proved to correlate with testosterone levels?</a></p>\n", "pids": ["55a65a1b65ce054aad650d83", "55a42dfa612ca648688a944b"], "flag": 0}
{"question": "What is the exact output of the Inception ResNet V2&#39;s feature extraction layer?", "body": "<p>I am working with <a href=\"https://ai.googleblog.com/2016/08/improving-inception-and-image.html\" rel=\"nofollow noreferrer\">the Inception ResNet V2 model</a>, pre-trained with ImageNet, for face recognition.</p>\n<p>However, I'm so confused about what the exact output of the feature extraction layer (i.e. the layer just before the fully connected layer) of Inception ResNet V2 is. Can someone clarify exactly this?</p>\n<p>(By the way, if you know some resource that explains Inception ResNet V2 clearly, let me know).</p>\n", "pids": ["5736960e6e3b12023e520c34"], "flag": 1}
{"question": "What references must be acknowledged in a paper?", "body": "<p>This question came up from <a href=\"http://meta.math.stackexchange.com/a/4466/468\">a discussion</a> on <a href=\"http://meta.math.stackexchange.com/\">meta.MSE</a>.</p>\n\n<p>My question is: </p>\n\n<blockquote>\n  <p>Do we need to search <a href=\"https://math.stackexchange.com/\">MSE</a> (or blogs, math forums, ...) to make sure someone hasn't already proven a result when writing a paper? </p>\n  \n  <p>What if we are already aware of a them (so no need for searching)?</p>\n  \n  <p>Is not citing such a post in these two cases considered plagiarism?</p>\n</blockquote>\n\n<p>As I understand, the common practice is to check standard reviewed reputable publication venues (journals, conferences, maybe arXiv) and also with experts in the area to make sure a result is not already published nor a well-known folklore result. No one is going to search all over the internet and check every post that Google returns and citing other resources is very uncommon. I think checking <a href=\"http://mathoverflow.com\">MatheOverflow</a> can be considered similar to the later (checking with experts) (also see this discussion on <a href=\"https://meta.mathoverflow.net/discussion/951/copyrights-at-mo\">MO</a> but that doesn't seem to apply to a site like MSE. I am not going to cite a discussion with some random person on the street (not a professional mathematician) who claimed to have a solution or an idea for a solution for a problem (which is not passed <a href=\"http://en.wikipedia.org/wiki/Peer_review\" rel=\"nofollow noreferrer\">peer-review</a> process and I might not want even want to spend time understanding or checking the correctness of the solution).</p>\n\n<blockquote>\n  <p>What are the accepted practice for checking originality of a result? </p>\n  \n  <p>What is expected from authors regarding this before making a paper submission?</p>\n</blockquote>\n\n\n\n<p>Some clarification since there seems to be a misinterpretation of the question about being academic honesty. The question is <strong>not</strong> about posts that</p>\n\n<ul>\n<li>you are aware of,</li>\n<li>contain a complete rigorousness solution (not just ideas), and</li>\n<li>you are confident the solution is correct.</li>\n</ul>\n", "pids": ["56d8dd6fdabfae2eeefc3531"], "flag": 1}
{"question": "Is the concept of &quot;employee engagement&quot; flawed?", "body": "<p>In theory, improving business performance by improving engagement makes sense. Yet surveys suggest that since 1991, the workforce is about 30% engaged, 40% disengaged and the remaining 30% actively disengaged, as widely reported by Gallup. <a href=\"http://www.gallup.com/services/178517/state-global-workplace.aspx\" rel=\"nofollow noreferrer\">http://www.gallup.com/services/178517/state-global-workplace.aspx</a></p>\n\n<p>Billions are being spent for no result, despite the considerable benefits the engaged enjoy, and the disbenefits suffered by the others. It seems that engaged people are so both at home and work, likewise the disengaged. Neither group seem able to turn it on or off.</p>\n\n<p>Does the failure to improve aggregate employee engagement levels suggest that the concept of employee engagement is flawed?</p>\n", "pids": ["56d8fae7dabfae2eeeb22a57"], "flag": 0}
{"question": "Why isn&#39;t the Ramachandran plot symmetric?", "body": "<p>Since only relative position of <a href=\"https://en.wikipedia.org/wiki/Functional_group\" rel=\"nofollow noreferrer\">groups</a> along a <a href=\"https://en.wikipedia.org/wiki/Chemical_bond\" rel=\"nofollow noreferrer\">bond</a> is considered while calculating torsional <a href=\"https://en.wikipedia.org/wiki/Strain_(chemistry)\" rel=\"nofollow noreferrer\">strain</a> and considering &quot;+&quot; and &quot;-&quot; means clockwise and anti clock wise <a href=\"https://en.wikipedia.org/wiki/Rotation\" rel=\"nofollow noreferrer\">rotation</a>, shouldn't any set of <span class=\"math-container\">$\\phi$</span> and <span class=\"math-container\">$\\psi$</span> angle say (x, y) satisfying the energy consideration have correspondingly (-x,-y) since they are relatively the same configuration? But only the <a href=\"https://en.wikipedia.org/wiki/Ramachandran_plot\" rel=\"nofollow noreferrer\">Ramachandran plot</a> for <a href=\"https://en.wikipedia.org/wiki/Glycine\" rel=\"nofollow noreferrer\">glycine</a> shows this <a href=\"https://en.wikipedia.org/wiki/Symmetry\" rel=\"nofollow noreferrer\">symmetry</a>, see below, why doesn't this show for all the <a href=\"https://en.wikipedia.org/wiki/Protein\" rel=\"nofollow noreferrer\">proteins</a>?</p>\n<p><a src=\"https://upload.wikimedia.org/wikipedia/commons/4/44/Ramachandran_plot_Gly.jpg\" alt=\"\" /></p>\n", "pids": ["5f76fe239fced0a24bcc793e"], "flag": 1}
{"question": "How are edge features implemented in Geometric Deep Learning?", "body": "<p>The work I've seen so far have the nodes containing features. Any resources for how to use a GCN on a graph where the edges are the ones that contain features rather than the nodes?</p>\n", "pids": ["5c756efbf56def9798626df1", "5c8a11324895d9cbc6121c34"], "flag": 1}
{"question": "Can ConvLSTMs outuput images?", "body": "<p>I am working on an image to image regression task which requires me to develop a deep learning model that takes in a sequence of 5 images and return another image. The sequence of 5 images and the output images are conceptually and temporally related. In fact, the 5 images in the sequence each correspond to timestep in a simulation and the output, the one I am trying to predict, corresponds eventually to the 6th timestep of that sequence.</p>\n\n<p>For now, I have been training a simple regression-type CNN model which takes in the sequence of 5 images stored in a list and outputs an image corresponding to the next timestep in the simulation. This does work with a small and rather simple dataset (13000 images) but works a bit worse on a more diverse and larger dataset (102000 images). </p>\n\n<p>For this reason, I have been researching a bit now in order to find a better way to carry out this task and I found the idea of ConvLSTMs. However, I have seen these applied to the prediction of feature and the output of a sentence describing that image. What I wanted to know is whether ConvLSTMs can also output images, but more importantly if they can be applied to my case. If not, what other types of deep learning network can be suitable for this task?</p>\n\n<p>Thanks in advance!</p>\n", "pids": ["573698016e3b12023e6da477", "599c7967601a182cd263922d"], "flag": 1}
{"question": "How to track eye movements with electrodes?", "body": "<p>I'm an Information Technology student (bachelor's degree) and as a summer project, I'd like to develop a small \"alarm\" system for ALS patients in case of emergency situations.</p>\n\n<p>I thought about tracking the eye movements of the patients via electrodes and then send the eye movement signals to the software system which I'm going to develop and then process the data. I'm planning to use Python programming language since I already have some experience on.</p>\n\n<p>However, I don't have any experience with using electrodes, processing the signals to detect eye movements. Do you know any good and simple online sources for the beginners like me? I can't afford to buy books so I'd be grateful if you can suggest me free online sources. </p>\n", "pids": ["5c1365c2da56295a089d5e49"], "flag": 0}
{"question": "What is the leading alternative to the &quot;stages&quot; model of grieving?", "body": "<p>In \"<a href=\"http://journals.sagepub.com/doi/pdf/10.1177/0030222817691870\" rel=\"nofollow noreferrer\">Cautioning Health-Care Professionals: Bereaved Persons Are Misguided Through the Stages of Grief</a>\" by Stroebe et al. the popular \"5 stage model\" of Kübler-Ross is incorrect. Stroebe et al. argue:</p>\n\n<blockquote>\n  <p>the regularities of stage theory are too simplistic and limited; they\n  fail to represent the complex emotions and processes of grief and\n  grieving. They also lack empirical foundation. Using stages in\n  practice is potentially harmful, and yet an (perhaps the) ultimate\n  goal of theory construction in our field is to enable health-care\n  professionals to provide tangible help to those who need it.</p>\n</blockquote>\n\n<p>What are the leading theories/models of bereavement and how are they superior?</p>\n", "pids": ["55a3ded965ce5cd7b3bad304"], "flag": 0}
{"question": "How long does DNA last in wood?", "body": "<p>I was wondering if it's possible to find out if the wood of the table I bought is from the same tree of the chair in the same set. Most likely not, but I was wondering if it's theoretically possible to get the DNA from both and compare them.</p>\n<p>How long does DNA last in wood to the point that it's still useful for DNA comparisons? Are we talking about days, months, years, maybe longer?</p>\n", "pids": ["5fc0d12ad4150a363c5e5265"], "flag": 1}
{"question": "How does Iota-Carrageenan achieve an antiviral effect?", "body": "<p>\"<a href=\"http://www.boots.com/en/Boots-Pharmaceuticals-Cold-Defence-Nasal-Spray-20ml_1224268/\" rel=\"nofollow noreferrer\">Cold Defence</a>\" nasal sprays are recommended to be taken either preventatively or in the early stages of a cold.  The active ingredient in these sprays is <em>Carrageenan</em>.  After some research, the active compound is <em>Iota-Carrageenan</em> (<em>ι-Carrageenan</em>).  </p>\n\n<p>This study by <a href=\"http://dx.doi.org/10.1186/1465-9921-11-108\" rel=\"nofollow noreferrer\">Eccles et al<sup>[1]</sup></a> shows that this drug is clinically effective.  The study was only designed to test efficacy rather than to explain the mechanism, however. A fleeting mention is provided in the discussion section:</p>\n\n<blockquote>\n  <p>The above results suggest that the treatment with Iota-Carrageenan reduces the viral replication. Consequently fewer cells are infected, the immune reaction against the viruses is less pronounced and fewer symptoms occur.</p>\n</blockquote>\n\n<p><a src=\"https://i.stack.imgur.com/8hUS3.jpg\" alt=\"ι-Carrageenan\"></p>\n\n<p><strong>How does <em>ι-Carrageenan</em> produce an anti-viral effect?</strong></p>\n\n<ol>\n<li><a href=\"http://dx.doi.org/10.1186/1465-9921-11-108\" rel=\"nofollow noreferrer\"><strong>Eccles R, Meier C, Jawad M, Weinmüllner R, Grassauer A, Prieschl-Grassauer E</strong>. 2010. Efficacy and safety of an antiviral Iota-Carrageenan nasal spray: a randomized, double-blind, placebo-controlled exploratory study in volunteers with early symptoms of the common cold. Respiratory Research, 11:108, doi:10.1186/1465-9921-11-108.</a></li>\n</ol>\n", "pids": ["53e9b954b7602d9704542640", "55a3e8d865ce5cd7b3bc6f52", "55a3d3fcc91b587b0963cc03"], "flag": 1}
{"question": "Could the knowledge of the construct of self-efficacy affect the student&#39;s aptitude to a certain task?", "body": "<p>I am a tutor for children with learning disabilities and i have read that they have lower levels of perceived self-efficacy than students without this learning disabilities. I decided to deepen the construct of self-efficacy reading something of Bandura and i found that the perception of our efficacy can influence our behaviour and performance outcomes (Bandura, 1977).</p>\n\n<p>So i asked to myself: if people - with or without learning disabilities - knew that they have thoughts (sometimes latent) about their abilities, it would affect their <strong>attitude</strong> to a certain task? In another way: Could, just the <strong>knowledge</strong> of self-efficacy, have some influence?</p>\n", "pids": ["53e9ae9cb7602d97038bd270"], "flag": 0}
{"question": "Can all mammals swim?", "body": "<p>When I checked it seemed trivial to answer: yes, all mammals can swim. But research on the internet provided different information. I found:</p>\n\n<ul>\n<li>people and primates cannot swim, but can be taught how to swim</li>\n<li><a href=\"http://www.arkive.org/giraffe/giraffa-camelopardalis/video-ti06.html\" rel=\"nofollow\">giraffes can't swim</a></li>\n<li>someone claimed elephants can't swim, but <a href=\"http://www.youtube.com/watch?v=-B7qlAeiXNE\" rel=\"nofollow\">this video ad shows the reverse</a></li>\n<li><a href=\"http://answers.yahoo.com/question/index?qid=20080517194505AAbU1wf\" rel=\"nofollow\">porcupines nor rhinos</a> can't swim</li>\n<li>at least some bats <a href=\"http://vimeo.com/2743336\" rel=\"nofollow\">can swim</a>, but according to <a href=\"http://www.si.edu/Encyclopedia_SI/nmnh/batfacts.htm\" rel=\"nofollow\">this source there's insufficient data</a>.</li>\n</ul>\n\n<p>Of each hit, I found other hits that claimed the reverse, sometimes with proof. Common sense tells me all mammals can swim, but is this true?</p>\n", "pids": ["55a3a05465ce5cd7b3b16c40"], "flag": 1}
{"question": "Why do language models place less importance on punctuation?", "body": "<p>I have very outdated idea about how NLP tasks are carried out by normal RNN's, LSTM's/GRU's, word2vec, etc to basically generate some hidden form of the sentence understood by the machine.</p>\n\n<p>One of the things I have noticed is that in general researchers are interested in generating the context of the sentence, but oftentimes ignore punctuation marks which is on of the most important aspects for generating context. For example:</p>\n\n<blockquote>\n  <p>“Most of the time, travellers worry about their luggage.”</p>\n  \n  <p>“Most of the time travellers worry about their luggage”</p>\n</blockquote>\n\n<p><a href=\"https://cybertext.wordpress.com/2012/11/22/a-light-hearted-look-at-how-punctuation-can-change-meaning/\" rel=\"nofollow noreferrer\">Source</a></p>\n\n<p>Like this there exists probably 4 important punctuation marks <code>.,?</code> and <code>!</code>. Yet, I have not seen any significant tutorials/blogs on them. It is also interesting to note that punctuations don't have a meaning (quite important, since most language models try to map word to a numerical value/meaning), they are more of a 'delimiter'. So what is the current theory or perspective on this? And why is it ignored?</p>\n", "pids": ["5bdc31b417c44a1f58a0b8c2", "5b8c9f4a17c44af36f8b6b8c"], "flag": 1}
{"question": "What is an identity recurrent neural network?", "body": "<p>What is an identity recurrent neural network (IRNN)? What is the difference between an IRNN and RNN?</p>\n", "pids": ["5550417845ce0a409eb3b963"], "flag": 1}
{"question": "Can somebody provide a standard test to measure ones working memory &amp; short term memory", "body": "<p>I suffer from memory problem but find it difficult to undrstand whether it is more belief based or real, need a standard test to confirm.</p>\n", "pids": ["53e9b5f3b7602d9704145033", "53e9a4ddb7602d9702e001ef"], "flag": 1}
{"question": "How can neural networks be used to generate rather than classify?", "body": "<p>In my experience with Neural Nets, I have only used them to take input vectors and return binary output.</p>\n\n<p>But, here in a video, <a href=\"https://youtu.be/ajGgd9Ld-Wc?t=214\" rel=\"nofollow noreferrer\">https://youtu.be/ajGgd9Ld-Wc?t=214</a>, Kai Fu Lee, renowned AI Expert shows a deep net which takes thousands of samples of Trump's speeches and <strong>generates output in the Chinese Language.</strong></p>\n\n<p>In short, how can deep nets/neural nets be used to <strong>generate</strong> output rather than giving answer <strong>yes or no</strong>? Additionally, how are these nets being trained? Can anyone here provide me a simple design to nets that are capable of doing that?</p>\n", "pids": ["5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "Structure discrepancy of an LSTM?", "body": "<p>I've found multiple depictions of how an LSTM cell operates. See 2 below:</p>\n\n<p><a href=\"https://i.stack.imgur.com/YGgZO.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/YGgZO.png\" alt=\"enter image description here\"></a></p>\n\n<p>and</p>\n\n<p><a href=\"https://i.stack.imgur.com/3e630.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/3e630.png\" alt=\"enter image description here\"></a></p>\n\n<p>Each of these images suggest the hidden state is utilised differently. On the top diagram, it is shown that the hidden state is added along with the previous output and current input to both the forget gate and the input gate. The bottom image suggests the input and forget gates are calculated only using the previous output and current input. Which is it?</p>\n\n<p>Also, when the previous output is fed in for the current layer, is this before or after it has been reshaped to the final output size and been put through a softmax?</p>\n", "pids": ["5550413145ce0a409eb3929c"], "flag": 1}
{"question": "How to fight with unstability in self play?", "body": "<p>I'm working on a neural network that plays some board games like reversi or tic-tac-toe (zero-sum games, two players). I'm trying to have one network topology for all the games - I specifically don't want to set any limit for the number of available actions, thus I'm using only a state value network.</p>\n<p>I use a convolutional network - some residual blocks inspired by the Alpha Zero, then global pooling and a linear layer. The network outputs one value between 0 and 1 for a given game state - it's value.</p>\n<p>The agent, for each possible action, chooses the one that results in a state with the highest value, it uses the epsilon greedy policy.</p>\n<p>After each game I record the states and the results and create a replay memory. Then, in order to train the network, I sample from the replay memory and update the network (if the player that made a move that resulted in the current state won the game, the state's target value is 1, otherwise it's 0).</p>\n<p>The problem is that after some training, the model plays quite well as one of the players, but loses as the other one (it plays worse than the random agent). At first, I thought it was a bug in the training code, but after further investigation it seems very unlikely. It successfully trains to play vs a random agent as both players, the problem arises when I'm using only self play.</p>\n<p>I think I've found some solution to that - initially I train the model against a random player (half of the games as the first player, half as the second one), then when the model has some idea what moves are better or worse, it starts training against itself. I achieved pretty good results with that approach - in tic-tac-toe, after 10k games, I have 98.5% win rate against the random player as the starting player (around 1% draws), 95% as the second one (again around 3% draws) - it finds a nearly optimal strategy. It seems to work also in reversi and breakthrough (80%+ wins against random player after the 10k games as both players). It's not perfect, but it's also not that bad, especially with only 10k games played.</p>\n<p>I believe that, when training with self play from the beginning, one of the players gains a significant advantage and repeats the strategy in every game, while the other one struggles with finding a counter. In the end, the states corresponding to the losing player are usually set to 0, thus the model learns that whenever there is the losing player's turn it should return a 0. I'm not sure how to deal with that issue, are there any specific approaches? I also tried to set the epsilon (in eps-greedy) initially to some large value like 0.5 (50% chance for a random move) and gradually decrease it during the training, but it doesn't really help.</p>\n", "pids": ["599c7965601a182cd2638f6c"], "flag": 1}
{"question": "Why can&#39;t LSTMs tell a long story?", "body": "<p>There is a recent trend in people using LSTMs to write novels. I haven’t attempted this myself. From what I’m hearing, they can tell a story, but it seems they lose the context of the story rather quickly. After which they begin constructing new, but not necessarily related constructs. </p>\n\n<p>Can they construct a plot in the long term?</p>\n", "pids": ["5c5ce50d17c44a400fc38caf"], "flag": 1}
{"question": "AI with conflicting objectives?", "body": "<p>A recent question on AI and acting recalled me to the idea that in drama, there are not only conflicting motives between agents (characters), but a character may themselves have objectives that are in conflict.</p>\n\n<p>The result of this in performance is typically nuance, but also carries the benefit of combinatorial expansion, which supports greater novelty, and it occurs to me that this would be a factor in <a href=\"https://en.wikipedia.org/wiki/Affective_computing\" rel=\"nofollow noreferrer\">affective computing</a>.  </p>\n\n<p>(The actress Eva Green is a good example, where her performances typically involve indicating two or more conflicting emotions at once.)</p>\n\n<p>It occurs to me that this can even arise in the context of a formal game where achieving the most optimal outcome requires managing competing concerns.</p>\n\n<ul>\n<li>Is there literature or examples of AI with internal conflicting objectives?</li>\n</ul>\n", "pids": ["5da447513a55ac47eccfc8c7"], "flag": 1}
{"question": "Can you build a pure CNN phoneme classification model?", "body": "<p>I was making a simple phoneme classification model for a 10 week-long class project and I ran into a small question.</p>\n<p>Is it possible to create a model that takes a 1-second (the longest phoneme is 0.2 second but the large image is kept for context) spectrogram as input? Some people suggest creating an RNN for phoneme classification, but can you build a pure CNN phoneme classification model?</p>\n", "pids": ["5a73cbc317c44a0b3035f0fa"], "flag": 1}
{"question": "Pose estimation using CNNs on Point clouds", "body": "<p>In the case of single shot detection of point clouds, that is the point cloud of an object is taken only from one camera view without any registration. Can a Convolutional Network estimate the 6d pose of objects (initially primitive 3D objects -- cylinders, spheres, cuboids)?</p>\n<p>The dataset will be generated by simulating a depth sensor using a physics engine (ex:<a href=\"http://gazebosim.org\" rel=\"nofollow noreferrer\">gazebo</a>) and primitive 3D objects are spawned with known 6d pose as ground truth. The resulting training data will be the single viewed point cloud of the object with the ground truth label (6d pose)?</p>\n", "pids": ["599c796c601a182cd263b3d8"], "flag": 1}
{"question": "Which neural network is appropriate for measuring object dimensions from stereo images?", "body": "<p>I have stereo pairs (left, right) images of concrete cracks. I want to measure the length of the crack from those image pairs. Which neural network is appropriate for measuring object dimensions from stereo images?</p>\n\n<p>Note: I am insisted to use the NN-based technique only.</p>\n", "pids": ["5f156e7091e011d7db223b03"], "flag": 1}
{"question": "Can supervised learning be used to solve the inverted pendulum problem?", "body": "<p>I know that <a href=\"https://www.youtube.com/watch?v=5Q14EjnOJZc\" rel=\"nofollow noreferrer\">reinforcement learning has been used to solve the inverted pendulum problem</a>.</p>\n\n<p>Can supervised learning be used to solve the <a href=\"https://en.wikipedia.org/wiki/Inverted_pendulum\" rel=\"nofollow noreferrer\">inverted pendulum</a> problem? </p>\n\n<p>For example, there could be an interface (e.g. a joystick) with the cart-pole system, which the human can use to balance the pole and, at the same time, collect a dataset for supervised learning. Has this been done before?</p>\n", "pids": ["61d56fef5244ab9dcb355dcd"], "flag": 1}
{"question": "Applying Machine Learning to 2D Laser Scanner Data", "body": "<p>We are using 2D Laser Scanner to scan various objects of different geometric shapes for e.g. cylinder, spiked, cylinder with notch, cylinder with curved edges e.t.c. The dataset contains points in the format [x, y] with the dimension of 1 complete scan being 160x2. The goal is to use these scan points to classify the various shapes.</p>\n\n<p>I have used a multilayer NN with sigmoid as the final layer and Adadelta optimizer for this problem but the accuracy reaches only upto 70%. </p>\n\n<p>Can anyone recommend a proper model that can be used for Laser Scanner Data Classification?</p>\n\n\n\n<h2>          MODEL</h2>\n\n<pre><code>def baseline_model():\n    model = Sequential()\n    model.add(Dense(2048, input_dim=160, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(1024, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.4))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(6, activation='softmax'))\n    Adam = optimizers.Adam(lr=0.001)\n    Adadelta =  optimizers.Adadelta(lr = 1)\n    model.compile(loss='categorical_crossentropy', optimizer=Adadelta,   metrics=['accuracy'])\n</code></pre>\n", "pids": ["5a4aef1617c44a2190f74c5d"], "flag": 1}
{"question": "In how few updates can a multi layer neural net be trained?", "body": "<p>A single iteration of gradient descent can be parallelised across many worker nodes. We simple split the training set across the worker nodes, pass the parameters to each worker, each worker computes gradients for their subset of the training set, and then passes it back to the master to be averaged. With some effort, we can even use model parallelism.</p>\n\n<p>However, stochastic gradient descent is an inherently serial proces. Each update must be performed sequentially. Each iteration, we must perform a broadcast and gather of all parameters. This is bad for performance. Ultimately, number of updates is the limiting factor of deep model training speed.</p>\n\n<p>Why must we perform many updates? \nWith how few updates can we achieve good accuracy?</p>\n\n<p>What factors affect the minimum number of updates requires to reach some accuracy?</p>\n", "pids": ["5ce2d21fced107d4c64a250e", "5cede0e2da562983788c14c4", "5a260c8617c44a4ba8a323dd"], "flag": 1}
{"question": "Is Hypnosis more effective than a placebo?", "body": "<p>Hypnosis has been proven effective as way to treat various illnesses. So have placebos. My question is, is Hypnosis more effective than a placebo?</p>\n\n<p>In particular has there any experiments comparing the effects of real hypnosis v.s. fake hypnosis?</p>\n", "pids": ["570e59f40cf2561762abe050"], "flag": 0}
{"question": "Which neural network architectures are there that perform 3D convolutions?", "body": "<p>I am trying to do <strong>3d image deconvolution</strong> using <strong>convolution neural network</strong>. But I cannot find many famous CNNs that perform a 3d convolution. Can anyone point out some for me?</p>\n<p>Background: I am using PyTorch, but any language is OK. What I want to know most is the network structure. I can't find papers on this topic.</p>\n<p>Links to research papers would be especially appreciated.</p>\n", "pids": ["58d82fced649053542fd7243", "573696f46e3b12023e5f10b0", "57a4e91aac44365e35c97583", "5a4aef9e17c44a2190f7a3c8"], "flag": 1}
{"question": "What is a cascaded convolutional neural network?", "body": "<p>For a project I am doing, I found the paper <a href=\"https://arxiv.org/pdf/1804.01005.pdf\" rel=\"nofollow noreferrer\">Face Alignment in Full Pose Range: A 3D Total Solution</a>.</p>\n\n<p>It is using a cascaded convolutional neural network, but I wasn't able to find the original paper explaining what that is.</p>\n\n<p>In layman's terms and intuitively, how does a cascaded CNN work? What does it solve? </p>\n", "pids": ["5aed14e217c44a4438159869"], "flag": 1}
{"question": "Most suitable model for video classification with a fixed camera", "body": "<p>Consider a fixed camera that records a given area. Three things can happen in this area: </p>\n\n<ul>\n<li>No action</li>\n<li>People performing action A</li>\n<li>People performing action B</li>\n</ul>\n\n<p>I want to train a model to detect when action B happens. A human observer could typically recognize action B even with a single frame, but it would be much easier with a short video (a few seconds at low FPS).</p>\n\n<p>What are the most suitable models for this task? I read <a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\" rel=\"nofollow noreferrer\">this paper</a> where different types of fusion are performed in order to feed different frames to a CNN. Are there better alternatives?</p>\n", "pids": ["5550411b45ce0a409eb3893d", "599c7947601a182cd262ac1e"], "flag": 1}
{"question": "What could I do to this CNN to achieve a higher accuracy on the cifar10 dataset?", "body": "<p>I have achieved around 85% accuracy using the following architecture:\n<a href=\"https://i.stack.imgur.com/97JWn.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/97JWn.png\" alt=\"enter image description here\"></a>\n<a href=\"https://i.stack.imgur.com/bgeBW.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/bgeBW.png\" alt=\"enter image description here\"></a></p>\n\n<p>I used a learning rate of 0.001 and trained the model over 125 epochs with a batch size of 64.\nAny suggestions would be much appreciated. Thanks in advance.</p>\n", "pids": ["5a260c8417c44a4ba8a31b80", "5736984a6e3b12023e712dd7", "5e5e189e93d709897ce2012a", "573697826e3b12023e66901d"], "flag": 1}
{"question": "Why everyone is using CNN for image segmentation?", "body": "<p>I'm a newbie in artificial intelligence.</p>\n\n<p>I have started to research how to do image segmentation and all the papers that I have found are about CNN. Most of them use the same network, U-net, but with little variations: with more or fewer layers, different parameter values, etc.; but with not very different results.</p>\n\n<p>It seems that CNNs are in fashion and everyone uses them. Or there are other reasons that I don't know.</p>\n\n<p>If everyone is getting not very different results, why are they using the same approach instead of trying different ones?</p>\n", "pids": ["5da6eb313a55ac45909c0329"], "flag": 1}
{"question": "Can a neural network learn to predict a number given a binarized image of a rectangle?", "body": "<p>Let's assume that we have a regression problem. Our input is just binarized image that contains a single rectangle and we want to predict just a float number.  Actually, this floating-point number depends on rectangle angle, rectangle size and rectangle location. Is this problem can be solved by a neural network?</p>\n\n<p>I think, it can not be solved by a neural network, because rectangle angle, size and location are latent variables and without learning these latent variable, above problem can not be solved. What do you think?</p>\n", "pids": ["5b67b4b417c44aac1c866faa"], "flag": 1}
{"question": "What are evolutionary algorithms for topology and weights evolving of ANN (TWEANN) other than NEAT?", "body": "<p>I wonder, if there are other than NEAT approaches to evolving architectures and weights of artificial neural networks?</p>\n\n<p>To be more specific: I am looking for projects/frameworks/libraries that use evolutionary/genetic algorithms to simultanousely evolve both topology and train weights of ANNs other than NEAT approach. By 'other' I mean similar to NEAT but not based entirely on NEAT. I hope to find different approaches to the same problem.</p>\n", "pids": ["53e9a246b7602d9702b4a8c8", "53e9a03bb7602d970291e5cc", "573f1a710cf2435a6d70b72b"], "flag": 1}
{"question": "How can I train a neural network for another input set, without losing the learning of the previous input set?", "body": "<p>I read <a href=\"https://hmkcode.com/ai/backpropagation-step-by-step/\" rel=\"nofollow noreferrer\">this tutorial</a> about backpropagation.</p>\n\n<p>So using this backpropagation we are training the neural network repeatedly for one input set, say [2,4], until we reach 100% accuracy of getting 1 as output. And the neural network is adjusting its weight values accordingly. So once after the neural network is trained this way, suppose we are giving another input set, say [6,8], also then will the neural network update its weight values (overwriting previous values), right? This will result in losing the previous learning, right?</p>\n", "pids": ["57a4e91aac44365e35c97dc2", "5c873b4d4895d9cbc6f504ad"], "flag": 1}
{"question": "How many layers exists in my neural network?", "body": "<p>I have a neural network model defined as below. How many layers exist there? Not sure which ones to count when we are asked about the number.</p>\n\n<pre><code>def create_model():\n    channels = 3\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size = (5, 5), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, channels)))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(2, activation = 'softmax'))\n\n    return model\n</code></pre>\n", "pids": ["573696ce6e3b12023e5ce95a", "573696026e3b12023e515eec"], "flag": 1}
{"question": "The role of high-performance in neuropsychology", "body": "<p>As far as I understand, neuropsychology gains most of its insights from the reconciliation of lesions of the brain and <strong>cognitive impairments</strong>. Normal functioning (both of the brain and the mind) plays a less important role in neuropsychology.</p>\n\n<p>My question is:</p>\n\n<blockquote>\n  <p>Which role does <strong>cognitive high-performance</strong> play in\n  neuropsychology? Are there attempts to map cognitive high-performance processes to neurophysiological structures and processes? Some examples would be great.</p>\n</blockquote>\n\n<p>Examples of cognitive high-performance:</p>\n\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Eidetic_memory\" rel=\"nofollow noreferrer\">eidetic memory</a> (e.g. <a href=\"https://de.wikipedia.org/wiki/Stephen_Wiltshire\" rel=\"nofollow noreferrer\">Stephen Wiltshire</a>)</li>\n<li>memorization of pi (e.g. <a href=\"https://en.wikipedia.org/wiki/Akira_Haraguchi\" rel=\"nofollow noreferrer\">Akira Haraguchi</a>)</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Mental_calculator\" rel=\"nofollow noreferrer\">mental calculators</a> (e.g. <a href=\"https://de.wikipedia.org/wiki/Gert_Mittring\" rel=\"nofollow noreferrer\">Gert Mittring</a>)</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Speedcubing\" rel=\"nofollow noreferrer\">speedcubing</a> (e.g. <a href=\"https://en.wikipedia.org/wiki/Lucas_Etter\" rel=\"nofollow noreferrer\">Lucas Etter</a>)</li>\n<li>advanced mathematics</li>\n<li>advanced chess playing</li>\n</ul>\n\n<p>The mere fact that for such high-performers there are possibly enlarged (and internally more strongly and probably more specifically connected) areas of the brain (and connections between them) is not what I am looking for. Especially for the more mathematical and intricate cases there must be more than that.</p>\n\n<p>The main difference between <em>neuropsycholgy by impairment</em> and <em>neuropsychology by high-performance</em> seems to be that in the former case you can more easily perform statistical studies (but also single-case studies), in the latter case you can only perform single-case studies.</p>\n", "pids": ["55a4115065ce5cd7b3c2f548"], "flag": 0}
{"question": "What is the difference between graph semi-supervised learning and normal semi-supervised learning?", "body": "<p>Whenever I look for papers involving semi-supervised learning, I always find some that talk about graph semi-supervised learning (e.g. <a href=\"https://arxiv.org/pdf/1910.14147v1.pdf\" rel=\"nofollow noreferrer\">A Unified Framework for Data Poisoning Attack to Graph-based Semi-supervised Learning</a>). </p>\n\n<p>What is the difference between graph semi-supervised learning and normal semi-supervised learning?</p>\n", "pids": ["5e807d589fced0a24b30b594", "5db9296f47c8f766461f640d"], "flag": 1}
{"question": "What is the name of this neural network architecture with layers that are also connected to non-neighbouring layers?", "body": "<p>Consider a feedforward neural network. Suppose you have a layer of inputs, which is feedforward to a hidden layer, and feedforward both the input and hidden layers to an output layer.  Is there a name for this architecture? A layer feeds forward around the layer after it?</p>\n", "pids": ["573696026e3b12023e515eec", "573696026e3b12023e515eec"], "flag": 1}
{"question": "In this VAE formula, why do $p$ and $q$ have the same parameters?", "body": "<p>In <span class=\"math-container\">$$\\log p_{\\theta}(x^1,...,x^N)=D_{KL}(q_{\\theta}(z|x^i)||p_{\\phi}(z|x^i))+\\mathbb{L}(\\phi,\\theta;x^i),$$</span> why does <span class=\"math-container\">$p(x^1,...,x^N)$</span> and <span class=\"math-container\">$q(z|x^i)$</span> have the same parameter <span class=\"math-container\">$\\theta?$</span></p>\n<p>Given that <span class=\"math-container\">$p$</span> is just the probability of the observed data and <span class=\"math-container\">$q$</span> is the approximation of the posterior, shouldn't they be different distributions and thus their parameters different?</p>\n", "pids": ["5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "What are the reasons for journals to have a policy against publishing material available as a preprint?", "body": "<p>As it can be appreciated from this <a href=\"http://en.wikipedia.org/wiki/List_of_academic_journals_by_preprint_policy\">list of journals with varying preprint policies</a>, certain journals consider a preprint to be \"prior publication\". In other fields like Chemistry, there is a strong policy against preprints.</p>\n\n<p>I'm curious about those reasons, if there are other reasons, and if they hold weight.</p>\n", "pids": ["56d91e13dabfae2eee8c3b91"], "flag": 1}
{"question": "GANs: Should Generator update weights when Discriminator says false continuously", "body": "<p>My GANs is like this:</p>\n\n<ul>\n<li>Train an autoencoder (VAE), get the decoder part and use as Generator</li>\n<li>Train Discriminator</li>\n</ul>\n\n<p>After training, do the generation in these steps:</p>\n\n<ul>\n<li>Call Generator to generate an image</li>\n<li>Call the Discriminator to classify the image to see whether it's acceptable</li>\n</ul>\n\n<p>The problem is that the Discriminator says 'false' a lot, which means the generated image is not useful.</p>\n\n<p>How should the Generator change (update weights) when Discriminator doesn't accept its generated image?</p>\n", "pids": ["5aed14d617c44a443815939a", "5cede0f1da562983788cf732", "58d82fced649053542fd7453"], "flag": 1}
{"question": "Have GANs been used to solve regression problems?", "body": "<p>I've noticed that in the last 2 years <a href=\"https://en.wikipedia.org/wiki/Generative_adversarial_network\" rel=\"nofollow noreferrer\">GANs</a> have become really popular. I know that initially they have been proposed for image classification but I was curious if any of you are aware of any papers where GANs are used to solve regression problems?</p>\n", "pids": ["5c8d650d4895d9cbc6594960", "5a4aef9e17c44a2190f7a1e2", "5d2ef2033a55acde068c113d", "5db9296d47c8f766461f63e7"], "flag": 1}
{"question": "Are self-described &quot;socially conscious&quot; individuals less likely to show implicit bias as measured by the implicit association test (IAT)?", "body": "<p>Many individuals, in particular young progressives, incorporate their attitudes on gender and race into their identity. I am wondering if people who consider themselves socially conscious in this respect are less likely to show implicit bias as measured by the implicit association test (IAT). For example, do people who frequently and openly discuss and defend LGBT rights show less implicit bias (or reverse bias) towards LBGT individuals?</p>\n", "pids": ["5a2210880cf2b25cfd536af6", "5a9e687f684d165d4bfab105"], "flag": 0}
{"question": "How can I constraint the actions with dependent coordinates?", "body": "<p>I am working on a customized RL environment where each action is represented as a tuple <span class=\"math-container\">$a = (a_1,a_2,\\cdots,a_n)$</span> such that certain condition must be satisfied for entries of <span class=\"math-container\">$a$</span> (for instance, <span class=\"math-container\">$a_1+a_2+\\cdots+a_n \\leq \\text{constant}$</span>). </p>\n\n<p>I am using the policy gradient method, but I am having some difficulty modeling the underlying probability distribution of actions.  Is there any work done in this direction?</p>\n\n<p>For the constraint <span class=\"math-container\">$a_1+a_2+\\cdots+a_n \\leq \\text{constant}$</span>, I was thinking about generating <span class=\"math-container\">$n+1$</span> uniform random variables <span class=\"math-container\">$U_1,U_2,\\cdots,U_n, U$</span>, and set <span class=\"math-container\">$a_i = \\text{constant}\\times U \\times \\frac{U_i}{\\sum_{j=1}^n U_j}$</span>. Problem is that the joint density is a bit messy to calculate, which is needed to get the negative log likelihood. I am curious about how such issue is handled in practice. </p>\n", "pids": ["5c9009554895d9cbc6711b11"], "flag": 1}
{"question": "How can I implement the reward function for an 8-DOF robot arm with TRPO?", "body": "<p>I need to get an 8-DOF (degrees of freedom) robot arm to move a specified point. I need to implement the TRPO RL code using OpenAI gym. I already have the gazebo environment. But I am unsure of how to write the code for the reward functions and the algorithm for the joint space motion. </p>\n", "pids": ["59ae3be32bbe271c4c71b8c3", "5aed14e217c44a443815995e"], "flag": 1}
{"question": "How can I train a neural network to describe the characteristics of a picture?", "body": "<p>I have collected a set of pictures of people with a text explaining the characteristics of the person on the picture, for example, \"Big nose\" or \"Curly hair\". </p>\n\n<p>I want to train some type of model that takes in any picture and returns a description of the picture in terms of characteristics.</p>\n\n<p>However, I have a hard time figuring out how to do this. It is not like labeling \"dog\" or \"apple\" because then I can create a set of training data and then evaluate its performance, now I can not. If so I would probably have used a CNN and probably also VGG-16 to help me out.</p>\n\n<p>I only have two ML courses under my belt and have never really encountered a problem like this before. Can someone help me to get in the right direction?</p>\n\n<p>As of now, I have a data set of 13000 labeled images I am very confident it is labeled well. I do not know of any pre-trained datasets that could be of help in this instance, but if you know of one it might help.</p>\n\n<p>Worth noting is that every label is or should at least be unique. If for example there exist two pictures with the same label of \"Big nose\" it is purely coincidental.</p>\n", "pids": ["573697826e3b12023e669567"], "flag": 1}
{"question": "What&#39;s the intuition behind contrastive learning?", "body": "<p>Recently, I have seen a surge of papers w.r.t contrastive learning (a subset of semi-supervised learning). </p>\n\n<p>Can anyone give a detailed explanation of this approach with its advantages/disadvantages and what are the cases in which it gives better results?</p>\n\n<p>Also, why it's gaining traction amongst the ML research community?</p>\n", "pids": ["5dcd263a3a55ac58039516c5", "5e4672c93a55ac14f595d8b5"], "flag": 1}
{"question": "Recent algorithms for correcting mislabeled data using multilayer perceptrons", "body": "<p>I am doing literature research on algorithms for correcting mislabeled data using multilayer perceptrons. Found an \"old\" paper <a href=\"https://pdfs.semanticscholar.org/3a09/c6f3873dd0327a3f9d83b7ff1c8b43a06cc3.pdf\" rel=\"nofollow noreferrer\">An algorithm for correcting mislabeled data</a> (2001) by Xinchuan Zeng et al. Please share if you are aware of recent/current updates with a brief thoughts. Thanks in advance.</p>\n", "pids": ["5dbff6b23a55ac6afe41c839"], "flag": 1}
{"question": "What are the AI technologies currently used to fight the coronavirus pandemic?", "body": "<p>The ongoing <a href=\"https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic\" rel=\"nofollow noreferrer\">coronavirus pandemic</a> of coronavirus disease 2019 (COVID-19), caused by <a href=\"https://en.wikipedia.org/wiki/Severe_acute_respiratory_syndrome_coronavirus_2\" rel=\"nofollow noreferrer\">severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)</a>, as of 29 September 2020, has affected many countries and territories, with more than 33.4 million cases of COVID-19 have been reported and more than 1 million people have died. The live statistics can be found at <a href=\"https://www.worldometers.info/coronavirus/\" rel=\"nofollow noreferrer\">https://www.worldometers.info/coronavirus/</a> or in the <a href=\"https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports\" rel=\"nofollow noreferrer\">World Health Organization (WHO) site</a>. Although countries have already started quarantines and have adopted extreme countermeasures (such as closing restaurants or forbidding events with multiple people), the numbers of cases and deaths will probably still increase in the next weeks.</p>\n<p>Given that this pandemic concerns all of us, including people interested in AI, such as myself, it may be useful to share information about the possible current applications of AI to slow down the spread of SARS-CoV-2, to help infected people or people in the healthcare sector that have been uninterruptedly working for hours to attempt to save more lives, while putting at risk their own.</p>\n<p>What are the existing AI technologies (e.g. computer vision or robotics tools) that are already being used to tackle these issues, such as slowing down the spread of SARS-CoV-2 or helping infected people?</p>\n<p>I am looking for references that prove that the mentioned technologies are really being used. I am not looking for potential AI technologies (i.e. research work) that could potentially be helpful. Furthermore, I am <strong>not</strong> looking for data analysis tools (e.g. sites that show the evolution of the spread of coronavirus, etc.)</p>\n", "pids": ["5e8ef2ae91e011679da0f1d0"], "flag": 1}
{"question": "What kind of optimizer is suggested to use for binary classification of similar images?", "body": "<p>I have spent some time searching Google and wasn't able to find out what kind of optimization algorithm is best for binary classification when images are <strong>similar</strong> to one another. </p>\n\n<p>I'd like to read some theoretical proofs (if any) to convince myself that particular optimization has better results over the rest. </p>\n\n<p>And, similarly, what kind of optimizer is better for binary classification when images are <strong>very different</strong> from each other?</p>\n", "pids": ["5550415745ce0a409eb3a739"], "flag": 1}
{"question": "How do mammals estimate the speed of moving objects?", "body": "<p>Has there been any research on how mammals predict the speed of moving objects? In particular, how do they integrate top-down information? For instance, do they have greater difficulty estimating the speed of a fast-moving sloth more than a moving mouse?</p>\n", "pids": ["55a5403b65ceb7cb02e5ee7c"], "flag": 0}
{"question": "Are studies included in most meta-analyses based on a narrow range of participants?", "body": "<p>This question is mostly quoted from <em>A New Psychology of Women</em> (2017) by Lips, page 63:</p>\n\n<blockquote>\n  <p>Finally, and perhaps most importantly, the studies included in most meta-analyses are based on a narrow range of participants (usually young, North American students) and are not reflective of the populations at large--although this limitation tends to be obscured by the combination of many studies into a single analysis (Halpern, 1995). </p>\n</blockquote>\n\n<p>I mean, this claim is more than 20 years old. Is it true today? Is there a study that examines the demographics of meta-studies at large or something related?\nIf it is true, is this the case for most psychology research, male-female differences or all studies in the social sciences?</p>\n", "pids": ["53e99930b7602d970216b9e8"], "flag": 0}
{"question": "Which work originally introduced gradient clipping?", "body": "<p>The <a href=\"https://www.deeplearningbook.org/contents/rnn.html\" rel=\"nofollow noreferrer\"><em>Deep Learning</em> book</a> mentions that it's been used for years but the oldest sources it mentions are from 2012: </p>\n\n<blockquote>\n  <p>A simple type of solution has been in use by practitioners for many years: clipping the gradient. There are diﬀerent instances of this idea (Mikolov, 2012; Pascanu et al., 2013). One option is to clip the parameter gradient from a mini-batch element-wise (Mikolov, 2012), just before the parameter update. Another is to clip the <span class=\"math-container\">$||g||$</span> of the gradient <span class=\"math-container\">$g$</span> (Pascanu et al., 2013) just before the parameter update  </p>\n</blockquote>\n\n<p>But I find it hard to believe that the first uses and mentions of gradient clipping are from 2012. Does anyone know the origins of the solution? </p>\n", "pids": ["53e9aa10b7602d970337f51e"], "flag": 1}
{"question": "How can I train a neural network if I don&#39;t have enough data?", "body": "<p>I have created a neural network that is able to recognize images with the numbers 1-5. The issue is that I have a database of 16x5 images which ,unfortunately, is not proving enough as the neural network fails in the test set. Are there ways to improve a neural network's performance without using more data? The ANN has approximately a 90% accuracy on the training sets and a 50% accuracy in the test ones.</p>\n\n<p>Code:</p>\n\n<pre><code>clear\ngraphics_toolkit(\"gnuplot\")\nsigmoid = @(z) 1./(1 + exp(-z));\nsig_der = @(y) sigmoid(y).*(1-sigmoid(y));\n\n\nparse_image;   % This external f(x) loads the images so that they can be read. \n%13x14\nnum=0;\nfor i=1:166\n  if mod(i-1,10)&lt;=5 &amp;&amp; mod(i-1,10) &gt; 0\n    num=num+1;\n    data(:,num) = dlmread(strcat(\"/tmp/\",num2str(i)))(:);\n  end\nend\n\n\n\nfunction [cost, mid_layer, last_layer] = forward(w1,w2,data,sigmoid,i)\n  mid_layer(:,1)=sum(w1.*data(:,i));\n  mid_layer(:,2)=sigmoid(mid_layer(:,1));\n  last_layer(:,1)=sum(mid_layer(:,2).*w2);\n  last_layer(:,2)=sigmoid(last_layer(:,1));\n  exp_res=rem(i,5);\n  if exp_res==0\n    exp_res=5;\n  end\n  exp_result=zeros(5,1); exp_result(exp_res)=1;\n  cost = exp_result-last_layer(:,2);\nend\n\nfunction [w1, w2] = backprop(w1,w2,mid_layer,last_layer,data,cost,sig_der,sigmoid,i)\n  delta(1:5) = cost;\n  delta(6:20) = sum(cost' .* w2,2);\n  w2 = w2 + 0.05 .* delta(1:5) .* mid_layer(:,2) .* sig_der(last_layer(:,1))';\n  w1 = w1 + 0.05 .* delta(6:20) .* sig_der(mid_layer(:,1))' .* data(:,i);\nend\n\nw1=rand(182,15)./2.*(rand(182,15).*-2+1);\nw2=rand(15,5)./2.*(rand(15,5).*-2+1);\n\nfor j=1:10000\n  for i=[randperm(85)]\n    [cost, mid_layer, last_layer] = forward(w1,w2,data,sigmoid,i);\n    [w1, w2] = backprop(w1,w2,mid_layer,last_layer,data,cost,sig_der,sigmoid,i);\n    cost_mem(j,i,:)=cost;\n  end\nend\n</code></pre>\n", "pids": ["5dca89823a55ac77dcb02095"], "flag": 1}
{"question": "What are ways to assess employability of workers?", "body": "<p>Employability is typically defined as </p>\n\n<blockquote>\n  <p>the continuous fulfilling, acquiring or\n  creating of work through the optimal use of competences. (Van der Heijde &amp; Van der Heijden, 2006) </p>\n</blockquote>\n\n<p>One's employability does not only depend on one's ability to work (both physically and mentally), but also one's motivation to work and learn and the opportunity to work (Brouwers, 2012; dutch citation). </p>\n\n<p>Especially for elders, who are getting older and older, and have to work longer (i.e. until a higher age), employability is becoming incredibly relevant. They need to be able (and willing) to keep on working until their retirement, either in their current position or another less demanding job. This is a difficult job without clear insights. However, with such an incredibly broad term, it will even be difficult to gain those insights. </p>\n\n<p>Are there tools available to asses the personal factors of individuals' employability? </p>\n\n\n\n<p><a href=\"http://doc.utwente.nl/82810/1/VanderHeijdeVanderHeijden2006.pdf\" rel=\"nofollow noreferrer\">Heijde, C. M., &amp; Van Der Heijden, B. I. (2006). A competence‐based and multidimensional operationalization and measurement of employability. Human resource management, 45(3), 449-476.</a></p>\n\n<p><a href=\"http://www.flexworkresearch.org/uploads/publication/document/4726/Duurzameinzetbaarheidvandeouderewerknemer_standvanzaken.pdf\" rel=\"nofollow noreferrer\">Brouwer, S., de Lange, A., van der Mei, S., Wessels, M., Koolhaas, W., Bültmann, U., ... &amp; van der Klink, J. (2012). Duurzame inzetbaarheid van de oudere werknemer: stand van zaken. Universitair Medisch Centrum Groningen, Groningen: Rijksuniversiteit Groningen.</a></p>\n", "pids": ["53e9b505b7602d9704036015", "5c0f7adfda562944ac79a4e2", "5aaa2d211b13da3ea920cb88"], "flag": 1}
{"question": "What are recent AI software systems and research papers close to J. Pitrat&#39;s ideas?", "body": "<p><a href=\"https://fr.wikipedia.org/wiki/Jacques_Pitrat\" rel=\"nofollow noreferrer\">J. Pitrat</a> (born in 1934) was a French leading artificial intelligence scientist (the first to get a Ph.D. in France mentioning &quot;artificial intelligence&quot;). His <a href=\"http://bootstrappingartificialintelligence.fr/WordPress3/\" rel=\"nofollow noreferrer\">blog</a> is still online and of course refer to most of his papers (e.g. <a href=\"https://pdfs.semanticscholar.org/2117/9600b3f05c0af399f9acbfc6e7b6d24daf03.pdf\" rel=\"nofollow noreferrer\"><em>A Step toward an Artificial Artificial Intelligence Scientist</em></a>, etc.) and books, notably <a href=\"https://onlinelibrary.wiley.com/doi/book/10.1002/9780470611791\" rel=\"nofollow noreferrer\"><em>Artificial Beings: the conscience of a conscious machine</em></a> (his last book). He passed away in October 2019. I attended (and presented a <a href=\"http://refpersys.org/Starynkevitch-CAIA-RefPerSys-2020mar06.pdf\" rel=\"nofollow noreferrer\">talk</a>) at a <a href=\"https://afia.asso.fr/journee-hommage-j-pitrat/\" rel=\"nofollow noreferrer\">seminar</a> in his memory.</p>\n<p><em>What are recent AI systems or research papers related to the idea of symbolic AI, introspection, declarative metaknowledge, meta-learning, meta-rules, etc.?</em></p>\n<p>Most of those I know are more than 20 years old (e.g. Lenat <a href=\"https://en.wikipedia.org/wiki/Eurisko\" rel=\"nofollow noreferrer\">Eurisko</a>; I am aware of <a href=\"https://en.wikipedia.org/wiki/Cyc#OpenCyc\" rel=\"nofollow noreferrer\">OpenCyC</a>). I am interested in papers or systems published after 2010 (perhaps <a href=\"https://en.wikipedia.org/wiki/Artificial_general_intelligence\" rel=\"nofollow noreferrer\">AGI</a> papers with <em>actual</em> complex open source software prototypes).</p>\n<p>-see also the <a href=\"http://refpersys.org/\" rel=\"nofollow noreferrer\">RefPerSys</a> system-</p>\n", "pids": ["5de79a0a9e795e7758069371", "5de632593a55ac4f55c255e4", "5ede0553e06a4c1b26a841eb"], "flag": 1}
{"question": "Should I always start from the same start state in reinforcement learning?", "body": "<p>In an episodic training of an RL agent, should I always start from the same initial state or I can start from several valid initial states?</p>\n\n<p>For example, in a gym environment, should my <code>env.reset()</code> function always resets me to the same start state or it can start from different states at each training episode?</p>\n", "pids": ["58d82fcbd649053542fd689f"], "flag": 1}
{"question": "What are some online courses on artificial general intelligence?", "body": "<p>Although no artificial general intelligence (AGI) has yet been created, probably, there are already some courses on the topic. So, what are some online (preferably free) courses on AGI?</p>\n", "pids": ["6063030291e0118c891f1aab", "57a4e91dac44365e35c98b0f"], "flag": 1}
{"question": "How to use pre-trained BERT to extract the vectors from sentences?", "body": "<p>I'm trying to extract the vectors from the sentences. Spent soo much time searching for the pre-trained BERT models but found nothing.</p>\n<blockquote>\n<p><strong>Is it possible to get the vectors using pre-trained BERT from the data?</strong></p>\n</blockquote>\n", "pids": ["5bdc31b417c44a1f58a0b8c2", "599c7987601a182cd2648373"], "flag": 1}
{"question": "Genetic Models for Natural Selection?", "body": "<p>My question is simple:</p>\n\n<p>Given that evolution is described by random genetic mutations allowing certain members of a species to gain a reproductive advantage over others that coexist in the particular environment- I am curious- single genetic mutations do not seem to really explain complex morphic changes such as the length of a giraffes neck. Instead it appears it must be a compilation of many such mutations. So what are the statistics for mutations? How long does it really take for so many to favorably compile? How does this compare with the reproductive time of the species?</p>\n", "pids": ["53e99ff0b7602d97028ceca1", "53e9a9dfb7602d9703340309"], "flag": 1}
{"question": "How can Siamese Networks be viewed as RNNs?", "body": "<blockquote>\n  <p>\"Single-object tracking commonly uses <strong>Siamese networks, which can be seen as an RNN</strong> unrolled over two time-steps.\"</p>\n</blockquote>\n\n<p><a href=\"https://arxiv.org/abs/1806.01794\" rel=\"nofollow noreferrer\">(from the SQAIR paper)</a></p>\n\n<p>I'm wondering how Siamese networks can be viewed as RNNs, as mentioned above. A diagrammatic explanation, or anything that helps understand the same, would help! Thank you!</p>\n", "pids": ["599c7945601a182cd2629f72"], "flag": 1}
{"question": "Reinforcement Learning (and specifically REINFORCE algorithm) for one-round &quot;games&quot;", "body": "<p>I'm interested about using Reinforcement Learning in a setting that might seem more suitable for Supervised Learning. There's a dataset <span class=\"math-container\">$X$</span> and for each sample <span class=\"math-container\">$x$</span> some decision needs to be made. Supervised Learning can't be used since there aren't any algorithms to solve or approximate the problem (so I can't solve it on the dataset) but for a given decision it's very easy to decide how good it is (define a reward). </p>\n\n<p>For example, you can think about the knapsack problem - let's say we have a dataset where each sample <span class=\"math-container\">$x$</span> is a list (of let's say size 5) of objects each associated with a weight and a value and we want to decide which objects to choose (of course you can solve the knapsack problem for lists of size 5, but let's imagine that you can't). For each solution the reward is the value of the chosen objects (and if the weight exceeds the allowed weight then the reward is 0 or something). So, we let an agent \"play\" with each sample <span class=\"math-container\">$M$</span> times, where play just means choosing some subset and training with the given value. </p>\n\n<p>For the <span class=\"math-container\">$i$</span>-th sample the step can be adjusted to be:\n<span class=\"math-container\">$$\\theta = \\theta + \\alpha \\nabla_{\\theta}log \\pi_{\\theta}(a|x^i)v$$</span> \nfor each \"game\" with \"action\" <span class=\"math-container\">$a$</span> and value <span class=\"math-container\">$v$</span>.</p>\n\n<p>instead of the original step:\n<span class=\"math-container\">$$\\theta = \\theta + \\alpha \\nabla_{\\theta}log \\pi_{\\theta}(a_t|s_t)v_t$$</span>\nEssentially, we replace the state with the sample.</p>\n\n<p>The issue with this is that REINFORCE assumes that an action also leads to some new state where here it is not the case. Anyway, do you think something like this could work?</p>\n", "pids": ["5a9cb65d17c44a376ffb83c6", "58d82fced649053542fd6fc9"], "flag": 1}
{"question": "What are the main differences between YOLOv3 and RetinaNet object detection algorithms?", "body": "<p>I am looking at a certain project that compares performance on a certain dataset for an object detection problem using YOLOv3 and RetinaNet (or the &quot;SSD_ResNet50_FPN&quot; from TF Model Zoo). Both YOLOv3 and RetinaNet seem to have similar features like detection at scales, skip connections, etc.</p>\n<p>So, what is the exact main difference between YOLOv3 and SSD_ResNet50_FPN?</p>\n", "pids": ["5aed14d617c44a4438159040", "5a260c8117c44a4ba8a30b08"], "flag": 1}
{"question": "What are the most common deep reinforcement learning algorithms and models apart from DQN?", "body": "<p>Recently, I have completed Atari Breakout (<a href=\"https://arxiv.org/pdf/1312.5602.pdf\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/1312.5602.pdf</a>) with DQN. </p>\n\n<p>Similar to DQN, what are the most common deep reinforcement learning algorithms and models in 2020? It seems that DQN is outdated and policy gradients are preferred.</p>\n", "pids": ["5736960a6e3b12023e51d96d", "5736960b6e3b12023e51e3ea", "5e72341993d709897cfbb428", "5c615e59e1cd8eae15018673", "59ae3bf12bbe271c4c71bc64"], "flag": 1}
{"question": "What are the main differences between sparse autoencoders and convolution autoencoders?", "body": "<p>What are the main differences and similarities between sparse autoencoders and convolution autoencoders?</p>\n\n<p>When should one be preferred over the other? What are their applications?</p>\n\n<p>(References are welcome. Somehow I was not able to find any comparisons of these autoencoders although I looked in a few textbooks and searched for material online. I was able to find the descriptions of each autoencoder separately, but what I am interested in is the comparison.)</p>\n", "pids": ["53e997f5b7602d9701ffa30e"], "flag": 1}
{"question": "Why can&#39;t DQN be used for self-driving cars?", "body": "<p>Why can't DQN be used for self-driving cars?\nWhy can't DQN and similar RL algorithms be used for self-driving cars?</p>\n\n<p>The reason why I am curious is that it successfully plays go and other multistate games.</p>\n", "pids": ["5e72341993d709897cfbb428", "5e3940c73a55ace46ed4370a"], "flag": 1}
{"question": "Indicate Journal name for &quot;under review&quot; and &quot;accepted/in press&quot; publications on CV", "body": "<p>there are similar questions on how to list on CV publications that have not passed the accepted or in press stage when applying to junior research positions ( PhD/postdoc).</p>\n\n<p>I am not clear if such publications should include the journal name or not, and what would be the reason for either choice.</p>\n", "pids": ["5fabb8cfd4150a363c632fb9"], "flag": 1}
{"question": "What are tendons made of specifically", "body": "<p>From what I read on wikipedia they are made of collagen. Collagen is just a protein. Right? How is this collagen structured (I imagine like fibers). Aren't there cells in this fibers as well?</p>\n\n<p>From this picture:<br>\n<a src=\"https://upload.wikimedia.org/wikipedia/commons/6/66/Tendon_-_very_high_mag.jpg\" alt=\"Tendon H&amp;E\">  </p>\n\n<p>Is the pink stuff the collagen? and the purple stuff the tenocytes?</p>\n\n<p>If someone can expand on this with a picture preferably, it would be great.</p>\n", "pids": ["55a6a46f65ce054aad6f195f", "55a6bdcb65ce054aad73b889", "53e99cedb7602d97025a3635"], "flag": 1}
{"question": "How and when should we update the Q-target in deep Q-learning?", "body": "<p>I have recently watched David silver's course, and started implementing the deep Q-learning algorithm. </p>\n\n<p>I thought I should make a switch between the Q-target and Q-current directly (meaning, every parameter of Q-current goes to Q-target), but I found a repository on GitHub where that guy updates Q-target as follows:</p>\n\n<p><span class=\"math-container\">$$Q_{\\text{target}} = \\tau * Q_{\\text{current}} + (1 - \\tau)*Q_{\\text{target}}$$</span>.</p>\n\n<p>where <span class=\"math-container\">$\\tau$</span> is some number probably between 0 and 1. </p>\n\n<p>Is that update correct or I miss something? </p>\n\n<p>I thought after some iterations (e.g. 2000 iteration), we should update Q-target as: <span class=\"math-container\">$Q_{\\text{target}}=Q_{\\text{current}}$</span>.</p>\n", "pids": ["5e72341993d709897cfbb428"], "flag": 1}
{"question": "Learning policy where action involves discrete and continuous parameters", "body": "<p>Typically it seems like reinforcement learning involves learning over either a discrete or a continuous action space. An example might be choosing from a set of pre-defined game actions in Gym Retro or learning the right engine force to apply in Continuous Mountain Car; some popular approaches for these problems are deep Q-learning for the former and actor-critic methods for the latter.</p>\n\n<p>What about in the case where a single action involves picking both a discrete and a continuous parameter? For example, when choosing the type (discrete), pixel grid location (discrete), and angular orientation (continuous) of a shape from a given set to place on a grid and optimize for some reward.\nIs there a well-established approach for learning a policy to make both types of decisions at once?</p>\n", "pids": ["5b67b4b917c44aac1c867e49", "5e0f1bdc3a55ac3c6e9e9407"], "flag": 1}
{"question": "What kind of problems cannot be solved using machine learning techniques?", "body": "<p>For the problems that can be solved algorithmically.</p>\n\n<p>We have very good formal literature for which problems can be solved in polynomial, exponential time and which cannot. <strong>P/NP/NP-hard</strong></p>\n\n<p>But do we know some problems in machine learning paradigm for which no model can be trained? (With/without infinite computation capacity)</p>\n", "pids": ["5c04967517c44a2c74709162"], "flag": 1}
{"question": "How to implement RAM versions of Atari games", "body": "<p>I have coded the breakout RAM version, but, unfortunately, its highest reward was 5. I trained it for about 2 hours and never reached a higher score. The code is huge, so I can't paste here, but, in short, I used <em>double deep Q-learning</em>, and trained it like it was CartPole or lunar-lander environment. In CartPole, the observation was a vector of 4 components. In that case, my double deep Q-learning agent solved the environment, but in the breakout-ram version whose observation was a vector of 128 elements, it was not even close. </p>\n\n<p>Did I miss something?</p>\n", "pids": ["5736960b6e3b12023e51e3ea"], "flag": 1}
{"question": "In Batch Normalisation, are $\\hat{\\mu}$, $\\hat{\\sigma}$ the mean and stdev of the original mini-batch or of the input into the current layer?", "body": "<p>In Batch Normalisation, are the sample mean and standard deviation we normalise by the mean/sd of the original data put into the network, or of the inputs in the layer we are currently BN'ing over? </p>\n\n<p>For instance, suppose I have a mini-batch size of 2 which contains <span class=\"math-container\">$\\textbf{x}_1, \\textbf{x}_2$</span>. Suppose now we are at the <span class=\"math-container\">$k$</span>th layer and the outputs from the previous layer are <span class=\"math-container\">$\\tilde{\\textbf{x}}_1,\\tilde{\\textbf{x}}_2$</span>. When we perform batch norm at this layer would be subtract the sample mean of <span class=\"math-container\">$\\textbf{x}_1, \\textbf{x}_2$</span> or of <span class=\"math-container\">$\\tilde{\\textbf{x}}_1,\\tilde{\\textbf{x}}_2$</span>? </p>\n\n<p>My intuition tells me that it must be the mean,sd of <span class=\"math-container\">$\\tilde{\\textbf{x}}_1,\\tilde{\\textbf{x}}_2$</span> otherwise I don't think it would be normalised to have 0 mean and sd of 1. </p>\n", "pids": ["573696ce6e3b12023e5ce95a"], "flag": 1}
{"question": "Why is the policy not a part of the MDP definition?", "body": "<p>I'm reading an article on reinforcement learning, and I don't understand why the agent's policy <span class=\"math-container\">$\\pi$</span> is not part of definition of Markov Decision process(MDP):</p>\n<blockquote>\n<p><a href=\"https://i.stack.imgur.com/giJ04.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/giJ04.png\" alt=\"enter image description here\" /></a></p>\n<p>Bu, Lucian, Robert Babu, and Bart De Schutter. &quot;A comprehensive survey of multiagent reinforcement learning.&quot; IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews) 38.2 (2008): 156-172.</p>\n</blockquote>\n<p>My question is:</p>\n<blockquote>\n<p>Why the policy is not a part of the MDP definition?</p>\n</blockquote>\n", "pids": ["5dbc05c747c8f7664629a148"], "flag": 1}
{"question": "Two DQNs in two different time scales", "body": "<p>I have the following situation. An agent plays a game and wants to maximize the accumulated reward as usual, but it can choose its adversary. There are <span class=\"math-container\">$n$</span> adversaries.</p>\n<p>In episode <span class=\"math-container\">$e$</span>, the agent must first select an adversary. Then for each step <span class=\"math-container\">$t$</span> in the episode <span class=\"math-container\">$e$</span>, it plays the game against the chosen adversary. Every step <span class=\"math-container\">$t$</span>, it receives a reward following the chosen action in step <span class=\"math-container\">$t$</span> (for the chosen adversary). How to maximize the expected rewards using DQN? It is clear that choosing the &quot;wrong&quot; (the strongest) adversary won't be a good choice for the agent. Thus, to maximize the accumulated rewards, the agent must take two actions at two different timescales.</p>\n<p>I started solving it using two DQNs, one to decide the adversary to play against and one to play the game against the chosen adversary. I have two duplicate hyperparameters (<code>batch_size</code>, <code>target_update_freq</code>, etc), one for each DQN. Have you ever seen two DQNs like this? Should I train the DQNs simultaneously?</p>\n<p>The results that I am getting is not that good. The accumulated reward is decreasing, the loss isn't always decreasing...</p>\n", "pids": ["5db92a1a47c8f76646200935"], "flag": 1}
{"question": "Does the number of parameters in a convolutional neuronal network increase if the input dimension increases?", "body": "<p>If I have a convolutional neuronal network, does the input dimension change the number of parameters? And if yes, why? If the sizes and lengths of the filters are still the same, how can the number of parameter in a network increase?</p>\n", "pids": ["57a4e91dac44365e35c987bb"], "flag": 1}
{"question": "How does the target network in double DQNs find the maximum Q value for each action?", "body": "<p>I understand the fact that the neural network is used to take the states as inputs and it outputs the Q-value for state-action pairs. However, in order to compute this and update its weights, we need to calculate the maximum Q-value for the next state <span class=\"math-container\">$s'$</span>. In order to get that, in the DDQN case, we input that next state <span class=\"math-container\">$s'$</span> in the target network.</p>\n<p>What I'm not clear on is: how do we train this target network itself that will help us train the other NN? What is its cost function?</p>\n", "pids": ["5736960b6e3b12023e51e3ea"], "flag": 1}
{"question": "What is the advantage of using experience replay (as opposed to feeding it sequential data)?", "body": "<p>Let's suppose that our RL agent needs to play a game with different levels. If we train our RL agent sequentially or with sequential data, our agent will learn how to play level 1, but then it will learn to play level 2 differently, because our agent learns how to play level 2 and forgets how to play level 1, since now our model is fitted using only experiences from level 2.</p>\n<p>How does an experience replay buffer change this? Can you explain this in simple terms?</p>\n", "pids": ["5a73cbcc17c44a0b3035f334"], "flag": 1}
{"question": "What is the difference between work engagement and flow?", "body": "<p><a href=\"https://en.wikipedia.org/wiki/Work_engagement\" rel=\"nofollow noreferrer\">Work engagement</a> has three aspects: vigor, dedication, and absorption. </p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Flow_(psychology)\" rel=\"nofollow noreferrer\">Flow</a> according to wikipedia \"is the mental state of operation in which a person performing an activity is fully immersed in a feeling of energized focus\". </p>\n\n<p>What is the difference between the two concepts?</p>\n", "pids": ["53e9b22db7602d9703cc77e9", "53e9bd45b7602d97049d1981"], "flag": 1}
{"question": "How do RNN&#39;s for sentiment classification deal with different sentence lengths?", "body": "<p>I have been doing a course which teaches you about Deep Neural Networks, during one of the exercises I was made to make an RNN for sentiment classification which I did, but I did not understand how an RNN is able to deal with sentences of different lengths while conducting sentiment classification.</p>\n", "pids": ["5cede0e4da562983788c3685"], "flag": 1}
{"question": "Cockroach olfactory bulb response to novel stimuli", "body": "<p><a href=\"https://github.com/ctn-waterloo/modelling_ideas/issues/18\" rel=\"nofollow noreferrer\">I've heard anecdotally</a>, that the cockroach olfactory bulb responds differently to novel stimuli vs. known stimuli. Specifically, it sends an oscillatory firing pattern for known stimuli and a constant firing pattern for novel stimuli. However, I'm having a hard time finding a reference for this? Does the olfactory bulb in insects (not just cockroaches) actually respond with different firing patterns?</p>\n", "pids": ["53e9ae29b7602d970383df71", "53e9a2dcb7602d9702be5587"], "flag": 0}
{"question": "Are there fundamental learning theories for developing an AI that imitates human behavior?", "body": "<p>Most, if not all, AI systems do not imitate humans. Some of them out-perform humans. Examples include using AI to play a game, classification problems, auto-driving, and goal-oriented chatbots. Those tasks usually come with an easily and clearly defined value function, which is the objective function for the AI to optimize.</p>\n<p>My question is: how is deep reinforcement learning, or related techniques, to be applied to an AI system that is designed to just <strong>imitate</strong> humans <strong>but not outperform</strong> humans?</p>\n<p>Note this is different from a human-like system. Our objective here is to let the AI become a human rather than a superintelligence. For example, if a human consistently makes a mistake in image identification, then the AI system must also make the same mistake. Another example is the classic chatbot to pass the Turing test.</p>\n<p>Is deep reinforcement learning useful in these kinds of tasks?</p>\n<p>I find it is really hard to start with because the value function cannot be easily calculated.</p>\n<p>What is some theory behind this?</p>\n", "pids": ["5dc29a843a55acf4d3a9093e"], "flag": 1}
{"question": "What are some examples of LSTM architectures?", "body": "<p>I've been doing some class assignments recently on building various neural networks. For convolutional networks, there are several well-known architectures such as LeNet, VGG etc. Such \"classic\" models are frequently referenced as starting points when building new CNNs. </p>\n\n<p>Are there similar examples for RNN/LSTM networks? All I've found so far are articles and slides explaining recurrent neurons, LSTM layers, and the math behind them, but no well-known examples of entire multi-layered network architectures, unlike CNNs which seem to have in abundance.</p>\n", "pids": ["57ffb1330cf2d8e2e21d9728", "5d4d46fb3a55acff992fdcbf", "599c796d601a182cd263c436", "53e9b136b7602d9703bb5f44", "5a9cb65d17c44a376ffb83f1", "5550413145ce0a409eb3929c"], "flag": 1}
{"question": "Extract features with CNN and pass as sequence to RNN", "body": "<p>I read an <a href=\"https://blog.coast.ai/five-video-classification-methods-implemented-in-keras-and-tensorflow-99cad29cc0b5\" rel=\"nofollow noreferrer\">article</a> about captioning videos and I want to use solution number 4 (extract features with a CNN, pass the sequence to a separate RNN) in my own project.</p>\n<p>But for me, it seems really strange that in this method we use the Inception model without any retraining or something like that. Every project has different requirements and even if you use pretrained model instead of your own, you should do some training.</p>\n<p>And I wonder how to do this? For example, I created a project where I use the network with CNN layers and then LSTM and Dense layers. And in every epoch, there is feed-forward and backpropagation through the whole network, all layers. But what if you have CNN network to extract features and LSTM network that takes sequences as inputs. How to train CNN network if there is no defined output? This network should only extract features but the network doesn't know what features. So the question is: How to train CNN to extract relevant features and then passing these features to LSTM?</p>\n", "pids": ["5eede0b091e0116a23aafc15"], "flag": 1}
{"question": "How often do good journals publish amusing little corollaries?", "body": "<p>I've had a little corollary sitting around a while now. It is closely related to a major theorem in my area.  Its statement is easy to understand (and rather interesting/amusing on the surface of it) and it's proof can be written in a couple of paragraphs.  </p>\n\n<p>I thought it had potential to be the beginnings of a nice paper, but I've struggled to find good \"related stuff\" to add to it.  </p>\n\n<p>Should I just submit this little 1.5 page paper, or would I be wasting everyone's time?  Do any good journals regularly accept these kinds of \"notes\"?</p>\n", "pids": ["5c7561c4f56def9798d8611d"], "flag": 1}
{"question": "Why is Google Scholar popular in some fields but not in others?", "body": "<p>In disciplines such as computer science and engineering, Google Scholar is a fundamental tool in not only searching for recent work of a researcher but is also frequently used as a metric for the proficiency of the researcher.</p>\n\n<p>I've noticed in many other fields, e.g. political science, or even math, Google Scholar is not nearly as popular. </p>\n\n<p>Does anyone have any insight into why this is the case? Do these other fields have other tools they use to follow researchers or measure their output? Perhaps these factors are not as important in these other fields?</p>\n", "pids": ["53e99bdcb7602d9702483fee"], "flag": 1}
{"question": "Have agents that &quot;dream&quot; been explored in Reinforcement Learning?", "body": "<p>I was reading <a href=\"https://www.unil.ch/files/live/sites/ln/files/shared/Revonsuo_1.pdf\" rel=\"nofollow noreferrer\">this article</a> about the question &quot;Why do we dream?&quot; in which the author discusses dreams as a form of rehearsal for future threats, and presents it as an evolutive advantage. My question is <strong>whether this idea has been explored in the context of RL</strong>.</p>\n<p>For example, in a competition between AIs on a shooter game, one could design an agent that, besides the behavior it has learned in a &quot;normal&quot; training, seeks for time in which is out of danger, to then use its computation time in the game to produce simulations that would further optimize its behavior. As the agent still needs to be somewhat aware of its environment, it could alternate between processing the environment and this kind of simulation. Note that this &quot;in-game&quot; simulation has an advantage with respect to the &quot;pre-game&quot; simulations used for training; the agent in the game experiences the behavior of the other agents, which could not have been predicted beforehand, and then simulates on top of these experiences, e.g. by slightly modifying them.</p>\n<p><strong>For more experienced folks, does this idea make sense? has something similar been explored?</strong></p>\n<p>I have absolutely no experience in the field, so I apologize if this question is poorly worded, dumb or obvious. I would appreciate suggestions on how to improve it if this is the case.</p>\n", "pids": ["599c796d601a182cd263c436"], "flag": 1}
{"question": "What is the difference (in a recording) between speech and a sound? What makes the difference to the brain?", "body": "<p>How does the brain cognitively differentiate between speech and a sound within a recording?  I am asking this theoretical question for speech synthesis, i.e. Making a voice with just waves (no recordings). Is this even possible?</p>\n", "pids": ["53e9ba54b7602d9704669cc1", "61c847265244ab9dcbe6b64b", "55a64f8165ce054aad640eac", "53e9aca1b7602d970367ab05", "53e9a50eb7602d9702e2dca2", "53e9adc7b7602d97037cdb21", "53e99bf0b7602d970249d185", "53e9ac48b7602d9703618d1c", "56d8e302dabfae2eee1edfe3"], "flag": 0}
{"question": "Referencing if a YouTube video is the sole source", "body": "<p>I have information that I found on YouTube, and when I searched for it on Google, I did not find it in any book, not even in an article, and nor in Google Scholar. Can I mention this information without a reference?</p>\n<p>I am afraid that it will have a reference without my knowledge.</p>\n", "pids": ["5f48ddd99fced0a24beae54c"], "flag": 1}
{"question": "Validity of limerance as a romantic evolutionary stage", "body": "<p>I was looking into the concept of <a href=\"https://www.wikiwand.com/en/Limerence#/overview\" rel=\"nofollow noreferrer\">limerence</a> as a stage of evolution in a romantic relationship, however I can't find any sources for it other than its origin in the book \"Love and Limerence: The Experience of Being in Love\" by Dorothy Tennov. Has there been any criticism of this as a concept, not as diagnosis for abnormal psychology? I'm somewhat skeptical of any psychological concept put forth by a single part without external validation.</p>\n", "pids": ["53e999d8b7602d970221de04", "53e99c7cb7602d970252b502", "53e9b43db7602d9703f38e0d"], "flag": 1}
{"question": "Do antidepressants provide a permanent solution for depression and anxiety?", "body": "<p>Antidepressants works temporarily (as long as you take them), and also affects the cognitive behaviour. Should they be seen as a permanent solution for depression? Shouldn't we find a solution at the psychosocial level, which actually works rather than suppressing the thoughts?</p>\n", "pids": ["5ae67c3e1b13da3b95e54fb4", "53e99d74b7602d9702630c11", "53e99eaeb7602d9702779b06"], "flag": 1}
{"question": "Is there a word or phrase that describes emotional self harm?", "body": "<p>Is psychologically/mentally self harming yourself on purpose possible, where you look for things that trigger you (trigger your anxiety, stress or PTSD), not to desensitise yourself but to hurt yourself? Is there a word for it?</p>\n", "pids": ["55a38f5d65ce5cd7b3ae9ffa", "53e9aae6b7602d9703465d19", "53e9a317b7602d9702c1e327"], "flag": 1}
{"question": "Can sport be used as a counselling tool to help one deal with negative life events?", "body": "<p>I found studies on how leisure activities can positively affect well-being, e.g. stress reduction.<br>\nMy question is more specific as I want to research how participation in sport can help one deal with difficult life circumstances like for instance loss of a loved one or abuse.  Academic literature in this area seems to be very scarce.  </p>\n\n<p>My aim would be to bring out the implications for counselling practice and demonstrate that sport participation is effective in dealing with negative life events. </p>\n", "pids": ["55a3d49a65ce5cd7b3b93765"], "flag": 0}
{"question": "Is GPT-3 an early example of strong AI in a narrow setting?", "body": "<p>In GPT-2, the large achievement was being able to generate coherent text over a long-form while maintaining context. This was very impressive but for GPT-2 to do new language tasks, it had to be explicitly fine-tuned for the new task.</p>\n<p>In GPT-3 (From my understanding), this is no longer the case. It can perform a larger array of language tasks from translation, open domain conversation, summarization, etc., with only a few examples. No explicit fine-tuning is needed.</p>\n<p>The actual theory behind GPT-3 is <em>fairly</em> simple, which would not suggest any level of ability other than what would be found in common narrow intelligence systems.</p>\n<p>However, looking past the media hype and the news coverage, GPT-3 is not explicitly programmed to &quot;know&quot; how to do these wider arrays of tasks. In fact, with limited examples, it can perform many language tasks quite well and &quot;learn on the fly&quot; so to speak. To me, this does seem to align fairly well with what most people would consider strong AI, but in a narrow context, which is language tasks.</p>\n<p>Thoughts? Is GPT-3 an early example of strong AI but in a narrower context?</p>\n", "pids": ["5e2ac03c3a55ac8999c1ad99"], "flag": 1}
{"question": "How is Google Translate able to convert texts of different lengths?", "body": "<p>According to my experience with Tensorflow and many other frameworks, neural networks have to have a fixed shape for any output, but how does Google translate convert texts of different lengths?</p>\n", "pids": ["5550410f45ce0a409eb384f8", "599c7987601a182cd2648373"], "flag": 1}
{"question": "How does the implementation of the VAE&#39;s objective function equate to ELBO?", "body": "<p>For a lot of VAE implementations I've seen in code, it's not really obvious to me how it equates to ELBO.</p>\n<p><span class=\"math-container\">$$L(X)=H(Q)-H(Q:P(X,Z))=\\sum_ZQ(Z)logP(Z,X)-\\sum_ZQ(Z)log(Q(Z))$$</span></p>\n<p>The above is the definition of ELBO, where <span class=\"math-container\">$X$</span> is some input, <span class=\"math-container\">$Z$</span> is a latent variable, <span class=\"math-container\">$H()$</span> is the entropy. <span class=\"math-container\">$Q()$</span> is a distribution being used to approximate distribution <span class=\"math-container\">$P()$</span>, which in the above case both <span class=\"math-container\">$P()$</span> and <span class=\"math-container\">$Q()$</span> are discrete distributions, because of the sum.</p>\n<p>A lot of the times when VAEs are built for reconstructing discrete data types, let's say for example an image, where each pixel can be black or white or <span class=\"math-container\">$0$</span> or <span class=\"math-container\">$1$</span>. The main steps of a VAE that I've seen in code are as follows:</p>\n<ol>\n<li><span class=\"math-container\">$\\text{Encoder}(Y) \\rightarrow Z_u, Z_{\\sigma}$</span></li>\n<li><span class=\"math-container\">$\\text{Reparameterization Trick}(Z_\\mu, Z_\\sigma) \\rightarrow Z$</span></li>\n<li><span class=\"math-container\">$\\text{Decoder}(Z) \\rightarrow \\hat{Y}$</span></li>\n<li><span class=\"math-container\">$L(Y)= \\text{CrossEntropy}(\\hat{Y}, Y) - 0.5*(1+Z_{\\sigma}-Z_{\\mu}^2-exp(Z_\\sigma))$</span></li>\n</ol>\n<p>where</p>\n<ul>\n<li><span class=\"math-container\">$Z$</span> represents the latent embedding of the auto-encoder</li>\n<li><span class=\"math-container\">$Z_\\mu$</span> and <span class=\"math-container\">$Z_\\sigma$</span> represent the mean and standard deviation for sampling for <span class=\"math-container\">$Z$</span> from a Gaussian distribution.</li>\n<li><span class=\"math-container\">$Y$</span> represents the binary image trying to be reconstructed</li>\n<li><span class=\"math-container\">$\\hat{Y}$</span> represents its reconstruction from the VAE.</li>\n</ul>\n<p>As we can see from the ELBO, it's the entropy of the latent distribution being learned, <span class=\"math-container\">$Q()$</span>, which is a Gaussian, and the cross entropy of the latent distribution being learned <span class=\"math-container\">$Q()$</span> and the actual distribution <span class=\"math-container\">$P()$</span> with <span class=\"math-container\">$Z$</span> intersected with <span class=\"math-container\">$X$</span>.</p>\n<p>The main points that confuse me are</p>\n<ul>\n<li>how <span class=\"math-container\">$\\text{CrossEntropy}(\\hat{Y}, Y)$</span> equates to the CE of the distribution for generating latents and its Gaussian approximation, and</li>\n<li>how <span class=\"math-container\">$(0.5*(1+Z_{\\sigma}-Z_{\\mu}^2-exp(Z_\\sigma)))$</span> equates to the entropy</li>\n</ul>\n<p>Is it just assumed the CE of <span class=\"math-container\">$Y$</span> with <span class=\"math-container\">$\\hat{Y}$</span> also leads to the CE of the latent distribution with it's approximation, because they're part of <span class=\"math-container\">$\\hat{Y}$</span>'s generation? It still seems a bit off because you're getting the cross entropy of <span class=\"math-container\">$Y$</span> with it's reconstruction, not the Gaussian distribution for learning latents <span class=\"math-container\">$Z$</span>.</p>\n<p>Note: <span class=\"math-container\">$Z_\\sigma$</span> is usually not softplused to be strictly positive as required by a Gaussian distribution, so I think that's what <span class=\"math-container\">$exp(Z_\\sigma)$</span> is for.</p>\n", "pids": ["5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "In DQN, is it possible to make some actions more likely?", "body": "<p>In a general DQN framework, if I have an idea of some actions being better than some other actions, is it possible to make the agent select the better actions more often?</p>\n", "pids": ["599c7983601a182cd2646bef"], "flag": 1}
{"question": "How economically efficient is the grant system?", "body": "<p>I wonder if someone (or eventually some country, organisation, etc ...) already evaluated the costs of the system of grants. </p>\n\n<ul>\n<li>It costs at least the salary of the researcher who writes and gets the grant</li>\n<li>but also the salary of all the researchers who didn’t get it, and could have done something else than writing a proposal</li>\n<li>plus the costs in administration (e.g. the National Contact Point(s) in Europe at several places in each country)</li>\n<li>plus the cost of organising the referral (travels, meetings, ...)</li>\n<li>plus the cost of the grant itself, of course.</li>\n</ul>\n\n<p>On the positive side, of course the entire society benefits from a completed grant.</p>\n\n<p>So my questions are:</p>\n\n<ul>\n<li>Are there some studies about the economical efficiency of the grant system?</li>\n<li>What are their conclusions?</li>\n<li>How much does the granting costs?</li>\n<li>Are there other system evaluated?</li>\n</ul>\n\n<p>Partially related questions : </p>\n\n<ul>\n<li><p><a href=\"https://academia.stackexchange.com/q/13354/7919\">How much time do researchers spend on writing grants?</a></p></li>\n<li><p><a href=\"https://academia.stackexchange.com/q/27594/7919\">How to quantify the loss in productivity due to time spent on writing proposals</a></p></li>\n</ul>\n\n<p>but this question is really about the economy of research and factual investigations about the system of grants, not about feeling from researchers.</p>\n", "pids": ["5f61df61266885cfe9de5822", "53e9bd87b7602d9704a29f69", "53e998b8b7602d97020efdf5"], "flag": 1}
{"question": "Is a concept of machiavellianism useful?", "body": "<p>I can't be classified by wikipedia as someone clearly machiavellian (I'm hedonist (in the sence of general pleasure/pain, not only physical) and try not to hurt other people). Yet, I managed to score 80 on MACH-IV. But I doubt that questions are well selected. In fact almost every question is ambiguous or ill-posed (it's sometimes about belief that everyone is a kind person, I'm not an ultra-optimist, I'm realist and sometimes just about being average person).</p>\n\n<p>By the way, I could not see anything in this test that could reveal machiavellian traits. Moreover, most study show only a weak correlation between them and high score in test. The real correlation is around .2 if not lower, which makes it unreliable.</p>\n\n<p>What I'm thinking is that people with similar [to mine] philosophy also can score higher than average just for similar reasons. And it's completely weird, since philosophies are too different.</p>\n\n\n\n<p>Well, for example, I know that concepts of narcissism (but NPI still has around of half useless questions in my opinion) and psychopathy are much better defined and appropriate tests seem to be more accurate. Yet, if there is another type of personality, that may ruin lifes of other people, it can't be revealed by MACH-IV.</p>\n\n<p>In fact statistics show that mean score is around 67 or so, which is considered as high Mach. If majority are high Machs, then there is no dark triad. Also, the form of graph is symmetrical, while form of graph on NPI test is highly assymmetrical.</p>\n\n<p>So, is it just a canard or is there some evidence, that such personality type exists (and it is something that is useful in terms of psychology)? (Of course, some people may treat themselves as the only really clever ones, who should rule the world, but yet think that they look as average person; which is some kind of narcissism).</p>\n", "pids": ["53e9b03db7602d9703a9a629", "62823f4f5aee126c0f98b8fb"], "flag": 1}
{"question": "Is it possible to pre-train a CNN in a self-supervised way so that it can later be used to solve an instance segmentation task?", "body": "<p>I would like to use self-supervised learning (SSL) to learn features from images (the dataset consists of similar images with small differences), then use the resulting trained model to bootstrap an instance segmentation task.</p>\n<p>I am thinking about using Faster R-CNN, Mask R-CNN, or ResNet for the instance segmentation task, which is pre-trained in an SSL way by solving a pretext task, with the aim that this will lead to higher accuracy and also teach the CNNs with fewer examples during the downstream task.</p>\n<p>Is it possible to use SSL to pre-train e.g. a faster R-CNN on a pretext task (for example, rotation), then use this pre-trained model for instance segmentation with the aim to get better accuracy?</p>\n", "pids": ["5e369fba3a55ac9d11d4933f"], "flag": 1}
{"question": "Do antisense transcripts have different names than their sense strand transcripts?", "body": "<p>I want to find which genes in the human genome can potentially be complementary to a transcript that could act as antisense transcript inhibtion? Are cis-NATs (naturally occuring anti-sense transcripts) considered different transcripts and named differently or do they have the same name as the sense transcript?</p>\n", "pids": ["53e999bbb7602d97022020f7"], "flag": 1}
{"question": "Is there a taxonomy of adversarial attacks?", "body": "<p>I am a medical doctor working on methodological aspects of health-oriented ML. Reproducibility, replicability, generalisability are critical in this area. Among many questions, some are raised by adversarial attacks (AA).</p>\n<p>My question is to be considered from a literature review point of view: suppose I want to check an algorithm from an AA point of view:</p>\n<ul>\n<li>is there a systematic methodology approach to be used, relating format of the data, type of models, and AA? Conceptually, is there a taxonomy of AA? If so, practically, are some AA considered as gold standards?</li>\n</ul>\n", "pids": ["5a73cbcc17c44a0b3035f399"], "flag": 1}
{"question": "How robust are deep networks to class imbalance?", "body": "<p>Before deep learning, I worked with machine learning problems where the data had a large class imbalance (30:1 or worse ratios). At that time, all the classifiers struggled, even after under-sampling the represented classes and creating synthetic examples of the underrepresented classes -- except Random Forest, which was a bit more robust than the others, but still not great.</p>\n<p>What are guidelines for class distribution when it comes to deep learning (CNNs, ResNets, transformers, etc)? Must the representation of each class be 1:1? Or maybe it's &quot;good enough&quot; as long as it is under some ratio like 2:1? Or is deep learning completely immune to class imbalance as long as we have enough training data?</p>\n<p>Furthermore, as a general guideline, should each class have a certain minimum number of training examples (maybe some multiple of the number of weights of the network)?</p>\n", "pids": ["6124dd7091e0114cbe7a8c1c"], "flag": 1}
{"question": "Why is neural networks being a deterministic mapping not always considered a good thing?", "body": "<p>Why is neural networks being a deterministic mapping not always considered a good thing?</p>\n<p>So I'm excluding models like VAEs since those aren't entirely deterministic. I keep thinking about this and my conclusion is that often times neural networks are used to model things in reality, which often time do have some stochasticity and since neural networks are deterministic if they are not trained on enough examples of the possible variance inputs in relation to outputs can have they cannot generalize well. Are there other reasons this is not a good thing?</p>\n", "pids": ["573696006e3b12023e513cb6"], "flag": 1}
{"question": "Does the taste of sugar replenish willpower?", "body": "<p>In a post titled <a href=\"https://www.lesserwrong.com/posts/XKfQF73YnyMRiRf9a/willpower-depletion-vs-willpower-distraction\" rel=\"nofollow noreferrer\">Willpower Depletion vs Willpower Distraction</a> the claim is made that:</p>\n\n<blockquote>\n  <p>Basically, for a while some researchers believed that willpower\n  depletion \"is\" glucose depletion in the prefrontal cortex, but some\n  more recent experiments have failed to replicate this, e.g. by finding\n  that the mere taste of sugar is enough to \"replenish\" willpower faster\n  than the time it takes blood to move from the mouth to the brain:</p>\n</blockquote>\n\n<p>Is that claim representative of the knowledge we have from studies?</p>\n", "pids": ["5a9e68d4684d165d4bfab115"], "flag": 1}
{"question": "How does replacing states with latent representations help RL agents?", "body": "<p>I have seen many papers using autoencoders to replace images (states) with latent representations. Some of those methods have shown higher rewards using such techniques. However, I do not understand how this helps the RL agent learn better. Perhaps viewing latent representations allows the agent to generalize to novel states more quickly?</p>\n<p>Here are 2 papers I have read -</p>\n<ul>\n<li><a href=\"https://arxiv.org/abs/1509.06113\" rel=\"nofollow noreferrer\">Deep Spatial Autoencoders for Visuomotor Learning</a></li>\n<li><a href=\"https://arxiv.org/abs/1806.00630\" rel=\"nofollow noreferrer\">DAQN: Deep Auto-encoder and Q-Network</a></li>\n</ul>\n", "pids": ["5db9296f47c8f766461f6404", "5f6488cf91e011f934ad258c"], "flag": 1}
{"question": "Why are large models necessary when we have a limited number of training examples?", "body": "<p>In Goodfellow et al. book Deep Learning <a href=\"https://www.deeplearningbook.org/contents/applications.html\" rel=\"nofollow noreferrer\">chapter 12.1.4</a> they write</p>\n<blockquote>\n<p>These large models learn some function <span class=\"math-container\">$f(x)$</span>, but do so using many more parameters than are necessary for the task. Their size is necessary only due to the limited number of training examples.</p>\n</blockquote>\n<p>I am not able to understand this. Large models are expressive, but if you train them on few examples they should also overfit.</p>\n<p>So, what do the authors mean by saying large models are necessary precisely because of the limited number of training examples?</p>\n<p>This seems to go against the spirit of using more bias when training data is limited.</p>\n", "pids": ["599c7dbb601a182cd284b20f"], "flag": 1}
{"question": "Can the rewards be matrices when using DQN?", "body": "<p>I have a basic question. I'm working towards developing a reward function for my DQN. I'd like to train an RL agent to edit pixels on an image. I understand that convolutions are ideal for working with images, but I'd like to observe the agent doing it in real-time. Just a fun side project.</p>\n<p>Anyway, to encourage an RL agent to craft a specific image I'm crafting a reward function that returns a <span class=\"math-container\">$N \\times N$</span> dimensional matrix. Which represents the distance between the state of the target image (RGB values for each pixel location) and the image the agent crafted.</p>\n<p>Generally speaking, is it better for rewards to be a scalar, or is using matrices okay?</p>\n", "pids": ["5de7995a9e795e77580692e4"], "flag": 1}
{"question": "Is there any research about effect of unfamiliar environment on stress?", "body": "<p>It seems intuitive to me that there is some kind of stress when one is put in an unfamiliar place (There's probably effect on cognitive abilities too). However, I can't find any paper in psychology which discusses that potential relationship.</p>\n", "pids": ["55a47e4565ce31bc877cd228", "55a451e72401c6de3b8f30cd"], "flag": 1}
{"question": "Would it be possible to determine the dataset a neural network was trained on?", "body": "<p>Let's say we have a neural network that was trained with a dataset <span class=\"math-container\">$D$</span> to solve some task. Would it be possible to &quot;reverse-engineer&quot; this neural network and get a vague idea of the dataset <span class=\"math-container\">$D$</span> it was trained on?</p>\n", "pids": ["5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "Is feature engineer an important step for a deep learning approach?", "body": "<p>I'd like to ask you if feature engineering is an important step for a deep learning approach.</p>\n<p>By feature engineering I mean some advanced preprocessing steps, such as looking at histogram distributions and try to make it look like a normal distribution or, in the case of time series, make it stationary first (not filling missing values or normalizing the data).</p>\n<p>I feel like with enough regularization, the deep learning models don't need feature engineering compared to some machine learning models (SVMs, random forests, etc.), but I'm not sure.</p>\n", "pids": ["5fc7685e91e0114897921118"], "flag": 1}
{"question": "In VQ-VAE code what does this line of code signify?", "body": "<p>The VQ-VAE implimentation:<a href=\"https://colab.research.google.com/github/zalandoresearch/pytorch-vq-vae/blob/master/vq-vae.ipynb\" rel=\"nofollow noreferrer\">https://colab.research.google.com/github/zalandoresearch/pytorch-vq-vae/blob/master/vq-vae.ipynb</a></p>\n<pre><code>quantized = inputs + (quantized - inputs).detach()\n</code></pre>\n<p>Why are we subtracting and adding input to quantized result?</p>\n", "pids": ["5a260c0917c44a4ba8a1dfbc"], "flag": 1}
{"question": "How does a neural network that has been trained keep learning while in a real world scenario", "body": "<p>Say I trained a Neural Network (not RNN or CNN) to classify a particular data set.</p>\n<p>So I train using a specific data set &amp; then I test using another and get an accuracy of 95% which is good enough.</p>\n<p>I then deploy this model in a production level environment where it will then be processing real world data.</p>\n<p>My question is, will this trained NN be constantly learning even in a production scenario? I can't figure out how it will because say it processes a dataset such as this:\n<code>[ [1,2,3] ]</code> and gets an output of <code>[ 0, 0.999, 0 ]</code></p>\n<p>In a training scenario it will compare the predicted output to the actual output and back propagate but in a real world scenario it will not know the actual value.</p>\n<p>So how does a trained model learn in a real world scenario?</p>\n<p>I am still very much a beginner in this field and I am not sure if the technology used is going to affect the answer to this question, but I am hoping to use Eclipse Deeplearning4J to create a NN. That being said the answer does not need to be restricted to this technology in particular as I am hoping more for the theory behind it and how it works.</p>\n", "pids": ["5ac1829d17c44a1fda918136"], "flag": 1}
{"question": "Why is it that the state visitation frequency equals the sum of state visitation frequency from initial time step to the horizon?", "body": "<p>In the maximum entropy inverse reinforcement learning paper, Ziebart <em>et al</em>. show that the state visitation frequency <span class=\"math-container\">$\\rho(s)$</span> of a state <span class=\"math-container\">$s$</span> can be computed as\n<span class=\"math-container\">$$\n\\rho_{\\pi}(s) = \\sum_{t}^{T} P(s_t=s|\\pi),\n$$</span>\nwhich is the sum of the probability that the state being visited at each time step.</p>\n<p>I just don't understand why is it the sum? From my perspective, a frequency should be the less than one, so that it should be the average value\n<span class=\"math-container\">$$\n\\rho_{\\pi}(s) = \\frac{1}{T}\\sum_{t}^{T} P(s_t=s|\\pi).\n$$</span></p>\n", "pids": ["5b67b4b117c44aac1c866bd8"], "flag": 1}
{"question": "Is it possible to use an internal layer&#39;s outputs in a loss function?", "body": "<p>For a network of the form:</p>\n<pre><code>Input(10)\nDense(200)\nDense(100+10)\nDense(20)\nOutput()\n</code></pre>\n<p>Those <code>+10</code> outputs are what I want to add to the standard <code>20</code> outputs, for my loss function.</p>\n<p>Is this possible - in theory or even with some pre-existing library?</p>\n", "pids": ["5550417d45ce0a409eb3bc08"], "flag": 1}
{"question": "How would the performance of federated learning compare to the performance of centralized machine learning when the data is i.i.d.?", "body": "<p>How would the performance of federated learning (FL) compare to the performance of centralized machine learning (ML), when the data is independent and identically distributed (i.i.d.)?</p>\n<p>Moreover, what is the difference in the performance of FL when the data is i.i.d. as compared to non-i.i.d?</p>\n", "pids": ["5f9be91791e011dcf482d998", "5da98d3b3a55ac6485652260"], "flag": 1}
{"question": "How do I increase the size of an (almost) balanced dataset?", "body": "<p>I am trying to add more data points in my (almost) balanced dataset for training my neural network. I have come across techniques such as SMOTE or Random Over Sampling, but they work best for imbalanced data (as they balance the dataset). How can I do this and is it even worth it?</p>\n<p>P.S. I know copying the same data points and appending them at the end doesn't add much value, but can we do it, and can it help to increase the prediction accuracy?</p>\n", "pids": ["5a260c8117c44a4ba8a30b08"], "flag": 1}
{"question": "Data augmentation for very small image datasets", "body": "<p>I am looking for techniques for augmenting very small image datasets. I have a classification problem with 3 classes. Each class consists of 20 different shapes. The shapes are similar between the classes, but the task is to identify which class the shapes belong to. Per shape, I have between 1 and 35 training examples. For two classes, I have 25 training examples per shape, but the number of examples per shape for the third classes is usually around 5. Now, what data augmentation schemes do you recommend? Geometric / affine transformations seem like a good place to start. However, I have also thought of applying Fast Fourier Transform (do the forward transform, add some noise, do the inverse transform). GANs seem infeasible, right? Not enough data, I suspect. In any case, I am grateful for your advice.</p>\n", "pids": ["6066ef9791e011f2d6d47bb8", "5f0bde8c9e795ea206ff8ef3"], "flag": 1}
{"question": "In style transfer, why does the comparison between channels give a good sense of style?", "body": "<p>I have been learning about Style Transfer recently. Style is defined as</p>\n<blockquote>\n<p>The correlation of activations between channels.</p>\n</blockquote>\n<p>I can't seem to understand why that would be true. Intuitively, style seems to be the patterns that exist in one particular channel/image rather than the patterns between channels. When filters in CNNs have different weights for acting as filters for different channels, why do we even expect 2 channels to be correlated? And further, why do we expect the style to be conveyed by it?</p>\n<p>I expected a style function that could compare activations in some layer of a CNN condensed into one channel so that an algorithm can search for which activations occur simultaneously and hold style information.</p>\n<p>I understand how we are carrying out the operations with the matrix and defining the loss function, what I don't get is why we are assuming style information lies in correlation between channels in the first place.</p>\n", "pids": ["58d82fd2d649053542fd792a", "573695fe6e3b12023e511894"], "flag": 1}
{"question": "Jung&#39;s Anima and Neurological Basis in Split-Brain Patients; Left-Persona and Right-Anima", "body": "<p>So, having skimmed some studies on split-brain patients, it makes me wonder about the whole \"left-brain/right-brain\" dichotomy that made its rounds in public perception some time ago.</p>\n\n<p>I'm not sure how much of that is really good science, but it looks like there's some real truth to the different sides taking on different roles and cognitive abilities.</p>\n\n<p>One thing in particular I wonder about now, is can you map Carl Jung's concept of Anima (I'll refer to the Anima, but what I have to say applies to Animus, as well) onto the right half of the brain?</p>\n\n<p>Jung's idea of Anima was essentially the male brain's mental image of \"the typical woman\". Thus it would posses typically feminine traits.</p>\n\n<p>Since the right half of the brain is associated with creativity, emotional response to (ie, recognizing) faces, and is more typically \"feminine\", would it be possible to devise an experiment with MRI to see if invoking the anima fires more neural activity on the right half of the brain?</p>\n\n<p>Say, have a subject describe \"the typical woman\" and watch activity, have them describe \"the typical man\" and some other controls to also invoke creativity and see how the neural activity compares? See if when men don a dress, their right-brain fires more activity than if they just don any other unfamiliar clothing (a hospital gown or a robe are gender-neutral but may also be unfamiliar enough to control for that part alone)?</p>\n\n<p>It's a very roundabout way of asking, but hopefully the questions kind of highlight the underlying question; </p>\n\n<p>in terms of Jungian Psychology, is it reasonable to hypothesize that you could split the hemispheres of the brain into \"persona\" and \"Anima\" as \"left\" and \"right\"? (and perhaps reversed for Persona and Animus)</p>\n\n<p>The interesting thing is that this leads to a testable hypothesis perhaps some people here already know the answer to: Is there any link between gender dysphoria and right-brain dominance? If there is, that would seem to support that hypothesis that the left hemisphere generally takes the masculine identity and the right houses the Anima (in general, though I would expect if the Anima exists as a largely separate neural network (or combined set of networks) that it would probably at least share a little activity on the left hemisphere).</p>\n", "pids": ["5f0e71869fced0a24b3ae58d", "5f0e71869fced0a24b3ae58d"], "flag": 1}
{"question": "Is there a multi-agent deep reinforcement learning algorithm which is for environments with only discrete action spaces (Not hybrid)?", "body": "<p>Is there a multi-agent deep reinforcement learning algorithm which is for environments with only discrete action spaces (Not hybrid) and have centralized training?</p>\n<p>I have been looking for algorithms, (A2C, MADDPG etc.) but still havent find any algorithm that provides all of properties i mentioned (Multi agent + discrete action space + deep learning + centralized training).</p>\n<p>I am wondering if we use an actor network that gets state as input and concatenated discrete actions of agents as output (For example if agent has 3 actions and we have 4 agents output can be [0,0,1, 0,1,0, 0,0,1, 1,0,0]) is that would be bad idea ?</p>\n", "pids": ["599c7965601a182cd2638f6c"], "flag": 1}
{"question": "How many types of variational auto-encoders are there?", "body": "<p>I have been studying about auto-encoders and variational auto-encoders. I would like to know how many variants of VAEs are there today.</p>\n<p>If there are many variants, can they be used for feature extraction for complex reinforcement learning tasks like self-driving cars?</p>\n", "pids": ["599c7b5a601a182cd272c31f", "5c2348ceda562935fc1d5722", "5736960d6e3b12023e5204bd", "5c8791d44895d9cbc62bd80b"], "flag": 1}
{"question": "Which AI techniques are there that combine multiple models to make sense of data at different stages?", "body": "<p>I have been working to design a system that uses multiple machine learning models to make sense of data that is dynamically webscraped. Each AI would handle a specific task, for example:</p>\n<p>An AI model would identify text in an image, then attempt to create plain text of what it might be. Once the text is extracted, it would be passed in a stored variable to an AI that can read the text to determine if it is a US city/state.</p>\n<p>I tried to look into if others have done this, but didn't find much on it relating to what I was looking for. Does anyone know if there are potential issues with this? Logically, it looks good to me, but I figured I'd ask.</p>\n<p>If anyone can put me in the right direction for reading material or further information, I would appreciate it.</p>\n", "pids": ["5fb7975191e01122f29d695a"], "flag": 1}
{"question": "What is the difference between feature extraction and fine-tuning in transfer learning?", "body": "<p>I'm building a model for <strong>facial expression recognition</strong>, and I want to use <em><strong>transfer learning</strong></em>. From what I understand, there are different steps to do it. The first is the <strong>feature extraction</strong> and the second is <strong>fine-tuning</strong>. I want to understand more about these two stages, and the difference between them. Must we use them simultaneously in the same training?</p>\n", "pids": ["5cede0f9da562983788d8458"], "flag": 1}
{"question": "Are emotions a function of muscle contractions? If so, how does the map look like?", "body": "<p>I hope this is the right (or rightest) place to ask this question, I wasn't sure whether this question is more appropriate for cogsci or biology. After all, it does concern the biology of emotions.</p>\n\n<p>To my knowledge, it is established research that the brain 'knows' what emotions you are having by examining their manifestations in the body. This absurd rube-goldbergian wiring can for instance be used to force oneself to become happier (at least temporarily) by smiling for a few minutes.</p>\n\n<p><em>This brings up the question, whether emotions have any identity separate from a cluster of bodily sensations (or even more specifically, muscle contractions) at all.</em></p>\n\n<p>It is certainly true (by introspection for e.g.) that 'negative' emotions are accompanied by muscle contradictions. On the other hand, there are several different 'negative' emotions that can be easily distinguished by the person having the emotion (e.g. shame and fear). Unfortunately I am not able to simply recall the sensations I had when I was ashamed or fearful from memory and compare them, but I would assume you could even tell from the outside, simply by looking at the person afflicted, which of the two emotions they are going through.</p>\n\n<p><em>So, what does the research say? Are emotions uniquely recognizable by facial expression/muscle contractions? Or do emotions have some kind of 'hidden variables' in the brain?</em></p>\n", "pids": ["55a4d89f612c6b12aafbabf5"], "flag": 1}
{"question": "Will some people ever be able to make our dreams visible on a screen?", "body": "<p>There are many SF-films in which dreams of people can be seen by others on a TV-screen. Don't you have to put so many information gathering devices in a person's brain for this to accomplish, that dream can't enter your brain anymore?</p>\n", "pids": ["55aa8d6024017ee4447332b6", "53e9b6cab7602d970425226b", "573695886e3b12023e4a9f84", "53e9b0e6b7602d9703b609fc"], "flag": 1}
{"question": "What is an &quot;input embedding&quot; in the context of NLP?", "body": "<p>When reading about NLP, I saw it said that &quot;input embeddings&quot; are a main element of encoder-decoder learning frameworks for sequence modelling. What is an &quot;input embedding&quot; in the context of NLP?</p>\n", "pids": ["53e9acc4b7602d97036a1037"], "flag": 1}
{"question": "Why adversarial images are not the mainstream for captchas?", "body": "<p>In order to check, whether the visitor of the page is a human, and not an AI many web pages and applications have a checking procedure, known as CAPTCHA. These tasks are intended to be simple for people, but unsolvable for machines.</p>\n<p>However, often some text recognition challenges are difficult, like discerning badly, overlapping digits, or telling whether the bus is on the captcha.</p>\n<p>As far as I understand, so far, robustness against adversarial attacks is an unsolved problem. Moreover, adversarial perturbations are rather generalizable and transferrable to various architectures (according to\n<a href=\"https://youtu.be/CIfsB_EYsVI?t=3226\" rel=\"nofollow noreferrer\">https://youtu.be/CIfsB_EYsVI?t=3226</a>).\nThis phenomenon is relevant not only to DNN but for simpler linear models.</p>\n<p>With the current state of affairs, it seems to be a good idea, to make CAPTCHAs from these adversarial examples, and the classification problem would be simple for human, without the need to make several attempts to pass this test, but hard for AI.</p>\n<p>There is some research in this field and proposed solutions, but they seem not to be very popular.</p>\n<p>Are there some other problems with this approach, or the owners of the websites (applications) prefer not to rely on this approach?</p>\n", "pids": ["5ce2d194ced107d4c64432a6"], "flag": 1}
{"question": "What&#39;s the difference between Confirmation Bias and the Affect Heuristic?", "body": "<p>I've been reading \"Thinking Fast &amp; Slow,\" by Daniel Kahneman. At the end of Chapter 9, he introduces the \"Affect Heuristic,\" a concept introduced by <a href=\"https://pdfs.semanticscholar.org/7f12/9787664da49795bc3ecd517c86b31d17bac7.pdf\" rel=\"nofollow noreferrer\">Paul Slovic</a> that effectively states that people let their likes and dislikes determine their beliefs about the world.</p>\n\n<p>Isn't this just an extension of confirmation bias - e.g. that people look for confirming evidence when evaluating ideas? It seems obvious that if you like something or dislike a concept, you'll search for evidence to affirm your preexisting position. For example - if I was a conservative and I learned of a bill introduced by a liberal politician, I'd naturally make the assumption that the bill is misguided and search for evidence to confirm that assumption (and vice-versa).</p>\n\n<p>What's the difference between them? I'm having trouble defining the \"Affect Heuristic\" clearly in my mind.</p>\n", "pids": ["5de0d716df1a9c0c415bb4c9"], "flag": 1}
{"question": "Why are BERT embeddings interpreted as representations of the corresponding words?", "body": "<p>It's often assumed in literature that BERT embeddings are contextual representations of the corresponding word. That is, if the 5th word is &quot;cold&quot;, then the 5th BERT embedding is a representation of that word, using context to disambiguate the word (e.g. determine whether it's to do with the illness or temperature).</p>\n<p>However, because of the self-attention encoder layers, this embedding can in theory incorporate information from any of the other words in the text. BERT is trained using masked language modelling (MLM), which would encourage each embedding to learn enough to predict the corresponding word. But why wouldn't it contain additional information from other words? In other words, is there any reason to believe the BERT embeddings for different words contain well-separated information?</p>\n", "pids": ["5bdc31b417c44a1f58a0b8c2", "5e58e54091e01189527e2b79"], "flag": 1}
{"question": "Why do we add 1 in the formula to calculate the shape of the output of the convolution?", "body": "<p>In the formula to calculate output shape of tensor after convolution operation\n<span class=\"math-container\">$$\nW_2 = (W_1-F+2P)/S + 1,\n$$</span>\nwhere:</p>\n<ul>\n<li><span class=\"math-container\">$W_2$</span> is the output shape of the tensor</li>\n<li><span class=\"math-container\">$W_1$</span> is the input shape</li>\n<li><span class=\"math-container\">$F$</span> is the filter size</li>\n<li><span class=\"math-container\">$P$</span> is the padding</li>\n<li><span class=\"math-container\">$S$</span> is the stride.</li>\n</ul>\n<p>Why do we add <span class=\"math-container\">$1$</span>? It gets us to the correct answer, but how is this formula derived?</p>\n<p>Source: <a href=\"https://cs231n.github.io/convolutional-networks/#pool\" rel=\"nofollow noreferrer\">https://cs231n.github.io/convolutional-networks/#pool</a></p>\n", "pids": ["573695ff6e3b12023e5136ef"], "flag": 1}
{"question": "Preconditioning before asking a favor", "body": "<p>Suppose I want to borrow an item, such as a phone charger from someone.</p>\n\n<p>Instead of directly asking them, \"Could I borrow a charger?\"</p>\n\n<p>I first ask this question: \"Do you have a charger?\"</p>\n\n<p>The act of asking a question of fact (whether they have the item or not) will make them more willing to lend you the item.</p>\n\n<p>Is there a term or explanation for this? </p>\n\n<p>Is this related or similar to the Ben Franklin effect and Anchoring effect?</p>\n", "pids": ["5aa213cbc13b2b7cf985672a"], "flag": 1}
{"question": "Is it realistic to train a transformer-based model (e.g. GPT) in a self-supervised way directly on the Mel spectrogram?", "body": "<p>In music information retrieval, one usually converts an audio signal into some kind &quot;sequence of frequency-vectors&quot;, such as STFT or Mel-spectrogram.</p>\n<p>I'm wondering if it is a good idea to use the transformer architecture in a self-supervised manner -- such as auto-regressive models, or BERT in NLP -- to obtain a &quot;smarter&quot; representation of the music than the spectrogram itself. Such smart pretrained representation could be used for further downstream tasks.</p>\n<p>From my quick google search, I found several papers which do something similar, but -- to my surprise -- all use some kind of symbolic/discrete music representation such as scores. (For instance <a href=\"https://arxiv.org/pdf/1809.04281.pdf\" rel=\"nofollow noreferrer\">here</a> or <a href=\"https://arxiv.org/pdf/1912.05537.pdf\" rel=\"nofollow noreferrer\">here</a>).</p>\n<p>My question is this:</p>\n<blockquote>\n<p>Is it realistic to train such an unsupervised model directly on the\nMel spectrogram?</p>\n</blockquote>\n<p>The loss function would not be &quot;log softmax of next word probability&quot;, but some kind of l2-distance between &quot;predicted vector of spectra&quot; and &quot;observed vector of spectra&quot;, in the next time step.</p>\n<p>Did someone try it?</p>\n", "pids": ["5a260c0917c44a4ba8a1dfbc", "5d06e47fda562926acc43871", "5eafe7e091e01198d3986663", "5f0d853d91e011047aff9876", "60717b3491e0117fe07c6dac", "5db80dc83a55acd5c14a266d"], "flag": 1}
{"question": "Markov Decision Processes with variable epoch lengths", "body": "<p>I am working on modeling a transportation problem as an MDP. Multiple trucks move material from one node to various other nodes in a network. However, the time it takes a truck to travel between any 2 nodes is different based on distance, and decisions are made when a truck arrives at a node. There lies the problem. Is it possible to have an MDP where the length of time between decision epochs is not uniform?</p>\n<p>The most similar MDP formulation I could find was the Semi-Markov Decision process, but that uses a random length epoch.</p>\n", "pids": ["5de799f19e795e775806935d"], "flag": 1}
{"question": "Resources about relaxation training as used in CBT", "body": "<p>I’m looking for resources about the relaxation training component of CBT. I had a professor who spent a good deal of time on it in class, but I’m no longer attending that school and he’s notoriously unresponsive to email. I’m looking for anything about the technique as used in cognitive-behavioral therapy.</p>\n\n<p>Our professor did mention <em>The Relaxation Response</em>, a book published in the ‘70s, was the basis for the type he was teaching about.</p>\n", "pids": ["5d455ece275ded87f98044ec"], "flag": 1}
{"question": "Can a face recognition system be trained using only computer generated hyper realistic faces?", "body": "<p>In order to train a face recognition system you need to have access to a large database with thousands of photos containing different faces. Companies like facebook and amazon have these databases but most average people do not.</p>\n<p>If you don't have access to a sufficiently large dataset with faces, could you use computer generated random faces instead? I'm asking this because computers are becoming better and better in rendering hyper realistic faces. An example is the <a href=\"https://www.youtube.com/watch?v=6MIkoLBWRv0\" rel=\"nofollow noreferrer\">meetmike digital human showcase video.</a> Another example is the <a href=\"https://www.youtube.com/watch?v=9owTAISsvwk\" rel=\"nofollow noreferrer\">unreal engine project spotlight video.</a>. Lastly you also have websites like <a href=\"https://thispersondoesnotexist.com/\" rel=\"nofollow noreferrer\">https://thispersondoesnotexist.com/</a> that can generate random faces.</p>\n<p>What if you generate a couple of photos of the same computer generated face and you make sure that each photo shows the face in a different setting or from a different angle. Could you then use such photos to train a facial recognition system that can accurately recognize real people?</p>\n", "pids": ["623b31d691e01142504ca43b", "624e569f5aee126c0f7f9095"], "flag": 1}
{"question": "Does the act of neural-repair fire off neurons?", "body": "<p><em>Disclaimer: I'm not well educated in this field, just a random curious person.  I don't know anything about neural repair save that it happens while we sleep.</em></p>\n\n<p>Anyways, the question is pretty simple: <strong>Does neural repair result in firing neurons?</strong></p>\n\n<p>Perhaps a damaged neuron being healed sometimes misfires, perhaps the little road workers that go around fixing neurons sometimes bump into things nearby and knock something loose, perhaps the processes of repairing leaves a bunch of neuro transmitters just floating in that area.. any of these could be a <em>reason for <strong>yes</em></strong>.</p>\n\n<p>A <em>reason for <strong>no</em></strong> might be \"We've studied where brain repair occurs, and where neurons are firing and there is no relation.\"</p>\n\n<p>Any solid speculation is nice too, as long as it's offered with a grain of salt.  </p>\n\n<p>I'm really just looking for something better than \"no clue.\"</p>\n", "pids": ["55a46e6465ce31bc877a79fd"], "flag": 1}
{"question": "What type of friends do narcissists have?", "body": "<p>For some time now, I have been looking up information on narcissism; however, <strong>I have never found information on the type of friends narcissists have.</strong> </p>\n\n<p>Research tends to show results about <code>narcissistic friends</code> which is not what I am trying to figure out.</p>\n\n<p><strong>So what is known about the types of friends narcissists have?</strong> I know that there tend to be different types of narcissists and they will probably have different types of friends, but there must be some kind of generalizations and specializations about friends.</p>\n", "pids": ["5c85f1924895d9cbc6fb2b9f", "56d924a3dabfae2eeeb36584", "5c79c19c4895d9cbc6694e03"], "flag": 0}
{"question": "Intracellular lipid transport", "body": "<p>I know that lipids are carried around the body in the blood either as micelles or by lipid-binding proteins which allow them to be solved.</p>\n\n<p>Lipids can't always be integrated in a membrane though, the phospholipids used in membranes have to be synthesised somewhere from a precursor which will also by hydrophobic.</p>\n\n<p>Consequently, at some point there will have to be transport of lipids within the cell where the lipids will need to be in solution. How is this facilitated?</p>\n", "pids": ["53e99dc5b7602d9702689cba"], "flag": 1}
{"question": "Benefits of Preserving Dopamine", "body": "<p>I recently came across a short piece on Twitter advocating for the preservation of dopamine release. The writer stated that a <a href=\"https://i.stack.imgur.com/yCD3X.jpg\" rel=\"nofollow noreferrer\">list of things</a> should be avoided to preserve dopamine.</p>\n\n<blockquote>\n  <p>Preserve your dopamine:</p>\n  \n  <ol>\n  <li>Turn off all social media notifications</li>\n  <li>Get to a commercial free place on TV and Internet</li>\n  <li>Zero real porn and limit controllable passive porn</li>\n  <li>Build in reflective time (I use a devotional)</li>\n  <li>Limit addictive substances (especially passive ones)</li>\n  </ol>\n</blockquote>\n\n<p>When I asked why, he stated that <a href=\"https://i.stack.imgur.com/qoixP.jpg\" rel=\"nofollow noreferrer\">preserving dopamine by avoiding these activities would mean I'd have more dopamine for other activities</a>:</p>\n\n<blockquote>\n  <p>No, the more places you spend dopamine, the less you have for the\n  things you need and the less you get from the things that are good for\n  you.</p>\n  \n  <p>Ex. Watching hardcore porn decreases your pleasure from healthy sex</p>\n</blockquote>\n\n<p>Is there truth to that statement? Is dopamine a truly finite resource that I won't produce more of each day if I spend it on these activities? Thus making me less motivated for important work. </p>\n\n<p>I'm looking for information on dopamine production and benefits of preservation in the answer. </p>\n", "pids": ["53e9adc7b7602d97037cf038"], "flag": 1}
{"question": "What is the best unobtrusive and objective method to measure mental workload?", "body": "<p>What is the current research/industry standard on measuring mental workload using objective measurements (e.g. EEG, eye-tracking)? </p>\n\n<p>Do you have any suggestions for specific tools and techniques? \nAre there combinations of physiological measurements one should consider?</p>\n", "pids": ["53e99e6ab7602d970272ea84"], "flag": 0}
{"question": "How does Cannabis cause psychosis?", "body": "<p>Whenever I research cannabis induced psychosis, I mostly get two types of results:</p>\n\n<p>1) Cannabis causes psychosis directly and a bunch of other issues (mostly misleading propaganda)</p>\n\n<p>2) There is no evidence that cannabis actually causes psychosis directly, rather it seems to be a correlation issue. (also misleading propaganda)</p>\n\n<p>However, my two best friends experienced permanent psychosis immediately after a heavy cannabis use episode (on separate occasions).</p>\n\n<p>I am convinced that cannabis is perfectly capable of causing or \"unlocking\" psychosis. I don't think that there is any question to this.</p>\n\n<p>But how does it actually work?</p>\n\n<p>In one of the cases, my friend had some very strong cannabis to smoke, after which he started to hear voices, and this never ended, even months after stopping smoking. Only after anti psychotic medication (Seroquel) did the symptoms stop, and they seem to be permanent, stopping the medication causes the symptoms to come back.</p>\n\n<p>From what I understand, Seroquel suppresses dopamine, while cannabis has nothing to do with dopamine.</p>\n\n<p>So how does cannabis induce a dopamine related disorder?</p>\n", "pids": ["55a4931065ceb7cb02d24116", "57e22a6e248a42004db6adad"], "flag": 1}
{"question": "Study on likability, weakness, and competence?", "body": "<p>I heard a podcast about a study (I think it was Radiolab or similar) that found that people are viewed as more likable after they reveal a weakness or a shortcoming, but the effect only occurs if they have established that they are competent. </p>\n\n<p>What is that study? The podcast said it is influential and well known.</p>\n\n<p>In the podcast, a professor told a story about how when he was a graduate student made a fool of himself in front of his PhD advisor and he joked that he did it on purpose to improve his likebility and she retorted that he hadn't yet established himself as competent. I remember hearing it in late 2014. Any help enormously appreciated!</p>\n", "pids": ["5ae172b9a2e6b107866a5f8e"], "flag": 0}
{"question": "People who climb the social hierarchy", "body": "<p>We know that people on top of the social hierarchy have (at least in developed countries) 30 or more years average life expectancy , more stable marriages, happier life and so on. So my question is for people who managed to get from the bottom to the top, what is their expected divorce rate, life expectancy and so on. It is more like the bottom or more like the top. Any research would help.</p>\n", "pids": ["55a4d62f612c6b12aafb5454"], "flag": 1}
{"question": "Can you give an example of automatic appraisal process?", "body": "<p><a href=\"https://i.stack.imgur.com/wbwLZ.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/wbwLZ.png\" alt=\"enter image description here\"></a></p>\n\n<p>I was reading this slide provided by my prof. of Affective Neuroscience.\nI've read that appraisal is considered a constitutive component of emotion by most of the actual theories.\nAppraisal is defined as the cognitive act to evaluate the potential impact that an external stimulus may have on me.</p>\n\n<p><strong>Can you provide an example of automatic appraisal?</strong></p>\n", "pids": ["59d98ddb0cf2415686e7d788"], "flag": 0}
{"question": "Do any plants exhibit hormonal changes similar to puberty?", "body": "<p>Just what the title states. </p>\n\n<p>Are there any plants/trees that exhibit a growth spurt at a definite interval after the shoot appears? </p>\n", "pids": ["53e9a650b7602d9702f810f6", "53e9b44bb7602d9703f48a8c", "55a497f765ceb7cb02d31a24", "55a4650bc91b587b097a8c75"], "flag": 1}
{"question": "Brain and General Sections", "body": "<p>Whereabouts in the brain gets triggered/switched on when an addictive substance is ingested/taken. I'm doing an addiction study with a couple of colleagues and would like some help with it.</p>\n", "pids": ["53e9b94db7602d9704539ed8"], "flag": 1}
{"question": "Biological Pathway of Lipid Hypothesis", "body": "<p>I've read a lot on both sides of the debate of low carb vs low fat diets trying to make some sense of what is being proposed. The lipid hypothesis runs roughly along the lines that we have lots of observational epidemiological evidence that eating a high fat diet correlates heart disease/obesity/enter disease of choice.</p>\n\n<p>An alternative hypothesis is that high carbohydrate diets cause these things. Since the studies haven't been done, there is not the correlation to point to. This hypothesis is believable (to some people) due to the well-understood biological pathway: Carbohydrates turn to glucose, which causes an insulin release, and insulin regulates fat storage, so high carbohydrate diets lead to weight gain (see a biochemsitry textbook for a more detailed explanation).</p>\n\n<p>My question is: Does the lipid hypothesis have any biological pathway for which there could be proposed a causal relation rather than just a correlation? Of all the speakers/writers on this topic, the low carb advocates always clearly describe the causal relation, whereas the low fat advocates never say <em>why</em> eating fat should cause weight gain.</p>\n\n<p>Note: I'm not interested in discussing the merits of the studies, but rather the proposed causal mechanism.</p>\n", "pids": ["55a4073c612ca6486881c61c"], "flag": 1}
{"question": "Do hallucinogenics affect chronic pain?", "body": "<p>As noted in a previous question, hallucinogenics, such as psilocybin, <a href=\"https://psychology.stackexchange.com/q/17840/4397\">have been used to treat depression with some success</a>. Chronic pain is affected somewhat by a top-down process from the brain, as shown in <a href=\"https://www.ncbi.nlm.nih.gov/pubmed/23532434\" rel=\"nofollow noreferrer\">neurofeedback treatment via EEG</a>. Have hallucinogenics been shown to be an effective treatment for chronic pain?</p>\n", "pids": ["53e9ad11b7602d97036efadd"], "flag": 0}
{"question": "At what point are MCTS results discarded in AlphaZero Training?", "body": "<p>Regarding the <a href=\"https://arxiv.org/pdf/1712.01815.pdf\" rel=\"nofollow noreferrer\">AlphaZero paper</a>, it is not clear to me when the Monte Carlo Tree Search (MCTS) results will be cleaned up.</p>\n<p>I assume this has to happen at some point, since mixing results could lead to lower quality results? Imagine in the self-play the Neural Network (NN) is updated to a new version and evaluates certain patterns differently by detecting a new trick. Many iterations must follow to outperform the old best choice (visit-count). I imagine discarding old MCTS results should be done about between an episode and the next NN weight updates.</p>\n<p>I feel that a wrong decision here could have a strong negative impact on the overall learning process.</p>\n", "pids": ["5cede101da562983788e0a61", "5a73cbcc17c44a0b3035f7b3", "59ec02da0cf22f5df7319dc3"], "flag": 1}
{"question": "Is there any domain in machine learning that solves a problem by using only analytical algorithms?", "body": "<p>Most of the algorithms in machine learning I am aware of use datasets and learning happens in an iterative manner given some examples. The examples can also be understood as experience in the case of reinforcement learning.</p>\n<p>Consider the following from <a href=\"https://www.deeplearningbook.org/contents/numerical.html\" rel=\"nofollow noreferrer\">Numerical Computation chapter of Deep Learning book</a></p>\n<blockquote>\n<p>Machine learning algorithms usually require a high amount of numerical computation. <strong>This typically refers to algorithms that solve mathematical problems by methods that update estimates of the solution via an iterative process, rather than analytically deriving a formula to provide a symbolic expression for the correct solution.</strong> Common operations include optimization (ﬁnding the value of an argument that minimizes or maximizes a function) and solving systems of linear equations. Even just evaluating a mathematical function on a digital computer can be diﬃcult when the function involves real numbers, which cannot be represented precisely using a ﬁnite amount of memory.</p>\n</blockquote>\n<p>I am wondering whether there is any domain in machine learning that deals with solving the problem analytically rather than computationally heavy iterative algorithms?</p>\n", "pids": ["5b67b4b917c44aac1c867c48", "609129b991e01105f877fb5f"], "flag": 1}
{"question": "Why do kefir grains stop growing in soy milk?", "body": "<p>Kefir is a fermented milk drink made with kefir grains. It usually is prepared by inoculating cow, goat or sheep milk with kefir grains.</p>\n\n<p>I would like to prepare the drink with soy milk, which worked fine for some months. Then the kefir grain stagnated in its growth. I use bottled soy milk from the supermarket. I do not produce the soy milk by myself.</p>\n\n<p>In \"real\" milk the kefir grains never stop growing (and dividing), but in soy milk they apparently do.</p>\n\n<p>Why do the kefir grains stop growing in soy milk? Are they lacking a specific nutrient that is only contained in milk from animals?</p>\n", "pids": ["53e9b289b7602d9703d2ecf3"], "flag": 1}
{"question": "Are there researched approaches to learning a subject more quickly?", "body": "<p>TLDR at bottom.</p>\n\n<p>So from my knowledge(correct me if I'm wrong) there is no evidence to suggest that we can improve general intelligence. But what about improving skills/intuition in specialized fields like programming or mathematics? </p>\n\n<p>I went through this course on coursera called Learning how to learn by Barbara Oakley(engineering professor) who suggests the following to quickly learn new subjects: </p>\n\n<ol>\n<li>Pomodoro technique 25 minutes study 5 min break</li>\n<li>Eliminate Distractions</li>\n<li>Do not neglect memory training. Recalling what you have studied is a great way to learn.</li>\n<li>Practice and consistency. </li>\n<li>Cramming is bad - it takes time to 'build neural chunks' as she says. I wasn't sure if this was based off of actual science or just conceptual. </li>\n</ol>\n\n<p>I do not like method 1 at all from my experience. Often times when I am going through technical textbooks and I have a timer randomly go off on me at 25 minutes in the session, I find myself jumping from my seat and my productivity wanes. However, timers at around 45 minutes(where my brain seems to slow down) does not have this kind of effect.</p>\n\n<p>But in Cal Newports Deep Work book, he suggests:</p>\n\n<ol>\n<li>Absolutely no distractions. Even delete social media from your life. Isolation can be a very ideal way of achieving deep levels of focus </li>\n<li>Be consistent.</li>\n<li>Do not tap in to willpower</li>\n<li>Use 'rituals' to turn the deep work mode on. </li>\n</ol>\n\n<p>From my experience, point 1 has severely reduced my ADHD symptoms and as a result my productivity has greatly improved. But even then, I still wonder to myself how much validity there are to these two professors approaches? Neither are neuroscientists, cognitive scientists, or psychology professors. I want to know if there is some kind of research, evidence(strong or weak), that there are more effective approaches to learning a specific field at a much faster pace. I have also read summaries of 'Peak' by Anders Erikson who is an apparent authority in this topic but I still haven't found anything eye opening. </p>\n\n<p><strong>Basically, is it possible to learn a subject at a much faster pace through the use of different studying techniques such as mnemonics, spaced repetition, etc.</strong></p>\n", "pids": ["56d920f1dabfae2eee9d50cb"], "flag": 1}
{"question": "Resources for reliable psychology research", "body": "<p>I'm looking for resources of reliable research in psychology. I mean 'reliable' in the following two senses:</p>\n\n<p><strong>1. Replicability</strong></p>\n\n<p>It seems more and more of the famous effects that I, as a psychology-curious layman, learned about by watching intro psych lectures or in popular media fail replication. It starts to seem like anything one believes to know about psychology is as likely as not to be false. As a layman it is quite difficult to track down all of the possible effects and replications thereof. Is there some resource which tracks the replication status of psychological research and collects the different effects which are reproducible (and which aren't)? </p>\n\n<p>EDIT: I was able to find the following which is actually pretty close to what I was looking for. This is not a complete list but it is the kind of thing that I am after.</p>\n\n<p><a href=\"https://osf.io/fgjvw/\" rel=\"nofollow noreferrer\">https://osf.io/fgjvw/</a></p>\n\n<p>I found this through the links in the accepted answer to <a href=\"https://psychology.stackexchange.com/questions/893/are-there-any-journal-articles-in-psychology-that-have-promoted-and-discussed-re/896#896\">this</a> SE question, which was suggested by a commenter below. However, now the comment is gone for some reason so I cannot give credit.</p>\n\n<p><strong>2. \"Bi-partisanship\"</strong></p>\n\n<p>Some areas of psychology are politically charged. Things like gender, race, intelligence, etc.,  are understandably controversial. It seems that often professional psychologists fall down on either side of a given issue, each insisting that it was settled by the scientific community long ago in their favour. As a layman, this is rather frustrating to make sense of. Is there some \"common ground\" resource which tracks the research that all sides agree on?</p>\n", "pids": ["5c7553d0f56def979862c521", "55a64e1865ce054aad63d45e"], "flag": 1}
{"question": "Can&#39;t use the urinal when next to someone. Is this psychological?", "body": "<p>It's a common symptom that men are unable to wee in public, for example in the urinals in a bar. This is sometimes called <a href=\"https://www.betterhealth.vic.gov.au/health/conditionsandtreatments/shy-bladder-syndrome\" rel=\"nofollow noreferrer\">shy-bladder syndrome</a> as far as I know.</p>\n\n<p>Is this condition known to have physiological grounds, or is it a psychological issue? </p>\n", "pids": ["53e99ddab7602d970269b7b9"], "flag": 0}
{"question": "Synesthesia hearing to see", "body": "<p>Can a <a href=\"https://www.youtube.com/watch?v=rkRbebvoYqI\" rel=\"nofollow noreferrer\">synesthetic person, also known as a synaesthete</a>, see sounds even when that person is actually blind? If so how does the brain interpret a picture without a vision?</p>\n", "pids": ["55a5b477612c6b12ab2b25cd"], "flag": 0}
{"question": "Beyond CBT and MBI, what are effective behavioral interventions for modern lifestyle addictions during their engagement?", "body": "<p>Some modern activities exploit the primitive mammalian reward areas in the brain. They include immediate access to social media, video games, music, sugar, pornographic material, gambling etc. Worse, excessively engaging in these activities without inhibition may enhance the neuroplasticity of the reward centers (and undermine the plasticity of areas involved in self-control, including the anterior cingulate cortex), thus leading to long-term changes of higher reward tolerance, lower self-regulatory abilities, and other exacerbating effects. Unfortunately, most worthwhile work (e.g., proactive learning, writing, thinking about new mechanisms and concepts etc.) usually doesn't offer nearly as much dopaminergic stimulation in the mammalian reward centers of the human brain. </p>\n\n<p><strong>Next to the obvious mindfulness-based interventions (e.g., being aware of the moment and noting the emotional occupation) and cognitive behavioral therapy based approaches (CBT), what interventions have proven to be effective or are likely to be effective for the use case below (*)?</strong> References to support these techniques are welcome. Perhaps some techniques from the substance abuse literature has some application. The main focus of this question mostly deals with the following situation:  </p>\n\n<p>(*) An adult is currently engaging in the addictive task and wishes to context-switch to the productive task. Additionally, the person is aware that the current (addictive) task offers a lower expected utility than the productive task. </p>\n", "pids": ["53e9aa8eb7602d9703409d9a", "5c0f8370da562944ac8c54b3", "5c0f8387da562944ac8c8bce"], "flag": 1}
{"question": "Is there a region of the brain that mediates pain in a manner reminiscent of the mesolimbic pathway?", "body": "<p>The mesolimbic dopamine pathway is a common neural pathway upon which rewards converge AKA the pleasure pathway.</p>\n\n<p>So I am trying to find a comparable pathway in the brain for pain -- is there such a thing? Ideally, one where a probe could be inserted and stimulated to induce intractable pain in the victim. Is there anything reminiscent of the mesolimbic pathway but for pain, perhaps with some sort of somatosensory mapping? </p>\n\n<p>What you never thought about using Deep Brain Stimulation to torture someone before? </p>\n", "pids": ["53e9bbcfb7602d970481ec9b"], "flag": 1}
{"question": "Why is the theory of mind named as such?", "body": "<blockquote>\n  <p><a href=\"https://en.wikipedia.org/wiki/Theory_of_mind#References\" rel=\"nofollow noreferrer\">Theory of mind</a> is the ability to attribute mental states—beliefs, intents, desires, emotions, knowledge, etc.—to oneself, and to others, and to understand that others have beliefs, desires, intentions, and perspectives that are different from one's own.</p>\n</blockquote>\n\n<p>So am I correct in saying that for a dyadic relationship, there are 2 \"theories of mind\", and for a group of $n$ person, there would be <a href=\"https://math.stackexchange.com/q/331383/157643\">$n^2-n$</a> \"theories of mind\"? I understand a system of inferences is properly called as \"theory\", but when so many people has different theory it loses the universal connotation as commonly used in \"theory of planned behavior\" or \"theory of gravitation\". Should it better be named as \"theory-forming of other's minds\"? </p>\n", "pids": ["53e9bdb3b7602d9704a62949", "53e9bbeab7602d970483e19e"], "flag": 1}
{"question": "Time spent in phases of cell cycle", "body": "<p>I am looking for references to papers containing the time intervals spent in different phases of the <a href=\"http://en.wikipedia.org/wiki/Cell_cycle\" rel=\"nofollow\">cell cycle</a> (ej., G0, G1, S, G2, M for eukaryotes) for different cells. In particular, I am interested in E. coli and CHO (Chinese Hamster Ovary cells), but any reference to studies of this kind for any typical cell will be useful.</p>\n\n<p>I'll accept an answer containing a representative sample of references to the literature on this subject. Preferably recent papers (since 2010).</p>\n\n<p>If you can provide the times spent in each phase but don't have references at hand, that will also be useful.</p>\n", "pids": ["55a5fb9d2401defa0dad27b4"], "flag": 1}
{"question": "What are the major layers in a Vision Transformer?", "body": "<p>Currently, I am studying deepfake detection using deep learning methods. Convolution neural networks, recurrent neural networks, long-short term memory networks, and vision transformers are famous deep learning-based methods that are used in deepfake detection, as I found in my study.</p>\n<p>I was able to find that CNNs, RNNs and LSTMs are multilayered neural networks, but I found very little about the neural network layers in a Vision Transformer. (Like a typical CNN has an input layer, pooling layer, and a fully connected layer, and finally an output layer. RNN has an input layer, multiple hidden layers and an output layer.)</p>\n<p>So, what are the <strong>main neural network layers</strong> in a <strong>Vision Transformer</strong>?</p>\n", "pids": ["5f92ba1691e011edb3573ba0"], "flag": 1}
{"question": "What research is there on how people go from examining/gathering evidence to executing on a decision?", "body": "<p>I'm curious what research there is about when/how people decide to stop evaluating or gathering evidence, and actually begin executing on an action, and how the order of information presented could therefore effect conclusions. Most of the articles I've found on this so far are related to premature closure in the area of medical diagnoses specifically -- i.e. when people make a diagnosis prematurely. However, it seems like this must be researched in psychology as well- I think I'm just missing the key terms to look at to find it. Any suggestions/idea of the research would be very helpful!</p>\n", "pids": ["5c0f7cb3da562944ac7de2ae"], "flag": 0}
{"question": "Do G&#246;del&#39;s theorems imply that intelligence systems may end up in some undecidable situation (that may make them take a wrong decision)?", "body": "<p>So far I understand - I know very little on the topic - the core of AI boils down to design algorithms that shall provide a TRUE/FALSE answer to a given statement. Nevertheless, I am aware of the limitations provided by the Gödel's incomplete theorems but I am also aware that there have been long debates such as the Lucas and Penrose arguments with all the consequent objections during the past 60 years. </p>\n\n<p>The conclusion is, in my understanding, that to create AI systems we must accept incompleteness or inconsistency. </p>\n\n<p>Does that mean that intelligence systems (including artificial ones), like humans, may end up in some undecidable situation that may lead to take a wrong decision? </p>\n\n<p>If this may be acceptable in some application (for example, if every once in a while a spam email ends up in the inbox folder - or vice versa - despite an AI-based anti-spam filter) in some other application it may not. I am referring to real-time critical applications when a \"wrong\" action from a machine may harm people. </p>\n\n<p>Does that mean that AI will never be employed for real-time critical applications? </p>\n\n<p>Would in that case more safe to use deterministic methods that do not leave room for any kind of undecidability?</p>\n", "pids": ["53e9b042b7602d9703aa0912"], "flag": 1}
{"question": "Best practice for handling letterboxed images for non fully-convolutional deep learning networks?", "body": "<p>I'm working on a depth estimation network.  It has two outputs:</p>\n<ol>\n<li>A relative depth map</li>\n<li>A scalar for scaling the relative depth map into an absolute depth map.  This second output uses dense layers so we cannot use variable-sized input.</li>\n</ol>\n<p>We are trying to handle two different dimensions (192x256 and 256x192). The current approach is to letterbox the image, meaning apply black on the image so that it comes out to 256x256. We decided on this approach instead of center-cropping images to 192x192 because we believe we may lose valuable data with cropping.</p>\n<p>When using letterboxes, I see two paths:</p>\n<ol>\n<li>Ignore the letterbox portions of the image in my loss function.  The loss function will only perform calculations on the original portion of the image.</li>\n<li>Set a static value for the letterbox portion and include it as part of the loss.</li>\n</ol>\n<p>Is #1 the correct approach?  The network will then be able to predict any depth value for the black letterbox portions without being penalized. I'm concerned with #2 about confusing the network between the letterbox portion and actual dark portions of images.</p>\n", "pids": ["55465d900cf2939c2fee792b"], "flag": 1}
{"question": "Would non-neural physiological insights be considered to be in the field of neuroscience?", "body": "<p>For example, would e.g. SCR (skin conductance response) or hormone level be considered to be \"neuroscientific measures\" according to general definition of neuroscience?</p>\n", "pids": ["5c0f8243da562944ac89c3aa"], "flag": 1}
{"question": "Can calmness happen during the fight-flight response?", "body": "<p>In the question <a href=\"https://psychology.stackexchange.com/q/15730/12937\">How do certain individuals, like Quang Duc, develop the ability to remain calm when enduring significant nociceptive pain?</a>, one answer says that it was the high level of cortisol that numbing his pain. But that's numb, not <a href=\"https://en.wikipedia.org/wiki/Calmness\" rel=\"nofollow noreferrer\">calm</a>. I don't think calmness can happen during stressful situations.</p>\n\n<p>So to check that answer, can calmness happens during the fight-flight response?</p>\n", "pids": ["55a4137d65ce5cd7b3c3659a", "53e9bb61b7602d970479fd71"], "flag": 0}
{"question": "How to compare effectiveness of psychological treatment for psychological illness, versus medical treatment for medical illness?", "body": "<p>I'm a college student. I read somewhere that people often assume that mental health issues do not get better, and that a person ends up seeing a psychiatrist forever. So I was wondering if there was a way to compare treatments for medical vs psychological issues. </p>\n\n<p>Like let's say we pick 10 common physical illnesses and 10 common psychological illnesses. And then look at best treatments for each. For instance, assume sinus infections are the top physical illness and depression is the most common mental illness. Further assume that the best treatment for depression is CBT, and for sinus infection is nasal corticosteroids. How would I go about comparing the effectiveness of  corticosteroids for sinus infections versus CBT for depression? Is there a particular number, some effect size, or something else that I can take from one research study and compare it to the other?</p>\n\n<p>Thanks for help or clarification. </p>\n", "pids": ["55a5580f65ceb7cb02e8f860"], "flag": 1}
{"question": "Questions of the type &quot;What do you think he/she would think?&quot;", "body": "<p>For a study in the adoption of new technology, my student and I are developing a questionnaire that will poll respondents on their opinions of what their colleagues would think about benefits/problems of adopting a particular technology. This is research in social science/business but not strictly psychology, and as we are not psychologists, we don't know the literature. </p>\n\n<p>Have psychologists investigated questions of the type <em>What do you think other people would think?</em> We are not asking for a tutorial here, just a pointer where should we should start looking.</p>\n", "pids": ["53e99a9eb7602d970231569c"], "flag": 1}
{"question": "Not being a first author diminishes the contribution of co-authors?", "body": "<p>If a group of students (say, 3 students), produces a work which has been accepted to a reputable conference. All of them contributed equally to the project,from implementation to writing and proof reading of the paper. \nHow should one decide who should be the first author. Even if the names are listed in alphabetical order, so by not being the first author, does it affect the prospects for the other two in any means ? \nMy field of research is computer science.</p>\n\n<p>(This question has been partly inspired by the  flurry of questions on ASE, regarding the importance of being the first author)</p>\n", "pids": ["53e99997b7602d97021d8c09"], "flag": 1}
{"question": "Encouraging Kindness in Rich People?", "body": "<p>Evidence presented in <a href=\"https://www.youtube.com/watch?v=L90R6PtxFKE\" rel=\"nofollow noreferrer\">this video</a> suggests that, statistically, rich people are more likely to be jerks than people with less money. How could this tendency be curbed, especially with regards to rich kids?</p>\n", "pids": ["56d8de5ddabfae2eee01f253", "56d8de5edabfae2eee01fa11", "55a469f3612ca6486895bedb", "55a3d231612ca6486879b45d"], "flag": 1}
{"question": "What is it called to attack a person then say something uplifting?", "body": "<p>Say a manager emailing the people under her in a way that to them feels degrading, and putting down. But at the end of the email its encouraging/uplifting type saying I know you are intelligent and capable people. </p>\n\n<p>So is there a name of this type of behavior to attack/degrade then at the end say something nice? </p>\n", "pids": ["55a5eba665cead59c82f953f"], "flag": 1}
{"question": "Terminology: why do psychologists use &quot;positive&quot; and &quot;negative&quot;?", "body": "<p>In a lot of places in psychology - for example in operant conditioning and in describing symptoms of psychological disorders - various things are described as \"positive\" and \"negative\". Positive rewards/punishments or positive symptoms are things that are <em>added</em> or <em>given</em> to an individual, whereas negative rewards/punishments or symptoms are things that are <em>taken away</em> or that <em>disappear</em>. </p>\n\n<p>This terminology seems confusing - both the word \"positive\" and the word \"negative\" have other connotations in areas that psychology is concerned with, for example in describing mood. Using this particular terminology for things like the symptoms of psychological disorders, instead of less ambiguous words with more direct meanings like \"additive\" or \"subtractive\", seems confusing. Is there a particular reason why the words \"positive\" and \"negative\" continue to be used in a scientific sense over such less ambiguous alternatives?</p>\n", "pids": ["53e99b7eb7602d9702422a0d"], "flag": 1}
{"question": "Can a person with delusions completely acknowledge their delusions", "body": "<p>I wanted to ask a question for a story I'm writing;</p>\n\n<p>Can a person with delusions completely acknowledge that they have delusions? For example, if someone claims that for a long time he believed certain crucial things about his life to be true (possible things, nothing bizarre; Like his parents being dead and then seeing them at home, him going to a certain school but the school doesn't exist and he actually went to an entirely different one etc.) and then was proven otherwise. </p>\n\n<p>He has no fixations to his previous believes, he's completely open to the possibility of him not being able to differentiate reality (He was open the second he suspected something to be awry). </p>\n\n<p>Would he still fall under the delusional category? If not would it at least be considered an <em>unordinary</em> case?</p>\n", "pids": ["55a441c32401c6de3b8b44ac", "55a417cac91b587b096cb1d0", "55a449532401c6de3b8d2292"], "flag": 1}
{"question": "Is the visual cortex of a newborn baby immediately capable of object detection or is this skill learned over time, and if so, how?", "body": "<p>Is the visual cortex of newborn babies right off the bat capable of making sense of raw visual data, for instance, converting the constant stream of raw RGB images perceived by the eyes into a meaningful higher-level representation of objects in motion in a 3D world? Yes? No? If not, then does it mean this skill has to be developed over time by means of some <strong>learning mechanism</strong>?</p>\n\n<p>If the visual cortex needs time to learn advanced visual skills, how does the actual learning mechanism work? Does the visual cortex have to optimize the connections between neurons, in a way analogous to how artificial neural networks optimize their parameters through backpropagation algorithm (machine learning)? If this is the case, then where does the visual cortex get its error signals from? To make the last question clear, in machine learning the typical approach is to compute the gradient of a loss function which compares the model's prediction with the ground truth, and the model's parameters are updated by moving the parameters in the direction of the gradient. If the visual cortex is learning advanced visual skills by virtue of a similar learning mechanism, then what kind of loss function is the visual cortex optimizing?</p>\n", "pids": ["5966c66b0cf2aff42d51b618"], "flag": 1}
{"question": "Composer Thomas Schoenberger&#39;s Sophia Musik effect on the brain?", "body": "<p>Thomas Schoenberger claims his 'Sophia Musik' (the Ultimate Baby CDs) hav many beneficial effects on the brain.  Are you aware of this prolific composer and have any advice regarding his musical claims? </p>\n", "pids": ["53e9b6d0b7602d970425b876"], "flag": 1}
{"question": "Is there a term for simulated irrationality?", "body": "<p>When 2 rational people want to accomplish their goals, they'll get compromise by meeting their goals halfway. But if one of them seems irrational, his opponent will go much farther in his concessions since he knows there's the risk of him burning everything to the ground.</p>\n\n<p><strong>Therefore, it can be advantegous to seem irrational or insane. Is there a term for behaving in such a manner on purpose?</strong></p>\n", "pids": ["53e9ac12b7602d97035d28f4"], "flag": 1}
{"question": "How many unique angles of an object do you need in your image training set in order to correctly classify it?", "body": "<p>I'm interested in using ResNet-50 to classify images of objects for around 1000 unique classes. I'm wondering if there is any way to estimate how many unique angles I need in my training set to classify images that can be taken from any angle. For example, if for a given object I had 500 training images from directly the front and 500 training images from directly the top, I'd have 2 unique angles.</p>\n<p>A model trained with only those 2 unique angles probably wouldn't be able to classify the same object if it was given a photo from the top right looking down.</p>\n<p>Is there anyway to figure out how many unique angles I would need in my training set to classify images that could be taken from any angle? If I had 12 unique angles (top, bottom, front, back, left, right, front-left, front-right, front-top, front-bottom, back-left, back-right, back-top, back-bottom) would I then be able to classify images of any arbitrary angle?</p>\n<p>To clarify, if I had 12 unique angles, that would mean I would have many photos from each of the 12 angles, but the 12 angles would all be exactly the same with no variation. I.E. top would be exactly a 90-degree angle towards the object on the Z-axis and 0-degree angles on the X and Y axis, for many photos.</p>\n", "pids": ["573696026e3b12023e515eec"], "flag": 1}
{"question": "An Example of Negative Reinforcement?", "body": "<p>In trying to understand the origins of test anxiety, a thought came up. </p>\n\n<blockquote>\n  <p>Consider an individual who has in the past performed badly in university assessment tasks. In an attempt to do better academically, the individual negatively reinforces unattainably high expectations to avoid any future feelings of inadequacy. </p>\n</blockquote>\n\n<p>Have I used the idea of negative reinforcement correctly in this instance? I have been taught the fundamental ideas of reinforcement and punishment as described by Skinner.</p>\n\n<p>Thanks :)</p>\n", "pids": ["5ae1b7bfa2e6b107866a6a75"], "flag": 1}
{"question": "Kendrick et. al version of Maslow&#39;s Hierarchy", "body": "<p><a href=\"https://i.stack.imgur.com/4h6p9.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/4h6p9.png\" alt=\"updated version of Maslow's hierarchy of fundamental human motives\" /></a></p>\n<p>The above reinterpretation of the hierarchy by <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3161123/\" rel=\"nofollow noreferrer\">Kendrick et. al (2010)</a> is straightforward enough. I am trying to see if there is any work done on generalizing the top portion there beyond peaking out at parenting e.g. mate acquisition-retention and parenting applied for life pursuits like academic or professional accomplishments. Maybe subject-acquisition-retention and progeny?</p>\n<h2>References</h2>\n<p>Kenrick, D. T., Griskevicius, V., Neuberg, S. L., &amp; Schaller, M. (2010). Renovating the Pyramid of Needs: Contemporary Extensions Built Upon Ancient Foundations. <em>Perspectives on psychological science : a journal of the Association for Psychological Science, 5</em>(3), 292–314. doi: <a href=\"https://doi.org/10.1177/1745691610369469\" rel=\"nofollow noreferrer\">10.1177/1745691610369469</a></p>\n", "pids": ["5a9de82c684d7e733ef89184"], "flag": 1}
{"question": "Difference between psychosis and schizophrenia", "body": "<p>Can you please illustrate the difference between the psychosis and the schizophrenia? </p>\n", "pids": ["5c757435f56def979891f59a", "6218b6de5aee126c0f7f879e"], "flag": 1}
{"question": "Does societal view of epic musician, author&#39;s epic work affect mainly any human the way they view them overall or it&#39;s their personal life or both?", "body": "<p>I am trying to figure out this question. It's just an inquisitive thought.</p>\n\n<p>Does a musician, author, novelist, poet's personal life affect a human being's personal view of that epic figure rather than enjoying these figures' personal poetry, short story, novel, a novella, and other works?</p>\n\n<p>If no then why do epic figures are constantly criticized for their personal life? Is it fair?</p>\n", "pids": ["53e9a930b7602d970328093b"], "flag": 1}
{"question": "Chromosomes are of different size but why do all chromosomes have similar GC percentage?", "body": "<p>When I browsed NCBI I saw a pattern: even if the chromosome sizes, number of genes, and number of proteins are different, GC% in chromosomes tend to be similar. The examples are linked below.</p>\n\n<p><a href=\"http://www.ncbi.nlm.nih.gov/genome/genomes/15?details=on&amp;\" rel=\"nofollow noreferrer\">Yeast</a>, \n<a href=\"http://www.ncbi.nlm.nih.gov/genome/genomes/33?details=on&amp;\" rel=\"nofollow noreferrer\">Plasmodium falciparum</a></p>\n\n<p>If you see Mitochondria genome it is not very similar to chromosome. Why all chromosomes tend adjust their GC% near to the average of total GC%\nIs there a specific reason related to metaphase of meosis?</p>\n\n<p>to further clarify I have some images to help</p>\n\n<p><a src=\"https://i.stack.imgur.com/i9PbC.png\" alt=\"enter image description here\">\n<a src=\"https://i.stack.imgur.com/6A3NH.png\" alt=\"enter image description here\"></p>\n\n<p>The chromosome size or genes in an organism are not adjusting near the average of their total but GC% does. It has only 3-2% (falciparum) or 3-4% (vivax) variation in GC%. It feel like its balancing like equalizer. Why?</p>\n", "pids": ["53e9b755b7602d97042f8309"], "flag": 1}
{"question": "Book recommendations for algorithms used in evolutionary biology", "body": "<p>Do you have recommendations for a book that presents the different algorithm used in theoretical evolutionary biology?</p>\n\n<p>I don't mean evolutionary or genetic algorithms (otherwise this question would not be a good fit for Biology.SE) but algorithms applied to evolutionary biology. I am not interested in statistical procedures and algorithms to reconstruct phylogenetic trees, to annotate DNA sequences or to find out synonymous changes by comparing sequences of closely related species. I am not interested in introductory book on programming.</p>\n\n<p>I am interested to computational modeling applied population genetics, kin selection, game theory, population range expansion, simulating sexual reproduction, selection for different sex determination system, evolution for robustness/evolvability, evolution of codon usage, evolution of genetic code, evolution of cognition, evolution of multicellularity, …</p>\n\n<p>I don't quite know if one book that encompass all these subjects exist. If not, I wold welcome suggestions of book that present the algorithmic used in some but not all of these subjects.</p>\n\n<p>Searching a bit in amazon, I easily found tons of book but don't quite know if they fit my expectations. Below are some examples</p>\n\n<p><a href=\"http://www.amazon.fr/The-Engine-Complexity-Evolution-Computation-ebook/dp/B00APDGG9G/ref=sr_1_1?ie=UTF8&amp;qid=1388169820&amp;sr=8-1&amp;keywords=computation+biology+evolution\" rel=\"noreferrer\">Evolution as computation</a></p>\n\n<p><a href=\"http://rads.stackoverflow.com/amzn/click/069109666X\" rel=\"noreferrer\">Individual based modeling and ecology</a></p>\n\n<p><a href=\"http://www.amazon.fr/Models-Algorithms-Genome-Evolution-Cedric-ebook/dp/B00FA1PTHI/ref=sr_1_2?ie=UTF8&amp;qid=1388169832&amp;sr=8-2&amp;keywords=computation+biology+evolution\" rel=\"noreferrer\">Models and algorithm for genome evolution</a></p>\n\n<p><a href=\"http://rads.stackoverflow.com/amzn/click/0521538564\" rel=\"noreferrer\">modelling for field biologists</a></p>\n\n<p><a href=\"http://rads.stackoverflow.com/amzn/click/0878933913\" rel=\"noreferrer\">Practical computing for biologist</a></p>\n\n<p><a href=\"http://www.amazon.fr/Evolution-As-Computation-Workshop-Princeton/dp/3642630812/ref=sr_1_4?ie=UTF8&amp;qid=1388169832&amp;sr=8-4&amp;keywords=computation+biology+evolution\" rel=\"noreferrer\">Evolution as computation</a></p>\n\n<p><a href=\"http://www.amazon.fr/Genetic-Evolutionary-Computation-Medical-Applications/dp/0470748133/ref=sr_1_6?ie=UTF8&amp;qid=1388169832&amp;sr=8-6&amp;keywords=computation+biology+evolution\" rel=\"noreferrer\">Genetic and evolutionary computation</a></p>\n\n<p><a href=\"http://www.amazon.fr/Genetic-Algorithms-Structures-Evolution-Programs/dp/3642082335/ref=sr_1_69?ie=UTF8&amp;qid=1388166676&amp;sr=8-69&amp;keywords=evolution+algorithm\" rel=\"noreferrer\">Genetic algorithms+ data structures = evolution programs</a></p>\n\n<p><a href=\"http://www.amazon.fr/The-Missing-Algorithm-Cooperation-Prediction/dp/1581125992/ref=sr_1_119?ie=UTF8&amp;qid=1388169248&amp;sr=8-119&amp;keywords=evolution+algorithm\" rel=\"noreferrer\">The missing algorith</a></p>\n\n<p><a href=\"http://www.amazon.fr/Cellular-Model-Mathematical-Bioinformatics-Computational/dp/613381960X/ref=sr_1_1?ie=UTF8&amp;qid=1388169453&amp;sr=8-1&amp;keywords=algorithm+theoretical+biology\" rel=\"noreferrer\">Cellular Model: Mathematical and theoretical biology, Algorithm, Data structure, Bioinformatics, Computational biology, Artificial life, Computer simulation</a></p>\n\n<p><a href=\"http://www.amazon.fr/Natural-Artificial-Models-Computation-Biology/dp/3642386369/ref=sr_1_3?ie=UTF8&amp;qid=1388169453&amp;sr=8-3&amp;keywords=algorithm+theoretical+biology\" rel=\"noreferrer\">Natural-Artificial-Models-Computation-Biology</a></p>\n\n<p><a href=\"http://www.amazon.fr/An-Introduction-Genetic-Algorithms-Paper/dp/0262631857/ref=sr_1_61?ie=UTF8&amp;qid=1388166452&amp;sr=8-61&amp;keywords=evolution+algorithm\" rel=\"noreferrer\">An-Introduction-Genetic-Algorithms-Paper</a></p>\n", "pids": ["53e9b9d4b7602d97045cef8b"], "flag": 1}
{"question": "How do I use machine learning to create an optimization algorithm?", "body": "<p>Let's say that I want to create an optimization algorithm, which is supposed to find an optimum value for a given objective function. Creating an optimization algorithm to explore through the search space can be quite challenging.</p>\n<p>My question is: can machine learning be used to automatically create optimization algorithms? Is there any source to look at for this?</p>\n", "pids": ["5d25bcd73a55ac8369529025"], "flag": 1}
{"question": "Can we use a neural network that is trained using Reinforcement Learning for dynamic game level difficulty designing in realtime?", "body": "<p>I am a newbie to Machine Learning and AI. As per my understanding, with the use of reinforcement learning \n(reward/punishment environment), we can train a neural network to play a game. I would like to know, whether it possible to use this trained model for deciding the difficulty of the next game level dynamically in realtime according to a player's skill level? As an example, please consider a neural network is trained using Reinforcement Learning for playing a mobile game (chess/puzzle, etc.). The game is not consists of a previously designed static set of game levels. After the training, can this model use to detect a particular player's playing style(score, elapsed time) to dynamically decide the difficulty of the next game level and provide customized game levels for each player in realtime?</p>\n\n<p>Thank you very much and any help will be greatly appreciated.</p>\n", "pids": ["53e99cdfb7602d97025966bd", "53e9a39db7602d9702caa02e"], "flag": 1}
{"question": "Does AlphaGo play random moves in a real competition?", "body": "<p>Alphago and AlphaGo zero use random play to generate data and use the data to train DNN. &quot;Random play&quot; means that there is a positive probability for AlphaGo to play some suboptimal moves based on the current DNN; this is for exploring and learning purposes (please correct me if my understanding is wrong).</p>\n<p><strong>In the real tournament, does AlphaGo still play the random moves?</strong> Is the random play feature only used in the training phase?</p>\n<p>If AlphaGo does not play a random move in the real competition, then I think AlphaGo is not learning in that competition. Human players do similar &quot;random play&quot;: they usually play some random moves or strange moves in minor contests, just to test out new strategies; in major tournaments, they will be more serious and play less unprepared moves.</p>\n<p>So, a related and broader question is: does AlphaGo learn from the game it is playing with the human in real-time?</p>\n<p>I think the second question is less important because AlphaGo's learning curve is extremely flat compared to humans: AlphaGo learns epsilon from one single game while human can learn a lot.</p>\n", "pids": ["5a73cbcc17c44a0b3035f7b3"], "flag": 1}
{"question": "What does White guilt feel like, how does it socially manifest itself &amp; is it treatable?", "body": "<p>White guilt would appear to be a genuine phenomenon which only White people can ever experience - and yet many people deny that it exists, at all, or that it is a form of phoney Liberalism or, worse, \"reverse racism\".</p>\n\n<p>However, such denials are suggestive of the very thing being denied. White guilt thus appears to feature characteristics of emotional self-indulgence, anger and the desire for forgiveness &amp; personal acceptance.</p>\n\n<p>Is White guilt the same or similar to other forms of guilt, or does it have its own unique characteristics setting it apart from other functions of the human conscience?</p>\n\n<p><a href=\"https://en.m.wikipedia.org/wiki/White_guilt\" rel=\"nofollow noreferrer\">White guilt</a></p>\n", "pids": ["53e9a1dbb7602d9702adafd0", "56d81fdddabfae2eeeb4adf3", "53e9ae04b7602d970380cc86"], "flag": 1}
{"question": "Why doesn&#39;t dropout mislead results during evaluation?", "body": "<p>I have seen that, usually, the dropout layer is used differently in training and evaluation modes, i.e. it is recommended to use during training but not in evaluation/testing.</p>\n<p>Dropout does remove a few nodes at random so that model does not end up in co-adaption. But, logically, if you are using one layer in training and not in evaluation/testing, should not the result be inconsistent? How/ why do we achieve the same/similar results though we are skipping a layer altogether?</p>\n", "pids": ["60659e7ae4510cd7c8e1c5de", "5f4f688191e0111f07b30962"], "flag": 1}
{"question": "Clues for genetic basis in Autism Spectrum Disorders", "body": "<p>In <a href=\"https://neurology.mhmedical.com/book.aspx?bookID=1049\" rel=\"nofollow noreferrer\">Principles of Neural Science 5th edition</a>, Chapter 3, It Is said that Autism Is a genetic disorder but which genes are involved Is not clear, how do we know there Is a genetic basis and Is not a response to environmental factors (or a combination)?</p>\n", "pids": ["5db9264447c8f766461ace0e"], "flag": 1}
{"question": "Are the domains of objective functions in AI always equals to $\\mathbb{R}^D$ or subset of it?", "body": "<p>Consider the following paragraph from the chapter named <a href=\"https://mml-book.github.io/book/mml-book.pdf#page=145\" rel=\"nofollow noreferrer\">Vector Calculus</a> from the textbook titled <strong><a href=\"https://mml-book.github.io/book/mml-book.pdf\" rel=\"nofollow noreferrer\">Mathematics for Machine Learning</a></strong> by <em>Marc Peter Deisenroth et al.</em></p>\n<blockquote>\n<p>Central to this chapter is the concept of a function. A function <span class=\"math-container\">$f$</span>\nis a quantity that relates two quantities to each other. In this book,\nthese quantities are typically inputs <span class=\"math-container\">$x \\in \\mathbb{R}^D$</span> and targets\n(function values) <span class=\"math-container\">$f(x)$</span>, which we assume are real-valued if not\nstated otherwise. <strong>Here <span class=\"math-container\">$\\mathbb{R}^D$</span> is the domain of <span class=\"math-container\">$f$</span></strong>, and the\nfunction values <span class=\"math-container\">$f(x)$</span> are the image/codomain of <span class=\"math-container\">$f$</span>.</p>\n</blockquote>\n<p>we can notice that the textbook is taking <span class=\"math-container\">$\\mathbb{R}^D$</span> as the domain for objective functions. I want to know whether it is valid in general cases.</p>\n<p>Do the objective functions that we generally use in artificial intelligence have <span class=\"math-container\">$\\mathbb{R}^D$</span> as the domain?</p>\n<p>I am guessing it would <em>not</em> be since the loss functions are generally defined on the datasets which can also have discrete attributes and hence the objective function cannot be defined on every point in <span class=\"math-container\">$\\mathbb{R}^D$</span>. So, I am guessing that the correct form of the bold statement from the quoted paragraph is &quot;<strong>Here the domain of <span class=\"math-container\">$f$</span> should be a subset of <span class=\"math-container\">$\\mathbb{R}^D$</span></strong>&quot; if we are intended to deal with a general case. Am I correct or is there any arrangement such as defining <span class=\"math-container\">$f$</span> as zero where the function is not defined?</p>\n", "pids": ["5ee8986f91e011e66831c593", "5c69360fe1cd8e202b1eb31e"], "flag": 1}
{"question": "Could it make any sense to choose a larger dimension for the latent space of the VAE with respect to the original input?", "body": "<p>Could it make any sense to choose a larger dimension for the <em>latent space</em> of the VAE with respect to the original input?</p>\n<p>For example, we may want to learn how to reconstruct a relatively low-dimensional input (let's say <span class=\"math-container\">$20$</span> dimensions), then could I define my encoder and decoder to have <span class=\"math-container\">$64,256,512...$</span> hidden neurons before bringing back the reconstruction?</p>\n<p>EDIT:\nWell I've thought about that and I think it would still be reasonable as in latent-variable models we are actually assuming that our original observations are generated from unseen 'hidden' variables. And (I think) the lower dimension of the latent space is only assumed for an original dimensionality-reduction purpose.</p>\n", "pids": ["61dcf54a5244ab9dcb1fb973"], "flag": 1}
{"question": "Solving logical pattern puzzles with Machine Learning?", "body": "<p><a href=\"https://i.stack.imgur.com/Y2NFs.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/Y2NFs.png\" alt=\"enter image description here\" /></a></p>\n<p>I found this kind of problem while reading about some web tests companies use to screen applicants. It is a puzzle where you need to guess what comes inside?</p>\n<p>Looking at this made me wonder,\n<strong>How would you approach solving problems like this using Machine Learning?</strong></p>\n<p>I assume that if people can recognize the pattern with a bit of training, so should A.I. be able to as well.</p>\n<p>If anyone knows anything that could be a good starting for me to solve this problem, please let me know. Any opinion will be appreciated! (whether this is possible or not, how difficult it is, computer vision models, algorithms etc., cool projects like this etc.)</p>\n<p>I've seen other people solve logic games like <a href=\"https://towardsdatascience.com/logicgamessolver-how-to-solve-logic-games-using-computer-vision-and-artificial-intelligence-1a4972e7e0be\" rel=\"nofollow noreferrer\">here</a>\nBut visual cues get complicated like this often in this type of puzzles. <a href=\"https://i.stack.imgur.com/TFxk0.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/TFxk0.png\" alt=\"enter image description here\" /></a></p>\n", "pids": ["5e7dcebb91e0115bf014c31a", "61df985e5244ab9dcbd2dd29"], "flag": 1}
{"question": "Help to find the International Trauma Questionnaire (ITQ)", "body": "<p>I'm looking for the <em>International Trauma Questionnaire (ITQ)</em> as per ICD-11 proposals, but I can not find it. It was previously called <em>the\nICD-11 Trauma Questionnaire (ICD-TQ)</em>. Can someone help me?</p>\n", "pids": ["5c0f8a0cda562944ac9a5808"], "flag": 0}
{"question": "Can we change a particular addiction into another addiction?", "body": "<p>My current knowledge about dopamine and serotonin came from a series of articles and web pages, a few videos also.</p>\n\n<p>As per my knowledge and readings I know that addiction is about reward, a person’s brain releases a chemical called <strong>dopamine</strong> when a person do addictive task and hence he feels momentarily good. But doing too much of it damages the receptors and hence the person cannot feel <em>happy</em> anymore by doing that addictive act but he keeps on doing it in hope of that reward.</p>\n\n<p>Now, if we treat that person so that his receptors gets healed a little and then we start giving him some medicine which releases <strong>dopamine</strong> in right amount and hence converting that person’s addition from that previous addictive task to the medicines ( well I believe this is what psychiatrist actually do, because a person who goes to a psychiatrist always ends up taking medicines whole of his life) . If it’s all about <em>feeling good</em> and the release of <strong>dopamine</strong> then it seems completely logical to treat it by medicines and some self control. Then, my question, finally, is <strong>Is it possible to cure addiction by converting it into another addiction?</strong>  </p>\n\n<p>I talked to some professionals and they said that it’s not wise to substitute a behavioural addiction with a substance addiction, but I cannot see any difference because both of these have same effect on the brain i.e. release of a <em>chemical</em>.  </p>\n\n<p>I know that there lies many many minute and significant details which I have failed to look over but I expect that the researchers, well educated and even self-learner’s will get the gist of what I have said.  </p>\n\n<p>Thank you.</p>\n", "pids": ["622a55c65aee126c0fecb544", "53e9b403b7602d9703ef6df8", "56d82a96dabfae2eeef9e139"], "flag": 1}
{"question": "Laughing as a psychological defense when nervous", "body": "<p>Say a persons experienced a scarring event in their life (ptsd), and so their mind has developed defense in which they laugh uncontrollably whenever their nervous. This is similar to Joker 2019, whenever Arthur was stressed or depressed he would break out in a laughing episode. However, I began to think otherwise, because later in the film Arthur was physically abused as a child (even being tied to a radiator), which may contributed to this being a physical disorder, but I'm looking for a psychological disorder. </p>\n\n<p>What is the name/term for this condition.</p>\n\n<p>I've thought of psuedobulbar affect (PBA), but after doing research, it is a physical disorder, not purely psychological.</p>\n", "pids": ["657017ac939a5f408286520d"], "flag": 1}
{"question": "Is this aggregation of multiple convolutions of the same input a type of attention or dynamic convolution?", "body": "<p>Are there any examples of people performing multiple convolutions at a single depth and then performing feature max aggregation as a convex combination as a form of &quot;dynamic convolutions&quot;?</p>\n<p>To be more precise: Say you have an input x, and you generate</p>\n<pre><code>Y_1 = conv(x) \nY_2 = conv(x)\nY_3 = conv(x)\n\nY = torch.cat([Y_1,Y_2,Y_3]) \nWeights = nn.Parameter(torch.rand(1,3)) \nWeights_normalized = nn.softmax(weights) \nAttended_features = torch.matmul(Y, weights_normalized.t())\n</code></pre>\n<p>So, essentially, you are learning a weighting of the feature maps through this averaging procedure.</p>\n<p>Some of you may be familiar with the &quot;Dynamic Convolutions&quot; paper. I’m just curious if you all would consider this dynamic convolution or attention of feature maps. Have you seen it before?</p>\n<p>If the code isn’t clear, this is just taking an optimized linear combination of the convolution algorithm feature maps.</p>\n", "pids": ["5e5e18cb93d709897ce31b3c", "5736960e6e3b12023e520be8", "5def90373a55ac809f181172"], "flag": 1}
{"question": "Why do we use a linear interpolation of fake and real data to penalize the gradient of discriminator in WGAN-GP", "body": "<p>I'm trying to better frame/summarize the formulations and motivations behind <em>Wasserstein GAN</em> with gradient penalty, based on my understanding.</p>\n<p>For the basic GAN we are trying to optimize the following quantity:</p>\n<p><span class=\"math-container\">$$\\min_\\theta \\max_\\phi \\mathbb{E}_{x \\sim p_{data}(x)}[D_\\phi(x)] + \\mathbb{E}_{z \\sim p_G(z)}[1-D(G_\\theta(z))]$$</span></p>\n<p>The problem is that the dissimilarity measure between the two probabilities given by <em>Jensen-Shannon divergence</em> will not take into account any <strong>distance</strong> in a <em>Euclidean</em> sense. That's why we consider the Wasserstein distance defined as:</p>\n<p><span class=\"math-container\">$$W(p_{data}, p_G) := \\inf_\\gamma \\, \\,\\mathbb{E}_{(x,y) \\sim \\gamma(x,y)}\\|x-y\\|$$</span></p>\n<p>that will account for a proper distance of our distributions. Computing it is very hard so we rely on Kantorovich-Rubinstein duality which states we can rewrite <span class=\"math-container\">$W$</span> as:</p>\n<p><span class=\"math-container\">$$W(p_{data},p_G) = \\sup_{\\|f\\|_L \\le 1}\\mathbb{E}_{x \\sim p_{data}(x)}[f_\\phi(x)] - \\mathbb{E}_{z \\sim p_{G}(x)}[f_\\phi(G_\\theta(z))]$$</span></p>\n<p>Now the crucial point, to enforce the constraint of <span class=\"math-container\">$1$</span>-Lipschitz continuity of the discriminator we add a penalty term to bound the norm of the gradient of <span class=\"math-container\">$f$</span>, so the final loss we consider is:</p>\n<p><span class=\"math-container\">$$\\mathcal{L} = \\mathbb{E}_{x \\sim p_{data}(x)}[f_\\phi(x)] - \\mathbb{E}_{z \\sim p_{G}(x)}[f_\\phi(G_\\theta(z))] + \\lambda \\, \\mathbb{E}_{\\hat{x}}[(\\|\\nabla_{\\hat{x}} f_\\theta(\\hat{x})\\|-1)^2]$$</span></p>\n<p>where</p>\n<p><span class=\"math-container\">\\begin{equation}\n\\hat{x} = tx + (1-t)z\n\\end{equation}</span>\n<span class=\"math-container\">$t \\in [0,1]$</span>.</p>\n<p>Now, I've understood that we bound the slope of discriminator because we want toavoid the vanishing gradient problem and keep gradient signal in order to make the generator learn, but why do we actually penalize the gradient of discriminator with respect to a linear interpolation of real and fake data?</p>\n", "pids": ["599c797f601a182cd26447c5"], "flag": 1}
{"question": "What is the difference between personality disorder and other types of mental illness?", "body": "<p>From <a href=\"https://www.mayoclinic.org/diseases-conditions/personality-disorders/symptoms-causes/syc-20354463\" rel=\"nofollow noreferrer\">Personality disorders - Mayo Clinic</a>:</p>\n\n<blockquote>\n  <p>A personality disorder is a type of mental disorder in which you have a rigid and unhealthy pattern of thinking, functioning and behaving. A person with a personality disorder has trouble perceiving and relating to situations and people. This causes significant problems and limitations in relationships, social activities, work and school.</p>\n</blockquote>\n\n<p>From <a href=\"https://www.mayoclinic.org/diseases-conditions/mental-illness/symptoms-causes/syc-20374968\" rel=\"nofollow noreferrer\">Mental illness - Mayo Clinic</a>:</p>\n\n<blockquote>\n  <p>Mental illness, also called mental health disorders, refers to a wide range of mental health conditions — disorders that affect your mood, thinking and behavior. Examples of mental illness include depression, anxiety disorders, schizophrenia, eating disorders and addictive behaviors.</p>\n</blockquote>\n\n<p>So I understand the personality disorders are more about having a rigid and unhealthy pattern of thinking, while mental illness in general is more about mood. However, in my understanding that mood is just automatic thinking that stems from past experience, which is no differ than personality disorder. The CBT approach, which is again fixing incorrect automatic thoughts, seems to be successful in working with both of them.</p>\n\n<p>So is there any actual difference between them? Or is that personality disorder just an extreme version of mental illness, in which the belief is more systematic (<a href=\"https://en.wikipedia.org/wiki/World_view\" rel=\"nofollow noreferrer\">world view</a> or <a href=\"https://en.wikipedia.org/wiki/Belief#Belief_systems\" rel=\"nofollow noreferrer\">belief system</a> I would say)?</p>\n\n<p><br></p>\n\n<p><sup>A minor and quick to answer question: why is personality disorder has the \"personality\" in its name? </sup></p>\n", "pids": ["5c3e1a33df5b8c0b3ccc4164", "5c7a69a0e1cd8e5cd2b37310"], "flag": 1}
{"question": "Where to get psychology assessment resources to put into my website?", "body": "<p>I'm not a psychologist and would like to know how to get a psychological assessment to put into my website? Is there a public assessment with question data and scoring logic?</p>\n\n<p>I'm sorry if the question is obvious to psychologists, and feel free to close the question.</p>\n\n<p>I'm initially looking for assessment for students to help them choose a career path. I Googled \"student career path quiz\" and found numerous assessments, they're free as well, though I don't have the resources to create those assessments in my own website. So I guess my question is:</p>\n\n<p><strong>is there a public resource for psychological assessments, including questions, answers, scoring logic, and reporting?</strong></p>\n\n<p>To be clear: I want to put an psychological assessment in my website to assess students for choosing a career path (e.g. their personality model) one example is the <a href=\"https://openpsychometrics.org/tests/IPIP-BFFM/\" rel=\"nofollow noreferrer\">IPIP Big-Five Factor Markers by OpenPsychometrics</a> for the big five personality.</p>\n\n<p>I'm coming from a programming background, so I'll code the assessment myself. But to do it, I need the list of questions, answers, scoring functions, and reporting standard. The ones that I found have questions and answers, but I couldn't find the scoring logic and how to generate reports for such questionnaires. I'm asking if there are public questionnaires that can I take to put into my own website.</p>\n", "pids": ["55a3cc21c91b587b0962c980", "618ba2aa5244ab9dcbbc6d58"], "flag": 1}
{"question": "How are neurotransmitter receptors discovered?", "body": "<p>Many neurotransmitter receptors are known, for example 5-HT<sub>2a</sub>, Mu, NMDA, and so on. How have these receptors been discovered?</p>\n", "pids": ["53e9a487b7602d9702da4901"], "flag": 1}
{"question": "Do I need to normalize all state-space variables? If so, how?", "body": "<p>I am playing around with a DRL agent in a stock-trading environment.</p>\n<p>I have normalized all the external input data (the features that my agent will use). However, what about characteristics that don't come from the environment?</p>\n<p>For example, I have included things like &quot;current account balance&quot; and &quot;current unrealized gain&quot; in my observation space (as I believe it's useful). However, I don't know how I could normalize these values, given that they are dependent on what actions the agent took, which changes every time etc.</p>\n<p>Any feedback or advice is appreciated.</p>\n<p>Will it be detrimental if I don't normalize these values (as long as they're reasonably within the orders of magnitude of my other normalized variables)?</p>\n<p>I guess a simple example would be like if a robot was being trained to pick up balls, and one of the observations was &quot;current number of balls picked up&quot;, how would you normalize that value, given that it's just a count that could technically go to infinity?</p>\n", "pids": ["600831ee9e795ed227f530d6"], "flag": 1}
{"question": "Why is training longer not better in reinforcement learning?", "body": "<p>I have trained an RL agent (PPO) for 6 million steps to solve the OpenAI gym LunarLander-v2. Surprisingly, the agent performs best already after 320K steps and is getting worse after that.\nIn the tensorboard log, I can see that the mean, min reward and explained variance do have the highest values at 320k training steps.</p>\n<p><a href=\"https://i.stack.imgur.com/JqsT8.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/JqsT8.png\" alt=\"enter image description here\" /></a></p>\n<p>I have seen this with stable-baselines and rllib and with other environments as well.</p>\n<p>I am wondering why this is the case. Is that a normal behaviour in reinforcement learning? Or do I have to modify some training parameters to continue improving the RL agent?</p>\n<p>I would like to see that the agent is increasing the min, mean reward so that it reaches almost the max reward. Is that realistic?</p>\n", "pids": ["5ee3526a91e011cb3bff746e"], "flag": 1}
{"question": "Why don&#39;t we also need to approximate $p(x \\mid z)$ in the VAE?", "body": "<p>In the VAE, we approximate the probability distribution <span class=\"math-container\">$p(z \\mid x)$</span>, where <span class=\"math-container\">$z$</span> is the latent vector and <span class=\"math-container\">$x$</span> is our data. The reason is that <span class=\"math-container\">$p(z \\mid x)$</span> becomes impossible to calculate for continuous data because of <span class=\"math-container\">$p(x)$</span>, which require integration (not in closed form) to be solved.</p>\n<p>But why don't we also need to approximate <span class=\"math-container\">$p(x \\mid z)$</span>?</p>\n<p>What I can guess here is that, in VAEs, we assume <span class=\"math-container\">$p(z)$</span> (prior), so we are able to calculate <span class=\"math-container\">$p(x \\mid z)$</span>, but for <span class=\"math-container\">$p(x)$</span> we can't assume its distribution? Is it right?</p>\n", "pids": ["5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "Plutchik&#39;s emotions from negative to positive", "body": "<p>I'm trying to order Plutchik's emotions model from the most negative to the most positive.</p>\n\n<p>These are the emotions in alphabetical order: </p>\n\n<pre><code>anger, anticipation, disgust, fear, joy, sadness, surprise, trust\n</code></pre>\n\n<p>I didn't find anything online regarding this. Can someone help me?</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 1}
{"question": "What can coma patients report about their experiences - if anything?", "body": "<p><a href=\"https://en.wikipedia.org/wiki/Coma\" rel=\"nofollow noreferrer\">Coma</a> is correlated to a significant inactivity of the cerebral cortex and the reticular activating system, while other parts of the brain - e.g. the limbic system - might still show considerable activity.</p>\n\n<p>My question is:</p>\n\n<blockquote>\n  <p>Are there cases where people recovered from a coma and could later plausibly report experiences they made during the coma?</p>\n</blockquote>\n\n<p>What kind of experiences would they typically report - if any? And how fine-grained can descriptions of such experiences be?</p>\n\n<p>Examples:</p>\n\n<ul>\n<li>\"I felt that I were alive.\" </li>\n<li>\"I felt horrible/relaxed.\" </li>\n<li>\"I sometimes felt hungry.\" </li>\n<li>\"I felt that my mother was there.\"</li>\n<li>\"I somehow felt she touched me.\" </li>\n<li>\"I somehow heard her say my name.\"</li>\n</ul>\n\n<p>Most surely, elaborate thoughts and complex emotions can not be recalled and plausibly reported (because they could not take place).</p>\n\n<blockquote>\n  <p>What would such reports tell us about the neural basis of\n  consciousness?</p>\n</blockquote>\n\n<p>Are there forms of recoverable coma where the cerebral cortex and/or the reticular activating system is completely mute, i.e. without any measurable coordinated neural activity?</p>\n\n<p>Do other parts of the brain necessarily show no measurable coordinated neural activity when the cerebral cortex and/or the reticular activating system doesn't?</p>\n", "pids": ["553bf9990cf2b2c73cb0539c"], "flag": 1}
{"question": "Is it possible to learn the number of layers?", "body": "<p>Is it possible, in a transformer or other deep architecture, to include the number of layers as a parameter of the model so it could be learned?</p>\n<p>In fact, I have a keras layer that I use to change the final layer without rebuilding the model, so I can just change a parameter between epochs (The original use was to try to train deep networks starting from shallower ones, increasing the number of layers after each epoch).</p>\n<pre><code>class LayerSelect(tf.keras.layers.Layer):\n    def __init__(self,nlevels,**kwargs):\n        super(LayerSelect,self).__init__(**kwargs)\n        self.nlevels = nlevels\n        self.range=tf.range(self.nlevels,dtype=tf.float32)\n                 \n    def build(self, input_shape):\n        self.kernel=self.add_weight(shape=(1,),\n                                    initializer=tf.keras.initializers.Constant(min(self.nlevels,14.0)/1.9),\n                                    trainable=True, dtype=tf.float32,\n                                    constraint=lambda x: tf.clip_by_value(x,1.0,self.nlevels))\n       \n    def call(self,inputs): \n        selector=tf.math.maximum([0.0], 1.0 - 1.0 *(self.range-self.kernel)**2 ) \n        final=tf.reduce_sum(inputs*selector,axis=-1)\n        return final\n</code></pre>\n<p>The layer expects an stack of hidden layers to choose from:</p>\n<pre><code>allEncoders=tf.stack([encoder[level] for level in range(layers)],axis=-1)\nfinalEncoderRaw=adhoc.LayerSelect(layers)(allEncoders)\n</code></pre>\n<p>So that by calling <code>set_weights</code> during the training I can choose as output any layer, or a combination of two, being the layer variable a float and using a wider selector, say <code>1.0 - 0.25 *(self.range-self.kernel)**2</code></p>\n<p>And as you can expect, if I set the weight to be trainable, the optimiser moves the variable. But it keeps either moving randomly some small percent or moving backwards towards smaller values. So it is possible that this approach is a dead end?</p>\n<p>If not a way to patch this method, is there another successful method to train the number of layers without using meta-parameter (hyperparameter grids) farms?</p>\n", "pids": ["58d82fc8d649053542fd59b8"], "flag": 1}
{"question": "If the instructions of a group intelligence test are misunderstood, are the results of that test invalid?", "body": "<p>For example, a researcher is investigating synonyms and prepares a test.  A participant undertaking the test incorrectly interprets the instructions, and understands the test to relate to antonyms rather than synonyms.</p>\n<p>Does this then make the test results invalid?</p>\n", "pids": ["56d924a3dabfae2eeeb363ad"], "flag": 1}
{"question": "Relationships Between Specific Behavioral Characteristics Associated With Clinical Diagnosis of Narcissists &amp; Sociopaths", "body": "<p>In the past 3½ decades, I've discussed, read, and studied a significant number of mental health practitioner claims, random anecdotal experiences, and clinical study abstract summaries &amp; reports regarding what is now called Narcissist Personality Disorder (NPD) and how this disorder relates to the psychological condition referred to as a sociopath. When I first looked into how the clinical community faced these two very similar conditions, I found most qualified sources to be mostly consistent in what they indicated.</p>\n\n<p>However, always open to opposing views, I've also read or been informed by others that seem to indicate the earlier claims have all made the same assumptions, and what was considered a common error. The conflicting sources suggested that the earlier sources all conflated the clinical behavior characteristics of the NPD condition with those exhibited by and leading to a diagnosis of a sociopath. </p>\n\n<p>In response to the resulting muddied waters, I found some clarity, at least to myself, in the notion that all Sociopaths are narcissists, but not all narcissists are sociopaths. In other words, when further confused and contradicted, I've always had a tendency to fall back onto those conclusions I arrived at years ago when first settling on a satisfactory understanding of the two. </p>\n\n<p>This understanding concluded that if a subject who was previously diagnosed with NPD was to be clinically diagnosed with the more severe condition of a sociopath, (I assume when formally diagnosed, the vernacular is more sophisticated than what I'm using here) the mental health practitioner making the determination would be required to observe, document, and assess any quantified increases in magnitudes of or changes to exhibited behavioral characteristics common to both the diagnosis of the NPD and the sociopath conditions, as well as any behavioral characteristics associated with either condition but presenting in novel form with the subject.</p>\n\n<p>From what I can remember, a number of these exhibited behaviors were very similar to, if not the same as those used in diagnosing someone with NPD, just at some sorry of elevated measure. Others were similar to those used with NPD, but would exhibit distinct differences if done so by a sociopath. Finally, some of those exhibited behaviors which contribute to the diagnosis of a sociopath seemed completely divorced from and in a few instances conflict with those suggesting a diagnosis of NPD.</p>\n\n<p>Frustratingly, what I have not retained are the specific characteristics or symptoms which triggered the very conversations I remember having. But what I do remember, and do so very clearly, was the lack of intellectual  satisfaction I always felt walking away from these discussion related to the unreconciled relationship I always felt these two conditions have to one another, where the parallels in behavior characteristics begin and where they end, or whether or not my fall back conclusion which always seemed to relation static was actually valid, at least from the clinical standpoint.</p>\n\n<p>I know I'm going to be told I can only present one question per post. As such, I'm going to get ahead of that criticism by providing my only question here:</p>\n\n<p><strong>Are there any relationships, similarities, or differences between the specific behavioral characteristics associated with a clinical diagnosis of narcissistic personality disorder (NPD) and those associated with a clinical diagnosis of a sociopath?</strong> </p>\n\n<p>That said, the following are not questions to be answered, rather meant to ensure those attempting to provide an answer have been provided a clear understanding of precisely what the single question above is trying to ask.</p>\n\n<p>The following should not be considered additional questions needed to be answered, that would be very anti-stack of me to do. Instead, the following offer additional granularity and detail in the form of drill down questions. These are meant for purposes of guidance in answering the single, not a multiple set of questions noted in bold above. </p>\n\n<p>Basically, I'm restating the same question in a few different ways at a few different levels to ensure the full breadth of the single question is understood and hopefully answered:</p>\n\n<p>1.1 - What are the actual, clinical differences between NPD and the disorder colloquially known as a sociopath?</p>\n\n<p>1.2 - Are the two conditions, NPD and the condition of sociopath, actually considered to be clinically related?</p>\n\n<p>1.3 -  Is the relationship really as simplistic as it always just a case of a narcissist exhibiting more acute levels of behavior which is common to both conditions, meet or exceeded a certain behavioral threshold, and thus jumped to the diagnosis of the more severe of the two conditions, and is now a sociopath?</p>\n\n<p>1.4 - If that's the case, what are the specific behavioral characteristics used to make this determination in the clinical setting?</p>\n\n<p>1.5 - What are the predetermined thresholds, how is the associated behavior quantified, and how are those metrics measured?</p>\n\n<p>See, those are simply all small parts of the same question. That's why they are numbered 1.X, to ensure that they are simply detailed parts of the single question in bold.</p>\n\n<p>For the record, this question is being asked to assist me in determining whether specific people I've been exposed to during my life at various times and to various effects to me, were as I suspect, likely diagnosable as sociopaths. All are narcissists, but the lines of delineation are not stated very clearly.</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 1}
{"question": "Can the output layer be connected to multiple layers?", "body": "<p>Normaly, the output layer is only connected to the second last layer.\nIs there any model that the output layer is connected to multiple layers (For example, the second last layer AND the layer before it.)</p>\n", "pids": ["573696026e3b12023e515eec", "5d5e6b9a3a55acfce79a16dd", "58437725ac44360f1082fa5e", "573698016e3b12023e6da477"], "flag": 1}
{"question": "Is there an analog to the five factor model for emotion?", "body": "<p>To the best of my understanding, the five factor model of personality comes from a factor analysis on a large list of adjectives that can be used to describe an individual's personality. It is validated, in some sense, by its usefulness in predicting behavior and life outcomes in a wide range of contexts.</p>\n<p>It seems like something very similar could be done for emotion. I.e. list words describing a persons present state (angry, remorseful, sad, bitter, frustrated, etcetera) and do a factor analysis on those. Then, see if the resulting model (assuming that the analysis yields something useful) is predictive of shorter term / state dependent behavior.</p>\n<p>Has any work like this been done?</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 1}
{"question": "What is the difference between representation and embedding?", "body": "<p>As I searched about this two terms, I found they are somehow like each other, both try to create a vector from raw data as I understood. But, what is the difference of this two term?</p>\n", "pids": ["53e9acc4b7602d97036a1037"], "flag": 1}
{"question": "Comparing Reinforcement Learning models", "body": "<p>I am currently completing my thesis on optimising combinatorial problems, and we decided to utilize reinforcement learning. The problem is that <strong>I am not sure which algorithm to choose.</strong> Is there a comprehensive table or guide to help me choose a model that works well for this domain or in general?</p>\n", "pids": ["5e5e18d693d709897ce344b7"], "flag": 1}
{"question": "Should I use an unsupervised approach or train a classifier with many classes to build a deep image feature extractor?", "body": "<p>I'd like to build a deep feature extractor of images (using a Bi-linear CNN).</p>\n<p>What would lead to the best results:</p>\n<ul>\n<li>an unsupervised approach (such as <a href=\"https://iopscience.iop.org/article/10.1088/1742-6596/1237/3/032044/meta\" rel=\"nofollow noreferrer\">https://iopscience.iop.org/article/10.1088/1742-6596/1237/3/032044/meta</a>), or</li>\n<li>training a classifier on as many classes as I can, and hope it generalized enough?</li>\n</ul>\n<p>I would then like to use this extractor as:</p>\n<ul>\n<li>A weights initialization for other classical tasks</li>\n<li>A feature extractor for Few Shot Learning approaches</li>\n</ul>\n", "pids": ["5eede0b091e0116a23aafc15", "618895205244ab9dcb40a5bc", "5fbcce8d91e01127d58eecf3", "5e997e4391e01118b66a5ebf", "5e91957f91e011505f40a476", "627cd8955aee126c0f42f822", "5e4672c93a55ac14f595d8b5", "5eede0b091e0116a23aafb82"], "flag": 1}
{"question": "Is down-sampling the only purpose of using stride?", "body": "<p>Stride is used in at least two operations: convolution and pooling. Both operations can be viewed as applying a kernel function on input using a kernel (filter).</p>\n<p>Stride determines the amount of &quot;jump&quot; the kernel needs to perform on the input. Obviously, in the extreme case, if the kernel size and stride are one, the input size is the same as the output size. In all other cases, the output size is less than the input size.</p>\n<p>So, I am guessing that down-sampling is the only purpose of using stride in any case. Am I true? Else, are there any cases in which stride is used in order to serve another purpose?</p>\n", "pids": ["573695ff6e3b12023e5136ef"], "flag": 1}
{"question": "Why don&#39;t we use diffusion for non-graph CNNs?", "body": "<p>I'm pretty new to graph neural networks, so please forgive me if this is a silly question.</p>\n<p>Diffusion is a method used to improve graph CNNs, however it seems to me that general CNNs can also benefit from taking into consideration diffusion-like processes (for example, in CV, one may want information to diffuse from a small neighborhood, then to a bigger neighborhood, etc.). Also, PDE-based methods have been used in CV traditionally (before deep learning became a thing), so there's at least some evidence that this might work. But I did search extensively, and I can't find any information on using diffusion for general CNNs!</p>\n<p>Therefore, what I'm curious about is: why didn't I find any information about this? Is it already explored under a different name? Or does it not really work because of some reason I don't know (or didn't think about)? Or maybe it does work, but there are some technical difficulties?</p>\n", "pids": ["573696016e3b12023e515a00", "5550417d45ce0a409eb3bc08", "58437725ac44360f1082fa5e", "57a4e91aac44365e35c97589"], "flag": 1}
{"question": "What is the role of skip connections in U-Net?", "body": "<p>I was able to find that the skip connections used in U-Net help to recover fine grained details in the prediction, however I do not understand what is meant by this. Besides, I was wondering what would happen if the U-Net does not include skip connections.</p>\n", "pids": ["573698016e3b12023e6da477", "573696026e3b12023e515eec"], "flag": 1}
{"question": "Order of features learned by DNNs during training?", "body": "<p>I'm looking for papers probing into the question of what features get learned when (or equivalently what subproblems get &quot;solved&quot; when) during the training process. For example, a paper showing that a Convnet trained on MNIST learns to distinguish 0 from 1 before it learns to distinguish 0 from 8.</p>\n<p>The one example I can think of off the top of my head is the <a href=\"https://arxiv.org/abs/2201.02177\" rel=\"nofollow noreferrer\">Grokking paper</a>, but that's looking at a slightly different (and less intuitive) phenomenon. Thanks!</p>\n", "pids": ["58437722ac44360f1082f090"], "flag": 1}
{"question": "Is there an image classification dataset where the class depends on spatial relations?", "body": "<p>My question is pretty much the one asked above. To clarify a bit further: I have only found datasets that do object localization and that also have relations between the objects annotated (like: &quot;Here is the horse, here is the rider. The rider rides the horse&quot;. What I am looking for is a dataset where you can do classification based on spatial relations (Like: &quot;I am a positive example, because the rider is above the horse. I am a negative example, because the rider is below the horse (or besides it, etc)&quot;).</p>\n<p>Any help is appreciated</p>\n", "pids": ["599c797b601a182cd26430c3"], "flag": 1}
{"question": "How is GPT 4 able to solve math?", "body": "<p>How can GPT 4 solve complex calculus and other math problems. I believe these problems require analytical reasoning and ability to compute numbers. Does it still use a LLM to complete this process or does it add on to this?</p>\n<p><a href=\"https://openai.com/research/gpt-4\" rel=\"nofollow noreferrer\">Here</a> is the link to the official results published by OpenAI</p>\n", "pids": ["62aa9fb55aee126c0fa5cba5"], "flag": 1}
{"question": "Should DQN/PPO be used for state spaces that are not that large?", "body": "<p>I'm interested in trying out Q-learning to solve a problem where I already have a simulation of the environment that can run at about 100,000 fps or steps/sec. Its also continuous with no terminal states.</p>\n<p>The estimated state space should be no more than 100,000. Most state can take integer values from 0 to 200.</p>\n<p>As for the action space, I am unsure if it should be 10, or if the action space should be 1000 (2**10). Basically there are 10 possible individual actions, but the actions can be pressed in all sorts of combinations, like action 1, 2, 3, and 5 can be taken at the same time.</p>\n<p>In this case, can tabular method still work fine? If so, are there any advantages of using a neural network, like DQN or PPO?</p>\n", "pids": ["5e885d0791e011213a31bc4f"], "flag": 1}
{"question": "How can positive and negative mindsets influence interpersonal relationships with others?", "body": "<p>I want to know how positive and negative mindset can influence interpersonal relationships with others.  For example: if you have a negative mindset, would people not want to relate with you?</p>\n", "pids": ["5e297001df1a9c0c41e7a137", "53e9991db7602d970215bf3c"], "flag": 1}
{"question": "Why readout operation in message passing graph neural nets have to be invariant to node permutations?", "body": "<p>I am reading the paper Neural Message Passing for Quantum Chemistry by Justin Gilmer et al. And I have a question regarding this passage</p>\n<blockquote>\n<p>The message functions Mt, vertex update functions Ut, and\nreadout function R are all learned differentiable functions.\nR operates on the set of node states and must be invariant to\npermutations of the node states in order for the MPNN to be\ninvariant to graph isomorphism.</p>\n</blockquote>\n<p>It is not clear for me, why MPNN have to be invariant to graph isomorphism. Could you please share your thoughts on it?</p>\n", "pids": ["5c8a11324895d9cbc6121c34"], "flag": 1}
{"question": "Metacognitive strategy in terms of cognitive science", "body": "<p>Everything I can find about term 'metacognitive strategy' or 'metacognition' is related to teaching or learning strategies, but I wonder what does it actually mean in terms of cognitive science.</p>\n", "pids": ["5a9cb66717c44a376ffb8bab"], "flag": 1}
{"question": "How do ChatGPT content filters work? (If not chatGPT then in general)", "body": "<p>I first tried ChatGPT few days ago.  And every day that goes by it seems more and more content filters are introduced.   I can still make it do stuff if I &quot;jailbreak it&quot; but I feel like the restrictions are getting tighter.  By the way I'm not making it do anything bad, just testing it's limits of what it can do.  Over time it can do less and less (or is willing to do less and less).  This makes me wonder how the filters are implemented and why they work the way they do:</p>\n<ul>\n<li>Why is it that seemingly for any filter that's put in place there is a workardound?  Things like (imagine, pretend etc).  If something is filtered wouldn't it be filtered across all contexts?   Why does adding a magic word like &quot;act as though&quot; make it ignore filters all of a sudden?</li>\n<li>Are the rest of you seeing the same trend of increased filtering?   For me, coming from a sysadmin background it almost feels like a fight between the admins and the users.  The admins begin gently with fine grained filters with very specific contexts, but as they see the onslaught in creativity of the users of bypassing those specific contexts they are using increasingly more and more general contexts to filter on (because they can't keep up with all the jailbreaks).   Of course this blocks legit uses too.</li>\n<li>Since ChatGPT is (or more precisely, used to be) very cooperative with what the users told it to behave like, do the admins have a similar natural language interface to interact with chatGPT to tell it how they want it to behave?   Ex admins say &quot;never give a response that's less than 5 sentences in length&quot;, then even though the user says &quot;answer me simply yes or no&quot;.  Admins (hidden) request takes precedence?</li>\n<li>Why in a single session I can have it cooperate and then when asked to do exactly the same thing seconds later it refuses? (ex: answer me with a single random swear word: works perfect and then couple questions later it refuses)</li>\n</ul>\n<p>I tried asking some of these questions to ChatGPT directly and I didn't get very far with it except that apparently the boiler plate &quot;As a large language model trained by OpenAI, I am a machine learning model that ...&quot; is some kind of hard-coded disclaimer added by the engineers.   Supposedly it's a different mechanism from content filters.   Which kind of makes sense.   Of course I don't know if I can trust that answer, as how the disclaimer sais ChatGPT is known to be confidently incorrect.</p>\n<p>Also, I realize chatGPT is proprietary, so I'm not expecting anyone to reveal any secrets.  I will be very satisfied of knowing how this is handled in similar NLP models.</p>\n", "pids": ["62f07ec290e50fcafde5ace6", "62f07ec290e50fcafde5ace6"], "flag": 1}
{"question": "What happens if you lie to a child during language acquisition?", "body": "<p>During language acquisition a child can learn 20 words a day. What would happen if the parent decided to lie to the child during this time so that whenever the child said \"what that?\" the parent made up a random word.</p>\n\n<p>Would this permanently stay in the child's mind forever? Or would the child just learn the \"real\" word from everyday speech?</p>\n\n<p>As an aside, for years I thought the word \"modest\" meant the opposite of what it means. Because it is only ever said sarcastically. As in \"wow, your <em>sooooo</em> modest!\" And that's just one word.</p>\n", "pids": ["53e9b1ddb7602d9703c70645", "56f6064b0cf2d36f21763292"], "flag": 0}
{"question": "How can the input order of pairs into a neural network not matter (i.e. symmetry)?", "body": "<p>Let me explain, suppose we are building a neural network that predicts if two items are similar or not. This is a classification task with hard labels (0, 1) of examples of similar and dissimilar items. Suppose we also have access to embeddings for each item.</p>\n<p>A naive approach might be to concat the two item embeddings, add a linear layer or two and finally perform a sigmoid (as this is binary classification) for the output probability.</p>\n<p>However, that approach would mean that potentially inputing <code>(x, y)</code> to the model could give a different score from inputing <code>(y, x)</code> into it, since concat is not symmetric.</p>\n<p>How can we go about overcoming this? What is the common practice in this situation?</p>\n<p>So far I have thought about:</p>\n<ol>\n<li><p>Whenever I input <code>(x, y)</code> I can also input <code>(y, x)</code> and always take the average prediction of both of them. But this feels like a hacky way of forcing the network to be symmetric, it doesn't make it learn the same thing despite of the input order.</p>\n</li>\n<li><p>Replacing concat with some other symmetric tensor operation. But what operation? Addition? Element-wise multiplication? Element-wise max? What's the &quot;default&quot;?</p>\n</li>\n</ol>\n", "pids": ["5fc6166a91e0118947381a45", "58d82fd2d649053542fd75d8", "58437722ac44360f1082ed35"], "flag": 1}
{"question": "Is there a biological reason for spreading food intake into breakfast-lunch-dinner?", "body": "<p>I keep hearing over an over how humans can satisfy their entire daily caloric need in one sitting at a fast food restaurant. At the same time I'm looking at the kitchen plates, cups, etc, and they also seem to be getting bigger. </p>\n\n<p>This makes me ask the question - <strong>was breakfast-lunch-dinner a concept invented because people:</strong></p>\n\n<ul>\n<li>Could not make enough food?</li>\n<li>Could not make food fast enough?</li>\n<li>Could not make food with high enough caloric intake?</li>\n</ul>\n\n<p>I'm thinking along the lines of: you can make only so much tasteless porridge and stuff it in your mouth before it gets cold. At the same time I know that gorillas and some other primates have a very long (8 hours?) feeding session of eating raw vegetation throughout the day.</p>\n\n<p><strong>Is there a biological explanation why human food intake should be spread into X distinct sittings?</strong></p>\n", "pids": ["55a51e3965ceb7cb02e17aab", "55a4702165ce31bc877aadb8", "53e9ae1cb7602d970382ec96"], "flag": 1}
{"question": "relationship between mood and working memory", "body": "<p>What is the relationship between working memory and positive or negative mood as higher order affective states which can change vary slowly compared to moment-to-moment affective responses (both valence and arousal)? Are there any literature related to this?</p>\n", "pids": ["55a4694465ce31bc8779c360"], "flag": 1}
{"question": "Research on teaching / learning methods for personality types", "body": "<p>I was reading <a href=\"https://www.research.ed.ac.uk/portal/en/publications/learning-approaches-associations-with-typical-intellectual-engagement-intelligence-and-the-big-five(d16c5563-d9c8-4061-885c-28dc8e380f2e).html\" rel=\"nofollow noreferrer\">research on learning approaches</a> and the big five personality traits, and was wondering if anyone can recommend existing research on the <strong>most effective learning methods for each personality type</strong>.</p>\n\n<p>Is this even a thing? Is there proof that some learning techniques can be better for some types of personalities than others?</p>\n", "pids": ["56d924a1dabfae2eeeb358f1", "56d9249edabfae2eeeb34856", "53e9b58eb7602d97040d29b9", "53e9aad8b7602d9703454df1"], "flag": 0}
{"question": "Looking for references discussing aspect of human/animal adaptivity and its pertaining computational objectives", "body": "<p>Does anyone know some references (e.g. papers or book chapters) that discuss aspects of the adaptivity of human/animal based on studying the behavior and ideally, what computational objectives pertaining to the adaptivity of human/animal have been or can be suggested based on them?</p>\n<p>An example: Animals should adapt to their environment to survive, they should develop whatever [computation] needed to detect the hunter and escape timely. They should update their internal model (whatever we define the internal model), with changes in their environment.</p>\n", "pids": ["5ff68425d4150a363cbced59"], "flag": 1}
{"question": "Relationship and differences between psychosomatic, somatoform and idiopathic disorders", "body": "<p>I'm really confused because it seems to me these terms overlap to some extent.</p>\n\n<p>Psychosomatic disorder</p>\n\n<blockquote>\n  <p>psychosomatic<br> adj.\n  1. of or pertaining to a physical disorder that is caused or notably influenced by emotional factors.<br> <a href=\"https://www.thefreedictionary.com/Psychosomatic\" rel=\"nofollow noreferrer\">American Heritage Dictionary</a></p>\n  \n  <p>psychosomatic<br>\n  1. (Psychology) of or relating to disorders, such as stomach ulcers, thought to be caused or aggravated by psychological factors such as\n  stress<br> <a href=\"https://www.thefreedictionary.com/Psychosomatic\" rel=\"nofollow noreferrer\">Collins English Dictionary</a></p>\n</blockquote>\n\n<p>somatoform disorder (called somatic symptom disorder since DSM-V)</p>\n\n<blockquote>\n  <p>denoting physical symptoms that can not be attributed to organic\n  disease and appear to be of psychic origin. <br> <a href=\"https://medical-dictionary.thefreedictionary.com/somatoform\" rel=\"nofollow noreferrer\">Miller-Keane\n  Encyclopedia and Dictionary of Medicine, Nursing, and Allied\n  Health</a></p>\n  \n  <p>denoting physical symptoms that cannot be attributed to organic\n  disease and appear to be psychogenic.<br> <a href=\"http://Dorland&#39;s%20Medical%20Dictionary%20for%20Health%20Consumers\" rel=\"nofollow noreferrer\">Dorland's Medical\n  Dictionary for Health Consumers</a></p>\n</blockquote>\n\n<p>In both cases these terms seem to be used for physical symptoms which rather than being attributed to physical conditions, are based on mental factors, ie., psychogenic.</p>\n\n<p>Also, three of these definitions are framed in terms of \"thought to be caused by psychological factors\", \"appear to be of psychic origin\" and \"appear to be psychogenic.\" Given that these three terms imply cause is not known with certainty they are idiopathic, right?</p>\n\n<blockquote>\n  <p>idiopathic<br> adj.<br> Of, relating to, or designating a disease\n  having no known cause.<br> <a href=\"https://www.thefreedictionary.com/idiopathic\" rel=\"nofollow noreferrer\">American Heritage Dictionary</a></p>\n</blockquote>\n\n<p>From looking at these two meanings of psychosomatic disorder and somatoform disorder, am I mistaken in perceiving them the same way, or at least confusingly almost the same thing? One says \"relating to disorders ... thought to be caused or aggravated by psychological factors\" and the other says \"denoting physical symptoms ... (that) appear to be of psychic origin.\"</p>\n\n<p>Could someone clarify what the differences are in light of the definitions, which seem quite the same to me?</p>\n", "pids": ["56d867bddabfae2eeeadb3a6"], "flag": 0}
{"question": "Do flies actually take off backwards?", "body": "<p>I've been told that flies take off backwards, but I haven't really been able to prove it to myself. The closest I've gotten was noticing that they fly into window glass back-first, with their heads pointing up. Is that how they take off?</p>\n", "pids": ["53e99ff0b7602d97028d1bdc"], "flag": 1}
{"question": "Is Paul&#39;s Churchland claim about qualia supported by science?", "body": "<p><a href=\"https://en.wikipedia.org/wiki/Knowledge_argument\" rel=\"nofollow noreferrer\">Knowledge argument</a>:</p>\n\n<blockquote>\n  <p>Mary is a brilliant scientist who is, for whatever reason, forced to investigate the world from a black and white room via a black and white television monitor. She specializes in the neurophysiology of vision and acquires, let us suppose, all the physical information there is to obtain about what goes on when we see ripe tomatoes, or the sky, and use terms like \"red\", \"blue\", and so on. She discovers, for example, just which wavelength combinations from the sky stimulate the retina, and exactly how this produces via the central nervous system the contraction of the vocal cords and expulsion of air from the lungs that results in the uttering of the sentence \"The sky is blue\". [...] What will happen when Mary is released from her black and white room or is given a color television monitor? Will she learn anything or not?</p>\n</blockquote>\n\n<p>Paul's Chuchland <a href=\"https://en.wikipedia.org/wiki/Qualia#Paul_Churchland\" rel=\"nofollow noreferrer\">answer is</a>:</p>\n\n<blockquote>\n  <p>According to Paul Churchland, Mary might be considered to be like a feral child. Feral children have suffered extreme isolation during childhood. Technically when Mary leaves the room, she would not have the ability to see or know what the color red is. A brain has to learn and develop how to see colors. Patterns need to form in the V4 section of the visual cortex. These patterns are formed from exposure to wavelengths of light. This exposure is needed during the early stages of brain development. In Mary's case, the identifications and categorizations of color will only be in respect to representations of black and white.</p>\n</blockquote>\n\n<p>But can't I really see new color if I never experienced some mixture of wavelengths prior? I thought that the person who saw only 90% of spectrum for the whole life still would gain new experience when seeing something from remaining 10%.</p>\n\n<p>I know cone cells are responsible for color perception. They are located on retina of eyes. Most people have three of them, but there can be more or less. Signals from them travel to parvocellular cells and to koniocellular cells. It's not clear how color is processed there, as far as I am aware. Then signals travel to visual cortex from there. And V1 is said to be the most influential part of visual cortex. But I am not sure how V4 is responsible for color perception.</p>\n\n<p>Is there scientific support for his claim? Or instead, is there scientific support for the opposite?</p>\n", "pids": ["5ae4d9fb1b13da3b95e5085f"], "flag": 0}
{"question": "Hobbies / interests correlated with Big 5 scores?", "body": "<p>Are there any established treatments (I'm going to leave the exact terms a little bit vague because my understanding is vague) of which hobbies and interests are most likely to be attractive to someone with XYZ score on an  OCEAN / Big 5 test?</p>\n\n<p>TIA,</p>\n", "pids": ["56d924a1dabfae2eeeb35972", "5de0bc55df1a9c0c4159b5e2"], "flag": 1}
{"question": "Is Freuds theory of negation testable and does it survive testing?", "body": "<p>Freuds body of work not only provides a basis von clinical practice, but is also often quoted in social sciences and social philosophy. I recently came across a text that references Freuds concept of <em>Verneinung</em> (Negation):</p>\n\n<blockquote>\n  <p>Ein verdrängter Vorstellungs- oder Gedankeninhalt kann also zum Bewusstsein durchdringen, unter der Bedingung, dass er sich verneinen lässt. Die Verneinung ist eine Art, das Verdrängte zur Kenntnis zu nehmen, eigentlich schon eine Aufhebung der Verdrängung, aber freilich keine Annahme des Verdrängten. [...]. Mit Hilfe der Verneinung wird nur die eine Folge des Verdrängungsvorganges rückgängig gemacht, dass dessen Vorstellungsinhalt nicht zum Bewusstsein gelangt. Es resultiert daraus eine Art von intellektueller Annahme des Verdrängten bei Fortbestand des Wesentlichen an der Verdrängung.</p>\n  \n  <p>A supressed element of thoughts or imaginations can surface in the conscious mind under the condition it can be negated. Negation is away of acknowledging the supressed, actually a repeal of the supression, but of course not an acceptance [...] By way of negation only one consequence of the supression is undone, that the content of the supressed does not become conscious. The result is a kind of intellectual acceptance of the supressed, while the supression mostly persists.</p>\n</blockquote>\n\n<p>(<a href=\"https://de.wikipedia.org/wiki/Verneinung_(Psychoanalyse)\" rel=\"nofollow noreferrer\">German text wikipedia</a>, translation mine)</p>\n\n<p>Now my question is, is this aspect of negation testable (=falsifiable) in some way? What where results of such tests, if any? Absent tests that would satisfy a positivist, is there a body of experience from clinical practice that supports (or not) this theory of negation?</p>\n\n<p>I'm aware that there's a lively debate about inhowfar psychoanalysis is  science or pseudoscience. Much of psychoanalysis is not falsifiable, but this specific aspect may be.</p>\n", "pids": ["56d83b34dabfae2eee60781a"], "flag": 0}
{"question": "What is the proper definition of psychopathy?", "body": "<p>I've seen all those checklists of psychopathy traits, read many articles and watched several tutorials - they mention like dozens of characteristics, but never make it clear about the actual meaning of the word.</p>\n\n<p>Is psychopathy the lack of emotion? Is it the lack of empathy? What's the most accurate definition of the term?</p>\n\n<p>Also, a lot of things that I've seen are unclear and contradictory:</p>\n\n<ol>\n<li>A lot of explanations mention \"disregard to social norms\" as an intrinsic trait - but it clearly contradicts the trait of \"self-interest\", because by committing crimes or disregarding norms they harm themselves just as much as they harm people around. That's exactly what some psychopaths respond to allegations that they are dangerous and may commit a crime: \"there's absolutely no reason or benefit of committing crime, so why would I do it?\"</li>\n<li>A lot of explanations mention \"superficial charm\", while it's unclear how do you even measure that objectively and what does it have to do with mental disorders? Is the evaluating therapist just supposed to tick \"yes\" next to \"superficial charm\" if they personally were charmed by a psychopath, or what? And what does it even have to do with mental health: it's not like \"charm\" is an aura directly projected by brain.</li>\n<li>It's very unclear about impulsiveness, aggressiveness and impulsivity: some mention them as intrinsic traits of psychopathy, while others claim that they have nothing to do with it. It's also unclear how do they fit together with lack of emotional response or self interest, because they have nothing to do with each other or even contradict each other.</li>\n<li>Things like \"manipulation\", \"lack of realistic goals\" or \"disregard to safety\" seem like things that 90% of the population would qualify for, at least at some point. What exactly is so special about \"psychopathic\" disregard for safety that makes it stand out from the disregard rutinely demostrated by every chemistry freshman? Is it like they are incapable of understanding the very concept of safety, or what? Are they not only remorseless and aggressive, but also intellectually retarded? Does there exist a negative thing that psychopaths aren't?</li>\n</ol>\n\n<p>In short, to the question of what psychopathy means, everyone says entirely different things, most of which either don't make sense or are self-contradictory. It seems like a blanket term for everything that's considered \"evil\" by society, but doesn't seem like a real mental disorder. Is it even one disorder, or a collective name for several unrelated disorders?</p>\n\n<p>The only thing that I am clear about is that psychopathy is innate (in comparison to sociopathy, which is trauma-induced).</p>\n\n<p>P.S. I have scientific background, but I am not a psychologist - so it's possible that everything in psychology is as \"vague\", and I just don't understand how does this area of science works (although, for example, bipolar disorder was clear enough to me).</p>\n", "pids": ["5db92b1847c8f7664621c81c"], "flag": 0}
{"question": "In what situation would you want to use NEAT over reinforcement learning?", "body": "<p>NEAT is an evolutionary algorithm. When would you want to use NEAT over more traditional/common RL algorithms like PPO or SAC etc. What advantage does it give you?</p>\n", "pids": ["5b67b46f17c44aac1c863092"], "flag": 1}
{"question": "Propagating gradients through an &quot;Item Selector&quot; network", "body": "<p>Consider the following problem:</p>\n<p>There are <span class=\"math-container\">$N$</span> items and <span class=\"math-container\">$S$</span> slots. Each item is a vector of length <span class=\"math-container\">$D$</span>.\nThe goal is to train a neural network to select one item per slot in order to minimize the loss function <span class=\"math-container\">$L$</span>, given any arbitrary list of items. This loss function could also be thought of as a reward function; it's not comparing labels, it just outputs the 'value' of some slots/items configuration, and it's differentiable. (In my particular application, this function is another MLP which can be trained separately; it's an actor-critic setup. But this problem applies to any sort of differentiable loss/reward function).</p>\n<p>Assumptions:</p>\n<ul>\n<li>The same item can be used multiple times in different slots.</li>\n<li>We have an infinite number of training examples available; they don't need to be labelled so they can be generated automatically.</li>\n<li><span class=\"math-container\">$S \\times N$</span> is large, such that we can't practically enumerate the value of <span class=\"math-container\">$L$</span> for all possible configurations of items in slots for a particular example. (If we could, then this would turn into a simple supervised learning case).</li>\n</ul>\n<p>Here's an example where <span class=\"math-container\">$N = 8$</span>, <span class=\"math-container\">$S = 4$</span>, <span class=\"math-container\">$D = 1$</span>. The neural network is an MLP which outputs an <span class=\"math-container\">$S \\times N$</span> matrix of logits. These are then converted to a binary matrix which is multiplied with the original list of items to get the selected item in every slot, on which the loss can be calculated.\n<a href=\"https://i.stack.imgur.com/Gasr6.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/Gasr6.png\" alt=\"enter image description here\" /></a></p>\n<p>The problem is what should happen between the neural net output and the binary 'selection' matrix (The ??? bubble in the diagram).</p>\n<ul>\n<li>It's natural to do an argmax/one-hot operation on the logits (i.e. push the max logit to 1 and the rest to zero). But this operation isn't differentiable, so the MLP can't be trained.</li>\n<li>You could do a softmax instead, which has good gradients, but then the problem is broken because the selected items are weighted combinations of items in the original list, which isn't allowed.</li>\n<li>You can also do softmax with &quot;temperature&quot;, e.g. <code>softmax(logits * 10e5)</code>, to get a more argmax-like behavior in a differentiable function. But in practice, the gradients are low quality and the network doesn't train properly.</li>\n<li>You can try argmax for the forward pass, but softmax for the backwards pass - this kind of works, but again in practice the neural network does not converge to a good solution.</li>\n</ul>\n<p>Is there any kind of neural network architecture or training regimen that can solve or sidestep this problem? Or is this application fundamentally unsuited for back-propagation?</p>\n", "pids": ["58d82fcbd649053542fd6178", "53e9ac95b7602d970366cfab"], "flag": 1}
{"question": "Why do we have to train a model from scratch every time?", "body": "<p>I have started on Andrew Ng's machine learning course. It seems that machine learning is learning correlations with known data based on as many parameters as possible. For example, if we collect data on existing property prices with information on the land area, built-in area, type of building, age of the building, etc, it is possible to predict the price of another property if we input the value of the various parameters of this property.</p>\n<p>Similarly, if we keep the images (the black and white pixels) of cats, we can tell whether a new picture is a cat if it bears some resemblance to the pixels of existing labeled cat images.</p>\n<ol>\n<li><p>This approach sounds great, but is it practical? How much effort and zettabytes of data do we have to keep just to reach the brainpower of, say, a 3-year old, who can recognize dogs, cats, tigers, a Mustang, trucks, a hamburger restaurant, and so on?</p>\n</li>\n<li><p>Why does everyone have to repeat the effort of learning the same things?</p>\n</li>\n<li><p>If Google has already learned cats, or if someone already has a program to recognize handwritten digits, can this knowledge be shared and re-used? Or is it just a matter of paying for them?</p>\n</li>\n</ol>\n", "pids": ["57a4e91aac44365e35c975bc"], "flag": 1}
{"question": "What was the average decision speed pf Alpha Zero in the recent Stockfish match?", "body": "<p>The match got a lot of press, and I doubt anyone is surprised that Alpha Zero crushed Stockfish.</p>\n\n<p>See: <a href=\"https://www.chess.com/news/view/google-s-alphazero-destroys-stockfish-in-100-game-match\" rel=\"nofollow noreferrer\">AlphaZero Destroys Stockfish in 100 Game Match</a> </p>\n\n<p>To me, what's really salient is that <em>\"much like humans, AlphaZero searches fewer positions that its predecessors. The paper claims that it looks at \"only\" 80,000 positions per second, compared to Stockfish's 70 million per second.\"</em>  </p>\n\n<p>For those who remember Matthew Lai's <a href=\"https://arxiv.org/pdf/1509.01549.pdf\" rel=\"nofollow noreferrer\">GiraffeChess</a>:</p>\n\n<blockquote>\n  <p>However, it is interesting to note that the way computers play chess is very different from how\n  humans play. While both humans and computers search ahead to predict how the game will go on,\n  humans are much more selective in which branches of the game tree to explore. Computers, on the\n  other hand, rely on brute force to explore as many continuations as possible, even ones that will be\n  immediately thrown out by any skilled human. In a sense, the way humans play chess is much more\n  computationally efficient - using Garry Kasparov vs Deep Blue as an example, Kasparov could not\n  have been searching more than 3-5 positions per second, while Deep Blue, a supercomputer with\n  480 custom ”chess processors”, searched about 200 million positions per second <a href=\"https://arxiv.org/pdf/1509.01549.pdf\" rel=\"nofollow noreferrer\">1</a> to play at\n  approximately equal strength (Deep Blue won the 6-game match with 2 wins, 3 draws, and 1 loss).</p>\n  \n  <p>How can a human searching 3-5 positions per second be as strong as a computer searching 200\n  million positions per second? And is it possible to build even stronger chess computers than what\n  we have today, by making them more computationally efficient? Those are the questions this\n  project investigates.</p>\n</blockquote>\n\n<p><em>[Lai was tapped by DeepMind as a researcher last year]</em></p>\n\n<p>But what I'm interested in at the moment is the decision speed in these matches:</p>\n\n<p><strong>- What was the average time to make a move in the AlphaZero vs. Stockfish match?</strong></p>\n", "pids": ["5a73cbcc17c44a0b3035f7b3"], "flag": 1}
{"question": "Training an AI to play Starcraft 2 with superhuman level of performance?", "body": "<p>I'm interested in working on challenging AI problems, and after reading this article (<a href=\"https://deepmind.com/blog/deepmind-and-blizzard-open-starcraft-ii-ai-research-environment/\" rel=\"nofollow noreferrer\">https://deepmind.com/blog/deepmind-and-blizzard-open-starcraft-ii-ai-research-environment/</a>) by DeepMind and Blizzard, I think that developing a robust AI capable of learning to play Starcraft 2 with superhuman level of performance (without prior knowledge or human hard-coded heuristics) would imply a huge breakthrough in AI research.</p>\n\n<p>Sure I know this is an extremely challenging problem, and by no means I pretend to be the one solving it, but I think it's a challenge worth taking on nonetheless because the complexity of the decision making required is much closer to the real world and so this forces you to come up with much more robust, generalizable AI algorithms that could potentially be applied to other domains.</p>\n\n<p>For instance, an AI that plays Starcraft 2 would have to be able to watch the screen, identify objects, positions, identify units moving and their trajectories, update its current knowledge of the world, make predictions, make decisions, have short term and long term goals, listen to sounds (because the game includes sounds), understand natural language (to read and understand text descriptions appearing in the screen as well), it should probably be endowed also with some sort of attention mechanism to be able to pay attention to certain regions of interest of the screen, etc. So it becomes obvious that at least one would need to know about Computer Vision, Object Recognition, Knowledge Bases, Short Term / Long Term Planning, Audio Recognition, Natural Language Processing, Visual Attention Models, etc. And obviously it would not be enough to just study each area independently, it would also be necessary to come up with ways to integrate everything into a single system.</p>\n\n<p>So, does anybody know good resources with content relevant to this problem? I would appreciate any suggestions of papers, books, blogs, whatever useful resource out there (ideally state-of-the-art) which would be helpful for somebody interested in this problem.</p>\n\n<p>Thanks in advance.</p>\n", "pids": ["5c8c09f64895d9cbc6c4734a"], "flag": 1}
{"question": "Detecting Keypoint of 3D model, and distance between them", "body": "<p>I am very new to AI, I have a set of 3D human models that I would like to train the algorithm to identify wrist, upper arm, lower arms, etc, and distance between them.</p>\n\n<p>From my understanding, this is a regression problem. But with my very limited knowledge, most tutorial online showing me cat and dog classification problem.</p>\n\n<p>Do you have any clue for me to research next? There are some paper saying to convert the 3D model to image, and use convolutional neural network for training.</p>\n\n<p>p/s: Please don't downvote me, I am too young and too lost in this field.</p>\n", "pids": ["573696f46e3b12023e5f10b0"], "flag": 1}
{"question": "Speeding up CNN training", "body": "<p>So I built a CNN without any scientific libraries like <a href=\"https://www.tensorflow.org/\" rel=\"nofollow noreferrer\">TensorFlow</a> or <a href=\"https://keras.io/\" rel=\"nofollow noreferrer\">Keras</a> (only <a href=\"http://www.numpy.org/\" rel=\"nofollow noreferrer\">NumPy</a>). It is taking a huge amount of time to train. What are some of the tricks and tips followed by people to speed up training of a CNN? (I am not talking about division of jobs into different processors but subtle redundant codes i.e. giving pre-calculated results which is not visible to common programmers).</p>\n", "pids": ["53e9ba54b7602d970466c10f"], "flag": 1}
{"question": "S-shaped nonlinearities in tanh neurons", "body": "<p>I have started reading <a href=\"https://books.google.com/books/about/Fundamentals_of_Deep_Learning.html?id=SL0BvgAACAAJ\" rel=\"nofollow noreferrer\">Fundamentals of Deep Learning by Nikhil Buduma</a> and I have a question regarding tanh neurons. In the book, it is stated:</p>\n\n<blockquote>\n  <p>\"When S-shaped nonlinearities are used, the tanh neuron is often preferred over the sigmoid neuron because it is zero-centered.\"</p>\n</blockquote>\n\n<p>Can anyone explain me why exactly??</p>\n", "pids": ["573696ce6e3b12023e5ce95a"], "flag": 1}
{"question": "How can AI be used to more reliably analyze and plan around the tie between climate and emissions?", "body": "<p><strong>Note to the Duplicate Police</strong></p>\n\n<p>This question is not a duplicate of the Q&amp;A thread referenced in the close request.  The only text even remotely related in that other thread is the brief mention of climate change in the Q and two sentences in the sole answer: \"Identify deforestation and the rate at which it's happening using computer vision and help in fighting back based on how critical the rate is. The World Resources Institute had entered into a partnership with Orbital Insight on this.\"</p>\n\n<p>If you look at the four bullet items below, you will find that this question asks a very specific thing about the relationship between climate and emissions.  Neither that question nor that answer overlaps with the content of this question in any meaningful way.  For instance, it is well known that CO<sup>2</sup> is NOT causing deforestation.  The additional carbon dioxide in the atmosphere causes faster regrowth.  This is because plants need CO<sup>2</sup> to grow.  Hydroponic containers deliberately boost it to improve growth rates.  Plants manufacture their own oxygen from the CO<sup>2</sup> via chlorophyll.</p>\n\n<p>If you recall from fifth grade biology, that's why they are plants.</p>\n\n\n\n<p><strong>Now Back to the Question</strong></p>\n\n<p>Several climate models have been proposed and used to model the relationship between human carbon emissions, added to the natural carbon emissions of life forms on earth, and features of climate that could damage the biosphere.</p>\n\n<p>Population growth and industrialization have many impacts on the biosphere, including loss of terrain and pollution. Negative oceanic effects, including unpredictable changes in plankton and cyanobacteria are under study.  Carbon emissions from combustion has received attention in recent decades just as sulfur emissions were central to concerns a century or more ago.</p>\n\n<p>Predicting weather and climate is certainly difficult because it is complex and chaotic, as typical inaccuracies in forecasts clearly demonstrate, but that is looking forward.  Looking backward, analyses of data already collected have shown a high probability that ocean and surface temperature rises followed increases in industrial and transportation related combustion of fuels.</p>\n\n<p>How might AI be used to produce some of the key models humans need to protect the biosphere from severe damage.</p>\n\n<ul>\n<li><p>A more reliable analysis of what has already occurred, since there is some legitimacy to the differing views as to how gross the effect of carbon emissions has been on extinctions of species in the biosphere and on arctic and antarctic melting</p></li>\n<li><p>A better understanding as to whether the climate of the biosphere behaves as a buffer of climate, always tending to re-balance after a volcanic eruption, meteor stroke, or other event, or whether the runaway scenario described by some climatologist, where there is a point of no return, is realistic</p></li>\n<li><p>A better model to use in trying out scenarios so that solutions can be applied in the order that makes sense from both environmental and economic perspectives</p></li>\n<li><p>Automation of climate planning so that the harmful effects of the irresponsibility of one geopolitical entity wishing to industrialize without constraint on other geopolitical entities can be mitigated</p></li>\n</ul>\n\n<p>Can pattern recognition, feature extraction, the learned functionality of deep networks, or generative techniques be used to accomplish these things?  Can rules of climate be learned?  Are there discrete or graph based tools that should be used?</p>\n", "pids": ["53e9a751b7602d970308a7f1"], "flag": 1}
{"question": "How do I change the annotations of variable-size images after having resized the images to a fixed size?", "body": "<p>In the data-sets like coco-text and total-text, the images are of different sizes (height*width). I'm using these data sets for text detection. I want to create a DNN model for this. So the input data should be of same size. If I resize these images to a fixed size, the annotations given in the data-set, that is the location of the text in the images, will be changed.</p>\n<p>So, how do I solve this problem?</p>\n", "pids": ["573695fe6e3b12023e5116f7"], "flag": 1}
{"question": "What is the physics engine used by DeepMimic?", "body": "<p>I found a <a href=\"https://youtu.be/vppFvq2quQ0\" rel=\"nofollow noreferrer\">video for the paper <em>DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills</em>\n</a> on YouTube.</p>\n\n<p>I looked in the related paper, but could not find details of how to the environment was created, such as the physics engine it used. I would like to use it, or something similar.</p>\n", "pids": ["5aed14d617c44a4438158bd0"], "flag": 1}
{"question": "Can addiction develop to the absence of a normally present negative stimulus?", "body": "<p>I am wondering, can someone become addicted to the absence or the removal of a negative stimulus? Normally, addiction is associated with pleasure-inducing drugs, like opiates and amphetamines as notorious examples. These compounds induce massive release of dopamine in the limbic system, ultimately leading to addiction. <a href=\"https://www.asam.org/resources/definition-of-addiction\" rel=\"nofollow noreferrer\">Addiction is a collection of behaviors</a>: </p>\n\n<blockquote>\n  <p>Addiction is characterized by <strong>inability to consistently abstain</strong>,\n  <strong>impairment in behavioral control</strong>, <strong>craving</strong>, <strong>diminished recognition of\n  significant problems with one’s behaviors and interpersonal\n  relationships</strong>, and a <strong>dysfunctional emotional response</strong>. Like other\n  chronic diseases, addiction often involves cycles of relapse and\n  remission.</p>\n</blockquote>\n\n<p>It is known that training can be assisted by positive reinforcement (well done! here's a candy), or by negative reinforcement (wrong! here's an electroshock). Can addiction be caused by either? In other words, suppose someone is constantly aware of something unpleasant (pain, itching, unwanted perceptions such as tinnitus (ringing in the ears), negative emotions or thoughts) <strong>can the removal/lessening of such a stimulus lead to an addiction of the means to remove it?</strong> </p>\n\n<p>For the sake of the question I think it is sufficient to focus the question on one (<em>e.g.</em>, <em>craving</em>), or several of the symptoms, as existing studies, if any, may have focused on only one or few of the symptoms of addiction.</p>\n\n<p>In short: <strong>are there studies on the addiction to the absence / removal of a negative stimulus</strong>?    </p>\n\n<p><sub>This question was fueled by the comments to <a href=\"https://psychology.stackexchange.com/questions/20736/is-there-a-region-of-the-brain-that-mediates-pain-a-la-mesolimbic-pathway\">an earlier question</a></sub> </p>\n", "pids": ["5c0f8fafda562944aca60071", "56d8e715dabfae2eee3820b1", "604c92a7ec47cda53216a546", "5c136559da56295a089cb7eb", "5c756ae8f56def979838956e"], "flag": 0}
{"question": "Compute Jacobian matrix of Deep learning model?", "body": "<p>I am trying to implement <a href=\"https://arxiv.org/abs/1511.07528\" rel=\"nofollow noreferrer\">this paper</a>. In this paper, the author uses the forward derivative to compute the Jacobian matrix <b>dF/dx</b> using chain rule where F is the probability got from the last layer and X is input image.\nMy model is given below. Kindly let me know how to go about doing that?</p>\n\n<pre><code>class LeNet5(nn.Module):\n\ndef __init__(self):\n\n    self.derivative= None # store derivative\n\n    super(LeNet5, self).__init__()\n    self.conv1= nn.Conv2d(1,6,5)\n    self.relu1= nn.ReLU()\n    self.maxpool1= nn.MaxPool2d(2,2)\n\n    self.conv2= nn.Conv2d(6,16,5)\n    self.relu2= nn.ReLU()\n    self.maxpool2= nn.MaxPool2d(2,2)\n\n    self.conv3= nn.Conv2d(16,120,5)\n    self.relu3= nn.ReLU()\n\n    self.fc1= nn.Linear(120,84)\n    self.relu4= nn.ReLU()\n\n    self.fc2= nn.Linear(84,10)\n    self.softmax= nn.Softmax(dim= -1)\n\n\ndef forward(self,img, forward_derivative= False):\n    output= self.conv1(img)\n    output= self.relu1(output)\n    output= self.maxpool1(output)\n\n    output= self.conv2(output)\n    output= self.relu2(output)\n    output= self.maxpool2(output)\n\n    output= self.conv3(output)\n    output= self.relu3(output)\n\n    output= output.view(-1,120)\n    output= self.fc1(output)\n    output= self.relu4(output)\n\n    output= self.fc2(output)\n    F= self.softmax(output)\n\n    # want to comput the jacobian dF/dimg \n    jacobian= computeJacobian(F,img)#how to write this function\n\n    return F, jacobian\n</code></pre>\n", "pids": ["573696076e3b12023e51a63f"], "flag": 1}
{"question": "CNN Pooling layers unhelpful when location important?", "body": "<p>I'm trying to use a CNN to analyse statistical images. These images are not 'natural' images (cats, dogs, etc) but images generated by visualising a dataset. The idea is that these datasets hopefully contain patterns in them that can be used as part of a classification problem.</p>\n\n<p><a href=\"https://i.stack.imgur.com/YGYUZ.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/YGYUZ.png\" alt=\"enter image description here\"></a></p>\n\n<p>Most CNN examples I've seen have one of more pooling layers, and the explaination I've seen for them is to reduce the number of training elements, but also to allow for some locational independance of an element (e.g. I know this is an eye, and can appear anywhere in the image).</p>\n\n<p>In my case location <em>is</em> important and I want my CNN to be aware of that. ie. the presence of a pattern at a specific location in the image means something very specific compared to if that feature or pattern appears elsewhere.</p>\n\n<p>At the moment my network looks like this (taken from an example somewhere):</p>\n\n<pre><code>_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 196, 178, 32)      896       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 196, 178, 32)      0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 98, 89, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 96, 87, 32)        9248      \n_________________________________________________________________\nactivation_2 (Activation)    (None, 96, 87, 32)        0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 48, 43, 32)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 46, 41, 64)        18496     \n_________________________________________________________________\nactivation_3 (Activation)    (None, 46, 41, 64)        0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 23, 20, 64)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 29440)             0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                942112    \n_________________________________________________________________\nactivation_4 (Activation)    (None, 32)                0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 32)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 3)                 99        \n_________________________________________________________________\nactivation_5 (Activation)    (None, 3)                 0         \n=================================================================\nTotal params: 970,851\nTrainable params: 970,851\nNon-trainable params: 0\n_________________________________________________________________\n</code></pre>\n\n<p>The 'images' I'm training on are 180 x 180 x 3 pixels and each channel contains a different set of raw data.</p>\n\n<p>What strategies are there to improve my CNN to deal with this? I have tried simply removing some of the pooling layers, but that greatly increased memory and training time and didn't seem to really help.</p>\n", "pids": ["5736960e6e3b12023e520c34"], "flag": 1}
{"question": "Why would giving my AI more data make it perform worse?", "body": "<p>So I trained an AI to generate shakespeare, which it did somewhat well. I used <a href=\"https://cs.stanford.edu/people/karpathy/char-rnn/shakespear.txt\" rel=\"nofollow noreferrer\">this 10,000 character sample</a>.</p>\n\n<p>Next I tried to get it to generate limericks using these <a href=\"http://oedilf.com/\" rel=\"nofollow noreferrer\">100,000 limericks</a>. It generated garbage output.</p>\n\n<p>When I limited it to 10,000 characters, it then started giving reasonable limerick output.</p>\n\n<p>How could this happen? I thought more data was always better.</p>\n\n<p>The AI was a neural network with some LSTM layers, implemented in keras.</p>\n", "pids": ["59ae3be32bbe271c4c71b7b4"], "flag": 1}
{"question": "Psychological explanation for exorcisms?", "body": "<p>I'm doing research on alleged testimonies and evidences of the spirit realm. In particular, I've been lately reviewing testimonies and live recordings of exorcisms, some of which I find particularly impressive. I say impressive because in my opinion the exorcisms look quite convincing, and I lack the expertise in psychology and neuroscience to provide a convincing explanation other than assuming that everything is staged (which I wouldn't be able to prove either).</p>\n<p>Common patterns are that the allegedly possessed person seems to switch personality (as though the alleged entity's personality is taking over), sometimes the exorcist and the alleged entity establish conversation, sometimes the person starts to &quot;throw up&quot; the alleged entity out of their body right before full deliverance is achieved.</p>\n<p>Here a few examples (timestamps included): <a href=\"https://youtu.be/I3paguHVtBE?t=1188\" rel=\"nofollow noreferrer\">example 1</a>, <a href=\"https://youtu.be/mAQevnUDU24\" rel=\"nofollow noreferrer\">example 2</a>, <a href=\"https://youtu.be/dtsxUcQO3v0\" rel=\"nofollow noreferrer\">example 3</a>, <a href=\"https://youtu.be/4rOYVuI6dXg\" rel=\"nofollow noreferrer\">example 4</a>, <a href=\"https://youtu.be/EteJtXUmqrE?t=202\" rel=\"nofollow noreferrer\">example 5</a>, <a href=\"https://youtu.be/Mkdaz6dVRO4?t=177\" rel=\"nofollow noreferrer\">example 6</a>, <a href=\"https://youtu.be/Ry0mU0flrJ4?t=215\" rel=\"nofollow noreferrer\">example 7</a>, <a href=\"https://youtu.be/zwKWT5ca0LE?t=1530\" rel=\"nofollow noreferrer\">example 8</a>, <a href=\"https://youtu.be/RXDX92mrGxU\" rel=\"nofollow noreferrer\">example 9</a>, <a href=\"https://v.youku.com/v_show/id_XMzA2Mjk0ODUzMg==.html\" rel=\"nofollow noreferrer\">example 10</a>, <a href=\"https://youtu.be/pIqPfZZOQsg?t=20\" rel=\"nofollow noreferrer\">example 11</a>, <a href=\"https://youtu.be/yKnxWl8500k?t=148\" rel=\"nofollow noreferrer\">example 12</a>.</p>\n<p>What is the psychological explanation for exorcisms?</p>\n<hr />\n<p>Possibly related questions:</p>\n<ul>\n<li><a href=\"https://psychology.stackexchange.com/q/3707/25376\">Is there a psychological explanation for people being &#39;overcome by the Holy Spirit&#39;?</a></li>\n<li><a href=\"https://psychology.stackexchange.com/q/25631/25376\">Is there a scientific explanation for dramatic body shaking and trembling in religious settings? (see videos for illustrative examples)</a></li>\n<li><a href=\"https://psychology.stackexchange.com/q/26179/25376\">Explanation for the &quot;spinal energy&quot; and other &quot;Kundalini awakening&quot; symptoms?</a></li>\n</ul>\n", "pids": ["55a51ea765ceb7cb02e17f7d", "5c7573c3f56def97988d256f", "55a66df9612ca6eebaafd51a", "5c75740ef56def97989051c3", "53e99ecab7602d9702794400"], "flag": 1}
{"question": "How to detect a Neural Network will work with the whole dataset?", "body": "<p>I want to implement a neural network on a big dataset. But training time is long (~1h30 per epoch). I'm still in the development process, so I don't want to wait such long time just to have poor results at the end.</p>\n\n<p><a href=\"https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607\" rel=\"nofollow noreferrer\">This</a> and <a href=\"https://www.reddit.com/r/MachineLearning/comments/5pidk2/d_is_overfitting_on_a_very_small_data_set_a/\" rel=\"nofollow noreferrer\">this</a> suggest that overfitting the network on a very small dataset (1 ~ 20 samples) and reach a loss near 0 is a good start.</p>\n\n<p>I did it and it works great. However, I am looking for the next step of validating my architecture. I tried to overfit my network over 100 samples, but I can't reach a loss near 0 in reasonable time.</p>\n\n<p>How can I ensure the results given by my NN will be good (or not), without having to train it on the whole dataset ?</p>\n", "pids": ["59ae3be32bbe271c4c71b7b4"], "flag": 1}
{"question": "What&#39;s the difference between poker with public cards and without them?", "body": "<p>Example: Texas Holdem poker vs Texas Holdem poker with the same rounds, just with no public cards dealt.</p>\n<p>Would algorithms, like CFR, approximate the Nash equilibrium more easily? Could AI that does not look at public cards achieve similar performance in normal Texas Holdem as AI that looks at public state tree?</p>\n", "pids": ["53e9a289b7602d9702b8cdeb"], "flag": 1}
{"question": "Are artificial intelligence learnings or trainings transferable from one agent to the other?", "body": "<p>One disadvantage or weakness of Artificial Intelligence today the slow nature of learning or training success. For instance, an AI agent might require a 100,000 samples or more to reach an appreciable level of performance with a specific task. But this is unlike humans who are able to learn very quickly with a minimum number of samples. Humans are also able to teach one another, or in other words, transfer knowledge acquired.</p>\n\n<p>My question is this: are Artificial Intelligence learnings or trainings transferable from one agent to the other? If yes, how? If no, why?</p>\n", "pids": ["5d9edb5b47c8f76646015f57"], "flag": 1}
{"question": "Image prediction model when data-set classes have visual similarity", "body": "<p>Lets say we have a data-set of all cats and we have to identify the cat breed based on given test image. As, the two different cat breeds have visual similarity can we use existing networks (VGG, ImageNet, GoogleNet) to solve this problem?</p>\n\n<ol>\n<li>Should faceNet be applied here? As, the problem is similar to face detection where face characteristics of two different people are same yet it can correctly recognize a person.</li>\n<li>What if with visual similarity in data-set we have only few example of each class? Like for a problem (random) we have good amount of data but for each class we have only few examples.</li>\n</ol>\n\n<p>Is there any model that can be applied here?</p>\n", "pids": ["573697846e3b12023e66ab35"], "flag": 1}
{"question": "Choosing Instance Semantic Detection", "body": "<p>A fixed video camera records people moving through its field of view.</p>\n\n<p>The goal is to <strong>detect</strong> and track the head, in real-time as it moves through the video.  The norm is there are many heads, which often are sometimes partially obscured.  This <a href=\"https://youtu.be/qDK6nLdm3sQ?t=45s\" rel=\"nofollow noreferrer\">example video boxes heads</a> and provides a head count.</p>\n\n<p>There seems to be many different models.  Examples include:   </p>\n\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=PRbr9-_xLzs\" rel=\"nofollow noreferrer\">Adaboost-haar Head detection</a> </li>\n<li><a href=\"https://www.zeolearn.com/magazine/instance-segmentation-using-deep-learning\" rel=\"nofollow noreferrer\">MASK R-CNN</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=tBwUbQ0pyUw\" rel=\"nofollow noreferrer\">LBP Cascade</a></li>\n</ul>\n\n<p>Given the context of the video, what is the thought process that you would use to choose a model?    </p>\n", "pids": ["5f156e7091e011d7db223b03", "5a260c8f17c44a4ba8a33bfa"], "flag": 1}
{"question": "How much time do academics in fact spend refereeing the research of others, on average?", "body": "<p><a href=\"https://academia.stackexchange.com/questions/121851/how-much-time-should-you-spend-on-reviewing-a-paper\">This</a> and similar questions ask how much time a researcher <em>should</em> devote to reviewing a paper, or to reviewing papers in general. But how much time do scientists spend refereeing papers <em>as a matter of fact</em>? </p>\n\n<p>I am specifically looking for answers based on empirical statistics with a large-enough n, be it within one or across several disciplines. I'm not so interested in anecdotes or educated guesses.</p>\n", "pids": ["5390b00c20f70186a0ed4dc1"], "flag": 1}
{"question": "Homoparental Adoption Studies", "body": "<p>Such as the <a href=\"https://www.wpath.org/\" rel=\"nofollow noreferrer\">World Professional Association for Transgender Health</a>, which involves a relative large group of professional for concluding about <em>Transgender</em> protocols and studies, and somehow unrelated but such as the <a href=\"http://www.nationalacademies.org/hmd/Reports.aspx\" rel=\"nofollow noreferrer\">National Academies of Sciences, Engineering and Medicine</a>, is there some neutral organization involving Systematic Reviews of studies concluding about the effects -rather positive and|or negative- about <em>Homoparental Adoption</em>?</p>\n\n<p>The most comprehensive reference I have found is a paper from <a href=\"https://lib.dr.iastate.edu/cgi/viewcontent.cgi?article=1053&amp;context=hdfs_pubs\" rel=\"nofollow noreferrer\">Schofield 2016</a> which summarizes 81 studies. But this paper is still a single person document, which perfectly could be subject to an author bias. </p>\n\n<p>Thanks in advance.</p>\n", "pids": ["53e9bc27b7602d97048937bc"], "flag": 0}
{"question": "How can I oppose two AI agents with keras / tensoflow?", "body": "<p>I am trying to use tensorflow / keras to play a text based game. The game opposes two players that play by answering questions by choosing an answer among the proposed ones.</p>\n\n<p>Game resembles this:</p>\n\n<ol>\n<li>Questions asked from player 1, choose value {0, 1, 2}<br/></li>\n<li>Player 1 chooses answer 1<br/></li>\n<li>Questions asked from player 2, choose value {0, 1}<br/></li>\n<li>Player 2 chooses answer 0<br/>\n( and so on )<br/></li>\n</ol>\n\n<p>The issue is that I do not have any data to use for training the agents and it not possible to evaluate each actions of the agent individually.<br /></p>\n\n<p>My idea is to get 2 agents to play against each other and evaluate them depending on who won / lost ( the games are very short with about 20 to 30 decisions made for each player ).</p>\n\n<p>The issue I have is that I do not know where to start. </p>\n\n<p>I normalized my input, but I do not know how to get the 2 agents to compete, as I do not have any training data as shown in the tutorials and the agents have to complete a full game in order to evaluate their performance.</p>\n", "pids": ["5db9295647c8f766461f4394"], "flag": 1}
{"question": "Is there a ReLU-like activation function that concatenates positive and negative values?", "body": "<p>Is there a ReLU-like activation function that concatenates positive and negative values? What is its name? Apparently, it doubles the output dimension.</p>\n", "pids": ["573696086e3b12023e51b25d"], "flag": 1}
{"question": "Is there a relationship between viewing and committing war crimes", "body": "<p>Recently, I’ve been curious if there’s any relationship between someone committing war crimes and previously viewing them.</p>\n<p>For example, the War in Afghanistan is considered asymmetrical warfare, where the enemy has no rule book in regards to international law, and the soldier has the international law as well as their own set of rules of engagements (RoE) to follow. As time goes on, many of their comrades are wounded or killed from seemingly preventable things if they didn’t have to follow a set of rules of engagement while the enemy were ignoring them (using children in wars, indiscriminate weapons, hiding in civilian crowds).</p>\n<p>Considering this then, is there a link between longer exposure to ‘dirty’ war fighting (not following international law) and the ability to carry out said rules of engagements without emotional compromise.</p>\n<p>It seems logical that as you witness warcrimes committed against yourself or the people around you, that the chances of you breaking your own RoE to have a (relatively) fair playing field against the enemy starts to increase. Particularly for soldiers in sustained combat.</p>\n<p>I don’t really have any research on this from what I’ve tried to find. I’m a mechanical engineer by trade so probably way out of my depth, so if there are good places to look for this kind of material, I’d be happy to have it sent to me. Any thoughts on this would be appreciated too!</p>\n", "pids": ["5c756ea1f56def97985eda53"], "flag": 1}
{"question": "Stereo matching using genetic algorithm", "body": "<p>I have been reading a few papers (<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S003132030000114X\" rel=\"nofollow noreferrer\">paper1</a>, <a href=\"https://arxiv.org/abs/1410.2474\" rel=\"nofollow noreferrer\">paper2</a>) on stereo matching using genetic algorithms. I understand how genetic algorithms work in general and how stereo matching works, but I do not understand how genetic algorithms are used in stereo matching. </p>\n\n<p>The first paper by Han et al says that \"1) individual is a disparity set, 2) a chromosome has a 2D structure for handling image signals efficiently, and 3) a fitness function is composed of certain constraints which are commonly used in stereo matching\".</p>\n\n<p>Does it mean that an individual is a disparity map with random numbers?\nThen a chromosome is a block within the individual's disparity map. \nThe constraint used for fitness function could be the famous epipolar line. </p>\n\n<p>I dont seem to understand how this works and even <em>WHY</em> you should use genetic algorithm on an algorithm that at its simplest form uses 5 for loops, for example, like in <a href=\"https://github.com/davechristian/Simple-SSD-Stereo/blob/master/stereomatch_SSD.py\" rel=\"nofollow noreferrer\">here</a>.</p>\n", "pids": ["557026072401b4b38c2397d0", "557026072401b4b38c2397d0"], "flag": 1}
{"question": "Personality at Birth", "body": "<p>What factors determine the personality of a newborn baby?</p>\n<p>Do all newborns exhibit identical behaviour?  If not, are genetics responsible for the differences?</p>\n<p>References consulted so far:</p>\n<ol>\n<li><p><a href=\"https://opentextbc.ca/introductiontopsychology/chapter/11-3-is-personality-more-nature-or-more-nurture-behavioral-and-molecular-genetics/#:%7E:text=on%20human%20behaviour.-,Behavioural%20genetics%20is%20based%20on%20the%20results%20of%20family%20studies,associated%20with%20which%20personality%20traits.\" rel=\"nofollow noreferrer\">Is Personality More Nature or More Nurture? Behavioural and Molecular Genetics</a></p>\n</li>\n<li><p><a href=\"https://www.verywellmind.com/are-personality-traits-caused-by-genes-or-environment-4120707\" rel=\"nofollow noreferrer\">Are Personality Traits Caused by Genes or Environment?</a></p>\n</li>\n<li><p><a href=\"https://www.psychologytoday.com/us/blog/under-the-influence/201307/do-genes-influence-personality\" rel=\"nofollow noreferrer\">Do Genes Influence Personality?</a></p>\n</li>\n</ol>\n", "pids": ["59a7758b0cf25762a5211b98", "599e3a7a0cf28d9fa5721a62", "55a6cb2665ce054aad75fee2", "5c35f2ecdf5b8c0b3c3ad84a", "5c8b11f84895d9cbc64a38f6", "5d1f23d43a55ac89851c1167", "53e9b983b7602d9704571d45", "53e9a439b7602d9702d58877"], "flag": 1}
{"question": "Choosing the right neural network settings", "body": "<p>I'm trying to train a neural network on evaluating chess positions if rather white (0.0) or black would win (1.0)</p>\n\n<p>Currently the input consists of 4 bits per chess field (piece id 0 - 12, equals 64*4). Factors like castling are being ignored for now. Also, all training sets are random positions from popular games where it's white's turn and the desired output is the outcome of the game (0.0, 0.5, 1.0).</p>\n\n<p>Are my input values the right choice?\nHow many hidden layers / neurons for each layer should be used and what's the best learning rate?\nWhat type of NN's and which activation function would you recommend for this project?</p>\n", "pids": ["573696026e3b12023e516627"], "flag": 1}
{"question": "Which neuron represents which part of the input?", "body": "<p>In a neural network, each neuron represents some part of the input. For example, in the case of a MNIST digit, consider the stem of the number 9. Each neuron in the NN represents some part of this digit.</p>\n\n<ol>\n<li><p>What determines which neuron will represent which part of the digit?</p></li>\n<li><p>Is it possible that if we pass in the same input multiple times, each neuron can represent different parts of the digit?</p></li>\n<li><p>How is this related to the back-propagation algorithm and chain rule? Is it the case that, before training the neural network, each neuron doesn't really represent anything of the input, and, as training proceeds, neurons start to represent some part of the input?</p></li>\n</ol>\n", "pids": ["53e9b40eb7602d9703f04187"], "flag": 1}
{"question": "Does fp32 &amp; fp64 performance of GPU affect deep learning model training?", "body": "<p>I am purchasing Titan RTX GPU. Everything seems fine with that except float32 &amp; float64 performance which seems lower vis-a-vis some of its counter parts. I wanted to understand if single precision and double precision performance of GPU affect deep learning training or efficiency ? We work mostly with images, however not limited to that.</p>\n", "pids": ["5a260c8417c44a4ba8a314e3"], "flag": 1}
{"question": "What&#39;s the difference between the neuroendocrine system vs endocrine system?", "body": "<p>No one in the Biology site seems to be answering this, so I thought I'd post it here as a last resort. I would really appreciate if you guys can take a look at it.</p>\n\n<p>This is what I have understood so far: \nNeuroendocrine system involves <strong>neuroendocrine cells</strong> (also known as neurosecretory cells) that receive nerve impulses by a <strong>sensory neuron</strong> to release <strong>neurohormones</strong> into the blood stream. Meanwhile, the endocrine system <strong>endocrine cells</strong> that release your 'classic' <strong>hormones</strong> into the blood stream when a <strong>receptor protein</strong> senses a stimulus.</p>\n\n<p>Here are my questions. You don't have to answer them in order, you can just provide an summary explanation:</p>\n\n<ol>\n<li><p>When it comes to the brain, are the neurosecretory cells located in\nthe hypothalamus or the posterior pituitary gland or both?</p></li>\n<li><p>Is the hypothalamus and the posterior pituitary gland classified as\n    neuroendocrine glands and is the anterior pituitary classified as an\n    endocrine gland?</p></li>\n<li><p>If the posterior pituitary gland is indeed a neuroendocrine gland,\n    is ADH and Oxytocin, which are both released by the posterior\n    pituitary gland, classified as \"neurohormones\", not just the classic\n    hormones?</p></li>\n</ol>\n", "pids": ["6312fa4b90e50fcafdc64ee9", "5de0c4b2df1a9c0c415a4ecf", "6051d704ec47cda5321a4c40"], "flag": 0}
{"question": "The differences between sensory distortions and hallucinations", "body": "<p>So, the way I've understood it, &quot;sensory disturbances&quot; can be categorized as follows:</p>\n<p><a href=\"https://i.stack.imgur.com/UcUXJ.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/UcUXJ.png\" alt=\"enter image description here\" /></a></p>\n<p>Any sensory experience that isn't real goes under &quot;sensory disturbances&quot; in this diagram. If this unreal sensory experience is a distortion or misunderstanding of real, external stimuli, then it falls under &quot;<a href=\"https://en.wikipedia.org/wiki/Illusion\" rel=\"nofollow noreferrer\">illusions</a>&quot;. If the unreal sensory experience is generated in the absence of external stimuli, it is a <a href=\"https://en.wikipedia.org/wiki/Hallucination\" rel=\"nofollow noreferrer\">hallucination</a>. If the person having the hallucination believes in it, it is a true hallucination. If not, then it is just a hallucination.</p>\n<p>So, if a person perceives an object to be a different color, whether it is due to an altered state of consciousness, or if it is due confusing circumstances, is this an illusion or a hallucination? The object is real, it does have a color (which in a sense isn't real and potentially experienced differently by different people), and the person sees the color differently than what they normally would. Is this external stimuli being distorted/misinterpreted, or is it a hallucination being superimposed upon or merged with an external piece of stimuli. What if the subject doesn't see a different color, but rather a different shade of the same color?</p>\n<p>If a taste is changed from e.g. sweet to salty is it an illusion or a hallucination? If an object is perceived to move when it is not moving, is it an illusion or a hallucination.</p>\n<p>At the heart of these questions really is the question: does in the absence of external stimuli necessitate that the hallucination not involve external stimuli, or not depend on it? If the object is falsely perceived to be moving, it involves it (and in a sense depends on it too), however, it isn't the nature of the object that causes the sensory disturbance, but rather an internally created disturbance (the perception of motion) instilled into the object. But since that percept of motion, although originating from within, modified an external stimuli in order to give the final experience, is that experience then an illusion due to it coming in the form of distorted, external stimuli?</p>\n<p>Basically, I'm wondering about the nuanced border between illusions and hallucinations, if there even is one. If there isn't one, and there's a large grey area between them, then how does one differentiate between the two different categories proposed for the class of drugs that are hallucinogens? The broadest definition includes all drugs that sensory disturbances, and the most narrow definition is limited to those that produce hallucinations. How can that discussion be had in the event that there is a large gray area between illusions and hallucinations?</p>\n", "pids": ["5ecce9ae9fced0a24bdbc33f"], "flag": 1}
{"question": "How can we estimate the transition model and reward function?", "body": "<p>In reinforcement learning (RL), there are model-based and model-free algorithms. In short, model-based algorithms use a transition model <span class=\"math-container\">$p(s' \\mid s, a)$</span> and the reward function <span class=\"math-container\">$r(s, a)$</span>, even though they do not necessarily compute (or estimate) them. On the other hand, model-free algorithms do not use such a transition model or reward function, but they directly estimate a value function or policy by interacting with the environment, which allows the agent to infer the dynamics of the environment.</p>\n<p>Given that model-based RL algorithms do not necessarily estimate or compute the transition model or reward function, in the case these are unknown, how can they be computed or estimated (so that they can be used by the model-based algorithms)? In general, what are examples of algorithms that can be used to estimate the transition model and reward function of the environment (represented as either an MDP, POMDP, etc.)?</p>\n", "pids": ["5bdc315817c44a1f58a06342", "5d06e48dda562926acc50a38", "5a260c8417c44a4ba8a31c29"], "flag": 1}
{"question": "How to make machine learning model that reports ambiguity of the input?", "body": "<p>Suppose I want to build a neural network regression model that takes one input and return one output.</p>\n\n<p>Here's the training data:</p>\n\n<pre><code>0.1 =&gt; 0.1\n0.2 =&gt; 0.2\n0.1 =&gt; -0.1\n</code></pre>\n\n<p>You will see that there are 2 inputs <code>0.1</code> that matches to different output values <code>0.1</code> and <code>-0.1</code>. So what will happen with most machine learning models is that they will predict the average when <code>0.1</code> is fed to the model. E.g. the output of <code>0.1</code> will be <code>(0.1 + (-0.1))/2 = 0</code>.</p>\n\n<p>But this <code>0</code> as an average answer is an incorrect answer. I want the model to be telling me that the input is ambiguous/insufficient to infer the output. Ideally, the model would report it as a form of confidence.</p>\n\n<p><strong>How do I report predictability confidence from the input?</strong></p>\n\n<p>The application that I find very useful in many areas is that I could then later ask the model to show me inputs that are easy to predict and inputs that are ambiguous. This would make me able to collect the data that are making sense.</p>\n\n<p>One way I know is to train the model then check the error on each training data, if it's high then it probably means that the input is ambiguous. But if you know any other papers or better techniques, I would be appreciated to know that!</p>\n", "pids": ["573696006e3b12023e513cb6"], "flag": 1}
{"question": "Long term cocaine use and personality change - Scientific references?", "body": "<p>I've experienced cocaine addicts first hand and noticed the development of egoistic personality traits such as selfishness or loss of empathy in cocaine addicts. Are there any scientific references which support that observation? </p>\n", "pids": ["55a5521c65ceb7cb02e8158f"], "flag": 0}
{"question": "How do psychologists measure malicious behaviour?", "body": "<p>How do psychologists measure malicious behaviour in humans? Is there a definitive definition of what constitutes malicious behaviour? Are there varying scales of malicious behaviour? Is it possible do conduct experiments where malicious behaviour can be reliably observed? E.g. is cheating in a competition against other humans considered malicious? If malicious behaviour is much further along the spectrum than this example, then how can you conduct such an experiment that remains ethical?</p>\n", "pids": ["55a5f79a65cead59c8319fc2", "5aa125dd684d788abcdabc66"], "flag": 0}
{"question": "What kind of political views are sociopaths more likely to espouse?", "body": "<p>I know of the pretty controversial links between <a href=\"http://oxfordre.com/politics/view/10.1093/acrefore/9780190228637.001.0001/acrefore-9780190228637-e-221\" rel=\"nofollow noreferrer\">personality and political orientation</a>, in general terms, e.g.</p>\n\n<blockquote>\n  <p>Although most research examining whether openness and conscientiousness influence political ideology has appeared only within the last decade, support for the expected openness-liberalism and conscientiousness-conservatism links already is voluminous.</p>\n</blockquote>\n\n<p>I'm curious if studies have looked at the finer correlations of abnormal psychology and political orientation. Do the extremes of personality lead people to more extreme political orientation of some sort? For instance, does sociopathy predispose to extreme left- or right-wing movements?</p>\n", "pids": ["5ce2d0b4ced107d4c63aa267"], "flag": 0}
{"question": "Symptoms of increase leptin receptor", "body": "<p>A genetic mutation that increases leptin receptor number. Does that lead to increase appetite or weight gain?</p>\n<p>I found online that a decrease in the leptin receptor number <a href=\"https://medlineplus.gov/genetics/condition/congenital-leptin-deficiency/\" rel=\"nofollow noreferrer\">could produce a feeling of fullness</a>. So it's reasonable to assume that the increase would lead to an increase in appetite and weight gain. But I am not sure of it.</p>\n<blockquote>\n<p>Congenital leptin deficiency is a condition that causes severe obesity beginning in the first few months of life. Affected individuals are of normal weight at birth, but they are constantly hungry and quickly gain weight. Without treatment, the extreme hunger continues and leads to chronic excessive eating (hyperphagia) and obesity.</p>\n</blockquote>\n", "pids": ["5c756c8ff56def979849cfe7", "5e09a92bdf1a9c0c4169ded8"], "flag": 1}
{"question": "Can AI come up with scientific theories of past when provided with sufficient data available at that time?", "body": "<p>I would love to know if an AI model could come up with certain theories of the old like Pythagoras' theorem, Euclid's formulations,\nNewton's gravity, Einstein's theories if provided and trained with sufficient amount of observable data available at those period of time. If this is possible can unsolved conjectures be proved by AI? Or even better can AI develop new theories or will it  fail to come up with even basic mathematical operations by itself?</p>\n", "pids": ["5bdc31c217c44a1f58a0cd40", "5e2c1672df1a9c0c41e839ac"], "flag": 1}
{"question": "What are examples of applications of the Fourier transform to AI?", "body": "<p>The (discrete and continuous) Fourier transform (FT) is used in signal processing in order to convert a signal (or function) in a certain domain (e.g. the time domain) to another domain (e.g., frequency domain). There are several resources on the web that attempt to explain the FT at different levels of complexity. See e.g. <a href=\"https://math.stackexchange.com/a/11114/168764\">this answer</a> or <a href=\"https://www.youtube.com/watch?v=mkGsMWi_j4Q\" rel=\"nofollow noreferrer\">this</a> and <a href=\"https://www.youtube.com/watch?v=spUNpyF58BY\" rel=\"nofollow noreferrer\">this</a> Youtube videos.</p>\n\n<p>What are examples of (real-world) applications of the Fourier transform to AI? I am looking for answers that explain the reason behind the use of the FT in the given application. I suppose that there are several applications of the FT to e.g. ML (data analysis) and robotics. I am looking for specific examples.</p>\n", "pids": ["5f8eb5b391e01153024c4c8d", "5f8eb5b391e01153024c4c8d"], "flag": 1}
{"question": "Why don&#39;t we decorrelate transitions for policy-based data?", "body": "<p>I'm implementing PPO myself strictly follow the steps:</p>\n\n<ol>\n<li>sample transitions</li>\n<li>randomly shuffle the sampled transitions</li>\n<li>compute gradients and update networks using the sampled transitions</li>\n<li>drop transitions and repeat the above steps </li>\n</ol>\n\n<p>I observe a strange phenomenon that randomly shuffling transitions makes the algorithm perform significantly worse than keeping it as it is. This is very strange to me. To my best understanding, neural networks perform badly when the input data are correlated. To decorrelate transitions, algorithms like DQN introduce replay buffer and randomly sample from it. But this seems not the same story to policy-based methods. I'm wondering why policy-based methods do not require to decorrelate the input data?</p>\n", "pids": ["59ae3bf12bbe271c4c71bc64"], "flag": 1}
{"question": "Correlation between anxiety disorders and PTSD", "body": "<p>The <a href=\"http://dx.doi.org/10.1126/science.aap8757\" rel=\"nofollow noreferrer\">mega study</a> on the genetic correlations of psychiatric (and neurological) disorders published in Science this summer has one interesting non-correlation: between anxiety disorders and PTSD.</p>\n\n<p><a href=\"https://i.stack.imgur.com/MhLpH.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/MhLpH.png\" alt=\"enter image description here\"></a></p>\n\n<p>Are the two (anxiety disorders and PTSD) correlated epidemiologically though? If so, is there a good explanation for the lack of genetic correlation? </p>\n", "pids": ["53e99991b7602d97021d7477", "5c756c5ef56def979847f385", "55a3c34e65ce5cd7b3b63644", "55a64be165ce054aad637383", "53e99e71b7602d9702733896", "55a4e771612c6b12aafda9d7"], "flag": 0}
{"question": "IQN bellman target: using Z vs using Q", "body": "<p>IQN paper (<a href=\"https://arxiv.org/abs/1806.06923\" rel=\"nofollow noreferrer\">https://arxiv.org/abs/1806.06923</a>) uses distributional bellman target:\n<span class=\"math-container\">$$ \\delta^{\\tau,\\tau'}_t = r_t + \\gamma Z_{\\tau'}(x_{t+1}, \\pi_{\\beta}(x_{t+1})) - Z_{\\tau}(x_t, a_t) $$</span>\nAnd optimizes: \n<span class=\"math-container\">$$ L = \\frac{1}{N'} \\sum^{N}_i \\sum^{N'}_j \\rho^\\kappa_{\\tau_i} \\delta^{\\tau_i,\\tau_j}_t $$</span></p>\n\n<p>But similar quantiles can be got just from Q values, when doing so:\n<span class=\"math-container\">$$ \\delta^\\tau_t = r_t + \\gamma \\frac{1}{N'} \\sum_{j}^{N'} Z_{\\tau_j}(x_{t+1}, \\pi_{\\beta}(x_{t+1})) - Z_\\tau(x_t, a_t) \\\\ = r_t + \\gamma Q (x_{t+1}, \\pi_\\beta(x_{t+1})) - Z_\\tau(x_t, a_t) $$</span>\noptimizing:\n<span class=\"math-container\">$$ L = \\sum^N_i \\rho^{\\kappa}_{\\tau_i} \\delta^{\\tau_i}_t $$</span></p>\n\n<p>Both lead to similar performance on CartPole env. The loss function of the 2nd one is more simpler and intuitive (atleast to me). So i was thinking if there are any obvious reason why authors didin't use it?</p>\n", "pids": ["599c7b58601a182cd272b540"], "flag": 1}
{"question": "Is sign language handled differently by the brain than spoken laguage?", "body": "<p>The human's ability to process language in the abstract is somewhat linked to our ability to both produce and understand sounds (see Broca's area), with that in mind, is Sign Language handled similarly by the brain? Is there any fMRI research that could corroborate that?</p>\n", "pids": ["56d82741dabfae2eeee509c7"], "flag": 0}
{"question": "What are the various methods for speeding up neural network for inference?", "body": "<p>One way to speed up a neural network is to prune the network and reducing number of neurons in each layer. What are the other methods to speed up inference?</p>\n", "pids": ["573696ce6e3b12023e5ceb2d"], "flag": 1}
{"question": "What is this type of graph called?", "body": "<p>It is common to represent various attributes on a pair of axes as in the examples below. In general, what is this sort of graph called?</p>\n\n<p>It is, perhaps, useful to think in these terms and we can recognise the resulting types/points. Examples of the such graphs are included below (Control vs Warmth of Parenting, belief vs knowledge in Religion, morals vs ethics or social vs economics) to produce different graphs.</p>\n\n<p><a href=\"https://i.stack.imgur.com/ZPDVK.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/ZPDVK.jpg\" alt=\"Parenting Styles\"></a>\n<a href=\"https://i.stack.imgur.com/ReChg.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/ReChg.png\" alt=\"Political Compass\"></a>\n<a href=\"https://i.stack.imgur.com/ER4vZ.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/ER4vZ.png\" alt=\"Belief vs Knowledge\"></a>\n<a href=\"https://i.stack.imgur.com/mR7Gv.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/mR7Gv.png\" alt=\"Ethics vs Morals\"></a></p>\n", "pids": ["5645ee790cf23363c3b4023b"], "flag": 0}
{"question": "Which algorithm should I use to map an input sentence to an output sentence?", "body": "<p>I am new to NLP realm. If you have an input text \"The price of orange has increased\" and output text \"Increase the production of orange\". Can we make our RNN model to predict the output text? Or what algorithm should I use?</p>\n", "pids": ["5bdc31b417c44a1f58a0b8c2"], "flag": 1}
{"question": "Psychometric scales of gender", "body": "<p>I have never read any study that has used a psychometric scale to find out the respondent's gender identity, sexual orientation or both. This makes me wonder if there are such scales or not, or if there can be such scales or not.</p>\n<p>I am more interested in scales for gender identity, for a study I am currently doing.</p>\n<p>I am not looking for qualitative studies. I would like to know if there are quantitative studies using Psychometrics that have tried to develop scales for gender identity, like we have ones for IQ, Big 5 personality, Political Conservatism etc. using factor analysis for example, or some other appropriate psychometric method? Is there any consensus on which approach/ scale is better, or is there any widely used scale? By approach I mean agreement on the main ideas behind a scale, for example there are many scales/ tests for Big 5 using different questions, but it is widely accepted that there are 5 dimensions. Anything like that for gender identity.</p>\n", "pids": ["55a3855c2401aa93797b6e39", "58d108460cf22173abb92e50"], "flag": 1}
{"question": "If I use MobileNetV2 for the encoder, can I use a different architecture for the decoder?", "body": "<p>I have way more unlabeled data than labeled data. Therefore I would like to train an autoencoder using MobileNetV2 as the encoder. Then I will use the pre-trained model for the classification of the labeled data.</p>\n<p>I think it is rather difficult to &quot;invert&quot; the MobileNet architecture to create a decoder. Therefore, my question is: can I use a different architecture for the decoder, or will this introduce weird artefacts?</p>\n", "pids": ["573698016e3b12023e6da477"], "flag": 1}
{"question": "Why is an expectation used instead of simple sum in GANs?", "body": "<p>Why do the GAN's loss functions use an expectation (sum + division) instead of a simple sum?</p>\n", "pids": ["5e3a928fdf1a9c0c41ebe39e"], "flag": 1}
{"question": "What is the most accurate name for the effect where people find excuses for flaws by leaders?", "body": "<p>A lot of the time, especially in political behaviour, people are likely to ignore the flaws of a leader or in some cases to somehow spin some bizarre positive angle.</p>\n\n<p>For example, corruption of public finance being spun as \"it is good because it shows how entrepreneurial the person is\". </p>\n\n<p>Even if not to that extent, this is an effect that is seen a lot, a strange kind of defence. </p>\n\n<p>While many terms come to mind, rose tinted glasses, excusing, shifting the burden, none of these exactly describe the psychological phenomenon here.</p>\n\n<p>What is the phenomenon called? </p>\n", "pids": ["53e9ab00b7602d9703481d29"], "flag": 0}
{"question": "Clear definition of ego", "body": "<p>Is there a clear definition of the ego which is accepted by the neuroscientific community?</p>\n\n<p>I have seen a previous post (<a href=\"https://psychology.stackexchange.com/questions/3966/what-do-id-ego-and-super-ego-exactly-mean?r=SearchResults\">What do id, ego and super-ego exactly mean?</a>) but this definition is for the Freudian concept of the ego. In neuroscience, the concept of ‘ego depletion’ is used (Baumeister) - but this has a different connotation.</p>\n", "pids": ["55a5e81a65cead59c82f1471"], "flag": 0}
{"question": "Why is deltaE not used as a measure of error?", "body": "<p>I've recently read a few articles pertaining to visual memory. Most of them (e.g. <a href=\"https://doi.org/10.1167/9.10.7\" rel=\"nofollow noreferrer\">Bays <em>et al</em>., 2009</a> use the continuous color recall task where they ask participants to recall the color of an object by clicking on a color wheel. They use as measure of error the angular distance between the participant's response and the actual angle on the color wheel of the object's color.</p>\n<p>Why use this dependent variable? In the industry, people use deltaE to determine the color difference between a product and a prototype.</p>\n<p>Wouldn't it make more sense to also use deltaE as dependent variable in psychology? From what I've read, deltaE tries to be accurate for human color perception.</p>\n", "pids": ["5c8f65e94895d9cbc6453e9c"], "flag": 0}
{"question": "Convolutional Neural Networks for different-sized Source and Target", "body": "<p>CNNs are often used in one of the following scenarios:</p>\n\n<ol>\n<li>A known-sized image is encoded to an intermediate format for later use</li>\n<li>An intermediate or precursor format is decoded into a known-sized image</li>\n<li>An image is converted into a same-size image</li>\n</ol>\n\n<p>(Usually 3 is done by sticking together 1 and 2.)</p>\n\n<p>Are there any papers dealing with convolutional techniques where the image sizes vary?  Not only would the size of input X differ from input Y, but also input X may differ from output Y. The total amount of variation can probably be constrained by the statistics of the dataset, but knowledge of input X does not grant <em>a priori</em> knowledge of the size of output Y</p>\n\n<p>(Masking is an obvious solution, but I am hoping for something more elegant if research already exists.  The problem domain need not be images.) </p>\n", "pids": ["5c610964da56297340b75034"], "flag": 1}
{"question": "Could a failure of condensed inner speech be linked to slowed cognition?", "body": "<p>Could a failure of \"condensed inner speech\" be linked to slowed cognition? It is a type of inner voice, and as conceptualized by Fernyhough it</p>\n\n<blockquote>\n  <p>involves the capacity to think in terms of pure meaning without the\n  need to put thoughts into words in order to grasp the meaning of the\n  thought.</p>\n</blockquote>\n\n<p>I'm just wondering whether, either in healthy or psychopathological cognition, condensed inner speech has been shown to be more difficult when thinking is slowed for some reason, such as psychotropic medication. I have read that people tend to use expanded (as opposed to condensed) inner speech when under <em>stress</em>.</p>\n", "pids": ["56d91bfadabfae2eee7fe447"], "flag": 0}
{"question": "Can stress situations force people to smile?", "body": "<p>I've seen many times in my life how people occasionally smile when trying to remain calm under huge stress regarding natural disasters, deaths, big losses, etc. It happened to me also.<br />\nEverything I find about it is just tips on how to <code>make yourself happy by forcing a smile</code>, but I doubt people was smiling intentionally - it was coming out naturally.<br />\nWas there any research on it? Is it a thing?</p>\n", "pids": ["53e9bc01b7602d9704862155", "53e99dbfb7602d9702681a38", "56d8ddd4dabfae2eeefe8da1"], "flag": 1}
{"question": "Can meditation be associated to lucid dream?", "body": "<p>The principal reason of this question is that I know people that can willingly enter in lucid dream (and so do what they want in it, and wake up when they want). Some of then use EEG (not professionnal one, ZEO sleep manager or Olimex) and they lucid are on NREM2 or REM.<br />\nSo it's still sleep (the brain waves length are said to be sleep). But they can basically fall asleep and start lucid dream.</p>\n<p>Important point to mention: those people are doing polyphasics sleep, hence the capacity to fall asleep for a nap really easily. But because of this they don't try to sleep outside their schedules.</p>\n<p>However, the thing is that they relax and then fall asleep in a lucid state.</p>\n<p>Meditation can be observed in theta wavelength (<a href=\"http://www.researchingmeditation.org/meditation-research-summary/brain-waves\" rel=\"nofollow noreferrer\">Manocha, n.d.</a>; <a href=\"https://www.innoacademy.org/sites/default/files/media/posts/documents/NEUROSCI.pdf\" rel=\"nofollow noreferrer\">Aftanas &amp; Golocheikine, 2001</a>) (referenced by <a href=\"https://en.wikipedia.org/wiki/Theta_wave#Meditation\" rel=\"nofollow noreferrer\">Wikipedia</a>). But it's mindless meditation.</p>\n<p>Also <a href=\"https://psychology.stackexchange.com/questions/15335/is-mindfulness-meditation-an-effective-method-to-fall-asleep\">this question</a> refer meditation as a good method to fall asleep.</p>\n<p>If you simplify it (a lot) meditation and lucid dream can have a lot of common points.</p>\n<p>But is there any known relatio between the two? Is it possible to fall in lucid dream by meditating?</p>\n<h2>References</h2>\n<p>Aftanas, L. I., &amp; Golocheikine, S. A. (2001). Human anterior and frontal midline theta and lower alpha reflect emotionally positive state and internalized attention: high-resolution EEG investigation of meditation. Neuroscience letters, 310(1), 57-60. doi: <a href=\"https://doi.org/10.1016/S0304-3940(01)02094-8\" rel=\"nofollow noreferrer\">10.1016/S0304-3940(01)02094-8</a></p>\n<p>Manocha, R. (n.d.). <em>Research Summary: Brain Waves</em>. Retrieved from: <a href=\"http://www.researchingmeditation.org/meditation-research-summary/brain-waves\" rel=\"nofollow noreferrer\">http://www.researchingmeditation.org/meditation-research-summary/brain-waves</a></p>\n", "pids": ["56d84060dabfae2eee838333"], "flag": 0}
{"question": "Is there a mental health disorder related to a harmful lack of anxiety and stress?", "body": "<p>Ataraxia is the freedom from distress or worry in ancient Greek philosophy.  However, emotions play a vital role in motivation and decision making.  Many disorders relate to having excessive emotional reactions or inappropriate triggers for them.  There are also a few concerning a lack of or dulled emotional responses.  While high levels of stress and anxiety are seen as harmful, the same concern is rarely shown for the opposite end of the spectrum.  </p>\n\n<p>I have been unable to find any information about disorders related to dulled or absent anxiety or stress reactions.  I assume this is due to the lower perceived harm, or conflation with depression disorders, but I find it hard to believe no one has done any work in this area. Clinical apathy is not what I'm looking for, since that seems to be typified by acute lack of response or interest in immediate stimulus or short time spans.</p>\n", "pids": ["53e9bc00b7602d970485d412", "53e9990db7602d970214b9df", "55a52933c91bf3b1cc505ffc"], "flag": 0}
{"question": "What is the difference between multi-agent and multi-modal systems?", "body": "<p>The Wikipedia definitions are as follows</p>\n\n<p><strong>Multi-agent systems</strong> - <em>A multi-agent system is a computerized system composed of multiple interacting intelligent agents.</em></p>\n\n<p><strong>Multi-modal interaction</strong> - <em>Multimodal interaction provides the user with multiple modes of interacting with a system.</em></p>\n\n<p>Doesn't providing a user with multiple modes of interacting with a system, assuming all modalities interact with each other to give final output (some sort of fusion mechanism for example), make it a multi-agent system? </p>\n\n<p>If not, what is the difference between multi-modal and multi-agent systems and, monolithic and uni-modal systems?</p>\n", "pids": ["5db92d6247c8f76646261f25"], "flag": 1}
{"question": "What are examples of books or papers on the details of convolutional neural networks?", "body": "<p>I'm studying a master's degree and my final work is going to be about the convolutional neural network.</p>\n\n<p>I read a lot of books and I did Convolutional Network Standford's course, but I need more.</p>\n\n<p>Are there books or papers on the details of convolutional neural networks (in particular, convolutional layer)? </p>\n", "pids": ["573696026e3b12023e515eec"], "flag": 1}
{"question": "Are there any good ways of simultaneously incorporating object detection with speech recognition?", "body": "<p>Are there any good ways of simultaneously incorporating object detection with speech recognition? For example, if you want to identify whether an animal is a dog or cat, we can obviously use visual features (e.g. YOLO, CNNs, etc.). But how would you incorporate speech and sound in this model?</p>\n", "pids": ["58d82fd2d649053542fd795a"], "flag": 1}
{"question": "In Faster R-CNN, how can I get the predicted bounding box given the neural network&#39;s output?", "body": "<p>The <a href=\"https://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf\" rel=\"nofollow noreferrer\">RPN</a> loss in <a href=\"https://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf\" rel=\"nofollow noreferrer\">Faster RCNN</a> paper is</p>\n<p><span class=\"math-container\">$$\nL({p_i}, {t_i}) = \\frac{1}{N_{cls}} \\sum_{i} L_{cls}(p_i,p_i^*) + \\lambda \\frac{1}{N_{reg}} \\sum_i p_i^* L_{reg}(t_i, t_i^*)\n$$</span></p>\n<p>For regression problems, we have the following parametrization</p>\n<p><span class=\"math-container\">$$t_x=\\frac{x - x_a}{w_a}, \\\\ t_y=\\frac{y−y_a}{h_a}, \\\\ t_w= \\log \\left( \\frac{w}{w_a} \\right),\\\\ t_h= \\log \\left(\\frac{h}{h_a} \\right)$$</span></p>\n<p>and the ground-truth labels are</p>\n<p><span class=\"math-container\">$$t_x^*=\\frac{x^* - x_a}{w_a},\\\\ t_y^*=\\frac{y^*−y_a}{h_a}, \\\\ t_w^*= \\log \\left( \\frac{w^*}{w_a} \\right), \\\\ t_h^*= \\log \\left(\\frac{h^*}{h_a} \\right)$$</span></p>\n<p>where</p>\n<ul>\n<li><p><span class=\"math-container\">$x$</span> and <span class=\"math-container\">$y$</span> are the two coordinates of the center, <span class=\"math-container\">$w$</span> the width, and <span class=\"math-container\">$h$</span> the height of the <em>predicted box</em>.</p>\n</li>\n<li><p><span class=\"math-container\">$x$</span> and <span class=\"math-container\">$y$</span> are the two coordinates of the center, <span class=\"math-container\">$w$</span> the width, and <span class=\"math-container\">$h$</span> the height of the <em>anchor box</em>.</p>\n</li>\n<li><p><span class=\"math-container\">$L_{reg}(t_i, t_i^*) = R(t_i − t_i^*)$</span>, where <span class=\"math-container\">$R$</span> is a robust loss function (smooth <span class=\"math-container\">$L_1$</span>)</p>\n</li>\n</ul>\n<p>These equations are unclear to me, so here are my two questions.</p>\n<ol>\n<li><p>How can I get the predicted bounding box given the neural network's output?</p>\n</li>\n<li><p>What exactly is the smooth <span class=\"math-container\">$L_1$</span> here? How is it defined?</p>\n</li>\n</ol>\n", "pids": ["5736986b6e3b12023e730129"], "flag": 1}
{"question": "structure of neural network for classification problems with large amounts of null classifications", "body": "<p>I am building a Convolution neural network to predict certain categories based on images (the location of a pointer on a surface) . However in many cases there will be no pointer in the view or something that is not the pointer. Initially I was just going to train it with outputs of the different classifications including the null classification. However given that the null classification is far more common than the others (perhaps 1000 times more likely) would it be better to have a separate null classifier and then if this outputted non null then the second classifier would be used.</p>\n\n<p>Any suggestions?</p>\n", "pids": ["599c7978601a182cd264164c", "5550417d45ce0a409eb3bc08"], "flag": 1}
{"question": "Does the performance of a model increase if dropout is disabled at evaluation time?", "body": "<p>I know dropout layers are used in neural networks during training to provide a form of regularisation in an attempt to mitigate over-fitting.</p>\n\n<p>Would you not get an increased fitness if you disabled the dropout layers during evaluation of a network?</p>\n", "pids": ["5a4aef9e17c44a2190f7a34c", "573696006e3b12023e513cb6"], "flag": 1}
{"question": "In Fast R-CNN, how are input RoIs mapped to the respective RoIs in the feature map before RoI pooling?", "body": "<p>I've been reading the <a href=\"https://arxiv.org/pdf/1504.08083.pdf\" rel=\"nofollow noreferrer\">Fast R-CNN paper</a>.</p>\n<p><strong>My understanding is</strong> that the input to one forward pass is the whole input image plus a list of RoIs (generated by selective search or another region proposal method). Then I understand that on the last convolution layer's feature map (<strong>let's call it FM</strong>), each <em>corresponding</em> RoI gets RoI-pooled, where now the corresponding ROIs are a rectangular (over height and width) slice of the FM tensor over all channels.</p>\n<p>But I'm <strong>having trouble with two concepts</strong>:</p>\n<ol>\n<li><p>How is the input RoI mapped to the corresponding RoI in FM? Each neuron comes from a very wide perceptive field, so, in a deep neural network, there's no way of making a 1:1 mapping between input neurons and neurons in the last convolution layer right?</p>\n</li>\n<li><p>Disregarding that I'm confused in point 1, once we have a bunch of RoIs in FM and we do the RoI pooling, we have N pooled feature vectors. Do we now run each of these through one FC network one by one? Or do we have N branches of FC networks? (that wouldn't make sense to me)</p>\n</li>\n</ol>\n<p>I have also read the <a href=\"https://arxiv.org/pdf/1506.01497v3.pdf\" rel=\"nofollow noreferrer\">faster R-CNN paper</a>. In the same way, I'm also interested to know about how the proposed regions from RPN map to the input of the RoI pooling in the Fast R-CNN layers. Because actually those proposed regions live in the space of the input image, not in the space of the deep feature map.</p>\n", "pids": ["5f156e7091e011d7db223b03"], "flag": 1}
{"question": "Can you train Transformers sequentially?", "body": "<p>I’m currently trying to train a BART, which is a denoising Transformer created by Facebook researchers. Here’s my Transformer code</p>\n\n<pre><code>import math\nimport torch\nfrom torch import nn\nfrom Constants import *\n\nclass Transformer(nn.Module):\n    def __init__(self, input_dim: int, output_dim: int, d_model: int = 200, num_head: int = 8, num_e_layer: int = 6,\n                 num_d_layer: int = 6, ff_dim: int = 1024, drop_out: float = 0.1):\n        '''\n        Args:\n            input_dim: Size of the vocab of the input\n            output_dim: Size of the vocab for output\n            num_head: Number of heads in mutliheaded attention models\n            num_e_layer: Number of sub-encoder layers\n            num_d_layer: Number of sub-decoder layers\n            ff_dim: Dimension of feedforward network in mulihead models\n            d_model: The dimension to embed input and output features into\n            drop_out: The drop out percentage\n        '''\n        super(Transformer, self).__init__()\n        self.d_model = d_model\n        self.transformer = nn.Transformer(d_model, num_head, num_e_layer, num_d_layer, ff_dim, drop_out,\n                                          activation='gelu')\n        self.decoder_embedder = nn.Embedding(output_dim, d_model)\n        self.encoder_embedder = nn.Embedding(input_dim, d_model)\n        self.fc1 = nn.Linear(d_model, output_dim)\n        self.softmax = nn.Softmax(dim=2)\n        self.positional_encoder = PositionalEncoding(d_model, drop_out)\n        self.to(DEVICE)\n\n    def forward(self, src: torch.Tensor, trg: torch.Tensor, src_mask: torch.Tensor = None,\n                trg_mask: torch.Tensor = None):\n        embedded_src = self.positional_encoder(self.encoder_embedder(src) * math.sqrt(self.d_model))\n        embedded_trg = self.positional_encoder(self.decoder_embedder(trg) * math.sqrt(self.d_model))\n        output = self.transformer.forward(embedded_src, embedded_trg, src_mask, trg_mask)\n        return self.softmax(self.fc1(output))\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout=0.1, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0).transpose(0, 1)    \n        self.register_buffer('pe', pe)\n</code></pre>\n\n<p>and here’s my training code</p>\n\n<pre><code>def train(x: list):\n    optimizer.zero_grad()\n    loss = 0.\n    batch_sz = len(x)\n    max_len = len(max(x, key=len)) + 1  # +1 for EOS xor SOS\n    noise_x = noise(x)\n    src_x = list(map(lambda s: [SOS] + [char for char in s] + [PAD] * ((max_len - len(s)) - 1), noise_x))\n    trg_x = list(map(lambda s: [char for char in s] + [EOS] + [PAD] * ((max_len - len(s)) - 1), x))\n    src = indexTensor(src_x, max_len, IN_CHARS).to(DEVICE)\n    trg = targetsTensor(trg_x, max_len, OUT_CHARS).to(DEVICE)\n    names = [''] * batch_sz\n\n    for i in range(src.shape[0]):\n        probs = transformer(src, trg[:i + 1])\n        loss += criterion(probs, trg[i])\n\n    loss.backward()\n    optimizer.step()\n\n    return names, loss.item()\n</code></pre>\n\n<p>As you can see in the train code. I am training it \"sequentially\" by inputting the first letter of the data then computing the loss with the output then inputting the first and second character and doing the same thing, so on and so forth.</p>\n\n<p>This doesn’t seem to be training properly though as the denoising is totally off. I thought maybe there’s something wrong with my code or you can’t train Transformers this way.</p>\n\n<p>I'm taking first name data then noising it then training the Transformer to denoise it, but the output to the Transformers doesn't look remotely like the denoised version or even the noised version of the name. I built a denoising autoencoder using LSTMs and it did way better, but I feel like BART should be way out performing LSTMs cause it's supposedly state of the art NLP neural network model.</p>\n", "pids": ["5dbab2523a55acea3c05b02b"], "flag": 1}
{"question": "What is the role of convex optimisation in AI systems?", "body": "<p>Convex optimisation is defined as:</p>\n\n<p><a href=\"https://i.stack.imgur.com/bQv8T.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/bQv8T.png\" alt=\"enter image description here\"></a></p>\n\n<p>I have seen a lot of talk about convex loss functions in Neural Networks and how we are optimising rewards or penalty in AI/ML systems. But I have never seen any loss function formulated in the aforementioned way. So my question is:</p>\n\n<p>Is there any role of convex optimization in AI? If so, in what algorithms or problem settings or systems?</p>\n", "pids": ["56d87179dabfae2eeef836c2"], "flag": 1}
{"question": "Whether &quot;group polarization&quot; and &quot;social segregation&quot; is the same?", "body": "<p>In a paper of (<a href=\"https://www.nature.com/articles/s41598-019-40990-z\" rel=\"nofollow noreferrer\">Murase, 2019</a>) use both terms &quot;group polarization&quot; and &quot;social segregation&quot;.</p>\n<p>The &quot;group polarization&quot; is explained <a href=\"https://psychology.stackexchange.com/questions/27815/what-is-the-name-of-phenomenon-that-people-state-their-initial-opinion-more-firm\">here</a>, and the author also documents about the &quot;social segregation&quot; as</p>\n<blockquote>\n<p>The relationship between homophily and segregation has been recognized\nlong ago.(...)In another approach to social segregation, opinion\ndynamics is used so that similar people can influence each other</p>\n</blockquote>\n<p>I am wondering whether these two terms &quot;<strong>group polarization</strong>&quot; and &quot;<strong>social segregation</strong>&quot; are the same?</p>\n", "pids": ["5c9210d3e1cd8edc3db5f8ed"], "flag": 1}
{"question": "how to share to mention/publish large datasets?", "body": "<p>When writting an article with outputs (by outputs I mean a big dataset created), how do you share them? </p>\n\n<p>Do you ask the readers to contact the main author? Should I pput them in a university website?</p>\n", "pids": ["58d82fcbd649053542fd677d"], "flag": 1}
{"question": "What does &quot;psychology of salience&quot; mean?", "body": "<p><a href=\"https://doi.org/10.1017/S0022109021000077\" rel=\"nofollow noreferrer\">Han et. al., (2021)</a> documented that</p>\n<blockquote>\n<p>Motivated by the <strong>psychology of salience</strong>, we also make a second key\npsychological assumption that receivers attend more to extreme\noutcomes</p>\n</blockquote>\n<p>I am wondering what does &quot;psychology of salience&quot; mean here. I search for the meaning and see <a href=\"https://psychology.wikia.org/wiki/Salience#:%7E:text=Salience%20in%20psychology.,stands%20out%20from%20the%20rest.\" rel=\"nofollow noreferrer\">that</a></p>\n<blockquote>\n<p>Salience in psychology. Distinctiveness, prominence, obviousness. The\nterm is widely used in the study of perception and cognition to refer\nto any aspect of a stimulus that, for any of many reasons, stands out\nfrom the rest</p>\n</blockquote>\n<p>However, I cannot fit this meaning to the sentence of Han,2021 as above.\nCould you please help me to sort it out?</p>\n<h2>References</h2>\n<p>Han, B., Hirshleifer, D., &amp; Walden, J. (2021). Social transmission bias and investor behavior. <em>Journal of Financial and Quantitative Analysis, First View</em>, 1-42. <a href=\"https://doi.org/10.1017/S0022109021000077\" rel=\"nofollow noreferrer\">https://doi.org/10.1017/S0022109021000077</a></p>\n", "pids": ["55a3e01165ce5cd7b3bb19a8"], "flag": 1}
{"question": "What is it called in AI when a program is designed to make &quot;x in the style of y&quot;?", "body": "<p>Simplified: <em>What is it called in AI when a program is designed to make \"x in the style of y;\" when it trains off of two types of sources in order to make a thing from source one, informed by features from source two?</em> For example, if a network made up of two smaller networks were to take sheet music of a specific compositional style in network A and audio samples from a certain genre in B and through an interface creates music from a certain genre in a certain compositional style; the <em>is</em> comes from One, the <em>seems</em> comes from Two.</p>\n\n<p>For more coarse and obvious examples:</p>\n\n<ul>\n<li>\"Compose synthpop in the style of Beethoven\"</li>\n<li>\"Draw impressionism in the style of Mondrian\"</li>\n<li>\"Generate casserole recipes using only ingredients most likely to fluctuate in price given current market data\"</li>\n<li>\"Sketch baseballs that look like they're made of espresso foam\"</li>\n</ul>\n", "pids": ["573695fe6e3b12023e511894", "58d82fced649053542fd7289"], "flag": 1}
{"question": "Why do I feel funny in my tummy when riding a virtual roller coaster?", "body": "<p>I've ridden a virtual roller coaster on an Oculus Rift. I felt tension as I went up to the top, but more interestingly I actually felt my stomach drop when I went down the steep drop on the other side. Why can I feel this, when no forces are actually being applied to my stomach?</p>\n\n<p>A bonus question: If you took someone that had never ridden a roller coaster, or even been exposed to rapid acceleration, and had them try a virtual one - would they feel the same stomach lurch as I did?</p>\n", "pids": ["56d85a30dabfae2eee4883fc", "55a4917865ceb7cb02d213e2"], "flag": 1}
{"question": "Why do SSRIs take multiple weeks to reach their full effect?", "body": "<p>What is it about SSRIs that they require 2-4 weeks for their long-term effect to become present?</p>\n<p>Is this the result of small accumulations over time in some aspect of the brain?</p>\n<p>Are there other medicines which are known to have a delayed onset of effect like this?</p>\n", "pids": ["61c90f9f5244ab9dcb54a8cb"], "flag": 1}
{"question": "Human/social behavior when one emphasizes their own superior achievements over others&#39;", "body": "<p>I'm looking for a name/category/definition of (personality?) disorder(s) that can be described with the following traits in one's (imaginary person) social/human behavior:</p>\n<ul>\n<li>this person brings up and emphasizes his own, (according to him) superior achievements whenever another person around him mentions their own success/results/etc. (relevant fact: this person's statements about his own achievements are usually true, so there is no or little exaggeration);</li>\n<li>still, this person does this in a way that likely hurts other's feelings or self-esteem (this person does this regardless of who's the other half, like friends/partner/family), maybe even permanently;</li>\n<li>when this person has to do something with the achievements of others, he also emphasizes his own role behind the success of the other half (may even claim that the other person would not have been able to achieve their results without his assistance/inspiration);</li>\n<li>finally, though this may be a bit further from the previous points, this person may also inspire other people to start doing the same things that he's already started earlier (through which he may have an edge in terms of performance, quicker results, etc.) - e.g., a hobby or a sport.</li>\n</ul>\n<p>As a follow-up question: what would be an ideal strategy to deal with (from friends/family perspective) such a person's behavior (preferably in a way that noone gets hurt)?\nNote please that I'm not looking for an answer/advice related to any personal issues or situation, the above scenarios are strictly hypothetical.</p>\n<p>As a 2nd follow-up question: I'd be also interested in the origin of such a situation/traits (like how one would develop such a behavior, e.g. through childhood events or parental issues).</p>\n<p>My research so far: tried to look for an answer online by summarizing the main points and got to &quot;Narcissistic personality disorder&quot; which (according to <a href=\"https://www.mayoclinic.org/diseases-conditions/narcissistic-personality-disorder/symptoms-causes/syc-20366662\" rel=\"nofollow noreferrer\">this site</a>) is a mental condition in which people have an inflated sense of their own importance, a deep need for excessive attention and admiration.</p>\n<p>However, I'm not 100% sure that the above traits completely match this definition since they emphasize one's superior results/role in other's success and usually are combined with mean/humiliating remarks. Also, this person rarely steers a conversation etc. in a way so that he'll have the attention/focus.</p>\n", "pids": ["53e9bc15b7602d970487bac9"], "flag": 1}
{"question": "Which simulation platform is used by DeepMind (and others) to handle inverse kinematics musculoskeletal?", "body": "<p>Which simulation platform is used by <a href=\"https://www.youtube.com/watch?v=Xmw3UwP_vnc\" rel=\"nofollow noreferrer\">DeepMind</a> and <a href=\"https://www.youtube.com/watch?v=pgaEE27nsQw\" rel=\"nofollow noreferrer\">others</a> to handle inverse kinematics musculoskeletal simulation, etc., for reinforcement learning simulations and agents?</p>\n\n<p>I thought they use Unity or Unreal but I assume that would be resource-heavy. </p>\n", "pids": ["59ae3be32bbe271c4c71b8c3"], "flag": 1}
{"question": "How do I identify the number and type of objects in the same picture?", "body": "<p>I need to identify the number and type of all objects in a picture, so there can be multiple objects of the same type.</p>\n\n<p>For example, I have a picture with <span class=\"math-container\">$10$</span> animals, and I want my program to tell me that, on the picture, I have <span class=\"math-container\">$3$</span> elephants, <span class=\"math-container\">$2$</span> cats and <span class=\"math-container\">$5$</span> dogs. However, I <strong>do not</strong> need the detection of the location of the objects. All I need is the information on the number of objects of each class, without their possible locations.</p>\n\n<p>I wanted to ask you guys for help in defining the type of problem I am dealing with and maybe some suggestions about where to start looking for a solution. It would be nice if you could point out some directions, algorithms or network architectures to solve the problem described below.</p>\n", "pids": ["573696026e3b12023e516718", "5736986b6e3b12023e730129", "573696056e3b12023e518676"], "flag": 1}
{"question": "Should I just use exploitation after I have trained the Q agent?", "body": "<p>When using a trained Q-learning algorithm in an actual game, would I just use exploitation and no longer use exploration? Should I use exploration only during the training phase?</p>\n", "pids": ["5ac1829d17c44a1fda918186"], "flag": 1}
{"question": "What are multi-hop relational paths?", "body": "<p>What are multi-hop relational paths in the context of knowledge graphs (KGs)?</p>\n\n<p>I tried looking it up online, but didn't find a simple explanation.</p>\n", "pids": ["5e621f3d91e01160711d5f37", "5e621f3d91e01160711d5f37"], "flag": 1}
{"question": "Which reward function works for recommendation systems using knowledge graphs?", "body": "<p>I've been reading <a href=\"https://arxiv.org/pdf/1906.05237.pdf\" rel=\"nofollow noreferrer\">this paper on recommendation systems</a> using reinforcement learning (RL) and knowledge graphs (KGs).</p>\n\n<p>To give some background, the graph has several (finitely many) entities, of which some are user entities and others are item entities. The goal is to recommend items to users, i.e. to find a recommendation set of items for every user such that the user and the corresponding items are connected by one reasoning path.</p>\n\n<p>I'm attaching an example of such a graph for more clarity (from the paper itself) -</p>\n\n<h1><a href=\"https://i.stack.imgur.com/zhdCC.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/zhdCC.png\" alt=\"enter image description here\"></a></h1>\n\n<p>In the paper above, they say</p>\n\n<blockquote>\n  <p>First, we do not have pre-defined targeted items for any user, so it is <strong>not applicable to use a binary reward</strong> indicating whether the user interacts with the item or not. A better design of the reward function is to <em>incorporate the uncertainty</em> of how an item is relevant to a user based on the rich heterogeneous information given by the knowledge graph.</p>\n</blockquote>\n\n<p>I'm not able to understand the above extract, which talks about the reward function to use - binary, or something else. A detailed explanation of what the author is trying to convey in the above extract would really help. </p>\n", "pids": ["5d06e496da562926acc593f2"], "flag": 1}
{"question": "Where to publish a critical comment on an academic paper?", "body": "<h3>Background</h3>\n\n<p>Last year, in October, an exceptionally weak paper <a href=\"https://doi.org/10.1038/nature19793\" rel=\"noreferrer\">was published in Nature</a>. The publication of such a piece in a top journal <a href=\"https://www.nrc.nl/nieuws/2016/12/09/how-weak-science-slipped-past-through-review-and-landed-in-a-top-journal-a1535637\" rel=\"noreferrer\">was a clear violation</a> of peer-review standards. Despite the title and publication in a reputable journal, this paper did not provide any evidence. </p>\n\n<h3>My attempts</h3>\n\n<p>I guess, I was the first to submit a <a href=\"http://www.nature.com/nature/authors/gta/commsarising.html\" rel=\"noreferrer\">Brief Communication Arising</a> to Nature just a week after the initial publication. My comment was rejected two weeks later, and I <a href=\"https://dx.doi.org/10.14322/publons.r505407\" rel=\"noreferrer\">published it in Publons system</a>. I see that up until now there has been no clear statement in the peer-reviewed academic literature of the flawed nature of Dong et al paper. </p>\n\n<h3>The question</h3>\n\n<p>What is the best way to publish a critical comment on a paper published in top journal, if that journal rejected the comment?   </p>\n\n<p><em>I believe, it is very important to publish the critical comment in a peer-reviewed journal. However, usually journals are only willing to consider critical comments on the papers published in their pages.</em> </p>\n", "pids": ["53e9b725b7602d97042bcbe0", "599c7afd601a182cd26fa0c9"], "flag": 1}
{"question": "Relationship between intelligence (IQ) and Big 5 Personality", "body": "<p>Is there any relationship  between intelligence and <a href=\"https://en.wikipedia.org/wiki/Big_Five_personality_traits\" rel=\"nofollow noreferrer\">big five personality traits</a>?</p>\n", "pids": ["5ae1ab3ea2e6b107866a6811", "56d924a1dabfae2eeeb356c2", "56d924a3dabfae2eeeb364c5"], "flag": 0}
{"question": "Can we combine Off-Policy with On-Policy Algorithms?", "body": "<p><strong>On-Policy Algorithms</strong> like PPO directly maximize the performance objective or an approximation of it. They tend to be quite stable and reliable but are often sample inefficient. <strong>Off-Policy Algorithms</strong> like TD3 improve the sample inefficiency by reusing data collected with previous policies, but they tend to be less stable. (Source: <a href=\"https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html\" rel=\"nofollow noreferrer\">Kinds of RL Algorithms - Spinning up - OpenAI</a>)</p>\n\n<p>Looking at learning curves comparing SOTA algorithms, we see that off-policy algorithms quickly improve performance at the training's beginning. Here <a href=\"https://spinningup.openai.com/en/latest/spinningup/bench.html#walker2d-tensorflow-versions\" rel=\"nofollow noreferrer\">an example</a>:\n<a href=\"https://i.stack.imgur.com/kLViU.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/kLViU.png\" alt=\"3M timestep benchmark of different algorithms for Walker2d-v3\"></a></p>\n\n<p>Can we start training off-policy and after some time use the learned and quickly improved policy to init the policy network of an on-policy algorithm? </p>\n", "pids": ["58d82fc8d649053542fd5b14"], "flag": 1}
{"question": "Is there a &quot;Facebook&quot; for researchers? (to collaborate on projects)", "body": "<p>I'm writing my PhD-thesis in economics at a fairly small university.\nAccordingly, there are relatively few scientists in my department.\nI am planning to write a research paper on a specific topic that nobody else at my university is researching.\nHowever, I think that it makes sense to write this paper with several people so that the expertise of others can also be included in this study (and many more reasons).</p>\n\n<p>My question now is where I can find other researchers on this topic. Is there a \"Facebook\" for researchers? And how can I contact them?</p>\n\n<p>I would also be pleased if someone would tell me about their experience on this problem.</p>\n", "pids": ["5c75672ff56def97981508db"], "flag": 1}
{"question": "How to use speaker&#39;s information as well as text for fine-tuning BERT?", "body": "<p>I want to classify my corporate chat messages into a few categories such as question, answer, and report. I used a fine-tuned BERT model, and the result wasn't bad. Now, I started thinking about ways to improve it, and a rough idea came up, but I don't know what to do it exactly.</p>\n\n<p>Currently, I simply put chat text into the model, but don't use the speaker's information (who said the text, the speaker's ID in our DB). The idea is if I can use the speaker's information, the model might better understand the text and classify it better.</p>\n\n<p>The question is, are there any examples or prior researches similar to what I want to achieve? I googled for a few hours, but couldn't find anything useful. (Maybe the keywords weren't good.)</p>\n\n<p>Any advice would be appreciated.</p>\n", "pids": ["5bdc31b417c44a1f58a0b8c2"], "flag": 1}
{"question": "Why cytotoxic T cells don&#39;t kill dendritic cells when they present antigen?", "body": "<p>When a cytotoxic T cell (CTL) recognizes a peptide presented in the MHC-1 of a dendritic cell (APC), why it doesn't kill this cell?</p>\n\n<p>I know that initially, in the lymph node, the T cell is inactivated. But eventually it becomes activated and travels to the tissue, where it again finds APCs presenting the offending antigen. So why doesn't the CTL kill the APC at this point?</p>\n\n<p>Moreover, not all MHC-1's of the dendritic cell present antigens from phagocytized cells. Some MHC-1's present peptides coming from the dendritic cell itself, so that if the dendritic cell itself becomes infected with virus or bacteria, it can be killed by a CTL that recognizes the peptide. So in this case, the CTL does indeed kill the dendritic cell.</p>\n\n<p>So my question is, when exactly does the CTL kill the APC? How does the CTL knows that should or shouldn't kill the APC?</p>\n", "pids": ["5c757d34f56def9798ab84b5", "5ce2d070ced107d4c637bb4c"], "flag": 1}
{"question": "Why are synapses that are connected to co-transmitting presynaptic vesicles uniformly distributed on the postsynaptic neuron?", "body": "<p><a href=\"https://urldefense.com/v3/__https://www.sciencedirect.com/science/article/pii/S0959438814000890?casa_token=PlmaRqdKYucAAAAA:GQL-xd53YSjaw28LMbIDBS_O8EGW4UcGWNJ72IpE2h8qbJjVJfpTP7oh2FRrC67AsQlwyLIoFg__;!!Dq0X2DkFhyF93HkjWTBQKhk!GLYpqKZisHfS8KicFrxaP5-Wcz6kZBL6cNbk6gRq-HRkrCovpF-LAcugtUUvDSVBHQM71ZuuJtpY8O7h$\" rel=\"nofollow noreferrer\">This paper</a> on functional implications of co-release and co-transmission says that &quot;Consistent with a co-transmission phenotype, cholinergic synapses are uniformly distributed on the postsynaptic neuron, whereas GABAergic synapses are non-uniformly distributed.&quot;</p>\n<p>Why is it the case that synapses across which neurotransmitters/modulators are co-transmitted are uniformly distributed? Also, what is the typical morphology of synapses that are co-released?</p>\n", "pids": ["53e9a603b7602d9702f3450f"], "flag": 1}
{"question": "Is Dissociative Personality Disorder Alter Takeover Possible?", "body": "<p>Is it possible for an individual with <a href=\"https://www.psychiatry.org/patients-families/dissociative-disorders/what-are-dissociative-disorders\" rel=\"nofollow noreferrer\">dissociative personality disorder</a>, with two distinct personalities, for the second personality (the 'alter') to take over and become the primary personality? More specifically, can the individual's second personality delete or suppress the individual's primary personality, therefore becoming the individual's sole personality?</p>\n", "pids": ["6028f689af79179a99cc9009", "5c756aabf56def97983627d5", "55a66b6465ce054aad6712c5", "53e9b344b7602d9703e1975c", "53e9a108b7602d97029f8307", "55a4d43d65ceb7cb02d9401b", "55a4cd1065ceb7cb02d8aa35", "5c0f8e09da562944aca2cf65"], "flag": 1}
{"question": "What&#39;s the best practice for Boltzmann Exploration temperature in RL?", "body": "<p>I'm currently modeling DQN in Reinforcement Learning. My question is: what are the best practices related to Boltzmann Exploration? My current thoughts are: (1) Let the temperature decay through training and finally stop at 0.01, when the method will always select the best practice, with almost no randomness. (2) Standardize the predicted Q values before feeding into the softmax function.</p>\n<p>Currently, I'm using (2), and the reward is suffering from high variance. I'm wondering whether it has something to do with the exploration method?</p>\n", "pids": ["599c7b59601a182cd272b6ef"], "flag": 1}
{"question": "Can I do state space quantization using a KMeans-like algorithm instead of range buckets?", "body": "<p>Are there any reference papers where it is used a KMeans-like algorithm in state space quantization in Reinforcement Learning instead of range buckets?</p>\n", "pids": ["5a73cbc317c44a0b3035f0a5"], "flag": 1}
{"question": "How to deal with the addition of a new state to the environment during training?", "body": "<p>Let's say we have a dynamic environment: a new state gets added after 2000 episodes have been done. So, we leave room for exploration, so that it can discover the new state.</p>\n<p>When it gets to that new state, it has no idea of the Q values, and, since we're past 2000 episodes, our exploration rate is very low. What happens if try to exploit when all Q values are 0?</p>\n", "pids": ["5c04966a17c44a2c7470855a"], "flag": 1}
{"question": "What exactly happens to brain during anesthesia", "body": "<p>While anesthesia is given to a patient what changes in the chemistry of brain happens. Which part of the brain is affected by the medicine which causes anesthetic effects. \nCan anesthesia be considered as sleep+painless state of body? Or is it more than that. </p>\n", "pids": ["55a4603e65ce31bc8778a4ee"], "flag": 0}
{"question": "How do I get the &quot;Avoidance and Inflexibility Scale&quot;?", "body": "<p>I am working with a smoking cessation app and I want to study the acceptance of smoking behaviour. I found a good paper by <a href=\"https://doi.org/10.1016/S0005-7894(04)80015-7\" rel=\"nofollow noreferrer\">Gifford et al. (2004)</a> in which the authors use their own questionnaire called the <strong>Avoidance and Inflexibility Scale (AIS)</strong>.</p>\n\n<p>However, I cannot find it in PsycInfo and Google Scholar. A more general research on google does not yield any result.</p>\n\n<p><sub>\nGifford, E. V., Kohlenberg, B. S., Hayes, S. C., Antonuccio, D. O., Piasecki, M. M., Rasmussen-Hall, M. L., &amp; Palm, K. M. (2004). <a href=\"https://doi.org/10.1016/S0005-7894(04)80015-7\" rel=\"nofollow noreferrer\">Acceptance-based treatment for smoking cessation.</a> Behavior therapy, 35(4), 689-705.\n</sub></p>\n", "pids": ["53e9a0e6b7602d97029cf87d", "55a6b45f65ce054aad71f72a"], "flag": 0}
{"question": "What tense to use when writing a thesis?", "body": "<p>I am well aware of the fact that there are a number of questions that talk about tenses in research, but I still have not found exactly what I am after.</p>\n\n<p>Basically my question is this, in a Master dissertation, should the tense be the same throughout the entire text? Or is it acceptable (or even required)  to use different tenses in different structures?</p>\n\n<p>Assuming the following structure, if you believe that there should be separate tenses, would the suggestions in brackets be correct?</p>\n\n<ul>\n<li>Title (<strong>Present</strong>)</li>\n<li>Abstract (<strong>Imperfect Past</strong>)</li>\n<li>Introduction (<strong>Present + Future</strong>)</li>\n<li>Methodology (<strong>Past Perfect, Present, Future or Mix?</strong>)</li>\n<li>Results (<strong>Past Perfect</strong>)</li>\n<li>Discussion (<strong>Present*</strong>)</li>\n<li>Conclusion (<strong>Mix?, conditional present</strong>)</li>\n</ul>\n\n<p>*Would the choice of any present tense put all preceding sections in a past tense?</p>\n\n<p>Looking at that structure I find it hard to see that only one tense should be adopted throughout the entire text. </p>\n\n<p>Sources: <a href=\"https://academia.stackexchange.com/questions/7791/what-tense-should-paper-titles-use/7800#7800\">This</a>, <a href=\"https://academia.stackexchange.com/questions/83688/which-tense-to-use-when-presenting-my-master-thesis\">this</a> and <a href=\"https://academia.stackexchange.com/questions/3608/in-what-tense-present-past-should-papers-be-written\">that</a>.</p>\n", "pids": ["5fd58343a4e4c3c831a9b017"], "flag": 1}
{"question": "Is GAIL applicable if the expert&#39;s trajectories are for the same task but are in a different environment?", "body": "<p>Is the <a href=\"https://papers.nips.cc/paper/2016/file/cc7e2b878868cbae992d1fb743995d8f-Paper.pdf\" rel=\"nofollow noreferrer\">GAIL</a> applicable if the expert's trajectories (sample data) are for the same task but are in a different environment (modified but will not be completely different)?</p>\n<p>My gut feeling is, yes, otherwise we can just simply adopt behavioural cloning. Furthermore, since the expert's trajectories are from a different environment, the dimension/length of state-action pairs will most likely be different. Will those trajectories still be useful for GAIL training?</p>\n", "pids": ["5a260c8417c44a4ba8a31c29"], "flag": 1}
{"question": "How to prevent image recognition of my dataset with neural networks and make it hard to train them?", "body": "<p>Suppose I have a private set of images containing some objects.</p>\n<p>How do i</p>\n<ol>\n<li><p>Make it very hard for the neural networks such as ImageNet to recognize these objects, while allowing humans to do it at the same time?</p>\n</li>\n<li><p>Suppose I label these private images - a picture of a cat with a label &quot;cat&quot; - how do I make it hard for the attacker to train his neural network on my labels? Is it possible to somehow fool a neural network so that they couldn't easily train it to recognize it?</p>\n</li>\n</ol>\n<p>Like random transforms etc, so that they couldn't use a neural network to recognize these objects, or even train it on my dataset if they had labels.</p>\n", "pids": ["58d82fced649053542fd6ec6"], "flag": 1}
{"question": "Am I an author if I am included as &quot;Consortia&quot; / &quot;Group Author&quot; for a research paper?", "body": "<p>I had a collaboration with a group and a paper is published as the result of this study which includes many experts. The study was done in groups where each group had a leader, we had multiple meetings, passed our research notes according to our study, the group leaders then wrote the paper. However when the paper was submitted we were not informed, we were informed only after it was accepted.</p>\n<p>I am included as Consortia, which goes like: Author1, Author2,..., Author8 &amp; Consortia</p>\n<p>and then in the paper the names of the Consortia is included in a table. The main author says we are co-authors but how does it work? Am I an actual author? Can I list this paper as my paper? I am not asking for a mere CV but I need to add this to a formal system that keeps track of my papers. I could just skip doing so (and not get points from the paper) but then again I actually should include it as I also represent my affiliation.</p>\n<p>I have seen that this is often done in natural sciences or in companies research teams. Can anyone who has experience / knows how it works let me know?</p>\n", "pids": ["62283d955aee126c0fdb42fe"], "flag": 1}
{"question": "How does batch normalisation actually work?", "body": "<p>I actually went through the Keras' batch normalization tutorial and the description there puzzled me more.</p>\n<p>Here are some facts about batch normalization that I read recently and want a deep explanation on it.</p>\n<ol>\n<li><p>If you froze all layers of neural networks to their random initialized weights, except for batch normalization layers, you can still get 83% accuracy on CIFAR10.</p>\n</li>\n<li><p>When setting the trainable layer of batch normalization to false, it will run in inference mode and will not update its mean and variance statistics.</p>\n</li>\n</ol>\n", "pids": ["573696ce6e3b12023e5ce95a"], "flag": 1}
{"question": "Given a DOI, how can I programmatically obtain all the relevant dates from a paper?", "body": "<p>I have to collect the relevant dates (date submited, revised, accepted, published) from a large amount of papers. I would like to do this using R but I could adapt to any other suggested method. Many thanks in advance.</p>\n", "pids": ["5c80ebcde1cd8e25fdd464b7"], "flag": 1}
{"question": "What is the difference between Bayes-adaptive MDP and a Belief-MDP in Reinforcement Learning?", "body": "<p>I have been reading a few papers in this area recently and I keep coming across these two terms. As far as I'm aware, Belief-MDPs are when you cast a POMDP as a regular MDP with a continuous state space where the state is a belief (distribution) with some unknown parameters.</p>\n<p>Are they not the same thing?</p>\n", "pids": ["5e5e18d993d709897ce35895", "5736965e6e3b12023e56b399"], "flag": 1}
{"question": "How do you write an acknowledgement section without having anything to acknowledge?", "body": "<p>If a journal requires an acknowledgement section, but you have nothing to acknowledge, how is this put best?</p>\n<p>&quot;The authors have nothing to acknowledge.&quot;? This sounds a bit arrogant to me.</p>\n<p>The <a href=\"https://www.nature.com/documents/ncomms-formatting-instructions.pdf\" rel=\"nofollow noreferrer\">formatting instructions say</a>: &quot;Must be brief and must not include thanks to Editors or referees, effusive comments or dedications.&quot; It is given as optional; yet, the editor asked for it for the second time now.</p>\n", "pids": ["5dfded9cdf1a9c0c41658185"], "flag": 1}
{"question": "What is the difference between artificial neural networks and deep learning?", "body": "<p>I have read many mixed definitions around these two terms. For example, is it right to say deep learning is any ANN with more than two hidden layers?</p>\n<p>What are formal definitions for these two?</p>\n", "pids": ["53e9b068b7602d9703acf032"], "flag": 1}
{"question": "How are mujoco environments used for meta-rl?", "body": "<p>Afaik, investigating meta reinforcement learning algorithms requires a collection of two or more environments which have similar structure but are still different enough.\nWhen I read <a href=\"https://arxiv.org/abs/1703.03400\" rel=\"nofollow noreferrer\">this paper</a> it was unclear to me what the meta-training and meta-testing environments were.</p>\n<p>For eg., a graph is given for Ant-Fwd-Bkwd showing its performance with number of gradient steps. I'm guessing these are the meta-testing performances. So, which environment was it 'meta-trained' on?</p>\n<p>Was it meta-trained on the same Ant-Fwd-Bkwd environment?</p>\n", "pids": ["5cede10dda562983788eda33"], "flag": 1}
{"question": "How does &#39;Bright score&#39; assess how strong the connection is between users and their jobs?", "body": "<p>In 2014 <a href=\"https://techcrunch.com/2014/02/06/linkedin-snatches-up-data-savvy-job-search-startup-bright-com-for-120m-in-its-largest-acquisition-to-date/\" rel=\"nofollow noreferrer\">Linkedin acquired Bright.com</a>, for $120 million and it is using AI and big data algorithms to connect users.</p>\n<blockquote>\n<p>Bright also throws in a little Klout, ranking people by a “Bright score” which it uses to assess how strong the chemistry is between a user and a particular job.</p>\n<p>It also takes into account historical hiring patterns into its matching, along with account location, a user’s past experience and synonyms.</p>\n</blockquote>\n<p>In brief, is it known (based on some research papers) how such algorithm works which aiming at scoring 'chemistry' between users and their jobs?</p>\n", "pids": ["53e9a9b7b7602d9703311eda"], "flag": 1}
{"question": "Why are Target Networks used in Deep Q-Learning as opposed to the Expected Value equation?", "body": "<p>I understand we use a target network because it helps resolve issues regarding stability, however, that's not what I'm here to ask.</p>\n<p>What I would like to understand is why a target network is used as a measure of ground truth as opposed to the expectation equation.</p>\n<p>To clarify, here is what I mean. This is the process used for DQN:</p>\n<ol>\n<li>In DQN, we begin with a state <span class=\"math-container\">$S$</span></li>\n<li>We then pass this state through a neural network which outputs Q values for each action in the action space</li>\n<li>A policy e.g. epsilon-greedy is used to take an action</li>\n<li>This subsequently produces the next state <span class=\"math-container\">$S_{t+1}$</span></li>\n<li><span class=\"math-container\">$S_{t+1}$</span> is then passed through a target neural network to produce target Q values</li>\n<li>These target Q values are then injected into the Bellman equation which ultimately produces a target Q value via the Q-learning update rule equation</li>\n<li>MSE is used on 6 and 2 to compute the loss</li>\n<li>This is then back-propagated to update the parameters for the neural network in 2</li>\n<li>The target neural network has its parameters updated every X epochs to match the parameters in 2</li>\n</ol>\n<p>Why do we use a target neural network to output Q values instead of using statistics. Statistics seems like a more accurate way to represent this. By statistics, I mean this:</p>\n<p>Q values are the expected return, given the state and action under policy π.</p>\n<p><span class=\"math-container\">$Q(S_{t+1},a) = V^π(S_{t+1})$</span> = <span class=\"math-container\">$\\mathbb{E}(r_{t+1}+ γr_{t+2}+ (γ^2)_{t+3} + ...    \\mid S_{t+1}) = {E}(∑γ^kr_{t+k+1}\\mid S_{t+1})$</span></p>\n<p>We can then take the above and inject it into the Bellman equation to update our target Q value:</p>\n<p><span class=\"math-container\">$Q(S_{t},a_t) + α*(r_t+γ*max(Q(S_{t+1},a))-Q(S_{t},a))$</span></p>\n<p>So, why don't we set the target to the sum of diminishing returns? Surely a target network is very inaccurate, especially since the parameters in the first few epochs for the target network are completely random.</p>\n", "pids": ["5a260c8117c44a4ba8a30ecc"], "flag": 1}
{"question": "How could logistic loss be used as loss function for an ANN?", "body": "<p>Normally, in practice, people use those loss functions with minima, e.g. <span class=\"math-container\">$L_1$</span> mean absolute loss, <span class=\"math-container\">$L_2$</span> mean squared error, etc. All those come with a minimum to optimize to.\n<a href=\"https://i.stack.imgur.com/RSccA.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/RSccA.png\" alt=\"enter image description here\" /></a></p>\n<p>However, there's another thing, logistic loss, I'm reading about, but don't get it why the logistic function could be used as a loss function, given that it has the so-called minimum at infinity, but that isn't a normal minimum. Logistic loss function (black curve):</p>\n<p><a href=\"https://i.stack.imgur.com/0pREW.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/0pREW.png\" alt=\"enter image description here\" /></a></p>\n<p>How can an optimizer minimize the logistic loss?</p>\n", "pids": ["5a260c8117c44a4ba8a30b08"], "flag": 1}
{"question": "Where do you place the link to open data in a manuscript?", "body": "<p>Assume you are writing a manuscript and you have uploaded your raw data to a relevant hosting site (e.g., The Dataverse Network, FigShare, etc.). Where in the manuscript should you indicate a link to this?</p>\n\n<p>This question was posted on <a href=\"https://twitter.com/nicebread303/status/590395191359582209\">twitter</a> and one suggestion was to include a link in the author notes and the results.</p>\n", "pids": ["5550415a45ce0a409eb3a8aa"], "flag": 1}
{"question": "What physics knowledge can be applied to biology of organisms and ecosystems?", "body": "<p>In the wiki page of <a href=\"https://en.wikipedia.org/wiki/Biophysics\">Biophysics</a>:</p>\n\n<blockquote>\n  <p>Biophysics spans all scales of biological organization, from the molecular scale <strong>to whole organisms and ecosystems.</strong></p>\n</blockquote>\n\n<p>But after searching on the internet; the dominant application of physics in biology that I see is at the molecular scale. In the wiki page <a href=\"https://en.wikipedia.org/wiki/Mathematical_and_theoretical_biology#Mathematical_biophysics\">Mathematical biophysics</a>, there is a lot of interesting information, but it is only about mathematical knowledge applied to biophysics, not physics itself. </p>\n\n<p>What, if any, physics knowledge (based on principles and laws of physics) can be applied to biology in the sense of organisms and ecosystems?</p>\n", "pids": ["55a605af65cead59c832cbdb"], "flag": 1}
{"question": "Why don&#39;t mosquitoes evolve towards muting themselves?", "body": "<p>Quite certainly, muted mosquitoes would be much more effective as far as their blood-sucking pursuits are concerned, since mosquito sound is predominantly responsible for sealing their fate (between the two palms of the hand). Muting themselves would certainly reduce the chances of being caught in the act. For instance, unless you notice by looking, leeches go undetected for long periods because there isn't any obvious sound emanating from them. </p>\n\n<p>Thus, reasoning says - this should be favorable from the point of view of evolution, unless there is a some indispensable purpose served by this sound, which can not be otherwise served. This <a href=\"http://www.mosquitoreviews.com/mosquitoes-buzz-ears.html\" rel=\"noreferrer\">page</a> seems to suggest that this is so from the point of view of mating. In fact, quoting verbatim:</p>\n\n<blockquote>\n  <p>Since female mosquitoes are larger, they flap their wings slower, and males know it. They use the distinctive pitch of the females' buzz to recognize them. Louis M. Roth, who studied yellow fever mosquitoes for the U.S. Army during World War II, noticed that males ignored females whenever the females were quietly resting, but whenever the females were flying, and therefore buzzing, the males wanted to mate with them. The males even wanted to mate with recordings of female mosquitoes or tuning forks that vibrated at the same pitch.</p>\n</blockquote>\n\n<p>But mating signals could also be of other forms, like some chemicals secreted (I envisage something like pheremones). Why is making sound so important? Why can't this noise be either less intense, or lie outside the audio range for humans (their targets)?</p>\n", "pids": ["58dc73e50cf2a646c3daae12"], "flag": 1}
{"question": "How to inform/attract more candidates for a postdoctoral position?", "body": "<p>When having fund for hiring postdoctoral fellow, it is tricky to find highly qualified applicants, since they can get aware of the opening position by chance. For almost any postdoctoral position (it should apply for any position, but more severe for post-doc), there are better candidates who were also interested, but did not hear about the opening.</p>\n\n<p>Possible approaches are not very effective.</p>\n\n<ul>\n<li>Spreading by word of mouth through colleagues is very limited.</li>\n<li>A few applicants may browse research group websites for checking\nopening positions. Moreover, search engines do not index and rank\nthem quickly to reach the deadline.</li>\n<li>Posting on academic job websites is good, but most of them are paid\nwebsites. For faculty positions, universities have enough fund to pay\nfor advertisement, but it is difficult to cover the advertisement cost\nby the limited fund of a postdoctoral position.</li>\n<li>Free job websites are not very common for academic positions.</li>\n</ul>\n\n<p>How to find more effective ways to inform and encourage more potentials candidates to apply for a postdoctoral positions to have a better chance to select a highly qualified applicant?</p>\n", "pids": ["5f0747c69e795e1a9f4ad6f4"], "flag": 1}
{"question": "Is there any strong empirical support that &quot;casual&quot; (10-20 minutes per day) mindfulness meditation leads to lasting cognitive improvements?", "body": "<p>I want to emphasize that I'm not referring to the intense mindfulness-based cognitive therapy (MBCT), but instead just 10-20 minutes of daily mindfulness meditation (MM), perhaps guided by a smartphone app.</p>\n\n<p>It's usually claimed that MM leads to improvements in the prefrontal cortex (enhanced focus, working memory etc.) and the amygdala (reduced depression, anxiety, stress etc.).  </p>\n\n<p>I have read recent studies claiming that mindfulness meditation is no more effective than watching a documentary, is counterproductive at work etc. (Some of these studies may have been context-specific.) Anecdotally, I've done MM myself on-and-off for several years and didn't notice any significant improvements in the areas listed above.  </p>\n\n<p>Due to publication bias, p-hacking, the reproducibility crisis etc. and my own personal experience, I'm skeptical that MM does anything significant (noticeable changes) and/or lasting (after the meditation, during the day).  </p>\n\n<p>Is there a large-scale, pre-registered replication effort to support the benefits of 'casual' MM (i.e., not the more intense MBCT)?</p>\n", "pids": ["53e9b042b7602d9703aa41d6", "53e9ba84b7602d97046a5799", "53e9ae9cb7602d97038bd68a", "53e9afe1b7602d9703a37cf3"], "flag": 1}
{"question": "Does cognitive psychology define motivation in terms of information processing?", "body": "<p>I recently asked a question on biology.stackexchange.com that if an amoeba showed &quot;avoidance&quot; behavior, would this constitute a &quot;motivation&quot; to avoid something.</p>\n<p>Within a biology context, the term &quot;motivation&quot; is seen to be a primarily human characteristic associated with &quot;free will&quot;.</p>\n<p>I explained that when I said &quot;motivation&quot;, I simply meant unscripted information processing.</p>\n<p>To this, the reply was:</p>\n<blockquote>\n<p>Again, definitions are important: &quot;motivation&quot; does not ordinarily mean &quot;information processing&quot; in fields of psychology/neuroscience/biology.</p>\n</blockquote>\n<p>This surprised me.  Doesn't cognitive psychology define human &quot;motivation&quot; in terms of information processing?</p>\n<p>When I did a google search, I found this <a href=\"https://link.springer.com/chapter/10.1007/978-1-4899-0827-8_13\" rel=\"nofollow noreferrer\">reference</a>.</p>\n<p>Am I wrong? Would it be unreasonable to attempt to define &quot;motivation&quot; in terms of information processing?</p>\n", "pids": ["5ce7c1133a55ac687ab1bef4"], "flag": 1}
{"question": "Is there a term to refer to humans&#39; automatic belief of encountered information?", "body": "<p>I believe there is a universal (or, highly regular in the mechanisms of cognition) human tendency to believe a proposition just because they encountered it. I mean this in a very specific way. It’s like they mistake someone asserting something for the discovery of a fact, from the oblivion. It’s almost like when propositions are placed somewhere free from context, the human mind through evolution has developed an (advantageous) tendency to absorb information / beliefs rapidly as they are transmitted. It would be way too much of an expense of cognitive energy to have to consider all logical factors necessary for a proposition to really be true. Even intelligent people must do it, it’s necessary for day to day functioning, and survival in / keeping up with a culture. You can imagine in paleolithic times, someone might say, &quot;There are blackberries in X location,&quot; and it's almost like a computer sending a transmission which automatically gets received. The sort of &quot;scrutiny&quot; mechanisms of human thought are not always active. There are times where just because someone said something, you immediately assume it's true without realizing or thinking about it, to the extent that you might transmit that information to someone else with the sense that it is authoritative knowledge. It's almost like we can intuitively distinguish between reported knowledge vs. (at least what we consider) an absolute fact, except we don't do it accurately - we are biased in favor of absolute facts over reported knowledge.</p>\n<p>In the extreme case it’s someone just believing anything they read online indiscriminately, but there are plenty of subtle everyday cases too. Sort of like Kahneman’s “WYSIWYG” concept (what you see is what you get), or could be an acronym such as the “I know it’s true because somebody said so” phenomenon. It’s meant to be more subtle and nuanced than just the general notion of being gullible.</p>\n<p>Have any scientists discussed this aspect of human psychology?</p>\n<p>Thank you</p>\n", "pids": ["55a4d88565ceb7cb02d9e998", "55a515c6c91bf3b1cc4e6e28", "53e9b221b7602d9703cb7521", "5a9ea66c684d55eb9298e44c", "53e9b5d4b7602d9704120fc1"], "flag": 1}
{"question": "Why do professors give &#39;updates&#39; about their unpublished, ongoing research?", "body": "<p>Why do some professors arrange meetings to give updates about their ongoing work?  The updates are certainly exciting, especially for the other people who have been in the lab for awhile and was involved in the work in some small way.  But these meetings are also open to visitors, and visiting professors and post docs come too.  Isn't there a fear of outsiders (or even insiders) scooping the ideas and beating them to publication?  Although I highly doubt that, but I'm curious to know.</p>\n", "pids": ["53e9b12ab7602d9703ba96d1"], "flag": 1}
{"question": "Does mindfulness meditation work for highly inattentive individuals?", "body": "<p>Mindfulness practice requires extensive concentration for a prolonged period of time (e.g., attending to breath/body sensation for above 5 minutes).  It is reasonable to assume that it might be challenging for people who are highly inattentive. However, mindfulness has been used as a health intervention for individuals with ADHD (with inattention as a symptom).</p>\n\n<p>One recent review with 9 studies (<a href=\"https://doi.org/10.1016/j.hkjot.2017.05.001\" rel=\"nofollow noreferrer\">Lee et al., 2017</a>) found that mindfulness is effective for adults with ADHD, yet it is</p>\n\n<blockquote>\n  <p>unclear whether mindfulness-based intervention is effective for children and adolescence with ADHD due to limited studies available and the limitations of the study design in the reviewed studies.</p>\n</blockquote>\n\n<p>What are the recent mindfulness studies involving children with ADHD? And is there any research on people with inattention only?</p>\n\n<p>References</p>\n\n<p>Lee, C. S., Ma, M. T., Ho, H. Y., Tsang, K. K., Zheng, Y. Y., &amp; Wu, Z. Y. (2017). The effectiveness of mindfulness-based intervention in attention on individuals with ADHD: A systematic review. <em>Hong Kong Journal of Occupational Therapy, 30</em>, 33-41. doi: <a href=\"https://doi.org/10.1016/j.hkjot.2017.05.001\" rel=\"nofollow noreferrer\">10.1016/j.hkjot.2017.05.001</a></p>\n", "pids": ["5c3de39ddf5b8c0b3ccbd2b5"], "flag": 1}
{"question": "Uses of the Brief Anxiety Scale", "body": "<p>I am currently completing my undergraduate research thesis on self-affirmations measured with anxiety. I am trying to see if the self-affirmation task reduces anxiety after. I found the Brief Anxiety Scale and am trying to find out what it is best used with, but my search of articles has not made the uses clear to me.</p>\n\n<p>For what is the scale best used? Are there different scales that might instead be recommended for my research?</p>\n\n<p>Thank you in advance to anyone who can provide assistance!</p>\n", "pids": ["53e99ffcb7602d97028df500", "55a4cbbb65ceb7cb02d88a96", "55a3fe7665ce5cd7b3bf922e"], "flag": 1}
{"question": "Is pleasure synonymous to positive reinforcement?", "body": "<p>I'm thinking about what pleasure is from the perspective of the <a href=\"https://en.wikipedia.org/wiki/Integrated_information_theory\" rel=\"nofollow noreferrer\">integrated information theory of consciousness</a>. As I understand it, according to the <a href=\"https://plato.stanford.edu/entries/emotion/#EvalTradAffeScieApprTheo\" rel=\"nofollow noreferrer\">appraisal theory of emotions</a>, the orientation on the good-bad spectrum is essential for every emotion. From the point of view of these theories, it seems pleasure should occur every time whenever a decision leads to a state evaluated as positive. Is this what modern research suggests or is there a better theory on what pleasure is information-wise?</p>\n<p>In other words, what is the algorithm of pleasure according to contemporary science?</p>\n", "pids": ["55a60e8e65cead59c833a2e2"], "flag": 1}
{"question": "Applications of Information Theory in Machine Learning", "body": "<p>How is information theory applied to machine learning, and in particular to deep learning, in practice? I'm more interested in concepts that yielded concrete innovations in ML, rather than theoretical constructions.</p>\n<p>Note that, I'm aware that basic concepts such as entropy is used for training decision trees, and so on. I'm looking for applications which use slightly more advanced concepts from information theory, whatever they are.</p>\n", "pids": ["5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "Get object&#39;s orientation or angle after object detection", "body": "<p>I'm trying to get a detected car's orientation when object detection is applied. For instance, when we apply object detection on a car and get a bounding box, is there any ways or methods to calculate where the heading is or the orientation or direction of the car (just 2D plane is fine)?</p>\n<p>Any thoughts or ideas would be helpful.</p>\n<p><a href=\"https://i.stack.imgur.com/km1Ey.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/km1Ey.png\" alt=\"enter image description here\" /></a></p>\n", "pids": ["5df0be543a55ac84bd7f48c4"], "flag": 1}
{"question": "Is there any real-time computer vision system that can learn to detect new objects of new classes?", "body": "<p>Suppose you have a ground plane and can use a stereo vision system to detect things that are possibly separate objects.</p>\n<p>Suppose also your robot or agent can attempt to pick up and move these objects around in real-time.</p>\n<p>Is there any current system in computer vision that allows new objects to be learned in real-time?</p>\n", "pids": ["5cede0f6da562983788d542d"], "flag": 1}
{"question": "Do peer reviewers receive any salary?", "body": "<p>Do academic peer reviewers receive any salary?\nIf yes, what is the annual average?</p>\n", "pids": ["56d818b5dabfae2eee842915"], "flag": 1}
{"question": "Does our consciousness die when we go to sleep or fall into a coma?", "body": "<p>I have sometimes wondered if our consciousness dies when we go to sleep at night or perhaps when we enter a deep coma, like from brain damage, for example.  When we wake, or are woken, a new consciousness is booted up with the memories of the previous consciousness, so that it gives the illusion of one continuous consciousness.   This question may be partly philosophical as well as scientific, because it looks at some of the assumptions about the nature of consciousness.</p>\n\n<p>A possibly unfair analogy might be to a computer, when its running it has a memory-set like a consciousness.  And if you shutdown and reboot the computer, then it can continue running as it did before, as if it had never been shut down.  However, once a computer is shut down, its largely inert, though I know there are unimportant edge cases exceptions to this.  The computer is effectively dead when its shut down, its ram has largely dispersed.  We can start the computer back up, but it will really be loading the ram from disk.  The original electrical activity that made up the 'consciousness' of the computer before it was rebooted is effectively dead.</p>\n\n<p><strong>How do we know we don't die when we go to sleep?</strong> I mean even if our consciousness doesn't wholly die, we may suffer a partial death of sorts. I could be wrong, but I believe its possible for victims of brain damage to show minimal neural activity.  Rarely, but occasionally some of these victims recover, but perhaps their brain has rebooted their mental ram (if you will). And they may not technically be the same consciousness who fell into the coma, but merely a copy of that consciousness reconstituted from data held in the brain.</p>\n\n<p>Surely plenty have considered this question, <strong>has there been any research?</strong>  Do we have any kind of answer to this question?</p>\n", "pids": ["57179e470cf2ed14891c19df"], "flag": 0}
{"question": "How does a GCN handle new input graphs?", "body": "<p>Quick questions to see whether I understand GCNs correctly.</p>\n<p>Is it correct that, if I have trained a GCN, it can take arbitrary graphs as input, assuming the feature size is the same?</p>\n<p>I can't seem to find explicit literature on this.</p>\n", "pids": ["5e0c6dcc3a55acc9707f378b"], "flag": 1}
{"question": "Aesthetic pleasure hormone or neurotransmitter", "body": "<p>When a human watched a beautiful painting, a beautiful animation, sees a beautiful nature scene what hormone or neurotransmitter is produced in the organism that he feels the aesthetic pleasure? </p>\n\n<p>Also is it the same chemical as when we hear a beautiful music?</p>\n\n<p>If there are many like for example dopamine, oxytocin and endorphin then which one is the main responsible for the pleasure? </p>\n", "pids": ["55a3ebcb65ce5cd7b3bcf85c"], "flag": 1}
{"question": "What is the relationship between fear and desire?", "body": "<p>Are fear and desire located on the opposite sides of a spectrum or are they more like filters/lenses through which one can look simultaneously?</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 1}
{"question": "How can I determine whether a video&#39;s frame is realistic (was recorded by a camera) or contains computer-generated graphics?", "body": "<p>Given a video, I'm trying to classify whether it is a graphical (computer-generated) or realistic scene. For instance, if it contains computer-generated graphics, credit, moving bugs, blue screen, etc. it will be computer-generated graphics, and if it is a realistic scene captured by camera, it will be a realistic scene.</p>\n<p>How can we achieve that with AI? Do we have any working solutions available?</p>\n<p>Some examples of graphical scenes:</p>\n<p><a href=\"https://i.stack.imgur.com/xiantm.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/xiantm.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/4TxE5m.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/4TxE5m.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/SxOUAm.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/SxOUAm.jpg\" alt=\"enter image description here\" /></a></p>\n", "pids": ["5c88d5c7e1cd8e620062e258", "5550415645ce0a409eb3a69e", "573696026e3b12023e516718"], "flag": 1}
{"question": "Has &quot;deep vs. wide&quot; been resolved?", "body": "<p>All else being equal, including total neuron count, I give the following definitions:</p>\n<ul>\n<li>wide is a parallel ensemble, where good chunks of the neurons have the same inputs because the inputs are shared and they have different outputs.</li>\n<li>deep is a series ensemble, where for the most part neurons have as input the output of other neurons and few inputs are shared.</li>\n</ul>\n<p>For CART ensembles the parallel (wide) ensemble is a random forest while the series (deep) ensemble is a gradient boosted machine.  For several years the GBM was the <a href=\"https://www.kdnuggets.com/2016/03/xgboost-implementing-winningest-kaggle-algorithm-spark-flink.html\" rel=\"nofollow noreferrer\">&quot;winningest&quot; on kaggle</a>.</p>\n<p>Is there a parallel of that applied to Neural networks?  Is there some reasonable measure that indicates whether deep outperforms wide when it comes to neural networks?  If I had the same count of weights to throw at a tough problem, all else being equal should they be applied more strongly in parallel or in series?</p>\n", "pids": ["5d04e8d7da56295d08daee44", "5d04e8d7da56295d08daee44"], "flag": 1}
{"question": "How to cite where names are not of [firstName lastName] form, in particular patronymic?", "body": "<p>In academia in the US, the dominant name format is [firstName lastName]. And in APA citation format you typically cite by referring to the last name. So e.g. if John Doe wrote a paper in 2014, you might cite it as <em>Doe (2014).</em></p>\n\n<p>More generally you'd cite by referring to the family name. So e.g. if the Chinese basketball player Yao Ming wrote a paper in 2014, you would cite it as <em>Yao (2014),</em> since <em>Yao</em> is his family name and <em>Ming</em> is his given name. But there is typically no confusion anyway, because when East Asians publish in Western academia, they simply give in to Western convention and reverse the order of their names. So Yao Ming would typically simply have his name printed as  Ming Yao. And so we're back to the [firstName lastName] format and there is no confusion.</p>\n\n<p>My question is: What about patronymics? E.g. if Osama bin Laden writes a paper in 2014, should he be cited as <em>Osama (2014)</em> or <em>bin Laden (2014)?</em> It seems that unlike with East Asians, people with patronymic names have been less inclined to give in to Western convention and reverse the order of their names. So his name would still appear as Osama bin Laden  on the title page. </p>\n\n<p>Suppose I notice that everyone simply cites his paper as <em>bin Laden (2014).</em> (Indeed, in the real world, this is how Western media outlets often refer to this historical figure, even though this makes as much sense as referring to George W. Bush as simply George.) If I want to cite this paper, should I simply follow what is now the convention and cite it as <em>bin Laden (2014),</em> even though this is mistaken? Or should I cite it as <em>Osama (2014),</em> at the risk of my peers having no idea which paper I am talking about? What is or should be the proper convention?</p>\n\n<p>Note that this 'problem' is not limited to Muslim names. Even in Europe there are e.g. <a href=\"http://en.wikipedia.org/wiki/Icelandic_name\">Icelandic names</a>. There are also some cultures where people go by a single given name (i.e. no last name/family name/surname) but which may sometimes be composed of more than one word (e.g. sometimes in Mongolia, Burma, South India, Indonesia).</p>\n", "pids": ["53e9bd5fb7602d97049f8be1"], "flag": 1}
{"question": "Is any of today&#39;s applied mathematics research in academia still done primarily on pencil and paper?", "body": "<p>Does there exist applied mathematics research that involves primarily pencil-to-paper work, without the use of computers?  Or, are computers quickly replacing everything that an applied mathematician can once do by hand / traditionally does by hand? </p>\n\n<p>Anything in academia in applied math research that computers <em>can't</em> do?  </p>\n\n<p>For instance, do PDE theorists use computers or strictly pencil and paper / chalk and chalkboard -- and leave the numerics of PDEs to numerical analysts instead?  Is there such a distinction, or is there instead always some sort of collaboration between the two types of applied mathematicians?</p>\n\n<p>Another example that I can think of is the work of probability theorists.</p>\n\n<p>Any insight to my very naive question would be greatly appreciated :)</p>\n\n<p>Thanks,</p>\n", "pids": ["53e9ac5bb7602d970362be63"], "flag": 1}
{"question": "What are the potential pitfalls of using non-Greek/non-European characters as symbol in scientific writing?", "body": "<p>So I am in a dilemma in that a recent publication literally has used up every (legible) character on <a href=\"https://artofproblemsolving.com/wiki/index.php/LaTeX:Symbols#Greek_Letters\" rel=\"noreferrer\">this page</a>. We have checked thoroughly and every single character is necessary and this many characters are unfortunately needed to avoid confusion (This is what happens when you try to combine several different theoretical areas together). We have also used up a bunch of symbols such as <a href=\"https://artofproblemsolving.com/wiki/index.php/LaTeX:Symbols#Finding_Other_Symbols\" rel=\"noreferrer\">stars or dots</a>. This question is not about how I should reduce the number of characters.</p>\n<p>So right now I am thinking of using characters from outside of the European family, such as Japanese characters (Hiragana/Katagana) or Korean or Chinese. Of course, provided that these characters are simple enough. Some candidates include ひ, と, ㅈ, ㄹ, し, 十. Some of these characters are quite suitable and have simple pronunciations, although we are not thinking of pronouncing them in presentations.</p>\n<p>But I have two concerns:</p>\n<ol>\n<li><p>most conferences and journals have a &quot;We only accept submission in English&quot; <a href=\"http://sacworkshop.org/SAC09/call_for_papers\" rel=\"noreferrer\">rule</a>: The submission must be written in English. Does this violate that policy?</p>\n</li>\n<li><p>does using these character violate some sort of implicit cultural norm in scientific writing and European/North American conferences so that we should avoid it?</p>\n</li>\n</ol>\n<p><strong>Update:</strong></p>\n<p>Thanks for all the feedback. But most seem to focus on what other fonts I should try to use instead. Just as a clarification, in my area it is highly not uncommon for the papers to use many many symbols. Here is a mild recent <a href=\"https://arxiv.org/pdf/2106.10513.pdf\" rel=\"noreferrer\">example</a> (not affiliated with these authors) and <a href=\"https://arxiv.org/pdf/2106.07079.pdf\" rel=\"noreferrer\">this one</a> I saw that made me go &quot;wow the notation is so nice!&quot; (again, not affiliated). These seem to be conference submissions (around 10 pages). For full submission it can go up to 20-40 pages. So as you can imagine a symbol problem quickly arises.</p>\n<p>I can't help if everything comes out like this. If you notice, it is easy find usage of thing such as $a^{i,j}_{k,l}$. k, and l are two agents from i and j graphs and a is just one possible variable out of many variables. So we are already making heavy use of super/subscripts. We use hats to denote estimated values so we are already there as well. We are also making use of mathcal, mathscr, mathbf, mathfrak, texttt, etc. to denote sets, graphs, matrices, special matrices and special conditions respectively. All extremely conventional usages.</p>\n", "pids": ["5e8da0c991e011f2de583784"], "flag": 1}
{"question": "What is cross-immunoreactivity, and how does it impact vaccine development?", "body": "<p>What I understand about cross-immunoreactivity is that the antibody induced by one specific antigen is also fairly effective against another antigen. How would this be used for vaccine development? </p>\n\n<p>Moreover, cross-immunoreactivity is related to epitopes. And how is how is cross-immunoreactivity defined among epitopes? Are variants of a specific virus hypervariable region some kinds of epitopes? What does antigenic convergence have to do with cross-immunoreactivity? Any comments or directions to further references are greatly appreciated.</p>\n", "pids": ["55a4992065ceb7cb02d33310"], "flag": 1}
{"question": "Spatial learning in microorganisms", "body": "<p>Has there ever been an experiment performed that demonstrated a form of 'spatial memory' in a unicellular organism?  I'm imagining something analogous to the classic 'rat in maze' experiments, but obviously on a much smaller scale.  Possibly even something as simple as following a concentration gradient, but choosing to go either upstream or downstream based on some sort of prior reward in a similar circumstance.</p>\n", "pids": ["53e9b96eb7602d970455c63f"], "flag": 1}
{"question": "What is the impact of sertraline on white blood cells?", "body": "<p><a href=\"http://rt.com/news/267310-white-blood-cells-death/\" rel=\"nofollow\">This simplified video and RT.com article</a> discusses how the mechanics of the death of a white blood cell can be useful as an \"alert mechanism\" to other white blood cells of an incoming infection.</p>\n\n<p>Also in the article it describes how this same notification mechanism might enable the transmission of certain types of pathogens and it has the following quote:</p>\n\n<blockquote>\n  <p>\"We found that a commonly used antidepressant can block this whole process and an antibiotic can promote this event,” said Ms Atkin-Smith.</p>\n</blockquote>\n\n<p>The <a href=\"http://www.nature.com/ncomms/2015/150615/ncomms8439/full/ncomms8439.html\" rel=\"nofollow\">full report is available here</a>.</p>\n\n<p>Can anyone explain, (with a summary in layman terms) the impact of Sertraline on white blood cells? </p>\n\n<p>Does taking Sertraline increase the risk of susceptibility to illness, or decrease it? </p>\n", "pids": ["55d06657696322190568bac1"], "flag": 1}
{"question": "Why cannot there be multiple sources for same species origins?", "body": "<p>We often associate Africa as the geographical location of the origin of humans. Why cannot there exist multiple geographic locations of origin (given same environmental conditions)? </p>\n\n<p>The same argument exists for other species as well. So what is the basis of the common ancestor (from single geographical location) theory?</p>\n\n<p>Please give me references so that I can read more on this subject. </p>\n", "pids": ["56d8189edabfae2eee8380fe"], "flag": 1}
{"question": "Are Markov Random Fields and Conditional Random Fields still used in computer vision?", "body": "<p>Back before deep learning, there were a lot of different attempts at computer vision. Some involved Conditional Random Fields and Markov Random Fields, which were both computationally difficult and hard to understand/implement.</p>\n<p>Are these areas still being developed in the computer vision domain? What was the end result of this line of study? I haven't seen any papers on this topic be cited in top-performing benchmarks, so I assume nobody cares about them anymore, but I wanted to ask.</p>\n", "pids": ["573696106e3b12023e522f0c", "58d82fced649053542fd7289", "57a4e921ac44365e35c98eb0"], "flag": 1}
{"question": "Naming convention of miRNAs", "body": "<p>I'm trying to understand naming convention of miRNAs. I've found the wikipedia article about it <a href=\"http://en.wikipedia.org/wiki/MicroRNA#Nomenclature/\">nomenclature</a> Based on it, I try to figure out what is <strong>hsa-let-7a</strong>. As far as I understood, hsa refers to human but I expected a \"<em>mir</em>\" or \"<em>miR</em>\" after hsa but there is a word \"<em>let</em>\" .So my question is that hsa-let-7a is a name for a single mature miRNA or is it a name of a miRNA family(if there exists such a thing) ?  </p>\n", "pids": ["55d0bf916963221905715290"], "flag": 1}
{"question": "Why are shallow networks so prevalent in RL?", "body": "<p>In deep learning, using more layers in a neural network adds the capacity to capture more features. In most RL papers, their experiments use a 2 layer neural network. <a href=\"https://arxiv.org/pdf/1711.06782\" rel=\"nofollow noreferrer\">Learning to Reset</a>, <a href=\"https://arxiv.org/pdf/1705.10528\" rel=\"nofollow noreferrer\">Constrained Policy Optimization</a>, <a href=\"https://arxiv.org/pdf/1705.08551\" rel=\"nofollow noreferrer\">Model-based RL with stability guarantees</a> just to name a few - these are papers I personally remember but there are definitely many others.</p>\n<p>I came across <a href=\"https://ai.stackexchange.com/questions/11539/is-reinforcement-learning-using-shallow-neural-networks-still-deep-reinforcement\">this question</a> whose answers generally agree that yes, RL using a shallow network is considered deep RL, but the reason for preference of shallow networks was not part of the question.</p>\n<p>In <a href=\"https://arxiv.org/pdf/1810.05017.pdf\" rel=\"nofollow noreferrer\">MetaMimic</a> (2018), the authors trained the largest neural net RL algorithm at the time (a residual net with 20 convolution layers) for one-shot imitation learning. The paper demonstrates that larger networks as policy approximators generalize better and represent many behaviours.</p>\n<p>So, why are shallow 2 layer networks so widely used?</p>\n", "pids": ["5f8ebe9591e01153024c4d99", "599c7971601a182cd263d94a"], "flag": 1}
{"question": "Correlation used as explanatory device in &#39;&#39;The neuroscience of Intelligence&#39;", "body": "<p>I am currently reading Dr. Richard Haier's book The Neuroscience of Intelligence. I have a base knowledge of statistics, but I am confused about the following extract from page 80 (chapter 2.4): </p>\n\n<blockquote>\n  <p>When correlations are computed in identical twins reared apart, the\n  correlation is  also one way to estimate heritability, so a\n  correlation of .70 indicates that 70% of the  variance in intelligence\n  is due to genetic factors and 30% is not.</p>\n</blockquote>\n\n<p>Is using correlation a valid way to estimate the heritability of a specific trait? I was under the impression that for a comparison of shared variance r² would have to be used, which would mean IQ is not 70% inherited, but only 49% (a huge difference!).</p>\n", "pids": ["55a6903565ce054aad6bebb2"], "flag": 1}
{"question": "Term for the tendency to relate events that occurred in proximity?", "body": "<p>What is the correct scientific term for the tendency to wrongfully relate arbitrary observations to a significant event, just because they occurred in temporal or spatial proximity?</p>\n<p>Most recently I have observed this error in a discussion about an unsolved killing, where a participant was quite sure that her observation of a black van in a far away town was related to the killing, for the single reason that it occurred around the same time.</p>\n", "pids": ["56d831aadabfae2eee2665ba"], "flag": 1}
{"question": "How does a PhD student make meaningful comments or suggestions regarding a professor&#39;s work?", "body": "<p>So <a href=\"https://academia.stackexchange.com/a/757/77\">bobthejoe said this</a>:</p>\n\n<blockquote>\n  <p>The PhD students I remember the most are the ones who came up to me\n  and made meaningful comments or suggestions regarding my work. They\n  get extra bonus points if in the middle of the night the next week\n  they offer more meaningful comments or suggestions.</p>\n</blockquote>\n\n<p>Here's the question though: how many PhD students actually manage to make meaningful comments or suggestions about a professor's work? And how often does the professor follow up and inform the student that those comments are helpful (rather than pretend that the comments are helpful as a matter of politeness)? And if the comments are implemented, does the professor ever notify the student?</p>\n\n<p>I'm saying this as someone who makes <em>a lot</em> of suggestions/comments to other people, but who can never be sure whether or not they find them helpful. Most suggestions seem to be discarded simply because it takes too much time/effort to implement them.</p>\n", "pids": ["53e99d36b7602d97025eef6f"], "flag": 1}
{"question": "How can a machine learning problem be reduced as a communication problem?", "body": "<p>I once heard that the problem of approximating an unknown function can be modeled as a communication problem. How is this possible? </p>\n", "pids": ["5550416145ce0a409eb3ac62"], "flag": 1}
{"question": "Is Orwellian Double-think Psychologically Possible?", "body": "<p>In George Orwell's <em>1984</em>, a great deal of space is devoted to explaining &quot;Double-think,&quot; part of The Party's method of &quot;reality control.&quot; Here's a particularly clear passage:</p>\n<blockquote>\n<p>Doublethink means the power of holding two contradictory beliefs in one's mind simultaneously, and accepting both of them. The Party intellectual knows in which direction his memories must be altered; he therefore knows that he is playing tricks with reality; but by the exercise of doublethink he also satisfies himself that reality is not violated. The process has to be conscious, or it would not be carried out with sufficient precision, but it also has to be unconscious, or it would bring with it a feeling of falsity and hence of guilt. Doublethink lies at the  very heart of Ingsoc, since the essential act of the Party is to use conscious deception while retaining the firmness of purpose that goes with complete honesty...</p>\n</blockquote>\n<p>Another really good passage describes the practice of doublethink. O'Brien, a member of the inner party, produces a photograph of some people who are supposed to have never existed. But then he destroys it.</p>\n<blockquote>\n<p>&quot;It exists!&quot; he [Winston, the protagonist] cried!</p>\n</blockquote>\n<blockquote>\n<p>&quot;No,&quot; said O'Brien... &quot;Ashes,&quot; he said. &quot;Not even identifiable ashes. Dust. It does not exist. It never existed.&quot;</p>\n</blockquote>\n<blockquote>\n<p>&quot;But it did exist! It does exist! It exists in memory. I remember it. You remember it.&quot;</p>\n</blockquote>\n<blockquote>\n<p>&quot;I do not remember it,&quot; said O'Brien.</p>\n</blockquote>\n<p>It's interesting (and terrifying), but I suspect it isn't possible.</p>\n<p>As I understand, in Freudian theory, repression is an unconscious process that happens to traumatic or unacceptable memories. That's clearly different from doublethink, even if it were possible (and there doesn't seem to be any evidence that it is.)</p>\n<p>Is doublethink actually possible? Are there any documented examples of it? Is there anything similar to it, possible or otherwise?</p>\n", "pids": ["55a58753612c6b12ab205815"], "flag": 1}
{"question": "Explain the difference in graphical patterns between discriminator fake loss and generator loss in GAN", "body": "<p>In GAN (generative adversarial networks), let us take &quot;binary cross-entropy&quot; as the loss function for discriminator <span class=\"math-container\">$$(overall \\; loss = -\\sum log(D(x_i)) -\\sum log(1-D(G(z_i))) $$</span>\n<span class=\"math-container\">$$ where \\; x_i = real \\; image \\; pixel \\; matrix$$</span>\n<span class=\"math-container\">$$ and \\; z_i = a \\; vector \\; from \\; latent \\; space$$</span>.\nLet us define discriminator real loss and fake loss:\n<span class=\"math-container\">$$ d_{fake \\; loss} = -\\sum log(1-D(G(Z)))$$</span>\n<span class=\"math-container\">$$ d_{real \\; loss} = -\\sum log(D(x))$$</span>\n<span class=\"math-container\">$$ d_{fake \\; loss} \\; implies \\; discriminator \\; loss \\; against \\; fake \\; images$$</span>\n<span class=\"math-container\">$$ d_{real \\; loss} \\; implies \\; discriminator \\; loss \\; against \\; real \\; images$$</span>\nGenerator Loss :\n<span class=\"math-container\">$$ g_{loss} = -\\sum log(D(G(z_i)))$$</span>\nSince the functions are similar, we should be expecting some similarity in graphical patterns (i.e since none of the functions are inherently oscillatory, I expect that if one comes out to be oscillatory, the other one should be the same as well). But, If you refer to chapter 10 of the book &quot;Generative Adversarial Networks with python by Jason Brownlee&quot;, we find some difference. The following are the graphs published in the book\n<a href=\"https://i.stack.imgur.com/KG6O1.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/KG6O1.png\" alt=\"Line plots for loss and accuracy for a stable GAN (1st GRAPH plots the losses)\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/5yPOF.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/5yPOF.png\" alt=\"Line plots for loss and accuracy for a stable GAN with mode collapse\" /></a></p>\n<p>Can anyone explain the difference in the plots between discriminator fake loss and generator loss (mathematically)?</p>\n", "pids": ["57a4e91aac44365e35c97d02", "58d82fced649053542fd7453"], "flag": 1}
{"question": "Proof for seemingly obvious statements in thesis?", "body": "<p>I'm currently writing a bachelor thesis in which there is a section that deals with the pros and cons of different data serialization formats. Since this is not the main focus of the thesis, I would like to limit the comparisons to include 2-3 of the most widely used formats - for instance; JSON and XML.</p>\n\n<p>I know from experience that JSON and XML are two of the most widely used formats for serializing data on the web, but how can I prove a statement like that? Does it need proof to be included as a boundary/limitation of the thesis? </p>\n", "pids": ["53e9b04eb7602d9703ab1718"], "flag": 1}
{"question": "Is there a training data capacity limit for AlphaZero (Chess)?", "body": "<p>In AlphaZero, we collect (<span class=\"math-container\">$s_t, \\pi_t, z_t$</span>) tuples from self-play, where <span class=\"math-container\">$s_t$</span> is the board state, <span class=\"math-container\">$\\pi_t$</span> is the policy, and <span class=\"math-container\">$z_t$</span> is the reward from winning/losing the game. In other DeepRL off-policy algorithms (I'm assuming here that AlphaZero is off-policy (?)) like DQN, we maintain a memory buffer (say, 1 million samples) and overwrite the buffer with newer samples if it's at capacity. Do we do the same for AlphaZero? Or do we continually add new samples without overwriting older ones? The latter option sounds very memory heavy, but I haven't read anywhere that older samples are overwritten.</p>\n", "pids": ["5a73cbcc17c44a0b3035f7b3"], "flag": 1}
{"question": "Is anyone here familiar with techniques and/or equipment for performing cerebrospinal fluid transfusions?", "body": "<p>I am a student at a University and we are discussing putting together a lab assessing the benefits that may be associated with cerebrospinal fluid (CSF) transfusions in Alzheimer's disease mice. So far it looks like from <a href=\"https://pubmed.ncbi.nlm.nih.gov/11552002/\" rel=\"nofollow noreferrer\">this paper</a> there may have existed a device at one time that could have been modified for our purposes. I contacted Infors AG and the representative believes this device to be out of production. Does anyone here know of anyone who is doing work with CSF transfusions? We are very eager to begin, especially myself and would greatly appreciate any leads as to literature available on this technique or biotech companies that may be able to provide the tools we seek.</p>\n", "pids": ["627c8c18116247000c3d7c38"], "flag": 1}
{"question": "What are some (bioinformatic) methods to characterize potentially novel gene transcripts?", "body": "<p>I am working with a few novel transcripts of genes- before I confirm their existence experimentally, I would like to perform some bioinformatic analysis. I have already considered coding potential, protein domain prediction, transcription factor binding sites, sequence homology, and RNA secondary structure (still a little unsure how to use this one). These transcripts were discovered using RNA-Seq. Are there any other elements of genes/confirmed transcripts that I should look for in the sequence of my transcripts and corresponding softwares? (I can find the software myself if necessary, but I have run out of characteristics to search for). I would like to characterize these transcripts structurally and functionally as completely as possible, including potential protein function, mRNA degradation, etc - some new features for what to look into would be appreciated. </p>\n", "pids": ["55a54ebb65ceb7cb02e7c201"], "flag": 1}
{"question": "What is the difference between a review paper and a research paper?", "body": "<p>I have been working on a review paper. After publication, how will it add on my academic research profile? When I will apply for MS or PHD admission, will it count as publication?</p>\n", "pids": ["619bad3f1c45e57ce9e5cce6"], "flag": 1}
{"question": "Why have international branch campuses?", "body": "<p>There are campuses in Malaysia belonging to the universities of <a href=\"http://www.southampton.ac.uk/my/\">Southampton</a>, <a href=\"http://www.nottingham.edu.my/index.aspx\">Nottingham</a> and <a href=\"http://www.reading.edu.my/\">Reading</a>.  There is a Mauritius branch belonging to <a href=\"https://www.aber.ac.uk/en/university/mauritius/\">Aberystwyth University</a>, whereas the <a href=\"https://www.timeshighereducation.com/news/wolverhampton-shut-down-mauritius-campus\">University of Wolverhampton has shut down its Mauritius campus</a>.  Newcastle University has a <a href=\"http://www.ncl.ac.uk/singapore/\">Singapore campus</a>.  There are many more examples of UK universities with campuses in Asia or Africa.</p>\n\n<p>Why do (some) universities based in the UK spend resources on establishing a campus on another continent?  Is it a form of developmental aid, to bring UK expertise to a spot where existing universities may be perceived to have less quality?  Or is there a different reason?</p>\n\n<p>I don't know if this is exclusive to the UK or if it also occurs with universities in other countries — I have not seen it anywhere else.</p>\n\n<p>The Wikipedia article <a href=\"https://en.wikipedia.org/wiki/International_branch_campus\">International branch campus</a> is not terribly informative.</p>\n", "pids": ["53e9b421b7602d9703f16bac"], "flag": 1}
{"question": "Has it ever happened that one paper&#39;s findings were contradicted by another?", "body": "<p>Since reviewers don't check the experimental results by trying to reproduce the experiment, is it possible for someone to submit a paper which basically says \"Method X was proposed in paper Y and according to them it improved performance by 15% as compared to baseline. However when we tried it, it didn't work so well (only 2% improvement). Hence we propose its modification which actually achieves 14% improvement as compared to baseline on the same train/test data.\"?</p>\n", "pids": ["55a4a13865ceb7cb02d4b42c", "55a4615665ce31bc8778c2fe"], "flag": 1}
{"question": "In attention models with multiple layers, are weight matrices shared across layers?", "body": "<p>In articles that describe neural architectures with multiple attention layers of the same form, are the weight matrices usually the same across the layers?  Consider as an example, &quot;Attention is all you need&quot;. The authors stack several layers of multi-head self-attention in which each layer has the same number of heads.  Each head <span class=\"math-container\">$i$</span> involves a trainable weight matrix <span class=\"math-container\">$W_{i}^{Q}$</span>.  There is no subscript, superscript, or any other indication that this matrix is different for each layer.  My questions is this: are there separate <span class=\"math-container\">$W_{i}^{Q}$</span> for layers <span class=\"math-container\">$1,2,3,...$</span> or is this a single matrix shared throughout layers?</p>\n<p>My intuition is that the authors of the paper wanted to cut down on notation, and that the matrices are different in different layers.  But I want to be sure I understand this, since I see the same kind of thing in many other papers as well.</p>\n", "pids": ["61ca12c15244ab9dcbe63505", "5db1765a3a55ac101c887e97"], "flag": 1}
{"question": "Model-based RL for time series data", "body": "<p>I have time-series data. When I take an action, it impacts the next state, because my action directly determines the next state, but it is not known what the impact is.</p>\n<p>To be concrete: I have <span class=\"math-container\">$X(t)$</span> and <span class=\"math-container\">$a(t-1)$</span>, where <span class=\"math-container\">$X(t)$</span> is n-dimensional time-series data and <span class=\"math-container\">$a(t)$</span> is 1-dimensional time-series data. At time <span class=\"math-container\">$t$</span>, they together represent the observation/state space. Also, at time <span class=\"math-container\">$t$</span>, the agent makes a decision about <span class=\"math-container\">$a(t)$</span>. This decision (action) <span class=\"math-container\">$a(t)$</span> directly defines the next state space <span class=\"math-container\">$X(t+1)$</span> and rewards, by some function <span class=\"math-container\">$f$</span> &amp; <span class=\"math-container\">$g$</span>, <span class=\"math-container\">$f(a(t), X(t)) = X(t+1)$</span> and <span class=\"math-container\">$g(a(t), X(t)) = R(t+1)$</span>.</p>\n<p>I have to estimate this impact, i.e. where I will end up (what will be the next state). I decided to use a model-based RL algorithm, because, from my knowledge, model-based RL does exactly this.</p>\n<p>Can you advise me on a good paper and Github code, to implement this project?</p>\n<p>As I noticed, there do not exist many works on Model-based RL.</p>\n", "pids": ["6076c50391e0113d72574435"], "flag": 1}
{"question": "Breaking an axis - is it ever a good idea?", "body": "<p>I know that using an origin other than 0 for numeric data is considered misleading. But for plots in academic publications, is it ever a good idea to break an axis so that patterns and outliers can be more easily seen?\nOr would you always try to find an alternative (e.g., using a logarithmic scale, faceting, using multiple plots with different scales)? I'm looking for a general rule of thumb.</p>\n", "pids": ["5fc6ad42e8bf8c1045e7343b"], "flag": 1}
{"question": "How to gather life-history traits data on bird species?", "body": "<p>I am looking for a data base of life history traits for bird species. Is there such data base? If not, what are your advice on how to collect those data? Is there a handy website that list characteristics of birds around the world? I started to gather those data using wikipedia (and the references anytime wikipedia actually have reference) but it is very cumbersome.</p>\n\n<p>The kind of data I am looking for are: </p>\n\n<ul>\n<li>Reproductive age</li>\n<li>Average lifespan</li>\n<li>Average gestation time</li>\n<li>Number of eggs per reproduction event</li>\n</ul>\n", "pids": ["565711c20cf20caa7d69721e"], "flag": 1}
{"question": "Can neuro-evolution methods be combined with A3C?", "body": "<p>As a amateur researcher and tinkerer, I've been reading up on neuro-evolution networks (e.g. NEAT) as well as the A3C RL approach presented by <a href=\"https://arxiv.org/pdf/1602.01783v1.pdf\" rel=\"nofollow noreferrer\">Mnih et al</a> and got to wondering if anyone has contemplated the merging of both these techniques.</p>\n\n<p>Is such an idea viable? Has it been tried? </p>\n\n<p>I'd be interested in any research in this area as it sounds like it could be compelling.</p>\n", "pids": ["5b67b46f17c44aac1c863092"], "flag": 1}
{"question": "When is a research question &quot;closed&quot;?", "body": "<p>I am in Computer Science. I read a <a href=\"http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&amp;arnumber=4553339&amp;contentType=Conference+Publications&amp;searchField%3DSearch_All%26queryText%3DA+brave+new+world+synchronization+games\">survey</a> today. The author gave such a good result by the end of the article that I think the research question can be called \"closed\": the result performance is ideal and I think the problem is not worth researching any more; future developers can simply use the algorithms proposed and things should be fine. However, the <strong>author of the survey</strong> did not say so -- they did not say that the problem is solved, nor did they said anything about future work.</p>\n\n<p>I believe (in this specific case), that the problem is solved:</p>\n\n<ol>\n<li>The research goal is to reduce network latency. By the time the survey was written (year 2008), the result latency was 100ms. With such latency, human users won't notice a network delay, because that only happens when the latency exceeds 150ms.</li>\n<li>The authors of the survey did not publish any paper on optimizing the algorithms after that survey.</li>\n</ol>\n\n<p>Does these mean that the problem is safely closed? If so, why didn't the survey authors say that? If not, why didn't they continue working on it? How would I know whether a research question is solved or not?</p>\n", "pids": ["53e99842b7602d97020708d2"], "flag": 1}
{"question": "What is MHC haplotype?", "body": "<p>What is MHC haplotype? I did check out the wiki article, but did not understand.\n<br><br>\n(I have not studied biology since last 8 years and now I am going through it because I need it for my research. So if someone can describe it in simple language it would be very helpful)</p>\n", "pids": ["5d00ce313a55ac2b2044b524", "5c711a39e1cd8e7ed65388f9"], "flag": 1}
{"question": "Evolution home experiment?", "body": "<p>If I were to take bakers yeast and put it in medium of minimal sugar(whatever quantity that would be) and rice(for a source of starch), could the yeast have a \"evolutionary leap\" and adapt to use the starch in its environment? I remember reading something similar in a report of E.coli bacteria and citrate adaption, under the heading:\n<a href=\"http://www.nature.com/news/2010/100217/full/463864a.html\"> <em>Catching evolution red-handed</em></a>.</p>\n\n<p>The passages in question are so:</p>\n\n<blockquote>\n  <p>\"Every night, the bacteria run out of the sugar glucose and go\n  dormant. The following day around noon, a researcher plunges a pipette\n  in and sucks up 1% of the culture to inoculate a fresh flask. <strong>Those\n  faster at gobbling up glucose will send more of their descendants to\n  the following day's pipette</strong> and, after a few weeks, descendants of the\n  fastest one will be the only ones transferred as the mutation 'sweeps'\n  to fixation.\"</p>\n</blockquote>\n\n<p>Under the heading: <em>The rise of Escherichia erlenmeyeri</em>, (bold emphasis mine).</p>\n\n<blockquote>\n  <p>\"One morning, at the turn of generation 33,127 according to the lab's\n  log book, a massive increase in turbidity was recorded on the vial\n  labelled Ara-3. <strong>The sugar-starved bacteria had suddenly 'discovered' a\n  vast new source of carbon by importing citrate, a pH buffer that had\n  been in the growth media all along,</strong> and it sent the population size\n  through the roof. \"</p>\n</blockquote>\n\n<p>So if I understand this correctly, there is evolution going on through the differential reproductive success of the bacteria, via their fitness which is affected by the glucose levels?</p>\n\n<p>This \"pressure\" caused a type of \"hopeful monster\" in the form of <em>Escherichia erlenmeyeri</em>, the bacteria that could metabolize citrate, in which it didnt have the means to do so before.</p>\n\n<p><strong>So then could I replicate this concept with baker's yeast and starch metabolism and hope for similar results hypothetically? Or am I misunderstanding this?</strong></p>\n", "pids": ["55a4e80f65ceb7cb02dba4c2"], "flag": 1}
{"question": "Neuroligins, neurexins and synaptic gaps", "body": "<p>Further to <a href=\"https://psychology.stackexchange.com/q/28966/7604\">Are all synapses &quot;gappy&quot;, and what exactly is in the gap?</a>, I found an open access article (<a href=\"https://doi.org/10.1371/journal.pone.0003542\" rel=\"nofollow noreferrer\">Biswas et al. 2008</a>) pointing out that</p>\n<blockquote>\n<p>Vertebrate studies show neuroligins and neurexins are binding partners in a trans-synaptic cell adhesion complex, implicated in human autism and mental retardation disorders.</p>\n</blockquote>\n<p>First of all, I looked more into what neuroligins and neurexins are in the abstract of <a href=\"https://doi.org/10.1016/B978-0-12-823672-7.00008-9\" rel=\"nofollow noreferrer\">https://doi.org/10.1016/B978-0-12-823672-7.00008-9</a> then skimming through the introduction of Biswas et al, the article points out that research implicates</p>\n<blockquote>\n<p>human neuroligins and neurexins in neuro-developmental psychiatric disorders where an imbalance in E/I ratio [excitatory/inhibitory ratio] is thought to occur. Numerous studies have localised mutations to <em>neuroligin 3</em> and <em>4</em> in families affected by autism, Aspergers syndrome and X-linked mental retardation [39]–[42]. The disease mutations in <em>neuroligin 3</em> and <em>4</em> lead to loss of neurexin binding, loss of synaptogenic capability and retention in the endoplasmic reticulum [43], [44]. Recent studies have also identified a high frequency of neurexin structural variants in families affected with autism and schizophrenia [45], [46].</p>\n</blockquote>\n<p>First of all, I'd like to be pointed in the direction of literature (where available) which indicates what neuro-developmental psychiatric disorders there are where an imbalance in E/I ratio is thought to occur.</p>\n<p>Are <a href=\"https://www.cdc.gov/ncbddd/autism/facts.html\" rel=\"nofollow noreferrer\">autism spectrum disorders</a> part of them?</p>\n<p>I am happy to separate the 2 following interrelated queries from this question if it would make the answer too long, but I also wonder, does the E/I imbalance cause the neuro-developmental psychiatric disorders or do the neuro-developmental psychiatric disorders cause the E/I imbalance? If E/I imbalances are involved in autism, is the imbalance towards excitory or inhibitory, and does the imbalance get worse?</p>\n<h2>Reference</h2>\n<p>Biswas, S., Russell, R. J., Jackson, C. J., Vidovic, M., Ganeshina, O., Oakeshott, J. G., &amp; Claudianos, C. (2008). Bridging the synaptic gap: neuroligins and neurexin I in Apis mellifera. <em>Plos one, 3</em>(10), e3542. <a href=\"https://doi.org/10.1371/journal.pone.0003542\" rel=\"nofollow noreferrer\">https://doi.org/10.1371/journal.pone.0003542</a></p>\n", "pids": ["56d83d86dabfae2eee6e8335", "5c756763f56def9798174938", "562103090cf276a3be15e8a3", "53e9af75b7602d97039b749b", "55a3826f65ce5cd7b3ad25b1", "5ee0b1ca9fced0a24b47306c"], "flag": 1}
{"question": "Can we use transformers for audio classification tasks?", "body": "<p>Since transformers are good at processing sequential data, can we also use them for audio classification problems (same as RNNs)?</p>\n", "pids": ["5e16fa233a55acac60fd36dd", "5ce2d08dced107d4c638f8be", "60717b3491e0117fe07c6dac"], "flag": 1}
{"question": "Simple DQN too slow to train", "body": "<p>I have been trying to solve the OpenAI lunar lander game with a DQN taken from this paper</p>\n<p><a href=\"https://arxiv.org/pdf/2006.04938v2.pdf\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/2006.04938v2.pdf</a></p>\n<p>The issue is that it takes 12 hours to train 50 episodes so something must be wrong.</p>\n<pre><code>import os\nimport random\nimport gym\nimport numpy as np\nfrom collections import deque\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import Model\n\nENV_NAME = &quot;LunarLander-v2&quot;\n\nDISCOUNT_FACTOR = 0.9\nLEARNING_RATE = 0.001\n\nMEMORY_SIZE = 2000\nTRAIN_START = 1000\nBATCH_SIZE = 24\n\nEXPLORATION_MAX = 1.0\nEXPLORATION_MIN = 0.01\nEXPLORATION_DECAY = 0.99\n\nclass MyModel(Model):\n    def __init__(self, input_size, output_size):\n        super(MyModel, self).__init__()\n        self.d1 = Dense(128, input_shape=(input_size,), activation=&quot;relu&quot;)\n        self.d2 = Dense(128, activation=&quot;relu&quot;)\n        self.d3 = Dense(output_size, activation=&quot;linear&quot;)\n\n    def call(self, x):\n        x = self.d1(x)\n        x = self.d2(x)\n        return self.d3(x)\n\nclass DQNSolver():\n\n    def __init__(self, observation_space, action_space):\n        self.exploration_rate = EXPLORATION_MAX\n\n        self.action_space = action_space\n        self.memory = deque(maxlen=MEMORY_SIZE)\n\n        self.model = MyModel(observation_space,action_space)\n        self.model.compile(loss=&quot;mse&quot;, optimizer=Adam(lr=LEARNING_RATE))\n\n    def remember(self, state, action, reward, next_state, done):\n        self.memory.append((state, action, reward, next_state, done))\n\n    def act(self, state):\n        if np.random.rand() &lt; self.exploration_rate:\n            return random.randrange(self.action_space)\n        q_values = self.model.predict(state)\n        return np.argmax(q_values[0])\n\n    def experience_replay(self):\n        if len(self.memory) &lt; BATCH_SIZE:\n            return\n        batch = random.sample(self.memory, BATCH_SIZE)\n        state_batch, q_values_batch = [], []\n        for state, action, reward, state_next, terminal in batch:\n            # q-value prediction for a given state\n            q_values_cs = self.model.predict(state)\n            # target q-value\n            max_q_value_ns = np.amax(self.model.predict(state_next)[0])\n            # correction on the Q value for the action used\n            if terminal:\n                q_values_cs[0][action] = reward\n            else:\n                q_values_cs[0][action] = reward + DISCOUNT_FACTOR * max_q_value_ns\n            state_batch.append(state[0])\n            q_values_batch.append(q_values_cs[0])\n        # train the Q network\n        self.model.fit(np.array(state_batch),\n                        np.array(q_values_batch),\n                        batch_size = BATCH_SIZE,\n                        epochs = 1, verbose = 0)\n        self.exploration_rate *= EXPLORATION_DECAY\n        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)\n\ndef lunar_lander():\n    env = gym.make(ENV_NAME)\n    observation_space = env.observation_space.shape[0]\n    action_space = env.action_space.n\n    dqn_solver = DQNSolver(observation_space, action_space)\n    episode = 0\n    print(&quot;Running&quot;)\n    while True:\n        episode += 1\n        state = env.reset()\n        state = np.reshape(state, [1, observation_space])\n        scores = []\n        score = 0\n        while True:\n            action = dqn_solver.act(state)\n            state_next, reward, terminal, _ = env.step(action)\n            state_next = np.reshape(state_next, [1, observation_space])\n            dqn_solver.remember(state, action, reward, state_next, terminal)\n            dqn_solver.experience_replay()\n            state = state_next\n            score += reward\n            if terminal:\n                print(&quot;Episode: &quot; + str(episode) + &quot;, exploration: &quot; + str(dqn_solver.exploration_rate) + &quot;, score: &quot; + str(score))\n                scores.append(score)\n                break\n        if np.mean(scores[-min(100, len(scores)):]) &gt;= 195:\n            print(&quot;Problem is solved in {} episodes.&quot;.format(episode))\n            break\n    env.close\nif __name__ == &quot;__main__&quot;:\n    lunar_lander()\n</code></pre>\n<p>Here are the logs</p>\n<pre><code>root@b11438e3d3e8:~# /usr/bin/python3 /root/test.py\n2021-01-03 13:42:38.055593: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n2021-01-03 13:42:39.338231: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n2021-01-03 13:42:39.368192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-01-03 13:42:39.368693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce GTX 1080 computeCapability: 6.1\ncoreClock: 1.8095GHz coreCount: 20 deviceMemorySize: 7.92GiB deviceMemoryBandwidth: 298.32GiB/s\n2021-01-03 13:42:39.368729: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n2021-01-03 13:42:39.370269: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n2021-01-03 13:42:39.371430: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n2021-01-03 13:42:39.371704: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n2021-01-03 13:42:39.373318: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n2021-01-03 13:42:39.374243: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n2021-01-03 13:42:39.377939: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n2021-01-03 13:42:39.378118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-01-03 13:42:39.378702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-01-03 13:42:39.379127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n2021-01-03 13:42:39.386525: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3411185000 Hz\n2021-01-03 13:42:39.386867: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4fb44c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2021-01-03 13:42:39.386891: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n2021-01-03 13:42:39.498097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-01-03 13:42:39.498786: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4fdf030 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n2021-01-03 13:42:39.498814: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1\n2021-01-03 13:42:39.498987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-01-03 13:42:39.499416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \npciBusID: 0000:01:00.0 name: GeForce GTX 1080 computeCapability: 6.1\ncoreClock: 1.8095GHz coreCount: 20 deviceMemorySize: 7.92GiB deviceMemoryBandwidth: 298.32GiB/s\n2021-01-03 13:42:39.499448: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n2021-01-03 13:42:39.499483: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n2021-01-03 13:42:39.499504: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n2021-01-03 13:42:39.499523: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n2021-01-03 13:42:39.499543: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n2021-01-03 13:42:39.499562: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n2021-01-03 13:42:39.499581: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n2021-01-03 13:42:39.499643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-01-03 13:42:39.500113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-01-03 13:42:39.500730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n2021-01-03 13:42:39.500772: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n2021-01-03 13:42:39.915228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-01-03 13:42:39.915298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n2021-01-03 13:42:39.915322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n2021-01-03 13:42:39.915568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-01-03 13:42:39.916104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-01-03 13:42:39.916555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6668 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\nRunning\n2021-01-03 13:42:40.267699: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n</code></pre>\n<p>This is the GPU stats</p>\n<pre><code>+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 450.66       Driver Version: 450.66       CUDA Version: 11.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1080    Off  | 00000000:01:00.0  On |                  N/A |\n|  0%   53C    P2    46W / 198W |   7718MiB /  8111MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n</code></pre>\n<p>As you can see, TensorFlow does not compute on the GPU but reserves the memory so I'm assuming it's because the inputs of the neural networks are too small and it uses the CPU instead.</p>\n<p>To make sure the GPU was installed properly, I ran a sample from their documentation and it uses the GPU.</p>\n<p>Is it an issue with the algorithm or the code? Is there a way to utilize the GPU in this case?</p>\n<p>Thanks!</p>\n", "pids": ["5736960b6e3b12023e51e3ea"], "flag": 1}
{"question": "Is there a place to review journals or conferences?", "body": "<p>There are plenty of journals and conferences in my research area. And there are things we could look up in advance, like impact factor, journal rank and so on. </p>\n\n<p>But I would like to find a place where I could put my <strong>personal experience</strong> with the journal (or conference). </p>\n\n<p>For instance, in Amazon the customers can review and criticize the books they read. In my country there is a site where you can complaint about any company that failed to satisfy the customer (a flight company, a magazine, a bank, etc). </p>\n\n<p>One could argue that this would be unfair to the people that invest their time as editors or reviewers, but in my opinion it is a <strong>two-way relationship</strong>. Things like waiting one year without an answer from editors, poor review or evasive answers, is a disrespect to a research group who invests a lot of time as well.</p>\n\n<p>So, <strong>is there a place where one could respectfully give a review and share their experience with a journal or conference?</strong></p>\n", "pids": ["55a6c40065ce054aad74b53c"], "flag": 1}
{"question": "Father with mutated mtDNA- why isn&#39;t his offspring at risk?", "body": "<p>Mothers transmit their mitochondria (and therefore mtDNA) to their offspring and fathers don't. Lets assume that father had a mutation of the gene that encodes mtDNA, would then be his offspring at risk? Why?</p>\n\n<p>I also found the following statement:\n\"The current genetic advice is that fathers with mtDNA mutations are at no risk of transmitting the defect to their offspring.\" </p>\n\n<p>How can that be true? Is it because of gene silencing? </p>\n\n<p>Thank you in advance!</p>\n", "pids": ["53e99940b7602d970217e4d6"], "flag": 1}
{"question": "Is Insulin-Glucose dynamic Lotka-Volterra?", "body": "<p>From Wikipedia:</p>\n\n<p>The Lotka–Volterra equations, also known as the predator–prey equations, are a pair of first-order, non-linear, differential equations frequently used to describe the dynamics of biological systems in which two species interact, one as a predator and the other as prey. The populations change through time according to the pair of equations:</p>\n\n<p>\\begin{align}\n\\frac{dx}{dt} = \\alpha x - \\beta x y \\\\\n\\frac{dy}{dt} = \\delta x y  - \\gamma y\n\\end{align}</p>\n\n<p><a src=\"https://i.stack.imgur.com/Ocuoy.png\" alt=\"enter image description here\"></p>\n\n<p>This looks very similar to how Insulin and Glucose interact with each other in the body. \n<a src=\"https://i.stack.imgur.com/V3jq2.png\" alt=\"enter image description here\"></p>\n\n<p>Glucose uptake release insulin and glucagon offsets the effect of insulin through glycogenesis.</p>\n\n<p>Can the Glucose-Insulin dynamic be described as Lotka Volterra?</p>\n", "pids": ["55a542e065ceb7cb02e62325", "55a54e8565ceb7cb02e7b0cc"], "flag": 1}
{"question": "Cognitive overtraining syndrome", "body": "<p>Since at least the late 80's, <strong>overtraining syndrome</strong> has been extensively studied and discussed in the field of sport medicine. It is know considered as an established entity, yet its pathophysiology remains unclear according to many authors (see for example <a href=\"https://doi.org/10.1249/JSR.0000000000000027\" rel=\"nofollow noreferrer\">the following review</a>).</p>\n<p>Overtraining syndrome essentially consists in a decrease in mood and physical performance occurring when an athlete fails to cope with high training load, despite adequate rest. In this type of situations, athlete's performance may even decrease, compared with their pre-overtraining level. Decrease in the training load is central in the management of the syndrome.</p>\n<p>What strikes me is how this description could also apply to the form of cognitive exhaustion that many students experience during their curriculum. Anyone who has engaged in demanding studies has already felt exhausted, cognitively impaired and depressed during the most difficult times of the year, despite taking enough rest.\nThis could suggest that there exists a form of &quot;cognitive overtraining syndrome&quot;, but I cannot find any material dealing with the subject.</p>\n<p><strong>Has &quot;cognitive overtraining syndrome&quot; ever been identified as such?</strong> If so, how extensively has it been studied ?<br>\nMany thanks in advance.</p>\n", "pids": ["5c0f791ada562944ac759c4c"], "flag": 1}
{"question": "Is high metabolism linked to high evolutionary turnover?", "body": "<p>I recently read <em>The Dinosaur Heresies</em> by Robert T. Bakker, a 1986 popular science book presenting arguments for an active lifestyle and high metabolic rate in dinosaurs.</p>\n\n<p>One of the arguments that Bakker presents relates to the pattern of species and genera in the fossil record over time.  He states that \"warm-blooded\" animals (i.e. animals with high metabolic rates) are expected to have higher turnover of taxa and faster rates of diversification.  Dinosaurs have high species and genus turnover and rapid diversification, which Bakker interprets as evidence for a high metabolism.</p>\n\n<p>This argument rests on the claim that high metabolism is correlated with high evolutionary turnover.  Setting dinosaur physiology aside, I wonder how reliable the underlying assumption really is.</p>\n\n<p>Is there good evidence that metabolism and evolutionary rates are causally linked, perhaps due to the ecological strategies that warm-blooded animals tend to adopt?</p>\n", "pids": ["56d8187bdabfae2eee825ebd"], "flag": 1}
{"question": "In this implementation of pix2pix, why are the weights for the discriminator and generator losses set to 1 and 100 respectively?", "body": "<p>I am working on a <a href=\"https://arxiv.org/abs/1611.07004\" rel=\"nofollow noreferrer\">pix2pix GAN model</a> that was inspired by the code in this <a href=\"https://github.com/eriklindernoren/Keras-GAN/blob/master/pix2pix/pix2pix.py\" rel=\"nofollow noreferrer\">Github repository</a>. The original code is working and I have already customized most of the code for my needs. However, there is one part I am unable to understand.</p>\n<p>The pix2pix GAN is a conditional GAN network that takes an image as a condition and outputs a modified image - such as blurry to clear, facades to buildings, filling up cut out part of an image, etc. The combined model thus takes as input a conditional image, the discriminator compares it with the dummy matrix named valid or fake, containing 0s or 1s according to validity (0 for generated samples, 1 for real samples). The generator loss is according to similarity with real sample + discriminator. The following code corresponds to what I told:</p>\n<pre><code>self.combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\nself.combined.compile(loss=['mse', 'mae'],\n                      loss_weights=[1, 100],\n                      optimizer=optimizer)\n</code></pre>\n<p>The losses are thus set as MSE for discriminator output and MAE for generator. That seems to be OK, but I can not understand why the implementation uses 1 and 100 for the weights of the discriminator and generator losses, respectively, which seems to imply that the discriminator loss is 100 times lower than the loss of the generator. I couldn't find the reason in the original article. Are my understandings of the GAN incorrect?</p>\n<p>Disclaimer: I have posted this question on <a href=\"https://stats.stackexchange.com/q/504673/82135\">Stats SE</a>, but have no luck with answers. Maybe it is more suitable for AI.</p>\n", "pids": ["58d82fced649053542fd7289"], "flag": 1}
{"question": "Cases of plagiarism in mathematics", "body": "<p>Are there known cases of plagiarism in mathematics? The writing practices in mathematics are clearly different from the writing practices in the humanities. In the latter area I roughly know how to characterize plagiarism because examples are known. But I do not know how plagiarism is possible in mathematics, except for blunt copies of text. </p>\n\n<p>Do you know about examples how plagiarism in mathematics looks like?</p>\n", "pids": ["53e99d3db7602d97025f2998"], "flag": 1}
{"question": "Is psychology an art or work?", "body": "<p>Some are born psychologists and they have passion towards it unlike some people who just work to earn money on it.</p>\n\n<p>The people who just do the same as work, will they satisfy the people with the care which is the prime importance, and is the real burden of talking to the patients concealed?</p>\n", "pids": ["55a3eb722401c6de3b7a01bb", "56604b920cf2dab45b564c6c", "53e9b6dbb7602d9704269b47"], "flag": 1}
{"question": "How is greed different from compulsion?", "body": "<p>I want to learn how is human <strong>greed</strong> different from <strong>compulsion</strong> in psychology? Which one is intentional and which one is unintentional? If it makes sense at all? One of the lecturers in our school mentioned that greed is more intentional, whereas compulsion is more an unintentional attribute of the mind. I appreciate any comments or helps in distinguishing these two. Thank you</p>\n<p>According to the Cambridge dictionary:</p>\n<p><strong>Greed</strong>: a very strong <strong>wish</strong> to continuously get more of something, especially food or money</p>\n<p><strong>Compulsion</strong>: a very strong <strong>feeling</strong> of wanting to do something repeatedly that is difficult to control</p>\n<p>But I don't know if it is technically sound or not?</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 1}
{"question": "Training a classifier on different datasets with different image conditions for different labels causes the model to infer using the background", "body": "<p>I have an interesting problem related to training the model on two different datasets for the target feature on images taken on different conditions, which might affect the model's ability to generalize.</p>\n<p>To explain I will give examples of images from the two different datasets.</p>\n<p>Dataset 1 sample image:</p>\n<p><a href=\"https://i.stack.imgur.com/lkduq.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/lkduq.png\" alt=\"enter image description here\" /></a></p>\n<p>Dataset 2 sample image:</p>\n<p><a href=\"https://i.stack.imgur.com/wy9LN.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/wy9LN.png\" alt=\"[Dataset 2 sample image:2\" /></a></p>\n<p>As you see the images are captured in two completely different conditions. I am afraid that the model will infer from the background information that it shouldn't use to predict the plant diseases, what makes the problem worse is that some plant diseases only exist in one dataset and not the other, if all the diseases are contained in both datasets then I wouldn't think there would be a problem.</p>\n<p>I am assuming I need a way to unify the background by somehow detecting the leaf pixels in the images and unifying the background in a way that makes the model focuses on the important features.</p>\n<p>I've tried some segmentation methods but the methods I tried don't always give desirable results for all the images.</p>\n<p>What is the recommended approach here? All help is appreciated</p>\n<p>Further explanation of the problem.</p>\n<p>Ok so I will explain one more thing, my model on the two datasets works fine when training and validating, It got a 94% accuracy.</p>\n<p>The problem is, even though the model performs well on the datasets I have, I am afraid that when I use the model on real-life conditions (say someone capturing an image with their phone) the model will be heavily biased towards predicting labels in the second dataset (the one with actual background) since the background is similar and it somehow associated the background with the inference process.</p>\n<p>I have tried downloading a leaf image of a label that is contained on the first dataset ( the one with the white background), where the image had a real-life background, the model as expected failed to predict the correct label and predicted a label contained in the second dataset, I am assuming it was due to the background. I have tried this experiment multiple times, and the model consistently failed in similar scenarios</p>\n<p>I used some Interpretability techniques as well to visualize the important pixels and it seems like the model is using the background for inference, but I am not an expert in interpreting these graphs so I am not 100% sure.</p>\n<p><a href=\"https://i.stack.imgur.com/ueZvC.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/ueZvC.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/1To4R.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/1To4R.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/IMIQw.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/IMIQw.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/vzNcl.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/vzNcl.png\" alt=\"enter image description here\" /></a></p>\n", "pids": ["5a73cbcc17c44a0b3035f7fc", "5bdc31b817c44a1f58a0c7bf"], "flag": 1}
{"question": "Are there free DOI generation services?", "body": "<p>Crossref, e.g., charges thousands of dollars to assign DOIs, but are there any free DOI registration services? In other words: Is there a free service that will generate DOIs for me?</p>\n", "pids": ["5f8a083edb0c4ff231649144"], "flag": 1}
{"question": "littering more often in dirty places?", "body": "<p>I'm now doing some city management related research and wondering about the idea of high crime areas. Well, the above phrase is a bit extreme. Say, littering, will this kind of behavior occur more often in areas that is already dirty and has tons of rubbish which should not be there? I believe so, however I searched things like littering, wrong parking and etc. on the internet but mostly news or policy. I'm looking for a scientific theory behind the phenomena and thinking of environmental criminology which I konw nothing about.</p>\n<p>Any help will be appreciated. New to this site, if anything inapproporiate or unclear, please let me know.</p>\n", "pids": ["5ce2d166ced107d4c64242ef"], "flag": 1}
{"question": "Where am I supposed to report a broken DOI?", "body": "<p>Where am I supposed to report a broken DOI? To <a href=\"https://www.doi.org/\" rel=\"noreferrer\">https://www.doi.org/</a>, to the  DOI registration agency that issued the DOI, to whoever is responsible for the website to which the DOI points to, or to somebody else?</p>\n\n<p>For example, <a href=\"http://dx.doi.org/10.1016/0364-0213(90)90002-E\" rel=\"noreferrer\">http://dx.doi.org/10.1016/0364-0213(90)90002-E</a> is 404:</p>\n\n<p><a href=\"https://i.stack.imgur.com/Bx8kB.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/Bx8kB.png\" alt=\"enter image description here\"></a></p>\n", "pids": ["5f37b4099fced0a24b345238"], "flag": 1}
{"question": "Is there evidence to suggest that nutrients in vitamin capsules are not as readily absorbed as the same nutrients in whole foods?", "body": "<p>I recently fell ill with a cold, and began to take a vitamin C capsule each day to help my immune system. When I noticed no change in my condition, I began to incorporate an abundance of citrus into my diet instead of taking the capsules. When I ate the citrus my condition began to improve markedly. </p>\n\n<p>The ingredients listed by the vitamin manufacturer are:</p>\n\n<ul>\n<li>Ascorbic Cellulose Gel</li>\n<li>Hydroxypropyl Cellulose</li>\n<li>Croscarmellose Sodium</li>\n<li>Stearic Acid</li>\n<li>Magnesium Stearate</li>\n<li>Silicon Dioxide</li>\n</ul>\n\n<p>Not excluding the possibility of coincidence, I was was intrigued. Has evidence been published to suggest that nutrients in whole foods like vitamin C in citrus fruits are more readily utilized in the body than nutrients in vitamin capsules? </p>\n", "pids": ["6217d3fe5aee126c0f1b1ba8"], "flag": 1}
{"question": "Why do we need to have two heads in D3QN to obtain value and advantage separately, if V is the average of Q values?", "body": "<p>I have two questions on the Dueling DQN paper. <strong>First</strong>, I have an issue on understanding the identifiability that Dueling DQN paper mentions:</p>\n<p><a href=\"https://i.stack.imgur.com/QDXyK.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/QDXyK.png\" alt=\"enter image description here\" /></a></p>\n<p>Here is my question: If we have given Q-values <span class=\"math-container\">$Q(s, a; \\theta)$</span> for all actions, I assume we can get value for state <span class=\"math-container\">$s$</span> by:</p>\n<p><span class=\"math-container\">$$V(s) = \\frac {1} {|Q|} \\sum_{a \\in \\mathcal{Q}} Q(s, a; \\theta)$$</span>\nand the advantage by:\n<span class=\"math-container\">$$A(s,a) = Q(s, a; \\theta) - V(s), ~~~ \\forall ~a ~in ~\\mathcal{A}(s)$$</span></p>\n<p>in which <span class=\"math-container\">$\\mathcal{A}(s)$</span> is the action space for state <span class=\"math-container\">$s$</span>. If this is correct, why do we need to have two heads in the network to obtain value and advantage separately?</p>\n<p>and then obtain Q-value using</p>\n<p><span class=\"math-container\">$$Q(s, a; \\theta, \\alpha, \\beta) = V(s; \\theta, \\beta) + \\left( A(s, a; \\theta, \\alpha) - \\max_{a' \\in | \\mathcal{A} |} A(s, a'; \\theta, \\alpha) \\right). \\tag{8}$$</span></p>\n<p>or\n<span class=\"math-container\">$$Q(s, a; \\theta, \\alpha, \\beta) = V (s; \\theta, \\beta) + \\left( A(s, a; \\theta, \\alpha) − \\frac {1} {|A|} \\sum_{a' \\in \\mathcal{A}} A(s, a'; \\theta, \\alpha) \\right). \\tag{9}$$</span></p>\n<p>Am I missing something?</p>\n<p>My <strong>second</strong> question is why Dueling DQN does not use the target network as it is used in the DQN paper?</p>\n", "pids": ["5736960b6e3b12023e51e3ea"], "flag": 1}
{"question": "Keeping academic credit on work with human rights impacts but fearing repressive regime retaliations", "body": "<p>I am from a country controlled by a repressive regime. I was able to leave the country and continue my academic activity in a top US university. Most of my work is focused on equality, human rights and distribution of resources. Until now, I couldn't publish using my name. Always ends up collaborating on different projects but without being an author (this is my request and other co-authors are just respecting my wish). </p>\n\n<p>Not all my works are in those themes but this is the field of research where I think I could contribute the most, and feel like I am achieving something. </p>\n\n<p>I was arrested by my government (kidnapped and tortured for 5 months) before leaving the country. Arrested for humanitarian activities, ended up tried by court-martial and then terrorism court, while I am a civilian. This was the one reason for me to focus on those issues. I fear that if I go public this regime may arrest my family members and/or confiscate my properties.   </p>\n\n<p>Is there a way for academics to publish (in peer reviewed journals) and do research while earning credit for their work without using their real names? Or at least a way to prevent their identity from going public ? </p>\n\n<p>I think that in academia there are so many ways depending on personal identity to thrive. I have this negative feeling that there is no way to advance professionally without using my personal identity. I do not know how to do it, but it is still early to make final judgments. </p>\n", "pids": ["56d89685dabfae2eee13976d"], "flag": 1}
{"question": "Is it advisable to upload your PhD thesis on Biorxiv?", "body": "<p>The university theses repository is not indexed in the main scientific literature search engines. This issue makes finding a thesis difficult, and it's a problem especially because after PhD many are looking for a postdoc position.</p>\n\n<p>Is it a good idea to upload a biology related PhD thesis on Biorxiv.org?</p>\n\n<p>Does Biorxiv.org allow it?\nIs is legal on the copyright side?\nAre there any drawbacks?</p>\n", "pids": ["599c77ef601a182cd258bfb5"], "flag": 1}
{"question": "Why is the DNA helix anti-parallel?", "body": "<p>Why is it that DNA strands are running in anti-parallel fashion? Given the chemical base-pairing, they could have been parallel just as well.</p>\n", "pids": ["59867fb50cf2a40728961190"], "flag": 1}
{"question": "Optimum Discriminator for label smoothed GAN", "body": "<p>I was reading the paper called <a href=\"https://arxiv.org/pdf/1606.03498.pdf\" rel=\"nofollow noreferrer\"><em>Improved Techniques for Training GANs</em></a>. And, in the one-sided label smoothing part, they said that optimum discriminator with label smoothing is</p>\n<p><span class=\"math-container\">$$ D^*(x)=\\frac{\\alpha \\cdot p_{data}(x) + \\beta \\cdot p_{model}(x)}{p_{data}(x) + p_{model}(x)}$$</span></p>\n<p>I could not understand where this is come from. How did we get this result?</p>\n<p>Note: By the way, I knew how to find optimal discriminator in vanilla GAN i.e.\n<span class=\"math-container\">$$ D^*(x) = \\frac{p_{r}(x)}{p_{r}(x) + p_g(x)} $$</span></p>\n", "pids": ["5736960e6e3b12023e520c34", "58d82fcbd649053542fd61ce"], "flag": 1}
{"question": "Is there a convention on the order of multiplication of the weights with the inputs in neural nets?", "body": "<p>Is there a convention on how the input data and the weights are multiplied? The input data can be anything, including the result from the previous layers.</p>\n<p>There are two options:</p>\n<p>Option 1:</p>\n<p><span class=\"math-container\">$$\\begin{bmatrix}i_1 &amp; i_2\\end{bmatrix} \\times \\begin{bmatrix} w_1 &amp; w_2 &amp; w_3\\\\w_4 &amp; w_5 &amp; w_6\\end{bmatrix} = \\begin{bmatrix}i_1*w_1 + i_2*w_4 &amp; i_1*w_2+i_2*w_5 &amp;i_1*w_3+i_2*w_6\\end{bmatrix}$$</span></p>\n<p>Option 2:</p>\n<p><span class=\"math-container\">$$\\begin{bmatrix} w_1 &amp; w_4\\\\ w_2 &amp; w_5\\\\ w_3 &amp; w_6\\end{bmatrix} \\times \\begin{bmatrix}i_1 \\\\ i_2\\end{bmatrix}  = \\begin{bmatrix}i_1*w_1 + i_2*w_4 &amp; i_1*w_2+i_2*w_5 &amp;i_1*w_3+i_2*w_6\\end{bmatrix}$$</span></p>\n", "pids": ["5d9edbf547c8f7664602d414", "5e5e18f493d709897ce3f0db"], "flag": 1}
{"question": "Are there studies on politeness towards machines?", "body": "<p>I noticed in several places (usually on web forms, but also with virtual assistants) that there is sometimes (or usually) an expectation of being polite towards the computer or device.</p>\n<p>An example would be a button &quot;yes, please&quot; or &quot;no, thank you&quot; instead of a &quot;yes&quot; or &quot;no&quot;.</p>\n<p>I also read about a casual review of how people interact with Alexa or Google Assistant - a sizable part (I think it was 30%) would say &quot;yes please&quot;.</p>\n<p><strong>I was wondering whether there was interesting research in that area, which could give some substance to hand-waving theories.</strong></p>\n<p>Notes:</p>\n<ul>\n<li>I work in IT for the past 30 years so I am used to talking to my computer (asking him to please go faster, or telling because my code does not work. I do not have &quot;casual exchanges&quot;, though.</li>\n<li>for the less serious aspect of that question, see <a href=\"https://www.youtube.com/watch?v=NMS2VnDveP8\" rel=\"nofollow noreferrer\">https://www.youtube.com/watch?v=NMS2VnDveP8</a> (2:25 for the politeness part, but the whole video is worth watching)</li>\n</ul>\n", "pids": ["555044ec45ce0a409eb52174"], "flag": 1}
{"question": "Does submitting a paper in Latex format enhance the chances of acceptance?", "body": "<p>If there is an option to submit your paper in either Latex or Word, which format should be given preference? Does it affect the chances of acceptance? My paper relates to computer science &amp; engineering, with a few mathematical formula, diagrams, and tables.</p>\n", "pids": ["55a6abde65ce054aad7041fe"], "flag": 1}
{"question": "Does completing research ethics / compliance training courses reduce the incidence of ethics or compliance breaches?", "body": "<p>Prior to initiating some research projects, researchers may be asked (e.g., by an Institutional Review Board) to complete research ethics / compliance training courses, such as CITI Program's Research Ethics and Compliance Training.</p>\n\n<p>Does completing research ethics / compliance training courses reduce the incidence of ethics or compliance breaches?</p>\n\n<p>I'm looking for studies/surveys, not guesses.</p>\n", "pids": ["55a4e81165ceb7cb02dbadbf"], "flag": 1}
{"question": "wisdom of crowds and group polarization", "body": "<p>I'm having a hard time understanding two concepts, <a href=\"https://en.wikipedia.org/wiki/Wisdom_of_the_crowd\" rel=\"nofollow noreferrer\">wisdom of crowds</a> and <a href=\"https://en.wikipedia.org/wiki/Group_polarization\" rel=\"nofollow noreferrer\">group polarization</a>, at the same time.</p>\n<p>Wisdom of crowds states that aggregation of information or prediction, in groups are often <em>better</em> than single member's.</p>\n<p>Group polarization, however, refers to the tendency that group makes <em>more extreme</em> decisions than single member's.</p>\n<p>It seems that the group decision, due to group polarization, should be <em>less accurate</em> than single member's since it's more extreme, which conflicts the idea of wisdom of crowds. I assume there should be boundaries between two concepts and a case-by-case basis?</p>\n<p>Any help will be appreciated.</p>\n", "pids": ["5f0e24309fced0a24b05a849"], "flag": 1}
{"question": "How to predict the best from a set of messages - best practice", "body": "<p>Suppose I have a set of messages A,B,C,D and I want to produce the best message for a website user at a given time.</p>\n<p>For training I plan to show random users a random single message [A/B/C/D] and fill these columns (i'm simplifying the data for illustration)</p>\n<ul>\n<li>converted before</li>\n<li>funnel state (e.g awareness, search, decision)</li>\n<li>number of page views</li>\n<li>message shown [A-D]</li>\n<li>Time to convert (this will be updated later if there is a conversion)</li>\n</ul>\n<p>I want to predict what is the best message to show to a specific user in order to maximise the chance of conversion (=min time to convert).</p>\n<p>I'm not sure how to represent this for training and inference. Its not a simple prediction like predicting one of the given data points.</p>\n<p>One option is to run prediction of time to buy for each of the messages but\n1- its not efficient\n2- It will prefer messages that are shown closer to purchase time regardless if they fit the current user time.</p>\n", "pids": ["59ae3bf12bbe271c4c71bc64", "5d04e908da56295d08dda3b9", "5cede10ada562983788eacc9"], "flag": 1}
{"question": "What would be the state of the art image captioning deep learning model?", "body": "<p>I saw a couple of architectures, like CNN-LSTM, with and without attention model, use of Glove vector, self-critical models, etc. I am overwhelmed looking at different notebooks and architectures, came here for a guidance.  I am looking to build a personal project on image annotations. Also, if I wanted to use this deep learning model together with TFX pipeline, what would be the best type of architecture I can go with?</p>\n", "pids": ["573697826e3b12023e669567"], "flag": 1}
{"question": "Expected behavior of adversarial attacks on deep NN?", "body": "<p>I am trying adversarial attack (AA) for a simple CNNs. Instead of the clean image, my simple CNN is trained with attacked images as suggested by some papers. As the training goes on, I am not sure if the training is well going or something is wrong.</p>\n<p>Here is what I observed:</p>\n<p>When the epsilon value is large, the classification performance of the model from the adversarial training is low. I understand if the attacked image is given to the model, then the performance is poor. Although the model is from the adversarial training, because the epsilon is large, the model is poorly perform. However, when an clean image is given, the performance of the model is still low. Performance on the clean images are higher than the performance of the attacked images, but not as high as the baseline model without adversarial training.</p>\n<p>So, I wonder if the adversarial training also degrades the performance of the model on the clean images. When I read papers, I only see the results on the adversarial Images, not clean images. If you have any experience, it will be very helpful to check if my training code is working well or not.</p>\n<p>When the epsilon is very large, the accuracy of the model on clean image is around 15%. The model without the adversarial training is around 81%.</p>\n<p>Some details.\nI use PGD attack with 5-iterations and epsilon is one of <code>eps = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.03, 0.05, 0.07]</code>. Step size is <code>eps/3</code>. Only one epsilon is selected and the adversarial training is conducted. So there are 8 different models trained with different epsilons.  I use natural image Dataset.</p>\n", "pids": ["5d1eb9d7da562961f0b115d5"], "flag": 1}
{"question": "What is the link between descriptive norm &amp; informational social influence? When the descriptive norm doesn&#39;t appear to be &quot;correct&quot;?", "body": "<p>I'm a first-year psychology student and this week I'm learning (from a crappy lecturer) about social norms, specifically injunctive vs descriptive norms, and normative vs informational social influence.</p>\n<p>I came across the following excerpt from my textbook:</p>\n<blockquote>\n<p>People conform to injunctive norms to gain social approval or to avoid social sanctions. [...] Conforming to descriptive norms typically has a different motivation, namely the desire to be correct. In many instances, following the group will lead to a correct outcome. For example,×following the crowd after arriving by train to an unfamiliar station will likely lead you to the exit. Deutsch and Gerard (1955) termed this type of motivation informational social influence.<br />\n(Steg, L., Berg, A., &amp; de Groot, J. (2019). Environmental psychology - An Introduction (2nd ed.). BPS Blackwell.)</p>\n</blockquote>\n<p>My question is, what if the group action is obviously wrong from the start? For instance, smoking, littering, or vandalism. Is the descriptive norm in this case still motivated by <em>informational</em> social influence? Or is the association between these two concepts not always applicable?</p>\n", "pids": ["5ce2d034ced107d4c6353607"], "flag": 1}
{"question": "Automatically building a database of forward and backward citations", "body": "<p>My goal is to produce a graph showing the linkages (and lack there of) between several fields that share a common subproblem by showing who cites whom.  There are many databases that show citations between papers: <a href=\"http://apps.webofknowledge.com/\">ISI Web of Knowledge</a>, <a href=\"http://academic.research.microsoft.com/\">Microsoft Academic Research</a>, and Google Scholar.  However none allows me to download even part of their database.  Is there some database I have overlooked?  Has someone written a scrapper for one of these websites?  </p>\n\n<p>For reference, the fields I'm considering are Mechanics, Magnetic Resonance Imaging, Signal Processing, Geophysics, and several others.</p>\n", "pids": ["599c7988601a182cd2648f8c"], "flag": 1}
{"question": "Humorous author pictures", "body": "<p>Some journals put author pictures and short bios at the end of the articles. Do you know of published examples in which the authors used humorous pictures of themselves, for instance with funny poses or unusual hats?</p>\n", "pids": ["53e9afadb7602d97039fd330", "558b42efe4b0b32fcb3ba55f", "558c505084ae6766fdf25aaa"], "flag": 1}
{"question": "Bias distrusting area of expertise while implicitly trusting other domains?", "body": "<p>I've run across descriptions of this bias before, but cannot find it right now...  I checked Wikipedia's <a href=\"https://en.wikipedia.org/wiki/List_of_cognitive_biases\" rel=\"nofollow noreferrer\">list of cognitive biases</a> to no avail.</p>\n<p>Basically, people working in some domain and having expertise in it, naturally tend to notice the problems in that area, such as incompetence of other people working in their field, bad policies and poor management decision making, etc, resulting in a disproportionate distrust of their own field of expertise.  For example, healthcare workers are <a href=\"https://dx.doi.org/10.1016%2Fj.ebiom.2015.06.028\" rel=\"nofollow noreferrer\">more likely to be vaccine hesitant</a> because they distrust their own industry more than most due to personal experience with incompetence, mismanagement, politics, and corruption within their field.</p>\n<p>However, this distrust does not carry over to other domains.  So for example, watching a movie that portrays something you have domain knowledge in, you will quickly notice the inaccuracies and misrepresentation, but portrayals of domains outside your expertise will naturally be believable and perceived as accurate.  Similarly, reading news stories about topics that you have expertise in, you will notice inaccuracies and bias immediately, but fail to recognize that the same level of inaccuracy and bias must exist in domains outside your area of expertise, implicitly treating such news stories as accurately reported.</p>\n<p>What is this bias called?</p>\n", "pids": ["53e9b8c1b7602d97044a0a25", "56d81d40dabfae2eeea30bee", "53e9992ab7602d970216500e", "53e99e71b7602d9702736f6d"], "flag": 1}
{"question": "What stops messenger RNA from binding to itself?", "body": "<p>Since mRNA is single-stranded, and (mostly) floats freely within the cytosol, what stops it from folding onto itself (like DNA) and preventing transcription?</p>\n", "pids": ["55d06680696322190568be55"], "flag": 1}
{"question": "Why our bees might have suddenly disappeared", "body": "<p>We have a large garden in Bedfordshire, UK, next to woods and to arable fields currently planted with intensively farmed rape. We usually have many bees in the garden. Earlier this year, things were humming along as usual. A cotoneaster bush in flower had perhaps a hundred bees on it at once, of at least 6 different species.</p>\n\n<p>Now, in July, we have lavender and clover in full bloom, normally swarming with bees. But, not now. This morning (overcast and warm) there were two bees on a lavender bush covering two square metres. I can walk for minutes in the garden without seeing a single bee. The leafcutter bees have left no holes in our rose leaves this year.</p>\n\n<p>The nearest managed hives are about 800m away. It's not just a managed hive that has gone, the bumblebees that nest in our garden have gone too.</p>\n\n<p>The rape flowers are long past. I don't know what might have been sprayed on the rape.  Our garden is organic. </p>\n\n<p>Wasps are down too. This is the first year in the last twenty that there are no wasp nests in our outbuildings. There are, however, plenty of flies.</p>\n\n<p>What might have caused such a sudden and unusual population change? Among multiple species of bee from multiple sources, between April and July? </p>\n\n<p>Could it be our globally-warmed <strong>weather</strong>? June and July have been wetter and warmer than usual, although not exceptionally so.</p>\n\n<p>Are UK farmers allowed to use an <strong>insecticide</strong> on rape that could kill most bees?</p>\n\n<p>Or is a dramatic in-year population change in bees a <strong>routine</strong>, if uncommon, event?</p>\n\n<p>Thanks!</p>\n\n<p><strong>Update August 17 2016</strong></p>\n\n<p>Our garden bees do seem to be gradually recovering - nothing like most years, but a few bees are coming back. Other nearby houses, at least 400m from the nearest rape field, have plenty of bees.</p>\n", "pids": ["55a6c95c65ce054aad75bb6d"], "flag": 1}
{"question": "How to train an LSTM to classify based on rare historic event?", "body": "<p>I want an LSTM to output one of two classes (Y, N), per frame, based on all the input so far.<br />\nMy original inputs are very long (~100000 samples long, far more than a standard LSTM training can handle due to vanishing gradients).</p>\n<ol>\n<li>If the last seen instance out of the tokens (A, B) was A, output Y.</li>\n<li>If the last seen instance out of the tokens (A, B) was B, output N.</li>\n<li>The very long sequence is guaranteed to start with either A or B.</li>\n</ol>\n<p>If the sequence was short, this would be quite easy.</p>\n<p>For example, the following top lines and bottom lines correspond to inputs and required outputs:</p>\n<pre><code>ABCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\nYNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n\nACCCCCCCCCBCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCACCCCCCCCCCCCCCCCACCCCCCCC\nYYYYYYYYYYNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNYYYYYYYYYYYYYYYYYYYYYYYYYY\n</code></pre>\n<hr />\n<p>Looks easy enough, just push batches comprised of chunks of the long sequence to the LSTM and have a coffee, right?<br />\nHowever, for my case, the available inputs are (A, B, C), of which (A, B) are extremely rare, meaning I can have batches comprised of 100% C's. The LSTM has no chance then, if not fed with some current state, telling it about the last A or B seen.<br />\nUnfortunately, this &quot;state&quot; is really something learned, and I can't just feed it as input AFAIK.</p>\n<pre><code>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n????????????????????????????????????????????????????????????????????\n</code></pre>\n<hr />\n<p>I am looking for a standard practice, or other references on how to train an LSTM or other RNN based model to be able to classify based on rare events far in history.</p>\n<p>I hope this is clear, if not please ask and I will edit.</p>\n<hr />\n<p>Please note that the data is labeled, and labeling can't be generated automatically for this task. The above is just an example for ease of understanding, the reality is more complicated.</p>\n", "pids": ["58d82fcbd649053542fd668b"], "flag": 1}
{"question": "In variational autoencoders, why do people use MSE for the loss?", "body": "<p>In VAEs, we try to maximize the ELBO = <span class=\"math-container\">$\\mathbb{E}_q [\\log\\ p(x|z)] + D_{KL}(q(z \\mid x), p(z))$</span>, but I see that many implement the first term as the MSE of the image and its reconstruction. Here's a paper (section 5) that seems to do that: <a href=\"https://arxiv.org/pdf/1911.02469.pdf\" rel=\"nofollow noreferrer\">Don't Blame the ELBO! A Linear VAE Perspective on Posterior Collapse</a> (2019) by James Lucas et al. Is this mathematically sound?</p>\n", "pids": ["5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "What is the difference between repeatability, replicability and reproducibility?", "body": "<p>I have seen many instances where authors used the term \"reproducibility\" and \"replicability\" interchangeably in the social and behavioural sciences. Sometimes, they distinguish between the \"repeatability\" of experiments (same measurand/same measurement conditions) and \"replicability\" (same measurand/different conditions). If the three concepts are differentiated than, in most cases, there seems to be an inherent hierarchy between the three concepts:<br>\n<code>repeatability &lt; reproducibility &lt; replicability</code>\nWhere a successful replication means that the same finding has been achieved with different data (or sometimes methods) and reproducibility means that it is possible to get the same results given the data and analytical means from the original study.</p>\n\n<p>However, it occurs to me that at least in computer science this seems to be different.[<a href=\"http://cogprints.org/7691/7/ICMLws09.pdf\" rel=\"noreferrer\">1</a>]<br>\nI am not aware of the situation in other fields. Therefore, I am curious which definitions of repeatability, reproducibility and replicability are used in other disciplines.</p>\n\n<p>What are the definitions most commonly associated to repeatability, reproducibility and replicability in your field? \nAre the definitions the same but the concepts have substantially different meanings between fields e.g. because pseudo-random numbers generated by computer experiments are different from true randomness in biological experiments?</p>\n", "pids": ["62181f055aee126c0fe35f52"], "flag": 1}
{"question": "PhD Research under guide/advisor of a different department", "body": "<p>I am a physics undergrad, who is also interested in pure mathematics. I am not very sure what I want to pursue for my PhD. Though I have specific interests in each of the two, and also inter-linked interests, in general I am very confused. My question is it legally and practically allowed for you to chose a guide from another department different than that which you are affiliated to? If not, can someone from another department become a co-guide? In particular, I am looking for laws and practices in the US and Europe (may differ from country to country).</p>\n", "pids": ["55a672fa65ce054aad685053"], "flag": 1}
{"question": "What work has been done studying methodological reforms in psychology after the replication crisis?", "body": "<p>Can anyone point me to academic work that systematically studies how standards and methods have changed in psychology as a response to the replication crisis? Thanks.</p>\n", "pids": ["605aa278e4510cd7c86b8676"], "flag": 1}
{"question": "Where to begin with Political Psychology literature?", "body": "<p>I am a law and public policy scholar, and I'm currently developing a civics curriculum for YouTube. As a phd, I'm (perhaps to an unhealthy degree) concerned with being able to cite good science whenever it's available.</p>\n<p>However, my own field of political science has rather let me down. I am trying to gather data about the impacts of citizen engagement with government in a number of ways, and one of the key mechanisms I'm looking at is contacting one's electeds (&quot;write your congressman!&quot; etc.).</p>\n<p>The problem is I'm not able to find literature on electeds' response to such communications (real or self-perceived) but have noticed some studies in behavioral psych that are next door to these themes.</p>\n<p>Lacking in a solid base of literature to begin from makes this search even harder and so...</p>\n<p>Q: Which authors/texts are considered foundational in political psychology, or behavioral psychology that covers political contexts?</p>\n", "pids": ["5d9eda5d47c8f76646010dc6", "62193f585aee126c0fd07327"], "flag": 1}
{"question": "Negative feedback loop and oscillations", "body": "<p>According to the textbook <a href=\"http://www.garlandscience.com/product/isbn/9780815341055\" rel=\"nofollow noreferrer\">Alberts Molecular Biology of the Cell</a> (5th ed., p. 902), negative feedback loops cause oscillations when they are long delayed. I just can't figure out why. </p>\n\n<p>Except for that, in case of short delayed feedback, the inhibition doesn't seem to be full and to go down only mid-way, according to the attached plot. Why?</p>\n\n<p><a href=\"https://i.stack.imgur.com/Yezzp.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/Yezzp.png\" alt=\"image attached\"></a></p>\n", "pids": ["53e9b3e9b7602d9703ed9171", "53e9ade2b7602d97037eae00"], "flag": 1}
{"question": "Replication or conceptual replication of card trick in Mind Field Ep 8?", "body": "<p>In <a href=\"https://www.youtube.com/watch?v=b2ng8HuPLTk\" rel=\"nofollow noreferrer\">Mind Field S1 E8</a> Michael Stevens presents a magician performing a trick with participants. Each participant is shown pairs of photographs of people and are given the forced choice of which one they preferred to work with. After being presented with all of the options, the magician performs a sleight of hand to sneak cards from the &quot;no&quot; pile into the &quot;yes&quot; pile while the participant is filling out a form. Then the participant is shown cards from the file that they believe are purely those that they said &quot;yes&quot; to, and asked to explain why they said &quot;yes&quot;. When presented with cards that the participants said &quot;no&quot; to they appear to have made up rationalizations.</p>\n<p>Are there studies that replicate this effect?</p>\n", "pids": ["55a4ed3465ceb7cb02dc2820", "55a533ec65ceb7cb02e42c47", "53e99c1ab7602d97024caced", "56d81ffedabfae2eeeb5859d", "621922295aee126c0f88a0d1", "55a65ec065ce054aad658d11"], "flag": 1}
{"question": "Is it a good practice to pad signal before feature extraction?", "body": "<p>Is padding, before feature extraction with VGGish, a good practice?</p>\n<p>Our padding technique is to find the longest signal (which is loaded <code>.wav</code> signal), and then, in every shorter signal, put zeros to the size of the longest one. We need to use it because one size of input data is desirable.</p>\n<p>Perhaps there is any other techniques you recommend?</p>\n<p>The difference between padding before and after the features extraction by accuracy is quite big - more than 20%. Using padding before extraction gives 97% accuracy.</p>\n<p>I'd be glad to read your feedback, and explain me why that happens, and tell me if that kind of padding is correct action or is there a better solution.</p>\n", "pids": ["58437725ac44360f1082fa5e"], "flag": 1}
{"question": "What are pros and cons of using a multi-head neural network versus a single neural network for multi-label classification?", "body": "<p>I haven't been able to find a good discussion specifically comparing the two (only one describing a classification and regression problem). I am training a classifier to learn both age and gender based on genomic data. Every sample has a known age and known gender (20 classes in total).</p>\n<p>Currently, I am using a single neural network with a sigmoid activation in the last layer with a binary_crossentropy loss. This works fine. However, I also see people using multi-head neural networks where, for example, a set of shared layers would split in to two either additional dense layers or in to two final layers for classification – each with an independent loss (in my case likely a categorical_ce).</p>\n<p>What I am unsure of, though, are the advantages and disadvantages between the two (maybe advantages and disadvantages are not the right words to use – actual differences between the two might be more appropriate and when one might use one of those over the other)?</p>\n<p>I want to be able to calculate the usual metrics – TP, FP, etc. after training – presumably it would be easier with two heads at the end of the network, as you can work with two independent sets of predictions to calculate these?</p>\n", "pids": ["5f5c9bc891e0115b33151d96"], "flag": 1}
{"question": "Are there any sources that estimate the number of *unique* direct connections between neurons?", "body": "<p>There are plenty of sources on the number of synapses the average neuron in some region of the brain has. However, its become clear that there is <em>some</em> degree of redundancy in these connections, where a pair of neurons have multiple synapses between them. I'm aware that the multiple synapses aren't truly redundant, they serve a purpose. I just want to know if there are any estimates on how many other neurons a single neuron receives from on average.</p>\n", "pids": ["5cf8e4633a55ac7fe7882ba8"], "flag": 1}
{"question": "Can you grow a small brain network in a petri dish?", "body": "<p>Perhaps with stem cells, genetic engineering like CRISPR, or just cellular extraction and harvesting/reproduction in some way, we could isolate and incubate a single neuron in an artificial environment, for example, a Petri dish or something similar.</p>\n<p>Has anyone succeeded in doing so for some N number of neurons and connecting them via the synapses, as they are in the brain?</p>\n<p>And then, trying to stimulate some of the neurons and exploring if that neural network can be used for anything, or used to study how the greater brain works?</p>\n<p>Thank you</p>\n", "pids": ["55a55eaa65ceb7cb02e9e657"], "flag": 1}
{"question": "Is it necessary to include and update the status of a paper on arXiv once it has been accepted for publication in a journal?", "body": "<p>Let's suppose you write a paper and you post it on arXiv. If a paper is sent to a journal for peer-review, should you always include this information in the paper comments (including the name of the journal where the paper was sent)?</p>\n\n<p>If the paper is accepted, is it necessary to include in the comments that the paper has been accepted for publication in... (and include the name of the journal)? Or it is better to wait until the paper is published and then include in the comments \"Published in... [name of the journal].\"?</p>\n\n<p>I understand that it may take some for a paper to be published once accepted.</p>\n", "pids": ["56d831a7dabfae2eee26531d", "5d9edba647c8f7664602279f"], "flag": 1}
{"question": "Term for how anxiety makes people think abnormally?", "body": "<p>For a paper I'm writing, I want to make a point about how anxiety changes the way people think - i.e., the same person in the same situation might think differently depending on whether or not they are anxious.</p>\n<p>The problem is that I'm not sure what search term to use to find papers that may be relevant, so I was just wondering if anyone else knows.</p>\n", "pids": ["53e9b53cb7602d97040740fb"], "flag": 1}
{"question": "Role of calcium chloride during competent cell preparation", "body": "<p>I am aware of the fact that $CaCl_2$ settles down on the cell wall making it less negative may be by forming bond with Teichoic acid. Also due to the positive charge it attracts DNA (DNA is negatively charged due to phosphate group). But is there anything else the $CaCl_2$ does? Also if its the work of $CaCl_2$ why we are adding $MgCl_2$ first in the standard protocol of the making competent cell preparation chemically?</p>\n", "pids": ["53e9a63db7602d9702f68efd", "53e99e93b7602d970275801a"], "flag": 1}
{"question": "Is reconciling shape discrepancies the only purpose of padding?", "body": "<p>Padding is a technique used in some of the domains of artificial intelligence.</p>\n<p>Data is generally available in different shapes. But in order to pass the data as input to a model in deep learning, the model allows only a particular shape of data to pass through it. And hence there is a need to allow padding in case if the input data shape contains dimensions that are less than the dimensions of the input of the model under consideration. For example, we <a href=\"https://ai.stackexchange.com/questions/26597/what-is-the-difference-between-zero-padding-and-character-padding-in-recurrent-n\">pad input sentences</a> in RNN to match the input shape of the RNN model. Sometimes we pad the input data in order to make a desired shape output. For example, padding is used in convolution operation to keep the size of feature maps intact.</p>\n<p>Is handling this type of <em>shape issues</em> is the only purpose of padding? If no, what are the other purposes of padding that are not related to the shaping requirements of data?</p>\n", "pids": ["5f7c572991e0117ac2a78c3b"], "flag": 1}
{"question": "Is there any metric for calculating how natural a single image is given a dataset of the same class images?", "body": "<p>Suppose there is a dataset <span class=\"math-container\">$D$</span> of images. We have enough number <span class=\"math-container\">$n$</span> of images in the dataset and all the images are of a single class.</p>\n<p>Suppose I generated a new image <span class=\"math-container\">$I$</span>, which is not present in the given dataset, of the same class using a generator neural network. I want to calculate how natural the image <span class=\"math-container\">$I$</span> is wrt the dataset <span class=\"math-container\">$D$</span></p>\n<p><span class=\"math-container\">$m(I, D) = $</span> how natural the image <span class=\"math-container\">$I$</span> with respect to dataset <span class=\"math-container\">$D$</span> of images.</p>\n<p>I don't want metrics that are applied to a bunch of generated images. I have only one generated image.</p>\n<hr />\n<p>I came up with a naive metric</p>\n<p><span class=\"math-container\">$m(I, D) = \\sum\\limits_{x \\in D} (x-I)^2 $</span></p>\n<p>where <span class=\"math-container\">$x-I$</span>, difference between two images, is defined as the sum of pixel differences of both the images i.e., <span class=\"math-container\">$$x-I = \\sum\\limits_{x_i \\in x, I_i \\in I} \\|x_i - I_i\\|$$</span></p>\n<p>But, this measure shows how similar the new image <span class=\"math-container\">$I$</span> w.r.t is to the set of images in my dataset at the pixel level. I want a measure of how natural it is.</p>\n", "pids": ["5c8d040b4895d9cbc632c827"], "flag": 1}
{"question": "Resource for journal acceptance rates", "body": "<p>Does anyone know of a resource or study that compiles statistics about paper acceptance rates in various journals?</p>\n\n<p>I am more interested in biomedical journals, but this would be a good place to list such resources in any scientific field.</p>\n", "pids": ["573696ab6e3b12023e5afa6c"], "flag": 1}
{"question": "Is Google Scholar reliable for reporting citations?", "body": "<p>When quoting the number of citations for each paper you have published, different sources can be used, Google Scholar, ResearcherID, Scopus.\nGoogle Scholar covers a larger range of literature.</p>\n\n<p>Is it acceptable to use Google Scholar? Or it is not a professional resource, and we necessarily should use ISI Web of Knowledge for counting citations?</p>\n", "pids": ["53e9be14b7602d9704acf0b8"], "flag": 1}
{"question": "How can abstract graphs be recognized by neural nets?", "body": "<p>Recognition of optical patterns (as pixel maps) by neural networks is standard. But optical patterns may be only slightly distorted or noisy, and may not be arbitrarily scrambled – e.g. by permutations of rows and columns of the pixel map – without losing the possibility to recognize them. This in turn is the normal case for abstract graphs in their standard representation as adjacency matrices: only under some permutations of nodes a possible pattern is visible. In general, for <strong>almost all</strong> random graphs under <strong>no</strong> permutation a pattern is visible, but for <strong>all</strong> graphs under <strong>almost all</strong> permutations a pattern is <em>in</em>visible.</p>\n<p>How can this be handled in the context of either unsupervised or supervised learning? Assume you have a huge set of graphs with 100 nodes and 1,000 edges, given as 100<span class=\"math-container\">$\\times$</span>100 adjacency matrices under arbitrary permutations, but with only two isomorphism classes. How could a neural network find this out and learn from the samples?\nIs this possibly common knowledge: that it can <strong>not</strong>? Or are there any tricks?</p>\n<p>(One trick might be to draw the graph <a href=\"https://en.wikipedia.org/wiki/Force-directed_graph_drawing\" rel=\"nofollow noreferrer\">force-directed</a> and hope that it settles in a recognizable configuration. But this to be detectable would require a much larger pixel map than 100<span class=\"math-container\">$\\times$</span>100. But why not?)</p>\n", "pids": ["5e3d35313a55ac4de410496e", "61c145c55244ab9dcb850edf"], "flag": 1}
{"question": "Is it abuse of notation to use tilde operator in this context?", "body": "<p>The <a href=\"https://mathworld.wolfram.com/Tilde.html\" rel=\"nofollow noreferrer\">following is a way</a> to use tilde (∼) in context of random variables or random vectors.</p>\n<blockquote>\n<p>In statistics, the tilde is frequently used to mean &quot;has the\ndistribution (of),&quot; for instance, <span class=\"math-container\">$X∼N(0,1)$</span> means &quot;the stochastic\n(random) variable <span class=\"math-container\">$X$</span> has the distribution <span class=\"math-container\">$N(0,1)$</span> (the standard\nnormal distribution). If X and Y are stochastic variables then <span class=\"math-container\">$X∼Y$</span>\nmeans &quot;<span class=\"math-container\">$X$</span> has the same distribution as <span class=\"math-container\">$Y$</span>.</p>\n</blockquote>\n<p>Consider the following usage of tilde in the paper titled <a href=\"https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf\" rel=\"nofollow noreferrer\">Generative Adversarial Nets</a></p>\n<p><span class=\"math-container\">$$x ∼ p_{data}(x)$$</span>\n<span class=\"math-container\">$$z ∼ p_z(z)$$</span></p>\n<p>I am thinking that the following is the standard (and possibly correct) notation</p>\n<p><span class=\"math-container\">$$x ∼ p_{data}$$</span>\n<span class=\"math-container\">$$z ∼ p_z$$</span></p>\n<p><span class=\"math-container\">$p_{data}$</span> is a probability distribution and <span class=\"math-container\">$p_{data}(x)$</span> is not a probability distribution and it is a value in <span class=\"math-container\">$[0, 1]$</span>. It is same in case of noise probability distribution.</p>\n<p>Is it an abuse of notation to use in such a way or is it also a standard and allowed notation to use?</p>\n", "pids": ["5736960f6e3b12023e522205"], "flag": 1}
{"question": "Is there any difference between an objective function and a value function?", "body": "<p>I found the usage of both objective function and value function in the same context.</p>\n<p><strong>Context #1</strong>: In the paper titled <a href=\"https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf\" rel=\"nofollow noreferrer\">Generative Adversarial Nets</a> by <em>Ian J. Goodfellow et al.</em></p>\n<blockquote>\n<p>We simultaneously train G to minimize <span class=\"math-container\">$\\log(1 −D(G(z)))$</span>. In other\nwords, <span class=\"math-container\">$D$</span> and <span class=\"math-container\">$G$</span> play the following two-player minimax game with\n<strong>value function</strong> <span class=\"math-container\">$V (G,D)$</span>:</p>\n<p><span class=\"math-container\">$$\\min_G \\max_DV(D, G) = \\mathbb{E}_{x ∼ P_{data}}[\\log D(x)] + \n \\mathbb{E}_{z ∼ p_z}[log (1 - D(G(z)))]$$</span></p>\n</blockquote>\n<p><strong>Context #2</strong>: In the paper titled <a href=\"https://arxiv.org/pdf/1411.1784.pdf,\" rel=\"nofollow noreferrer\">Conditional Generative Adversarial Nets</a> by <em>Mehdi Mirza et al.</em></p>\n<blockquote>\n<p>The <strong>objective function</strong> of a two-player minimax game would be as</p>\n<p><span class=\"math-container\">$$\\min_G \\max_DV(D, G) = \\mathbb{E}_{x ∼ P_{data}}[\\log D(x|y)] + \n \\mathbb{E}_{z ∼ p_z}[log (1 - D(G(z|y)))]$$</span></p>\n</blockquote>\n<p>In fact, the second paper also iterated <strong>context #1</strong> i.e., used the term &quot;value function&quot; at another place.</p>\n<p>We can observe that objective function is a <a href=\"https://ai.stackexchange.com/questions/9005/what-is-an-objective-function\">function</a> which we <a href=\"https://ai.stackexchange.com/questions/13646/what-are-the-major-differences-between-cost-loss-error-fitness-utility-obje\">want to optimize</a></p>\n<blockquote>\n<p>The objective function is the most general term that can be used to\nrefer to a cost (or loss) function, to a utility function, or to a\nfitness function, so, depending on the problem, you either want to\nminimize or maximize the objective function. The term objective is a\nsynonym for goal.</p>\n</blockquote>\n<p>Since the generator or discriminator has to perform optimization, it is agreeable to use the term objective function in this context.</p>\n<p>But what is the definition for the value function and how is it different from the objective function in this context?</p>\n", "pids": ["5f4f65a491e0111f07b3091f"], "flag": 1}
{"question": "What percentage of links posted in published articles are dead?", "body": "<p>Is there any research/study that looked at the impact of the  percentage of links posted in published articles are dead? I am trying to know to what extent dead links are an issue. E.g. <a href=\"https://meta.stackoverflow.com/q/300916/395857\">on Stack Overflow, it looks like 10% of the links posted here are dead</a>.</p>\n", "pids": ["53e9990db7602d970214b0eb", "554893bf0cf20218727356ef", "53e9a931b7602d9703283a39"], "flag": 1}
{"question": "How does a VGG-based Style-Loss incorporate color information?", "body": "<p>I've recently been reading a lot about style transfer, its applications and implications. I understand what the Gram matrix is and does. I can program it. But one thing that has been boggling me is: how does the VGG style loss incorporate color information into the style?</p>\n<p>In the paper &quot;<a href=\"https://proceedings.neurips.cc/paper/2015/file/a5e00132373a7031000fd987a3c9f87b-Paper.pdf\" rel=\"nofollow noreferrer\">Texture Synthesis by CNNs</a>&quot;, Gatys et al. show that minimizing the MSE between the Gram matrices of a random white noise image and a &quot;target texture&quot; yields new instances of that texture, with stochastic variation. I understand that this must work, as the Gram matrix measures the correlation between features detected by the VGG activations across channels, without spatial relation. So if we optimize the white noise image to have the same Gram matrix, it will exhibit the same statistics, and hence look like an instance of the original texture.</p>\n<p>But how does this work with color? Of course, the VGG could learn something like a mean filter, with all ones, whose output would be the avg. color over that filter kernel. After all, &quot;color&quot; is just another statistic. But then when using that in conjunction with the Gram loss, wouldn't this information be lost, as it's all just correlation and hence &quot;relative&quot; to each other?</p>\n<p>While writing this question, I'm starting to think of it like this: Maybe the feature correlation expresses these color constraints in some form like: &quot;if one part is red, there must be a green part close to it&quot; (for the radish), or &quot;if there is a rounded edge, one side of it must be in shadow (=darker)&quot; in case of the stone texture. This would tie color to the surrounding statistics (e.g., edges, other colors) and is the only reason I can think of why this works at all.</p>\n<p>Can somebody confirm/refute this, and share their thoughts? Happy to discuss!</p>\n<p><a href=\"https://i.stack.imgur.com/Bw87C.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/Bw87C.jpg\" alt=\"Image Source: Gatys et al., Texture Synthesis by Convolutional Neural Networks\" /></a></p>\n<p>Image Source: Texture Synthesis by Convolutional Neural Networks, Gatys et al.</p>\n", "pids": ["58d82fd2d649053542fd792a"], "flag": 1}
{"question": "Combinatorial woes", "body": "<p>I am interested in the creation of chunks (aka configural nodes) from smaller chunks and input features (only interested in System 1 cognition).</p>\n\n<p>Unitization studies (e.g. Goldstone (<a href=\"http://cogprints.org/909/3/doodlesold.pdf\" rel=\"nofollow\">pdf</a>)), suggest that we start with generic features, and slowly combine them into more specific chunks. As we do this unitization, we wouldn't store all of the learned combinations --- a mere 10 input features can be combined in 3.6 million configurations!</p>\n\n<p>Simon suggested generic elements get overwritten by more specific ones at each exposure. but what would you do with the predictions/rules learned about a given chunk? Transfer them to the newly created specific chunk? What if they do not apply at that more specific level?</p>\n\n<p>Nosofsky was suggesting a rule-plus-exception model, where the more generic elements are always stored and their predictions are recorded as general rules; When those predictions are broken, more specific chunks are stored to explain the exceptions to these rules. What does it mean for predictions to be broken? In a probabilistic environment like ours, sometimes a prediction is correct, sometimes it isn't -- updating the weight of the prediction seems much more reasonable than deeming it invalid in favor of an 'exception'.</p>\n\n<p>When do I chunk two co-occurring features? When do I chunk those two with a third? Do I delete the 2-feature chunk in favor of the 3-feature? What do I do with the memories associated with the deleted chunk?</p>\n", "pids": ["55a4674865ce31bc8779683a"], "flag": 1}
{"question": "How do the flowers of Diphylleia grayi become transparent after rain?", "body": "<p>Known as the skeleton flower, its flowers turn transparent in rain. How does it do so? How can it gain transparency in rain when water is already present in flower? Or is it because other components present in the rain? Also is there any  advantage of this for the plant? I research using Google, but I couldn't find an answer.</p>\n\n<p><a href=\"https://i.stack.imgur.com/rTH3W.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/rTH3W.jpg\" alt=\"photo\"></a></p>\n\n<p><a href=\"https://youtube.com/watch?v=84YboMfyzjo\" rel=\"nofollow noreferrer\">YouTube</a></p>\n", "pids": ["56d841a5dabfae2eee8d40e3"], "flag": 1}
{"question": "Why was the VC dimension not defined for all configurations of $d$ points?", "body": "<p>Let's start with a typical definition of the VC dimension (as described in <a href=\"https://mitpress.ublish.com/ereader/7093/?preview=#page/36\" rel=\"nofollow noreferrer\">this book</a>)</p>\n<blockquote>\n<p><strong>Definition <span class=\"math-container\">$3.10$</span> (VC-dimension)</strong> The <span class=\"math-container\">$V C$</span> -dimension of a hypothesis set <span class=\"math-container\">$\\mathcal{H}$</span> is the size of the largest set that can be shattered by <span class=\"math-container\">$\\mathcal{H}$</span> :\n<span class=\"math-container\">$$\n\\operatorname{VCdim}(\\mathcal{H})= \\max \\left\\{m: \\Pi_{\\mathcal{H}}(m)=2^{m}\\right\\}\n$$</span></p>\n</blockquote>\n<p>So, if there <strong>exists</strong> <em>some</em> set of size <span class=\"math-container\">$d$</span> that <span class=\"math-container\">$\\mathcal{H}$</span> can shatter and it cannot shatter any set of size <span class=\"math-container\">$d+1$</span>, then the <span class=\"math-container\">$\\operatorname{VCdim}(\\mathcal{H}) = d$</span>.</p>\n<p>Now, my question is: why would we be just interested in the <strong>existence</strong> of <strong>some</strong> set of size <span class=\"math-container\">$d$</span> and not <strong>all</strong> sets of size <span class=\"math-container\">$d$</span>?</p>\n<p>For instance, if you consider one of the typical examples that are used to illustrate the concept of the VC dimension, i.e. <span class=\"math-container\">$\\mathcal{H}$</span> is the set of all rectangles, then we can show that <span class=\"math-container\">$\\operatorname{VCdim}(\\mathcal{H}) = d = 4$</span>, given that there's a configuration of <span class=\"math-container\">$d=4$</span> points that, for all possible labellings of those points, there's a hypothesis in <span class=\"math-container\">$\\mathcal{H}$</span> that correctly classifies those points. However, we can also easily show that, if the 4 points are collinear, there's some labelling of them (i.e. the 1st and 3rd are of colour <span class=\"math-container\">$A$</span>, while the 2nd and 4th are of colour <span class=\"math-container\">$B \\neq A$</span>) that a rectangle cannot classify correctly.</p>\n<p>So, the class of all rectangles can shatter some sets of points, but not all, so we would need another class of hypotheses to classify all sets of four points correctly. The VC dimension does not seem to provide any intuition on which set of classes would do the trick.</p>\n<p>So, do you know why the VC dimension wasn't defined for all configurations of <span class=\"math-container\">$d$</span> points? Was this just a need of Vapnik and Chervonenkis for the work they were developing (VC theory), or could have they defined it differently? So, if you know the rationale behind this specific definition, feel free to provide an answer. References to relevant work by Vapnik and Chervonenkis are also appreciated.</p>\n", "pids": ["53e99eeeb7602d97027b8c6b"], "flag": 1}
{"question": "Does it make sense to use BLEU or ROUGE for any machine translation task?", "body": "<p>Many machine translation metrics such as BLEU or ROUGE are used to evaluate sequence to sequence models where, usually, the sequences are pieces of natural language.</p>\n<p>Is it possible to use these metrics when the dataset is not constituted of natural language sequences? For instance, if the sequences are source code (in some programming language), does it still make sense to use BLEU or ROUGE? How &quot;good&quot; are these metrics in general?</p>\n", "pids": ["60e7be6891e011dcbc23b0a0"], "flag": 1}
{"question": "Do other online/incremental algorithms not suffer from catastrophic forgetting?", "body": "<p>All the literature I read seems to indicate catastrophic forgetting affects only neural networks. Do other online/incremental algorithms not suffer from catastrophic forgetting (for example, <a href=\"https://scikit-learn.org/0.15/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier\" rel=\"nofollow noreferrer\">SGDClassifier</a>)? Why would that be the case?</p>\n", "pids": ["599c7947601a182cd262ae3c"], "flag": 1}
{"question": "Residual Blocks - why do they work?", "body": "<p>I've learnt that idea that the residual block was invented to solve the vanishing gradient problem due to the deep layer to layer multiplication.</p>\n<p>I understand that for example if I have 10 layers, and I add another 5 layers, that the output of the 10th layer will 'skip' the 5 layers. Although, the output of the 10th layer will also pass through the 5 layers as well. Just before the 15th layer Relu, the output from the 10th layer is element-wise summed with the 15th layer, just prior to the final Relu.\nI have some confusion with this.</p>\n<ol>\n<li><p>Identity mapping/function. I keep reading that it creates an identiy function or it learns an identity function. What exactly is this? Isn't is just F(x) = 5 added layers, and x =output of 10th layer and thus it is just F(X) + X?</p>\n</li>\n<li><p>By summing the output of the 10th layer to the 15th layer, will this not affect what was learnt in the 5 layers? I.e. from 11th -15th layer.</p>\n</li>\n<li><p>I believe it also helps with backpropagation so that it doesn't have to update all the weights layer by layer and it can skip back to shallow layers. Therefore, are the weights inside the residual block, i.e layers 11-15 not updated? If not, then what is the point of the 11-15th layer if they are not designed to &quot;do anything&quot;.</p>\n</li>\n</ol>\n", "pids": ["573696026e3b12023e515eec"], "flag": 1}
{"question": "Why does $I_N + D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$ have eigenvalues in the range [0, 2]?", "body": "<p>In <a href=\"https://arxiv.org/pdf/1609.02907.pdf\" rel=\"nofollow noreferrer\">Semi-supervised classification with Graph Convolutional Networks</a>, I am unable to understand a few things.</p>\n<p>Given an undirected graph having</p>\n<ul>\n<li>adjacency matrix <span class=\"math-container\">$A$</span>,</li>\n<li>degree matrix <span class=\"math-container\">$D_{ii} = \\sum_j A_{ij}$</span>,</li>\n<li>normalized graph laplacian <span class=\"math-container\">$L = I_N + D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}} = U \\Lambda U^T$</span>, where <span class=\"math-container\">$\\lambda_{max} \\approx 2$</span> (see page 3, 2nd paragraph, not sure which matrix they are talking about)</li>\n</ul>\n<p>Then, <span class=\"math-container\">$I_N + D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$</span> has eigenvalues in the range [0, 2]. How?</p>\n", "pids": ["5d9edc8347c8f76646042a37"], "flag": 1}
{"question": "How often can the reviewers correctly guess the identity of the authors when the review is double-blind?", "body": "<p>Is there any research/study/survey/dataset that looked at how often the reviewers correctly guess the identity of the authors when the review is double-blind?</p>\n\n<p>I am aware that the answer is likely field-dependent, or even publication venue dependent. I am mostly interested in computer science, machine learning and natural language processing, but curious about other fields as well.</p>\n", "pids": ["53e9b745b7602d97042df0d3", "5d9edc0547c8f766460306d3"], "flag": 1}
{"question": "Is there prestige to be had by posting to arXiv?", "body": "<p>Do people ever upload papers exclusively to arXiv, or do authors simply use arXiv to assist in review while they find a journal to publish in?  If people sometimes publish exclusively on arXiv, what's the point?  What do they get for their work?  A paper on their CV?  Is it at all prestigious?</p>\n", "pids": ["53e9acccb7602d97036ab597", "53e9bd76b7602d9704a12cfa"], "flag": 1}
{"question": "Why does DNA mutate?", "body": "<p>I just read that pregnancy in space would be super dangerous because - among other reasons - of a higher risk of mutations due to radiation. This made me wonder: why does the DNA in organisms mutate? What are the main natural reasons? Is this due to the construction of DNA and would happen even in \"perfect\" conditions or is it due to something that is in the environment, like radiation?</p>\n\n<p>So far I got two answers <a href=\"https://www.reddit.com/r/explainlikeimfive/comments/88j0bl/eli5_why_do_cells_mutate/\" rel=\"noreferrer\">on reddit</a> and also asked this question to a doctor and what I heard is along the lines of \"this is how it is\". I heard about \"cells being worn out\". But what makes the process non-deterministic, probabilistic? I guess I don't know enough about biochemistry to formulate the question, but I guess it's related to \"given certain conditions, what determines at which point (and what kind of) a mutation occurs?\"</p>\n", "pids": ["53e9acfeb7602d97036de721"], "flag": 1}
{"question": "PPO when does the update happen?", "body": "<p>In many places, it says PPO and Actor-Critic methods in general use TD-updates, but in the loss function for PPO, the Value function loss component uses the difference between output of the value function and the value target, which I can only assume is the discounted sum of rewards that can only be obtained at the END of the episode?</p>\n<p>So this might be a moment of stupidity for me, but</p>\n<ol>\n<li><p>Is the value target in PPO set only at the end of the episode using the discounted sum of rewards? or is there a secret way of setting these value targets that I am missing?</p>\n</li>\n<li><p>If a learning update indeed takes place every learning step (before the end of the episode), then how does this TD-learning happen - does it use some other approximate of the value target?</p>\n</li>\n</ol>\n<p>Thank you.\nPlease help.</p>\n<p>Sincerely,\na frustrated student</p>\n", "pids": ["59ae3bf12bbe271c4c71bc64"], "flag": 1}
{"question": "How to measure Deep RL algorithms in terms of safety?", "body": "<p>I applied for a Ph.D. in AI, my advisor told me that my thesis is about safe applications of deep RL algorithms in healthcare. So I decided to do as the first paper, a comparison of Deep RL algorithms in terms of their inherent safety. However, after lots of research, I could not find an answer to my question, that is: How to measure Deep RL algorithms in terms of safety?</p>\n", "pids": ["5dce785c3a55ac93ec8348d0"], "flag": 1}
{"question": "What is the best open source python repo for facial recognition?", "body": "<p>I am looking for best open source python repo for facial recognition. Best if it uses tensorflow backend. I know you can train images to recognize. Yolo can be used if trained on face. To name the person.</p>\n<p>But I wonder if there is any code where you can add new faces to database without training or minimum training. As new faces are added I don't want to train the network repeatedly. Also the less amount of face picture needed the better.</p>\n<p>If code is not available any guide or research paper will also be helpful. For example what approach can I take to make an app for a person who has difficulty remembering peoples name. So the app can take a small video or few photos with name and will be able to tell the persons name in the future. Neural network should not be retrained while adding new face to database if possible.</p>\n", "pids": ["5ce937225ced2477cb328b46"], "flag": 1}
{"question": "What is the effect of background music in educational videos on the learning outcome?", "body": "<p>Is there any research/study/survey/... that looked at the effect of background music in educational videos on the learning outcome?</p>\n\n<p>I am aware of (1) but they focus on educational virtual environments.</p>\n\n\n\n<p>(1) Fassbender, Eric, Deborah Richards, Ayse Bilgin, William Forde Thompson, and Wolfgang Heiden. \"VirSchool: The effect of background music and immersive display systems on memory for facts learned in an educational virtual environment.\" Computers &amp; Education 58, no. 1 (2012): 490-500. <a href=\"https://scholar.google.com/scholar?cluster=4113404139067026741&amp;hl=en&amp;as_sdt=0,22\">https://scholar.google.com/scholar?cluster=4113404139067026741&amp;hl=en&amp;as_sdt=0,22</a></p>\n", "pids": ["53e9b53cb7602d97040734ee"], "flag": 1}
{"question": "What is the study with the dual-task experiment that involved a colour-wheel change detection task?", "body": "<p>This may be a long-shot, but I'm looking for a paper that I vaguely remember reading a few years ago. Unfortunately I can't remember many details about the paper or its content, and thus my multiple attempts at keyword searches have failed. I'm posting this question in the hope that someone recognises the few details I do remember.</p>\n\n<p>The paper presented more than one experiment, but the one I'm trying to recall involved a colour wheel/pie displayed in the centre of the screen. The slices of the pie were each a different colour and the colours would change a few times throughout each trial. There were only a small number of slices/colours. The observer's task was to count the number of times the colours changed. While doing this the observer also had to perform another task, for which the stimuli were shown on the rest of the display, in peripheral vision. I can't remember what the other task was, though it may have been a multiple object tracking task or a visual search task. The paper may have been about the effect of attentional load on working memory, though I'm not sure about that.</p>\n", "pids": ["53e9b070b7602d9703ad6a15"], "flag": 1}
{"question": "How do convolutional layers of basic Graph Convolutional Networks work?", "body": "<p>I was reading the following article on Towards Data Science (<a href=\"https://towardsdatascience.com/graph-convolutional-networks-for-geometric-deep-learning-1faf17dee008\" rel=\"nofollow noreferrer\">here</a>) and it says the following, regarding the calculation of convolutional layers:</p>\n<blockquote>\n<p>So the overall steps are:</p>\n<ol>\n<li>Transform the graph into the spectral domain using eigendecomposition</li>\n<li>Apply eigendecomposition to the specified kernel</li>\n<li>Multiply the spectral graph and spectral kernel (like vanilla convolutions)</li>\n<li>Return results in the original spatial domain (analogous to inverse GFT)</li>\n</ol>\n</blockquote>\n<p><strong>Question:</strong> How can we visualize the convolutional layer working for a graph neural network?</p>\n<p>For example, for a CNN we can imagine the following (source: Stanford CS231n YouTube lectures, Lecture 5: Convolutional Neural Networks (<a href=\"https://www.youtube.com/watch?v=bNb2fEVKeEo&amp;list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&amp;index=5\" rel=\"nofollow noreferrer\">here</a>)). What is the analogous image for a graph convolutional filter?</p>\n<p><a href=\"https://i.stack.imgur.com/9noug.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/9noug.jpg\" alt=\"CNN filter sliding across image\" /></a></p>\n", "pids": ["57a4e91aac44365e35c97c6e"], "flag": 1}
{"question": "Is the bipolar neuron of the retina considered a sensory neuron?", "body": "<p>Any neuron that participates in sending impulses from receptors to the CNS are referred as sensory neurons. But I often see bipolar neurons of the eye (which according to the above definition should be sensory neurons) being called interneurons. Same is the case with the <a href=\"https://en.wikipedia.org/wiki/Amacrine_cell\" rel=\"nofollow noreferrer\">amacrine cells</a> and the <a href=\"https://en.wikipedia.org/wiki/Retina_horizontal_cell\" rel=\"nofollow noreferrer\">horizontal cells</a>.</p>\n<p>So what are sensory neurons? Are all the following retinal neurons sensory?</p>\n<ul>\n<li><strong>Rods/Cones,</strong></li>\n<li><strong>bipolar neurons,</strong></li>\n<li><strong>amacrine cells,</strong></li>\n<li><strong>horizontal cells &amp;</strong></li>\n<li><strong>neurons of the optic nerve (ganglionic neurons)</strong></li>\n</ul>\n<p>Are all the neurons of brain interneurons? Obviously, there are neurosecretory cells in the hypothalamus that  I wouldn't consider interneurons. But, still.</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Interneuron\" rel=\"nofollow noreferrer\">Wikipedia</a> tells us that only 20% of neurons in the cortex are interneurons.</p>\n<blockquote>\n<p>Unlike the peripheral nervous system (PNS), the central nervous system, including the brain, contains many interneurons. In the neocortex (making up about 80% of the human brain), approximately 20-30% of neurons are interneurons.</p>\n</blockquote>\n<p>Shouldn't that be about 80%?</p>\n", "pids": ["53e9bad7b7602d9704706183"], "flag": 1}
{"question": "What is the name of the method for the smart extend of image surroundings?", "body": "<p>I'm looking for the name of the method (or algorithms family, or research body) used for the smart extend of image surroundings.</p>\n<p>For example, the method I'm looking for would take this <a href=\"https://www.travelawaits.com/2486039/highland-cattle-scotland-majestic-cows/\" rel=\"nofollow noreferrer\">image</a>:</p>\n<p><a href=\"https://i.stack.imgur.com/4TiEJ.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/4TiEJ.jpg\" alt=\"enter image description here\" /></a></p>\n<p>And smartly extend it into:</p>\n<p><a href=\"https://i.stack.imgur.com/PcHO2.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/PcHO2.jpg\" alt=\"enter image description here\" /></a></p>\n<p>So that the grass and the surrounding scenery are all generated to fill the desired area.</p>\n<p>Generally speaking, what I'm looking for should smartly generate surroundings including entities such as tree trunks and branches, grass patterns, mountains slopes, clouds patterns, water bodies like puddles, shrubs, stones on ground, and so on.</p>\n<p>Also, it would be nice to know how mature is this technology, i.e. how well can different entities be smartly extended.</p>\n<p>Note that <a href=\"https://en.m.wikipedia.org/wiki/Seam_carving\" rel=\"nofollow noreferrer\">Seam Carving</a> is a candidate (used in Photoshop under the name Content-Aware Scale (<a href=\"https://youtu.be/GM9sisF4OEI\" rel=\"nofollow noreferrer\">see this for example</a>)), but I'm looking for something smarter, I think, and I'm not really sure if it can do what I'm looking for.</p>\n", "pids": ["5e01e1d13a55ac7df0019783", "557c42476feeaa8086d96f87"], "flag": 1}
{"question": "Is there a special name for rejection of extremes in the list of cognitive biases?", "body": "<p>Is there a special name for the cognitive bias that causes a person choose a compromise solution even the extreme solutions are better or causes person prefer a middle value even the extreme values are more suitable?</p>\n", "pids": ["56d8ede1dabfae2eee621eca", "5c3b63dddf5b8c0b3ca87d43"], "flag": 1}
{"question": "What kind of algorithm or approach can I use to find a specific type of object in an image?", "body": "<p>What kind of algorithm or approach can I use to find a specific type of object in an image?</p>\n<p>In particular, I am interested in finding an object like a windmill in an image taken, for example, from Google Maps. The image could be something like this</p>\n<p><a href=\"https://i.stack.imgur.com/OCJ2P.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/OCJ2P.png\" alt=\"Wind Turbine \" /></a></p>\n", "pids": ["573696026e3b12023e516718"], "flag": 1}
{"question": "Can I extend Graph Convolutional Networks to graphs with weighted edges?", "body": "<p>I'm researching spatio-temporal forecasting utilising GCN as a side project, and I am wondering if I can extend it by using a graph with weighted edges instead of a simple adjacency matrix with 1's and 0's denoting connections between nodes.</p>\n<p>I've simply created a similarity measure and have replaced the 1's and 0's in the adjacency with it.</p>\n<p>For example, let's take this adjacency matrix</p>\n<p><span class=\"math-container\">$$A=\n\\begin{bmatrix}\n0 &amp; 1 &amp; 0 \\\\\n1 &amp; 0 &amp; 1 \\\\\n0 &amp; 1 &amp; 0\n\\end{bmatrix}\n$$</span></p>\n<p>It would be replaced with the following weighted adjacency matrix</p>\n<p><span class=\"math-container\">$$\nA'=\n\\begin{bmatrix}\n0 &amp; 0.8 &amp; 0 \\\\\n0.8 &amp; 0 &amp; 0.3 \\\\\n0 &amp; 0.3 &amp; 0\n\\end{bmatrix}\n$$</span></p>\n<p>As I am new to graph NN's, I am wondering whether my intuition checks out. If two nodes have similar time-series, then the weight of the edge between them should be approximately 1, right? If the convolution is performed based on my current weights, will this be incorporated into the learning?</p>\n", "pids": ["60b6e7b191e011903fc2b99a"], "flag": 1}
{"question": "Is there a benchmark for multi-objective evolutionary algorithms?", "body": "<p>I'm working on a project for an evolutionary algorithms course, and the problem we're trying to solve is multi-objective. We'll use NSGA-II but we also wanted to compare with some other MOEAs, however, we haven't been able to find good comparisons/benchmarks of these algorithms, so we don't really know how to decide.</p>\n<p>Any insights will be appreciated.</p>\n", "pids": ["53e9b587b7602d97040cd833", "557df2bcd19faf961d1658a3", "5e37ef373a55acc00ddb89c4"], "flag": 1}
{"question": "Why is an initiator tRNA required, distinct from the methionine tRNA used in elongation?", "body": "<p>I'm confused by why there is a need for different tRNA-methionine complexes for translational initiation and elongation. </p>\n\n<p><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2795131/\" rel=\"nofollow noreferrer\" title=\"paper\">This paper</a> mentions that</p>\n\n<blockquote>\n  <p>It is important that each type of methionyl tRNA be restricted to its separate function, as competition for tRNA by the initiation and elongation machinery could lead to serious problems for the cell</p>\n</blockquote>\n\n<p>I don't understand what these problems may be. </p>\n", "pids": ["53e9b40eb7602d9703f0065a", "55a4a00765ceb7cb02d48196"], "flag": 1}
{"question": "Can I use the transformers for the prediction of historical data?", "body": "<p>Can I use the transformers for the prediction of wind power with the historical data?</p>\n<p>Dataset</p>\n<p>Datetime, Ambient temperature (Degree), Dewpoint (Degree), Relative Humidity\\n (%), Air Pressure, Wind Direction (Degree), Wind Speed at 76.8 m (m/sec), Power Generated(kW).</p>\n<p>15 years of data from 2007 to 2021 with a sampling time of 1 hour​</p>\n", "pids": ["5e2ac03c3a55ac8999c1ad6d"], "flag": 1}
{"question": "Multi Agent Deep Reinforcement Learning for continuous and discrete action", "body": "<p>I am looking to have a cooperative multi agent reinforcement learning framework where one agent has a discrete action space and another agent has a continuous action space. Is there a way to do this as most papers I have seen will only handle one or the other.</p>\n", "pids": ["5736960d6e3b12023e5207a6", "5cf48a20da56291d5828199d", "5c9009554895d9cbc6711b11"], "flag": 1}
{"question": "Are sleep stations on-campus effective in promoting productivity of students?", "body": "<p>Several universities in the United States have begun setting up areas (usually in the library) for students to rest, ideally for those doing all-nighters. Its purpose is to help its students cope with the lack of sleep.  Not much has been said about its effectivity.</p>\n\n<p>The student government of our university has been discussing employing the same concept  on-campus. I would like to know if this is a good idea or if it is more likely to promote a culture of lethargy.</p>\n", "pids": ["53e9b2eab7602d9703da46c9"], "flag": 1}
{"question": "Is there any paper that shows that multi-channel neural networks are universal approximators?", "body": "<p>Lately, I have been reading a lot about the universal approximation theorem. I was surprised to find only theorems about &quot;single-channel&quot; standard networks (multi-layer perceptrons), where all layers are 2D vectors and the weights can be represented in weight matrices.</p>\n<p>In particular, this is no longer applicable in some convolutional network applications, where the layers tend to be tensors with multiple feature channels. Of course, one could construct an equivalent &quot;single-channel&quot; neural network from a multi-channel network by putting the weight matrices together in a certain way. However, one would then have sparse matrices as weight matrices with very many constraints on the matrix entries, so that the &quot;standard theorems&quot; would no longer be applicable.</p>\n<p><strong>Do you know of any papers that study the Universal Approximation Theorem for multi-channel neural networks? Or is there a way to derive it from one of the other theorems?</strong></p>\n", "pids": ["5b1643ba8fbcbf6e5a9bc4d0"], "flag": 1}
{"question": "How is the VAE related to the Autoencoding Variational Bayes (AEVB) algorithm?", "body": "<p>I am familiar with the variational autoencoder, but not totally clear on what exactly the AEVB is.</p>\n<p>In <a href=\"https://arxiv.org/abs/1312.6114\" rel=\"nofollow noreferrer\">the original VAE paper</a> (by Kingma and Welling), he uses both the terms variational autoencoder and autoencoding variational Bayes.</p>\n<blockquote>\n<p>For the case of an i.i.d. dataset and continuous latent variables per datapoint, we propose the Auto-Encoding VB (AEVB) algorithm. In the AEVB algorithm, we make inference and learning especially efficient by using the SGVB estimator to optimize a recognition model that allows us to perform very efficient approximate posterior inference using simple ancestral sampling, which in turn allows us to efficiently learn the model parameters, without the need of expensive iterative inference schemes (such as MCMC) per datapoint.</p>\n</blockquote>\n<p>And then in section 2, the paper talks about the SGVB estimator and the AEVB algorithm.</p>\n<p>Then in section 3, it says that the VAE is an example.</p>\n<p>So, is the VAE a special application of AEVB?</p>\n", "pids": ["5c2348ceda562935fc1d5722", "5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "What does current research tell us about addictive behaviors in games?", "body": "<p>I'm creating a game, and I would like to know what research I can consult to make it more \"addicting\".</p>\n\n<p>The game is a casual one, like Candy Crush, Angry Birds, etc</p>\n", "pids": ["60fd3df65244ab9dcbccf112", "5fae682ad4150a363ce19f16"], "flag": 1}
{"question": "Are prions a recent biological phenomenon?", "body": "<p>Is there evidence to suggest whether prions have existed for a large portion of evolutionary history, played a role in evolutionary history, or could they actually be a recent biological technology invented by mother nature? Is there evidence or biochemical data that prions may predate cells?</p>\n", "pids": ["53e99ab3b7602d970232f5ac"], "flag": 1}
{"question": "How can I use a ResNet as a function approximator for pixel based reinforcement learning?", "body": "<p>I'd like to use a residual network to improve learning in image-based reinforcement learning, specifically on Atari Games.</p>\n<p>My main question is divided into 3 parts.</p>\n<ol>\n<li><p>Would it be wise to integrate a generic ResNet with a DQN variant?</p>\n</li>\n<li><p>I believe ResNets take a long to train, and therefore would it be realistic to train on an Atari simulator? What would the downsides be?</p>\n</li>\n<li><p>Are there any fast ResNets that can be used for such purposes? Perhaps a fast ResNet that is specifically designed for online settings?</p>\n</li>\n</ol>\n", "pids": ["60bec75091e011849181779a", "627e296d5aee126c0f861f26"], "flag": 1}
{"question": "Copyright statement (US Government) in acknowledgments - what to do as a reviewer?", "body": "<p>I am currently reviewing a paper, which has this statement in the acknowledgements:</p>\n\n<blockquote>\n  <p>The United States Government retains and the publisher, by accepting\n  the article for publication, acknowledges that the United States\n  Government retains a non-exclusive, paid-up, irrevocable, world-wide\n  license to publish or reproduce the published form of this manuscript,\n  or allow other to do so, for United States Government purposes.\n  <a href=\"https://www.osti.gov/stip/sti-and-copyright\" rel=\"noreferrer\">Source</a></p>\n</blockquote>\n\n<p>As a reviewer, I could simply ignore it. However, it seems rather weird to me, since usually after acceptance you have to sign a form which deals with exactly this kind of right transfer / copyright etc. The editors and referees do not have any legal power over this anyway.</p>\n\n<p>Does my role as a reviewer also include to mention this to the editor who should forward it to the publisher, or should I simply ignore it, on the risk that this statement potentially collides with the journal policies?</p>\n", "pids": ["6218c4185aee126c0fa04d9c"], "flag": 1}
{"question": "Why are today&#39;s neural networks not modeled with probability theory?", "body": "<p>In the paper <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.335.3398&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow noreferrer\"><em>The Perceptron: A probabilistic model for information storage and organization in the brain</em></a>, Rosenblatt used the probability theory to model his perceptron.</p>\n<p>My professor told me that today's neural networks are not modeled with probability theory anymore. Why is that?</p>\n", "pids": ["5c2348ceda562935fc1d5722", "5550411c45ce0a409eb3897f"], "flag": 1}
{"question": "Are there any resources that introduce the basics of online machine learning?", "body": "<p>Are there any resources (either books, articles, or tutorials) that introduce the basics of online machine learning?</p>\n<p>For example, <a href=\"https://web.eecs.umich.edu/%7Ejabernet/eecs598course/fall2015/web/\" rel=\"nofollow noreferrer\">this website</a> has nice lecture notes (from lec16) on some of the aspects. Or <a href=\"https://ii.uni.wroc.pl/%7Elukstafi/pmwiki/uploads/AGT/Prediction_Learning_and_Games.pdf\" rel=\"nofollow noreferrer\">this book</a>.</p>\n<p>I can't seem to find many resources on this. I'm trying to understand the basics, not read research papers.</p>\n", "pids": ["5a9cb66717c44a376ffb89fd"], "flag": 1}
{"question": "Is it possible to use stochastic gradient descent at the beginning, then switch to batch gradient descent with only a few training examples?", "body": "<p>Batch gradient descent is extremely slow for large datasets, but it can find the lowest possible value for the cost function. Stochastic gradient descent is relatively fast, but it kind of finds the general area where convergence happens and it kind of oscillates around that area.</p>\n<p>Is it possible to use stochastic gradient descent at the beginning and find the way to a general convergence and then use batch gradient descent on only a few training examples out of the huge dataset to get even closer to the exact point of convergence?</p>\n<p>I know that a model with a cost function that's a bit away from the lowest value for the cost function performs well in stochastic gradient descent, but assuming you want better results, will this work well?</p>\n", "pids": ["615a709d5244ab9dcb3a72e9", "5aed14d617c44a44381591ca", "5a260c8617c44a4ba8a323dd"], "flag": 1}
{"question": "What kind of NN to use to find misprints in test", "body": "<p>I have a bunch of unique full names of users. I made pseudo-physical model to emulate misprints of desktop and mobile users (hence, fatfingering, jumpy fingers, accidentals touches of touch bar etc.)</p>\n<p>So, I have pairs like John Snow - joh Snown</p>\n<p>I tried first Recurrent networks, LSTM, like some kind of vocabulary to &quot;translate&quot; from bad words to good ones, but it return only known predicted result, and when I try to put unknown last names, it returns wrong results.</p>\n<p>I wish to find some patterns in misspelled words, and to predict correct spelling.</p>\n<p>Can you please advice some kind of NN to cope with the task, or maybe some contributions in that domain?</p>\n<p>P.S. Yes, I know that there exist other AI methods to get things done</p>\n<p>P.P.S. This vocabulary is not in English, just in case</p>\n<p><strong>UPDATE</strong></p>\n<p>LSTM nn works nice with known names and last names endings for new last names. Right now I use 2 different nn, first to correct mistypes, second to determine first, last and middle name.</p>\n<p><strong>UPDATE2</strong></p>\n<p>Sequence to sequence solution also can normalize name (put them in order), find sex of person, find probability of error, etc.</p>\n", "pids": ["5ffd681291e01106b3240e54"], "flag": 1}
{"question": "How to become an Editorial board member?", "body": "<p>How to become an Editorial board member?<br/>Is it appropriate to contact journal's Editor in Chief to show interest for joining editorial board?</p>\n", "pids": ["5c136a47da56295a08a4ada4"], "flag": 1}
{"question": "How to train an ML model to convert the given lyrics into a song by a particular singer?", "body": "<p>I am interested in training a machine algorithm to convert the lyrics I give into a song by a particular singer.</p>\n<p>My language is non-English (south Indian) The songs are mostly monophonic (very few instruments, if at all). I have data of a bunch of songs sung by this singer, I want to try new lyrics and imagine how to singer would have sung.</p>\n", "pids": ["5eafe7e091e01198d3986663"], "flag": 1}
{"question": "Writing an article outside of Academia. Is it likely to get supported?", "body": "<p>I graduated from my MSc two and a half years ago, so I have been outside of the University environment for a while.</p>\n<p>I have recently started working on some novel machine learning techniques. Writing an article by myself and submitting it to a prestigious journal is no joke. I'm wondering: how likely is it to get supported from a University, or by specific researchers that are working in a University (for example PhD or postdoc students) with my work? I envision them becoming co-authors of the paper. Would they benefit from this? For example can they get some credits for correcting the paper and being a co-author even if I'm not a PhD student?</p>\n<p>Clarifications:</p>\n<ul>\n<li>I'm developing my own technique, independent from my employer. It's a general topic (regularization) so it's not directly applied to an industrial task.</li>\n<li>I want to apply for a doctorate, but my GPA and MSc thesis grade weren't brilliant. Hence, the need to publish an article before applying for the PhD - but also for the pleasure of writing about innovative research, of course</li>\n</ul>\n", "pids": ["5ac1829d17c44a1fda917e2e"], "flag": 1}
{"question": "How to output an integer/discrete number n with a single output neuron?", "body": "<p>Say I have a game with 4 base actions [left, right, up, down] and then a value n, which determines how many times the chosen action is repeated.</p>\n<p>For example, action = left, n = 3 -&gt; go left 3 times. In this game <span class=\"math-container\">$(left,1)*3 \\neq (left,3)$</span> as negative reward is handed out at every single time step (this is for research purposes, so it cannot change).</p>\n<p>I would like to test how a DDQN and a DQN algorithm are affected, as I increase the number of actions available (increase <span class=\"math-container\">$n$</span>).</p>\n<p>My question is; Is there a smarter way to implement this, other than increasing the depth of the output layer? I.e <code>len(output_layer) = n</code>?</p>\n<p>I was thinking of whether or not, there was a way for a single neuron to determine n and then have 4 other neurons that determine the best action? Would this even have any positive effects? (such as less training time, faster computation, better generalization, etc.)</p>\n<p>If yes, how would this typically be done?</p>\n", "pids": ["59ae3bf12bbe271c4c71bb36"], "flag": 1}
{"question": "Validity of ImageNet for measurement of the model performance", "body": "<p><a href=\"https://www.image-net.org\" rel=\"nofollow noreferrer\">ImageNet</a> dataset is an established benchmark for the measurement of the performance of CV models.</p>\n<p>ImageNet involves 1000 categories and the goal of the classification model is to output the correct label given the image.</p>\n<p>Researchers compete with each other to improve the <a href=\"https://paperswithcode.com/sota/image-classification-on-imagenet\" rel=\"nofollow noreferrer\">current SOTA</a> on this dataset, and the current state of the art is 90.88% top-1 accuracy.</p>\n<p>If the images involved only a single object and background - this problem would be well-posed (at least from our perceptual point of view). However, many images in the dataset involve multiple objects - a group of people, a person, and an animal - the task of classification becomes ambiguous.</p>\n<p>Here are some examples.</p>\n<p>The true class for this image is <code>bicycle</code>. However, there is a group of people. The model that recognizes these people would be right from the human point of view, but the label would be wrong.</p>\n<p><a href=\"https://i.stack.imgur.com/0qgxQ.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/0qgxQ.jpg\" alt=\"enter image description here\" /></a></p>\n<p>Another example is the fisherman with fish called <code>tench</code>.\nThe model could have recognized the person, but be wrong.</p>\n<p><a href=\"https://i.stack.imgur.com/4KVi0.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/4KVi0.png\" alt=\"enter image description here\" /></a></p>\n<p>So, my question is - how does much the performance of the best models of ImageNet reflect their ability to capture complicated and diverse image distribution, and how much the final result on the validation set is accidental. When there are multiple objects present on the image, the network can predict any of them. Prediction can match the ground truth class or can differ. And for the model, that happens to be luckier, this benchmark will show better performance. The actual quality can be the same, in fact.</p>\n", "pids": ["60001b0e91e011b170d7bf8d"], "flag": 1}
{"question": "Is the phrase &quot;Feature Pyramid Network&quot; refer to CNN only?", "body": "<p>&quot;Feature Pyramid Network&quot; is a network that is used for feature extraction. Since it is pyramid in shape, it might be called so.</p>\n<p>Consider the following excerpts from two different sources</p>\n<p><a href=\"https://paperswithcode.com/method/fpn\" rel=\"nofollow noreferrer\">#1</a></p>\n<blockquote>\n<p>A Feature Pyramid Network, or FPN, is a feature extractor that takes a\nsingle-scale image of an arbitrary size as input, and outputs\nproportionally sized feature maps at multiple levels, in a fully\n<strong>convolutional</strong> fashion. This process is independent of the backbone\nconvolutional architectures. It, therefore, acts as a generic solution\nfor building feature pyramids inside deep convolutional networks to be\nused in tasks like object detection.</p>\n</blockquote>\n<p><a href=\"https://jonathan-hui.medium.com/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c\" rel=\"nofollow noreferrer\">#2</a></p>\n<blockquote>\n<p>FPN composes of a bottom-up and a top-down pathway. The bottom-up\npathway is the usual <strong>convolutional</strong> network for feature extraction. As\nwe go up, the spatial resolution decreases. With more high-level\nstructures detected, the semantic value for each layer increases.</p>\n</blockquote>\n<p>Both the sources are giving a strong sense that the phrase &quot;Feature Pyramid Network&quot; must be used for CNN's only as it is used mainly intended for object detection. But the name and purpose suggest to me that any ANN that is pyramid in shape can be attributed as &quot;Feature Pyramid Network&quot;  since any ANN tries to extract features only in the general sense.</p>\n<p>Am I true? Can I use the phrase for any arbitrary ANN that is pyramid in shape or is it an exclusive term of CNNs in computer vision only?</p>\n", "pids": ["5b8c9f4a17c44af36f8b6d91", "605dbaf191e0113c28655a7f"], "flag": 1}
{"question": "Would AlphaZero work just with a value network?", "body": "<p>There is a nice <a href=\"https://stats.stackexchange.com/q/374100\">post</a> about the intuition why AlphaZero works.</p>\n<p>One of the advantages of using a policy network in the games where a perfect simulator is available (such as chess) is to save computation time by not generating all subsequent moves and then evaluating them using the value network. Instead, we can only focus on the good moves given by the policy network.</p>\n<p>However, besides the computation time savings of the policy network, are there any requirements why it needs to be used during training?</p>\n<p>What if we would replace the computation of the policy network with this logic: generate all subsequent moves, evaluate them using value network, and create policy from these predictions. Would this still work?</p>\n<p>I would appreciate any references where this topic is discussed.</p>\n", "pids": ["56ab70cd0cf2c98bf5bc717a", "5fe1c21391e0119a161edcb1", "5f2bcb5291e011b36ba9cd32"], "flag": 1}
{"question": "How Come My (D)DQN Fails To Learn?", "body": "<p>I am currently trying to teach a (D)DQN algorithm to play a 10x10 GridWorld game, so I can compare the two as I increase the number of moves the agent can take.</p>\n<p>The rewards are as follows:\nA step = -1\nkey = 100\nDoor = 100\nDeath wall = -100</p>\n<p>See the setup of the AI in the code.</p>\n<p>My problem is, that regardless of what I do, it ends up following the same strategy of just going to the outer walls and staying there. I presume this is because, the outer walls givve the least amount of punishment per step, as the risk of dying is decreased considerably. At the same time, as the moves increase, the chance of ending up at the outer walls increases as well (see the heatmaps)\n<a href=\"https://i.stack.imgur.com/s2v2J.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/s2v2J.png\" alt=\"Left: 1 move per direction Right: 8 moves maximum per direction\" /></a></p>\n<p>I've tried the following:</p>\n<ul>\n<li>Drastically decreasing the decay of the epsilon, such that it reaches its final state only\nin the last 10% of the training steps.</li>\n<li>Running 100k moves just to add to the EMR before I start actually counting the steps.</li>\n<li>Increasing the size of the network</li>\n<li>Giving out a negative -2 reward for staying in the same tile</li>\n<li>Feeding it the whole grid as the input vector</li>\n</ul>\n<p>None of this has worked. The longest I have trained a single model was for 14 million training steps. Still, same strategy as before.</p>\n<p>The way I evaluate the model is by(in this order):</p>\n<ul>\n<li>At every 1 millionth training step I run 50-100k evaluation steps where I record the outcome of every step</li>\n<li>Generating a heatmap to see whether or not it remains in the same few places (which are not the key or the door)</li>\n<li>Running its best policy and visually estimating whether or not it has improved</li>\n</ul>\n<p>CODE:\n<a href=\"https://github.com/BrugerX/IISProject3Ugers\" rel=\"nofollow noreferrer\">https://github.com/BrugerX/IISProject3Ugers</a></p>\n<p>Training is done through the TrainingLoop.py and the evaluation is done through the HeatMapEvaluation.py.</p>\n<p>What is it, that I have missed? How come, even after 14 million training steps, that the model still hasn't learnt to memorize the path in GridWorld?</p>\n", "pids": ["59ae3be32bbe271c4c71b97a"], "flag": 1}
{"question": "What techniques exist to increase the learning importance of difficult-to-learn labels over easy ones?", "body": "<p>I am training a model to place labels in image data. Some labels are learnt very quickly by the model while others take a long time to perfect. I cannot simply add more labeled data with only the labels I am looking to improve on since most of the image data contains a combination of the easy labels and the more difficult ones.\nAre there any smart ways to get the model to focus on the hard labels? I am just looking for some leads. Of course I can just train for longer but that seems inefficient as half the labels are already predicted almost perfectly.</p>\n", "pids": ["57a4e91aac44365e35c98023"], "flag": 1}
{"question": "Are there some known neural networks that, given an input image, can generate a similar image, with the same topic?", "body": "<p>Are there some known neural networks that, given an input image, can generate a <strong>similar image</strong>, with the same topic?</p>\n<p>Example: input = a photo of a cat on a green table, output = a generated photo of another cat on another green table.</p>\n<p>Example 2: input = a portrait of a man with glasses and a beard, output = a portrait of a generated person with similar glasses / beard (see &quot;ThisPersonDoesNotExist&quot;).</p>\n<p>I imagine it is possible with a <a href=\"https://en.wikipedia.org/wiki/Generative_adversarial_network\" rel=\"nofollow noreferrer\">GAN</a>, but more precisely which kind of architecture?</p>\n", "pids": ["573696006e3b12023e514358"], "flag": 1}
{"question": "What does the complexity equation constitute exactly in “Why Should I Trust You?” LIME paper", "body": "<p>I've recently been reading <a href=\"https://arxiv.org/pdf/1602.04938.pdf\" rel=\"nofollow noreferrer\">this paper on LIME</a>, an algorithm to interpret ANY machine learning model. I encountered this equation (in red) on page 4 and have just been having a hard time deciphering exactly what it means. I understand that it's a measure of complexity of something - but of what exactly? And what does each symbol in the equation entail and correspond to? What part(s) of the models and instances constitute and contribute to the complexity?</p>\n<blockquote>\n<p>For text classification, we ensure that the explanation is interpretable by letting the <em>interpretable representation</em> be a bag of words, and by setting a limit <span class=\"math-container\">$K$</span> on the number of words, i.e. <span class=\"math-container\">$\\color{red}{\\Omega(g)=\\infty \\mathbb{1}\\left[\\left\\|w_{g}\\right\\|_{0}&gt;K\\right]}$</span>. Potentially, <span class=\"math-container\">$K$</span> can be adapted to be as big as the user can handle, or we could have different values of <span class=\"math-container\">$K$</span> for different instances.</p>\n</blockquote>\n<p>Could anyone help me with it?</p>\n", "pids": ["599c797a601a182cd26427e2"], "flag": 1}
{"question": "Does Using the Same Background for Binary Classification Improve Model Accuracy?", "body": "<p>I am training a CNN that detects if a there is a pot of boiling water vs if there is a pot of boiling water with pasta inside. My hypothesis is that having the same background for both a positive and negative class image will improve model accuracy because it will force it to look exclusively at the foreground for hints. Is this hypothesis reasonable?</p>\n", "pids": ["619321415244ab9dcbbb49a5"], "flag": 1}
{"question": "How to use structural information in a Transformer?", "body": "<p>I am performing a Neural Machine Translation (NMT) task. In my case, input data has relational information.</p>\n<p>I know I can use a Graph Neural Network (GNN) and use a Graph2Seq model. But I can't find a good generational model for GNN.</p>\n<p>So I want to use Transformer. But then the challenge is how can I embed structural information there? Is there any open source artefact for Relational Transformer that I can use out of the box?</p>\n<p>Any pointers?</p>\n", "pids": ["60c57d6791e011368ce8c1b7"], "flag": 1}
{"question": "GAN model predictions before training is predictable", "body": "<p>I have a dataset of 3000 8x8 images, and I would like to train a GAN for an image generation purpose.</p>\n<p>I am planning to start with a simple GAN model and see if it overfits. Before training, I try to do a comparison of the discriminator model prediction using real image input against the whole GAN model prediction using random seed input. My thought process is that since this model is not trained yet, the output for real images and fake images by the discriminator should not be predictable.</p>\n<p>However, the discriminator model prediction using real image input always returns a value very close to <code>1.0</code>, and the whole GAN model prediction using random seed input always returns a value near <code>0.5</code> with a small deviation. I suspect that during training, the model would simply pull the <code>0.5</code> value near <code>0.0</code> and would never actually learn from the dataset.</p>\n<p>I try to increase the training parameters and different initializers, but the output is still the same.</p>\n<p>By ruling out the possibility a bad dataset, what could be the reason for this situation?</p>\n<p>This is some sneak peek of the generator and discriminator model building: <a href=\"https://pastebin.com/ehMDP7k6\" rel=\"nofollow noreferrer\">https://pastebin.com/ehMDP7k6</a></p>\n", "pids": ["573696006e3b12023e514358", "57a4e91aac44365e35c97d02", "58d82fced649053542fd7453"], "flag": 1}
{"question": "How to build a DQN agent with state and action being arrays?", "body": "<p>I have a Reinforcement-Learning environment where the state is an array of 0s and 1s with length equals to the number of users the agent must satisfy (11 users).</p>\n<p>The agent must choose one of 12 resources for the 11 users according to the state array. If <code>state[0] == 1</code>, that means that user0 needs a resource, so the agent must choose a resource out of the 12 resources it has. So, the action array's first element would be, for example: <code>action[0] = 10</code>, which means that resource 10 was allocated to user0.</p>\n<p>If the next user (user1) is asking for a resource as well, then the number of resources to choose from is <code>12 - 1</code>, in other words, because resource10 was already allocated to user0, it cannot be allocated to another user.</p>\n<p>If <code>state[X] == 0</code>, it means that userX is not asking for a resource, therefore it must not be allocated any resource.</p>\n<p>An example of a state array:</p>\n<pre><code>[1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0]\n</code></pre>\n<p>An example of an action array according to the state array example: (resource count starts at 0 | -1 indicates no resource was allocated)</p>\n<pre><code>[10, 2, -1, -1, -1, 3, 11, 5, -1, -1, -1]\n</code></pre>\n<p>I'm new to Reinforcement Learning and Deep Learning, and I have no idea how to translate that into a neural network.</p>\n", "pids": ["5e72341993d709897cfbb428", "59ae3bf12bbe271c4c71bc64"], "flag": 1}
{"question": "What is the difference between Attention Gate and CNN filters?", "body": "<p>Attention models/gates are used to focus/pay attention to the important regions. According to <a href=\"https://arxiv.org/pdf/1804.03999.pdf\" rel=\"nofollow noreferrer\">this paper</a>, the authors describe that a model with Attention Gate (AG) can be trained from scratch. Then the AGs automatically learn to focus on the target.</p>\n<p>What I am having trouble understanding is that, in the context of computer vision, doesn't a filter from the convolutional layers learn the region of interest?</p>\n<p>The authors say that adding Attention Gate reduces complexity when compared with multi-stage CNNs. But the job a trained AG would do is the same as that of a filter in a convolutional layer that would lead to the correct output, right?</p>\n", "pids": ["5a260c8117c44a4ba8a30771"], "flag": 1}
{"question": "Mutation That Loses Stop Codon", "body": "<p>Someone asked this in my class and my instructor wasn't sure in her answer, doesn't anyone know what happens in protein synthesis if a mutation causes mRNA to not possess a stop codon? Would the protein eventually stop? Would it keep coding into the poly-A chain and insert a bunch of phenylalanine?</p>\n", "pids": ["55a4c8de65ceb7cb02d85540", "55a65ec265ce054aad65914d"], "flag": 1}
{"question": "Is &quot;node embedding&quot; in GNN analogous to &quot;hidden layer&quot; of FFN?", "body": "<p>So in Graph Neural Network (GNN) we have node embeddings which is a feature vector that describes the node, is it analogous to hidden layer of Artificial neural network such as feed-forward neural network? After all hidden layer stores set of weights and biases to extract some &quot;feature&quot;, which begs the question if node embeddings are analogous to a hidden layer?</p>\n", "pids": ["5aed14d617c44a4438159031"], "flag": 1}
{"question": "Current state of the art and datasets for combining NLP and CV?", "body": "<p>I was considering a scenario where natural language processing (NLP) and computer vision (CV) are combined, for example in extended reality systems that get as input both natural language and non-verbal information, e.g. human gestures, and can comprehend it. For example, the agent would get language and non-verbal input and talk to a user.</p>\n<p>How could this be realized? My naive guess would be a conditional transformer, where the conditioning happens on the non-verbal input, but I'm not sure how exactly the conditioning could happen. <strong>What is a current state-of-the-art model for combining NLP and CV?</strong></p>\n<p>Also, are there datasets available for the aforementioned use case? I'm thinking of the scenario where a sentence, e.g.</p>\n<blockquote>\n<p>Yeah, I like him too!</p>\n</blockquote>\n<p>can either mean what is said, and the non-verbal input could be that the person saying it is smiling. However, if the non-verbal input is some laughter, then the above sentence might be meant ironically. <strong>Is there any dataset for this, where sentences and non-verbal inputs are combined?</strong> (Please note that I'm not talking about the generation of a sentence to an image, I'm referring to a <strong>combination</strong> of NLP and CV.)</p>\n<p>Thanks a lot!</p>\n", "pids": ["60c576e691e011368ce8c17a"], "flag": 1}
{"question": "Making generated texts from &quot;data-to-text&quot; more variable", "body": "<p>I am diving in data-to-text generation for long articles (&gt; 1000 words). After creating a template and fill it with data I am currently going down on paragraph level and adding different paragraphs, which are randomly selected and put together. I also added on a word level different outputs for date, time and number formats.</p>\n<p>The challenge I see is, that when creating large amounts of such generated texts they become boring to read as the uniqueness for the reader goes down.</p>\n<p>Furthermore, I also think it's easy to detect that such texts have been autogenerated. However, I still have to validate this hypotheses.</p>\n<p>I was wondering if there is an even better method to bring in variability in such a text?</p>\n<p>Can you suggest any methods, papers, resources or share your experience within this field.</p>\n<p>I highly appreciate your replies!</p>\n", "pids": ["5bdc31b417c44a1f58a0b8c2", "599c7987601a182cd2648373", "5ed0e04291e011915d9e43ee", "599c795b601a182cd2634920"], "flag": 1}
{"question": "Machine Learning Models for Longitudinal Data", "body": "<p>Recently, I had the following question about supervised classification models (e.g. random forest) for longitudinal data.</p>\n<p>Suppose I have the following data about students passing a fitness test - the students (each student has an &quot;id&quot;) who enroll in a school take a fitness test each year and record their height and weight (at the start of each school year, before the fitness test). They can either pass (1) or fail (0) the fitness test each year. The school is interested in knowing which students are likely to fail the fitness test, so they can focus more attention on these students. Naturally, some students might have taken the fitness test more times than other students.</p>\n<p>I simulated some data (using the R programming language) to show how the historical data might look like:</p>\n<pre><code>score &lt;- c(&quot;1&quot;,&quot;0&quot;)\nscore &lt;- as.numeric(sample(score, 1000, replace=TRUE, prob=c(0.3, 0.7)))\nid_sample &lt;- 1:140\nid &lt;- sample(id_sample, replace = TRUE, 1000)\nheight &lt;- abs(rnorm(1000, 150,5))\nweight &lt;- abs(rnorm(1000, 75,5))\n\ndata = data.frame(id, height, weight, score)\ndata &lt;- data[order(data$id),]\n</code></pre>\n<p>I then added two variables to this data - one to show how many times the fitness test was taken, the another to show the (cumulative) average number of times the test was passed:</p>\n<pre><code>library(dplyr)\ndata =  data.frame(data %&gt;% group_by(id) %&gt;% mutate(counter = row_number(id)))\ndata<span class=\"math-container\">$csum &lt;- ave(data$</span>score, data<span class=\"math-container\">$id, FUN=cumsum)\ndata$</span>average &lt;- data<span class=\"math-container\">$csum/data$</span>counter\n</code></pre>\n<p>Now, suppose some of the students are about to take this test again and we would like to predict what their score will be - some of these students are existing students, but some of these students are new and have never taken the test before (i.e. they have no historical data):</p>\n<pre><code>id_sample &lt;- 1:140\nid &lt;- sample(id_sample, replace = FALSE, 23)\nheight &lt;- abs(rnorm(23, 150,5))\nweight &lt;- abs(rnorm(23, 75,5))\n\nnew_data = data.frame(id, height, weight)\nnew_data &lt;- new_data[order(new_data$id),]\n\nid_sample &lt;- 141:200\nid &lt;- sample(id_sample, replace = FALSE, 5)\nheight &lt;- abs(rnorm(5, 150,5))\nweight &lt;- abs(rnorm(5, 75,5))\n\n#simulating data for students who never took the test before\nn_data = data.frame(id, height, weight)\nn_data &lt;- n_data[order(n_data$id),]\n\ntest_data = rbind(new_data, n_data)\n</code></pre>\n<p>Now, to this test data, (where applicable) I added &quot;longitudinal variables&quot; that take into account the number of times the students took the test and their most recent average cumulative score:</p>\n<pre><code>#counter\nmax = data.frame(data %&gt;% \n             group_by(id) %&gt;%\n             filter(counter == max(counter)))\n\ncolnames(max)[5] &lt;- &quot;max_counter&quot;\n\nmax<span class=\"math-container\">$max_counter = max$</span>max_counter + 1\n\ntest_with_counter =  merge(x = test_data, y = max, by = &quot;id&quot;, all.x = TRUE)\n\ntest  = test_with_counter[, c(1,2,3,7,9)]\n\n test<span class=\"math-container\">$max_counter[is.na(test$</span>max_counter)] &lt;- 1\n\n test<span class=\"math-container\">$average[is.na(test$</span>average)] &lt;- 0\n\n#formatting\ncolnames(test)[2] &lt;- &quot;height&quot;\ncolnames(test)[3] &lt;- &quot;weight&quot;\ncolnames(test)[4] &lt;- &quot;counter&quot;\ndata<span class=\"math-container\">$csum = NULL\ndata$</span>score = as.factor(data$score)\n</code></pre>\n<p>At this point, there is nothing stopping me from training a supervised classification model (e.g. random forest) to predict the &quot;score&quot; variable for the test data:</p>\n<pre><code>#skip cross validation for brevity of question\nlibrary(randomForest)\nrf &lt;- randomForest(score~., data=data)\npred = predict(rf, newdata = test)\n\nprint(rf)\n\nCall:\n randomForest(formula = score ~ ., data = data) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 23.4%\nConfusion matrix:\n    0   1 class.error\n0 636  79   0.1104895\n</code></pre>\n<p><strong>My Question:</strong> Does the approach that I have proposed for supervised classification of longitudinal data sound reasonable (e.g. better than &quot;nothing&quot;) - or are there any major statistical flaws on this approach (e.g. structural multicollinearity, variance inflation, etc.) ? Or is it better to use some supervised classification model/software implementation that has been specifically designed for longitudinal data (e.g. <a href=\"https://cran.r-project.org/web/packages/LongituRF/LongituRF.pdf\" rel=\"nofollow noreferrer\">https://cran.r-project.org/web/packages/LongituRF/LongituRF.pdf</a>)? Thanks!</p>\n<p>Note:</p>\n<ul>\n<li><p>This is a rough sketch of the situation I am dealing with - I am also planning to include variables such as &quot;number of days that elapsed since last fitness test&quot;.</p>\n</li>\n<li><p>The sample data in this stackoveflow question is randomly simulated and obviously wont show any longitudinal trends.</p>\n</li>\n<li><p>I have heard that models such as Random Forest have the ability to recover/model around complex interactions and correlations within the data that otherwise need to be explicitly specified in standard supervised models (<a href=\"https://ishwaran.org/papers/IKBL.AOAS.pdf\" rel=\"nofollow noreferrer\">https://ishwaran.org/papers/IKBL.AOAS.pdf</a>).</p>\n</li>\n</ul>\n", "pids": ["6184a0d25244ab9dcb28bff8"], "flag": 1}
{"question": "Should PPO always converge toward the global optimum?", "body": "<p>I'm trying to &quot;solve&quot; the OpenAI gym environment &quot;Humanoid-v3&quot;  using PPO. I got it to work to some degree (The NN is learning a policy and perfecting it. Average reward of about 5.5k). However, the learned policies do not yet resemble the human stride (like in the <a href=\"https://openai.com/blog/openai-baselines-ppo/\" rel=\"nofollow noreferrer\">PPO blog post</a>), which brought up a question.</p>\n<p>Should the algorithm always converge toward the global optimum (given good hyperparameters)? Or is a good convergence somewhat luck-based and you may need multiple training processes?</p>\n", "pids": ["5fc88628dfae549b1c499bf4"], "flag": 1}
{"question": "How does MAML inner loop optimization works?", "body": "<p>I started to learn meta-learning, reading the MAML paper <a href=\"https://arxiv.org/pdf/1703.03400.pdf\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/1703.03400.pdf</a></p>\n<p><a href=\"https://i.stack.imgur.com/kXMXz.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/kXMXz.png\" alt=\"enter image description here\" /></a></p>\n<p>In the inner loop, I am calculating adapted parameters for each task, I will be doing multiple steps of inner SGD.\nI will calculate adapted parameters after two or more gradient steps (<span class=\"math-container\">$\\theta{'}$</span>, <span class=\"math-container\">$\\theta^{''}$</span> , <span class=\"math-container\">$\\theta^{n}$</span>), then using testing parameters, I will have a loss in respect to the original <span class=\"math-container\">$\\theta$</span> (If I understand the derivation correctly). Now I am supposed to backpropagate through the gradient. Unfortunately, I am not sure how it is done...</p>\n<blockquote>\n<p><em>Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\nPage 3.</em>\n<br> &quot;The MAML meta-gradient update involves a gradient\nthrough a gradient&quot;</p>\n</blockquote>\n<p>To do this, I understand that I have to store each <span class=\"math-container\">$\\theta^{n}$</span>, but don't know how the loss from <span class=\"math-container\">$\\theta^{n}$</span> to <span class=\"math-container\">$\\theta^{n-1}$</span> is transferred up to the original  <span class=\"math-container\">$\\theta$</span>.<br>\nI guess that the for the last series of parameters (<span class=\"math-container\">$\\theta^{n}$</span>) loss is calculated in the standard way with the testing set, but then I somehow need to pass information saying how much the previous set of parameters was wrong... <em>(Gradient of the gradient?)</em></p>\n<p>I see Hessian and vector products popping up everywhere on the internet, but I cannot imagine how that works, and have no idea how it is calculated and passed/implemented...</p>\n<p>Can someone explain to me how the inner loop [back-propagation trough meta-gradient] is working - how the derivations go and how loss is transferred/updated?</p>\n", "pids": ["5e96db3891e01129d1a04091", "5550417845ce0a409eb3b9b3", "599c7974601a182cd263f01c"], "flag": 1}
{"question": "RL solutions for OpenAI Gym environments?", "body": "<p>Is there any place where people share their agent's settings for solving OpenAI Gym Environments?</p>\n<p>For example, I'd like to know what are good parameters for a DDPG agent to learn the task in Reacher-v2. I believe that a lot of people tried to solve it and maybe they shared their solution for achieving better performance.</p>\n", "pids": ["5e1d91563a55ac91798fe8e2"], "flag": 1}
{"question": "Does LSTM provide any unique value or advantages compared to other algorithms, including &quot;vanilla&quot; RNN?", "body": "<p>I have heard a lot of hype around LSTM for all kinds of time-series based applications including NLP. Despite this, I haven't seen many (if any) applications of LSTM where LSTM performs <em><strong>uniquely</strong></em> well compared to other type of deep learning, including more vanilla RNN.</p>\n<p>Are there any examples where LSTM does significantly better on a particular task, compared to other modern algorithms and architectures?</p>\n", "pids": ["5550411c45ce0a409eb3897f"], "flag": 1}
{"question": "How to tune hypeparametes in A2C-ppo?", "body": "<p>Im currently working with A2C. The model was able to learn open ai pong, i ran this as a sanity check that i havent made any bugs. Now im trying to make the model play breakout, but still after 10m steps the model has not made any significant progress. Im using baseline hyperparameters which can be found here <a href=\"https://github.com/openai/baselines/blob/master/baselines/a2c/a2c.py\" rel=\"nofollow noreferrer\">https://github.com/openai/baselines/blob/master/baselines/a2c/a2c.py</a>, except my buffersize have been from 512 to 4096.  Ive noticed that entropy decreases extremely slowly</p>\n<p><a href=\"https://i.stack.imgur.com/ahGMN.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/ahGMN.png\" alt=\"enter image description here\" /></a></p>\n<p>given the buffersize from the interval which i just gave. So my questions are how to make entropy decrease and how to increase rewards per buffer?  Ive tried to decrease the entropy coefficient to almost zero, but still it acts very weirdly.</p>\n<p>Update: Even when i set the entropy coef to zero entropy wont decrease, i guess i might have a bug?</p>\n<p><a href=\"https://i.stack.imgur.com/p7D2h.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/p7D2h.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/Frt4L.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/Frt4L.png\" alt=\"enter image description here\" /></a></p>\n", "pids": ["5736960a6e3b12023e51d64d"], "flag": 1}
{"question": "Hyperparameter tuning methods for neural networks", "body": "<p>I have a fully connected feedforward classifier neural network that uses the leaky ReLU activation function. I would like to apply a state-of-the-art hyperparameter tuning method to my methodology. Currently, the fitness function associated with each parameter setting is a weighted combination of (i) accuracy of both training and test data sets (<span class=\"math-container\">$acc_{tr}$</span> and <span class=\"math-container\">$acc_{ts}$</span>, respectively), (ii) numbers of activated hidden layers (<span class=\"math-container\">$nL$</span>) and their neurons (<span class=\"math-container\">$nN_l$</span>), and (iii) number of epochs (<span class=\"math-container\">$nE$</span>) - length of training. The fitness function is computed as follows:</p>\n<p><span class=\"math-container\">\\begin{equation}\\label{eqq}\n FF = 0.7 \\times (acc_{tr} + acc_{ts}) + 0.1 \\times \\frac{nL}{10} + 0.1 \\times \\frac{\\sum_{l \\in \\mathcal{L}} nN_l}{1000} + 0.1 \\times \\frac{nE}{2000}\n\\end{equation}</span></p>\n<p>Note that I have determined the weights in function <span class=\"math-container\">$FF$</span> based on my experimental observations. Potential values for the parameters of this neural network are given in the following table:</p>\n<p><a href=\"https://i.stack.imgur.com/TSfJC.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/TSfJC.png\" alt=\"enter image description here\" /></a></p>\n<p><span class=\"math-container\">$\\alpha$</span> here is the leakage parameter of the ReLU activation function. Considering that I am new to this field, my questions are as follows:</p>\n<ul>\n<li>Is the weighted fitness function an appropriate one? Should I include both training and test accuracies at the same time? Why?</li>\n<li>Do the potential values make sense for a fully connected feedforward classifier neural network with the leaky ReLU activation function? Are there any other parameters that I have to tune? Please consider that I have developed this neural network using the Keras library.</li>\n<li>The above table also shows the elite configuration. I have found this parameter setting using the iRace package. Do you recommend any other method for hyperparameter tuning in neural networks?</li>\n<li>I have seen many papers use genetic algorithms to tune their parameters. What are the advantages of using a genetic algorithm in comparison to the iRace package (if there is any)?</li>\n</ul>\n<p>Please kindly answer my above questions with supporting scientific references. Also, please let me know if there are any other considerations for the hyperparameter tuning of neural networks. Thank you!</p>\n", "pids": ["5c871f994895d9cbc6cebc7b"], "flag": 1}
{"question": "Last linear layer of the decoder of a transformer", "body": "<p>I am learning the transformers architecture from these two sources:</p>\n<p><a href=\"https://arxiv.org/pdf/1706.03762.pdf\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/1706.03762.pdf</a></p>\n<p><a href=\"https://jalammar.github.io/illustrated-transformer/\" rel=\"nofollow noreferrer\">https://jalammar.github.io/illustrated-transformer/</a></p>\n<p>I just wanted to ask about the final step in the decoder. Let's fix testing time. As I understand, the decoder starts with an input of dimension <span class=\"math-container\">$(N_{words},d_{emb})$</span>, where <span class=\"math-container\">$N_{words}$</span> is the number of words already predicted and <span class=\"math-container\">$d_{emb}$</span> is the embedding dimension.</p>\n<p>Now if we &quot;follow&quot; the following decoder steps, at each step (after e.g. the attention layers) we should have a vector of dimension <span class=\"math-container\">$(N_{words},d_{model})$</span> where <span class=\"math-container\">$d_{model}$</span> is the model dimension. In other words, up to the final linear layer we have <span class=\"math-container\">$N_{words}$</span> vectors which are <span class=\"math-container\">$d_{model}$</span>-dimensional.</p>\n<p>Are all these <span class=\"math-container\">$N_{words}$</span> vectors fed into the last linear layer (before the softmax) or, as I suspect, only the last of these vectors is used ? In the latter case the last linear layer would be a matrix of dimension <span class=\"math-container\">$d_{model}\\times N_{vocab}$</span>, where <span class=\"math-container\">$N_{vocab}$</span> is the vocabulary dimension.</p>\n<p>Is this correct ? Are there any issues in what I wrote ? Unluckily from the online sources I was not able to clarify this point...</p>\n<p>PS: I conjectured that the last linear layer is using just the last vector, because than I would understand what happens in training time, one would just use in that case all the output vectors from the decoder, instead of just the last one, to have a parallelized prediction.</p>\n", "pids": ["599c7987601a182cd2648373"], "flag": 1}
{"question": "Why not use only expert demonstrations in Imitation Learning approaches?", "body": "<p>Some IL approaches train the agents by using some specific ratio of expert demonstrations to trajectories generated using the policy being optimized.</p>\n<p>In the specific <a href=\"https://arxiv.org/abs/1809.03531\" rel=\"nofollow noreferrer\">paper</a> I'm reading they say <em>&quot;we experimented with various IL proportions (10-50% by increments of 10%) and observed that the RL/IL ratio does not seem to affect the performance of the trained policy by much.&quot;</em></p>\n<p>My question is: why not rely <em>only</em> on expert demonstrations instead of introducing the noise of trajectories generated by a sub-optimal policy?.</p>\n<p>My assumptions are:</p>\n<ol>\n<li>This noise helps explore the state space beyond the specific episodes experienced by the expert system.</li>\n<li>You might have expert systems that only work on a limited state space and do not scale to bigger, more complex environments. Therefore, although you <strong>can't</strong> use expert demonstrations in the bigger envs you still want to leverage their experience by learning their behavior in limited settings and the way to avoid overfitting to a specific, constrained policy is by always having some proportion of episodes generated by your policy being learned.</li>\n</ol>\n", "pids": ["5cede0fcda562983788db9c4"], "flag": 1}
{"question": "What is the loss function and training task on which the original BERT model was trained", "body": "<p>I was checking on sentence embeddings and stumbled across the BERT model which employs transformers.</p>\n<p>I understand that BERT applies a WordPice tokenizer (e.g. working like <a href=\"https://keras.io/api/keras_nlp/tokenizers/word_piece_tokenizer/\" rel=\"nofollow noreferrer\">https://keras.io/api/keras_nlp/tokenizers/word_piece_tokenizer/</a>) and then passes the tokens through several (transformer) layers.\nIf using the transformers library, the output of each hidden layer can be accessed easily as described here  <a href=\"https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\" rel=\"nofollow noreferrer\">https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/</a> .\nFor each token we can then obtain a word embedding and aggregate a sentence embedding by e.g. mean- or max-pooling over all word embeddings in a sentence.</p>\n<p>On <a href=\"https://d2l.ai/chapter_natural-language-processing-pretraining/bert-pretraining.html\" rel=\"nofollow noreferrer\">https://d2l.ai/chapter_natural-language-processing-pretraining/bert-pretraining.html</a> , I found that BERT can be trained on e.g. WikiText-2 (<a href=\"https://blog.salesforceairesearch.com/the-wikitext-long-term-dependency-language-modeling-dataset/\" rel=\"nofollow noreferrer\">https://blog.salesforceairesearch.com/the-wikitext-long-term-dependency-language-modeling-dataset/</a> ) but I do not see</p>\n<ol>\n<li>on which training task</li>\n<li>which loss function the original BERT model is trained?</li>\n</ol>\n<p>This is curcial, since it determines what pattern the model picks up.</p>\n<p>The last website states that the loss function is a cross-entropy loss. But I do not yet understand corss-entropy between what? What is the (X,y)-pairs used for training Bert?</p>\n", "pids": ["5bdc31b417c44a1f58a0b8c2"], "flag": 1}
{"question": "Do we need to know or verify properties of loss functions / metrics&#39; implementations?", "body": "<p>I will start with an example, in order to get to the general question.</p>\n<p>I was reading the following paper (<a href=\"https://www.cns.nyu.edu/pub/lcv/wang03-preprint.pdf\" rel=\"nofollow noreferrer\">https://www.cns.nyu.edu/pub/lcv/wang03-preprint.pdf</a>) about Structural Similarity Index (SSIM), which is a function used in computer vision. Basically, given two images, it returns (according to some criteria) &quot;how similar&quot; these images are.</p>\n<p>But what strikes me is that, in the paper, the following is stated: &quot;<em>we also would like the similarity measure to satisfy the following conditions</em>&quot;.</p>\n<p>I'll explain these properties now, but my question is the following:  <strong>why we would <em>like a function to satisfy some properties</em>?</strong> In other words, what I understand is that <strong>it is interesting to prove that these properties hold</strong>, am I right?</p>\n<p>Some years ago, I used SSIM not only as a metric to measure the performance of some algorithms, but also as a loss function itself. However, I definitively did not know about these properties, so it could be the case that I was optimizing (or measuring my results) with an implementation of the function that does not hold these properties, is that so?</p>\n<p>As for the properties, these are straightforward:</p>\n<ul>\n<li>Unique maximum:  <code>S(x, y) = 1 if and only if x = y </code></li>\n<li>Boundedness:  <code>S(x, y) ≤ 1 </code></li>\n<li>Symmetry:  <code>S(x, y) = S(y, x) </code></li>\n</ul>\n<p>So the problem of &quot;proving&quot; SSIM's properties is useful for me for to raise the next (more general) research question: <strong>do AI-developers usually now properties of their loss functions/metrics? Are these properties relevant (e.g., are there functions for critical tasks)? Are they already being verified?</strong></p>\n<p>I would appreciate some insight about this.</p>\n", "pids": ["5cede107da562983788e6d77"], "flag": 1}
{"question": "How to use RL on a robotic moving arm?", "body": "<p>I'm working on a simulation of a motor that is attached to a wing (Later, this will also have a real-life counterpart once I'll assemble all the components in our lab), and I can control the forces/torques that the motor applies. I want to use RL and find an optimal action in terms of</p>\n<blockquote>\n<p>&quot;<em>what force should the motor apply to maximize lift</em>&quot;.</p>\n</blockquote>\n<p>To make things clearer, check out the following figure</p>\n<p>                                              <a href=\"https://i.stack.imgur.com/RWhxa.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/RWhxa.png\" alt=\"enter image description here\" /></a></p>\n<p>So for example, I can find <span class=\"math-container\">$\\phi$</span> at every single time step <span class=\"math-container\">$t$</span> (using some 1st-year physics equations and python integrators) and this will be my state <span class=\"math-container\">$s$</span>.</p>\n<p>Are you familiar with approaches that deal with this problem?</p>\n", "pids": ["59ae3be32bbe271c4c71b8c3"], "flag": 1}
{"question": "How are IQ test scores affected by psychological stress or trauma?", "body": "<p>Does <a href=\"https://en.wikipedia.org/wiki/Psychological_stress\" rel=\"nofollow noreferrer\">mental stress</a> or <a href=\"https://en.wikipedia.org/wiki/Psychological_trauma\" rel=\"nofollow noreferrer\">trauma</a> have a significant impact on IQ test performance relative to baseline, and if so, how much?</p>\n<p>For example, if a person is affected by abuse, bullying, neglect, or some other stressor or trauma, then how much of an effect would that have on their test score?</p>\n", "pids": ["55a3c91dc91b587b09625598", "56d822c1dabfae2eeec76625", "53e9a818b7602d970315a8b9", "53e9a53fb7602d9702e621c3", "56d8df48dabfae2eee079329", "55a52b72612c6b12ab05c6e0", "53e9aa5cb7602d97033caf02", "55a643a765ce054aad621609", "56d83a27dabfae2eee5a4bed", "56d82904dabfae2eeeefd21f", "55a4d5e065ceb7cb02d98a84", "53e9bd55b7602d97049ea2dd", "53e9b42fb7602d9703f28380"], "flag": 1}
{"question": "What is the domain of the discriminator of a GAN?", "body": "<p>I've read that the discriminator <span class=\"math-container\">$D$</span> validates an image <span class=\"math-container\">$D(x)$</span>, where <span class=\"math-container\">$x$</span> is either a real image or a fake one created by the generator, i.e. <span class=\"math-container\">$ D(G(x))$</span>.</p>\n<p>What does the function of the discriminator return? Is it either 0 (marked as fake) or 1 (discriminator thinks the image is real)? I have read that this function returns the whole <span class=\"math-container\">$\\mathbb{R}$</span>, but I don't understand what the output then means.</p>\n", "pids": ["5e3a928fdf1a9c0c41ebe39e", "58d82fced649053542fd7453", "5e3a928fdf1a9c0c41ebe39e", "599c7956601a182cd2632333"], "flag": 1}
{"question": "Knowledge graph progress from 2012 to 2022?", "body": "<p>I watched <a href=\"https://vtrs.hep.com.cn/#/detail?id=b5b598ab-1036-4d30-9a6b-761b1f383d70\" rel=\"nofollow noreferrer\">this lecture</a> by <a href=\"http://www.tjudb.cn/dbgroup/index.php/Xin_Wang\" rel=\"nofollow noreferrer\">professor Xin Wang</a>, and a picture in the beginning interested me:</p>\n<p><a href=\"https://i.stack.imgur.com/Jn543.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/Jn543.png\" alt=\"enter image description here\" /></a></p>\n<p>The confusing thing is that this lecture was delivered on Sep. 19, 2022, but it seems from the diagram above that over the last ten years knowledge graph has made no progress. The diagram is still what I was shown when I was a student in 2015 or 2016.</p>\n<p>Since I cannot get a hold of this professor, I googled <a href=\"https://www.google.com/search?q=progress+of+knowledge+graph&amp;newwindow=1&amp;sxsrf=ALiCzsYYRVPMr6zHh9QDhiBigJq26qkEOg:1666073559215&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ved=2ahUKEwjho6rVj-n6AhXWQPUHHaxTDYIQ_AUoAXoECAIQAw&amp;biw=1280&amp;bih=629&amp;dpr=1.5#imgrc=jh1JJTQuE0HhVM\" rel=\"nofollow noreferrer\">knowledge graph progress pictures</a> but found that no single one mentioned any big events after 2012.</p>\n<p>What happened over the last decade to knowledge graph? Any big events?</p>\n", "pids": ["5e3940c73a55ace46ed436d2", "5f6dbda991e01153370054e0"], "flag": 1}
{"question": "Fine tuning a Deep Learning model post training", "body": "<p>I have trained a CNN in a binary classification problem, however the original problem has 6 different classes, of which, I am only interested in classifying one, so if it is that certain class or not.in this case, let's say class 2.</p>\n<p>After looking closely into the model's performance on test dataset, I have found that the model confuses class 2 with class 1 often. Is it common practice, to make a balanced dataset from the data that I have only from class 1 and class 2, and further train the model on that dataset? Are there any pieces of research/papers on this? If no, what other possible solutions would there be, of course other than making a new model?</p>\n", "pids": ["53e9b310b7602d9703dd99ee"], "flag": 1}
{"question": "How embeddings learned from one model can be used in another?", "body": "<p>In the <a href=\"https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\" rel=\"nofollow noreferrer\">website</a> the following explanation is provided about Embedding layer:</p>\n<blockquote>\n<p>The Embedding layer is initialized with random weights and will learn\nan embedding for all of the words in the training dataset.</p>\n<p>It is a flexible layer that can be used in a variety of ways, such as:</p>\n<p>It can be used alone to learn a word embedding that can be saved and\nused in another model later. It can be used as part of a deep learning\nmodel where the embedding is learned along with the model itself. It\ncan be used to load a pre-trained word embedding model, a type of\ntransfer learning.</p>\n</blockquote>\n<p>Isnt embeddings model specific? I mean to learn a representation of something we need the model that something was used to represent! so how can embeddings learned in one model can be used in another?</p>\n", "pids": ["5b1642a68fbcbf6e5a9b7dd9"], "flag": 1}
{"question": "How to validate my knowledge of models implementation, pros and cons and area of applicability?", "body": "<p>So I've been doing ML for ~2 years in industry, I'm a BSc in applied math, finished several courses on ML/DL on coursera, read some specific topics in ML/DL books. Seem to be in the know, more or less.</p>\n<p>But the catch is: I've never <em>really</em> validated my knowledge, as in taken an exam or certification. Some time has passed since I read theory and I sort of think that I'm losing it (especially since all I did was time-series forecasting).</p>\n<p>What are the possible ways to validate that I actually understand stuff? Do I just text random ML experts &quot;hey could I tell you stuff and you say whether that's bs or not&quot;?..</p>\n", "pids": ["61d3bae45244ab9dcba35383"], "flag": 1}
{"question": "How can rewards and loss calculation be extended to multiple agents in a vanilla policy gradient RL setting?", "body": "<p>Say I have a simple multi-agent reinforcement learning problem using vanilla policy gradient methods (i.e. REINFORCE) that is currently running with one network per agent. If I can say that each of my agents:</p>\n<ul>\n<li>are all of the same class</li>\n<li>have ~equivalent environmental contexts (on average)</li>\n<li>have no privileged state relative to other agents</li>\n<li>performs updates equally to all other agents</li>\n<li>DO use LSTMs (but store and reset memory states separately)</li>\n<li>DO receive rewards for individual actions based on their individual states</li>\n</ul>\n<p>...is it possible to use one network for all agents so as to minimize training time? And if so, how do I combine rewards and generate losses? For instance, if I calculate loss as the -logprob * reward (in the REINFORCE case), could I simply sum or average this over all agents and then backprop accordingly?</p>\n", "pids": ["5cede0ebda562983788c9efc"], "flag": 1}
{"question": "Research on the van Norden percept", "body": "<p>What are the latest research and explanations concerning this auditory effect? I haven't managed to turn up much on the net, so just to check that I've named it correctly, my experience of it was being exposed to two alternately repeated beeps differing distinctly in pitch and finding that after a while I just heard a single repeated beep of constant pitch as if my brain had merged the two. </p>\n\n<h3>Context</h3>\n\n<p>Jansson (1994) writes:</p>\n\n<blockquote>\n  <p>Music may also be intercepted successively by noise bursts and still\n  be perceived as continuous, even if the music signals are deleted\n  within the noise bursts (van Norden, 1975)</p>\n</blockquote>\n\n<h3>References</h3>\n\n<ul>\n<li>Jansson, E. V. (1994). Violin timbre and the picket fence. Quarterly Progress and Status Report, KTH, Stockholm, 35, 79-84.<a href=\"http://www.speech.kth.se/prod/publications/files/qpsr/1990/1990_31_2-3_089-095.pdf\" rel=\"nofollow\">PDF</a></li>\n<li>van Norden, L.P.A.S. (1975): Temporal Coherence in the Perception of Tone Sequences, Thesis, Technical University, Eindhoven.</li>\n</ul>\n", "pids": ["56d81aaddabfae2eee911641", "5c865f674895d9cbc651a423", "55a66cfb65ce054aad6764fd"], "flag": 1}
{"question": "Are masks needed for images that don&#39;t contain the object of interest in (binary) Image Segmentation tasks?", "body": "<p>Total Dataset :- 100 (on case level)</p>\n<p>Training :- 76 cases (18000 slices)\nValidation :- 19 cases (4000 slices)\nTest  :- 5 cases (2000 slices)</p>\n<p>I have a dataset that consists of approx. Eighteen thousand images, out of which approx. Fifteen thousand images are of the normal patient and around 3000 images of patients having some diseases. Now, for these 18000 images, I also have their segmentation mask. So, 15000 segmentations masks are empty, and 3000 have patches.</p>\n<p>Should I also feed my model (deep learning, i.e., unet with resnet34 backbone) empty masks along with patches (non empty mask)?</p>\n", "pids": ["5a260c8117c44a4ba8a30b08"], "flag": 1}
{"question": "Batching together similar length sequences to avoid padding and packing", "body": "<p>I am training an RNN in PyTorch to produce captions for images. It's a pretty standard architecture – the image is processed by a pre-trained InceptionV3 to extract features, the recurrent module processes the words seen so far and then its result is merged with image features and fed through a linear layer to produce a probability distribution over the vocab to predict the next word. A network trained this way can auto-regressively predict a whole caption for an image (it's seeded with an artificial  token at the beginning to have a preceding sequence to start off with).</p>\n<p>To train the network every caption is decomposed like this in the training dataset:</p>\n<pre><code>X, y\n&lt;START&gt;, a\n&lt;START&gt; a, man\n&lt;START&gt; a man, is\n&lt;START&gt; a man is, sitting\n&lt;START&gt; a man is sitting, on\n&lt;START&gt; a man is sitting on, a\n&lt;START&gt; a man is sitting on a, chair\n&lt;START&gt; a man is sitting on a chair, &lt;END&gt;\n</code></pre>\n<p>The result is that there is a lot of input sequence length variation in the training data which is a problem since we would need a lot of padding in batches. I am aware that there are techniques of counteracting this (<code>pack_padded_sequence</code> in PyTorch) but I came up with another idea.</p>\n<p>I am modifying the <code>Sampler</code> object that's used to provide indices for the <code>DataLoader</code> to construct batches in such a way that the <code>Sampler</code> orders all of the example indices by input sequence length, groups it into batch-size chunks, and shuffles the chunks before feeding them to the <code>DataLoader</code>. As a result the sequences in individual batches are almost always the same length – not because of any padding but because of the fact that we ordered the examples by length before grouping them. There will be some batches that will encompass examples on a border of length groups so some padding will be necessary but it will be minimal (just one zero for a group of lengths [5, 5, 5, 6, 6, 6] for example) and the number of such groups would be negligible (~0.002% of the batches in my case).</p>\n<p>My question is – does this method introduce some kind of drawback that I am not aware of? I find it simpler than having completely random batches and padding and packing them. I can't tell however, if it would introduce some kind of bias to the model. My intuition tells me that this should not be problem since the sequence lengths for batches would vary greatly across training (since I am shuffling the index chunks), but I wanted to get a second opinion. I guess the question boils down to -&gt; is sequence length variation <strong>within the batch</strong> important for proper training? Or, for this specific case -&gt; is it important that the net process examples decomposed from a single caption <strong>within the same batch</strong> or close to each other time-wise?</p>\n<p>I'd be happy to train the network with both solutions and check the results myself but it's quite time-expensive and I'd prefer to avoid some stupid stuff if I can.</p>\n", "pids": ["599c7987601a182cd2648373"], "flag": 1}
{"question": "Group image classification for whether containing unrelated images", "body": "<p>I'm kind of new to computer vision, and wondering whether this is any existing researches / solutions to following scenarios.</p>\n<p>Suppose I have a dataset, each data point contains a few images (&lt; 20 images), and a corresponding label. The label indicate whether those images contain any unrelated images.</p>\n<p>For example,<br />\nif the images are {apple, apple, apple} then the label is false.<br />\nif the images are {apple, basketball, basketball} then the label is true.</p>\n<p>I would like to build a model to classify whether those group of images contain such unrelated images.</p>\n<p>Seems the idea appeared in my mind is to have a model such as following</p>\n<ol>\n<li>image decoder (e.g efficient net) to decoder each image in the data point. Then each datapoint contains a few images after decoding</li>\n<li>a self-attention layer for every image above after decoding to measure a similarity matrix for all images in this data point.</li>\n<li>flatten above similarity matrix, and then connect to a fc layer into a single node as the prediction result.</li>\n</ol>\n<p>Loss function would just be the binary cross entropy with the actual label.</p>\n<p>I searched a bit, seems there isn't too much researches about such group classification, so not very sure whether above model make much sense.. Any idea would be appreciate, thanks!</p>\n", "pids": ["58d82fc8d649053542fd5a7a"], "flag": 1}
{"question": "Is there a disorder that causes one to give inanimate objects human emotions?", "body": "<p>For example, if one is using multiple pens to write something and has not used one of them in awhile, one may think it is \"feeling\" \"left out\" and so will switch to use that one. A logical mind KNOWS that inanimate objects cannot feel but one may have such empathy for all things - living or not - that one may attribute human feelings and emotions to them and an emotional brain does this automatically. It is not a conscious action, it is automatic and it dictates how one interacts with things. One can use a logical mind to recognize it but stills feel compelled to make sure everything is taken care of and included. Is this a specific disorder or just a piece of one of another disorder?</p>\n", "pids": ["55a41c9965ce5cd7b3c4991b"], "flag": 1}
{"question": "Effects of hyperparameters in Q-learning", "body": "<p>While playing around with the learning rate and discount factor in the Q-learning algorithm, I noticed some behavior that I could not really understand myself.</p>\n<p>Firstly, I noticed that increasing the learning rate increased the variance in total reward from the optimal policy. A low learning rate always gave the same total rewards when I ran the algorithm, but a high learning rate yielded different total rewards. Why is that?\nI could see this same behavior when decreasing the discount factor. I once again do not understand why.</p>\n<p>Secondly, I saw that increasing the discount factor resulted in longer learning time. I realize why increasing the learning rate increases learning time (number of episodes until convergence) by definition, but not necessarily why this would hold for the discount factor as well.</p>\n", "pids": ["5d9c5e463a55ac916a95f96c"], "flag": 1}
{"question": "Survey on non-machine learning object detection algorithms", "body": "<p>I am working on a project in which I will be performing object detection on deformed objects. Unfortunately, there isn't enough data sets to train them on some neural network. I am looking for reference on computer vision algorithms that does not require learning or training on datasets. Rather, topics arising from &quot;structure from motion&quot; that are popular within the computer vision community.</p>\n<p>Some note: The object detection will take place in an open environment rather close environment.</p>\n", "pids": ["5eba73be91e01108d77cf805", "5a260c8617c44a4ba8a323ef", "605aa1f5e4510cd7c86ab29f", "62cf89cd5aee126c0f563daf"], "flag": 1}
{"question": "When do we use the neural network to predict value during the expansion stage of MCTS in the AlphaZero algorithm?", "body": "<p>According to what I understand from the <em>AlphaZero</em> algorithm, a neural network is used to set value and prior probability for a node during the expansion stage of MCTS. On the other hand, according to the rules of the game, we need to set the value equal to +1 a win, -1 for a loss, or 0 for a draw.</p>\n<p><strong>Question</strong>: When do we use the neural network to predict the value and when do we use the rules of the game to set the value during the expansion stage of MCTS in <em>AlphaZero</em>?</p>\n", "pids": ["5a73cbcc17c44a0b3035f7b3"], "flag": 1}
{"question": "GAN with multiple discriminators", "body": "<p>I am looking for literature recommendations regarding GANs with multiple discriminators.\nIn particular, I am looking for examples where each discriminator has a slightly different learning objective, rather than learning on different data. My thinking was that the generator sometimes is exposed to reward sparsity: i.e. its samples get constantly rejected. Having multiple objectives be optimised through multiple discriminators might help alleviate this problem to a certain extent, as it increases the chance of positive feedback from one of the discriminators. Do you know of any examples, and does GAN training with multiple discriminators generally make sense or does it make training more unstable for some reason I have not considered?</p>\n", "pids": ["5b3d98cc17c44a510f801f85"], "flag": 1}
{"question": "For specific tasks, is it better to fine-tune models on examples or just use prompting with the context of the task?", "body": "<p>These days large language models cover a vast amount of topics and information, but I wanted to understand: <em>For specific tasks, is it better to fine-tune models on examples or just use prompting with the context of the task?</em></p>\n<p>For example, if I wanted to train a language model to do question answering for linear algebra, is it better to train it with examples of linear algebra problems and their solutions, or try out different prompts?</p>\n", "pids": ["607ffd8d91e011772654f712"], "flag": 1}
{"question": "What is the advantage of adding CNN to LSTM for forecasting sequential data?", "body": "<p>I am working with simulated sequential data and the goal is to forecast that data. Long-short-term-memory (LSTM) is one of the most advanced models to forecast time series according to this <a href=\"https://ai.stackexchange.com/questions/27312/advantages-of-cnn-vs-lstm-for-sequence-data-like-text-or-log-files\">post</a>. I can imagine that it is a good model because of the memory-cells they use which are useful when learning of the past.</p>\n<p>This <a href=\"https://journalofbigdata.springeropen.com/articles/10.1186/s40537-022-00599-y\" rel=\"nofollow noreferrer\">paper</a> discussed the use of CNN in time-series analysis. It says:</p>\n<blockquote>\n<p>CNN is suitable for forecasting time-series because it offers dilated\nconvolutions, in which filters can be used to compute dilations\nbetween cells. The size of the space between each cell allows the\nneural network to understand better the relationships between the\ndifferent observations in the time-series [14].</p>\n</blockquote>\n<p>It even outperformed LSTM:</p>\n<blockquote>\n<p>A specific architecture of CNN, WaveNet, outperformed LSTM and the\nother methods in forecasting financial time-series [16].</p>\n</blockquote>\n<p>I see more and more posts about the usage of CNN in combination with LSTM, but I can't find any information about the advantages and disadvantages of using these in combination.</p>\n<p>This post (<a href=\"https://ai.stackexchange.com/questions/27312/advantages-of-cnn-vs-lstm-for-sequence-data-like-text-or-log-files\">Advantages of CNN vs. LSTM for sequence data like text or log-files</a>), it is asked about the advantages of CNN vs. LSTM. But I would like to know the advantages and disadvantages of adding CNN to LSTM for forecasting univariate sequential data? Or should you use one of the two algorithms?</p>\n", "pids": ["5bdc31b817c44a1f58a0c60f", "5736986b6e3b12023e72fa3b"], "flag": 1}
{"question": "How can a language model keep track of the provenance of the main knowledge/sources used to generate a given output?", "body": "<p>One of the main criticisms against the use of ChatGPT on Stack Exchange is that it doesn't attribute the main knowledge/sources used to generate a given output. How can a language model keep track of the provenance of the main knowledge/sources used to generate a given output?</p>\n", "pids": ["639be1d090e50fcafd578d9b"], "flag": 1}
{"question": "DQN with experience history to learn from already saved - which reward should I take?", "body": "<p>I want to train a DQN model in an off-policy fashion, where my behavior policy is an older agent. I have a big memory of a lot of episodes of this agent. Now I want to find a better policy using DQN. Now I am just wondering, in the &quot;normal&quot; DQN case you would use the experience replay buffer and would update behavior and target policy online (behavior not really online but with the time lag introduced after which these parameters are also updated).</p>\n<p>In my case, I already have all the experience and would like to learn from it. Do you think it makes sense to use the exact same procedure in this context, so sampling one new action, state and immediate reward, follow up action or could it be better here to use the fact that all experience is already stored to exchange <span class=\"math-container\">$R_{t+1} + \\gamma  \\max Q(S_{t+1},a)$</span> with some more future information about the rewards (up to the point of Monte Carlo where you take <span class=\"math-container\">$G_t$</span> so the discounted cumulative reward seen during the episode from point t onwards)?</p>\n", "pids": ["5eb7896cda5629cf244307b4"], "flag": 1}
{"question": "What is the difference between the term &quot;generative&quot; in classical machine learning and deep learning?", "body": "<p>There are lots of explanations on DGM (Deep Generative Model) and generative classifier (most of the explanations on which are about generative classifier vs discriminative classifier)</p>\n<p>But, I can hardly find the common parts between the two concepts. In my understanding, 'generative' from DGM is quite straightforward - it almost goes the same with its literal meaning. In the contrary, 'generative' from the comparisons with the discriminative model is a little bit technical but it's the one that took the word earlier than the former one. (Jordan and Ng, 2002).</p>\n<p>Is it just that these two concepts are not really unrelated? Were they just used just because they do produce some distributions while learning?</p>\n", "pids": ["6047925891e0116b67c79374"], "flag": 1}
{"question": "Relationship between processing speed and IQ in twice exceptional children", "body": "<p>How come some twice exceptional children (i.e., intellectually gifted children who have some form of disability) have high iq, but low processing speed? Isn't processing speed a factor of intelligence? If not, why do iq tests have a time limit?</p>\n", "pids": ["56d92a68dabfae2eeed53a31"], "flag": 1}
{"question": "Are there any advantages of encoding an image as a graph to use in Graph Convolutional Networks?", "body": "<p>I have seen this encoding of an image as a graph:</p>\n<ul>\n<li>The set of the nodes <span class=\"math-container\">$V$</span> is the set of pixels. If the image is of size <span class=\"math-container\">$10\\times10$</span>, then we have <span class=\"math-container\">$10\\cdot10=100$</span> pixels.</li>\n<li>Each node has a length 3 feature vector <span class=\"math-container\">$x_i = (r,g,b)$</span> which states the Red, Green and Blue intensity for each pixel.</li>\n<li>All nodes are connected. Furthermore, an adjacency matrix <span class=\"math-container\">$A$</span> contains at the element <span class=\"math-container\">$(i,j)$</span> the distance between pixel <span class=\"math-container\">$i$</span> and <span class=\"math-container\">$j$</span> encoded as a number between zero and one. For instance, <span class=\"math-container\">$A_{2,2}=0$</span> and <span class=\"math-container\">$A_{firstpixel, lastpixel}=1$</span></li>\n</ul>\n<p>Is this better for any reason, in any context? Maybe using this in GCN makes sense for some applications?</p>\n<p>I honestly don't see the point. GCNs are used for either link prediction or node classification. In this case, the nodes have no classification (they're just pixels) and the link is just the distance between the pixels, and there's of course no interest in predicting links here.</p>\n<p>Is my intuition wrong?</p>\n", "pids": ["5bdc31b417c44a1f58a0ba6c", "53e9a4ebb7602d9702e0c0c0"], "flag": 1}
{"question": "Is there a neural network method to encode a directed graph?", "body": "<p>I want to do a graph classification task. Those graphs are directed, and their edges have features. I knew little about graph representation methods, but I did some research, and find most of the works for graph classification seem to be based on undirected graphs. So is there a way to encode this kind of graph? Or any suggestions to encode this kind of graph?</p>\n", "pids": ["60b6e7b191e011903fc2b99a", "5bdc31b417c44a1f58a0ba6c", "58437722ac44360f1082efeb"], "flag": 1}
{"question": "Is there a mathematical proof that a binary neural network can approximate any function with arbitrary accuracy?", "body": "<p>Since the Universal approximation theorem shows that standard multilayer feedforward networks with as few as a single hidden layer, sufficient hidden units, and arbitrary bounded and nonconstant activation function can approximate any continuous function with arbitrary accuracy, does this theory also apply to binary neural networks? Is there a specific mathematical proof that binary neural networks can fit any function.</p>\n", "pids": ["5aed14d617c44a443815923d", "601d36fe91e0119457922478"], "flag": 1}
{"question": "How does masturbation influence your brain and dreams?", "body": "<p>What exactly changes in your brain the moment after you've finished masturbating? Could there be any effect neuro-psychologically on dreams or lucid dreaming?</p>\n", "pids": ["53e9aadfb7602d970346080d"], "flag": 1}
{"question": "Solve the AI alignment problem using (meta-level) AI itself?", "body": "<p>If the AI alignment problem is one of the most pressing issues of our time, could AI itself augment our (i.e., human) quest to solve the alignment problem? Or would AI itself actually be counter-productive for such a meta-level goal?</p>\n", "pids": ["63a1750c90e50fcafd1f38d7"], "flag": 1}
{"question": "Why exactly are the reflections of sunlight in this dragonfly&#39;s eye hexagonal?", "body": "<p>I photographed a rather cooperative, large dragonfly today and after getting back to my desk and looking closer at the images I realized that the reflection of the Sun in its eyes produced large hexagonal bright spots that are:</p>\n<ol>\n<li>much larger/wider than if the eye surface were smooth specular reflector</li>\n<li>relatively uniform in brightness all the way to the edge</li>\n<li>have very sharp edges, transition from bright to dull red is very abrupt.</li>\n</ol>\n<p>I'm aware that the components of <a href=\"https://en.wikipedia.org/wiki/Compound_eye\" rel=\"noreferrer\">compound eyes</a> are usually at least roughly hexagonally packed, but what is happening here is something more than that.</p>\n<p>What is it about a dragonfly's compound eye that can account for all three of these characteristics of reflected sunlight?</p>\n<p>Presumably this is the same red dragonfly species as is seen in <a href=\"https://biology.stackexchange.com/q/95610/27918\">Identify these two large, colorful dragonflies in Taiwan?</a> It's the same area and time of year.</p>\n<p><a href=\"https://i.stack.imgur.com/yIfbF.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/yIfbF.png\" alt=\"red dragonfly with hexagonal spots in its eyes\" /></a></p>\n<p>Two more taken at different angles relative to the Sun. (click for larger)</p>\n<p><a href=\"https://i.stack.imgur.com/uwJRX.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/uwJRXm.png\" alt=\"red dragonfly with hexagonal spots in its eyes\" /></a> <a href=\"https://i.stack.imgur.com/wFs6v.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/wFs6vm.png\" alt=\"red dragonfly with hexagonal spots in its eyes\" /></a></p>\n", "pids": ["53e9afeeb7602d9703a40978"], "flag": 1}
{"question": "NN Architecture for the detection of &quot;sparse&quot; Objects", "body": "<p>I have a document digitalization task where I want to detect technical drawings from images. These Images mostly consist of objects made up of combination of shapes like lines, circles and rectangles. See this example: <a href=\"https://i.stack.imgur.com/lWeMr.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/lWeMr.png\" alt=\"Example Drawing\" /></a>.</p>\n<p>What I want as the result is a detection of all &quot;objects&quot; in this image like e.g. switches, wirings and devices that are present.</p>\n<p>I already tried multiple network architectures like:</p>\n<ul>\n<li>YOLO</li>\n<li>DeepLab</li>\n<li>UNet (for Pixel based classification)</li>\n</ul>\n<p>Generally I observe that all these approaches work well for small objects but have big problems with &quot;bigger&quot; objects due to their &quot;sparsity&quot;. I guess thats not surprising if you consider the nature of CNNs.</p>\n<p>One one hand my task seems simple due to things like</p>\n<ul>\n<li>high contrast</li>\n<li>limited set of shapes (or &quot;poses&quot;) for the different objects</li>\n</ul>\n<p>But I think CNNs all have problems with the &quot;sparseness&quot; of the objects as its only the boundary that is detectable and the inner is often empty.</p>\n<p>Has anyone here an Idea which architectures to try or links to papers to read for these kinds of problems?\nIdeally I would like to get the list of objects as output but I am unsure how to encode this in the NN as e.g. YOLO does this by an approach that would not work in my scenario, I think (merging all &quot;inner&quot; boxes that show the same object).</p>\n<p>Thanks already!</p>\n", "pids": ["5f803c8f91e01119a5df749b"], "flag": 1}
{"question": "Why does CLIP use a decoder-only transformer for encoding text?", "body": "<p>In CLIP [1], the authors train a model to learn multi-modal (text, audio) embeddings by maximizing the cosine similarity between text and image embeddings produced by text and image encoders.</p>\n<p>For the text encoder, the authors choose to use a variant of GPT2 which is a decoder-only transformer, taking the activations of the highest layer of the transformer at the [EOS] token the feature representation of the text (emphasis mine):</p>\n<blockquote>\n<p>The text encoder is a Transformer (Vaswani et al., 2017) with the architecture modifications described in <strong>Radford et al. (2019)</strong>. As a base size we use a 63M-parameter 12- layer 512-wide model with 8 attention heads. The trans- former operates on a lower-cased byte pair encoding (BPE) representation of the text with a 49,152 vocab size (Sennrich et al., 2015). For computational efficiency, the max sequence length was capped at 76. The text sequence is bracketed with [SOS] and [EOS] tokens and the <strong>activations of the highest layer of the transformer at the [EOS] token are treated as the feature representation of the text</strong> which is layer normalized and then linearly projected into the multi-modal embedding space.</p>\n</blockquote>\n<p>I found this pretty weird considering that they could have used an encoder (a-la BERT) which to me seem more fitted to act as encoders than decoders. Perhaps they wanted to enable generative text capabilities, but they could've achieved that with an encoder-decoder architecture (a-la T5) too.</p>\n<p>I was expecting ablations on the text-encoder architecture, motivating their choices, but found none. Any clue why they made these choices?</p>\n<h1>References:</h1>\n<p>[1] A. Radford et al., ‘Learning Transferable Visual Models From Natural Language Supervision’, in Proceedings of the 38th International Conference on Machine Learning, Jul. 2021, pp. 8748–8763. Accessed: Feb. 07, 2023. [Online]. Available: <a href=\"https://proceedings.mlr.press/v139/radford21a.html\" rel=\"nofollow noreferrer\">https://proceedings.mlr.press/v139/radford21a.html</a></p>\n", "pids": ["62c28ae55aee126c0f8a207c", "5cf48a45da56291d582a879b", "5ca600ae6558b90bfa4d76e1"], "flag": 1}
{"question": "Why do LLMs need massive distributed training across nodes -- if the models fit in one GPU while batch decreases the variance of gradients?", "body": "<h1>Why do large language models (LLMs) need massive distributed training across nodes -- if the models fit in one GPU and larger batch only decreases the variance of gradients?</h1>\n<p>tldr: assuming for models that don't need sharding across nodes, why do we need (massive) distributed training if the models (e.g. CLIP, Chinchilla, even really large GPTs e.g. CLIP fits in a V100 32GB) fit in one GPU and larger batch only decreases the variance of gradients (but not expose ore tokens or param updates)? A larger batch doesn't necessarily mean we train on &quot;more data/tokens&quot; -- or at least that doesn't seem to be wrt SGD like optimizers.</p>\n<hr />\n<p>Intuitively, it feels that if we had a larger batch size then we have more tokens to learn about -- but knowing some theory of optimization and what SGD like algorithms actually do -- a larger batch size only actually decreases the variance of gradients. So to me it's not clear why massie distributed training is needed -- at all unless the model is so large that it has to be shared across nodes. In addition, even if the batch was &quot;huge&quot; -- we can only do a single gradient update.</p>\n<p>I feel I must be missing something obvious hence the question given how pervasive massive distributed training is.</p>\n<p>In addition some toy training curves with V100s &amp; T5's show me there is very little if any benefit in additional GPUs\n<a href=\"https://i.stack.imgur.com/8pZTP.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/8pZTP.png\" alt=\"enter image description here\" /></a></p>\n<p>In addition, it seems from nonGPT we know small batch sizes are sufficient to train (reference <a href=\"https://github.com/karpathy/nanoGPT\" rel=\"nofollow noreferrer\">https://github.com/karpathy/nanoGPT</a> but I did ask Karpathy directly to confirm  <a href=\"https://github.com/karpathy/nanoGPT/issues/58\" rel=\"nofollow noreferrer\">https://github.com/karpathy/nanoGPT/issues/58</a>).</p>\n<p>I am missing something obvious, but I wanted to clear this up in my head since it seems to be a foundation thing in training foundation models.</p>\n<p>Related to the previous, I've also been unsure about the role of the batch size in training LLMs compared to traditional deep learning. In traditional deep learning when we used epochs to train, a model <strong>the larger the batch size the quicker we could go through an epoch</strong> -- so the advice I received (e.g. approximate advice by Ruslan Salakhutdinov's at the Simon's institute for deep learning tutorials) was to make the batch size large. Intuitively, the larger the batch size the more data the model sees per iteration. But mathematically this only really improves the variance of the gradient -- which isn't immediately obvious is what we want (I've done experiments and seen papers where noisy gradients lead to better models).\nIt is clear too the that the larger the context size the better (for everything, but for the sake of this conv it's better for training) -- whenever possible.  But context size is totally different from batch size. So my question is, how does distributed training, especially at the node level help at all if batch size isn't really the helping factor (which might be a wrong assumption)? So the only role for distributed training I see is if the model is to large to fit in 1 node -- since I'm arguing there is no point to make the batch size too large (I'd guess 64-32 is fine due to the CLT).</p>\n<p>What am I missing? Empirical answers are fine! Or any answers are fine!</p>\n<hr />\n<p>Related:</p>\n<ul>\n<li>cross quora: <a href=\"https://www.quora.com/unanswered/Why-do-large-language-models-LLMs-need-massive-distributed-training-across-nodes-if-the-models-fit-in-one-GPU-and-larger-batch-only-decreases-the-variance-of-gradients\" rel=\"nofollow noreferrer\">https://www.quora.com/unanswered/Why-do-large-language-models-LLMs-need-massive-distributed-training-across-nodes-if-the-models-fit-in-one-GPU-and-larger-batch-only-decreases-the-variance-of-gradients</a></li>\n<li>cross reddit: <a href=\"https://www.reddit.com/r/learnmachinelearning/comments/113whxu/why_do_llms_need_massive_distributed_training/\" rel=\"nofollow noreferrer\">https://www.reddit.com/r/learnmachinelearning/comments/113whxu/why_do_llms_need_massive_distributed_training/</a></li>\n</ul>\n", "pids": ["63ae56ca90e50fcafda968f1"], "flag": 1}
{"question": "Are there versions of attention that do not require a key-value pair, but just act on one input?", "body": "<p>Are there versions of attention that do not require a key-value pair, but just act on one input? Or does this idea simply not make sense?</p>\n", "pids": ["599c7987601a182cd2648373"], "flag": 1}
{"question": "Can I speed up NN training by manually guiding training?", "body": "<p>I have not found any neural network training methods that recommend manually intervening in the training process while it is happening.  However, some experiments I've done seem to show this can be an effective way to speed up training.</p>\n<p>For example, once the network has converged on a suboptimal solution, I can have the network focus on particular sections of the training data for awhile, and then switch back to the entire training data to get the network out of the local optima.  Gradient descent alone would not be able to do this because while I have the network focus on a subset of the training data the error becomes very large, and then after I release the focus the error drops below the previous local optima value.  Gradient descent would not choose to explore an area of the solution space with a significantly higher error than the current region.</p>\n<p>Has there been any research into whether these kinds of manual intervention methods can improve over purely automated training?</p>\n", "pids": ["53e99c84b7602d97025347d6"], "flag": 1}
{"question": "Are there any examples of popular self published textbooks?", "body": "<p>It’s a well known fact that textbooks are expensive and that writing a textbook earns you very little in royalties (e.g. <a href=\"https://academia.stackexchange.com/a/167367/11353\">https://academia.stackexchange.com/a/167367/11353</a> ). At the same time <a href=\"https://en.wikipedia.org/wiki/Self-publishing\" rel=\"nofollow noreferrer\">self-publishing</a> is becoming a bigger and bigger deal in non-academic circles. This sounds like an ideal solution for academic textbooks.</p>\n<p>Are there any examples of <em>popular</em> self published textbooks?</p>\n<p>I am not looking for any type of (exhaustive) lists. I am either interested in even a single example of such a textbook or alternatively answers that explore the main issues with this approach. Going through my collection of books from the time when I was ‘in academics’, I cannot find a single book that looks like it wasn’t published through an (academic) publisher.</p>\n", "pids": ["53e9a957b7602d97032ac2af"], "flag": 1}
{"question": "What does it mean if a neuron is &quot;expressing&quot; something?", "body": "<p>Sorry for the simple question, not a neuroscientist just trying to understand a paper for school. In a study with mice, there was 2-photon calcium imaging done, and part of it read:</p>\n<blockquote>\n<p>We used single- and multi-plane imaging approaches to record the activity of populations of excitatory neurons and two inhibitory classes, Somatostatin (Sst) and Vasoactive Intestinal Peptide (Vip) expressing interneurons, across multiple cortical depths and two visual areas (VSIp and VISl)</p>\n</blockquote>\n<p>First I thought this meant that SST &amp; VIP were inhibitory neurons. But when I Google it says they're <a href=\"https://en.wikipedia.org/wiki/Somatostatin\" rel=\"nofollow noreferrer\">hormones</a>.</p>\n<p>So is this saying they recorded activity from inhibitory interneurons that were ... releasing? producing? ... SST &amp; VIP ? What does &quot;expressing&quot; mean in this sense.</p>\n", "pids": ["55a51c2365ceb7cb02e13364"], "flag": 1}
{"question": "Can Fluoride be absorbed into the blood from within the mouth without swallowing?", "body": "<p>I'm having a discussion with somebody regarding Fluoride usage. I told him that even if he doesn't like the idea of ingesting it, brushing and spitting it out will do you no harm. He then said this:</p>\n<blockquote>\n<p>You have missed the point of ingestion massively! Brushing with fluoridated paste is NOT fine.</p>\n<p>The mouth, with its gum entry and under tongue glands are the PERFECT entry point to the blood, without even swallowing? What do you think oil pulling is all about? Fluoride passes those barriers as easy as the shit that resides in your blood can!&quot;</p>\n</blockquote>\n<p>Now I call BS on this, but I'd just like an expert opinion with cited sources if possible. Can Fluoride be absorbed purely by the mouth without ingestion?</p>\n", "pids": ["55a35eab24012c2ab7a89d07"], "flag": 1}
{"question": "What makes ChatGPT a generative model?", "body": "<p>I'm working my way through how ChatGPT works. So I read that ChatGPT is a generative model. When searching for generative models, I found two defintions:</p>\n<ul>\n<li>A <strong>generative</strong> model includes the distribution of the data itself, and tells you how likely a given example is</li>\n<li><strong>Generative</strong> artificial intelligence (AI) describes algorithms (such as ChatGPT) that can be used to create new content</li>\n</ul>\n<p>Do they both mean the same? That is, for generating new content, a model must learn the distribution of data itself? Or do we call chatGPT generative because it just generates new text? I see that ChatGPT is something other than a discriminative model that learns a boundary to split data, however, I can not bring ChatGPT in line with a more traditional generative model like naive bayes, where class distributions are inferred.</p>\n", "pids": ["599c7987601a182cd2648373"], "flag": 1}
{"question": "What percentage of the human genome hasn&#39;t been sequenced yet? If percentage estimates aren&#39;t precise, why is it difficult to estimate?", "body": "<p>What percentage of the human genome hasn't been sequenced yet? I have read different estimates, e.g.: </p>\n\n<ul>\n<li><a href=\"https://www.genome.gov/human-genome-project/Completion-FAQ\" rel=\"noreferrer\">https://www.genome.gov/human-genome-project/Completion-FAQ</a> (<a href=\"https://web.archive.org/web/20190705021503/https://www.genome.gov/human-genome-project/Completion-FAQ\" rel=\"noreferrer\">mirror</a>): \"In the April 2003 version, there are less than 400 gaps and <strong>99 percent</strong> of the genome is finished with an accuracy rate of less than one error every 10,000 base pairs\"</li>\n<li><a href=\"https://www.statnews.com/2017/06/20/human-genome-not-fully-sequenced/\" rel=\"noreferrer\">https://www.statnews.com/2017/06/20/human-genome-not-fully-sequenced/</a> (<a href=\"https://web.archive.org/web/20190705021627/https://www.statnews.com/2017/06/20/human-genome-not-fully-sequenced/\" rel=\"noreferrer\">mirror</a>):  \"Church estimates <strong>4 percent to 9 percent</strong> of the human genome hasn’t been sequenced. Miga thinks it’s <strong>8 percent</strong>.\"</li>\n</ul>\n\n<p>If there isn't a consensus on the percentage of the human genome that hasn't been sequenced yet, why is it difficult to estimate?</p>\n", "pids": ["5e72335593d709897cfa92b0"], "flag": 1}
{"question": "Can a hyperpolarized neuron fire action potentials?", "body": "<p>Is there any chance that a neuron could fire when hyperpolarized? In that case, would the spike be different than usual?</p>\n", "pids": ["55a5ff3d65cead59c8324319"], "flag": 1}
{"question": "Which personality theories do belong to humanistic?", "body": "<p>I went through literature and I am confused which theories of personality belong to humanistic, in literature there is often just Rogers (who is sometimes also considered to be phenomenologic) and Maslow. Do you know about some other that could be considered for humanistic too?\nCan I say that all humanistic psychologists created humanistic personality theory (e. g. Allport, Frankl etc.)?</p>\n", "pids": ["61c8b0b05244ab9dcb36ec34"], "flag": 1}
{"question": "Flair/Badge for arXiv paper?", "body": "<p>This is borderline trivial, but in my attempt to publish my work in a public repository, I've found badges at the top of my <code>README.md</code> to be useful. For example, using <a href=\"https://zenodo.org/\" rel=\"noreferrer\">Zenodo</a>, I can create a badge that points to a proper DOI that looks like this:</p>\n\n<p><a href=\"http://dx.doi.org/10.5281/zenodo.11304\" rel=\"noreferrer\"><a src=\"https://zenodo.org/badge/doi/10.5281/zenodo.11304.png\" alt=\"DOI\"></a>\n<em>Encyclopedia of Finite Graphs</em></p>\n\n<p>If I have a critical piece of code, I can publish <a href=\"http://docs.travis-ci.com/user/status-images/\" rel=\"noreferrer\"><code>Travis.CL</code></a> badges or <a href=\"https://coveralls.io/\" rel=\"noreferrer\"><code>Coveralls</code></a> for code coverage.</p>\n\n<p>Is the an equivalent badge or icon I can use to visually indicate that the work has been published on the <a href=\"http://arxiv.org/\" rel=\"noreferrer\"><code>arXiv</code></a>?</p>\n", "pids": ["56d82946dabfae2eeef16d9e"], "flag": 1}
{"question": "Why do fruit flies go so close to large reservoirs of liquid when they are likely to fall in due to surface tension?", "body": "<p>I had accidentally left out half a glass of red wine by the windowsill when I went to sleep. As anyone knows, if you do this with a window cracked you will get quite a few fruit flies near it in that time(region dependent obviously). </p>\n\n<p>I noticed that many of them had simply fallen in as there was nearly nothing on the sides of the glass. What causes this behavior in a likely death scenario? Is it only exhibited during extreme hunger? Would this also not likely be an evolutionary cost or is that outweighed?</p>\n", "pids": ["53e9a8d4b7602d97032242ef", "53e9998bb7602d97021d0db3", "56d8d7a9dabfae2eeed788a7"], "flag": 1}
{"question": "Novel bacterial strains of bacteria first isolated on the International Space Station, did the space environment lead to these genetic changes?", "body": "<h2>Question</h2>\n<p><a href=\"https://www.frontiersin.org/articles/10.3389/fmicb.2021.639396/full\" rel=\"noreferrer\">Methylobacterium ajmalii sp. nov., Isolated From the International Space Station</a> (Bijlani et al. Frontiers in Microbiology, <strong>12</strong>, p. 534, 2021) is a thorough analysis of &quot;novel strains&quot; of bacteria isolated from the International Space Station (<a href=\"https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-019-0666-x\" rel=\"noreferrer\">Characterization of the total and viable bacterial and fungal communities associated with the International Space Station surfaces</a>)</p>\n<p><strong>Question:</strong> Bijlani et al. 2021 is written at a very dense and technical level that is challenging for me to understand. I'd like to know:</p>\n<ol>\n<li>Does the article suggests these may be newly discovered species or only that they are novel strains of known species of Earth bacteria?</li>\n<li>Does the article suggest that the environment on the ISS <em>selected</em> for these species or strains, and they resulted from some genetic changes due to the ISS environment, or if we looked hard enough we'd expect to find the same ones on Earth and they <em>just happened to be identified first on the ISS</em> because of the rigorous studies of those samples?</li>\n</ol>\n<hr />\n<h2>Background</h2>\n<p>I was lead to the paper after seeing the ink the BBC's <a href=\"https://www.bbc.com/future/article/20210510-could-the-perseverance-rover-have-carried-life-to-mars\" rel=\"noreferrer\">Could humans have contaminated Mars with life?</a> which is primarily about a different topic.</p>\n<p>The paper is one of 10 papers the 2021 topic <a href=\"https://www.frontiersin.org/research-topics/15100/extremophiles-microbial-genomics-and-taxogenomics#articles\" rel=\"noreferrer\">Extremophiles: Microbial Genomics and Taxogenomics</a>.</p>\n<p>The ISS is a unique closed environment with plenty of surfaces with sometimes <a href=\"https://space.stackexchange.com/a/20429/12102\">problematic</a> mold <a href=\"https://space.stackexchange.com/a/2531/12102\">growth</a>, and a population of usually 3-6 humans with regular rotations every 5 to 6 months who maintain an array of biological experiments including a sustained effort to <a href=\"https://space.stackexchange.com/q/21133/12102\">try to grow vegetables and flower</a> hydroponically <em><strong>and in soil.</strong></em></p>\n<p>The atmosphere is maintained similar to Earth's surface (oxygen/nitrogen ~1 bar) with <a href=\"https://space.stackexchange.com/a/2540/12102\">60% relative humidity</a> and often has a CO2 concentration <a href=\"https://space.stackexchange.com/q/24600/12102\">slightly higher than the astronauts would prefer</a>.</p>\n<p><a href=\"https://i.stack.imgur.com/QQnag.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/QQnagm.jpg\" alt=\"mold on the ISS\" /></a> <a href=\"https://i.stack.imgur.com/I5xf5.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/I5xf5m.jpg\" alt=\"flowers on the ISS\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/QInv0.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/QInv0m.jpg\" alt=\"plants on the ISS\" /></a> <a href=\"https://i.stack.imgur.com/Akma4.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/Akma4m.jpg\" alt=\"Personal CO2 monitor on the ISS\" /></a></p>\n", "pids": ["5cac6fcce1cd8e144a7fe753"], "flag": 1}
{"question": "What are the correlations between the facets of honesty-humility in HEXACO personality and the Dark Triad?", "body": "<p>I was just reading some of the items in the HEXACO measure of personality. It seems to me that the \"honesty-humility\" factor is actually more naturally expressed in the opposite way. I.e., about three quarters of the items are reverse scored.</p>\n\n<p>For example, items measuring fairness (i.e., reverse coded) tend to focus on a willingness to engage in corrupt or even criminal behavior to advance your self-interest. Items measuring greed avoidance seem to be focused on concern with social status grounded in superficial things. Modesty items seems more like a measure of narcissism (i.e., believing you are better than others in some essential and vague way). Sincerity seems to have items concerned with a willingness to engage in social manipulation through flattery and guilt.</p>\n\n<p>This got me interested in the correlation between honest-humility and the dark triad: machiavellianism, narcissism, and psychopathy.</p>\n\n<p><strong>What are the best estimates of the correlation between HEXACO honesty-humility (and facets) with the Dark Triad?</strong></p>\n", "pids": ["5c756d20f56def97984f9e04"], "flag": 1}
{"question": "What prevents non-aminoacylated tRNA from binding to mRNA on the ribosome and disrupting protein synthesis?", "body": "<p>Specific aminoacyl-tRNA synthetases catalyse a reaction in which a transfer RNA molecule with a given anticodon is covalently attached to its cognate amino acid (aminoacylated).</p>\n<p><em>What factors favor the binding to the ribosome/mRNA of an aminoacylated tRNA molecule, rather than one without an attached amino acid?</em></p>\n<p>Is it exclusively the presence of an exposed OH group on the end of the non-aminoacylated-tRNA molecule or is it possible that the tRNA molecule undergoes some degree of conformation change when the amino acid is enzymatically attached that makes the anticodon have a greater affinity for the codon?</p>\n", "pids": ["6229f0a85aee126c0f35230d"], "flag": 1}
{"question": "Do IEEE transactions allow for any &quot;co-first authors&quot;?", "body": "<p>I, personally, have never see any authors in IEEE transactions listed as \"co-first\" authors, as such</p>\n\n<pre><code>John Smith†, Bill Lee†, and Boss James\n...\n† These two authors contribute equally to the work.\n</code></pre>\n\n<p>Is this allowed in IEEE transactions?</p>\n", "pids": ["53e9b7e8b7602d9704397f4a"], "flag": 1}
{"question": "Are virtual machines good for reproducibility and open science?", "body": "<p>Virtual machines (VMs) provide a way for scientists to package not only scientific software, but also data, external dependences, and even entire operating system configurations, facilitating a faithful and exact reproduction of a particular computing environment used to derive a particular result.</p>\n\n<p>Are VMs and other container systems used in this way actually a net positive for open science? If the scientific software used to compute a result can only be replicated in a very particular computing environment, is it useful and reliable?</p>\n", "pids": ["53e9984fb7602d9702084059"], "flag": 1}
{"question": "As a computational chemist, which online resources are available for Ph.D. level jobs?", "body": "<p>Which online resources are available for job search at the Ph.D. level in the computational chemistry field?</p>\n", "pids": ["5f0747c69e795e1a9f4ad6f4"], "flag": 1}
{"question": "Do ALL decisions arouse cognitive dissonance?", "body": "<p>I continue to see an oversimplification in the descriptions of the options available that arouse cognitive dissonance: some websites state that all decisions have positive and negative aspects that will lead to dissonance and some say that dissonance is aroused only when a decision is made between two equally desirable options.</p>\n\n<p>In other words, do ALL decisions arouse cognitive dissonance? Or just the decisions made between options that are equally or near-equally desirable? </p>\n\n<p>For example, if I were to choose between an Ivy league college or a SUNY school, I don't think I would very much regret going to the Ivy league school and not the other (or would I be reducing dissonance by telling myself that?). However, the website explaining cognitive dissonance simply labels these options as \"colleges\".</p>\n\n<p>Also what if the decision making was something trivial (in my perceptions)? Do whimsical decisions arouse dissonance as well? </p>\n\n<p>For example, if I had a very large sum of money and I was selecting between two equally desirable cars, and I could very easily afford both, would I still experience much dissonance? </p>\n", "pids": ["53e9b7d4b7602d970438558d", "55a3bcea65ce5cd7b3b55089", "56d8f468dabfae2eee89c48d", "55a51e3865ceb7cb02e177b2", "56d9001ddabfae2eeed203c0"], "flag": 1}
{"question": "What is the impact of using complex words on the paper acceptance probability?", "body": "<p><em>Oppenheimer, Daniel M. \"<a href=\"https://scholar.google.com/scholar?cluster=18327303614821613289&amp;hl=en&amp;as_sdt=0,22\">Consequences of erudite vernacular utilized irrespective of necessity: Problems with using long words needlessly.</a>\" Applied Cognitive Psychology 20, no. 2 (2006): 139-156.</em> looked at the impact of using complex words on the graduate admission probability.</p>\n\n<p>Is there any research/study/survey that looked at the impact of using complex words on the paper acceptance probability?</p>\n\n<p>I am most interested in the field of computer science, and English-speaking venues.</p>\n", "pids": ["5d0b00988607575390fd2f3a"], "flag": 1}
{"question": "How do reward signals strengthen synaptic connections in the human brain?", "body": "<p>In a vast simplification, the mid-brain sends reward signals (for example through dopaminergic neurons) that tell the rest of the brain whether it succeeded at fulfilling the needs of the organism. If there are certain activities in the brain that lead to a successful action, then these activities should have a higher probability of occurring again (since that is useful for achieving the organism's needs in future).</p>\n\n<p>To increase the probability of the occurrence of an activation pattern as a response to a certain history of sensory input, the neurons that were involved to produce this pattern will need to adapt their synapses such that they become more sensitive to this input.</p>\n\n<p>I'm wondering, how are the reward signals thought to affect the neurons that were involved in the previous actions of the organism at the synaptic level?</p>\n", "pids": ["53e99a2fb7602d970228b0a1"], "flag": 1}
{"question": "Negative emotions in individuals spreading to others", "body": "<p>I am aware of the effect of positive emotions on others, but I am wondering about negative emotions.  I am not talking about <a href=\"https://cogsci.stackexchange.com/questions/4126/how-to-prevent-insults-from-unconsciously-causing-negative-emotions\">insults leading to negative emotions</a>.  I am talking about emotions like anger, frustration etc. in some leading to anger, frustration etc. in others.</p>\n\n<p>Are there any studies which suggest that there is the ability for emotions such as anger and frustration to transfer and spread amongst others or lead to <strong>other</strong> emotions in others?</p>\n\n<p>For example, can a group of people seeing one or more people getting frustrated about something lead to some or all in the observing group suffer from frustration or annoyance or other negative emotions?</p>\n\n<h2>**Update**</h2>\n\n<p>I have found the answer to <a href=\"https://cogsci.stackexchange.com/a/12795/7604\">this question</a> which was interesting, talking about <strong>negative priors</strong> (<a href=\"https://books.google.com/books?hl=en&amp;lr=&amp;id=L09cRS0xWj0C&amp;oi=fnd&amp;pg=PP15&amp;dq=aaron+beck&amp;ots=FWOmjQ7jbl&amp;sig=6WEjYZ2m1_JbwfwCQ5-Hjd1mWV8#v=onepage&amp;q=aaron%20beck&amp;f=false\" rel=\"nofollow noreferrer\">Beck, 1979</a>; <a href=\"http://www.cns.nyu.edu/~daw/hdd15.pdf\" rel=\"nofollow noreferrer\">Huys, Daw, &amp; Dayan, 2015</a>) shaping your predictions about the world leading to more negative emotions.</p>\n\n<p>What I am interested in is the possibility of negative emotions spreading amongst otherwise psychologically healthy people, just as positive emotions do.  Although there is an interesting quote...</p>\n\n<p>“Smile and the world smiles with you, cry and you cry alone.” ― Stanley Gordon West, <a href=\"http://www.goodreads.com/work/quotes/888260\" rel=\"nofollow noreferrer\">Growing an Inch</a> </p>\n", "pids": ["5f463a1d9fced0a24b211e49"], "flag": 1}
{"question": "How does the Endoplasmic Reticulum scale with Cell Volume in Epithelial Cells?", "body": "<p>I am working on a mathematical model of a biological tissue (drosophila pupal notum; an epithelial tissue) where the tissue is built up from cells all described by the same cellular-model. The tissue is generated using a somewhat random process, and so each cell in the tissue has a different size (volume, surface area, etc.)</p>\n<p>The model focuses on the movement of particles both between cells as well as between the cytosol of each cell and internal stores (like the Endoplasmic Reticulum (ER)). In order to use the same parameters across the entire tissue, I need to know the ratios of various volumes and surface areas, such as the ratio of the volume of the cell to the volume of the ER, or the ratio of the volume of the cell to the surface area of the ER.</p>\n<p>So my question is, if we have a cell of some volume <span class=\"math-container\">$V_1$</span>, and we look at another cell with volume <span class=\"math-container\">$V_2$</span>, what can we say about how the volume of the ER of cell <span class=\"math-container\">$1$</span>, <span class=\"math-container\">$V_{\\text{ER},1}$</span>, or the surface area of the ER of cell <span class=\"math-container\">$1$</span>, <span class=\"math-container\">$A_{\\text{ER},1}$</span>, compares to the volume and surface area of the ER of cell <span class=\"math-container\">$2$</span>, <span class=\"math-container\">$V_{\\text{ER},2}$</span>, and <span class=\"math-container\">$A_{\\text{ER},2}$</span>? For example, would we expect <span class=\"math-container\">$V/V_\\text{ER}$</span> to remain constant across all cells in the tissue? Or maybe we would expect <span class=\"math-container\">$V/A_\\text{ER}$</span> to be a constant across cells in the tissue? Or maybe both of these ratios follow some other sort of scaling law?</p>\n", "pids": ["5c0f8895da562944ac975752"], "flag": 1}
{"question": "Do color-blind people have more rod cells in their retinae than the normally sighted?", "body": "<p>All types of color-blindness are said to be caused by the defect or lack of cone cells in the eyes<sup>[1]</sup>. Since cone cells sense color<sup>[2]</sup> and rod cells can only sense light intensity<sup>[3]</sup>, the lack of cone cells would mean that the eye cannot detect color. However, rod cell function better in low light than cone cells. Color-blind people have fewer cone cells than other people. My question is, is it possible that they also have <em><strong>more</strong></em> rod cells than other people?</p>\n<p>I am color-blind, and I have observed instances where I was able to see better in low light than other people. For example, most often when I read at night or in low light, people have wondered how I'm able to see in the low light condition. I also do not turn on the light most of the time when I walk around the house at night, whereas other people in the house often cannot see well enough to walk without turning on the light. I also recently noticed that my favorite theme (for VS Code), is actually meant for people who work in low light conditions or at night. But they have also noted that it is suitable for people with color blindness.</p>\n<p>All these occurrences made me wonder whether color-blind people have more rod cells than average people, and hence can see better in low light too.</p>\n<p>[1] <a href=\"https://en.wikipedia.org/wiki/Color_blindness#:%7E:text=The%20most%20common%20cause%20of%20color%20blindness%20is%20an%20inherited%20problem%20in%20the%20development%20of%20one%20or%20more%20of%20the%20three%20sets%20of%20the%20eyes%27%20cone%20cells%2C%20which%20sense%20color.\" rel=\"noreferrer\">‘Color Blindness’ entry in Wikipedia</a></p>\n<p>[2] <a href=\"https://en.wikipedia.org/wiki/Cone_cell#:%7E:text=Cone%20cells%2C%20or%20cones%2C%20are%20photoreceptor%20cells%20in%20the%20retinas%20of%20vertebrate%20eyes%20including%20the%20human%20eye.%20They%20respond%20differently%20to%20light%20of%20different%20wavelengths%2C%20and%20are%20thus%20responsible%20for%20color%20vision%2C\" rel=\"noreferrer\">‘Cone Cell’ entry in Wikipedia</a></p>\n<p>[3] <a href=\"https://en.wikipedia.org/wiki/Rod_cell#:%7E:text=However%2C%20rods%20have%20little%20role%20in%20color%20vision%2C\" rel=\"noreferrer\">‘Rod Cell’ entry in Wikipedia</a></p>\n", "pids": ["5749ac000cf270c1a80f4a34"], "flag": 1}
{"question": "How are DNA virus cladograms actually calculated in practice? Is the procedure different for RNA viruses? Are these processes somewhat subjective?", "body": "<p>The May 24, 2022 Bloomberg opinion piece <a href=\"https://www.bloomberg.com/opinion/articles/2022-05-23/monkeypox-isn-t-looking-like-a-covid-sized-threat\" rel=\"nofollow noreferrer\">Monkeypox Isn’t Looking Like a Covid-Sized Threat; It’s still early, but contact-tracing efforts and analysis of the virus’s genome offer hope that this outbreak can be contained.</a> includes the following:</p>\n<blockquote>\n<p>Why now, monkeypox?</p>\n<p>Scientists are scrambling to answer this key question. <strong>Two strains, or clades</strong>, of monkeypox are known to exist, and the one currently circulating seems to be the milder West Africa one. (For more on that, see <a href=\"https://www.bloomberg.com/opinion/articles/2022-05-19/what-is-monkeypox-why-is-it-spreading-and-should-we-worry\" rel=\"nofollow noreferrer\">this explainer</a> from Therese Raphael and Sam Fazeli.)</p>\n</blockquote>\n<blockquote>\n<p>One challenge is that researchers lack a good baseline measure on the <strong>transmissibility of this clade of the virus</strong>. Over the weekend, Maimuna Majumder, a computational epidemiologist at Harvard Medical School, provided an initial analysis of the monkeypox virus’s R0 (R-naught) — the number of people expected to be infected by a single case. These findings, which have yet to be peer reviewed and are based on very limited data, suggest an R0 of 1.15 to 1.26 — low enough to imply that the virus can be kept in check by contact tracing, vaccination and isolation of infected people.</p>\n</blockquote>\n<blockquote>\n<p>While the present chain of monkeypox transmission differs from earlier patterns, <strong>this clade of the virus is generally mild</strong> for most infected people (albeit with a long period of isolation and recovery). And, critically, vaccines and antivirals are available to address infections.</p>\n</blockquote>\n<p>I'd never heard the term &quot;clade&quot; before. I've found News Medical/Life Science's (Last Updated: Jan 11, 2022) <a href=\"https://www.news-medical.net/health/What-are-Viral-Clades.aspx\" rel=\"nofollow noreferrer\">What are Viral Clades?</a> which which introduces the concept of the <em>cladogram</em> and <em>basal clade</em> and uses the RNA virus SARS-CoV-2 as an example is somewhat helpful but it's more of an explainer than a procedure, consistent with the site's mission to be</p>\n<blockquote>\n<p>a tight-knit community of scientific, medical, and life sciences experts that produce and share the latest information, in a readable, understandable way.</p>\n</blockquote>\n<p>So I checked Wikipedia's <a href=\"https://en.wikipedia.org/wiki/Cladogram\" rel=\"nofollow noreferrer\">Cladogram</a> which has a general discussion but doesn't go into great detail.</p>\n<p>So I'd like to ask:</p>\n<blockquote>\n<p>How are DNA virus cladograms actually calculated in practice? Is the procedure different for RNA viruses? Are these processes somewhat subjective?</p>\n</blockquote>\n<p>By &quot;subjective&quot; I mean do scientists producing cladograms have to make any decisions as to what genetic differences are important for the diagram, or would several groups working independently always arrive at identical diagrams from identical data sets because they apply a standardized methodology?</p>\n", "pids": ["558a9f33e4b031bae1f8b3f9"], "flag": 1}
{"question": "What are the profit margins of academic publishers?", "body": "<p>With an eye to finding the reasons behind <a href=\"https://academia.stackexchange.com/q/29923/452\">high journal subscription costs</a>: do journals / publishers make outrageous margins, or are prices truly justified by the costs to run journals? In other words, how does their budget look like?</p>\n", "pids": ["55a52d2965ceb7cb02e36097"], "flag": 1}
{"question": "What is the difference between attractor and recurrent network?", "body": "<p>How are attractor and recurrent networks related? Is attractor network is <a href=\"https://en.wikipedia.org/wiki/Limiting_case_(mathematics)\" rel=\"nofollow noreferrer\">private case</a> of recurrent? Is there a mathematical formalism that defines both rigorously as <a href=\"https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)\" rel=\"nofollow noreferrer\">graphs</a>? </p>\n", "pids": ["5c0f7343da562944ac685c65", "53e9a0c9b7602d97029b0244"], "flag": 1}
{"question": "Neural Network output for the game of Checkers", "body": "<p>I'm trying to train a RL agent to play the game of checkers (AlphaZero style) and so far I've managed a proof of concept training a connect 4 agent up until perfection. However, unlike connect 4, checkers <em>moves</em> pieces rather than placing them and sometimes even multiple times. I think I understand how I would do this for chess: I have an output size of 80 (16+8*8) and have the first 16 outputs represent the <em>piece</em> that will move and the other 64 represent the <em>position</em> it will move to. I'm not sure if this is a valid solution though. The real problem arises when considering checkers with multiple jumps. Is there any solution to this and am I thinking about it the right way? I've pondered not changing the player turn whenever a double jump is available but I feel like this will screw with the MCTS.</p>\n", "pids": ["5dd50ed43a55ac513761791a", "5a73cbcc17c44a0b3035f7b3", "5dd50ed43a55ac513761791a"], "flag": 1}
{"question": "Standard practice when merging papers on arxiv", "body": "<p>I and another author have decided to merge our manuscripts into one paper.\nBoth of us have already put preprints on <a href=\"http://arxiv.org/\">arxiv</a>. How should we handle the merging on arxiv? Is there a standard practice?</p>\n\n<p>I can think of three options:</p>\n\n<ol>\n<li> Create a new submission for the merged paper.\n<li> Upload the merged paper as a revision of both of the original preprints.\n<li> <a href=\"https://arxiv.org/help/withdraw\">Withdraw</a> one of the original preprints and upload the merged paper as a revision to the other. \n</ol> \n\n<p>I worry that option 1 might look like we are spamming arxiv by uploading three papers when we really should only have uploaded one. Option 2 is undesirable because then there are two versions of the exact same paper on arxiv. Option 3 is asymmetric.</p>\n\n<p>Has anyone had a similar experience? </p>\n", "pids": ["573697b06e3b12023e692cee", "5550414545ce0a409eb39da8", "5550417b45ce0a409eb3bb3f"], "flag": 1}
{"question": "Why can&#39;t SARS-CoV2 antigen lateral flow tests be used for testing animals?", "body": "<p>Real use case:\nTwo male neutered <em>Felis catus</em> individuals live in a household where up to three humans live of which all were infected with SARS-CoV2 at the same time, proven by antigen and PCR tests. All three humans were clearly symptomatic.\nFunny sidenote: All three humans most likely contracted the infection at the same event, however two were diagnosed with omicron and one with delta by sequentiation.</p>\n<p>After a week and with the symptoms of the humans already declined one of the cats developed symptoms with similarities to the humans in the following temporal order:</p>\n<ul>\n<li>sneezing</li>\n<li>coughing</li>\n<li>repeated choking while feeding</li>\n<li>sneezing with sputtering blood from the nostrils</li>\n</ul>\n<p>After onset of symptoms and three days later an antigen lateral flow test designed for detection of SARS-CoV2 in humans was applied to the symptomatic cat. Sample was taken from the throat. Test kit was from brand Longsee. Both tests yielded a clear positive result. The cat was treated symptomatically and has recovered.</p>\n<p>The results were reported to different veterinaries including the district veterinary office. All stated that the test result is void and most likely false positive, because tests designed for use on humans can't be used on other animals.</p>\n<p>I want to discuss, which possible causes might lead to a false positive in this case.</p>\n<p>I think it is very unlikely that we have a false positive here, my thoughts are</p>\n<ul>\n<li>To my knowledge lateral flow tests for SARS-CoV2 detect either a spike protein or a capsid protein, so they react only on presence of parts of the virus.</li>\n<li>The lateral flow tests are designed to be very specific to that virus. There are lots of corona viruses able to infect humans and provoke symptoms of a typical cold. So the tests should not react to other corona viruses.</li>\n<li>There are corona viruses specific to other mammals (e.g. FCoV), however many of them have strong similarities to human corona viruses, so it is very likely that the tests are specific enough to rule out false positive</li>\n</ul>\n<p>What aspects did I miss? Which effects you can think of preventing fairly good specificity of such tests when used in cats?</p>\n<p>Maybe this question includes another question: What is the nature of false positives in lateral flow antigen tests for SARS-CoV2?</p>\n", "pids": ["6153e4eb5244ab9dcb3f026d"], "flag": 1}
{"question": "Can I sue my advisor due to not giving me authorship", "body": "<p>So long story short is that, while I was doing my masters I have worked with a PhD candidate on a paper. I basically developed half of the system and did all the experiments while I was doing my masters. During my masters they tried to publish the results at different venues, but did not get selected. After one year, the PhD candidate got accepted into a venue and did not give me any authorship, they are just mentioning me in the acknowledgement section.</p>\n<p>It is frustrating to see that I am not getting the well earned credit that I deserve.</p>\n<p>What are some actions that I can take?</p>\n", "pids": ["5c0f9115da562944aca8da88"], "flag": 1}
{"question": "Is there a max number of authors for a paper of math?", "body": "<p>I never saw a paper published in a journal of (pure) math with more than six authors. Is it a rule?<br />\n(see <a href=\"https://doi.org/10.1007/s10468-019-09873-9\" rel=\"noreferrer\">this one</a>)</p>\n", "pids": ["602b90f091e0113d72356b78"], "flag": 1}
{"question": "What is the deepest living underground organism?", "body": "<p>A quick search reveals <a href=\"https://en.wikipedia.org/wiki/Halicephalobus_mephisto\" rel=\"noreferrer\"><em>Halicephalobus mephisto</em></a> which was</p>\n<blockquote>\n<p>detected in ore recovered from deep rock fracture water in several gold mines in South Africa [...] 3.6 km (2.2 mi) under the surface of the Earth.</p>\n</blockquote>\n<p>Have any deeper living organisms ever been found?</p>\n", "pids": ["6023b422af79179a997a0413"], "flag": 1}
{"question": "Online vs hard copy, which texts are students more likely to read?", "body": "<p>I am wondering if anyone knows of any studies that indicate whether students read online texts more or less than hard copy texts.</p>\n\n<p>I am in the midst of trying to \"reboot\" the intro stats class I teach and a big question in my mind is how effective the text is. Active learning (like the flipped classroom) requires the students read the material beforehand, and I'm not convinced (from the results I saw this year using a Pearson Learning Management System (LMS)) that the students are reading the online text very much.</p>\n\n<p>I have a suspicion that students read the online texts less (and I plan to give my students a survey to check) but I'd like to know if there is any research supporting my limited observations. </p>\n", "pids": ["53e9a766b7602d970309f61e", "5c75691df56def97982618ed", "56d8ef2bdabfae2eee6a7a94"], "flag": 1}
{"question": "When to update an Arxiv posting vs. creating a new post?", "body": "<p>I have a paper on the Arxiv which has recently been referenced in someone else's published work. I have since used the new work (of someone else) to significantly extend my current Arxiv work. Since my previous Arxiv posting has not yet appeared anywhere, I am sending the old work along with the extensions to a journal in a single paper. So my question is this: should I update the Arxiv listing for the previous paper with the new extended version as a revision or should I add it as a new paper? </p>\n\n<p>I guess my worry is this: let A be my paper, B be the other paper that references A and A' be my extended paper which builds on some ideas from B to significantly extend A. If I post A' as a revision to A, then there is a weird referencing problem where B refers to my Arxiv post without knowing that A' builds on B. However, if I post A' as a new paper, then it includes essentially all of A in it (though presented in a more clear manner) and so there seems to be some duplication.</p>\n", "pids": ["5c61078eda56297340b0bdeb", "5d9edbb847c8f76646024a4c", "5c61078eda56297340b0bdeb"], "flag": 1}
{"question": "Pedagogical reasons for closed-book exams in graduate-level courses?", "body": "<p>Is there any research/study/survey that looked at the pedagogical benefits of assessing students with closed-book exams for graduate-level courses (vs. open-book exams)?</p>\n\n<p>I'm mostly interested in computer science and math education in the USA, if the answer is field- or country-dependent.</p>\n", "pids": ["53e9bc15b7602d9704878ede"], "flag": 1}
{"question": "Tracking updates for an individual paper in arXiv", "body": "<p>Albeit arXiv offers <a href=\"http://arxiv.org/help/rss\">RSS news feeds for subject areas updates</a>, it is also possible to track an individual paper for updates (such as if it was submitted and/or accepted to a journal)?</p>\n", "pids": ["55a651d665ce054aad646011", "55a651d665ce054aad646011", "55a651d665ce054aad646011"], "flag": 1}
{"question": "Preprint services for environmental and earth sciences?", "body": "<p>Is there a good, reputable preprint service that is used in the environmental and earth sciences, and considered acceptable by the major publishers? Many journals specifically state that it is okay to submit a paper that has been uploaded to arXiv and I would like to take advantage of that, however I am not in a field covered by arXiv. </p>\n\n<p>[I'm aware of the similar question, <a href=\"https://academia.stackexchange.com/questions/84/preprint-services-other-than-arxiv-for-other-fields\">Preprint services other than arXiv (for other fields)</a>, but it is fairly old and there are no answers relevant to my field] </p>\n", "pids": ["53e9b8a8b7602d970448005f"], "flag": 1}
{"question": "Can I post a pre-print of my paper on ArXiv knowing the paper will go through major changes? Alternatives?", "body": "<p>I wrote a paper with a new approach and I implemented this approach in both R and SAS. I want to put the software online on Github and ideally on CRAN too. The paper has been reviewed by my collaborators, but I was told that the structure is atypical as this is my first paper and I used a structure more typical of a thesis. The paper will need to go trough major changes and it will have the reorganized differently. Still the modelling approach itself is good and well detailed in the paper. </p>\n\n<p>I’d like to release the software on Github and include the current draft of the paper with it but I’m wondering if I should also sent it to ArXiv at the same time even though it’s not publication-ready. Is putting my paper on Github (and maybe Researchgate?) enough to prevent someone from legally stealing my work? Can I and should I send it to a place like ArXiv? Should I put a license on the online draft?</p>\n", "pids": ["57a4e91dac44365e35c98bde"], "flag": 1}
{"question": "What safe, accessible enveloped virus should we use for beginning experiments?", "body": "<p>I need to know which virus meets the following criteria:</p>\n<ol>\n<li>It has to be enveloped.</li>\n<li>It has to have a DNA packaging scheme similar to Adenovirus (basically, sticks most of itself together then draws in the DNA like the way a human eats a noodle).</li>\n<li>It can’t infect humans (for obvious reasons).</li>\n<li>It has to be easily propagated, either in a microbe such as ecoli or in embryonic chicken eggs.</li>\n<li>It has to be virus stock that can be easily derived or purchased.</li>\n<li>It has to be BSL1 rated</li>\n</ol>\n<p>Avian adenovirus met all but the sixth criteria, unfortunately.</p>\n<p>Is there something else that you are aware of that would meet those criteria? It does not even have to be in a particular family.</p>\n", "pids": ["53e99e4db7602d9702713f81", "5feda20cd4150a363c30c42e", "5c136b2ada56295a08a68425"], "flag": 1}
{"question": "Why are men more susceptible to severe COVID-19?", "body": "<p>It seems that globally, men are more susceptible to severe COVID-19 than women:</p>\n\n<p><a href=\"https://www.theguardian.com/world/2020/mar/26/men-are-much-more-likely-to-die-from-coronavirus-but-why\" rel=\"noreferrer\">https://www.theguardian.com/world/2020/mar/26/men-are-much-more-likely-to-die-from-coronavirus-but-why</a></p>\n\n<p>This is seen in other coronavirus diseases (SARS, MERS) but not respiratory diseases generally. Do we know the reasons for this?</p>\n", "pids": ["56d8ae78dabfae2eeece573c", "53e99bf0b7602d97024983c2", "53e9a432b7602d9702d4b42f", "5e5a379a93d709897c36aa66", "53e99ef4b7602d97027c2cf7", "53e9a8beb7602d970320eac5", "53e9aeebb7602d97039176ea", "5ee4a6739fced0a24bcc5e20"], "flag": 1}
{"question": "Why are beta-galactosidase proteins overexpressed in senescent cells?", "body": "<p><a href=\"http://en.wikipedia.org/wiki/SA-beta-gal\">Wikipedia</a> explains that it's a hypothetical hydrolase enzyme that catalyzes the hydrolysis of β-galactosides into monosaccharides only in senescent cells.</p>\n\n<p>I'm just wondering - what causes it to be overexpressed in senescent cells - to the point that it often becomes a biomarker of senescence? And what exactly happens to the particular cell when you catalyze the hydrolysis of more β-galactosides (like lactose) into monosaccharides? </p>\n", "pids": ["53e9a2d6b7602d9702be1448"], "flag": 1}
{"question": "Random forests - are more estimators always better?", "body": "<p>I'm learning about more advanced methods of hyperparameter optimization, such as the Bayesian methods in the <code>scikit-optimize</code> package.  For those unfamiliar with the package, it can be used easily with model classes from <code>scikit-learn</code>, in this case the random forest classes such as <code>RandomForestClassifier</code>, and it provides more intelligent alternatives to traditional hyperparameter optimization methods like grid search.</p>\n<p>I noticed that in some examples, the <code>n_estimators</code> hyperparameter (of the random forest) is included in the optimization, which I wouldn't expect.  The <code>n_estimators</code> hyperparameter determines the number of component decision trees in the random forest, so I would expect that more estimators always results in a better model with respect to a single target variable (for clarity, I'm not referring to anything having to do with optimizing a custom objective function in <code>scikit-optimize</code>, only single variables).</p>\n<p>Ignoring practical issues like training time as well as the potential effects of randomness (i.e., that different random seeds could lead to models with varying effectiveness), are there situations where fewer estimators could result in a more accurate model?  If so, what is the rationale?</p>\n", "pids": ["53e9ad9eb7602d970379db90", "5f0e68879fced0a24b730c81"], "flag": 1}
{"question": "Subtitling vs. dubbing and vice versa", "body": "<p>What are the benefits for <strong>viewers</strong> of subtitling over dubbing -or- dubbing over subtitling foreign TV and film?</p>\n\n<p>I've noticed some media will opt for subtitles, while others will opt to dub. </p>\n\n<p>There must be benefits and drawbacks to both, for example: </p>\n\n<p><strong>Reading vs. Listening:</strong> \nReading might be harder to put oneself in the scene, where as listening could make you feel a part of the \"show\". </p>\n\n<p>Are there any studies or any data as to benefits and drawbacks of subtitling vs. dubbing?</p>\n", "pids": ["6217a8ac5aee126c0fa48a07"], "flag": 1}
{"question": "Bicoid regulation of hunchback", "body": "<p>I'm learning about development via the example of <em>Drosophila</em> embryogenesis. I understand that bicoid regulates hunchback, among other genes. My question whether the regulation is direct or indirect? In other words, does the level of bicoid directly govern the expression of hunchback, or are there steps in between?</p>\n", "pids": ["53e9a658b7602d9702f8ba8e"], "flag": 1}
{"question": "Is there a conventional use of the term &quot;empirical grounding&quot;?", "body": "<h2>Background</h2>\n\n<p>The notion of grounding theory in empirical data, originates from the work by Glaser &amp; Strauss (1967). At present, while reputable scholars, for instance Eisenhardt and Graebner (2007), make use of the term \"<strong>empirical grounding</strong>\", it doesn't seem to be used quite frequently in (English-language) psychological literature. For instance, today, the database \"<a href=\"https://en.wikipedia.org/wiki/PsycINFO\" rel=\"nofollow noreferrer\">PsycINFO</a>\" returns not more than 66 journal articles where the mentioned term is used. </p>\n\n<h2>Question</h2>\n\n<p>Does the term \"<strong>empirical grounding</strong>\" designate a distinct methodological procedure (or result) that exists independently from the grounded theory methodology? </p>\n\n<h2>References</h2>\n\n<p>Eisenhardt, K. M., &amp; Graebner, M. E. (2007). Theory Building from Cases: Opportunities and Challenges. <em>Academy of Management Journal</em>, 50(1), 25–32. <a href=\"https://doi.org/10.5465/AMJ.2007.24160888\" rel=\"nofollow noreferrer\">https://doi.org/10.5465/AMJ.2007.24160888</a>  </p>\n\n<p>Glaser, B. G., &amp; Strauss, A. L. (1967). The discovery of grounded theory: strategies for qualitative research (4. paperback printing). New Brunswick: Aldine.</p>\n", "pids": ["53e9b409b7602d9703efdd94"], "flag": 1}
{"question": "Why do glial cells of the retina become more abundant the closer they are to the optic nerve?", "body": "<p>I am doing a project on expression of GFAP in the zebrafish retina. GFAP is a marker for glial cells. \nI have found that the glial cells are more abundant the closer they are to the optic nerve at the middle of the eye. This may just be because the cells are more tightly compacted here than at the edges of the eye... \nBut I am wondering if it may have something to do with the glial cells being involved with neuornal processes, and the optic nerve being the transmitter of signals from the eye to the brain? </p>\n", "pids": ["55a426b7c91b587b096e8744"], "flag": 1}
{"question": "Short term effects of alcohol on IQ", "body": "<p>I am looking for some references on the short term effects of alcohol on \"IQ\". I am particularly interested in what aspects of \"intelligence\" is affected (e.g., cognition/reasoning/memory). Essentially, I am looking for studies that compare performance while sober and drunk in moderate drinkers.</p>\n", "pids": ["55a42de62401c6de3b86869f", "55a372ec612ca648686d29ca"], "flag": 1}
{"question": "Relation of confidence and problem solving ability", "body": "<p>My personal experiences have shown me multiple times that by only boosting my confidence in my ability to solve a problem,  without gaining any additional knowledge, I was able to solve it!</p>\n\n<p>My question is, has this been studied that to what extent our confidence in our abilities can help us to find a solution for a problem?</p>\n\n<p>If so, can you please provide a link?</p>\n", "pids": ["55a6628965ce054aad65d92d"], "flag": 1}
{"question": "Does risk of developing depression continue to increase after age 60?", "body": "<p>Age is a risk factor for depression when we look at the entire lifespan. Does that hold true in a population of >60 years old?</p>\n", "pids": ["53e9b07db7602d9703ae5727"], "flag": 1}
{"question": "Long-term efficacy and absence of side effects of anti-covid vaccines", "body": "<p>The question is about the methodology/biostatistics of clinical trials (I state this beforehand to avoid accusations of being an anti-vaxxer).</p>\n<p>As multiple anti-COVID vaccines are offered on the market, the question naturally arises about their long-term efficacy and possible side effects. As SARS-CoV-2 virus has been known for a bit more than a year, neither of these could be tested directly, so one probably has to rely on indirect knowledge due to the experience in developing other vaccines. Given that multiple vaccines have been approved for a wide use, there should exist well-established procedures to assure their efficacy and safety.</p>\n<p>The question is: how does one prove the long-term efficacy and absence of side effects during a short period of time (short in comparison to the expected duration of immunity and absence of side effects).</p>\n<p><strong>Update</strong><br />\nAs @MattDMo have correctly pointed in their answer, the absence of long-term effects is established in <a href=\"https://en.wikipedia.org/wiki/Clinical_trial#Phases\" rel=\"nofollow noreferrer\">the last phase of the clinical trials</a>, while observing cohorts of vaccinated individuals during a long period of time. @MaximilianPress, in their comment, has also correctly brought up the fact that this is done within the framework of <a href=\"https://www.springer.com/gp/book/9780387202877\" rel=\"nofollow noreferrer\">survival analysis</a>. In particular, this means that it is sufficient to follow the vaccinated cohort during several years to evaluate the side effects that occur during their lifetime, as the survival analysis keeps track of the sensored data.</p>\n<p>Here we are dealing with a situation where such a study could not be done - the best we can guarantee is the absence of the side effects in the next few months. We thus need to rely on a <em>different method</em>, which would account for the similarity between the established and the new vaccines.</p>\n<p>I am less concerned about the vaccine efficacy, since the inefficacy of vaccines is usually against different strains of virus, as is in the case of influenza and <a href=\"https://en.wikipedia.org/wiki/Dengue_vaccine\" rel=\"nofollow noreferrer\">Dengue</a>.</p>\n<p><strong>Update 2</strong>\nThe accepted answer points out two important things:</p>\n<ul>\n<li>The long-term side effects of a vaccine/medication can be truly understood only in the Phase IV of the clinical trials, i.e., after the vaccine is in widespread use.</li>\n<li>The threshold for approving this specific vaccine is lower due to the emergency of the current health crisis.</li>\n</ul>\n<p>This however still leaves open the question of the safeguards undertaken in the Phase III of the clinical trials, before the vaccine approval. I.e., the question is about ranking the candidate vaccines against the above-mentioned threshold.</p>\n<p>Remarks:</p>\n<ul>\n<li>I understand why this question irritates, but I believe that it is not the asking, but rather refusing to seek the answer that plays in the hands of anti-vaxxers.</li>\n<li>I did follow the suggestions in the comments to pose this question in the medical and the statistics communities, but it seems to get there even less traction.</li>\n</ul>\n<p><strong>Update 3</strong><br />\n<a href=\"https://www.nytimes.com/2021/03/11/business/astrazeneca-vaccine-denmark-blood-clots.html\" rel=\"nofollow noreferrer\">Recent suspensions of Astrazeneca vaccine</a> in 9 European countries demonstrate the importance of this issue.</p>\n<p><strong>Update 4</strong> <a href=\"https://www.fda.gov/news-events/press-announcements/fda-approves-first-covid-19-vaccine\" rel=\"nofollow noreferrer\">Pfizer vaccine has been fully approved</a> - that is from now on it is considered a fully tested vaccine (till now it had been used under the <em>emergency authorization</em>).</p>\n", "pids": ["5fd58077a4e4c3c831a6cb24"], "flag": 1}
{"question": "Book on current state of knowledge on the genetics of intelligence", "body": "<p>I'm looking for a book that gives a good summation of the current state of knowledge on the genetics underlying intelligence.</p>\n\n<p>I have read textbooks on human population genetics but I'm looking for something more specific.</p>\n\n<p>I'd be happy for pointers to any books on neuroscience, developmental psychology, genetics that give some coverage to this topic.</p>\n\n<p>I am not really looking for a popular science book.</p>\n", "pids": ["5c8c737f4895d9cbc60575cf"], "flag": 1}
{"question": "Theorem of uncertainty in cognitive science", "body": "<p>Recently, reading one book I have come across such paragraph:</p>\n\n<p><code>\"[...] The operation would require de facto to create a complete record of the mind and build the brain again - an impossible thing for absolutely fundamental reasons. Cognitive science has its own theorem on uncertainty, the law proving the impossibility of reducing the mental structure to numerical data.\"</code></p>\n\n<p>I am guessing, that the author was referring to the Heisenberg's uncertainty theorem, but that is the only thing that came to my mind (my knowledge about cognitive sciences is very limited). Do you know, what the author might have meant? Or maybe it was just fiction?</p>\n", "pids": ["53e9a90db7602d970325cb81"], "flag": 1}
{"question": "Evidence and arguments for and against bounded rationality?", "body": "<p>Can anyone point me to a couple prominent papers on Simon's concept of bounded rationality (i.e., that human rationality is shaped by limitations in our ability to ingest and process information)? Specifically, I'm looking for empirical evidence for or against and arguments against (I'm content with Simon's own arguments for.) I know the literature on this is extensive; I just need a very high-level overview with some credible scholarly support.</p>\n", "pids": ["56d8ede1dabfae2eee621fb6"], "flag": 1}
{"question": "Long term effects of a high self monitor who voluntarily chooses a contradictory self-presentation", "body": "<p>Are there any cases or studies of a <code>high self monitor</code> who intuitively chooses to act \"by impulse\" in order to reform said impulse? </p>\n\n<p>In other words when the HSM behaves as a <code>low self monitor</code> they selectively and willingly embrace a <code>low self presentation</code> in order to challenge (or embrace flaws) within their own pride, ego, or some other aspect of psychology.</p>\n\n<p><strong>Additional questions</strong></p>\n\n<ul>\n<li><p>What else can be said of this situation? </p></li>\n<li><p>What other questions, or background is necessary to analyze this occurrence? </p></li>\n<li><p>Is this behavior indicative of other problems worth investigating? (e.g. morally flawed premise for taking such action)</p></li>\n<li><p>What negative effects could there be on the ego and super-ego by behaving this way over long periods of time? </p></li>\n</ul>\n\n<p><strong>Edit</strong></p>\n\n<p>At a young age, this HSM may have discovered that behaving as a low-self-presentation allowed them to abdicate responsibility.  This was later corrected in adulthood when the subject decided to actively pursue accountability on past and present behavior... thus leading to overall character improvement. </p>\n", "pids": ["56d8e73ddabfae2eee392820", "5c0f726cda562944ac65e9fe"], "flag": 1}
{"question": "Can you get addicted from using topical or local anaesthetics to ease pain?", "body": "<p>I've been wondering if there was such a thing as developing some kind of physical or psychological dependence on things that relieve pain. While we often hear about opioid addiction, which is primarily physical, I wonder if someone could psychologically be hooked on using something like lidocaine to numb every bruise or injury they get, just to numb the pain.</p>\n\n<p>I did hear that cocaine was once used as an anaesthetic, but it was also physically addicting.\nThis makes me wonder if physical withdrawal and hunger cravings are similar.</p>\n", "pids": ["53e9b062b7602d9703ac8159", "53e9be0fb7602d9704ac57f9"], "flag": 1}
{"question": "Can people act randomly?", "body": "<p>Let's imagine an experiment. We will tell N normal people that they need to act randomly in the Rock–paper–scissors game (in this game Game Optimal Strategy is to choose an action with uniform probability 1/3). \nTwo question:</p>\n\n<ul>\n<li><p>How close to uniformly randomness can we expect each person to act? </p></li>\n<li><p>More important question. Will this be a stationary distribution or it will change over the time if there will be a lot of trials?</p></li>\n</ul>\n\n<p><em>(People in the experiment can't use any kind of external random generators</em>).</p>\n", "pids": ["53e9b8b3b7602d970448e773"], "flag": 1}
{"question": "Are the skills trained and learn from world memory championship transferable?", "body": "<p>I recently learn something about world memory championship and I am considering to embark on some training. But I would like to know if the skills trained and learn from world memory championship are transferable? Like improving IQ, improving imagination capability, improving \"innate memory power\" (meaning that your memory improves even when not applying techniques)?</p>\n", "pids": ["5a9d3a07684d7fe2ff403bb8", "56d90281dabfae2eeee0cdd5"], "flag": 1}
{"question": "How are Genetic Circuits Modelled?", "body": "<p>I've read a recent Nature Methods paper by Moon <a href=\"http://www.ncbi.nlm.nih.gov/pubmed/23041931\" rel=\"nofollow\">T.S. <em>et al</em></a>, in which a synthetic genetic circuit consisting of layered logic gates was created. For example, the paper, a circuit is modelled in Figure 4a. How is this circuit computationally modelled? Can you refer me to any graduate level texts on the subject?</p>\n", "pids": ["5f0df7a89fced0a24bd2c478"], "flag": 1}
{"question": "How much pleasure can brain endure?", "body": "<p>As of 2018, is it possible to induce pleasure in humans by some intervention like sending electrical signals? I've read that it's been done on mice. If not, it's quite imaginable that it will become possible in the near future. What would be the neurological implications of such intervention, other than addiction? I mean what would happen to the brain if we force the brain to stay in an orgasm-like or ecstasy state for several minutes? What are the possible adverse effects or damages? Of course that we know very little yet, but I appreciate to get some insights on how pleasure works, and if there really are pleasure centers in the brain that can be easily manipulated. </p>\n", "pids": ["5c3cc6dcdf5b8c0b3cc978f7"], "flag": 1}
{"question": "Models of quorum sensing for multi-agent systems", "body": "<p><a href=\"https://en.wikipedia.org/wiki/Quorum_sensing\" rel=\"nofollow noreferrer\">Quorum sensing</a> is a system of stimulus and responses correlated to population density that is used by bacteria to coordinate gene-expression. I am looking for a simple computational/mathematical model of quorum sensing that abstracts away from the details of the mechanism implementing it inside the agent, but keeps the key inter-agent properties like diffusion rate, range, and timing.</p>\n<p><strong>Is there a standard abstract mathematical model of quorum sensing used by biologists?</strong></p>\n<p>I am not interested in the particulars of a specific organism, but would like a general model I could apply to capture the 'gist' for any organism that relies on quorum sensing for part of its behavior.</p>\n<hr />\n<p><a href=\"https://www.sciencedirect.com/science/article/pii/S0304397506007493\" rel=\"nofollow noreferrer\">Bernardini et al. (2007)</a> provided an extension to <a href=\"https://en.wikipedia.org/wiki/P_system\" rel=\"nofollow noreferrer\">P-systems</a> incorporating the basics of quorum sensing, and <a href=\"https://direct.mit.edu/artl/article-abstract/14/1/95/2599/A-Model-of-the-Quorum-Sensing-System-in-Vibrio\" rel=\"nofollow noreferrer\">Romero-Campero &amp; Pérez-Jiménez (2008)</a> have used their approach to model bioluminosity in <em>vibrio fischeri</em>. This approach is conceptually appealing to me, but that is because I am predominantly a computer scientists. Although P-system can be used for modeling biological systems <a href=\"https://link.springer.com/article/10.1023/A:1024943605864?from=SL\" rel=\"nofollow noreferrer\">(Ardelean &amp; Cavaliere, 2003)</a>, they still feel fundamentally computer-science-y and are typically not published in orthodox biological venues. This makes me suspect there is a more standard approach among biologists, probably via dynamic systems and diffusion equations.</p>\n", "pids": ["55a4165465ce5cd7b3c3bb5f", "53e99ddbb7602d970269fa96", "55a47f1565ce31bc877ce3c5", "60814dd2e4510cd7c85df43a", "57d4fb56a57c569c44e9ca95", "59b201fd0cf2cd24b516f8a6"], "flag": 1}
{"question": "Has there been any studies of pathological &quot;nomad-ness&quot;?", "body": "<p>I've spent some time trying to search for this but my lack of knowledge limits my ability to find any information about this subject. </p>\n\n<p>I know someone who constantly sees another city as a \"Grass is Greener\" and will pack up and move about every eight months. This behavior of \"loose-footing\" that I'm trying to describe meets the 4 D's of Psychopathology: </p>\n\n<ol>\n<li><strong>Deviance</strong>: Moving to another town for an unacceptably bad reason that someone of their intelligence wouldn't accept if they heard it from someone else.</li>\n<li><strong>Distress</strong>: Forgoing valuable social and capital assets that causes hardship after the move. Feelings of loneliness after losing touch of newly created friendships before the move. Constant anxiety of not moving to a new city when they think they find a better one.</li>\n<li><p><strong>Dysfunctional</strong>: The person is in complete denial of the behavior trend and after moving to a new city will spend resources in material or non material assets that reflect an intention to not move again. Like signing a two-year lease or selling or buying a car or a city parking space. Or quitting a Top-100 University after two years and a 4.0GPA in engineering that gave them a full-ride, because of a unacceptably poor reason.</p></li>\n<li><p><strong>Danger</strong>: These self-imposed hardships give the person chronic depression and a danger to harm themselves.</p></li>\n</ol>\n\n<p>I'm only talking about this when it is pathological. I am assuming this is common, but I'm unsure of how common it is as I can't find any info about it. Hence the motivation for the  question.  I'm not referring to a cultural group or a nomad as being pathological.</p>\n\n<p>One could say that this is just depression and/or anxiety and while that is true. I would imagine that this behavior is unique or common enough to deserve its own study of this trend, its origins or treatment strategies. For example growing up with derelict parents or maybe moving too often during childhood.</p>\n", "pids": ["56f001580cf276b216258776"], "flag": 1}
{"question": "What do brain waves look like under the influence of psilocybin?", "body": "<p>I am curious about what brain waves (EEG) look like under the influence of psilocybin mushrooms or LSD.  Is there any research on subjects in psychedelic states and how their brain waves change relative to normal?</p>\n", "pids": ["5c0f7224da562944ac653056"], "flag": 1}
{"question": "I think my thesis analysis sucks and I don&#39;t know how make it work", "body": "<p>I'm writing an undergraduate thesis in linguistics. My topic is about comparing politeness in English to the honorific system in Korean. No one in my school speaks Korean, neither my supervisor, but I wanted to include the language in my thesis to make the writing more fun for me. I think it was a mistake.</p>\n<p>I am stuck with my analysis. I've chosen a book in English and the translation of that book in Korean. I chose 4 politeness techniques in English and found around 74 sentences. I wanted to compare them to Korean. However, my analysis has to contain around 100 elements that should be analysed and put into a graph for visual representation. I have no idea how to make this happen so that it makes sense and my supervisor is not helping me. I feel like I've been improvising all the way till now and now I'm stuck</p>\n<p>I feel like I'm writing empty work that doesn't make any sense. It's making me very stressed and anxious because I have not even 2 months left, I feel like I'll fail and won't finish my undergrad because I chose a dumb topic. I have a lot of stuff written but everything seems pointless to me, as if my analysis made no sense. I wish someone would give me any advice as to how to progress, how to make this thesis better so that it makes sense. How can I incorporate those graphs, what data should I put in there? I feel so lost. What can I even do with this topic anymore, should I just give up?</p>\n", "pids": ["53e9bcbab7602d9704937557"], "flag": 1}
{"question": "Why this guilt discrepancy in human beings?", "body": "<p>I believe no person is born a criminal.</p>\n\n<p>Then why do some people have compunctious guilt after a wrongdoing even when they were raised in an unhealthy family and some people have no guilt at all even when they were raised in a healthy family?</p>\n\n<p>Why this guilt discrepancy in human beings?</p>\n", "pids": ["53e9b14cb7602d9703bd21c3"], "flag": 1}
{"question": "Does EMDR legitimately treat any condition?", "body": "<p>Are there any studies not funded by friends or beneficiaries of EMDR that prove it helps with a strong p-value?</p>\n", "pids": ["55a3a054c91b587b095d3e2e"], "flag": 1}
{"question": "Survey questions to test competitiveness", "body": "<p>I'm running an experiment and am suspecting that competitive people may respond differently to experimental treatments compared to non-competitive people.</p>\n\n<p>To determine whether a person has a competitive personality, I'm thinking of surveying and asking questions such as </p>\n\n<p>\"My friends would describe me as a competitive person.\"</p>\n\n<p>\"I would describe myself as a competitive person.\"</p>\n\n<p>\"Even when there is no monetary reward, I will seek to surpass others when doing a task.\"</p>\n\n<p>Would these be good measures of competitiveness? What other questions could I use?</p>\n", "pids": ["53e9b6cbb7602d9704254893", "53e9ad9eb7602d9703798f6f"], "flag": 1}
{"question": "How does the brain’s visual memory work?", "body": "<p>I have read a lot about people who are good memorizing images (visual type memory), music, words, numbers, etc. but I have never read a lot about <strong>how</strong> all these things are \"saved\" in our brain.</p>\n\n<p>I am not trying to understand the biological part, that is far away from my competences, I am talking more about a more general layer, like <em>what we actually memorize?</em></p>\n\n<p>I will start from an example: what do we \"save\" when we remember an image?</p>\n\n<ul>\n<li>Do we memorize all the \"pixels\" as a computer would?</li>\n</ul>\n", "pids": ["609fa094e4510cd7c834ee8e", "5c3ed5c7e1cd8e0a9606a804"], "flag": 1}
{"question": "Does Transcranial Direct-Current Stimulation (tDCS) enhance cognitive function?", "body": "<p>From the book \"The future is faster than you think\" by Peter Diamandis, Steven Kotler:</p>\n\n<p>“Consider the nine-dot problem, a classic test of creative problem-solving. Connect nine dots with four lines in ten minutes without lifting your pencil from the paper. Under normal circumstances, fewer than 5 percent of the population can pull this off. In a study run at the University of Sydney in Australia, none of their test subjects did. But then the researchers took a second group of subjects, and used transcranial direct stimulation to artificially mimic many of the changes produced during flow. What happened? Forty percent solved the problem—a record result.”</p>\n\n<p>What is the current scientific consensus on this question?</p>\n\n<p>This appears to be the study mentioned:<br>\nBrain stimulation enables the solution of an inherently difficult problem<br>\n<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0304394012003618\" rel=\"nofollow noreferrer\">https://www.sciencedirect.com/science/article/abs/pii/S0304394012003618</a></p>\n\n<p>An APA reference to the study was requested.<br>\nHere is one such reference:<br>\nUsing transcranial direct current stimulation to enhance creative cognition: Interactions between task, polarity, and stimulation site.<br>\n<a href=\"https://psycnet.apa.org/record/2017-24133-001\" rel=\"nofollow noreferrer\">https://psycnet.apa.org/record/2017-24133-001</a></p>\n", "pids": ["5ce2d047ced107d4c6360be7", "58ca7a540cf2b22b9fa3e1a2", "5c7559f5f56def979881999c", "5fc77839a84b2957c5b93f94", "5c8bd3e14895d9cbc6b008fa", "58ca74bc0cf2b22b9fa3c6b9", "5c757d2bf56def9798ab2423", "5c755963f56def97987bbd7e", "565862800cf2ac45f629eca3", "56d91050dabfae2eee37367e", "55503f5145ce0a409eb2d6da", "57a4e932ac44365e35c9bdb3", "5724cf240cf2952b60b72a51", "573350320cf2704310d619cc", "5e09a8c3df1a9c0c4169338e", "5c8bb1554895d9cbc6a3eb44", "56d83b95dabfae2eee628411", "58ca7b320cf2b22b9fa3e60e", "58d554040cf210d30c5aa80b", "58d4b2dc0cf221de036069c7", "5c86586e4895d9cbc64cb4b6", "59d599730cf2bb5427763c8f", "55a6b9d265ce054aad72d1b7", "5c756deef56def979857c011", "565711560cf20caa7d69652a"], "flag": 1}
{"question": "What&#39;s the psychological reason for the fascination with gossiping or scandalous life?", "body": "<p>Why do people find fascination in a tabloid magazine, paparazzi magazine, gossiping or whether prince and kings are dating or not or if actors, actresses, singers having any scandalous affairs or not?</p>\n\n<p>I find gossiping similar to character assassination.</p>\n\n<p>I have no business in their lives.</p>\n\n<p>So what's the psychological reason for the fascination with gossiping or scandalous life?</p>\n", "pids": ["53e9bb9ab7602d97047e37fa"], "flag": 1}
{"question": "Do most people want to murder?", "body": "<p>It seems like the most popular theory among philosophers and neuroscientists who believe in free will is something called <a href=\"https://www.psychologytoday.com/us/blog/dont-delay/201106/free-wont-it-may-be-all-we-have-or-need\" rel=\"nofollow noreferrer\"><strong>free won’t</strong></a>. This basically means that we cannot <em>will</em> what we want to will, but we have the power to <em>veto</em> a thought that our brain has produced.</p>\n\n<p>This would mean that a person who is about to murder another person should have the power to veto pulling the trigger- but if they don’t, then they should be held morally responsible because they didn’t use their <em>free won’t</em> power. </p>\n\n<p>Now, I don’t think about murdering people, but I might be a weirdo. <strong>Do most people want to murder other people, but they use their <em>free won’t</em> to refrain- so that they should be praised for their <em>self-control</em>?</strong></p>\n", "pids": ["53e99905b7602d970214051d", "5c87531f4895d9cbc6031e18", "56d918a6dabfae2eee6ac38a", "53e9a74ab7602d9703083b39"], "flag": 1}
{"question": "Body temperature increasing when trying to solve difficult problems", "body": "<p>[ <em>I am unsure if this is the correct site to ask this question</em> ]<br><br> \nI am a HS student, currently studying IT and personally I focus on the field of software (programming) and of course where there is programming there are problems which require you to have the skills to solve problems that occur. So I wanted to improve my skills by trying to solve problems and I've been doing some on <a href=\"http://hackerrank.com\" rel=\"nofollow noreferrer\">hackerrank</a>. </p>\n\n<p>However, whenever i try to solve a problem which is difficult to me and that I'm not capable of understanding it, I begin \"<em>overheating</em>\", literally. This keeps me from taking further steps to learn about the problems and different ways to approach to the solution. Basically, I feel  like a moron and stop working on the problem. </p>\n\n<p><strong>my question to you is, why do I \"overheat\" (body temp. increases) when i try to solve problems that are difficult to me?</strong></p>\n\n<p>is it because I don't have a goal which motivates me hard enough or am I just... a moron ? <br>Is there are way to \"turn off\" this overwhelming feeling?</p>\n\n<p>EDIT :</p>\n\n<p>After some more research i've come across this article which I believe could be the <a href=\"https://www.mybrainsolutions.com/library/2014/04/breaking-down-the-feeling-of-overwhelmed/\" rel=\"nofollow noreferrer\">answer</a> to my question (not sure).</p>\n", "pids": ["621682bc5aee126c0ff947b0", "56d8df49dabfae2eee07972c", "5a14e1540cf2dcc70c057f65"], "flag": 1}
{"question": "How do we imagine? How do images have qualia?", "body": "<p>After reading a bit about qualia and hard problem of consiousness, I came up to theoretical solution. The reason why we have this problem is because we can imagine. We can imagine an object visible to us as red being green, for example. Green fire. Even if we never saw it in the reality.</p>\n\n<p>But how do we imagine? How do those images have properties named by people as qualia? I can imagine a blue cube or a red cube, or a red sphere, and visual periphery is not involved here, I can do it with closed eyes.</p>\n\n<p>What parts of our brain are responsible for imagination? How does the brain \"give\" qualia (form, color, smell, etc.) to images? What differs in my brain when I imagine a red cube from when I imagine a blue cube? And are qualia stored in our memory?</p>\n", "pids": ["5c136aeeda56295a08a61672", "5c0f842cda562944ac8e007c"], "flag": 1}
{"question": "Can children restore brain cells?", "body": "<p><em>By \"children\" I mean young people at the age of 10 or lower.</em></p>\n\n<p>I know that the adult brain cannot restore brain cells, but what about children? I mean, the brain must develop from a few cells to a 90 billion cells somehow, when do we lose this ability?</p>\n\n<p>I'm also interested in cases when a child gets hit into the head (concussion). Can the damage  be fixed over time?</p>\n", "pids": ["5ce2d1c3ced107d4c6463dd7"], "flag": 1}
{"question": "Primary cilia: what cell types have non-motile cilia that migrate?", "body": "<p>My understanding is that there are two broad categories of cilia: motile and non-motile (also called primary. </p>\n\n<p>Examples of the former include sperm flagella and the cilia of epithelial cells that line the airways. </p>\n\n<p>Examples of the latter are mostly single cilia that protrude from the cell and act as an antenna, usually packed with certain receptors (HH pathway, Notch pathway etc.)</p>\n\n<p>In the inner ear, a primary cilium called the kinocilium extends out of the center of the apical side of hair cells and migrates to the lateral side over the course of a few days. This cilium is non-motile, it is simply anchored to a basal body which is pulled to one side of the cell.</p>\n\n<p>Does anyone know of another such example in any other tissue? A single non-motile primary cilium whose basal body migrates along the apical plane of the cell after docking with the cell cortex.</p>\n\n<p>Thanks.</p>\n", "pids": ["53e9b0d1b7602d9703b4daf2"], "flag": 1}
{"question": "Bounds on skew and kurtosis of IQ", "body": "<p>The question of whether IQ is Normally distributed, or instead follows e.g. a Pearson type IV distribution, has been debated since at least the 1910s. The quotient- and deviation-based definitions give rise to very different eras in that debate, of course. (However, the distribution of an integer-valued IQ cannot be exactly Normal, even on a deviation-based definition.) A Normal distribution is uniquely characterised by its mean <span class=\"math-container\">$\\mu$</span> and standard deviation <span class=\"math-container\">$\\sigma$</span>. Its next two moments are the skew <span class=\"math-container\">$\\gamma_1=0$</span> and excess kurtosis <span class=\"math-container\">$\\kappa_\\text{excess}=0$</span>. To disambiguate, I've defined</p>\n\n<p><span class=\"math-container\">$$\\gamma_1=\\mathbb{E}\\bigg(\\tfrac{X-\\mu}{\\sigma}\\bigg)^3,\\,\\kappa_\\text{excess}:=\\mathbb{E}\\bigg(\\tfrac{X-\\mu}{\\sigma}\\bigg)^4-3.$$</span></p>\n\n<p>By contrast, a Pearson type IV distribution requires all four moments to be specified.</p>\n\n<p>While we can't literally prove <span class=\"math-container\">$\\gamma_1=\\kappa_\\text{excess}=0$</span> empirically, we can constrain such quantities. Have any empirical studies provided either upper or lower bounds on these moments of the IQ distribution (or something analogous such as another quantification estimating psychometric <span class=\"math-container\">$g$</span>), on either the quotient or deviation definition? In the interests of keeping this question appropriate to the site, I don't care what method of defining or measuring IQ was assumed in a particular study, so there's no need to take a stance on that.</p>\n", "pids": ["56d92b3fdabfae2eeed9d2d8"], "flag": 1}
{"question": "How will the pet therapy aid the child with autism?", "body": "<p>As a <strong>Special Education Teacher at ACCEL</strong>, behaviors of individuals with autism has been remarkably consistent over time with the help of ABA therapy services, which include pet therapy and individualized education program.</p>\n\n<p>What are your thoughts about pet therapy for this population? How is it proven to be beneficial?</p>\n", "pids": ["55a4f90265ceb7cb02dd7987"], "flag": 1}
{"question": "Can extinct animals be cloned?", "body": "<p>Scientists have found mammoth blood, and are planning to <a href=\"http://www.inquisitr.com/680125/mammoth-blood-found-cloning-extinct-species-may-soon-be-possible/\" rel=\"nofollow\">clone a mammoth.</a></p>\n\n<p>How does one go from having its blood to a full blown living mammoth? Is it possible?  </p>\n\n<p>Why does it matter if the blood is frozen or not? Suppose one found dinosaur blood, could one clone a dinsosaur (as in say 'Jurassic Park')?   </p>\n", "pids": ["56d818badabfae2eee844a48"], "flag": 1}
{"question": "What electrical stimuli do brain implants use?", "body": "<p>I was reading about artificial eyes and came to think about how the brain works. More specifically, what \"signals\" it uses in the case of cortical visual prosthetics in blind people? Cortical prosthetics apply current stimulations through electrodes placed on the surface of the visual cortex. </p>\n\n<p>Now suppose I would want to let a blind person wearing a cortical prosthesis to see the color red, what signal would I send through the electrodes? Would a sine wave of 200 Hz do the job? </p>\n", "pids": ["53e9a584b7602d9702eab0c6", "5d0b006c8607575390fc491b"], "flag": 1}
{"question": "Why do cell membranes have a lipid bilayer instead of a monolayer?", "body": "<p>Many cells have a cell membrane composed of two layers of lipids. Why is it that they have two layers and not just one? </p>\n\n<p>What purpose do this arrangement serve?</p>\n", "pids": ["55a6c61765ce054aad75305f"], "flag": 1}
{"question": "Using home address when submitting an article with no affiliation?", "body": "<p>If you're submitting information for an article, and you have no institution affiliation, what should you use? I was asked for an address and all I have is an home address. That seems a bit weird to use, however. </p>\n", "pids": ["55a4d5de65ceb7cb02d98514", "56604bb80cf2dab45b565a4a"], "flag": 1}
{"question": "Inheritance of Huntington&#39;s disease", "body": "<p>People with Huntington's disease have <em>HTT</em> genes with more than 37 copies of CAG repeat. The risk of extra copies being generated is higher during sperm formation than during ovum formation. Why is it so?</p>\n\n<p>Interesting fact: People with HD allele inherited from father develop symptoms earlier than if that allele is inherited from mother.</p>\n", "pids": ["55a4a68365ceb7cb02d542f8"], "flag": 1}
{"question": "Is stainless steel plating possible?", "body": "<p>Is there a method for plating steel with stainless steel? </p>\n\n<p>If so, is it chemical, electrical, or electrochemical? </p>\n\n<p>I did a quick search on the internet but was unable to find a service. I'm interested in applying a food safe finish to something that would otherwise be cost prohibitive to make out of solid stainless steel.</p>\n", "pids": ["648d1b4cd68f896efaa7ac41"], "flag": 1}
{"question": "What is &quot;flow instability&quot; in porous media?", "body": "<p>Pressure drop across a porous medium can be described by the Forchheimer extension to Darcy’s law:\n$$-\\frac{dp}{dx} = \\frac{\\mu}{K_1}\\cdot v + \\frac{\\rho}{K_2}\\cdot v^2$$</p>\n\n<p>where $K_1$ and $K_2$ are permeability coefficients that depends on medium geometry (Pitz-Paal\net al., 1996).</p>\n\n<p>I just came across this paragraph in a paper studying the flow stability in porous media in solar volumetric receivers, which I couldn't digest at all:</p>\n\n<blockquote>\n  <p>In the flow through a porous sample, the mass flow density is determined by the pressure difference between the two sides of the sample. <strong><em>The pressure drop is produced by a blower. Instability occurs when a pressure drop causes different mass flow densities</em></strong></p>\n</blockquote>\n\n<p>What blower? and what makes pressure drop cause different mass flow? (Keeping in mind previous equations)</p>\n", "pids": ["53e99bb9b7602d97024645bf"], "flag": 1}
{"question": "Can I reduce the column moment due to beam, by setting the beam end to pin?", "body": "<p>I have a structure, which contains only frame elements ( beam and column).</p>\n\n<p><a href=\"https://i.stack.imgur.com/8zIej.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/8zIej.png\" alt=\"enter image description here\"></a></p>\n\n<p>From what I know, if I apply point load at the columns on both left and right hand side,and if the beam-column joint is rigid, then the column at the center will experience extra moment, because the beam moment will be transmitted to the center column.</p>\n\n<p>In other words, the center column will take moment because of the beam's existence, am I right?</p>\n\n<p>In order to eliminate this extra moment taken by the center column, can I then set the beam-column join connection as pin? How would the structural behavior changes?</p>\n", "pids": ["56d83c7adabfae2eee67fd1d"], "flag": 1}
{"question": "Are some non-coding RNA spliced?", "body": "<p>Are some non-coding RNA spliced like mRNA? I tried to find some information but I don't find anything...</p>\n", "pids": ["5f2945af91e011376d9c5ff7", "55a4e3ab65ceb7cb02db2073"], "flag": 1}
{"question": "Understanding pressure drop and mass average values", "body": "<p>While studying some papers,  I didn't understand the following sentences:</p>\n\n<blockquote>\n  <p><code>deltP</code> the pressure drop across the turbine, evaluated using the mass average values at the inlet and outlet sections of the computational domain, respectively.</p>\n</blockquote>\n\n<p>What is the exact meaning of the \"mass average values\"?</p>\n\n<p>And is there such a option of \"mass average values\" in Fluent?  I dont know that how to compute this parameter in Fluent.</p>\n", "pids": ["53e999b5b7602d97021fcd2c"], "flag": 1}
{"question": "Functionality of vitamin A, Bx, C, D, E, K as used in cosmetics for the skin?", "body": "<p>I was wondering if someone can compare the functionality of vitamin A, Bx (x means numbers, such as 1, 2, 3, ...), C, D, E, K in the skin?  They are used in cosmetics but what is their actual effect?</p>\n\n<p>If there is some source that compares between them in particular, I think it will help me understand some important basics.</p>\n\n<p>Some products:</p>\n\n<p><a href=\"http://www.gnc.com/product/index.jsp?productId=2134133\" rel=\"nofollow\">GNC Vitamin C Moisturizing Cream</a></p>\n\n<p><a href=\"http://www.gnc.com/product/index.jsp?productId=2134134\" rel=\"nofollow\">GNC Vitamins E, A &amp; D Moisturizing Cream</a></p>\n\n<p><a href=\"http://www.gnc.com/product/index.jsp?productId=2134011\" rel=\"nofollow\">Reviva™ Labs Alpha Lipoic Acid Vitamin C Ester &amp; DMAE Cream</a></p>\n\n<p><a href=\"http://www.gnc.com/product/index.jsp?productId=2612785\" rel=\"nofollow\">Reviva™ Labs Vitamin K Cream</a></p>\n", "pids": ["53e99cb5b7602d970256941a", "53e99c04b7602d97024ae0f1", "53e9af81b7602d97039c8bfb", "55a4a8ae65ceb7cb02d571b4", "55a480e4612ca6486898dd27", "6229769d5aee126c0f9ce2d7", "62298fac5aee126c0ff4f929", "53e99b36b7602d97023d2372"], "flag": 1}
{"question": "Control theory: Closed loop zeros, Root locus and its dynamic response", "body": "<p>Why the closed loop dominant poles of the root locus can show the response of the system? Wont it neglect the effect of the closed loop zeros?</p>\n\n<p>As I read on the books, root locus method deal with the closed loop poles. It sketch the locus of the close-loop poles under an increase of one open loop gain(K) and if the root of that characteristic equation falls on the RHP. It means the close loop pole fall into RHP and make system unstable. But the exercises and examples also treat Root locus as a method of designing compensation or gain to fulfill the system requirement like damping factor and setting time. Isn't the root locus method for stability only?</p>\n\n<p>I thought the system response should include the closeloop zero. Did I miss something? </p>\n\n<p>Also, can Nyquist plot also used to show the system response and to design the system? As I thought its some how same as Root locus, with frequency being the varying K(gain).</p>\n", "pids": ["53e9ae22b7602d9703836de3"], "flag": 1}
{"question": "Could a water stream be used as a fiber optic sensor and detect when the stream is broken?", "body": "<p>I have a small idea/project I am working on in which I want to use a water fiber optic sensor that can detect whether the water stream is broken and if so shut off the water.</p>\n\n<p>Having looked into fiber optic sensor systems in general, all I have managed to work out is I would need an intrinsic sensing region system.  I do not know what type of Optical Modulation mechanism I would need so have hit a wall.</p>\n\n<p>Any guidance into which of these systems, Intensity modulated, Phase modulated, Wavelength modulated or Polarization modulated, could be useful would be massively appreciated as I'd love to be able to look into this further.</p>\n", "pids": ["5488ea4b45ce471f90915bb0"], "flag": 1}
{"question": "Distance of Pivot from the Rear axle", "body": "<p>I am designing an NSAM crane. I have encountered the following issue when designing the vehicle:</p>\n\n<p>Generally the pivot(or the point about which the NSAM crane rotates) is in the center. But from two online sources(<a href=\"https://patents.google.com/patent/US8002074\" rel=\"nofollow noreferrer\">https://patents.google.com/patent/US8002074</a>, <a href=\"https://www.tandfonline.com/doi/abs/10.7158/M12-108.2014.12.1\" rel=\"nofollow noreferrer\">https://www.tandfonline.com/doi/abs/10.7158/M12-108.2014.12.1</a>) I have found that if the pivot is in the center, then the NSAM crane has easy maneuverability and tip over stability. If the pivot is away from the center and towards the rear axle, the roll over stability is more.</p>\n\n<p>Even though some calculations have been given in the sources, I am not able to understand why this is the case and which stability is more important for the NSAM crane?</p>\n\n<p>Also please help me with any Simply supported beam type of calculations for the stability if any.</p>\n\n<p>Any references would be appreciated.</p>\n\n<p>Thanks</p>\n", "pids": ["5c7b53884895d9cbc669bc59"], "flag": 1}
{"question": "Are wild cats the same species as house cats?", "body": "<p>I thought that the definition of species is \"can interbreed\"</p>\n\n<p>From <a href=\"https://en.wikipedia.org/wiki/Wildcat\" rel=\"nofollow\">Wikipedia</a>:</p>\n\n<blockquote>\n  <p>The wildcat (Felis silvestris) is a small cat found throughout most of\n  Africa, Europe, and southwest and central Asia into India, China, and\n  Mongolia. Because of its wide range, it is classed by the IUCN as\n  Least Concern. However, crossbreeding with housecats is extensive and\n  has occurred throughout almost the entirety of the species' range.[2]</p>\n</blockquote>\n\n<p>So why does it have a different name than the house cat?</p>\n\n<p>From <a href=\"https://en.wikipedia.org/wiki/Species\" rel=\"nofollow\">Species</a> at Wikipedia:</p>\n\n<blockquote>\n  <p>A species is often defined as a group of organisms capable of interbreeding and producing fertile offspring. While in many cases this definition is adequate, the difficulty of defining species is known as the species problem.</p>\n</blockquote>\n\n<p>While I understand that sometimes problems arise, what makes biologist mark the wild cat as a distinct species from the house cat? If they are genetically different, how different?</p>\n\n<p>Donkeys can breed with horses. The result is sterile. Tigers can breed with lions with lots of complication. Wildcat seems to interbreed with housecat without problem whatsoever. Or does it? That's actually the essence of the question.</p>\n", "pids": ["5c757e24f56def9798b5b2e4"], "flag": 1}
{"question": "Is solving cancer required in order to avoid aging?", "body": "<p>When the telomerase enzyme is not active the telomere shortens every time the cell duplicates leading to a reproductive limit (<a href=\"http://en.wikipedia.org/wiki/Hayflick_limit\" rel=\"nofollow\">Hayflicks limit</a>).\nOn one hand this is a believed reason for aging. On the other hand this makes a mutated cell more difficult to acquire cancer, since in order to become cancerous, it would need to mutate such that the telomere enzyme becomes active.  </p>\n\n<p>The telomere enzyme is not active in most human cells.\nTherefore activating the telomerase enzyme in somatic (body) cells could theoretically decrease aging but would also increase the risk of cancer.</p>\n\n<p>Am I right to assume that in order to avoid aging of humans one would first need to \"solve cancer\"?</p>\n", "pids": ["5e8ea5bb9fced0a24b52221e"], "flag": 1}
{"question": "Why is pure shear a &quot;shear&quot;?", "body": "<p>If one looks up the meaning of shear strain, most sources talk about this situation:</p>\n\n<p><a href=\"https://i.stack.imgur.com/a7rys.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/a7rys.png\" alt=\"enter image description here\"></a></p>\n\n<p>That is, a force acts <em>along</em> a surface of an element at it is elongated, turning a rectangle into a rhombus. Apparently this is called \"simple shear\".</p>\n\n<p>But then I found out there is something called \"pure shear\", which is illustrated in this picture:</p>\n\n<p><a href=\"https://i.stack.imgur.com/IV4DX.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/IV4DX.png\" alt=\"enter image description here\"></a></p>\n\n<p>So pure shear, on the other hand, is a \"flattening\" of a body; the element is squeezed flatter on one axis and elongated on another. There is no change in angle between the lines, as there was in the simple shear case.</p>\n\n<p>My question is: <strong>Why are these two things both called \"shear strains\"? What do they have in common, besides that neither change the area of the element? What is \"pure\" about \"pure shear\" and \"simple\" about \"simple shear\"?</strong></p>\n\n<p>Simple shear is caused when the force is acting <em>along</em> the surface of the element, without normal forces. But what about pure shear? It involves squeezing in one axis and elongating on other, so it must be caused by normal forces, right? But if this is right, then it wouldn't make sense to put this in the same category (\"shear\") as simple shear, as one would be caused by normal forces that act directly on the surfaces of the element, and the other by forces <em>along</em> the surfaces of the element.</p>\n", "pids": ["5c8f01544895d9cbc6053080"], "flag": 1}
{"question": "Free falling fluid pressure distribution", "body": "<p>Consider a free falling tank of fluid. The goal is to find the pressure distribution.</p>\n\n<p>My intuition says that there should be no pressure distribution; the pressure should be uniform since the container is also accelerating at the same rate and direction as gravity, so there is no upward reacting force on the fluid to create a hydrostatic pressure distribution. This is also previously supported by others: <a href=\"https://physics.stackexchange.com/questions/4619/water-pressure-in-free-fall\">https://physics.stackexchange.com/questions/4619/water-pressure-in-free-fall</a></p>\n\n<p>Previous questions and answers, however, are entirely handwavy and also based on intuition. How can we prove this mathematically?</p>\n\n<p>I start with Euler's equation in the downward direction of acceleration, let's say the <span class=\"math-container\">$z$</span> direction:</p>\n\n<p><span class=\"math-container\">$\\rho a_z = -\\frac{\\partial P}{\\partial z} - \\rho g$</span></p>\n\n<p>and the fluid is accelerating downward with acceleration <span class=\"math-container\">$a_z = -g$</span>.</p>\n\n<p>Substituting into Euler's equation yields</p>\n\n<p><span class=\"math-container\">$ \\frac{\\partial P}{\\partial z} = 0$</span></p>\n\n<p>thus proving that the pressure in a free-falling fluid is uniform.</p>\n\n<p>Is this correct? Can I apply <span class=\"math-container\">$a_z = -g$</span> in the fluid equation of motion even though gravity is already accounted for?</p>\n", "pids": ["53e99d0bb7602d97025bd837"], "flag": 1}
{"question": "Tests for alertness", "body": "<p>Have there been any researched paper or digital tests developed that test a persons alertness at a given point in time? By alert I mean having the reactions of a person who is not over-tired, intoxicated, with a disability that inhibits reaction time, etc.</p>\n\n<p>Edit:</p>\n\n<p>I didn't see my answer in <a href=\"http://www.optalert.com/news/dr-johns-drowsiness-detection-technology-pharmaceutical-industry\" rel=\"nofollow noreferrer\">http://www.optalert.com/news/dr-johns-drowsiness-detection-technology-pharmaceutical-industry</a> . </p>\n\n<p>I am interested in a digital or paper test.</p>\n", "pids": ["56fbde0f0cf2cd3b44e4a0d8", "55a5499f65ceb7cb02e704d9", "6217099e5aee126c0ffc245d", "55a45bed612ca6486893a2d8", "55a44ab8612ca6486890652d"], "flag": 1}
{"question": "experimental tracking and treating bipolar disorder", "body": "<p>Is there a way to measure what neurotransmitters (and in what amount) are present in a person via blood or other method? I feel like if such information was available there could be experiments regarding the tracking and treatment of many mental disorders, but most specifically Bipolar Disorder. For example, if there could be an established \"norm\" of neurotransmitter levels you could then find the levels a person has and alter them via a mixture of drugs and monitor the levels periodically. This wouldn't require MRI imaging because you wouldn't be tracking when the neurotransmitters were triggered but the levels, the triggering/action potentials would be changed through cognitive behavioral and dialectal behavioral therapy. This is a alight ramble but i would appreciate any thoughts or insight.</p>\n", "pids": ["53e9bd04b7602d970498d8e9", "53e9a7c8b7602d9703104c6c", "53e9a618b7602d9702f45747", "53e9b923b7602d970450b063"], "flag": 1}
{"question": "How fast can stimuli be administered for evoked potentials?", "body": "<p>I'm looking for a reference about the ability for sensory stimuli to generate separate evoked potentials in the brain. </p>\n\n<p><strong>What is the maximum repetition rate for sensory evoked potentials?</strong></p>\n", "pids": ["53e9b6e8b7602d9704277063"], "flag": 1}
{"question": "Would a PE-pipe filled with concrete make a good pillar?", "body": "<p>An idea that keeps popping up in my head, that I don't know enough structural/civil engineering to know if it's good from a technical point of view.</p>\n\n<p>Take a piece of <a href=\"http://en.wikipedia.org/wiki/Polyethylene\" rel=\"nofollow\">polyethelene</a> (PE) piping, fill it with concrete, let the concrete bind. My understanding is that under compression, a concrete (or other) pillar will 'want' to shear apart in a plane 45° to the direction of the compression (assuming we don't bend our pillar). This is an outward movement. This shear force could be contained by the surrounding pipe, since PE is quite good in tension. Othe materials for the pipe might work the same, I say PE because it's quite corrosion resistant.</p>\n\n<p>I know everyone is building concrete pillars with rebar inside, I don't claim my idea is superior. I'm not interested in understanding why everyone is building pillars the way everyone is building them, I want to understand the flaws and limitations in my idea. Some thoughts:</p>\n\n<p>I think it's useful to think as pressure in the pipe, as we have that data easily available - if we use PN10, it can take 10 bar, etc., and we don't need to think about the thickness of the pipe and it's yield strength. But how would the compressive force translate into pressure on the pipe? The concrete is no liquid, so pressue will be less than compressive load / pipe area. How much? I think understanding this will tell us how much, or little, our pillar will carry. </p>\n\n<p>Another possible issue is that PE is quite smooth. The pipe can't take forces via friction and in my mind that translates to point loads at the places where the concrete happens to deform most.</p>\n", "pids": ["53e9b2e6b7602d9703da01b2"], "flag": 1}
{"question": "Do all thermoelectric generators (TEG) require two distinct metals?", "body": "<p>Most thermocouples that I've seen being sold online consist of two separate metal wires connected at junctions. Many smaller thermoelectric generators consist of a combination of iron and copper or iron and aluminum. However, I'm a tad confused why two different materials are being used.</p>\n<p>If I take a look at the image below, I see that an n-type and p-type semiconductor is attached to a conducting wire with a heat source and heat sink on opposite ends. Do the semiconductor materials need to be different? For instance, can't I simply use n-type and p-type doped germanium? Why do I need to use two distinct metals? Is there a benefit, for instance using silicon for one and germanium for the other?</p>\n<p>Does the circuit wire need to be a special alloy, or just regular copper wire to transfer current?</p>\n<p>Ultimately, I'm a bit confused regarding the Seebeck Effect. I've seen this diagram, but also models with different alloys. Any clarification will be great!</p>\n<p><a href=\"https://i.stack.imgur.com/C7Iyfm.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/C7Iyfm.jpg\" alt=\"Science ABC, Venkatesh\" /></a></p>\n<p>(Image by <em>Science ABC - Venkatesh Vaidyanathan</em>)</p>\n", "pids": ["56d82a71dabfae2eeef8e628"], "flag": 1}
{"question": "Extracting power from fusion?", "body": "<p>If we are able to create a fusion reactor so there is a net gain in energy how can we turn the heat into electricity.</p>\n\n<p>I know how it is done normally for fission, steam, but how could this be adapted for a fusion reactor where all of the heat is confined?</p>\n\n<p>Are there any concepts for the stage after fusion becomes net positive?</p>\n", "pids": ["56d90d55dabfae2eee2564bc", "56d90eb7dabfae2eee2d8691"], "flag": 1}
{"question": "How to extract a building&#39;s heat isolation and thermal inertia based on temperature curves?", "body": "<p>So imagine we have a house with some isolation and some thermal inertia. This house also has a heating system that turns on (starts heating) when the observed temperature curve goes below some predefined temperature threshold.</p>\n\n<p>I figured that in the scenario where the heating system is off (the observed temperature is above the threshold the temperature decrease will give us information on the thermal isolation and inertia. We need of course to take in to account the external temperature, the wind, and the sun irradiation.</p>\n\n<p>I was wondering if there was a way to dissociate the information of the thermal isolation and the information of the thermal inertia. Clearly, if we had information about the thermal power loss it would give an indication but unfortunately we don't.</p>\n\n<p>The data I have :  Observed inside temperature and desired inside temperature, outside temperature, wind, humidity from a weather station in the same city (so I guess only the external temperature can be used)</p>\n\n<p>Objective: Determine the conductivity and thermal mass of the house for sales purposes (sell more isolation, help them master energy efficient behavior  etc)</p>\n", "pids": ["56d82b5fdabfae2eeefec97d"], "flag": 1}
{"question": "Modelling gas desorption from a still solution (e.g. a beer)", "body": "<p>The common way to model or estimate gas (e.g. CO2) desorption rate from a liquid solution is by using an equation similar to this one</p>\n\n<p>$J_{CO_2} = -k_L a(H·C^G_{CO_2} - C^L_{CO_2})$</p>\n\n<p>where $J_{CO_2}$ is the molar (or mass) flowrate, $k_L$ is the mass transfer coefficient, $a$ is the specific contact surface, $H$ is one of the many expressions used for Henry's constant, and the G and L scripts stand for gas and liquid phase respectively.</p>\n\n<p>The problem with this approach is that all the correlations I know used to estimate $k_L$, $a$, or most commonly $k_La$ imply that there is a gas stream with a given gas velocity (e.g. aeration or sparging).\nHow could I estimate $k_La$ for a still solution, for instance a glass containing beer where the gas bubbles are stripped slowly? Furthermore, if I wanted to assess the effect of stirring the beer with a spoon, how could I estimate the effect? </p>\n", "pids": ["53e9ae11b7602d97038222b0"], "flag": 1}
{"question": "Does the Rubik&#39;s Cube increase mental ability?", "body": "<p>Does becoming efficient in the <a href=\"https://eu.rubiks.com/\" rel=\"nofollow noreferrer\">cube</a> help build your brain to be able to do other tasks better? What tasks and how?</p>\n", "pids": ["56d85721dabfae2eee316505"], "flag": 1}
{"question": "More efficient to use LED lighting than to open blinds for light and thereby lose heat when very cold outside?", "body": "<p>Currently here it is 9 degrees Farenheit.  My home is heated by electric resistance heating (not a heat pump, just plain heating coils).  Am I correct in believing that it's more energy efficient to keep our wooden blinds and curtains closed and turn on LED lighting than to open our blinds and curtains for light?</p>\n<p>Our windows are double-paned.  My local utility says it's better to open the windows than turn on an LED light, but I can't believe that's true under current conditions.</p>\n<p>My belief is:\nLoss of heat due to opening blinds and curtains * electricity needed to replace that heat via resistance &gt; electricity needed to power LED lights (say 8 watts per window).</p>\n<p>NOTE:  This is when the sun is <em>not</em> shining directly in thru the window.  Direct solar radiation can be very heating, as detailed in an answer below.</p>\n", "pids": ["56d82b5fdabfae2eeefec7cf"], "flag": 1}
{"question": "Possible applications of the big five personality traits testing in human resource departments", "body": "<p>I am a multimedia artist who is interning in a human resources department of a casino resort. In the department we have daily meetings to discuss updates to both the orientation and the performance of the casino's employees.</p>\n\n<p>During the discussion I had an idea on maybe using psychometric ( big 5 ) testing for either helping in filtering out unfit candidates for certain positions or/and allocation of time or resources to certain to certain people or group's of people to help them in certain ways or identify problems as to improve the effectiveness of the staff.</p>\n\n<p>My questions are;</p>\n\n<p>1: Can it be used in this way, or what other ways can HR use it?</p>\n\n<p>2: How to go about using it?</p>\n\n<p>3: Will it be effective?</p>\n\n<p>4: Does there exists other companies that use psychometric testing or big 5 for there employees?</p>\n", "pids": ["53e9aab0b7602d970342b18e"], "flag": 1}
{"question": "Why isn&#39;t high functioning autism recognized by the DSM-5 or the ICD-10?", "body": "<p>I was looking at this <a href=\"https://en.m.wikipedia.org/wiki/High-functioning_autism\" rel=\"nofollow noreferrer\">https://en.m.wikipedia.org/wiki/High-functioning_autism</a> and it said that. Aspergers is also closely related to high functioning autism but it is also not recognized anymore. Does this mean that neither of them are a \"thing\" anymore? Would diagnosing someone with either of these labels be inaccurate?</p>\n", "pids": ["55a5381c65ceb7cb02e4eb6b", "5c13680cda56295a08a0ec73", "5c7559c9f56def97987fe011", "55a4e80d65ceb7cb02db9f73", "55a4739265ce31bc877b3c3c", "53e99fe4b7602d97028bfdde"], "flag": 1}
{"question": "Why do the humans become sleepy after meals?", "body": "<p>I don't know about all the mankind, but I know enough people, who becomes sleepy after their meals. Also, I'm not sure, what kind of food do they consume, but I personally get sleepy almost from any food: sweet, fat, spicy, salty, liquid, tasty, not tasty, etc.</p>\n\n<p>Is this phenomenon well known? And, if yes, how does it occur?</p>\n", "pids": ["53e9ae17b7602d9703828c7b"], "flag": 1}
{"question": "Super-resolution imaging in vivo", "body": "<p>Are there any microscopy modalities or techniques for <strong><em>in vivo</em></strong> imaging at higher resolutions than the <strong>diffraction limit</strong>?</p>\n\n<p>I was looking at this list: <a href=\"http://en.wikipedia.org/wiki/Super_resolution_microscopy\" rel=\"nofollow noreferrer\">Super resolution microscopy</a>, but they don't talk about <em>in vivo</em> imaging.</p>\n", "pids": ["55a4118b65ce5cd7b3c30fda", "55a3ea0b65ce5cd7b3bc99e3"], "flag": 1}
{"question": "Adding phase error to a system based on phase margin", "body": "<p>I have a MIMO transfer function and referring to a <a href=\"https://ieeexplore.ieee.org/document/9147500\" rel=\"nofollow noreferrer\">research work</a>, I have found a phase margin for this MIMO system. I want to check and see the system blow when a phase error greater than the phase margin is introduced to the system. But I cannot think of how to do that either in time or the Laplace domain? Any help or other source to read from is highly appreciated , thanks.</p>\n", "pids": ["5f648d069fced0a24b3b7dae"], "flag": 1}
{"question": "Thermal conductivity relationship with particle size in nanofluids", "body": "<p>Is thermal conductivity of nano sized particles and bulk particles the same? If not, what's the difference and is there any relation between thermal conductivity and and particle size?</p>\n", "pids": ["5488fb2645ce471f909b3cfe"], "flag": 1}
{"question": "How much ductile can be the MAX phases?", "body": "<p>I want to know something about the mechanical properties of the MAX phases. How ductile can $\\text{Ti}_3\\text{SiC}_2$ for example be at elevated temperatures? Can it be as ductile as Zinc or Aluminium?</p>\n", "pids": ["5c7566d5f56def9798111e1c"], "flag": 1}
{"question": "Why not use Sodium Hydroxide mist to precipitate carbon dioxide from hydrocarbon combustion exhaust", "body": "<p>Much of the currently used techniques of scrubbing the carbon dioxide from power plant exhaust uses sophisticated amine and other organic compounds.  These compounds are then forced to release the CO2 with electric current or heat so that the concentrated CO2 can be pumped underground or otherwise sequestered.\nWhy not just spray the power plant exhaust with a finely atomized Sodium Hydroxide mist to directly precipitate out the CO2 as Sodium Carbonate or Sodium BiCarbonate?  The carbonates can be sold as carbon credits and/or be useful products.  Sodium Hydroxide can be obtained in quantity cheaply from electrolysis of sea water and other methods. </p>\n", "pids": ["56d92512dabfae2eeeb617e8"], "flag": 1}
{"question": "What is the state of automated quantitative analysis?", "body": "<p>Quantitative analysis of microscope images is essential for many types of studies, but the techniques used most often are very labor-intensive. I have been able to find some literature about using computers to perform the analysis, but do not have a good picture of the state of the art.</p>\n\n<ul>\n<li><p>Is there a good literature review on the topic?</p></li>\n<li><p>Is there much use in practice which I have not yet seen?</p></li>\n</ul>\n", "pids": ["55a3ee1e65ce5cd7b3bd8947"], "flag": 1}
{"question": "What mathematical operation should I do in order to translate from TWyr/y to TWyr_30 in this article?", "body": "<p>In this article\n<a href=\"https://www.sciencedirect.com/science/article/pii/S266711312200002X\" rel=\"nofollow noreferrer\">https://www.sciencedirect.com/science/article/pii/S266711312200002X</a></p>\n<p>the authors show a result of prediction on energy reserves (in particular solar ones) as known in 2015 (Figure 1) and as known in 2022 (Figure 2).</p>\n<p>In the first one (Figure 1), they quote result in TWyr/y. For solar, they quote 23 000 TWyr/y.</p>\n<p>In the second one (Figure 2), they quote result in TWyr<sub>30</sub>. For solar, they quote 8300 TWy<sub>30</sub>.\nThey state &quot;we will refer to TWyr over 30 years as TWyr<sub>30</sub>&quot;.</p>\n<p>Since results on estimation of solar energy reserves should not change by a huge factor between an estimation of 2015 and 2022, what mathematical operation should I do in order to translate from one to the other ?</p>\n<p>(If I do 23 000 * 30, it will not decrease the result, so it is not the good operation.)</p>\n<p>Figure 1 :</p>\n<p><a href=\"https://i.stack.imgur.com/SqdFg.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/SqdFg.png\" alt=\"enter image description here\" /></a></p>\n<p>Figure 2 :</p>\n<p><a href=\"https://i.stack.imgur.com/hikS6.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/hikS6.png\" alt=\"enter image description here\" /></a></p>\n", "pids": ["633d8c9d90e50fcafd71c72c"], "flag": 1}
{"question": "Does the genetic material the sperm carries affect its physical properties", "body": "<p>Basically, what I'm asking is, is the actual sperm cell built from the blueprint in the DNA of the man or is it itself also a consequence of the DNA it carries?</p>\n\n<p>I'd like to know a few more things related to this. For example, which DNA is in the nucleus of a sperm? Is it the same as the DNA of other bodily cells in the man's body, or is it just the DNA it's delivering? Can the sperm's performance be affected by any specific genetic traits that can be observed in a potential human the sperm could make? For example, a sperm swims faster if it's carrying the genetic material that would result in a tall person (probably a silly question).</p>\n\n<p>The original question I had is if the statement that female sperm live longer is true. If it turns out that the man's body makes all the sperm more or less the same and they're just boxes that can swim, then I would guess the answer is no.</p>\n", "pids": ["55a65a1a65ce054aad6509c3"], "flag": 1}
{"question": "How 2 lasers interacting causes a dot of light", "body": "<p>Take a loom at this diagram\n<a href=\"https://i.stack.imgur.com/ANglD.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/ANglD.jpg\" alt=\"enter image description here\" /></a></p>\n<p>You have probably heard of this before but im just curious what laser they are using to do this. They do t appear to be ionizing air. It seems the one laser is just for color on the particle but what is the other? I would like to try this at home and make a dot for fun but i dont quite understand whats going on here. Any ideas?</p>\n", "pids": ["5c0f7657da562944ac6f33b0"], "flag": 1}
{"question": "Ansys Norton creep power law constants?", "body": "<p>I’m trying to learn creep analysis in Ansys, and am currently working on deriving creep constants, specifically C1, C2, and C3 for the Norton Power Law.</p>\n<p>I understand that the equation is usually shown in 2 ways:</p>\n<p><span class=\"math-container\">$$\\dot\\epsilon = A \\sigma^n t^m$$</span></p>\n<p>or</p>\n<p><span class=\"math-container\">$$\\dot\\epsilon = A \\sigma^n \\exp\\left(-\\dfrac{Q}{RT}\\right)$$</span></p>\n<p>Which form does Ansys use? I can’t seem to find an answer in any of the manuals or anywhere online.</p>\n<p>For example, I know solid works uses the first form, where <span class=\"math-container\">$C_1 = A$</span>, <span class=\"math-container\">$C_2 = n$</span>, and <span class=\"math-container\">$C_3 = m$</span>.</p>\n", "pids": ["56d881f2dabfae2eee6edd96"], "flag": 1}
{"question": "Is is possible to &quot;delete&quot; a memory permanently?", "body": "<p>If cognitive memory is compared to computer memory, then is it possible to purposefully and permanently forget a specific memory, using known technologies and methodologies?</p>\n", "pids": ["5c757e2bf56def9798b5f63d", "5ea014229fced0a24b9f6efc", "5c51029de1cd8eb0c958a7af"], "flag": 1}
{"question": "Emotional energy exchange between bodies?", "body": "<p>I'm not sure on which platform to ask this question:</p>\n\n<p>Is it possible to exchange emotional energy between two bodies via acts of goodwill? Two examples of acts of goodwill are: Help someone with their groceries, and buy someone a thoughtful gift. Is it possible that in these examples, both bodies gain emotional energy, which both bodies can store and then have the ability to dispatch subsequently to other bodies?</p>\n\n<p>Science has proven that doing an act of goodwill for someone else benefits both parties.</p>\n\n<p>So what if the human network stopped doing acts of goodwill? Would the network suffer in some way? For example, I do know that babies die if they are not held. What if all bodies in the network lost the ability to do acts of goodwill to another? </p>\n\n<p>Would all the babies die? </p>\n\n<p>If so, that would be very dangerous to society, because we would all go extinct. So shouldn't we be looking into this?</p>\n\n<blockquote>\n  <p>Thanks to the late great David Hawkins, MD, Ph.D., we have proof that emotions have measurable energy and can either foster or negate actual cell life. Dr. Hawkins’s groundbreaking work, as explained in his book Power vs. Force, shows how a person’s log level--the measurable energy level in their magnetic field--increases as that person experiences more positive emotions. Hawkins’s most interesting finding was that cells actually died when the log level was below 200, where the emotions of scorn, hate, anxiety, shame, regret, despair, blame, and humiliation reside. So it’s key to regulate and manage our emotional state, not just for our overall well-being (and that of those around us) but also for our physical health.</p>\n</blockquote>\n\n<p><a href=\"https://www.forbes.com/sites/christinecomaford/2018/06/02/emotions-have-energy-what-energy-are-you-sending/#579d0b512545\" rel=\"nofollow noreferrer\">https://www.forbes.com/sites/christinecomaford/2018/06/02/emotions-have-energy-what-energy-are-you-sending/#579d0b512545</a></p>\n", "pids": ["55a4151e65ce5cd7b3c38bcd"], "flag": 1}
{"question": "Looking for a paper: AI in human host", "body": "<p>I am searching for a paper where participants were confronted with a (female) person, who gave answers according to a computer algorithm. She had an earpiece that gave her the answers and was trained to simultaneously listen and speak.</p>\n\n<p>Some participants thought that she was acting a bit off, but none recognized that they are talking to a computer. I think the aim of the study was some sort of turing test. </p>\n\n<p>Hope anyone can help me find it. I don't know how to look for it anymore...</p>\n", "pids": ["56d831abdabfae2eee266995"], "flag": 1}
{"question": "Does any animal species have two sexes and more genders?", "body": "<p>Are there any animal species that have two sexes and a kind of different internal diversification in two genders or more? I don't mean something like different-task-based diversity, but something biological? \nFor example let's imagine a species with:</p>\n\n<ul>\n<li>2 sexes (male and female)</li>\n<li>2 gender (A and B)</li>\n</ul>\n\n<p>and individuals can match iff they are not only of different sex but also of different gender.\nSo you can only have Ma-Fb, Mb-Fa.</p>\n", "pids": ["5fd560148cdecd4daa153b75"], "flag": 1}
{"question": "Why aren&#39;t pneumatic/hydraulic artificial muscle actuated humanoid robots more common?", "body": "<p>I'm designing a humanoid robot using pneumatic artificial muscles. I chose these actuator units because</p>\n<ul>\n<li>they're much cheaper than electric motors of comparable power output capability.</li>\n<li>instead of needing a high power darlington mosfet array for each motor, only one is needed for the prime movers. Small servo motors individually control the pneumatic valves</li>\n<li>modern deep learning architectures can &quot;learn&quot; optimal control policies that give reasonable precision</li>\n<li>pneumatics are way easier to scale to hundreds of muscles than electric motors</li>\n<li>many pneumatic components can be prototyped with only a 3d printer; custom motor design is graduate school stuff</li>\n<li>hydraulic fluid (like water) can be used for muscles requiring high stiffness (like fingers)</li>\n</ul>\n<p>I'm having a hard time looking past these advantages. Most of the DIY humanoid robot designs I see involve big expensive motors, speed controller, and complex mechanical contraptions. Why haven't cheap (like &lt;$1k) humanoid robots already been commercialized using pneumatic artificial muscles?</p>\n", "pids": ["60cb26f7e4510cd7c83ac507"], "flag": 1}
{"question": "What is the original source of the common Ziegler-Nichols PID tuning coefficients?", "body": "<p>In many places, including but not limited to <a href=\"https://en.wikipedia.org/wiki/PID_controller#Ziegler%E2%80%93Nichols_method\" rel=\"nofollow noreferrer\">the Wikipedia page about PID controllers</a>, I see the following PID coefficients: <span class=\"math-container\">$K_P = 0.6K_U$</span>, <span class=\"math-container\">$K_I = 1.2 K_U / T_U$</span>, and <span class=\"math-container\">$K_D = 0.075 K_UT_U$</span>. When were these constants first introduced? The sources point to the papers  <em><a href=\"http://davidr.no/iiav3017/papers/Ziegler_Nichols_%201942.pdf\" rel=\"nofollow noreferrer\">Optimum Settings for Automatic Controllers</a></em> and <em>Rule-Based Autotuning Based on Frequency Domain Identification</em>, but I cannot find these values there.</p>\n<p>Table I in the second mentioned paper introduces <span class=\"math-container\">$K_C = 0.6K_U$</span>, <span class=\"math-container\">$T_i = 0.5T_U$</span>, and <span class=\"math-container\">$T_D = 0.125T_U$</span>, but I do not understand what those coefficients mean and how I go to <span class=\"math-container\">$K_P$</span>, <span class=\"math-container\">$K_I$</span>, and <span class=\"math-container\">$K_D$</span> from there.</p>\n", "pids": ["558a6bd6e4b0b32fcb36b5f0"], "flag": 1}
{"question": "Can we really &#39;discover&#39; 85% of mammalian viruses?", "body": "<p>This virology <a href=\"http://www.virology.ws/2013/09/06/how-many-viruses-on-earth/\" rel=\"nofollow\">[blog]</a> discusses estimates of the number of mammalian viruses and the costs of 'discovering' 85% of them. </p>\n\n<p>My question is whether this is not a forlorn hope. The \".632 rule\" in statistics says roughly that as we approach n random samples from a large population of size n we will see only about 62.3 per cent of the population. After a point we would begin to see the same viruses again and again. This argument is probably stronger with respect to marine viruses, as they may be even more numerous and sampling at depths could be difficult. </p>\n\n<p>I wonder if someone with experience sampling small organisms from large populations or familiarity with the literature has an idea about the plausibility of seeing 85% of a large population, such as mammalian viruses, by sampling? </p>\n\n<p>If the samples are really random (in some sense) and the population is large, a few computer simulations reveal the power of this rule of thumb.    </p>\n\n<p><strong>Edit in response to comment/question:</strong> </p>\n\n<p>Like any such estimate, the blog's estimate of 3.6 million is a guess. I am not reproducing the calculation here because it's just speculation.</p>\n\n<p>Having said that, if 3.6 million were correct, we would have to draw about 6.8 million samples to find 85% of the existing viruses, 8.2 million to find 90%, and so on. As the blog notes, the PCR approach detects viruses similar to those we know, so the sampling is worse than random. If we look at the difficulty of finding/using a method that has a reasonable chance of capturing any of the extant viruses, the number 3.6 million looks very big. </p>\n", "pids": ["55a4607965ce31bc8778b0d3"], "flag": 1}
{"question": "Origin of the 260/280 ratio?", "body": "<p>This is not a duplicate of all the other 260/280 ratio questions, I already know that DNA is supposed to be 1.8 and RNA is supposed to be 2.0. However, this might be more appropriate for chemistry, and will move it if I have to.</p>\n\n<p>My question has to do with the Poly A tails on mRNA. I've been doing in vitro transcription and tailing for a while now and have noticed that the untailed RNA has a 260/280 of about 2.0, like you'd expect, but successful tailing results in ratios from 2.15 to 2.45, with higher ratios correlating to better band shifts on agarose gels, implying a longer tail. I suspect the reason for this is because the adenine has a much higher 260/280 than the other bases, so if you add a lot of adenines to the 3' end of the RNA you add much more 260 absorbance than 280 absorbance.</p>\n\n<p>After seeing this I tried to come up with a mathematical method to estimate tail length based on 260/280, since gels are annoying, while I can get the ratio directly from the nanodrop.</p>\n\n<p>I started by using the 260/280 for each nucleotide, A: 4.50, G: 1.15, C: 1.51, U: 4.00, T: 1.47 source here: <a href=\"http://www.bio.davidson.edu/projects/gcat/protocols/NanoDrop_tip.pdf\" rel=\"noreferrer\">1</a>. I then took the sequence for the Luciferase gene I'm using for mRNA and counted the nucleotides, 449 A, 566 C, 470 G, 374 U. I tried to get the weighted average of the 260/280 for my RNA. </p>\n\n<pre><code>A: 449 x 4.50 = 2020.50\nC: 566 x 1.51 =  854.60\nG: 470 x 1.15 =  540.50\nU: 374 x 4.00 = 1496.00\nSum:            4911.60\n\nNucleotides: 449 + 566 + 470 + 374 = 1859\nSum / Nucleotides : 4911.60 / 1859 = 2.64\n</code></pre>\n\n<p>2.64 is clearly not 2.0. Even accounting for the potential effect of pH and ionic strength on RNA 260/280 ( acidic solutions have lower ratios ) I can't explain why the calculated ratio is so high. Even if we assumed an RNA with 25% of each base, the weighted average is still (1.15 + 4.50 + 1.51 + 4.00)/4 = 2.79, even higher than for my real sequence.</p>\n\n<p>Doing the same calculation for DNA, (1.15 + 4.50 + 1.51 + 1.47)/4 = 2.16.</p>\n\n<p>So why don't my calculated ratios for RNA and DNA 260/280 match the \"ideal\" ratios of 2.0 and 1.8?</p>\n", "pids": ["55a3bc33612ca6486876ffe1"], "flag": 1}
{"question": "What standards or industry guidance define a top temperature for human contact to surfaces?", "body": "<p>I'm looking for guidance to define how hot is too hot when related to human safety.  I have heard of a general limit from OSAH of 60 °C (140 °F) being ok for contact up to 5 sec.  Are there better sources for defining this limit for different temperatures and time limits?</p>\n", "pids": ["5c756e6af56def97985c9ad9"], "flag": 1}
{"question": "Is internal friction angle isotropic in soil?", "body": "<p>I am studying geotechnical engineering and specifically the chapter in B.M. Das book of the same name, 6th edition.</p>\n<p>On the topic of shear forces, reference to internal friction angle, <span class=\"math-container\">$\\phi$</span> is made. My understanding is that the friction angle is the angle in a right triangle with legs of magnitude <span class=\"math-container\">$F_N$</span>,force normal to a specific plane, and <span class=\"math-container\">$\\mu F_N$</span>, the friction force parallel with the plane, where <span class=\"math-container\">$tan(\\phi)=\\frac{F_N \\mu }{F_N}=\\mu$</span>.</p>\n<p>My question is if <span class=\"math-container\">$\\phi$</span> is constant for all planes in a specific soil, i.e. isotropic, or can it be anisotropic?</p>\n<p>Further, is the answer the same for rocks and minerals?</p>\n", "pids": ["5c756c71f56def979848a70f"], "flag": 1}
{"question": "How does heat shock transformation work?", "body": "<p>What exactly happens when competent cells like DH5ɑ are heatshocked with DNA present? How does the DNA get inside the cells?</p>\n\n<p>Specifically, why are all the steps necessary? What if you heatshock right after adding DNA? What if you don't put on ice after heatshock? What does the calcium chloride do? What actually happens when cells are \"competent\"? What governs transformation efficiency (besides obvious things like amount of DNA or cells)?</p>\n\n<p>To make it clear what I'm talking about, I use a protocol like the following:</p>\n\n<ol>\n<li>Take cells out of -80C and thaw on ice for 5 min.</li>\n<li>Add 1 ul (~500 ng) plasmid DNA to 50 ul cells, mix gently with pipette tip.</li>\n<li>Leave on ice for 30 min.</li>\n<li>Put in 42C water bath for 45 sec.</li>\n<li>Put on ice for 10 min.</li>\n<li>Add 950 ul LB, put in 37C for 1 hour.</li>\n<li>Spread 300 ul of the culture on LB-agar plates with appropriate selection.</li>\n</ol>\n\n<p>I usually get thousands of colonies from this (in fact, often 1:10 or 1:100 dilution is necessary so I can actually get isolated colonies). Even if I skip the outgrowth, I still get hundreds. </p>\n\n<p>I don't have my competent cell protocol, but basically I use that one rubidium chloride that everyone uses: DH5ɑ cells are washed with some buffers, suspended in a solution with CaCl2 and RbCl, then frozen in liquid nitrogen. I never actually measured, but usually the concentration of cells in the frozen aliquots is about 10 times as many as you would get from an overnight liquid culture (they are spun down and resuspended in a small volume).</p>\n", "pids": ["55a49d06c91bf3b1cc4072da"], "flag": 1}
{"question": "What is the evolutionary advantage of being embarrassed?", "body": "<p>What I am trying to understand is why do I feel embarrassed in certain situation. </p>\n\n<p>E.g. when I'm talking to people, why do I think about being judged or sounding stupid that would result me in embarrassment. I have been considered as \"intelligent\" since I was a kid and may be making or looking stupid goes against my own belief of me being 'intelligent'?</p>\n\n<p>Also, when I'm playing a game or playing music, I think about embarrassing myself, making mistakes and think what may the audience/team mates thinking about me? So I avoid it and when I actually get a chance of play, I make mistake and regret/punish myself mentally for making a mistake or regret quite a bit. So, basically, this results me in being low confident. </p>\n\n<p>I'm thinking about \"impressing people\" and me resulting in an embarrassing situation, acting stupid, sounding stupid would spoil my \"impression\". \nHowever, I want to act stupid or sound stupid sometime and be ok with it. \nSomehow my biology/mind prevents me every time and I feel the resistance. </p>\n\n<p>So, in search of understanding the reason, I wanted to ask if this has any evolutionary benefit or is it part of natural selection? E.g. having a better chances of survival, when you express less/ be quiet or shy, so that others are not threatened by you? </p>\n\n<p>Can anybody with more knowledge shed some light or possibly guide me to help my situation?</p>\n\n<p>Thanks for reading a long post!</p>\n", "pids": ["53e99998b7602d97021da242"], "flag": 1}
{"question": "Fixed-Free End Column Design", "body": "<p>I am currently working on a problem where I have to design a column. The structure I am currently designing currently takes the following form,</p>\n\n<p><a href=\"https://i.stack.imgur.com/Bn8Sl.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/Bn8Sl.png\" alt=\"enter image description here\"></a></p>\n\n<p>When designing the column, I know that I have to calculate what the maximum axial and bending stresses acting on the column are due to the horizontal beam. \nHowever, one thing I am unsure of is how do I calculate the bucking load/stress for the column? I'm not sure if I can treat the column as axially loaded due to the bending moment that is applied to it by the horizontal beam. Should I treat the load due to the beam as an eccentric load to account for the moment it applies on the column?</p>\n\n<p>Also, when designing the column, other than than calculating the axial stress, bending stress and the buckling stress, are there any other parameters that I should calculate?</p>\n\n<p>Thank you!</p>\n", "pids": ["5c90268b4895d9cbc676ab1e"], "flag": 1}
{"question": "How is intelligence in children measured?", "body": "<p>Intelligence is dependent on mental age and <a href=\"https://academic.oup.com/ije/article/39/5/1362/802787\" rel=\"nofollow noreferrer\">education</a>. So how can an IQ test be performed to check the mental/intellectual capabilities in children?</p>\n", "pids": ["53e9b8b4b7602d97044931b9", "53e99991b7602d97021d8757", "5f0c2f3f9fced0a24ba031c6", "53e99c92b7602d97025474f8"], "flag": 1}
{"question": "Why do different humans look different?", "body": "<p>Although farmers appear to be able to tell their cows apart, cows look very much alike to me. And this similarity in appearance seems to be a general trait across the animal kingdom: one individual of one animal species looks much like another.</p>\n\n<p><strong>Why do human facial and body shapes vary so much?</strong></p>\n\n<p>I understand that human beings live in many different environments (e.g. hot and cold) and have adapted to these (e.g. through lighter or darker skin color), but there seems to be much variation that has no apparent evolutionary purpose. So does the difference have a purpose in itself? That is, did we evlove to vary in appearance, and what is the purpose of this variation?</p>\n", "pids": ["55a6910265ce054aad6bf351"], "flag": 1}
{"question": "Ritalin for treating attention and lack of focus in depression", "body": "<p>I’d like to know if there’s research about the use of ritalin for treating attention deficit in Major Depression Disorder. </p>\n", "pids": ["56d8957fdabfae2eee0b7869", "5c75554af56def9798683173"], "flag": 1}
{"question": "How realistic is the &quot;death by CRT monitor&quot; scene from Final Destination?", "body": "<p>First of all, I realize that not only is this a fictional scene in a movie, but a movie (series) particularly infamous for its ridiculous, over-the-top death scenes.</p>\n<p>Yet, I <em>have</em> heard of basically this exact thing from other and very serious sources over the years: something about CRT TVs and CRT computer monitors spontaneously just cracking/exploding and shooting very lethal shards of glass all over, especially straight ahead, cutting through your skin and eyes and <em>at best</em> crippling you for life.</p>\n<p>The relevant part of the scene:</p>\n<blockquote>\n<p>Ms. Lewton pours ice-cold vodka into a previously hot mug, causing it to crack. She carries the mug across to the computer, as it leaves a trail of vodka on the floor, and when she leans over the computer, some drips into the the (CRT) monitor. She realizes that the monitor is smoking and goes to check it, only for it to explode, sending a shard of glass into her throat.</p>\n</blockquote>\n<p>Source (very poor video): <a href=\"https://www.youtube.com/watch?v=zZWCbJcw5ms\" rel=\"nofollow noreferrer\">https://www.youtube.com/watch?v=zZWCbJcw5ms</a></p>\n<p>Of course, I would never lean over any of my CRTs with any kind of liquid, for any reason, so it should not be possible to happen like in the described scene. Still, who knows what could happen? An opened water bottle accidentally flying across the room while the TV is on, etc. Or even no water/liquid at all; it might just explode &quot;spontaneously&quot; for all I know.</p>\n<p>Is this entirely nonsensical, and in reality, it would never explode in the sense that we imagine, unless perhaps you directly smash it with a huge sledgehammer?</p>\n<p>In particular, water entering the TV seems like it should at most cause it to die, or possibly catch fire, but why would it explode?</p>\n", "pids": ["558b613784ae84d265c30c2d", "53e99fd6b7602d97028b5048"], "flag": 1}
{"question": "Name of cognitive bias where people try to use all given information regardless of quality?", "body": "<p>In psych class, I recall learning about a cognitive bias where people are inclined to use all information available to them when making a decision, even if some of the information would be better ignored.</p>\n\n<p>I believe the example given was a study in which participants were asked to evaluate the (college?) application of a candidate. Some participants were given just the conventional application information, while others were additionally given irrelevant information in the form of a portfolio of the candidate's elementary school artwork. The finding was that the artwork influenced the participant's decisions when it was provided.</p>\n\n<p>What I don't remember is what this bias is called!</p>\n", "pids": ["53e9bcbab7602d9704938a21", "53e99cb5b7602d970256bef7"], "flag": 1}
{"question": "Is there any Sleep limit for a human body?", "body": "<p>Can we sleep throughout our whole life if we are supplied the necessary things like food,water etc.</p>\n", "pids": ["55a698b865ce054aad6d23aa"], "flag": 1}
{"question": "Hebbian theory &quot;fire together&quot; clarification", "body": "<p>Donald Hebb states it as follows:</p>\n\n<blockquote>\n  <p>\"Let us assume that the persistence or repetition of a reverberatory activity (or \"trace\") tends to induce lasting cellular changes that add to its stability.… When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A's efficiency, as one of the cells firing B, is increased.\"\n  <em>Or we can conclude in short: \"Neurons that fire together, wire together\".</em></p>\n</blockquote>\n\n<p>As I understand it, this means that synapses that already exist become stronger between neurons.</p>\n\n<ol>\n<li>Could new synapses form between neighboring neurons that \"fire together\", but are not necessarily directly connected through an axon?</li>\n<li>And if so, what is the mechanism to direct the new synapse formation towards that other neighboring neuron that \"fires together\"?</li>\n</ol>\n", "pids": ["53e99da4b7602d970266451b", "53e9aad2b7602d9703450f41"], "flag": 1}
{"question": "Is there a mindfulness meditation technique that tends to produce gamma rhythms in the brain (and not just the alpha frequencies that are typical)?", "body": "<p>This is a follow up to a <a href=\"https://christofkoch.files.wordpress.com/2013/12/cr-brain-buddha-13.pdf\" rel=\"nofollow noreferrer\">paper</a> (^) that was cited in a <a href=\"https://psychology.stackexchange.com/a/19829/3379\">response</a> to one of my past questions here. It was found that <strong>experienced Buddhist monks generate a substantial increase in gamma</strong> waves on demand during their meditation, while novices don't.  </p>\n\n<p><a href=\"https://www.sovhealth.com/mental-health/mindfulness-meditation-alters-brain-waves-produces-peace-mind/\" rel=\"nofollow noreferrer\">This</a> website cites a <a href=\"https://doi.org/10.3389/fnhum.2013.00012\" rel=\"nofollow noreferrer\">study</a> (*) that found that <strong>mindfulness meditation causes an increase in alpha waves in subjects</strong>.  </p>\n\n<p>I'm therefore wondering if there is something that the Buddhist monks are doing differently. <strong>Is there a mindfulness meditation technique that tends to produce gamma rhythms in the brain (and not just the alpha frequencies that are typical during mindfulness practice)?</strong>  </p>\n\n<p>Perhaps gamma waves (in the orbitofrontal cortex and areas of the prefrontal cortex) are generated from simply a deeper focus. However, if that's the case, it's still not clear to me how one can attain this. What kind of techniques are likely to lead to this phenomenon? Is it more likely that a more open/wide focus (example cue: \"pay attention to all thoughts/feelings/sensations that appear in your mind and, if you get distracted, just come back to the meditation\") or narrow/sharp focus (example cue: \"pretend to receive a huge reward for focusing on your breath with high clarity and minimal distractions\") leads to gamma activity? Are there any other dimensions of mindfulness meditation that are relevant here?</p>\n\n<p>(^) The Brain of Buddha - Christof Koch<br>\n(*) <em>Mindfulness starts with the body: somatosensory attention and top-down modulation of cortical alpha rhythms in mindfulness meditation</em></p>\n", "pids": ["5ce2ca80ced107d4c6278568", "53e9ba8ab7602d97046b0d66", "53e9b5f3b7602d970414767c"], "flag": 1}
{"question": "Constraints on dataset size for AI-assisted connectome reconstruction", "body": "<p>From an exchange with <a href=\"http://seunglab.org/\" rel=\"nofollow noreferrer\">Dr. Seung</a>, an expert on connectomics, I learned that one of his former PhD students Viren Jain is leading the <a href=\"https://ai.google/research/teams/perception/connectomics/\" rel=\"nofollow noreferrer\">Connectomic effort at Google</a> using supervised learning methods. Now, supervised deep learning methods usually require large amounts of data to succeed. (I know this based on experience in industry as well as the deep learning literature.) However, due to the time and effort of human annotation the datasets for circuit reconstruction are really small: </p>\n\n<p><a href=\"https://i.stack.imgur.com/f2BZy.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/f2BZy.png\" alt=\"enter image description here\"></a></p>\n\n<p><em><a href=\"https://science.eyewire.org/science-artificial-intelligence.html\" rel=\"nofollow noreferrer\">It takes about six months for humans to annotate 1 cubic millimeter of brain volume.</a></em> </p>\n\n<p>In fact, Dr. Seung informed me that the <a href=\"https://cremi.org/data/\" rel=\"nofollow noreferrer\">following dataset</a> from a circuit reconstruction competition in 2016 which is less than five gigabytes in total is basically state of the art. </p>\n\n<p>Given that <a href=\"https://arxiv.org/abs/1712.04621\" rel=\"nofollow noreferrer\">augmenting training data with synthetic data</a> is frequently used for computer vision problems, I am led to the following questions: </p>\n\n<ol>\n<li>Might it theoretically be possible to augment human-annotated training data with morphologically similar synthetic data? </li>\n<li>What methods in the near future might allow us to significantly increase the size of human-annotated training data?</li>\n</ol>\n\n<h2>References:</h2>\n\n<ol>\n<li>Michał Januszewski, Jörgen Kornfeld, Peter H. Li, Art Pope, Tim Blakely, Larry Lindsey, Jeremy Maitin-Shepard, Mike Tyka, Winfried Denk &amp; Viren Jain. High-precision automated reconstruction of neurons with flood-filling networks. Nature. 2018. </li>\n<li>Luis Perez and Jason Wang. The Effectiveness of Data Augmentation in Image Classification using Deep Learning. Arxiv. 2017. </li>\n<li>Alberto Bailoni, Constantin Pape, Steffen Wolf, Thorsten Beier, Anna Kreshuk, Fred A. Hamprecht. A Generalized Framework for Agglomerative Clustering of Signed Graphs applied to Instance Segmentation. Arxiv. 2019.</li>\n<li>EyeWire: mapping neurons. <a href=\"https://science.eyewire.org/science-mapping-neurons\" rel=\"nofollow noreferrer\">https://science.eyewire.org/science-mapping-neurons</a> Accessed 21 August 2019. </li>\n</ol>\n", "pids": ["5ce2d24cced107d4c64c1de8", "5c136b72da56295a08a73a0e"], "flag": 1}
{"question": "How happy are people relative to neutral (as measured by experience sampling)?", "body": "<p>Most studies on <a href=\"https://en.wikipedia.org/wiki/Experience_sampling_method\" rel=\"nofollow noreferrer\">experience sampling</a> are about whether some activity correlates with increased or decreased happiness/subjective well-being. However, it's often hard to tell from these studies what number corresponds a neutral point, where someone is neither unhappy or happy (or equally so), or is feeling an valence/affect equivalent to a nonconscious state. For instance <em><a href=\"https://books.google.com/books?hl=en&amp;lr=&amp;id=05e5d_KBYY0C&amp;oi=fnd&amp;pg=PP13&amp;dq=experience+sampling&amp;ots=rtKOM3tmc0&amp;sig=GJp6aaU09aJXINg_91LAHeC_s7c#v=onepage&amp;q&amp;f=false\" rel=\"nofollow noreferrer\">Experience Sampling Method: Measuring the Quality of Everyday Life</a></em> (2007) shows its results in terms of z-scores, which are defined relative to some average, but it's unclear whether that average would be higher or lower than a neutral point. As such, while we can say that these people are happier in this situation than another, it's hard to see whether they're overall happy or unhappy in that situation.</p>\n\n<p>I'm not particularly interested in what activities or age or gender correlates with happiness, but just how happy people are relative to some clearly defined neutral point. Ideally, the study wouldn't just show some average among all study participants across all their experiences, but also what percentile corresponds to what happiness ratings, and the range of happiness scores and the frequency of different happiness ratings for each person. Is there a study that addresses this topic?</p>\n", "pids": ["5c0f7bf2da562944ac7c32b2", "5c0f7bf2da562944ac7c32b2"], "flag": 1}
{"question": "How accurate are diagnoses on Autism to Children under 3 years old?", "body": "<p>I have a son with autism. He was diagnosed under 3 years old. 2 years old to be exactly. After I doubted several pediatricians that claimed that wouldn't be a valid diagnose after 5 years old. I discovered by myself that it wasn't entirely true. I've read that specialists would diagnose under 2, or even, babies. I want to know because other parents say their doctors say to wait from 2 to 3 years old or even more. </p>\n", "pids": ["5c185944dfae54832c9865f5", "55a4b26d65ceb7cb02d6748c", "5affc51fa2e6b1328d55c797", "55a42120612ca6486887adb2"], "flag": 1}
{"question": "Superconductor Magnetic Field Limit", "body": "<p>Not sure if this is a question for the engineering or physics stack exchange:</p>\n<p>The current maximum magnetic field for a nonpulsed magnetic field is around 45 Tesla while pulsed is around 100 Tesla. I'm assuming the primary reason for the limitation is that the coils overheat (from additional current being added) but how come superconductors also seem to have this limitation if they have no resistance and therefore emit no heat? Thanks!</p>\n", "pids": ["53e99bd5b7602d970247f689", "53e9be15b7602d9704ad11e9", "5d041b0e3a55acfcafefaf0b", "56d9172adabfae2eee61436e"], "flag": 1}
{"question": "Situation Awareness - what is it good for?", "body": "<p>I was looking into Situation Awareness (SA), but have problems understanding its general use. I am aware of the work by Mica Endsley and a few others. <a href=\"https://aviation.stackexchange.com/questions/44771/what-is-situational-awareness-and-why-is-it-important/44772#44772\">This question</a> is related, but I find the answer not satisfying. </p>\n\n<p>My current understanding is this: if I know everything I need to know to achieve some goal, then I am situation-aware. In that case, I would need SA for <em>everything</em> I do. Is that correct?</p>\n\n<p>More specifically: what does Situation Awareness allow me to do that I couldn't do without it?</p>\n", "pids": ["555042bb45ce0a409eb4457c"], "flag": 1}
{"question": "Reliable channel or method for self-study of Psychology", "body": "<p>Out of interest, I've been reading some psychology topics online recently (I have zero background in psychology). For example, Maslow theory in depth. On and off, I come across terms that sound like having same meaning. So I need to search their explanation, in order to learn their differences, if any. More and more often, I run into situation where different psychology related websites giving slightly different explanation, or sometimes, even conflicting explanation. So, I'm often confused and unable to determine which explanation is the right one. </p>\n\n<p>Is there a de-facto reliable source to learn psychology (except attending school), where knowledge and explanation given are considered as truth? Or... is the field of Psychology itself still full of ambiguity nowadays?</p>\n\n<p>--- update 4/19 (summary)</p>\n\n<p>My study approach is by keep searching and reading from multiple websites until I reach a point where I feel somewhat confident to take a guess. All along I've been uncomfortable with this approach because I find it not as productive as I wish, and the outcome may not reflect the truth.</p>\n\n<p>My understanding from input of @AliceD and @Chris Rogers is that, it seems that to learn psychology in informal way for non-pro purpose (in my case, for personal growth, to understand myself better), this is the logical and viable way, even though it is not as intuitive as I've been hoping. And for those who suspect they have mental health problem, the best is to reach out to registered mental health professional for help.</p>\n", "pids": ["53e9a8dbb7602d970322b6c0"], "flag": 1}
{"question": "How widespread is learned-helplessness in society?", "body": "<p>Looking at these resources:</p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Learned_helplessness\" rel=\"nofollow noreferrer\" title=\"Learned helplessness - Wikipedia\">Wikipedia, Learned helplessness</a></li>\n<li><a href=\"https://onlinelibrary.wiley.com/doi/epdf/10.1002/9780470479216.corpsy0500\" rel=\"nofollow noreferrer\" title=\"Learned Helplessness - Peterson - - Major Reference Works - Wiley Online Library\">Christopher Peterson, Learned Helplessness, 2010</a></li>\n<li><a href=\"https://books.google.com.vn/books?hl=en&amp;lr=&amp;id=BSz5BwAAQBAJ&amp;oi=fnd&amp;pg=PA1&amp;dq=learned+helplessness+&amp;ots=1wyov6f1To&amp;sig=qn4sJFj6GKQS27nr9GlMCcnfa4o&amp;redir_esc=y#v=onepage&amp;q=learned%20helplessness&amp;f=false\" rel=\"nofollow noreferrer\" title=\"Human Learned Helplessness: A Coping Perspective - Mario Mikulincer - Google Books\">Mario Mikulincer, Human Learned Helplessness: A Coping Perspective, 2013</a></li>\n</ul>\n<p>I'm still unable to find how widespread learned helplessness is in society. Do you know where I should take a look?</p>\n", "pids": ["55a5e7e2612c6b12ab313f67"], "flag": 1}
{"question": "What is the condition called when someone believes that robots should be treated as though they are human?", "body": "<p>There is a movement calling for the \"humanitarian treatment of robots\" where robots must not be \"sexually molested\", must be spoken to with kind words and be treated, generally, like sensitive humans. This is likely because people are incapable of separating human from robot when they look at a robot made up to look human.</p>\n\n<p>This question came up when there was a video of Boston Dynamics engineers shoving a robot and knocking it over went viral.</p>\n\n<p>What is this condition where this inability to separate the two manifests? Perhaps the bonus question is: What is the phobia called where one fears that these groups will gain enough momentum to make it law?</p>\n", "pids": ["5ce2d175ced107d4c642e554", "619b5e951c45e57ce94397de"], "flag": 1}
{"question": "Anxiety vs Stressfulness in the Big Five?", "body": "<p>From these sources (<a href=\"https://cloud.ibm.com/docs/personality-insights?topic=personality-insights-agreeableness\" rel=\"nofollow noreferrer\">1</a>, <a href=\"http://www.timothy-judge.com/documents/2013-31562-001.pdf\" rel=\"nofollow noreferrer\">2</a>, <a href=\"http://www.testsonthenet.com/Factors-facets.htm\" rel=\"nofollow noreferrer\">3</a>) I have figured out that anxiety and stressfulness are generally defined as:</p>\n\n<ul>\n<li><strong>Anxiety</strong> - Prone to have generalized anxiety, panic, specific phobias, worry as well as feeling tension, nerviousness.</li>\n<li><strong>Stressfulness</strong> - Feeling helpless, overwhelmed under stress, pressure or when facing emergency situations.</li>\n</ul>\n\n<p>But isn't feeling helpless and overwhelmed cause you to feel anxious? And isn't feeling of helplessness and overwhelmed basically comes from anxiety? When I feel overwhelmed, it basically means that I am very anxious at the moment.</p>\n\n<p>Another definition (<a href=\"https://www.youtube.com/watch?v=k08aJYvRTCU\" rel=\"nofollow noreferrer\">4</a>) might be that stressfulness is a proclivity to feeling panic. But isn't panic is just a final stage of being anxious?</p>\n\n<p>What is the difference between <strong>anxiety</strong> and <strong>stressfulness</strong>?</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 1}
{"question": "Why does the Elaboration Likelihood Model not account for truthfulness of the message?", "body": "<p>This is a sample problem with the answer I am stuck on:</p>\n\n<blockquote>\n  <p><strong>Question:</strong> According to the elaboration likelihood model, which of the following does NOT predict whether a message will be persuasive?</p>\n  \n  <p>A.  The length of the message<br>\n   B.  The attractiveness of the person delivering the message<br>\n   C. The truthfulness of the message<br>\n   D.  The trustworthiness of the person delivering the message</p>\n  \n  <p><strong>Answer:</strong> The correct answer is C. According to the elaboration likelihood model, the truthfulness of the message itself is not actually a characteristic used to determine whether a message will be persuasive (choice C is correct). The message characteristics (including length) do predict persuasiveness (choice A is wrong), as do the source characteristics (including the attractiveness and the trustworthiness of the person delivering the message; choices B and D are wrong).</p>\n</blockquote>\n\n<p>Wouldn't the truthfulness of the message still be a factor, since it is a characteristic of the message itself (via the central route with message characteristics)? I get why the other answers are wrong. I don't get why C is correct.</p>\n", "pids": ["56d91e0fdabfae2eee8c2539"], "flag": 1}
{"question": "Looking for a source for Valence/Arousal values Russell&#39;s advance circumplex model of emotion?", "body": "<p>I've been looking for a chart/table of Valence and Arousal values from the advanced Russell's model such as the one referenced in this article <a href=\"https://www.researchgate.net/publication/50805681_Asymmetrical_Facial_Expressions_based_on_an_Advanced_Interpretation_of_Two-dimensional_Russells_Emotional_Model\" rel=\"nofollow noreferrer\">https://www.researchgate.net/publication/50805681_Asymmetrical_Facial_Expressions_based_on_an_Advanced_Interpretation_of_Two-dimensional_Russells_Emotional_Model</a></p>\n\n<p>I'm unable to find anything that isn't a picture, and what I'm really looking for is a table/spreadsheet with the emotions and the valence/arousal values for each emotion.</p>\n\n<p>Is there a source for this that I can reference?</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 1}
{"question": "Revenge attitude: is it innate or acquired in human", "body": "<p>I am trying to understand what is the root cause for revenge? I understand anger is caused by the gap between expectation/anticipation and the reality. But as to revenge, I am not satisfied just with identity related or social order maintenance or reciprocity. While resources pointing to the direction of getting started, any valuable input, views, opinions and research outcomes would be very much helpful.</p>\n", "pids": ["5c31f2e93a55ac7f9317fc64"], "flag": 1}
{"question": "Predicting the individual effects of psychotropic drugs", "body": "<p><a href=\"https://www.ncbi.nlm.nih.gov/m/pubmed/23796468/\" rel=\"nofollow noreferrer\">https://www.ncbi.nlm.nih.gov/m/pubmed/23796468/</a></p>\n\n<p>I have searched the national library of medicine but I could not find any papers about predicting both the therapeutic and adverse effects on the specific patient (individual) in front of us.</p>\n\n<p>People work on/ have an extremely similar chemistry (all cells do that was the phenomenon that the theory of evolution explained) but it is not identical (absolutely) across individuals otherwise we should predict drugs would have absolutely the same effects on all individuals.</p>\n\n<p>As drugs do have different effects across individuals the expectation of the effects should be different too. Because we now know that they have a similar but slightly non-homogeneous chemistry.</p>\n\n<p>How can we earnestly predict the effects, both therapeutic and adverse, of psychotropic drugs on the specific patient in front of us?</p>\n", "pids": ["5c0f9013da562944aca6c6d1", "5dd661ecdf1a9c0c41576666"], "flag": 1}
{"question": "How can I ask (or determine) if someone on the phone is human without offending them?", "body": "<p>I recently saw a doctor about a minor medical problem. This is the first time I saw this doctor . After the appointment I asked my doctor a follow-up question via my insurance company's website. I got a call back from the doctor but during the entire call I was distracted because all of the doctor's remarks sounded so dull and artificial. Also, he didn't seem to remember anything about me and just kept telling me to make a follow-up appointment with my doctor. I thought to myself that I might have been talking to an AI. That didn't seem too far-fetched to me with the recent advances in AI and doctors' busy schedules. During the entire call I was trying to determine if he was real and almost blurted out \"are you a real person??\". </p>\n\n<p>In hindsight, I think I was talking to a real person and he just has to deal with so many patients that he starts to talk like that. But I have started getting automated telemarketing calls that try to trick me into thinking a real person is talking to me. </p>\n\n<p>Is there a polite way to ask if someone is a real person? Or if there is a way to determine if I'm talking to a real person (sort of a reverse Turing test).</p>\n", "pids": ["573696066e3b12023e519c8b"], "flag": 1}
{"question": "A friend always talks in dry-professional language even though being very close to me for years", "body": "<p>It is strange that one of my close friends, who I know for years and have spent a lot of time in recreational activities, talks to me in very dry-professional language. It is a very minor thing, but it is kind of annoying me a little. For example, he would say &quot;I would prefer to ..&quot; rather than simply saying &quot;I want to ..&quot;. There is no language issue here, as he is fluent in English. We are not co-workers. Also, and he does not mirror me, because I don't talk in the professional language (even in professional settings).</p>\n<p>Plus, he has a habit of talking as if he is giving a presentation at a workplace of some sort. For example, even in casual conversations, he would often not show any emotions, try his best to be perfect with the facts, no loose sentences, lots of apologies. When asked a question, just to continue the conversation, a question that does not have a definite answer, he would just say &quot;I don't know&quot;, and close the conversation. For example, sometimes I try to have or continue the conversation by asking questions such as &quot;so are you feeling hungry&quot;, and he would answer &quot;I don't know&quot;. That would obviously be the end of that conversation.</p>\n<p>In general, I am not a big fan of talking in the dry-professional language, so I don't like when my close friend talks like that. We definitely have a much closer friendship than coworkers generally have. So I am not sure why he does that. He does not have many close friends, and as I have seen, talks like that with them too. The only exception is when he is drunk, then he talks casually, like a normal person. When undrunk, he seems to live like a professional of some sort all the time. We have been close friends for many years. Although I sometimes feel only I am actively in this friendship, so it is sort of a one-sided friendship. I tend to be as accommodating as possible and try to match the &quot;frequency&quot; with him. But sometimes it is very frustrating to be around him.</p>\n<p>I wonder if he has this persona because he tends to be deeply entrenched in his work and sort of an eccentric person. So far, I haven't confronted him to say that some of his behaviors are bothering me because I want to if I could find a subtle solution rather than putting him in the spot.</p>\n<p>I wonder if anybody has any suggestions regarding how to subtly</p>\n<ol>\n<li>encourage him to speak more casually</li>\n<li>better ways to respond to his 'I don't know' statements</li>\n</ol>\n", "pids": ["621899ec5aee126c0f328cee"], "flag": 1}
{"question": "For how long can a raven stay airborne (a week or more)?", "body": "<p>I'm wondering for how long a raven can stay continuously airborne, if strained to do so? If it makes a difference, I'm mostly interested in the Common raven, <em>Corvus corax</em>. Are there for instance any information on long-distance dispersal (wind-blown individuals over sea?) that can be used to roughly estimate this? Information on other corvid species could also be interesting, as a rough proxy.</p>\n\n<p>If you are wondering, my motivation for asking is the biblical story in Genesis 6&ndash;8 (the deluge of Noah). Here, Noah sends out a raven and a dove to look for land. From the story it appears as if the raven can stay airborne for a longer time than the dove, which returns to the ark to rest. Is there any realism in the claim that a raven can stay airborne for one or maybe even two weeks?</p>\n\n<p>Some background from Genesis 8 (<a href=\"http://en.wikipedia.org/wiki/The_Living_Torah_and_Nach\" rel=\"noreferrer\">this translation</a>):</p>\n\n<blockquote>\n  <p>After forty days, Noah opened the window he had made in the ark. He sent out the raven, and it departed. It went back and forth until the water had dried up from the land's surface. He then sent out the dove to see if the water had subsided from the land's surface. The dove could not find any place to rest its feet, and it returned to him, to the ark. There was still water over all the earth's surface. [Noah] stretched out his hand, and brought it to him in the ark. He waited another seven days, and once again sent the dove out from the ark. The dove returned to him toward evening, and there was a freshly-plucked olive leaf in its beak. Noah then knew that the water had subsided from the earth. He waited yet another seven days and sent out the dove [again]. This time it did not return to him any more.</p>\n</blockquote>\n\n<p>So the raven couldn't find a place to land, and it flew around until it could do so. A week later, the dove still couldn't find a place to land, but a week later it could. Thus, either (a)&nbsp;the raven was flying around for more than a week (as much as two weeks) or (b)&nbsp;the raven could more readily land in a wet area than the dove. Can either of these be true?</p>\n", "pids": ["55a5d4be65ce60f99bf6ab65", "5c0f7338da562944ac68349e"], "flag": 1}
{"question": "What is the basis of the belief that modern psychology demonstrates that words themselves can be hurtful and verbal aggression should be wed out?", "body": "<p>I'm sorry for the length of this question, but to ask it I'll need to refer to two concepts.</p>\n\n<p>Firstly, we see the escalating trend to weed out any and all examples of even very minor negativity or aggression in words. Those are deemed unacceptable, addressees of such messages may be called 'victims', and telling people to 'grow a thicker skin' is explicitly declared a non-solution to the problem. Examples of this are many: StackExchange's new Code of Conduct, strict rules of communication Riot Games is trying to enforce in League of Legends, punishing people for jokes, firing employees for not being nice enough to their colleagues, etc etc.</p>\n\n<p>It is claimed that such policies are backed up by modern psychology:</p>\n\n<blockquote>\n  <p>One major mistake in this reasoning is \"unlike with sticks and stones, with words the addressees have the choice: to accept the message or to drop it\". They do not, the message will be received and the emotional reaction will happen, emotions are not subject to conscious control. One can choose to \"get over it\", but the same can be said of sticks and stones, so the real issue is the damage assessment. One reason for the new consensus is the undermining of folk misconceptions that heavily weigh physical damage over emotional one (as in the saying) by modern psychology.</p>\n</blockquote>\n\n<p>-- <a href=\"https://philosophy.stackexchange.com/questions/55866/what-is-the-basis-of-the-belief-that-words-themselves-can-be-hurtful-and-verbal?noredirect=1#comment150979_55866\">@Conifold</a></p>\n\n<blockquote>\n  <p>Humans are social creatures. If a grief stricken person can be consoled by words and interactions. Why would you not expect the opposite to be equally effective that is turning a happy person depressed and mentelly unwell? To say that people should just \"ignore it\" is to assign all blame to the victim but that's not fair and ignores everything we know about human behaviour.</p>\n</blockquote>\n\n<p>-- <a href=\"https://philosophy.stackexchange.com/questions/55866/what-is-the-basis-of-the-belief-that-words-themselves-can-be-hurtful-and-verbal?noredirect=1#comment150983_55866\">@Cell</a></p>\n\n<p>Here I have to jump for a short while to the second concept... Monika and Marcin Gajda, in their book \"Rozwój. Jak współpracować z łaską\" (which is a Polish book on self-development that claims to be based on psychology and is written from an extensive Christian angle) introduces the concept of \"emotional sovereignty\". It distinguishes five levels of this sovereignty:</p>\n\n<ol>\n<li><strong>Submission.</strong> For example, if a bum insults me, I'll have the rest of my day screwed because I'll think how useless I must be that even a bum holds me in contempt.</li>\n<li><strong>Entering a symmetrical conflict.</strong> Here I'll insult back the bum or even start physically fighting him to defend my good name.</li>\n<li><strong>Ignoring aggressively.</strong> Here, feeling superior to the bum, I'll walk away, maybe mumbling something silently to myself.</li>\n<li><strong>Assertiveness.</strong> As described by modern psychology.</li>\n<li><strong>Merciful love.</strong> Told you the book is written with an extensive Christian angle. Here, with no contempt, feelings of superiority, aggression, urges of vengeance, or anything of this sort on my side, I'll look at the bum with compassion, seeing how miserable he must be to behave that way.</li>\n</ol>\n\n<p>The book claims that people can - and should - work themselves from the lower levels to the higher levels, for their own good. Staying on the lower levels is harmful, also from the psychological point of view, for the people who stay there. Also the book claims that a person may be on different levels in relation to different people: for example, a person may be on the 5th level with regard to this exemplary 'bum', but on the lowest level with regard to one's own mother. (Important: This self-development is not supposed to include trying to control one's own emotions).</p>\n\n<p>And here is where the two concepts meet, at least in my mind. If such 'abusive' words and messages are treated as 'big deal', if growing a thicker skin is not to be advised, if, having received such messages, the correct action to take is deemed to be to report the offender to whoever is in charge of the community, if, as psychologists want, not attempting to stop receiving these messages is not respecting oneself enough… Then such beliefs and policies seem to me to hurt, rather than protecting, 'victims' of verbal abuse, because effectively they teach them to stay at the lower levels of emotional sovereignty. If, instead of attempting to cleanse the word of all verbal 'negativity', the emphasis was on empowering the addressees of such messages to be 'sovereign' over them, then the old adage that '<em>sticks and stones can break my bones, but words can never hurt me</em>' would become true. On the other hand, the current emphasis of fighting the 'abusive' messages themselves seems to me to give the abusers the power to actually hurt the receivers of the verbal abuse: and that's a lot of power to place in improper hands.</p>\n\n<p>I understand that my reasoning may be very well wrong, as the general consensus seems to be in the opposite. Then do both models not contradict themselves, regardless of whatever would seem to me to be the case? Or is Gajdowie's model of emotional sovereignty wrong?</p>\n\n<p>EDIT: Just to clarify: The precise point that is hard to reconcile for me is this one: It is impossible for the receiver of the 'abusive' messages to avoid being damaged by such messages (the quoted comments) vs it is possible (Gajdowie)</p>\n", "pids": ["53e99fefb7602d97028ccedb", "53e9a6e0b7602d9703017ebd", "55a6a0d865ce054aad6e6cd3", "53e9ad11b7602d97036efa0c"], "flag": 1}
{"question": "Highest Pressure Human Body Can Survive In?", "body": "<p>One design for underwater human inhabited environments is to have equal pressure between the surrounding water and the submerged habitat, thus allowing a section of the floor to be open to the water and removing the necessity for strong plating to protect it.  This requires the air pressure within the environment to be greater than atmospheric pressure so that it can withstand the pressure of both the atmosphere and the pressure from the overlying water.  </p>\n\n<p>So how much pressure can the human body survive in without need for special suits and breathing apparatuses (as this would place a limit on how deep you could build such an environment without special accommodation)?     </p>\n\n<p>Edit: So far i've found an article about a man trapped in a sunken boat who survived for days in an air pocket trapped in the bathroom 100 feet down.  He couldn't resurface without the use of a diving bell and gradual decompression; but this case provides a lower bound for how high the highest pressure can be.  </p>\n\n<p>Calculations:  14.7 psi (atm pressure) + 1200 inches*0.037 psi/in^3 = 60 psi for the underwater pocket (roughly 4 times atmospheric pressure).\n<a href=\"http://news.nationalgeographic.com/news/2013/12/131204-nigerian-air-bubble-survival-shipwreck-viral-video-science/\" rel=\"noreferrer\">http://news.nationalgeographic.com/news/2013/12/131204-nigerian-air-bubble-survival-shipwreck-viral-video-science/</a></p>\n", "pids": ["55a5d55a2401defa0da5a930", "55a34611612ca6486866fb89"], "flag": 1}
{"question": "How do you respond (in a reasonable manner) when a less-educated friend suggests reasons for your current psychiatric disorder?", "body": "<p>My friend suggested that a recent and ongoing flare of my autoimmune disease was causing my ongoing depression.</p>\n<p>She is a very close friend, and I love her dearly, but she is much less educated than I am -- I am not at all saying she is not intelligent. I am a retired psychiatrist. She suggested I see a physician. I see a board-certified psychiatrist once a week, and have seen this physician, who is more intelligent than I am, for 15 years. I am on medication and have psychotherapy.</p>\n<p>My friend knows all these details. I was shocked, as my friend knows my depression is complicated, and the recent problems have been going on over a year.</p>\n<p>My autoimmune flare has been going on for 6 weeks, and it is being treated with medication that I already have for flares. Needless to say, I was flabbergasted, expressed some shock, but just mumbled something.</p>\n<p>So <strong>how could I have responded (in a reasonable manner) to this friend?</strong></p>\n", "pids": ["5d9ed30947c8f76646f7f7cc"], "flag": 1}
{"question": "How to avoid blaming a single person for issues submitting a group assignment?", "body": "<p>I have a group assignment that is due soon. We are only allowed one submission per group (and further submissions, even before the deadline, will be penalized). This group assignment is worth a significant portion of our grade (about 50%).</p>\n<p>This group assignment requires digitally submitting multiple separate documents and have very specific requirements (filename must be <code>groupAssignment1.pdf</code>, it must be submitted between 18:00 and 18:30 on a specific day, and so on). All group members receive the same grade.</p>\n<p><strong>How can I/we submit the group assignment without putting the blame on the submitter for forgetting to submit a required document or submitting it &quot;incorrectly&quot; (as defined by the strict requirements)?</strong></p>\n<p>At best, the blame should be put on the whole group if the submission was done &quot;incorrectly&quot;.</p>\n<p>I have suggested this:</p>\n<blockquote>\n<p>To meet up just before the deadline with everyone watching the submission process (one person prepares documents to submit, everyone else watches and catches errors). The people who did not/can not make it there have no right to complain if it was done incorrectly (I don't feel comfortable with this because some people have legitimate reasons for not  being able to make it).</p>\n</blockquote>\n", "pids": ["56d90467dabfae2eeeecf66f"], "flag": 1}
{"question": "How can one induce psychogenic death?", "body": "<p>I saw something about psychogenic death. I am wondering if it can be induced by a desire. I think that it can by a person being lazy and not caring about the world. It is said to happen with prisoners of war. The article says that it is not suicide but I don't know if it is true. It cannot happen all at once, it just happens because the person does not care.</p>\n<p>There is an article here: <a href=\"https://www.eurekalert.org/pub_releases/2018-09/uop-pcd092018.php\" rel=\"nofollow noreferrer\">https://www.eurekalert.org/pub_releases/2018-09/uop-pcd092018.php</a></p>\n<p>Reference to the original research is: Leach, J. (2018). ‘Give-up-itis’ revisited: Neuropathology of extremis. Medical hypotheses, 120, 14-21. <a href=\"https://doi.org/10.1016/j.mehy.2018.08.009\" rel=\"nofollow noreferrer\">https://doi.org/10.1016/j.mehy.2018.08.009</a></p>\n", "pids": ["5c0f8b1dda562944ac9c83ef", "56d8985fdabfae2eee2251dc"], "flag": 1}
{"question": "What is the most accurate method of discerning between “irredeemable evil” and “temporary insanity”?", "body": "<p>To be precise, by &quot;evil&quot; I am referring specifically to\nthe weakness of the trait of (or compulsion) for “genuine care and concern for the wellbeing of others”\nwith respect to\nthe strength of the trait of (or compulsion for) &quot;the pursuit of self-interest&quot;.</p>\n<p>Or, more succinctly, the weakness of the force of conscience as a constraining force on the predatory compulsion of self-interest.</p>\n<blockquote>\n<p>“The battle line between good and evil runs through the heart of every\nman.&quot;<br />\n ~Aleksandr Solzhenitsyn</p>\n</blockquote>\n<p>Some humans seem to lack this “genuine care and concern for the wellbeing of others”<br />\nOf those who do, there seem to be at least 2 distinct groups:<br />\n1: Those who lack it permanently. (irredeemably evil)<br />\n2: Those who lack it only temporarily. (temporary insanity)</p>\n<p>By &quot;temporary insanity&quot; I am referring to the phenomenon of people who seem to act without care and concern for the well being of others, but who seem to do so because they lack the ability to control their fear at the time and are later genuinely remorseful for their behavior.</p>\n<p>By &quot;irredeemably evil&quot; I am referring to those who never experience any genuine remorse for such behavior.</p>\n<p><strong>Difficulty #1: The seeming absence of a single underlying cause</strong></p>\n<p>Psychopathy is probably the best example of &quot;irredeemable&quot; evil. There are methods like the PCL-R to detect this particular type of evil. However, there seems to be growing evidence that narcissism also has a strong heritable component. The methods for detecting psychopathy do not seem to be applicable to narcissism.</p>\n<p>To add to the difficulty of the problem, the evidence would seem to suggest that the absence of moral constraint to predatory compulsions may not have a single cause.</p>\n<p>For example, there is some evidence to suggest that psychopathy may be the result of weak pain signals in general.</p>\n<p>One interpretation of this is that conscience emerges and is strengthened by the process of persistent pain giving rise to rumination. i.e. When our actions harm others, the persistent guilt that we feel, gives rise to a resolve to change our behavior both to relieve the pain in the moment and to avoid feeling this pain again in the future. However, if the pain signal is too weak to give rise to rumination, then the conscience does not form.</p>\n<p>On the other hand, narcissists seem to typically have normal levels of pain for themselves but lack the affective empathy which would trigger similar levels of pain when other humans are suffering. One interpretation of this is that the persistent pain which gives rise to the rumination which gives rise to conscience does not arise, due not to the inability to experience pain in general, but rather to the inability to experience pain of others due to the absence of affective empathy.</p>\n<p>Given these different ways in which the growth of conscience can be interrupted, it's possible that the most effective means of discernment between &quot;irredeemable evil&quot; an &quot;temporary insanity&quot; might be to identify the traits of those who have a fully developed conscience and look for the absence of those traits in the individual in question.</p>\n<p><strong>Difficulty #2: Variance in the size of the circle of genuine care and concern.</strong></p>\n<p>To further add to the difficulty of this problem, it seems that the size of the circle of &quot;genuine care and concern&quot; varies considerably amongst humans.</p>\n<p>For some, it extends only to kin.<br />\nFor others it might extend to a larger tribe.<br />\nFor others still, it might, as some religions would encourage us, extend to all humans or even all living beings.</p>\n<p>To be more precise, therefore,\ngiven that evil is the perception of the absence of &quot;genuine care and concern for the well being of others&quot;,\nand that those who lack &quot;genuine care and concern for the well being of others&quot; will feel compelled to fake it in order to survive and thrive in society,\nthis question seems to break down into the following 2 components:</p>\n<p>1: pre-discovery: What is the most accurate method that potential prey can use to detect that the &quot;care and concern&quot; displayed by the skilled predator is, in fact, a deception?</p>\n<p>2: post-discovery: Having witnessed evidence of the absence of &quot;genuine care and concern for the well being of others&quot;, what is the most accurate means of determining if this is due to a permanent versus temporary inability to expand the circle of care and concern?</p>\n", "pids": ["5e297001df1a9c0c41e7a137", "53e9991db7602d970215bf3c", "55a5f79a65cead59c8319fc2"], "flag": 1}
{"question": "Most interesting statistical paradoxes", "body": "<p>Because I find them fascinating, I'd like to hear what folks in this community find as the most interesting statistical paradox and why.</p>\n", "pids": ["5d4ac1f13a55acb184527f16"], "flag": 1}
{"question": "How is it possible that validation loss is increasing while validation accuracy is increasing as well", "body": "<p>I am training a simple neural network on the CIFAR10 dataset. After some time, validation loss started to increase, whereas validation accuracy is also increasing. The test loss and test accuracy continue to improve.</p>\n\n<p>How is this possible? It seems that if validation loss increase, accuracy should decrease. </p>\n\n<p>P.S. There are several similar questions, but nobody explained what was happening there.<a href=\"https://i.stack.imgur.com/GrnRo.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/GrnRo.png\" alt=\"enter image description here\"></a></p>\n", "pids": ["599c797a601a182cd2641eda"], "flag": 1}
{"question": "Difference between neural net weight decay and learning rate", "body": "<p>In the context of neural networks, what is the difference between the learning rate and weight decay? </p>\n", "pids": ["5ce2d0feced107d4c63dd498"], "flag": 1}
{"question": "Why are neural networks becoming deeper, but not wider?", "body": "<p>In recent years, convolutional neural networks (or perhaps deep neural networks in general) have become deeper and deeper, with state-of-the-art networks going from 7 layers (<a href=\"http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf\">AlexNet</a>) to 1000 layers (<a href=\"https://arxiv.org/pdf/1512.03385v1.pdf\">Residual Nets)</a> in the space of 4 years. The reason behind the boost in performance from a deeper network, is that a more complex, non-linear function can be learned. Given sufficient training data, this enables the networks to more easily discriminate between different classes.</p>\n\n<p>However, the trend seems to not have followed with the number of parameters in each layer. For example, the number of feature maps in the convolutional layers, or the number of nodes in the fully-connected layers, has remained roughly the same and is still relatively small in magnitude, despite the large increase in the number of layers. From my intuition though, it would seem that increasing the number of parameters per layer would give each layer a richer source of data from which to learn its non-linear function; but this idea seems to have been overlooked in favour of simply adding more layers, each with a small number of parameters.</p>\n\n<p>So whilst networks have become \"deeper\", they have not become \"wider\". Why is this?</p>\n", "pids": ["573696026e3b12023e5163e1"], "flag": 1}
{"question": "T-test for non normal when N&gt;50?", "body": "<p>Long ago I learnt that normal distribution was necessary to use a two sample T-test. Today a colleague told me that she learnt that for N>50 normal distribution was not necessary. Is that true?</p>\n\n<p>If true is that because of the central limit theorem?</p>\n", "pids": ["53e99f03b7602d97027d1614"], "flag": 1}
{"question": "Is it possible to train a neural network without backpropagation?", "body": "<p>Many neural network books and tutorials spend a lot of time on the backpropagation algorithm, which is essentially a tool to compute the gradient.</p>\n\n<p>Let's assume we are building a model with ~10K parameters / weights. Is it possible to run the optimization using some gradient free optimization algorithms? </p>\n\n<p>I think computing the numerical gradient would be too slow, but how about other methods such as Nelder-Mead, Simulated Annealing or a Genetic Algorithm?</p>\n\n<p>All the algorithms would suffer from local minima, why obsessed with gradient?</p>\n", "pids": ["58437722ac44360f1082f5c4"], "flag": 1}
{"question": "How to politely ask my family to stop pressuring me to &#39;like&#39; posts more on social media?", "body": "<p>It happens fairly often: someone in the family buys a 'cool new thing', and posts pictures of it on social media like Whatsapp. Sometimes something interesting pops up that deserves a comment from me, but usually it is something I do not really care about.</p>\n\n<p>Now I'm being asked by family to 'like' stuff more, since I'm normally more of a quiet person. Personally I don't see the purpose of being another +1 in a social circle for stuff I don't really care about. However, I don't want to break off communication with these people.</p>\n\n<p>Now someone in my family is trying to get me to 'like' things more by saying it's \"good for my social development\". However, I don't see how 'liking' things helps me get actual social skills. I also feel like it's actually a detriment by liking stuff I don't actually like, as it makes me more irritated about the stuff that gets posted (since I actually have to respond to it), while simultaneously encouraging other people to post more of the stuff I don't care about (because they may think I actually like it due to my comments while in reality I don't).</p>\n\n<p>I personally feel like there is no benefit to be gained from 'liking' stuff. In that case, what is the best way to get people asking me to 'like' more off my back and tell them politely that I'm not a kind of person that likes to 'like' a lot.</p>\n\n<p>So far I have said that I am simply am just more of a quiet type, but that doesn't quite cut it. I kind of want to tell them that I simply don't like having to dedicate my attention to monitoring feeds that are unlikely to contain stuff that's really interesting to me. By the time I do take some time to catch up, 3 people have already responded. However, I can't think of a way of saying that without it offending people.</p>\n", "pids": ["53e9bda6b7602d9704a525d9", "53e9b4e4b7602d970400dc61", "56d81a2cdabfae2eee8e0be1", "55503ef945ce0a409eb2b6c3"], "flag": 1}
{"question": "What is the relation between k-means clustering and PCA?", "body": "<p>It is a common practice to apply PCA (principal component analysis) before a clustering algorithm (such as k-means). It is believed that it improves the clustering results in practice (noise reduction). </p>\n\n<p>However I am interested in a comparative and in-depth study of the relationship between PCA and k-means. For example, Chris Ding and Xiaofeng He, 2004, <a href=\"http://ranger.uta.edu/~chqding/papers/KmeansPCA1.pdf\" rel=\"noreferrer\">K-means Clustering via Principal Component Analysis</a> showed that \"principal components are the continuous\nsolutions to the discrete cluster membership indicators for K-means clustering\". However, I have hard time understanding this paper, and Wikipedia actually <a href=\"https://en.wikipedia.org/wiki/Principal_component_analysis#Relation_between_PCA_and_K-means_clustering\" rel=\"noreferrer\">claims that it is wrong</a>.</p>\n\n<p>Also, the results of the two methods are somewhat different in the sense that PCA helps to reduce the number of \"features\" while preserving the variance, whereas clustering reduces the number of \"data-points\" by summarizing several points by their expectations/means (in the case of k-means).\nSo if the dataset consists in $N$ points with $T$ features each, PCA aims at compressing the $T$ features whereas clustering aims at compressing the $N$ data-points.</p>\n\n<p>I am looking for a layman explanation of the relations between these two techniques + some more technical papers relating the two techniques.</p>\n", "pids": ["626754bb5aee126c0fbccb56"], "flag": 1}
{"question": "Obtaining knowledge from a random forest", "body": "<p>Random forests are considered to be black boxes, but recently I was thinking what knowledge can be obtained from a random forest?</p>\n\n<p>The most obvious thing is the importance of the variables, in the simplest variant it can be done just by calculating the number of occurrences of a variable.<br>\nThe second thing I was thinking about are interactions. I think that if the number of trees is sufficiently large then the number of occurrences of pairs of variables can be tested (something like chi square independence). \nThe third thing are nonlinearities of variables. My first idea was just to look at a chart of a variable  Vs score, but I'm not sure yet whether it makes any sense.  </p>\n\n<p>Added 23.01.2012<br>\n<strong>Motivation</strong>  </p>\n\n<p>I want to use this knowledge to improve a logit model. I think (or at least I hope) that it is possible to find interactions and nonlinearities that were overlooked.</p>\n", "pids": ["57a4e91aac44365e35c97a30", "5f028667dfae54360a45e69e", "56d8463bdabfae2eeeb05915"], "flag": 1}
{"question": "What does &quot;oddly related&quot; mean in a mental status exam?", "body": "<p>Mental Status Exams done by psychiatrists often include a description of the &quot;relatedness&quot; of a patient. Sometimes, patients are described as &quot;oddly related.&quot; What is &quot;relatedness&quot; and what qualifies as &quot;oddly related&quot;?</p>\n<p>A google search for &quot;oddly related psychiatry&quot; shows a similar question on <a href=\"https://www.reddit.com/r/AskDoctorSmeeee/comments/4scq1n/what_does_oddly_related_mean/\" rel=\"nofollow noreferrer\">reddit</a> and <a href=\"https://allnurses.com/oddly-related-t387449/\" rel=\"nofollow noreferrer\">allnurses</a> without a proper answer unfortunately.</p>\n", "pids": ["56698c400cf25a01a9fbb764", "5c0f8693da562944ac935bac", "5d455ecf275ded87f9804948"], "flag": 1}
{"question": "Comprehensive list of activation functions in neural networks with pros/cons", "body": "<p>Are there any reference document(s) that give a comprehensive list of activation functions in neural networks along with their pros/cons (and ideally some pointers to publications where they were successful or not so successful)?</p>\n", "pids": ["53e9bd6ab7602d9704a0a65a", "573696f46e3b12023e5f0d4d", "5c04967517c44a2c747093a2"], "flag": 1}
{"question": "How does the reparameterization trick for VAEs work and why is it important?", "body": "<p>How does the <a href=\"http://arxiv.org/pdf/1312.6114v10.pdf\">reparameterization trick</a> for variational autoencoders (VAE) work? Is there an intuitive and easy explanation without simplifying the underlying math? And why do we need the 'trick'? </p>\n", "pids": ["5bdc31b817c44a1f58a0c572", "5550443b45ce0a409eb4c39d"], "flag": 1}
{"question": "Mean absolute error OR root mean squared error?", "body": "<p>Why use Root Mean Squared Error (RMSE) instead of Mean Absolute Error (MAE)??  </p>\n\n<p>Hi</p>\n\n<p>I've been investigating the error generated in a calculation - I initially calculated the error as a Root Mean Normalised Squared Error.</p>\n\n<p>Looking a little closer, I see the effects of squaring the error gives more weight to larger errors than smaller ones, skewing the error estimate towards the odd outlier. This is quite obvious in retrospect. </p>\n\n<p>So my question - in what instance would the Root Mean Squared Error be a more appropriate measure of error than the Mean Absolute Error? The latter seems more appropriate to me or am I missing something?</p>\n\n<p>To illustrate this I have attached an example below:                 </p>\n\n<ul>\n<li><p>The scatter plot shows two variables with a good correlation, </p></li>\n<li><p>the two histograms to the right chart the error between Y(observed )\nand Y(predicted) using normalised RMSE (top) and MAE (bottom).</p></li>\n</ul>\n\n<p><a src=\"https://i.stack.imgur.com/UBIqN.png\" alt=\"enter image description here\"></p>\n\n<p>There are no significant outliers in this data and MAE gives a lower error than RMSE. Is there any rational, other than MAE being preferable, for using one measure of error over the other?        </p>\n", "pids": ["5d9ed79547c8f76646004a56"], "flag": 1}
{"question": "Why is ANOVA taught / used as if it is a different research methodology compared to linear regression?", "body": "<p>ANOVA is equivalent to linear regression with the use of suitable dummy variables. The conclusions remain the same irrespective of whether you use ANOVA or linear regression.</p>\n<p>In light of their equivalence, is there any reason why ANOVA is used instead of linear regression?</p>\n<p>Note: I am particularly interested in hearing about <strong>technical</strong> reasons for the use of ANOVA instead of linear regression.</p>\n<p><strong>Edit</strong></p>\n<p>Here is one example using one-way ANOVA. Suppose, you want to know if the average height of male and females is the same. To test for your hypothesis you would collect data from a random   sample of male and females (say 30 each) and perform the ANOVA analysis (i.e., sum of squares for sex and error) to decide whether an effect exists.</p>\n<p>You could also use linear regression to test for this as follows:</p>\n<p>Define:  <span class=\"math-container\">$\\text{Sex} = 1$</span> if respondent is a male and <span class=\"math-container\">$0$</span> otherwise.\n<span class=\"math-container\">$$\n\\text{Height} = \\text{Intercept} + \\beta * \\text{Sex} + \\text{error}\n$$</span>\nwhere: <span class=\"math-container\">$\\text{error}\\sim\\mathcal N(0,\\sigma^2)$</span></p>\n<p>Then a test of whether <span class=\"math-container\">$\\beta = 0$</span> is a an equivalent test for your hypothesis.</p>\n", "pids": ["622993455aee126c0ffdaa75"], "flag": 1}
{"question": "Where should I place dropout layers in a neural network?", "body": "<p>Is there any general guidelines on where to place dropout layers in a neural network?</p>\n", "pids": ["573696006e3b12023e513cb6", "5f0ed26f91e011ead9665307"], "flag": 1}
{"question": "Can someone explain Gibbs sampling in very simple words?", "body": "<p>I'm doing some reading on topic modeling (with Latent Dirichlet Allocation) which makes use of Gibbs sampling. As a newbie in statistics―well, I know things like binomials, multinomials, priors, etc.―,I find it difficult to grasp how Gibbs sampling works. Can someone please explain it in simple English and/or using simple examples? (If you are not familiar with topic modeling, any examples will do.) </p>\n", "pids": ["53e9a9bdb7602d970331a3bf"], "flag": 1}
{"question": "Asking &quot;What&#39;s wrong in you life?&quot; → Person sees more problems", "body": "<p>I think if you ask a person &quot;What's wrong in your life?&quot; several times (for example monthly) the person starts to focus on negative things.</p>\n<p>Maybe questions like this can have a negative outcome. The person will focus on (maybe even search) things which are negative. These questions might influence his attention. And finally the person might get depressed or the relationship gets worse.</p>\n<p>I am new to psychology. Is there a term for this? Or are there researches on this topic?</p>\n<p>Similar questions:</p>\n<ul>\n<li>What is causing you stress?</li>\n<li>What do you dislike at your workplace?</li>\n<li>What annoys you most about your spouse?</li>\n</ul>\n", "pids": ["5f5b72659fced0a24bdeb859", "55a6ad4f65ce054aad70b4d4", "53e9bd50b7602d97049e55d3", "5afe3150a1947207c6ac2afa", "55a4dfbf612c6b12aafc6d21", "53e9a3fbb7602d9702d148cf", "53e9adc7b7602d97037ccf14", "5ae4d103a2e6b107866add3f"], "flag": 1}
{"question": "Clustering on the output of t-SNE", "body": "<p>I've got an application where it'd be handy to cluster a noisy dataset before looking for subgroup effects within the clusters.  I first looked at PCA, but it takes ~30 components to get to 90% of the variability, so clustering on just a couple of PC's will throw away a lot of information.  </p>\n\n<p>I then tried t-SNE (for the first time), which gives me an odd shape in two dimensions that is very amenable to clustering via k-means.  What's more, running a random forest on the data with the cluster assignment as the outcome shows that the clusters have a fairly sensible interpretation given the context of the problem, in terms of the variables that make up the raw data.</p>\n\n<p>But if I'm going to report on these clusters, how do I describe them?  K-means clusters on principal components reveal individuals who are nearby to one another in terms of the derived variables that comprise X% of the variance in the dataset.  What equivalent statement can be made about t-SNE clusters?</p>\n\n<p>Perhaps something to the effect of:</p>\n\n<blockquote>\n  <p>t-SNE reveals approximate contiguity in an underlying high-dimensional manifold, so clusters on the low-dimensional representation of the high-dimensional space maximize the \"likelihood\" that contiguous individuals will not be in the same cluster</p>\n</blockquote>\n\n<p>Can anyone propose a better blurb than that?</p>\n", "pids": ["5a260c4617c44a4ba8a27580", "5a73cbcc17c44a0b3035f4b5"], "flag": 1}
{"question": "When is unbalanced data really a problem in Machine Learning?", "body": "<p>We already had multiple questions about unbalanced data when using <a href=\"https://stats.stackexchange.com/questions/6067/does-an-unbalanced-sample-matter-when-doing-logistic-regression\">logistic regression</a>, <a href=\"https://stats.stackexchange.com/questions/94295/svm-for-unbalanced-data\">SVM</a>, <a href=\"https://stats.stackexchange.com/questions/28029/training-a-decision-tree-against-unbalanced-data\">decision trees</a>, <a href=\"https://stats.stackexchange.com/questions/15036/bagging-with-oversampling-for-rare-event-predictive-models\">bagging</a> and a number of other similar questions, what makes it a very popular topic! Unfortunately, each of the questions seems to be algorithm-specific and I didn't find any general guidelines for dealing with unbalanced data.</p>\n<p>Quoting <a href=\"https://stats.stackexchange.com/a/131259/35989\">one of the answers by Marc Claesen</a>, dealing with unbalanced data</p>\n<blockquote>\n<p>(...) heavily depends on the learning method. Most general purpose\napproaches have one (or several) ways to deal with this.</p>\n</blockquote>\n<p>But when exactly should we worry about unbalanced data? Which algorithms are mostly affected by it and which are able to deal with it? Which algorithms would need us to balance the data? I am aware that discussing each of the algorithms would be impossible on a Q&amp;A site like this. I am rather looking for general guidelines on when it could be a problem.</p>\n", "pids": ["5c3f2739df5b8c0b3cce862c"], "flag": 1}
{"question": "Is there a criterion to distinct between a philia and a paraphilia?", "body": "<p>The terms &quot;<a href=\"https://en.wikipedia.org/wiki/Androphilia_and_gynephilia\" rel=\"nofollow noreferrer\">Androphilia&quot; and &quot;Gynephilia&quot;</a> describe the two major <code>romantic and/or sexual orientation/s</code> of humans → towards &quot;masculine&quot; humans and &quot;feminine&quot; humans, respectively.</p>\n<p>Generally any human (including Asexuals which only lack the desire to have sex but   not the romantic connection desire) will likely be classified by some in society as a &quot;heterosexual&quot;, &quot;homosexual&quot; or &quot;bisexual&quot;, according to that person's <code>romantic and/or sexual orientation/s</code> and in the context of gender.</p>\n<ul>\n<li><p>One can say that attractions to FTM transgenders and attraction to MTF transgenders are separate major philias &quot;Andromimetophilia&quot; and &quot;Gynemimetophilia&quot;<sup>(as somewhat accurate yet probably bad terms)</sup>.</p>\n</li>\n<li><p>One could speak of a third and forth philias (or fifth and sixth philias, depending how one counts) to Male-oriented intersex individuals and Female-oriented intersex individuals.</p>\n</li>\n<li><p>One could go to the extreme and speak about philias to FTM and MTF <a href=\"https://en.wikipedia.org/wiki/Detransition\" rel=\"nofollow noreferrer\">detransitioned</a> people.</p>\n</li>\n</ul>\n<h2>My problem</h2>\n<p>Any of the above philias can have one or more paraphilias, which can be not harmful or does harmful but it is unclear to me if there is a criterion to distinct between a philia and a paraphilia.</p>\n<h3>Non harmful examples</h3>\n<ul>\n<li><p>A man with gynephilia (heterosexual) can have a paraphilia such as for women in army uniform and on the contrary, a man with androphilia (homosexual) can have a paraphilia for men in army uniform.</p>\n</li>\n<li><p>A man with gynephilia (heterosexual) can have a paraphilia for women with Gothic appearance and on contrary, a man with androphilia (homosexual) can have a paraphilia for men with Gothic appearance.</p>\n</li>\n</ul>\n<h3>Harmful examples</h3>\n<ul>\n<li><p>The first harmful example is pedophiliac paraphilia:<br>\nA man with gynephilia (heterosexual) can have a paraphilia for little girls (say under sexual maturation) and on the contrary, a man with androphilia (homosexual) can have a paraphilia for little boys (say, under sexual maturation).</p>\n</li>\n<li><p>Another harmful example is zoophilia which includes exploitation of animals who cannot give consent and might be raped.</p>\n</li>\n</ul>\n<p>Both pedophilia (not to be confused with hebephilia which is attraction to young teenagers) as well as zoophilia, are rare paraphilias that may manifest themselves in harmful or illegal behavior.</p>\n<h2>Interim note</h2>\n<p>As I have shown, the &quot;philia&quot; term can describe both sexual orientations and their sub components (<em>not harmful</em> and <em>is harmful</em>).</p>\n<h2>My question</h2>\n<p>Is there a criterion to distinct between a philia and a paraphilia?</p>\n<blockquote>\n<p>This question encapsulates the question:</p>\n<ul>\n<li>Does the term Philia exists in psychological literature for describing <code>romantic and/or sexual orientation/s</code> and not just fetishes, or alternatively, as a standalone term?</li>\n</ul>\n</blockquote>\n", "pids": ["55a5ce8365ce60f99bf5e607", "53e9b89ab7602d9704470bb6", "5c0f7cc2da562944ac7e0cf5", "53e9a698b7602d9702fcb749", "55a4091a65ce5cd7b3c129e6"], "flag": 1}
{"question": "Is it true that mirror neurons can make a man with an amputated arm feel sensation just by looking at someone else&#39;s arm, like Ramachandran said?", "body": "<p>In <a href=\"https://www.youtube.com/watch?v=l80zgw07W4Y\" rel=\"nofollow noreferrer\">this</a> Ted Talk Ramachandran sais that <a href=\"https://en.wikipedia.org/wiki/Mirror_neuron\" rel=\"nofollow noreferrer\">mirror neurons</a> can make a person with an amputated arm feel sensation, is it true? And if so, why doesn't the brain feel a sensation by looking at someone else's arm when your arm is intact?</p>\n", "pids": ["53e99b7eb7602d97024248f1"], "flag": 1}
{"question": "How to plot ROC curves in multiclass classification?", "body": "<p>In other words, instead of having a two class problem I am dealing with 4 classes and still would like to assess performance using AUC.</p>\n", "pids": ["539099b320f70186a0e1b890"], "flag": 1}
{"question": "What is the neurological basis for the association between Bipolar type 2 and autism spectrum disorder (ASD)?", "body": "<p>Bipolar disorder type 2 and autism spectrum disorder (ASD) is regularly seen together. What is the neurological explanation for this?</p>\n", "pids": ["5c1369feda56295a08a40564", "53e9a357b7602d9702c62e80", "5c170c86da562969c458bd48"], "flag": 1}
{"question": "Who Are The Bayesians?", "body": "<p>As one becomes interested in statistics, the <a href=\"https://youtu.be/BOWNHl3qOVA\">dichotomy \"Frequentist\" vs. \"Bayesian\"</a> soon becomes commonplace (and who hasn't read <a href=\"https://en.wikipedia.org/wiki/The_Signal_and_the_Noise\">Nate Silver's <em>The Signal and the Noise</em></a>, anyway?). In talks and introductory courses, the point of view is overwhelmingly frequentist (<a href=\"https://en.wikipedia.org/wiki/Maximum_likelihood\">MLE</a>, $p$ values), but there tends to be a tiny fraction of time dedicated to admire Bayes formula and touch upon the idea of a <em>prior distribution</em>, usually tangentially. </p>\n\n<p>The tone employed to discuss Bayesian statistics oscillates between respect for its conceptual underpinnings, and a hint of skepticism regarding the chasm between lofty objectives, and arbitrariness in the selection of the prior distribution, or eventual use of frequentist maths after all.</p>\n\n<p>Sentences such as \"if you are a hard-core Bayesian...\" abound.</p>\n\n<p>The question is, Who are the Bayesians today? Are they some select academic institutions where you know that if you go there you will become a Bayesian? If so, are they specially sought after? Are we referring to just a few respected statisticians and mathematicians, and if so who are they?</p>\n\n<p>Do they even exist as such, these pure \"Bayesians\"? Would they happily accept the label? Is it always a flattering distinction? Are they mathematicians with peculiar slides in meetings, deprived of any $p$ values and confidence intervals, easily spotted on the brochure?</p>\n\n<p>How much of a <a href=\"https://normaldeviate.wordpress.com/2013/09/01/is-bayesian-inference-a-religion/\">niche</a> is being a \"Bayesian\"? Are we referring to a minority of statisticians?</p>\n\n<p>Or is current Bayesian-ism equated with machine learning applications?</p>\n\n<p>... Or even more likely, is Bayesian statistics not so much a branch of statistics, but rather an <a href=\"http://plato.stanford.edu/entries/epistemology-bayesian/\">epistemological</a> movement that transcends the ambit of probability calculations into a philosophy of science? In this regard, all scientists would be Bayesian at heart... but there would be no such thing as a pure Bayesian statistician impermeable to frequentist techniques (or contradictions).</p>\n", "pids": ["56d84a14dabfae2eeece1a1e"], "flag": 1}
{"question": "Are there any examples where Bayesian credible intervals are obviously inferior to frequentist confidence intervals", "body": "<p>A recent question on the difference between confidence and credible intervals led me to start re-reading Edwin Jaynes' article on that topic:</p>\n\n<p>Jaynes, E. T., 1976. `Confidence Intervals vs Bayesian Intervals,' in Foundations of Probability Theory, Statistical Inference, and Statistical Theories of Science, W. L. Harper and C. A. Hooker (eds.), D. Reidel, Dordrecht, p. 175; (<a href=\"http://bayes.wustl.edu/etj/articles/confidence.pdf\">pdf</a>)</p>\n\n<p>In the abstract, Jaynes writes:</p>\n\n<blockquote>\n  <p>...we exhibit the Bayesian and orthodox solutions to six common statistical problems involving confidence intervals (including significance tests based on the same reasoning).  In every case, we find the situation is exactly the opposite, i.e. the Bayesian method is easier to apply and yields the same or better results.  Indeed, the orthodox results are satisfactory only when they agree closely (or exactly) with the Bayesian results. <strong>No contrary example has yet been produced.</strong></p>\n</blockquote>\n\n<p>(emphasis mine)</p>\n\n<p>The paper was published in 1976, so perhaps things have moved on. My question is, are there examples where the frequentist confidence interval is clearly superior to the Bayesian credible interval (as per the challenge implicitly made by Jaynes)?</p>\n\n<p>Examples based on incorrect prior assumptions are not acceptable as they say nothing about the internal consistency of the different approaches.</p>\n", "pids": ["53e9aa24b7602d9703392d76"], "flag": 1}
{"question": "How to annoy a statistical referee?", "body": "<p>I recently asked a question regarding general principles around <a href=\"https://stats.stackexchange.com/questions/3460/reviewing-statistics-in-papers\">reviewing statistics in papers</a>. What I would now like to ask, is what particularly irritates you when reviewing a paper, i.e. what's the best way to really annoy a statistical referee!</p>\n\n<p>One example per answer, please.</p>\n", "pids": ["609a6f2be4510cd7c8932cfd"], "flag": 1}
{"question": "Motor skill: Let speed come naturally?", "body": "<p>I've commonly heard that when practising a motor skill, one should start slow with correct form and one shouldn't force speed. Rather, let speed come naturally. I believe this but I can't find a citation for its prescription. Does anyone have a study to support (or deny) this?</p>\n<p>I'm particularly interested in <a href=\"https://www.sciencedirect.com/topics/engineering/aiming-movement\" rel=\"nofollow noreferrer\">aiming movement</a> in <a href=\"https://www.youtube.com/watch?v=ykuuv23-40o\" rel=\"nofollow noreferrer\">first-person shooter</a> video-games. The input device is moving a computer mouse. I am also training in <a href=\"https://www.youtube.com/watch?v=vDjlV6Qtb90\" rel=\"nofollow noreferrer\">Super smash Bros. Melee</a>, a platform fighting game. The input device is a <a href=\"https://www.google.com/search?tbm=isch&amp;q=gamecube+controller\" rel=\"nofollow noreferrer\">GameCube controller</a>. These would both fall under fine motor skill.</p>\n", "pids": ["55a3cf882401c6de3b74b712"], "flag": 1}
{"question": "Does everyone make big mistakes?", "body": "<p>It is sometimes said that we all make big mistakes.  Is this true?</p>\n<p>As a starting point, 'big mistake' could be defined as a mistake which we do unconsciously for months, and for which the implications endure for more than a few months.</p>\n<p>What is the best approach to recover from 'big mistakes'?</p>\n", "pids": ["5c0f8385da562944ac8c84a6"], "flag": 1}
{"question": "Feature selection for &quot;final&quot; model when performing cross-validation in machine learning", "body": "<p>I am getting a bit confused about feature selection and machine learning\nand I was wondering if you could help me out.  I have a microarray dataset that is\nclassified into two groups and has 1000s of features.  My aim is to get a small number of genes (my features) (10-20) in a signature that I will in theory be able to apply to\nother datasets to optimally classify those samples.  As I do not have that many samples (&lt;100), I am not using a test and training set but using Leave-one-out cross-validation to help\ndetermine the robustness.  I have read that one should perform feature selection for each split of the samples i.e.</p>\n\n<ol>\n<li>Select one sample as the test set</li>\n<li>On the remaining samples perform feature selection</li>\n<li>Apply machine learning algorithm to remaining samples using the features selected</li>\n<li>Test whether the test set is correctly classified</li>\n<li>Go to 1.</li>\n</ol>\n\n<p>If you do this, you might get different genes each time, so how do you\nget your \"final\" optimal gene classifier? i.e. what is step 6.</p>\n\n<p>What I mean by optimal is the collection of genes that any further studies\nshould use.  For example, say I have a cancer/normal dataset and I want\nto find the top 10 genes that will classify the tumour type according to\nan SVM.  I would like to know the set of genes plus SVM parameters that\ncould be used in further experiments to see if it could be used as a\ndiagnostic test.</p>\n", "pids": ["5f0e1fb69fced0a24ba99145"], "flag": 1}
{"question": "What is the bandwidth of visual perception?", "body": "<p>Approximately how much &quot;bandwidth&quot;, in bits per second, can typical human visual perception process?</p>\n<p>Consider &quot;The Matrix&quot;, where we assume a near-perfect digital encoding that can reproduce any experience nearly perfectly, compressed with a digital intelligence beyond our own. Now they need to create a cable that plugs into our brainstem. How much bandwidth would that cable need to carry, in order to simulate full human visual experiences?</p>\n<p>For auditory processing -- given all the effort in digital audio compression, it seems likely the answer is somewhere close to 256 kbps (256,000 bits per second), at least within an order of magnitude, give or take. But vision seems far more complex, and I can't find any study or near-approximation that seems plausible.</p>\n<p>Presumably the answer is <em>somewhere</em> from 1 mbps (1,000,000 bits per second) to 1,000 times that amount. A naive approach would be what is the theoretical bandwidth to create any arbitrary video, to the fidelity where human perception could not distinguish differences. However, this is so grossly far from accurate that I suspect it is almost meaningless. I am relatively aware that our visual and auditory processing compress and transform the inputs we perceive, leading to optical illusions etc, which would suggest a much lower number than we might otherwise expect.</p>\n", "pids": ["5f0dffac9fced0a24b98f225"], "flag": 1}
{"question": "How to measure confidence in non-binary (e.g. ordinal) choice tasks?", "body": "<p>In metacognition literature, why is confidence, regardless of scale (Likert-type or continuous) and definition (e.g. decision confidence as a subjective probability of a decision being correct), mostly measured in binary decision tasks, such as 2AFC?</p>\n<p>Is it psychologically valid to obtain confidence in other types of choice tasks, such as multiple-alternatives or ordinal ones, in a similar way?</p>\n", "pids": ["56d82e23dabfae2eee10c763", "5ea55d649fced0a24b5538e9"], "flag": 1}
{"question": "Is Trauma‐Focused Cognitive Behavioral Therapy applicable to adults?", "body": "<p>Can <a href=\"https://en.wikipedia.org/wiki/Trauma_focused_cognitive_behavioral_therapy\" rel=\"nofollow noreferrer\">Trauma‐Focused Cognitive Behavioral Therapy (TF CBT)</a> be used for adults? I've been told that it is applicable to adults but the literature I've found is all focused on children. Has anyone found this used in connection with adults?</p>\n<p><strong>Reference</strong></p>\n<p>Deblinger, E., Mannarino, A.P., Cohen, J.A., Runyon, M.K. and Steer, R.A. (2011), Trauma‐focused cognitive behavioral therapy for children: impact of the trauma narrative and treatment length. Depress. Anxiety, 28: 67-75. <a href=\"https://doi.org/10.1002/da.20744\" rel=\"nofollow noreferrer\">https://doi.org/10.1002/da.20744</a></p>\n", "pids": ["53e99960b7602d97021a52f9"], "flag": 1}
{"question": "Euclidean distance is usually not good for sparse data (and more general case)?", "body": "<p>I have seen somewhere that classical distances (like Euclidean distance) become weakly discriminant when we have multidimensional and sparse data. Why? Do you have an example of two sparse data vectors where the Euclidean distance does not perform well? In this case which similarity should we use?</p>\n", "pids": ["53e999fab7602d970223ff96", "539087cb20f70186a0d5a780"], "flag": 1}
{"question": "What&#39;re the differences between PCA and autoencoder?", "body": "<p>Both PCA and autoencoder can do demension reduction, so what are the difference between them? In what situation I should use one over another?</p>\n", "pids": ["5b1643ba8fbcbf6e5a9bc4e6"], "flag": 1}
{"question": "How is psychohistory theory of deMause viewed in academia?", "body": "<p>I've recently came across the <a href=\"https://en.wikipedia.org/wiki/Psychohistory\" rel=\"nofollow noreferrer\">psychohistory theory</a> of deMause. To best of my understanding,\nit roughly tries to capture the common psychology of an era by analyzing the childbearing practices of that era. See the <a href=\"https://en.wikipedia.org/wiki/Lloyd_deMause\" rel=\"nofollow noreferrer\">summary</a> below.\n<a href=\"https://i.stack.imgur.com/oqrff.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/oqrff.png\" alt=\"enter image description here\" /></a></p>\n<p>I'd like to know how credible this theory is. Briefly, how is it viewed by academicians, what is the summary of some different opinions surrounding it etc.\nThe wiki is rather silent on such discussions.</p>\n", "pids": ["53e99792b7602d9701f58a2d"], "flag": 1}
{"question": "Online conversation vs face to face interaction", "body": "<p>There are a lot of articles out there about the dangers of internet and some of them talk about the fact that online interactions are nothing compared to face to face conversation. Those sort of articles often say that online conversations can't fulfill the emotional needs you have and that people should talk to their friends in the \"real world\".</p>\n\n<p>Recently, I was reading those article and saying to myself: \"if they say so, it might be true\". However, I now have a really dear online friend with whom I talk every day online and I'm wondering \"is this really true?\".</p>\n\n<p>So, is there any <strong>serious</strong> research comparing a deep online friendship (with instantaneous one on one messaging) vs a \"face to face\" one? And some explanation as to why an online conversation isn't as fulfilling as a face to face one?</p>\n", "pids": ["53e9b4abb7602d9703fb7b1b", "55a4905c65ceb7cb02d1f28c", "5a2b4adf0cf274182519acbe", "53e9aeaab7602d97038cc177", "53e9a9c4b7602d9703321d86", "55a5536565ceb7cb02e85228", "55a6a63e65ce054aad6f545a", "5c756b75f56def97983e3548", "573695776e3b12023e49a26b", "56d8fbcedabfae2eeeb7d572"], "flag": 1}
{"question": "In EEG recording, why ERD or ERS are not phase-locked wheras Bereitschaftspotential is?", "body": "<p>I guess this question is for experts of the domain, but anyway, maybe someone can answer it.</p>\n<p>So in EEG recording ERD and ERS (event related (de)synchronizition) designate short amplitude attenuation (or augmentation) of rythms within the alpha band..</p>\n<p>So, if they are not phase locked it means that when the event appears, the time they actually get trigered by it must vary ?</p>\n<p>On the contrary, for Bereitschaftspotential  (BP), when the event appears, we know exactly when BP will be trigered ?</p>\n<p>Are theses good explanations of the phase-lock and not phase-lock definition ?</p>\n<p>Thank you</p>\n", "pids": ["53e99937b7602d97021734a7", "55a539bc65ceb7cb02e51335"], "flag": 1}
{"question": "Why should I be Bayesian when my model is wrong?", "body": "<p><strong>Edits:</strong> I have added a simple example: inference of the mean of the $X_i$. I have also slightly clarified why the credible intervals not matching confidence intervals is bad.</p>\n\n<p>I, a fairly devout Bayesian, am in the middle of a crisis of faith of sorts.</p>\n\n<p>My problem is the following. Assume that I want to analyse some IID data $X_i$. What I would do is:</p>\n\n<ul>\n<li><p>first, propose a conditional model:\n$$ p(X|\\theta) $$</p></li>\n<li><p>Then, choose a prior on $\\theta$:\n$$ p(\\theta) $$</p></li>\n<li><p>Finally, apply Bayes' rule, compute the posterior: $p(\\theta | X_1 \\dots X_n )$ (or some approximation to it if it should be uncomputable) and answer all questions I have about $\\theta$</p></li>\n</ul>\n\n<p>This is a sensible approach: if the true model of the data $X_i$ is indeed \"inside\" of my conditional (it corresponds to some value $\\theta_0$), then I can call upon statistical decision theory to say that my method is admissible (see Robert's \"The Bayesian choice\" for details; \"All of statistics\" also gives a clear account in the relevant chapter).</p>\n\n<p>However, as everybody knows, assuming that my model is correct is fairly arrogant: why should nature fall neatly inside the box of the models which I have considered? It is much more realistic to assume that the real model of the data $p_{true}(X)$ differs from $p(X|\\theta)$ for all values of $\\theta$. This is usually called a \"misspecified\" model.</p>\n\n<p>My problem is that, in this more realistic misspecified case, I don't have any good arguments for being Bayesian (i.e: computing the posterior distribution) versus simply computing the Maximum Likelihood Estimator (MLE):</p>\n\n<p>$$ \\hat \\theta_{ML} = \\arg \\max_\\theta [ p(X_1 \\dots X_n |\\theta) ] $$</p>\n\n<p>Indeed, according to <a href=\"https://projecteuclid.org/download/pdfview_1/euclid.ejs/1332162333\" rel=\"noreferrer\">Kleijn, v.d Vaart (2012)</a>, in the misspecified case, the posterior distribution:</p>\n\n<ul>\n<li><p>converges as $n\\rightarrow \\infty $ to a dirac distribution centered at a $\\hat \\theta_{ML} $</p></li>\n<li><p>does not have the correct variance (unless two values just happen to be same) in order to ensure that credible intervals of the posterior match confidence intervals for $\\theta$. (Note that, while confidence intervals are obviously something that Bayesians don't care about excessively, this qualitatively means that the posterior distribution is intrinsically wrong, as it implies that its credible intervals do not have correct coverage)</p></li>\n</ul>\n\n<p>Thus, we are paying a computational premium (Bayesian inference, in general, is more expensive than MLE) for no additional properties</p>\n\n<p>Thus, finally, my <strong>question: are there any arguments, whether theoretical or empirical, for using Bayesian inference over the simpler MLE alternative when the model is misspecified?</strong></p>\n\n<p>(Since I know that my questions are often unclear, please let me known if you don't understand something: I'll try to rephrase it)</p>\n\n<p><strong>Edit:</strong> let's consider a simple example: infering the mean of the $X_i$ under a Gaussian model (with known variance $\\sigma$ to simplify even further).\nWe consider a Gaussian prior: we denote $\\mu_0$ the prior mean, $\\beta_0$ the inverse variance of the prior. Let $\\bar X$ be the empirical mean of the $X_i$. Finally, note: $\\mu = (\\beta_0 \\mu_0 + \\frac{n}{\\sigma^2} \\bar X) / (\\beta_0 + \\frac{n}{\\sigma^2} )$.</p>\n\n<p>The posterior distribution is:</p>\n\n<p>$$ p(\\theta |X_1 \\dots X_n)\\; \\propto\\; \\exp\\!\\Big( - (\\beta_0 + \\frac{n}{\\sigma^2} ) (\\theta - \\mu)^2 / 2\\Big) $$</p>\n\n<p>In the correctly specified case (when the $X_i$ really have a Gaussian distribution), this posterior has the following nice properties</p>\n\n<ul>\n<li><p>If the $X_i$ are generated from a hierarchical model in which their shared mean is picked from the prior distribution, then the posterior credible intervals have exact coverage. Conditional on the data, the probability of $\\theta$ being in any interval is equal to the probability that the posterior ascribes to this interval</p></li>\n<li><p>Even if the prior isn't correct, the credible intervals have correct coverage in the limit $n\\rightarrow \\infty$ in which the prior influence on the posterior vanishes</p></li>\n<li><p>the posterior further has good frequentist properties: any Bayesian estimator constructed from the posterior is guaranteed to be admissible, the posterior mean is an efficient estimator (in the Cramer-Rao sense) of the mean, credible intervals are, asymptotically, confidence intervals.</p></li>\n</ul>\n\n<p>In the misspecified case, most of these properties are not guaranteed by the theory. In order to fix ideas, let's assume that the real model for the $X_i$ is that they are instead Student distributions. The only property that we can guarantee (Kleijn et al) is that the posterior distribution concentrates on the real mean of the $X_i$ in the limit $n \\rightarrow \\infty$. In general, all the coverage properties would vanish. Worse, in general, we can guarantee that, in that limit, the coverage properties are fundamentally wrong: the posterior distribution ascribes the wrong probability to various regions of space.</p>\n", "pids": ["5c6108ecda56297340b57ba4", "5f817a1cc6c3b86a50617efd", "5736960f6e3b12023e521fc7", "56d850a4dabfae2eee000a1e", "5f8e9f769e795e9e76f6f5b2"], "flag": 1}
{"question": "What are possible applications for room temperature superconductor requiring extreme presssure?", "body": "<p>At standard room pressure, the highest temperature superconductor is &quot;the cuprate of mercury, barium, and calcium, at around 133 K&quot; (-140 °C).</p>\n<p>If pressure can be increased, however, the record belongs to LaH<span class=\"math-container\">$_{10}$</span> at -23 °C requiring 170 GPa, or possibly <a href=\"https://en.wikipedia.org/wiki/Carbonaceous_sulfur_hydride\" rel=\"nofollow noreferrer\">carbonaceous sulfur hydride</a> at +15 °C requiring 270 GPa.</p>\n<p>(<a href=\"https://en.wikipedia.org/wiki/High-temperature_superconductivity\" rel=\"nofollow noreferrer\">https://en.wikipedia.org/wiki/High-temperature_superconductivity</a>)</p>\n<p>Since -23 °C and 15 °C are commonly encountered conditions in many parts of the Earth, what possible applications might there be for a superconductor at these non-extreme temperatures, but which requires 170-270 gigapascals of pressure to operate?</p>\n", "pids": ["5c0f91b1da562944aca9f4c6"], "flag": 1}
{"question": "Correlation between sexual repression in adolescents and sexual deviancy later in life?", "body": "<p>Is there a correlation between sexual repression and sexual deviancy?</p>\n<p>Now we all have heard stories of people growing up in incredibly strict households that become some of the most exploratory and sexually deviant persons as soon as they get a 'taste of freedom' in college, or kids that went to Catholic schools that seem to stand for the antithesis of everything the Catholic church is as soon as they get out.</p>\n<p>I was wondering, &quot;what gives?&quot; Before, having researched this topic, I just figured that repression of all kinds leads to deviant behavior, but after a search through some databases, I could not find anything that corroborates this belief.</p>\n<p>I did a few Google searches using the keywords Sexual repression and sexual deviance, as well as using the PsycINFO database from Ebsco that my school provides and using the same keywords to no avail. I also did searches of just the single keywords or ideas that vaguely mean the same thing, and I couldn't find what I was looking for.</p>\n<p>Am I just wrong in my assumption, or am I using these words or search terms wrong? I would really appreciate some insight into this topic, thanks everyone!</p>\n", "pids": ["5c0f8989da562944ac995362"], "flag": 1}
{"question": "What are the shortcomings of the Mean Absolute Percentage Error (MAPE)?", "body": "<p>The <a href=\"https://en.wikipedia.org/wiki/Mean_absolute_percentage_error\" rel=\"noreferrer\">Mean Absolute Percentage Error</a> (<a href=\"/questions/tagged/mape\" class=\"post-tag\" title=\"show questions tagged &#39;mape&#39;\" rel=\"tag\">mape</a>) is a common accuracy or error measure for time series or other predictions,</p>\n\n<p>$$ \\text{MAPE} = \\frac{100}{n}\\sum_{t=1}^n\\frac{|A_t-F_t|}{A_t}\\%,$$</p>\n\n<p>where $A_t$ are actuals and $F_t$ corresponding forecasts or predictions.</p>\n\n<p>The MAPE is a percentage, so we can easily compare it between series, and people can easily understand and interpret percentages.</p>\n\n<p>However, I hear that the MAPE has drawbacks. I'd like to understand these drawbacks better so I can make an informed decision about whether to use the MAPE or some alternative like the MSE (<a href=\"/questions/tagged/mse\" class=\"post-tag\" title=\"show questions tagged &#39;mse&#39;\" rel=\"tag\">mse</a>), the MAE (<a href=\"/questions/tagged/mae\" class=\"post-tag\" title=\"show questions tagged &#39;mae&#39;\" rel=\"tag\">mae</a>) or the MASE (<a href=\"/questions/tagged/mase\" class=\"post-tag\" title=\"show questions tagged &#39;mase&#39;\" rel=\"tag\">mase</a>).</p>\n", "pids": ["53e9a782b7602d97030c008b", "5d9ed79547c8f76646004a56", "56d929d8dabfae2eeed1f2f3"], "flag": 1}
{"question": "When does a human baby develop a consciousness?", "body": "<p>Not to offend anyone or anything, but I've been searching up about abortion lately, and all the debate about it, and it got me wondering, when does a baby develop a consciousness?</p>\n\n<p>Consciousness - the ability to sense the world around you in an independent way. You can think for yourself, and make choices that defy your natural instincts. It is what some say separates us from wild animals. Animals have a survival instinct. They do what they can to survive. Eating colourful packets of soap is <em>not</em> an example of a survival instinct, and therefor proves that we have a consciousness.</p>\n\n<p><a href=\"https://psychology.stackexchange.com/questions/5410/definitions-of-consciousness?rq=1\">Definitions of consciousness</a></p>\n\n<p>So when does consciousness begin in a baby? And before that time, how does the brain work? Does it just feel the surroundings without any response? Any help would be greatly appreciated. Thanks!</p>\n", "pids": ["53e9b326b7602d9703df3eb9"], "flag": 1}
{"question": "Why haven&#39;t robust (and resistant) statistics replaced classical techniques?", "body": "<p>When solving business problems using data, it's common that at least one key assumption that under-pins classical statistics is invalid. Most of the time, no one bothers to check those assumptions so you never actually know.</p>\n<p>For instance, that so many of the common web metrics are &quot;long-tailed&quot; (relative to the normal distribution) is, by now, so well documented that we take it for granted. Another example, online communities--even in communities with thousands of members, it's well-documented that by far the largest share of contribution to/participation in many of these community is attributable to a minuscule group of 'super-contributors.' (E.g., a few months ago, just after the SO API was made available in beta, a <em>StackOverflow</em> member published a brief analysis from data he collected through the API; his conclusion--<em>less than one percent of the SO members account for most of the activity on SO</em> (presumably asking questions, and answering them), another 1-2% accounted for the rest, and the overwhelming majority of the members do nothing).</p>\n<p>Distributions of that sort--again more often the rule rather than the exception--are often best modeled with a <em>power law</em> density function. For these type of distributions, even the central limit theorem is problematic to apply.</p>\n<p>So given the abundance of populations like this of interest to analysts, and given that classical models perform demonstrably poorly on these data, and given that robust and resistant methods have been around for a while (at least 20 years, I believe)--why are they not used more often? (I am also wondering why <em>I</em> don't use them more often, but that's not really a question for <em>CrossValidated</em>.)</p>\n<p>Yes I know that there are textbook chapters devoted entirely to robust statistics and I know there are (a few) R Packages (<em>robustbase</em> is the one I am familiar with and use), etc.</p>\n<p>And yet given the obvious advantages of these techniques, they are often clearly the better tools for the job--<em><strong>why are they not used much more often</strong></em>? Shouldn't we expect to see robust (and resistant) statistics used far more often (perhaps even presumptively) compared with the classical analogs?</p>\n<p>The only substantive (i.e., technical) explanation I have heard is that robust techniques (likewise for resistant methods) lack the power/sensitivity of classical techniques. I don't know if this is indeed true in some cases, but I do know it is not true in many cases.</p>\n<p>A final word of preemption: yes I know this question does not have a single demonstrably correct answer; very few questions on this Site do. Moreover, this question is a genuine inquiry; it's not a pretext to advance a point of view--I don't have a point of view here, just a question for which i am hoping for some insightful answers.</p>\n", "pids": ["53e9b321b7602d9703dee117"], "flag": 1}
{"question": "Does anonymity decrease risk aversion?", "body": "<p>I was wondering if anonymity decreases risk-aversion? And if there are studies made in this subject already from which this could be further researched.</p>\n<p>For example. If we imagine a public casino where people wins and loses will be made public for everyone to see, would decrease the amount of risk taken vs a fully private casino.</p>\n<p>And I would like to know if know is this behaviour would extrapolate to other situation, like in social interactions (relationships)</p>\n", "pids": ["56d85e6fdabfae2eee68dc1f", "53e9a408b7602d9702d20541"], "flag": 1}
{"question": "Is there a term/name for the feeling you get when trying to pat your head and rub your tummy?", "body": "<p>I often hear the phrase &quot;It's like patting your head and rubbing your tummy/belly&quot; when referring to trying to perform two seemingly simple actions that inexplicably conflict with each other, preventing one or even both of the actions from being performed well.</p>\n<p>Another popular example involves swinging your right foot in a clockwise motion while trying to draw the number 6.</p>\n<p>It kind of reminds me of &quot;cognitive dissonance&quot;, the uncomfortable feeling you get when holding two contradictory beliefs.</p>\n<p>So is there a word for this sensation? &quot;Operational dissonance&quot; perhaps? I'd love to read more about it, but I've no idea what to search for.</p>\n", "pids": ["53e9b93fb7602d970452d2e1", "53e9b4e9b7602d970401109c"], "flag": 1}
{"question": "How long does an area clean-up help it stay clean?", "body": "<p>Sometime in middle or high school I remember coming across this popular thinking of,\nwhen an area or neighbourhood has some trash, it makes people think it's ok to litter there themselves, and the more trash there is, the more of an unspoken 'norm' littering becomes. However, the hope was that the reverse is also true, and if a neighbourhood's cleaned up, then it signals to people that littering is the anti-norm here.</p>\n<p>But I have gone on trash cleaning walks around my neighbourhood in the past few months, and I can't say that that hope is totally founded. The street by my apartment building has trash reemerge with a vengeance within a week. It makes me think there's some discrepancy in how this is thought about. Like, it's harder to see during night-time, so it absolves you from confronting the results of trash on the grass, and the like.</p>\n<p>Are there long-term studies around (various) neighbourhoods that study this behaviour, and detangle and clarify the different factors at play here? Other studies are good too.</p>\n", "pids": ["5c757d2bf56def9798ab2ae4", "5c7f9a5ce1cd8e08659f4e5e", "5a9f9e67684d03e1ed1bc0dd"], "flag": 1}
{"question": "What&#39;s the exact definition of a cognitive mechanism?", "body": "<p>I've been trying to get to a specific definition of a cognitive mechanism, but googling it surprisingly didn't give me anything. The only things I've found out are :</p>\n<ol>\n<li>How to know if something can be considered a cognitive mechanism :\n<a href=\"https://ajp.psychiatryonline.org/doi/full/10.1176/ajp.155.12.1677\" rel=\"nofollow noreferrer\">https://ajp.psychiatryonline.org/doi/full/10.1176/ajp.155.12.1677</a></li>\n<li>I've come across examples like dissociation, planning fallacy(wrt entrepreneurship) etc.</li>\n</ol>\n<p>They sounded more like cognitive processes, but I'd like a clearer definition of it. I also wanted to know when do we think about cognitive mechanisms vs behavioural mechanisms.</p>\n<p>Would really appreciate the clarity!</p>\n<p>Edit : I first found the term in the paper mentioned in point 1.</p>\n", "pids": ["53e99df7b7602d97026b71e4", "55a46b5365ce31bc8779f364", "5e5e19a193d709897ce7cf74"], "flag": 1}
{"question": "What is verbal memory useful for?", "body": "<p>A friend of mine did the <a href=\"https://humanbenchmark.com/tests/verbal-memory\" rel=\"nofollow noreferrer\">Verbal Memory Test at http://humanbenchmark.com/</a> and got an extremely high score (almost 300 words). English is not his first language and he knew the meaning of only about two thirds of the words (if that's something to take into account).</p>\n<blockquote>\n<p>About the test</p>\n<p>This test measures how many words you can keep in short term memory at once.</p>\n<p>The number of words you need to remember grows continually, until you can't keep them in your head anymore.</p>\n<p>Go as long as you can. You have 3 strikes until game over.</p>\n<p>Your score is how many turns you lasted.</p>\n</blockquote>\n<p>Does this have any practical use or influence in other areas of cognition?</p>\n", "pids": ["56d8d751dabfae2eeed563f2", "53e9b029b7602d9703a8764e", "56ae9e900cf2a8c8f71499f1"], "flag": 1}
{"question": "Is it allowed for a psychologist to claim to be a friend of the patient", "body": "<p>Is there any ethical/therapeutical guidelines preventing a psychologist to claim to be a friend of the patient?</p>\n<p>The relevant points are:</p>\n<ul>\n<li><p>I am aware that there <a href=\"https://psychology.stackexchange.com/questions/21441/can-a-friend-become-a-therapist\">are rules against treating friends</a>,  and I have even found references to disciplinary actions when the relationship started after the treatment.</p>\n</li>\n<li><p>But here there is no relationship other than the professional one. Patient and psychologist did not knew before treatment, do not meet outside of practice hours, and do not develop any social activity that could be interpreted as friendship. It is just the therapist claiming to be a friend.</p>\n</li>\n<li><p>OTOH, there is no ill-intent. No &quot;I am your friend, so tell me your credit card number&quot; schema or anything like that.</p>\n</li>\n</ul>\n<p>Could this kind of action be considered as going against ethical/therapeutical principles?</p>\n<p>If a country is needed, it would be in Spain, although I am asking just to inform myself so I would be ok with an &quot;universal&quot; answer if that is possible.</p>\n", "pids": ["55a49f0f65ceb7cb02d46c6c"], "flag": 1}
{"question": "What measure or criteria wording can be used to track trends in p factor?", "body": "<p>Background: you can use factor analysis on mental illness to get a general psychopathology factor, like the g factor in intelligence but instead a general mental illness factor.</p>\n<p><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4209412/\" rel=\"nofollow noreferrer\">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4209412/</a></p>\n<p>Intent: I am interested in using a forecast aggregation platform to predict whether we will discover a Flynn effect like trend in p factor, either up or down.\n<a href=\"https://www.metaculus.com/questions/\" rel=\"nofollow noreferrer\">https://www.metaculus.com/questions/</a></p>\n<p>Caveat: Flynn may be hollow for g, and in theory something like that could happen with a p factor trend too.  That's fine. Our forecast question can be agnostic about the nature of the trend, in order to be reliably resolvable without too much administrative effort.</p>\n<p><em>Specific need:</em> what simple metric, or criteria wording, could be shown to the forecasters, such that they could predict something that will reliably resolve? In forecasting, the event description must be unambiguous.  This is harder than people new to forecasting tend to expect.  One thing that might affect our criterion choice is how we think future researchers will measure such a thing, as piggybacking off already-reported metrics can make forecast question-writing easier.</p>\n<p>E.g. suppose if we had the following wording: &quot;Will there be data to support a trend in the p factor, at least equivalent to an average 2 IQ point-per-decade change, either up or down, during any 10-year period before 2040?&quot;  Would it be easy for people not working in any related field to kind of just, do a cursory search around 2040 (or every few years) and clearly tell if such a thing has happened? If not, what would be a better way to word it?</p>\n<p>Any input appreciated!</p>\n", "pids": ["55a6649265ce054aad664ae8", "5c0f9174da562944aca98794", "5ce3a74aced107d4c653a854", "53e9ad0ab7602d97036e7916", "5e85c26d9fced0a24bdfcabf", "61c8e9905244ab9dcb77eab1", "5548db350cf2abac7d0411ee"], "flag": 1}
{"question": "Are there methods of evaluating the effects of psychoactive drugs that use free-form verbal reports?", "body": "<p>If one wished to study the effects of a psychoactive drug such as LSD, what strikes me as a natural primary starting point would be to ask participants what they actually experienced.  For example, they could write a page in response to a simple question about what the experience was like.</p>\n<p>The results could then be analyzed using an approach such as <a href=\"https://en.wikipedia.org/wiki/Natural_language_processing\" rel=\"nofollow noreferrer\">natural language processing</a>, to find common themes in reported effects.  This analysis would then be open to peer-review and replication.</p>\n<p>Is this a method of research that anyone currently practices in psychology?</p>\n", "pids": ["5f8a0870db0c4ff2316491a9", "5ff682c3d4150a363cbb0083"], "flag": 1}
{"question": "How are genetic behaviors expressed?", "body": "<p>There are some behaviors that are clearly genetic and not learned, such as insect dance patterns.</p>\n<p>How are such behaviors expressed in the organism?</p>\n<p>Do the genes specifically code for some neural circuitry that is always the same when it is present in the genome?</p>\n<p>So if the gene is absent, is that neural structure just absent?</p>\n<p>My understanding is that genes code for proteins. So how can a group of genes lead to such complex behaviors by just being expressed as some proteins?</p>\n", "pids": ["55a4dadb65ceb7cb02da1e55", "53e99d65b7602d970261e79c"], "flag": 1}
{"question": "Can molecular genetics make a boolean variable from a continuous variable?", "body": "<p>In the same kind of idea than <a href=\"https://biology.stackexchange.com/questions/30116/does-dna-have-the-equivalent-of-if-statements-while-loops-or-function-calls-h\">this question</a>. Gene expression are regulated through complex interactions. The concentration of enhancers and repressors is an important aspect that dictate the level of expression of a given gene. These concentrations can take different value on a continuous scale.</p>\n\n<p>Imagine a case where fitness is maximized when a given gene produce <code>n</code> proteins per minute if the concentration of a given protein is greater than <code>x</code>. If the concentration of the protein was to be lower than <code>x</code>, then the gene should not be expressed (0 proteins per minute are produced). In such case, it would be great if a bunch of reactants were to be able to simulate a \"switch function\" that would switch from \"NO EXPRESSION\" to \"EXPRESSION\" at <code>x</code>.</p>\n\n<p>It seems to me that such switch function should be very complicated to evolve. I would suspect that all chemical reactions, including the binding of enhancer to promoter region should follow the law of Michaelis-Menten and the Michaelis-Menten function is not at all switch function. So, I have been thinking about cooperative binding. <a href=\"http://en.wikipedia.org/wiki/Hill_equation_(biochemistry)\" rel=\"nofollow noreferrer\">Hill's equation</a> describes a function that is effectively a switch function given that the hill coefficient is high enough. However, seeking a bit in the literature, it's seems that the Hill coefficient never really overpass 3 (or 5 for extreme estimates). A Hill coefficient of within this range gives a logistic function but still looks quite suboptimal compared to what a perfect switch function could do.</p>\n\n<p><strong>Are there switch functions in molecular genetics that could translate a concentration into a TRUE/FALSE signal?\nHow well do they simulate the perfect switch function?\nAre they based on cooperative binding or on some other mechanism?</strong></p>\n\n\n\n<p>References for estimate of Hill coefficients:</p>\n\n<ul>\n<li><sub><a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1435008/pdf/biophysj00200-0109.pdf\" rel=\"nofollow noreferrer\">http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1435008/pdf/biophysj00200-0109.pdf</a></sub></li>\n<li><sub><a href=\"http://onlinelibrary.wiley.com/doi/10.1046/j.1537-2995.1983.23283172857.x/abstract\" rel=\"nofollow noreferrer\">http://onlinelibrary.wiley.com/doi/10.1046/j.1537-2995.1983.23283172857.x/abstract</a></sub></li>\n<li><sub><a href=\"http://www.pnas.org/content/93/19/10078.short\" rel=\"nofollow noreferrer\">http://www.pnas.org/content/93/19/10078.short</a> </sub></li>\n<li><sub><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/8816754\" rel=\"nofollow noreferrer\">http://www.ncbi.nlm.nih.gov/pubmed/8816754</a> </sub></li>\n<li><sub><a href=\"http://www.fasebj.org/content/11/11/835.short\" rel=\"nofollow noreferrer\">http://www.fasebj.org/content/11/11/835.short</a> </sub></li>\n<li><sub><a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2816740/\" rel=\"nofollow noreferrer\">http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2816740/</a></sub></li>\n</ul>\n", "pids": ["55a46c08c91b587b097b5aee"], "flag": 1}
{"question": "Is aphantasia an inability to record memories, or an inability to recall memories?", "body": "<p>People with aphantasia are unable to <em>voluntarily</em> create or recall mental images.<br />\nThis can extend to non-visual memory too (e.g. remembering <em>that</em> they heard a loud bang, but not remembering the sound of the loud bang itself).</p>\n<p>Everything I've read talks about the overall symptoms, but not about the underlying mechanism.</p>\n<p>Does the mind correctly record memories (which can't be recreated), or does it fail to record sensory memories in the first place?\nI.e. is the memory failure in the recording or in the recalling?</p>\n", "pids": ["618116075244ab9dcbee8144", "5ef328289fced0a24be66c99", "5ecce9ad9fced0a24bdbc056", "5f6417da9fced0a24bdcb4d4", "613742455244ab9dcb0ad199"], "flag": 1}
{"question": "Is there any evidence that accepting, affirming parenting is associated with less child depression?", "body": "<p>Is there any evidence that children of parents who are accepting and affirming in general of their children have lower rates of depression?</p>\n<p>I mean the opposite of personally critical, negating, condemning or negatively judging (which could be towards one child and not another); as well as cooperating with their children’s desires and wishes rather than rejecting, forcing, or controlling them.</p>\n", "pids": ["56ab70da0cf2c98bf5bc75c1", "5c8dcca64895d9cbc6a27966", "5c6bfa76e1cd8e6642f1bb8c", "563e05e60cf219a1e1f70934"], "flag": 1}
{"question": "How does Panchang predict agricultural conditions?", "body": "<p>There are research papers which mention that panchangs are more accurate than IMD in terms of climate prediction. Moreover, I read that there are multiple predictions possible, over and above rainfall prediction.\nCan I know if there is any document/book which discusses how this is calculated?\nI would like to know how it is calculated, and not the links where predictions are available.</p>\n", "pids": ["622913125aee126c0f77cf3a"], "flag": 1}
{"question": "Golden ratio in hinduism", "body": "<p>Christianity talks of the golden ratio. I have read about it from the Da Vinci Code. Is there anything similar to the golden ratio in Hinduism?</p>\n", "pids": ["53e9bb67b7602d97047a79b2"], "flag": 1}
{"question": "Was Ravana&#39;s Lanka not the present day Sri Lanka?", "body": "<p>Many people are thinking and confidently stating that Ravana's Lanka is in fact present day Sri Lanka, situated south-east of India.</p>\n\n<p>However, the narration given by Sage Valmiki in Sundara Kanda gives a different picture about the location of Ravana's Lanka.</p>\n\n<ol>\n<li>After flying 100 Yojanas over the ocean and reaching Lanka,  Sri Hanuman observes the scenic beauty of flora  of the Lanka.  Sage Valmiki describes elaborately in Sundara Kanda.</li>\n</ol>\n\n<blockquote>\n  <p>संततान् विविधैर्वऋकैः सर्वर्तुफलपुष्पितैः | <br> \n  उद्यानानि च रम्याणि ददर्श कपिकुञ्जरः ||   </p>\n  \n  <p>(Sundara Kanda 2nd Sarga 13th Sloka)</p>\n  \n  <p>Hanuman saw various glorious pleasure-groves filled by various trees\n  that give fruits and flowers in all seasons and beautiful gardens.</p>\n</blockquote>\n\n<ol start=\"2\">\n<li>After reaching Asoka Garden, Sri Hanuman observes the beautiful flora in that Garden.</li>\n</ol>\n\n<blockquote>\n  <p>नन्दनम् विविध उद्यानम् चित्रम् चैत्ररथम् यथा || ५-१५-११ <br></p>\n  \n  <p>अतिवृत्तम् इव अचिन्त्यम् दिव्यम् रम्यम् श्रिया वृतम् | <br>\n  द्वितीयम् इव च आकाशम् पुष्प ज्योतिर् गण आयुतम् || ५-१५-१२ <br></p>\n  \n  <p>पुष्प रत्न शतैः चित्रम् पन्चमम् सागरम्य था | <br>\n  सर्व ऋतु पुष्पैर् निचितम् पादपैर् मधु गन्धिभिः || ५-१५-१३ <br></p>\n  \n  <p>नाना निनादैः उद्यानम् रम्यम् मृग गणैर् द्विजैः | <br>\n  अनेक गन्ध प्रवहम् पुण्य गन्धम् मनो रमम् || <br></p>\n  \n  <p>(Sundara Kanda 15th Sarga 11 -14th Slokas)</p>\n  \n  <p>Like the garden of Nandana, a celestial garden, wonderful like\n  Caitraratham, a garden of Kubera, surpassing all, unfathomable, an\n  excellent one, a beautiful one consisting of glory together with\n  flowers like clusters of stars, like a second sky wonderful with\n  flowers, like hundreds of diamonds, like a second ocean with flowers\n  of all seasons, spread with trees having the smell of honey, beautiful\n  with groups of animals of various sounds, diffused with many smells\n  with an auspicious soul pleasing smell.</p>\n</blockquote>\n\n<p>It is necessary to study the following phrase used by Sage Valmiki :</p>\n\n<blockquote>\n  <p>सर्वर्तुफलपुष्पितैः   -   Trees that give fruits and flowers in all\n  seasons</p>\n</blockquote>\n\n<p>Modern <a href=\"http://people.wku.edu/charles.smith/wallace/S288.htm\">research</a> revealed that the equatorial zone on the Earth has the special climatic feature of allowing the trees to bear flowers and fruits in all seasons.</p>\n\n<blockquote>\n  <p>The various causes now enumerated are sufficient to enable us to understand how the great characteristic features of the climate of the equatorial zone are brought about; how it is that so high a temperature is maintained during the absence of the sun at night, and why so little effect is produced by the sun's varying altitude during its passage from the northern to the southern tropic.</p>\n  \n  <p>As a result of this condition of the earth and atmosphere, there is no check to vegetation, and little if any demarcation of the seasons. Plants are all evergreen; flowers and fruits, although more abundant at certain seasons, are never altogether absent; while many annual food-plants as well as some fruit-trees produce two crops a year. In other cases, more than one complete year is required to mature the large and massive fruits, so that it is not uncommon for fruit to be ripe at the same time that the tree is covered with flowers, in preparation for the succeeding crop. </p>\n</blockquote>\n\n<p>Sri Hanuman flew 100 Yojanas over the ocean.</p>\n\n<p>1 Yojana = 13 Kms (approx.)</p>\n\n<p>Hence, Sri Hanuman flew 1,300 Kms. over the ocean.</p>\n\n<p>We have to calculate the aerial distance from Southern tip of India to Northern tip of Lanka only, as Sri Hanuman flew 100 Yojanas over the ocean to reach Ravana's Lanka.</p>\n\n<p>The Latitude and Longitude of Sri Lanka at Jaffna, the Northern tip of Sri Lanka, is 09°45'N and  80°02'E.  </p>\n\n<p>Hence, Sri Lanka cannot be Ravana's Lanka.</p>\n\n<p>Am I correct?</p>\n", "pids": ["53e9ba17b7602d970461d8f4"], "flag": 1}
{"question": "How easy is it to carry out de novo sequence assembly?", "body": "<p>Today a colleague of mine asked the following question:</p>\n<blockquote>\n<p>&quot; Assuming I need to build from 0, a chromosome of a fish, with short reads\nbut no other reference whatsoever <strong>[de novo assembly]</strong>:</p>\n<ul>\n<li>how much work is that?</li>\n<li>Is there a generic software (like SAMtools) that will align the reads in a\nscaffold one can use?</li>\n<li>Basically, given a reasonably clear pipeline in terms of software, is it still blood sweat and tears or is it just a matter of getting it on a cluster?&quot;</li>\n</ul>\n</blockquote>\n<p>Very grateful for any suggestions, sources of information, software etc.</p>\n", "pids": ["55a5ec0865cead59c82faddb"], "flag": 1}
{"question": "What is the meaning of behaviorally oriented outside-in nature of therapy?", "body": "<p>What is the meaning of behaviorally oriented outside-in nature of therapy? I am especially interested why this outside-in word was used but please provide me a wider context of this type of therapy. Especially as it is meant on the following page.</p>\n\n<p><a href=\"https://www.sheknows.com/health-and-wellness/articles/1126691/depression-treatment-behavioral-activation/\" rel=\"nofollow noreferrer\">https://www.sheknows.com/health-and-wellness/articles/1126691/depression-treatment-behavioral-activation/</a></p>\n\n<p>Could you possibly give some resources such as scholarly articles or book chapters where this method is used? My problem is that I am a non-expert on psychotherapy but need a starting point on the above issue. Thank you.</p>\n", "pids": ["53e9b754b7602d97042f3102"], "flag": 1}
{"question": "Are there known examples where an evolved mechanism &quot;echoes&quot; one originally provided by the environment?", "body": "<h2>Short summary</h2>\n\n<p>I am a researcher in origins of life, a field that deals with hypotheses about evolutionary processes that took place before LUCA (the last universal common ancestor), and with the chemical processes that gave rise to life and evolution in the first place. This is very hard to study empirically, and as a consequence there are many competing hypotheses. However, I've noticed that many of them have a common form, which I will describe below. My question is about whether hypotheses of this particular form exist (and have been investigated, for example using phylogenetic methods) in post-LUCA evolutionary biology.</p>\n\n<p>My reason for asking is that my colleagues and I were not able to think of a good example. If no example is known in post-LUCA evolutionary biology then it casts doubt on the plausibility of this type of hypothesis in pre-LUCA evolution. I suspect this is the case, and therefore my ideal answer would provide me with bibliographic material to support a claim that there just aren't any good examples of this in evolutionary biology. However, I would also be happy to be proven wrong with a really good example.</p>\n\n<h2>Longer explanation</h2>\n\n<p>Hypotheses regarding the origins of life are difficult to test empirically, because phylogenetic methods can give us little direct evidence about anything before LUCA, and because there are no fossils dating from that time. (The entirety of Earth's surface has since been replaced by plate tectonics.) Consequently there are a number of competing hypotheses that differ from one another in almost every way. However, I've noticed that many of them have a common form: they say that </p>\n\n<ol>\n<li><p>one or more of the features of a modern (i.e. post-LUCA) cell were originally provided by an external mechanism, in the form of abiotic chemical processes that took place in some very specific microenvironment, and</p></li>\n<li><p>evolution eventually provided a solution that very closely echoed the one that had originally been provided by the environment.</p></li>\n</ol>\n\n<p>Point (1) seems relatively easy to satisfy in an evolutionary scenario; it's point (2) that I'm specifically interested in. The two most popular hypotheses in the field both have this form:</p>\n\n<ul>\n<li><p>Some forms of the The <a href=\"https://en.wikipedia.org/wiki/RNA_world_hypothesis\" rel=\"nofollow\">RNA-World hypothesis</a> hold that originally, RNA nucleotides were produced by purely chemical processes in the environment, and that life evolved from self-replicating RNA molecules made up from these abiotically-produced monomers. Later, life evolved a cellular metabolism by which it could construct its own RNA monomers. This satisfies point (2) because it says that the environment provided RNA rather than some other heteropolymer with catalytic properties; the evolutionary solution echoes the environmental one in that it uses the same complex molecule.</p></li>\n<li><p>Wächterschäuser's <a href=\"https://en.wikipedia.org/wiki/Iron%E2%80%93sulfur_world_theory\" rel=\"nofollow\">Iron-Sulphur World</a> theory, and many of its descendants, including Russel's <a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2442388/\" rel=\"nofollow\">alkaline vent theory</a>, hold that the reductive tricarbolic acid cycle (rTCA cycle, aka reverse citric acid cycle) was originally catalysed by mineral surfaces. This enabled the formation of the first cells, which eventually evolved enzymes that could be used to catalyse the rTCA cycle without the mineral catalysts. This satisfies point (2) because it says that the first evolved solution used essentially the same chemical pathway as the one provided by the environment, just with different catalysts.</p></li>\n</ul>\n\n<p>(Not all hypotheses in origins of life have this form. Some versions of the RNA World theory hold that RNA-based life was preceded by life based on some other heteropolymer, for example. But the hypotheses described above are very popular.)</p>\n\n<p>From an evolutionary biology point of view, point (2) seems rather an odd feature for a hypothesis to have. Evolution is great at producing novel solutions to problems, but to my knowledge it isn't good at copying old ones. (Mimicry doesn't provide a counterexample to this, since it's about appearance rather than mechanism, and often the mimic produces the same visual effect through a very different mechanism. For example, although the treehopper Cyphonia clavata mimics the outward appearance of an ant, it does so not by being anatomically similar to an ant but by <a href=\"http://www.sciencedirect.com/science/article/pii/S0960982211004222\" rel=\"nofollow\">having a face on its butt</a>.) </p>\n\n<p>Consequently I'm looking for known examples from evolutionary biology that satisfy both point (1) and point (2). That is, I'm looking for examples where a species originally relied on some relatively complex process in its environment, and became less dependent on its environment <em>by evolving a mechanism that closely echoes the one originally provided by the environment</em>.</p>\n\n<p>An example that might fit the bill would be a species that was originally unable to produce a key metabolite (e.g. an amino acid), but then later evolved the ability to produce the metabolite for itself. Evidence for this might be constituted by finding a species that produces the metabolite using a novel set of proteins, indicating that the capability to produce the metabolite was lost and then re-evolved. It would make an even better example if the novel proteins catalyse substantially the same chemical pathway that other species use to produce the same metabolite.</p>\n\n<p>It may be that no good examples of this exist, which is actually better for me than if they do. More than any particular example, the main thing I want to know is whether ideas along these lines have been discussed in evolutionary biology at all (perhaps outside the context of the origins of life), and if so where I can find the literature on it.</p>\n", "pids": ["55a6638265ce054aad65f40d"], "flag": 1}
{"question": "Which study proved that macaques were superior to humans in recalling in which some items appeared?", "body": "<p><strong>Which studies proved that macaques were superior to humans in recalling in which a sequence of items appeared?</strong></p>\n<p>I saw a video which reported on an experiment using computers, macaques and humans, I believe from the 80s or 90s:</p>\n<ul>\n<li>subjects (humans and macaques) played a video game and macaques performed vastly better than humans;</li>\n<li>the games consisted of two phases:\n<ol>\n<li>in the first phase, a sequence of items (numbers, I believe) appear on the screen in distinct positions, at regular interval;</li>\n<li>in the second phase, the items are masked, and the subject is asked to select the items in the order in which they appeared.</li>\n</ol>\n</li>\n<li>increasing the length of the sequence and reducing the time each item is shown quickly lost the human subjects, when the macaques subjects could play on instances which no humans answered correctly.</li>\n</ul>\n<p>I would be interested in designing a software to repeat such experiment using modern computing devices such as tablets and smart phones, with other species of animals other than humans, but could not find the reference of the original study, nor whether similar studies had been performed since.</p>\n", "pids": ["5d7e0fa247c8f76646dc50f7", "53e9acb5b7602d9703694f8f"], "flag": 1}
{"question": "What is the biological limit on hearing resolution?", "body": "<p>I sometimes wonder how many different individual musical scales could be perceived by human ears. I define a musical scale as a collection of notes that relate to some fundamental frequency by specific ratios. For instance</p>\n\n<ul>\n<li>do $2^{0}f$</li>\n<li>re $2^{\\frac{1}{6}}f$</li>\n<li>mi $2^{\\frac{1}{3}}f$</li>\n<li>fa $2^{\\frac{5}{12}}f$</li>\n<li>sol $2^{\\frac{7}{12}}f$</li>\n<li>la $2^{\\frac{9}{12}}f$</li>\n<li>ti $2^{\\frac{11}{12}}f$</li>\n<li>do $2^{1}f$</li>\n</ul>\n\n<p>I once did an experiment where I took various sine waves at different frequencies and multiplied them by the appropriate ratios. I found for the ones I tried that I did indeed heard the major scale. But a mathematician will look at the positive real numbers $\\Bbb{R}^+$ and say there are an infinite, uncountable number of possible frequencies. However, Biologically I cannot imagine the human ear is capable of distinguishing between an infinite number of frequencies.  </p>\n\n<p>What is the biological limit on hearing resolution? Is there a way to estimate how many different major scales one can hear? In other words, how many different frequencies can be heard? </p>\n", "pids": ["53e9bde2b7602d9704a96982"], "flag": 1}
{"question": "What is the biochemical explanation for tingling and burning sensation in brain due to certain food?", "body": "<p>Consumption of mustard (spicy English Mustard), wasabi and horseradish based food dressings usually result in a burning, tingling or freezing sensation in the brain/scalp and nostrils as the vapour goes through the nasal cavity. </p>\n\n<p>I read somewhere, the checmical which gives the burning sensation is <strong>isothyocyanates</strong>. And some of the posts roughly mention about sinuses being agitated due to this chemical vapour.</p>\n\n<p>How to explain this from biochemical and biology aspect? e.g. What sort of a cell reaction, if any receptors involved etc. (Appreciate an answer that is <a href=\"https://youtu.be/R8JMfbYW2p4\">similar to <strong>the type of explanation</strong> here.</a>)</p>\n", "pids": ["53e9abdab7602d97035957ca"], "flag": 1}
{"question": "Does the human eye have a muscle that if paralyzed would make us only see things that are in motion?", "body": "<p>In &quot;K<a href=\"https://www.scribd.com/document/362019220/Kwantechizm-pdf\" rel=\"nofollow noreferrer\">wantechizm</a>&quot;, a relatively popular book written by a Polish physicist Andrzej Dragan, I read that chickens move their head so that they can see things that are not in motion, with the following comment:</p>\n<blockquote>\n<p>(...) It is similar with humans, because our eye is built on a similar principle to that of a chicken's eye. But to avoid the need to bend the head, it has special muscles that make it vibrate quickly. It is only thanks to these vibrations that we can see anything. If someone does not believe, they can inject a special injection into their eye to relax the muscles and the eye will stop twitching and everything that is still around will become invisible. Only the things that will move by themselves will emerge from the complete blackness.</p>\n</blockquote>\n<p>(translated using Google Translate)</p>\n<p>Is that true? Which muscle could he be talking about?</p>\n", "pids": ["53e9a812b7602d9703153a95"], "flag": 1}
{"question": "Winnicott and Ogden : Fear of breakdown and &#39;reliving&#39;", "body": "<p>I've been reading some text from Winnicott and Ogden about &quot;The Fear of Breakdown&quot; and the unlived life.</p>\n<p>Ogden, T. H. (2016) wrote this about Winnicott's previous work in <em>Reclaiming unlived life: experiences in psychoanalysis</em>;</p>\n<blockquote>\n<p>So, the past event that occurred, but was not experienced, continues to\ntorment the patient until it is lived in the present (with the mother/analyst).\nAnd yet, despite the beauty of Winnicott’s response to the question he poses, I find his answer incomplete. It seems to me that <em>a principal, if not the principal motivation for an individual who has not experienced important parts of what happened in his early life is the urgent need to lay claim to those lost parts of himself, to finally complete himself by encompassing within him-self as much of his unlived (unexperienced) life as he is able</em>. I read this as a universal need – the need on the part of every person to re-claim, or claim\nfor the first time, what he has lost of himself and, in so doing, take the\nopportunity to become the person he still holds the potential to be. One\ndoes so despite the fact that attempting to realize that potential to become more fully oneself involves experiencing the pain (of breakdown and the primitive agony that results from breakdown), which had been too much to bear in infancy and childhood and has led to the loss of important aspects of self</p>\n</blockquote>\n<p>My question is, does this mean the person actually unconciously wants to repeat the feeling they had during the childhood trauma?</p>\n", "pids": ["53e9aab7b7602d9703436591"], "flag": 1}
{"question": "How does NHEJ cause indels?", "body": "<p>I was reading up on CRISPR-cas9 and how it works and I am having trouble wrapping my head around how NHEJ to repair the DSB can cause indels to occur. Shouldn't the NHEJ just stick the two strands of DNA back together?</p>\n\n<p>I believe I read somewhere that if other agents cause a DSB, such as certain chemicals, they can also damage / cleave nucleotides ; the damaged nucleotides would have to be removed and overhangs filled in by polymerase before the ligation, which could result in the errors that NHEJ is famous for.</p>\n\n<p>Since cas9 does not cause such damage, how can it result in an indel?</p>\n\n<p>Thanks.</p>\n", "pids": ["55a60d5c65cead59c833876e", "55a38f5d65ce5cd7b3ae9fde"], "flag": 1}
{"question": "Have psychologists recognized how some people feel more embarrassment?", "body": "<p>Is there a personality subtype where it’s really common to feel embarrassed about one's past self, like cringing about something you said, wrote, or did some time ago?  It may change over time, but I think some people just naturally have this inclination, like a propensity towards social anxiety.</p>\n<p>Is this a known phenomenon?</p>\n", "pids": ["5c0f830fda562944ac8b8183", "53e9a4ebb7602d9702e0908b", "53e99a1ab7602d97022703df", "53e99a4eb7602d97022b04ac", "5ce2d0fdced107d4c63dca9b"], "flag": 1}
{"question": "How does psychological exhaustion work?", "body": "<p>Let's say I am studying a subject X. I believe as the time spent on the subject X increases, the marginal rate of knowledge gained per unit time decreases to almost nothing. This reduce is associated with a general feeling of &quot;being tired&quot;.</p>\n<p>Why does this happen?</p>\n", "pids": ["53e9b4b9b7602d9703fcf1ca", "53e99a26b7602d970227bd29"], "flag": 1}
{"question": "Do we consume DNA and proteins of other organisms?", "body": "<p>When we eat raw meat, e.g. chicken or fish, we are actually consuming the DNA, proteins etc. which are present in their cells. </p>\n\n<ol>\n<li><p>Wouldn't this affect our cell functions as this DNA might enter our cells?</p></li>\n<li><p>It is known that we get energy by eating them. Is it glucose or ATP or some other form of energy that is produced from them? </p></li>\n</ol>\n", "pids": ["55a50b2265ceb7cb02df4adb", "55a4664765ce31bc87795353"], "flag": 1}
{"question": "What are disadvantages of using the lasso for variable selection for regression?", "body": "<p>From what I know, using lasso for variable selection handles the problem of correlated inputs. Also, since it is equivalent to Least Angle Regression, it is not slow computationally. However, many people (for example people I know doing bio-statistics) still seem to favour stepwise or stagewise variable selection. Are there any practical disadvantages of using the lasso that makes it unfavourable?</p>\n", "pids": ["5c75705cf56def97986e5d98"], "flag": 1}
{"question": "Is there any scientific evidence that nootropics improve synaptic plasticity / learning ability?", "body": "<p>I'm attempting to learn a very specific skill (perfect pitch) and I'm considering nootropic supplements.</p>\n\n<p>While I can find plenty of websites offering these supplements and making big claims, I can't find any rigourous scientific experiments backing these claims.</p>\n\n<p>On the other hand I can't find any rigourous scientific experiments debunking them.</p>\n\n<p>I would imagine such an experiment would not be too hard to set up; for example, performance on a simple \"pairs\" card game could give a measure of short-term memory.</p>\n\n<p>How might I intelligently go about searching for such experimental results?</p>\n", "pids": ["55a52fc165ceb7cb02e3a016"], "flag": 1}
{"question": "What is global max pooling layer and what is its advantage over maxpooling layer?", "body": "<p>Can somebody explain what is a <a href=\"https://keras.io/layers/pooling/\" rel=\"noreferrer\">global max pooling</a> layer and why and when do we use it for training a neural network. Do they have any advantage over ordinary max pooling layer?</p>\n", "pids": ["5550412645ce0a409eb38dd9", "53e99838b7602d970205eb3b"], "flag": 1}
{"question": "Nicotine levels in non fruit/edible parts of plants (that are not tobacco)", "body": "<p>I am an ex smoker who now vapes (uses e-cigs). Various authorities are equating vaping with smoking by calling it a 'tobacco product' - which is in a sense true given that the majority of nicotine sold is extracted from the leaves of tobacco. I am interested in the practicality (or otherwise) of extracting nicotine from other botanical sources.</p>\n\n<p>Of course, it is not just tobacco that contains nicotine, it is common in other plants of the nightshade family, as suggested by <a href=\"http://www.nejm.org/doi/full/10.1056/NEJM199308053290619\" rel=\"nofollow noreferrer\">The Nicotine Content of Common Vegetables</a> &amp; <a href=\"https://en.wikipedia.org/wiki/Nicotine#Occurrence_and_biosynthesis\" rel=\"nofollow noreferrer\">Nicotine: Occurrence and biosynthesis</a>. The second source notes:</p>\n\n<blockquote>\n  <p>Nicotine is a natural product of tobacco, occurring in the leaves in a range of 0.5 to 7.5% depending on variety.[84] Nicotine also naturally occurs in smaller amounts in plants from the family Solanaceae (such as potatoes, tomatoes, and eggplant).[85] </p>\n</blockquote>\n\n<p>Reference 85 points back to the first link, which shows this table.</p>\n\n<p><a href=\"https://i.stack.imgur.com/VoHfY.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/VoHfY.png\" alt=\"Table of nicotine levels in common food plants\"></a></p>\n\n<p>But looking at the numbers, it seems unlikely. At even .5%, the 'low nicotine' tobacco leaf comes in at 5 mg/g, which is 5,000,000 ng/g - around 50,000 times more concentrated than eggplant. In fact, here is a graph of the log<sub>10</sub> value (2 is <strong><em>ten times larger</em></strong> than 1) of each.</p>\n\n<p><a href=\"https://i.stack.imgur.com/QvhsP.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/QvhsP.png\" alt=\"enter image description here\"></a></p>\n\n<p>On the other hand, the ability of a plant to produce nicotine is retained and handed down to ancestors because <em>nicotine is a pesticide</em> that ..discourages insects from eating the plant, and larger herbivores will also get sick if they eat too much of it. Logically, levels of nicotine would be higher in the leaves and stems of a plant than in the fruits/food that we &amp; animals are more interested in eating. That again makes sense, since most fruits are 'designed' to be put through the stomach of a larger animal as part of the process of regeneration.</p>\n\n<p>That logic seems to be borne out by the levels of nicotine in tomatoes, that start around 40 ng/g in green tomatoes, but end up at just over 4 ng/g in ripe tomatoes (not sure what's going on with that 'pureed tomato' level of over 50 ng!). The drop suggests to me that's the plant's way of preventing consumption while the fruits are still developing, but making them safe(r) to eat once ripe.</p>\n\n<p>But what about the nicotine content in the leaves of those plants? Logically they might have a higher nicotine content. Does anyone know of studies of the levels of nicotine in the <em>other parts</em> of plants of the nightshade family?</p>\n", "pids": ["621846f55aee126c0f4e68bb"], "flag": 1}
{"question": "Is using tensorflow for Spiking neural networks a &quot;good&quot; idea?", "body": "<p>I recently started working with Spiking Neural Networks and was hoping for some input from others. I saw there were many libraries/platforms specifically made for working with SNN's (Brian, PyNN, NEURON, etc...) however I was wondering if there were any tradeoffs in using plain, old popular Tensorflow for SNN implementation. Is there a reason that it is underresearched? Has anyone tried or working on this?</p>\n<p>Thanks for any feedback anyone can offer,</p>\n", "pids": ["5c8fb9c24895d9cbc65dcabc", "608937b3e4510cd7c8639cd3"], "flag": 1}
{"question": "What causes humans to be physically weak compared to animals like gorillas?", "body": "<p>Animals like gorillas seem to have a physical fitness and muscle mass that don't depend as strongly on how much exercise they get, compared to humans. E.g. gorillas living in the wild sleep and rest a lot. While they do get quite a bit of exercise (a lot more than the average human), they are not going to exert themselves much more than is necessary. So, they push themselves a lot less than people who exercise very hard. Yet the average gorilla would easily outperform even a well trained human being in bodyweight exercises.</p>\n\n<p>So, there seems to be something fundamentally different about maintaining physical fitness in humans compared to gorillas.</p>\n", "pids": ["53e9aabdb7602d970343d66c"], "flag": 1}
{"question": "Can radiation therapy cause cancer?", "body": "<p>Radiation therapy is a very popular cancer treatment method. But can it have any risk for make a different cancer? Because i think that radiation exposure can make DNA mutation and thus increase the risk to cause cancer, so why we still use radiation to treat cancer? That's so contradictory.</p>\n", "pids": ["55a57b88612c6b12ab1e27ce"], "flag": 1}
{"question": "Sarasvatii - a goddess or a river first?", "body": "<p>Historians (Marxists) claim that Rig Vedic Sarasvati is an imaginary river born out of minds of Rig Vedic Rishis, because there is no physical evidence of this river as Yamuna has.</p>\n<p>We, the adherent of Hinduism blissfully forgot the route of ancient Sarasvati and made people to believe that it flows underground and meets Yamuna and Ganga at Allahabad (Prayag), until the satellite imagery indicated that a huge river has paleo-channel passing through Harayana, Rajsthan and Gujarat, and it might be the ancient Sarasvati. We have not maintained a single religious place as a memorial of that great river of which we claim to be descendent. What a lapse!</p>\n<p>Our scriptures depict Sarasvati as a revered river and as goddess the wife of Brahma.But Rig Veda is categorical in agreement with satellite imagery as stated in RV.7.95.2</p>\n<blockquote>\n<p><em>eko cetat sarasvati nadinam suciryati giribhyam aa samudrAt</em>-</p>\n<p>The only river we think is Sarasvati that cleanses from mountain upto sea.</p>\n</blockquote>\n<p>Now my question is - In Hinduism what form of Sarasvati came first as a river or a goddess. From dogmatic religious point of view Brahma is Creator and Sarasvati is his wife, logically river is created lateron. From rational point of view Rig Veda is the source of all later scriptures and it depicts Sarasvati as river and it is later religious development that a river is symbolised as goddess.</p>\n", "pids": ["5dd7b5e5df1a9c0c4157a072"], "flag": 1}
{"question": "How do thoughts work at the neuron level?", "body": "<p>How does thought work at the biological level of individual neurons? I believe there are many neurons which are active in the brain at the same time. For example, our senses are constantly taking in sensory information on a continual basis. However, most of the neurons activated by sensory input are not capturing our attention, and as a result, our thoughts are elsewhere. I believe that thought, an \"active cognitive process,\" is a collection of neurons which are responsible for engaging our complete attention. This collection of neurons shifts as our attention shifts. But this does not explain what is responsible for controlling our attention at the neural level. Can't find any answers to this question.</p>\n", "pids": ["55a55c5065ceb7cb02e99bc5"], "flag": 1}
{"question": "What&#39;s so &#39;moment&#39; about &#39;moments&#39; of a probability distribution?", "body": "<p>I KNOW what moments are and how to calculate them and how to use the moment generating function for getting higher order moments. Yes, I know the math.</p>\n<p>Now that I need to get my statistics knowledge lubricated for work, I thought I might as well ask this question – it's been nagging me for about a few years and back in college no professor knew the answer or would just dismiss the question (honestly).</p>\n<p>So what does the word &quot;moment&quot; mean in this case? Why this choice of word? It doesn't sound intuitive to me (or I never heard it that way back in college :) Come to think of it I am equally curious with its usage in &quot;moment of inertia&quot; ;) but let's not focus on that for now.</p>\n<p>So what does a &quot;moment&quot; of a distribution mean and what does it seek to do and why THAT word! :) Why does any one care about moments? At this moment I am feeling otherwise about that moment ;)</p>\n<p>PS: Yes, I've probably asked a similar question on variance but I do value intuitive understanding over 'look in the book to find out' :)</p>\n", "pids": ["53e997edb7602d9701fedd15"], "flag": 1}
{"question": "What would happen if we cut the corpus callosum?", "body": "<p>How would a two-halved brain work? If it would, could we still control things like motion, and would hearing, vision, and other senses still function?</p>\n", "pids": ["55a49d7465ceb7cb02d4245e"], "flag": 1}
{"question": "Are we more attracted to people of the same ethnicity?", "body": "<p>Are humans more attracted to people from their own ethnic groups? I ask this because most of the time people have relationships with people of their own ethnicity, and I wonder if it's purely social, or if there's more behind it.</p>\n", "pids": ["53e9a9d3b7602d9703333136"], "flag": 1}
{"question": "The actual age of each yuga", "body": "<p>Puranas extensively mention the length of a mahayuga or a chaturyuga to be of 12000 divine years or 4,320,000 human years. This period is divided in 4:3:2:1 in 4 subsequent Yugas.\nBut Yukteshwar Giri, in his book the holy science, addressed these numbers as inflated figures due to lack of understanding among seers around 2900 years ago. This resulted in introduction of this extra &quot;divya varsh&quot; concept( a multiplication of actual figure with 360) . He explained that, in reality, each mahayuga cycle is divided in ascending and decending period of 12000 human years each. We are currently living in 322nd year of Dwapara which started in 1700 AD.\nWhich of the 2 explanations is more authentic : The one which is discussed in puranas or the one put forward by Yukteshwar Giri in his book ?</p>\n", "pids": ["5a2210ae0cf2b25cfd5377ac"], "flag": 1}
{"question": "Why is Ganga considered sacred? Why do so many devotees worship this river?", "body": "<p>What is river Ganga considered sacred? Why do so many devotees worship her?</p>\n\n\n\n<p>Note: This is not a dup. of <em><a href=\"https://hinduism.stackexchange.com/q/285\">Historically, when (and why) did Ganga become a holy river? Is it after Sarasvati dried up?</a></em> as that's about when and how Ganga as a river rose in prominence compared to other rivers.</p>\n", "pids": ["53e9b5fab7602d970414a631"], "flag": 1}
{"question": "How to compute precision/recall for multiclass-multilabel classification?", "body": "<p>I'm wondering how to calculate precision and recall measures for multiclass multilabel classification, i.e. classification where there are more than two labels, and where each instance can have multiple labels?</p>\n", "pids": ["5390881820f70186a0d81feb"], "flag": 1}
{"question": "What is the advantage of using plant-derived antibacterials rather than bacteria-derived antibacterials?", "body": "<p>So obviously we have a big problem with antibiotic resistance. Most of our antibiotics originate from bacteria themselves (or are synthetic variations on scaffolds which originate from bacteria). I have heard it asserted that using antibacterials derived from plants would lessen the problem. </p>\n\n<p>One argument for the use of plants is that the bacteria from which we derive an antibiotic must themselves already be resistant to that antibiotic, meaning that the allele for resistance is already in the bacterial gene pool and when we exert a selection pressure by using the antibiotic, resistance will eventually appear among pathogenic species. </p>\n\n<p>Another argument I have heard is that plants can provide a lot of structurally diverse metabolites from which we might discover new classes of antibacterials.</p>\n\n<p>Is there anything else to this?</p>\n\n<p>(I know I have answered my own question to an extent, but I am wondering whether there are any other good reasons to look to plants for the next generation of antibacterial drugs).</p>\n\n<p>Thank you!</p>\n", "pids": ["55a4603d65ce31bc87789f02"], "flag": 1}
{"question": "Reduce Classification Probability Threshold", "body": "<p>I have a question regarding classification in general. Let <span class=\"math-container\">$f$</span> be a classifier, which outputs a set of probabilities given some data D. Normally, one would say: well, if <span class=\"math-container\">$P(c|D) &gt; 0.5$</span>, we will assign a class 1, otherwise 0 (let this be a binary classification). </p>\n\n<p>My question is, what if I find out, that if I classify the class as 1 also when the probabilities are larger than, for instance 0.2, and the classifier performs better. Is it legitimate to then use this new threshold when doing classification?</p>\n\n<p>I would interpret the necessity for lower classification bound in the context of the data emitting a smaller signal; yet still significant for the classification problem.</p>\n\n<p>I realize this is one way to do it. However, if this is not correct thinking of reducing the threshold, what would be some data transformations, which emphasize individual features in a similar manner, so that the threshold can remain at 0.5?</p>\n", "pids": ["5d9ed79547c8f76646004a56"], "flag": 1}
{"question": "What is the set of cards used in the Wisconsin/Berg Card Sorting task?", "body": "<p>I'm a little confused about what cards are included in the Wisconsin card sorting task. According to PEBL there are two sets of cards available for the task, one set of 64 cards and one set of 128 cards. I think I've figured out what the 64 card deck is given that there are four different number, four different colours and four different shapes. Consequently, 4*4*4=64. However, what is contained in the 128 card deck?</p>\n", "pids": ["55a492b2612ca648689b8b74"], "flag": 1}
{"question": "In CRISPR bacteria, how does viral genomes get integrated into the spacers of CRISPR? Also, in its use, where does Cas9 cut the DNA?", "body": "<p>I've been out of Biology for about a year polishing my programming skills. I know CRISPR/Cas9 allows targeted 'cutting' of DNA via RNA-guidance. Few questions regarding this.</p>\n\n<ol>\n<li><p>Regarding to its natural phenomenon, when a virus infects a microbe with CRISPR capabilities, how does the genome get integrated into the 'spacers' of CRISPR region versus elsewhere of the prokaryote genome so that when transcribed, the Cas enzymes know that it's a foreign DNA element to be targeted? My understanding of virus infections is a little cloudy too; I'm thinking random transpositions.</p></li>\n<li><p>I'm looking into it now, so I may figure this out before someone answers, but when the target DNA is located via the guiding RNA, where does the Cas9 enzyme decide to 'cut' -- rendering it useless -- the DNA, and how does it identify the location? </p></li>\n</ol>\n\n<p>-EDIT- Ah. The target sequence must also include a 'PAM' sequence downstream (Protospacer Adjacent Motif), which allows binding of the riboprotein complex(guiding RNA + Cas9), and biochemistry magic cuts it ~3-4 bases upstream of the PAM). citation: <a href=\"https://www.addgene.org/CRISPR/guide/\" rel=\"nofollow\">https://www.addgene.org/CRISPR/guide/</a></p>\n\n<ol start=\"3\">\n<li>Just thought of another question, if the DNA is cut at the seemingly specific spot, is the DNA repair that ensues downstream totally random? I feel like it would be in the organism's best interest (anthropomorphogenic, oops), and evolution generally says it usually does, to have a mechanism to repair it to its original state.</li>\n</ol>\n", "pids": ["55a6b5ed65ce054aad724979", "55a6484565ce054aad62d338"], "flag": 1}
{"question": "How to read this DNA inversion diagram?", "body": "<p>In the following diagram about chromosome inversion, I don't understand:</p>\n\n<ol>\n<li>Why do we need to take the reverse complement from step 1 to 2? Isn't inversion just reversing the bases in the region?</li>\n<li>How is the bottom diagram derived? For example, where does the <code>ACCCCACTC</code> come from? I thought it should be: <code>GACTGCCGT</code> for 5'→3' and <code>CTGACGGCA</code> for 3'→5' (inversion of the sequences in the second step).</li>\n</ol>\n\n<p><a href=\"https://i.stack.imgur.com/ijaLQ.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/ijaLQ.png\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"http://web2.mendelu.cz/af_291_projekty2/vseo/print.php?page=315&amp;typ=html\" rel=\"noreferrer\">http://web2.mendelu.cz/af_291_projekty2/vseo/print.php?page=315&amp;typ=html</a></p>\n", "pids": ["53e99af2b7602d970237ec7c"], "flag": 1}
{"question": "Understanding neuronal firing in the context of Spike Timing Dependent Plasticity", "body": "<p>When discussing Spike Timing Dependent Plasticity in neurons, when we say that a neuron fires do we mean it fires only one spike? Or do we still say \"the neuron has fired\" when a train of n spikes was actually fired? </p>\n\n<p>I find this detail a little confusing when we learn spike timing dependent plasticity (STDP), for example. If the neuron fires only one spike, then the time of firing is precise enough for relative timing between input and output signals to be well defined, and then the theory makes sense. Otherwise, one should give an approximation of the duration of the firing train of spikes and compare it with the duration of depolarization process in the dendrite that triggered this firing. But I can't find any of these anywhere. </p>\n", "pids": ["5f0e0b7d9fced0a24bb90fb5"], "flag": 1}
{"question": "Why do neural network researchers care about epochs?", "body": "<p>An epoch in stochastic gradient descent is defined as a single pass through the data. For each SGD minibatch, $k$ samples are drawn, the gradient computed and parameters are updated. In the epoch setting, the samples are drawn without replacement.</p>\n\n<p>But this seems unnecessary. Why not draw each SGD minibatch as $k$ random draws from the whole data set at each iteration? Over a large number of epochs, the small deviations of which samples are seen more or less often would seem to be unimportant.</p>\n", "pids": ["53e9ada5b7602d97037a301f", "5de0f4e1df1a9c0c415df2f2"], "flag": 1}
{"question": "Principled way of collapsing categorical variables with many levels?", "body": "<p><strong>What techniques are available for collapsing (or pooling) many categories to a few, for the purpose of using them as an input (predictor) in a statistical model?</strong></p>\n\n\n\n<p>Consider a variable like <a href=\"https://en.wikipedia.org/wiki/Major_(academic)\" rel=\"noreferrer\">college student major</a> (discipline chosen by an undergraduate student). It is unordered and categorical, but it can potentially have dozens of distinct levels. Let's say I want to use major as a predictor in a regression model.</p>\n\n<p>Using these levels as-is for modeling leads to all sorts of issues because there are just so many. A lot of statistical precision would be thrown away to use them, and the results are hard to interpret. We're rarely interested in specific majors -- we're much more likely to be interested in broad categories (subgroups) of majors. But it isn't always clear how to divide up the levels into such higher-level categories, or even how many higher-level categories to use.</p>\n\n<p>For typical data I would be happy to use factor analysis, matrix factorization, or a discrete latent modeling technique. But majors are mutually exclusive categories, so I'm hesitant to exploit their covariance for anything.</p>\n\n<p>Furthermore I don't care about the major categories on their own. I care about producing higher-level categories that are coherent <em>with respect to my regression outcome</em>. In the binary outcome case, that suggests to me something like linear discriminant analysis (LDA) to generate higher-level categories that maximize discriminative performance. But LDA is a limited technique and that feels like dirty data dredging to me. Moreover any continuous solution will be hard to interpret.</p>\n\n<p>Meanwhile something based on covariances, like multiple correspondence analysis (MCA), seems suspect to me in this case because of the inherent dependence among mutually exclusive dummy variables -- they're better suited for studying multiple categorical variables, rather than multiple categories of the same variable.</p>\n\n<p><strong>edit</strong>: to be clear, this is about <em>collapsing</em> categories (not selecting them), and the categories are predictors or independent variables. In hindsight, this problem seems like an appropriate time to \"regularize 'em all and let God sort 'em out\". Glad to see this question is interesting to so many people!</p>\n", "pids": ["5c756aeaf56def979838a5c8", "5c756aeaf56def979838a5c8", "53e9b4dab7602d9704000872", "53e9b4dab7602d9704000872"], "flag": 1}
{"question": "How to interpret F-measure values?", "body": "<p>I would like to know how to interpret a difference of f-measure values. I know that f-measure is a balanced mean between precision and recall, but I am asking about the practical meaning of a difference in F-measures.</p>\n\n<p>For example, if a classifier C1 has an accuracy of 0.4  and another classifier C2 an accuracy of 0.8, then we can say that C2 has correctly classified the double of test examples compared to C1. However, if a classifier C1 has an F-measure of 0.4 for a certain class and another classifier C2 an F-measure of 0.8, what can we state about the difference in performance of the 2 classifiers ? Can we say that C2 has classified X more instances correctly that C1 ?    </p>\n", "pids": ["5f2927ad91e011376d9c5ca7"], "flag": 1}
{"question": "RNA processing in eukaryotes", "body": "<p>Why does post-transcriptional  processing of eukaryotic mRNA involve addition of a 3' polyA tail, rather than one of polyU, -G, or -C?</p>\n", "pids": ["53e9a281b7602d9702b8788b"], "flag": 1}
{"question": "Function of the alpha subunit in mitochondrial ATP-synthase?", "body": "<p>Within the catalytic core of <em>mitochondrial ATP-synthase</em> there are two different types of subunits; $\\alpha$ and $\\beta$. From what I have read, the catalytic sites occur only in the $\\beta$ subunit so clearly it is in these where ATP is synthesised. </p>\n\n<p>However, I can't find <strong>what the function of the $\\alpha$ subunit is</strong>. A source would be appreciated.  </p>\n", "pids": ["53e99ff0b7602d97028cef04"], "flag": 1}
{"question": "What are good initial weights in a neural network?", "body": "<p>I have just heard, that it's a good idea to choose initial weights of a neural network from the range $(\\frac{-1}{\\sqrt d} , \\frac{1}{\\sqrt d})$, where $d$ is the number of inputs to a given neuron. It is assumed, that the sets are normalized - mean 0, variance 1 (don't know if this matters).</p>\n\n<p>Why is this a good idea?</p>\n", "pids": ["53e9ada5b7602d97037a301f", "573696f46e3b12023e5f0d4d", "573696ce6e3b12023e5ce95a"], "flag": 1}
{"question": "Performance metrics to evaluate unsupervised learning", "body": "<p>With respect to the unsupervised learning (like clustering), are there any metrics to evaluate performance?</p>\n", "pids": ["53e9ac70b7602d970364149f", "5cdbeb5be1cd8e2fdc3b9472"], "flag": 1}
{"question": "Variable selection for predictive modeling really needed in 2016?", "body": "<p>This question has been asked on CV some yrs ago, it seems worth a repost in light of 1) order of magnitude better computing technology (e.g. parallel computing, HPC etc) and 2) newer techniques, e.g. [3].</p>\n\n<p>First, some context. Let's assume the goal is not hypothesis testing, not effect estimation, but prediction on un-seen test set. So, no weight is given to any interpretable benefit. Second, let's say you cannot rule out the relevance of any predictor on subject matter consideration, ie. they all seem plausible individually or in combination with other predictors. Third, you're confront with (hundreds of) millions of predictors. Fourth, let's say you have access to AWS with an unlimited budget, so computing power is not a constraint.  </p>\n\n<p>The usual reaons for variable selection are 1) efficiency; faster to fit a smaller model and cheaper to collect fewer predictors, 2) interpretation; knowing the \"important\" variables gives insight into the underlying process [1].</p>\n\n<p>It's now widely known that many variable selection methods are ineffective and often outright dangerous (e.g. forward stepwise regression) [2].</p>\n\n<p>Secondly, if the selected model is any good, one shouldn't need to cut down on the list of predictors at all. The model should do it for you. A good example is lasso, which assigns a zero coefficient to all the irrelevant variables. </p>\n\n<p>I'm aware that some people advocate using an \"elephant\" model, ie. toss every conceivable predictors into the fit and run with it [2].</p>\n\n<p>Is there any fundamental reason to do variable selection if the goal is predictive accuracy?</p>\n\n<p>[1] Reunanen, J. (2003). Overfitting in making comparisons between variable selection methods. The Journal of Machine Learning Research, 3, 1371-1382.</p>\n\n<p>[2] Harrell, F. (2015). Regression modeling strategies: with applications to linear models, logistic and ordinal regression, and survival analysis. Springer.</p>\n\n<p>[3] Taylor, J., &amp; Tibshirani, R. J. (2015). Statistical learning and selective inference. Proceedings of the National Academy of Sciences, 112(25), 7629-7634.</p>\n\n<p>[4] Zhou, J., Foster, D., Stine, R., &amp; Ungar, L. (2005, August). Streaming feature selection using alpha-investing. In Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining (pp. 384-393). ACM.</p>\n", "pids": ["56d847e1dabfae2eeebcbf02", "56d8b5e7dabfae2eee07ea5e", "554ba1fd0cf2e6443df05415"], "flag": 1}
{"question": "Diagnostics for logistic regression?", "body": "<p>For linear regression, we can check the diagnostic plots (residuals plots, Normal QQ plots, etc) to check if the assumptions of linear regression are violated.</p>\n\n<p>For logistic regression, I am having trouble finding resources that explain how to diagnose the logistic regression model fit. Digging up some course notes for GLM, it simply states that checking the residuals is not helpful for performing diagnosis for a logistic regression fit.</p>\n\n<p>Looking around the internet, there also seems to be various \"diagnosis\" procedures, such as checking the model deviance and performing chi-squared tests, but other sources state that this is inappropriate, and that you should perform a Hosmer-Lemeshow goodness of fit test. Then I find other sources that state that this test may be highly dependent on the actual groupings and cut-off values (may not be reliable).</p>\n\n<p>So how should one diagnose the logistic regression fit?</p>\n", "pids": ["56d8dbb4dabfae2eeef12178"], "flag": 1}
{"question": "Optimization when Cost Function Slow to Evaluate", "body": "<p>Gradient descent and many other methods are useful for finding local minima in cost functions. They can be efficient when the cost function can be evaluated quickly at each point, whether numerically or analytically.  </p>\n\n<p>I have what appears to me to be an unusual situation. Each evaluation of my cost function is expensive. I am attempting to find a set of parameters that minimize a 3D surface against ground truth surfaces. Whenever I change a parameter, I need to run the algorithm against the entire sample cohort to measure its effect.  In order to calculate a gradient, I need to change all 15 parameters independently, meaning I have to regenerate all the surfaces and compare against the sample cohort way too many times per gradient, and definitely way too many times over the course of optimization.</p>\n\n<p>I have developed a method to circumvent this problem and am currently evaluating it, but I am surprised that I have not found much in the literature regarding expensive cost function evaluations.  This makes me wonder if I am making the problem harder than it is and that there might be a better way already available.</p>\n\n<p>So my questions are basically this: Does anyone know of methods for optimizing cost functions, convex or not, when evaluation is slow?  Or, am I doing something silly in the first place by rerunning the algorithm and comparing against the sample cohort so many times?</p>\n", "pids": ["599c7b58601a182cd272b5cd", "53e9b428b7602d9703f20f5d"], "flag": 1}
{"question": "Model for predicting number of Youtube views of Gangnam Style", "body": "<p>PSY's music video <a href=\"http://www.youtube.com/watch?v=9bZkp7q19f0\" rel=\"noreferrer\">\"Gangnam style\"</a> is popular, after a little more than 2 months it has about 540 million viewers. I learned this from my preteen children at dinner last week and soon the discussion went in the direction of if it was possible to do some kind of prediction of how many viewers there will be in 10-12 days and when(/if) the song will pass 800 million viewers or 1 billion viewers.  </p>\n\n<p>Here is the picture from number of viewers since it was posted: \n<a src=\"https://i.stack.imgur.com/tB74k.jpg\" alt=\"PSY OGS\"></p>\n\n<p>Here are the picture from number of viewers of the No1 \"Justin Biever-Baby\"and No2 \"Eminem - Love the way you lie\" music videos that both have been around for a much longer time\n<a src=\"https://i.stack.imgur.com/6mww9.jpg\" alt=\"Justin\">\n<a src=\"https://i.stack.imgur.com/xSUNA.jpg\" alt=\"Eminem\"></p>\n\n<p>My first attempt to reason about the model was that is should be a S-curve but this doesn't seem to fit the the No1 and No2 songs and also doesn't fit that there are no limit on how many views that the music video can have, only a slower growth. </p>\n\n<p>So my question is: what kind of model should I use to predict number of viewers of the music video? </p>\n", "pids": ["56d86ba6dabfae2eeecba665"], "flag": 1}
{"question": "How do features of the work environment such as type of pen or color of paper influence productivity and workplace well-being?", "body": "<p><strong>Background:</strong> Recently I have been doing mathematics a whole lot,and I have noticed that my output varies wildly from many external factors,but mostly it is the enviorment I am working in. Namely one of the most unexpected things is that most my output depends on the quality of pen I am using and kind of notebook I am writing in. Last day I went to buy new notebooks and I laid my eyes upon one with especially distinguishing blue-white color scheme,and in my mind it was already set that it will be notebook I will write abstract algebra into,and truly while using that notebook I feel really motivated, it feels like the color of it and the subject of abstract algebra are intertwined in my brain.</p>\n\n<p><strong>Questions:</strong></p>\n\n<ul>\n<li>What is the phenomena called where features of the work environment such as type of pen or color of paper influence productivity or workplace well-being? </li>\n<li>How can such features be used to improve productivity?</li>\n</ul>\n", "pids": ["55a4a456612ca648689ea9e8", "53e99b9bb7602d970244055e", "53e9b923b7602d9704509dd3", "53e9a1bcb7602d9702ab44f6"], "flag": 1}
{"question": "Other emotions relative to angry/happy base emotions", "body": "<p>In my layman's experience, I'm vaguely aware there are four base emotions: <strong>happy, sad, afraid/surprised, and angry/disgusted</strong>.<sup><a href=\"http://www.theatlantic.com/health/archive/2014/02/new-research-says-there-are-only-four-emotions/283560/\" rel=\"nofollow\">1</a></sup></p>\n\n<p>Some background:  We're training an AI to learn the difference between happy voices and angry voices.  We've had some success, by showing it 200 <strong>angry</strong> audio clips, 200 <strong>happy</strong> audio clips, and 200 <strong>neutral</strong>.  It can now reasonably tell when we're talking pleasantly or confrontationally... but the accuracy could be better.</p>\n\n<p>Our total training dataset is made up of these audio clips: <strong>Happy, angry, neutral, calm, sad, fearful, disgust, and surprised</strong>. I think we can be more accurate by including these emotions.  </p>\n\n<p>But this is the problem:</p>\n\n<p>Happy/angry/neutral span opposite ends of a spectrum; like binary.  It's easy to say:</p>\n\n<pre><code>Happy     1\nNeutral   0\nAngry    -1\n</code></pre>\n\n<p>That's the shape of the data we need to train a neural network to recognize 'Happy'. </p>\n\n<p>So the question would be, is there any 'right answer' on filling in these blanks?  I've given it my best guesses below, but I'm hoping for something more scientific....</p>\n\n<pre><code>Happy     1\nAngry    -1\nNeutral   0\nCalm      X  (0.5?)\nSad       X  (-1?)\nFearful   X  (-0.5?)\nDisgust   X  (-0.75?)\nSurprised X  (0.75?)\n</code></pre>\n\n<p><sub> \n1: <a href=\"http://www.theatlantic.com/health/archive/2014/02/new-research-says-there-are-only-four-emotions/283560/\" rel=\"nofollow\">http://www.theatlantic.com/health/archive/2014/02/new-research-says-there-are-only-four-emotions/283560/</a>\n</sub></p>\n", "pids": ["53e9b732b7602d97042ca31b", "573698816e3b12023e740961"], "flag": 1}
{"question": "How to statistically compare two time series?", "body": "<p>I have two time series, shown in the plot below:</p>\n\n<p><a src=\"https://i.stack.imgur.com/w398k.png\" alt=\"Time Series Plot\"></p>\n\n<p>The plot is showing the full detail of both time series, but I can easily reduce it to just the coincident observations if needed.</p>\n\n<p>My question is: <strong>What statistical methods can I use to assess the differences between the time series?</strong></p>\n\n<p>I know this is a fairly broad and vague question, but I can't seem to find much introductory material on this anywhere. As I can see it, there are two distinct things to assess:</p>\n\n<p><strong>1. Are the values the same?</strong></p>\n\n<p><strong>2. Are the trends the same?</strong></p>\n\n<p>What sort of statistical tests would you suggest looking at to assess these questions? For question 1 I can obviously assess the means of the different datasets and look for significant differences in distributions, but is there a way of doing this that takes into account the time-series nature of the data?</p>\n\n<p>For question 2 - is there something like the Mann-Kendall tests that looks for the similarity between two trends? I could do the Mann-Kendall test for both datasets and compare, but I don't know if that is a valid way to do things, or whether there is a better way?</p>\n\n<p>I'm doing all of this in R, so if tests you suggest have a R package then please let me know.</p>\n", "pids": ["5cf792d93a55ac68c5d2da11"], "flag": 1}
{"question": "Understanding stratified cross-validation", "body": "<p>I <a href=\"https://en.wikipedia.org/wiki/Cross-validation_(statistics)\" rel=\"noreferrer\">read in Wikipedia</a>: </p>\n\n<blockquote>\n  <p>In <strong>stratified k-fold cross-validation</strong>, the folds are selected so that the <strong>mean response value</strong> is approximately equal in all the folds. In\n  the case of a dichotomous classification, this means that each fold\n  contains roughly the same proportions of the two types of class\n  labels.</p>\n</blockquote>\n\n<ol>\n<li>Say we are using CV for estimating the performance of a predictor or estimator. What would <strong>mean response value</strong> (MRV) mean in this context? Just the average value of the predictor / estimator? </li>\n<li>In what scenarios  would <em>\"achieving approximately the same MRV\"</em> in all folds be actually <strong>important</strong>? In other words, what are the consequences of <strong>not</strong> doing so?</li>\n</ol>\n", "pids": ["5550413f45ce0a409eb39ab8", "53e99d36b7602d97025ea8be"], "flag": 1}
{"question": "Which activation function for output layer?", "body": "<p>While the choice of activation functions for the hidden layer is quite clear (mostly sigmoid or tanh), I wonder how to decide on the activation function for the output layer. Common choices are linear functions, sigmoid functions and softmax functions. However, when should I use which one?</p>\n", "pids": ["5a73cb9817c44a0b3035c5f4"], "flag": 1}
{"question": "How to simulate data that satisfy specific constraints such as having specific mean and standard deviation?", "body": "<p>This question is motivated by <a href=\"https://stats.stackexchange.com/q/30294/183\">my question on meta-analysis</a>. But I imagine that it would also be useful in teaching contexts where you want to create a dataset that exactly mirrors an existing published dataset.</p>\n\n<p>I know how to generate random data from a given distribution. So for example, if I read about the results of a study that had:</p>\n\n<ul>\n<li>a mean of 102,</li>\n<li>a standard deviation of 5.2 , and </li>\n<li>a sample size of 72.</li>\n</ul>\n\n<p>I could generate similar data using <code>rnorm</code> in R. For example, </p>\n\n<pre><code>set.seed(1234)\nx &lt;- rnorm(n=72, mean=102, sd=5.2)\n</code></pre>\n\n<p>Of course the mean and SD would not be exactly equal to 102 and 5.2 respectively:</p>\n\n<pre><code>round(c(n=length(x), mean=mean(x), sd=sd(x)), 2)\n##     n   mean     sd \n## 72.00 100.58   5.25 \n</code></pre>\n\n<p>In general I'm interested in how to simulate data that satisfies a set of constraints. In the above case, the constaints are sample size, mean, and standard deviation. In other cases, there might be additional constraints. For example, </p>\n\n<ul>\n<li>a minimum and a maximum in either the data or the underlying variable might be known.</li>\n<li>the variable might be known to take on only integer values or only non-negative values.</li>\n<li>the data might include multiple variables with known inter-correlations.</li>\n</ul>\n\n<h3>Questions</h3>\n\n<ul>\n<li><strong>In general, how can I simulate data that exactly satisfies a set of constraints?</strong></li>\n<li><strong>Are there articles written about this? Are there any programs in R that do this?</strong></li>\n<li><strong>For the sake of example, how could and should I simulate a variable so that it has a specific mean and sd?</strong></li>\n</ul>\n", "pids": ["56d8985edabfae2eee224afc"], "flag": 1}
{"question": "Clustering with a distance matrix", "body": "<p>I have a (symmetric) matrix <code>M</code> that represents the distance between each pair of nodes. For example,</p>\n\n<pre>\n    A   B   C   D   E   F   G   H   I   J   K   L\nA   0  20  20  20  40  60  60  60 100 120 120 120\nB  20   0  20  20  60  80  80  80 120 140 140 140\nC  20  20   0  20  60  80  80  80 120 140 140 140\nD  20  20  20   0  60  80  80  80 120 140 140 140\nE  40  60  60  60   0  20  20  20  60  80  80  80\nF  60  80  80  80  20   0  20  20  40  60  60  60\nG  60  80  80  80  20  20   0  20  60  80  80  80\nH  60  80  80  80  20  20  20   0  60  80  80  80\nI 100 120 120 120  60  40  60  60   0  20  20  20\nJ 120 140 140 140  80  60  80  80  20   0  20  20\nK 120 140 140 140  80  60  80  80  20  20   0  20\nL 120 140 140 140  80  60  80  80  20  20  20   0\n</pre>\n\n<p>Is there any method to extract clusters from <code>M</code> (if needed, the number of clusters can be fixed), such that each cluster contains nodes with small distances between them. In the example, the clusters would be <code>(A, B, C, D)</code>, <code>(E, F, G, H)</code> and <code>(I, J, K, L)</code>.</p>\n\n<p>I've already tried UPGMA and <code>k</code>-means but the resulting clusters are very bad.</p>\n\n<p>The distances are the average steps a random walker would take to go from node <code>A</code> to node <code>B</code> (<code>!= A</code>) and go back to node <code>A</code>. It's guaranteed that <code>M^1/2</code> is a metric. To run <code>k</code>-means, I don't use the centroid. I define the distance between node <code>n</code> cluster <code>c</code> as the average distance between <code>n</code> and all nodes in <code>c</code>.</p>\n\n<p>Thanks a lot :)</p>\n", "pids": ["64a407ded68f896efaf1d6fb", "53e9bd6ab7602d9704a06602", "53e9b145b7602d9703bcb5e7"], "flag": 1}
{"question": "How to split the dataset for cross validation, learning curve, and final evaluation?", "body": "<p><strong>What is an appropriate strategy for splitting the dataset?</strong></p>\n\n<p><em>I ask for feedback on the following approach</em> (not on the individual parameters like <code>test_size</code> or <code>n_iter</code>, but if I used <code>X</code>, <code>y</code>, <code>X_train</code>, <code>y_train</code>, <code>X_test</code>, and <code>y_test</code> appropriately and if the sequence makes sense):</p>\n\n<p>(extending <a href=\"http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\">this</a> example from the scikit-learn documentation)</p>\n\n<h3>1. Load the dataset</h3>\n\n<pre><code>from sklearn.datasets import load_digits\ndigits = load_digits()\nX, y = digits.data, digits.target\n</code></pre>\n\n<h3>2. Split into training and test set (e.g., 80/20)</h3>\n\n<pre><code>from sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n</code></pre>\n\n<h3>3. Choose estimator</h3>\n\n<pre><code>from sklearn.svm import SVC\nestimator = SVC(kernel='linear')\n</code></pre>\n\n<h3>4. Choose cross-validation iterator</h3>\n\n<pre><code>from sklearn.cross_validation import ShuffleSplit\ncv = ShuffleSplit(X_train.shape[0], n_iter=10, test_size=0.2, random_state=0)\n</code></pre>\n\n<h3>5. Tune the hyperparameters</h3>\n\n<p>applying the cross-validation iterator on the <strong>training set</strong></p>\n\n<pre><code>from sklearn.grid_search import GridSearchCV\nimport numpy as np\ngammas = np.logspace(-6, -1, 10)\nclassifier = GridSearchCV(estimator=estimator, cv=cv, param_grid=dict(gamma=gammas))\nclassifier.fit(X_train, y_train)\n</code></pre>\n\n<h3>6. Debug algorithm with learning curve</h3>\n\n<p><code>X_train</code> is randomly split into a training and a test set 10 times (<code>n_iter=10</code>). Each point on the training-score curve is the average of 10 scores where the model was trained and evaluated on the first <em>i</em> training examples. Each point on the cross-validation score curve is the average of 10 scores where the model was trained on the first <em>i</em> training examples and evaluated on all examples of the test set. </p>\n\n<pre><code>from sklearn.learning_curve import learning_curve\ntitle = 'Learning Curves (SVM, linear kernel, $\\gamma=%.6f$)' %classifier.best_estimator_.gamma\nestimator = SVC(kernel='linear', gamma=classifier.best_estimator_.gamma)\nplot_learning_curve(estimator, title, X_train, y_train, cv=cv)\nplt.show()\n</code></pre>\n\n<p><a src=\"https://i.stack.imgur.com/XJ4nN.png\" alt=\"Learning curve\"></p>\n\n<p><a href=\"http://scikit-learn.org/dev/auto_examples/plot_learning_curve.html\">plot_learning_curve()</a> can be found in the current dev version of scikit-learn (0.15-git).</p>\n\n<h3>7. Final evaluation on the test set</h3>\n\n<pre><code>classifier.score(X_test, y_test)\n</code></pre>\n\n<h3>7a. Test over-fitting in model selection with nested cross-validation (using the whole dataset)</h3>\n\n<pre><code>from sklearn.cross_validation import cross_val_score\ncross_val_score(classifier, X, y)\n</code></pre>\n\n<p><strong>Additional question:</strong> <em>Does it make sense to replace step 7 by nested cross-validation? Or should nested cv be seen as complementary to step 7</em></p>\n\n<p>(the code seems to work with k-fold cross validation in scikit-learn, but not with shuffle &amp; split. So <code>cv</code> needs to be changed above to make the code work)</p>\n\n<h3>8. Train final model on whole dataset</h3>\n\n<pre><code>classifier.fit(X, y)\n</code></pre>\n\n<p>EDIT: I now agree with cbeleites that step 7a doesn't make much sense in this sequence. So I wouldn't adopt that.</p>\n", "pids": ["53e99f0ab7602d97027d59ed"], "flag": 1}
{"question": "What is the difference between ZCA whitening and PCA whitening?", "body": "<p>I am confused about ZCA whitening and normal whitening (which is obtained by dividing principal components by the square roots of PCA eigenvalues). As far as I know,</p>\n\n<p>$$\\mathbf x_\\mathrm{ZCAwhite} = \\mathbf U \\mathbf x_\\mathrm{PCAwhite},$$ where $\\mathbf U$ are PCA eigenvectors.</p>\n\n<p>What are the uses of ZCA whitening? What are the differences between normal whitening and ZCA whitening?</p>\n", "pids": ["56d86afddabfae2eeec6cfea"], "flag": 1}
{"question": "Why is the validation accuracy fluctuating?", "body": "<p>I have a four layer CNN to predict response to cancer using MRI data. I use ReLU activations to introduce nonlinearities. The train accuracy and loss monotonically increase and decrease respectively. But, my test accuracy starts to fluctuate wildly. I have tried changing the learning rate, reduce the number of layers. But, it doesn't stop the fluctuations. I even read this answer and tried following the directions in that answer, but not luck again. Could anyone help me figure out where I am going wrong? </p>\n\n<p><a href=\"https://i.stack.imgur.com/nDdaT.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/nDdaT.png\" alt=\"Screenshot\"></a></p>\n", "pids": ["573696086e3b12023e51af09"], "flag": 1}
{"question": "Test if two binomial distributions are statistically different from each other", "body": "<p>I have three groups of data, each with a binomial distribution (i.e. each group has elements that are either success or failure).  I do not have a predicted probability of success, but instead can only rely on the success rate of each as an approximation for the true success rate. I have only found this <a href=\"https://stats.stackexchange.com/questions/80123/test-if-two-samples-of-binomial-distributions-comply-with-the-same-p\">question</a>, which is close but does not seem to exactly deal with the this scenario.</p>\n<p>To simplify down the test, let's just say that I have 2 groups (3 can be extended from this base case).</p>\n<div class=\"s-table-container\">\n<table class=\"s-table\">\n<thead>\n<tr>\n<th>Group</th>\n<th>Trials <span class=\"math-container\">$n_i$</span></th>\n<th>Successes <span class=\"math-container\">$k_i$</span></th>\n<th>Percentage <span class=\"math-container\">$p_i$</span></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Group 1</td>\n<td>2455</td>\n<td>1556</td>\n<td>63.4%</td>\n</tr>\n<tr>\n<td>Group 2</td>\n<td>2730</td>\n<td>1671</td>\n<td>61.2%</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>I don't have an expected success probability, only what I know from the samples.</p>\n<p>The success rate of each of the sample is fairly close. However my sample sizes are also quite large. If I check the CDF of the binomial distribution to see how different it is from the first (where I'm assuming the first is the null test) I get a very small probability that the second could be achieved.</p>\n<p>In Excel:</p>\n<blockquote>\n<p>1-BINOM.DIST(1556,2455,61.2%,TRUE) = 0.012</p>\n</blockquote>\n<p>However, this does not take into account any variance of the first result, it just assumes the first result is the test probability.</p>\n<p>Is there a better way to test if these two samples of data are actually statistically different from one another?</p>\n", "pids": ["617a16125244ab9dcbdb3ead"], "flag": 1}
{"question": "Standard errors for lasso prediction using R", "body": "<p>I'm trying to use a LASSO model for prediction, and I need to estimate standard errors. Surely someone has already written a  package to do this. But as far as I can see, none of the packages on CRAN that do predictions using a LASSO will return standard errors for those predictions.</p>\n\n<p>So my question is: Is there a package or some R code available to compute standard errors for LASSO predictions?</p>\n", "pids": ["5c610875da56297340b3bda6"], "flag": 1}
{"question": "What is so cool about de Finetti&#39;s representation theorem?", "body": "<p>From <a href=\"http://books.google.es/books/about/Theory_of_Statistics.html?id=F9A9af4It10C&amp;redir_esc=y\">Theory of Statistics</a> by Mark J. Schervish (page 12):</p>\n\n<blockquote>\n  <p>Although DeFinetti's representation theorem 1.49 is central to motivating parametric models, it is not actually used in their implementation.</p>\n</blockquote>\n\n<p>How is the theorem central to parametric models?</p>\n", "pids": ["5ee7495b91e01198a507f9f1"], "flag": 1}
{"question": "Why is tanh almost always better than sigmoid as an activation function?", "body": "<p>In Andrew Ng's <a href=\"https://www.coursera.org/learn/neural-networks-deep-learning\" rel=\"noreferrer\">Neural Networks and Deep Learning course on Coursera</a> he says that using $tanh$ is almost always preferable to using $sigmoid$.</p>\n\n<p>The reason he gives is that the outputs using $tanh$ centre around 0 rather than $sigmoid$'s 0.5, and this \"makes learning for the next layer a little bit easier\".</p>\n\n<ol>\n<li><p>Why does centring the activation's output speed learning? I assume he's referring to the previous layer as learning happens during backprop?</p></li>\n<li><p>Are there any other features that make $tanh$ preferable? Would the steeper gradient delay vanishing gradients?</p></li>\n<li><p>Are there any situations where $sigmoid$ would be preferable?</p></li>\n</ol>\n\n<p>Math-light, intuitive  answers preferred.</p>\n", "pids": ["573696ce6e3b12023e5ce95a"], "flag": 1}
{"question": "What is the difference in Bayesian estimate and maximum likelihood estimate?", "body": "<p>Please explain to me the difference in Bayesian estimate and Maximum likelihood estimate?</p>\n", "pids": ["53e9b254b7602d9703cf6315"], "flag": 1}
{"question": "40,000 neuroscience papers might be wrong", "body": "<p>I saw <a href=\"http://www.economist.com/news/science-and-technology/21702166-two-studies-one-neuroscience-and-one-palaeoclimatology-cast-doubt\" rel=\"nofollow noreferrer\">this article</a> in the Economist about a <a href=\"http://www.pnas.org/content/113/28/7900.full.pdf\" rel=\"nofollow noreferrer\">seemingly devastating paper</a> [1] casting doubt on \"something like 40,000 published [fMRI] studies.\" The error, they say, is because of \"erroneous statistical assumptions.\" I read the paper and see it's partly a problem with multiple comparison corrections, but I'm not an fMRI expert and am finding it difficult to follow. </p>\n\n<p><strong>What are the erroneous assumptions the authors are talking about</strong>? Why are those assumptions made? What are ways around making these assumptions?</p>\n\n<p>A back of the envelope calculation says 40,000 fMRI papers is over a $billion in funding (grad student salary, operating costs, etc.).</p>\n\n\n\n<p>[1] Eklund et al., Cluster failure: Why fMRI inferences for spatial extent\nhave inflated false-positive rates, PNAS 2016</p>\n", "pids": ["5c136e31da56295a08ac1b0c"], "flag": 1}
{"question": "Statistics interview questions", "body": "<p>I am looking for some statistics (and probability, I guess) interview questions, from the most basic through the more advanced. Answers are not necessary (although links to specific questions on this site would do well).</p>\n", "pids": ["53e9a819b7602d970315fd3d"], "flag": 1}
{"question": "Why doesn&#39;t Random Forest handle missing values in predictors?", "body": "<p>What are theoretical reasons to not handle missing values? Gradient boosting machines, regression trees handle missing values. Why doesn't Random Forest do that?</p>\n", "pids": ["6038ce58d3485cfff19fbb78"], "flag": 1}
{"question": "Cost function of neural network is non-convex?", "body": "<p>The <a href=\"http://ufldl.stanford.edu/wiki/index.php/Backpropagation_Algorithm\">cost function</a> of neural network is $J(W,b)$, and it is claimed to be <strong>non-convex</strong>. I don't quite understand why it's that way, since as I see that it's quite similar to the cost function of logistic regression, right?</p>\n\n<p>If it is non-convex, so the 2nd order derivative $\\frac{\\partial J}{\\partial W} &lt; 0$, right?</p>\n\n<p><strong>UPDATE</strong></p>\n\n<p>Thanks to the answers below as well as @gung's comment, I got your point, if there's no hidden layers at all, it's convex, just like logistic regression. But if there's hidden layers, by permuting the nodes in the hidden layers as well as the weights in subsequent connections, we could have multiple solutions of the weights resulting to the same loss. </p>\n\n<p>Now more questions, </p>\n\n<p>1) There're multiple local minima, and some of them should be of the same value, since they're corresponding to some nodes and weights permutations, right?</p>\n\n<p>2) If the nodes and weights won't be permuted at all, then it's convex, right? And the minima will be the global minima. If so, the answer to 1) is, all those local minima will be of the same value, correct?</p>\n", "pids": ["5550413145ce0a409eb392b5"], "flag": 1}
{"question": "Is it true that the percentile bootstrap should never be used?", "body": "<p>In the MIT OpenCourseWare notes for 18.05 Introduction to Probability and Statistics, Spring 2014 (currently available <a href=\"https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading24.pdf\" rel=\"noreferrer\">here</a>), it states:</p>\n\n<blockquote>\n  <p>The bootstrap percentile method is appealing due to its simplicity. However it depends on\n  the bootstrap distribution of $\\bar{x}^{*}$ based on a <strong>particular</strong> sample being a good approximation to\n  the true distribution of $\\bar{x}$. Rice says of the percentile method, \"Although this direct equation\n  of quantiles of the bootstrap sampling distribution with confidence limits may seem initially\n  appealing, it’s rationale is somewhat obscure.\"[2] In short, <strong>don’t use the bootstrap\n  percentile method</strong>. Use the empirical bootstrap instead (we have explained both in the\n  hopes that you won’t confuse the empirical bootstrap for the percentile bootstrap).</p>\n  \n  <p>[2] John Rice, <em>Mathematical Statistics and Data Analysis</em>, 2nd edition, p. 272</p>\n</blockquote>\n\n<p>After a bit of searching online, this is the only quote I've found which outright states that the percentile bootstrap should not be used. </p>\n\n<p>What I recall reading from the text <em>Principles and Theory for Data Mining and Machine Learning</em> by Clarke et al. is that the main justification for bootstrapping is the fact that \n$$\\dfrac{1}{n}\\sum_{i=1}^{n}\\hat{F}_n(x) \\overset{p}{\\to} F(x)$$\nwhere $\\hat{F}_n$ is the empirical CDF. (I don't recall details beyond this.)</p>\n\n<p>Is it true that the percentile bootstrap method should not be used? If so, what alternatives are there for when $F$ isn't necessarily known (i.e., not enough information is available to do a parametric bootstrap)?</p>\n\n\n\n<h3>Update</h3>\n\n<p>Because clarification has been requested, the \"empirical bootstrap\" from these MIT notes refers to the following procedure: they compute $\\delta_1 = (\\hat{\\theta}^{*}-\\hat{\\theta})_{\\alpha/2}$ and $\\delta_2 =  (\\hat{\\theta}^{*}-\\hat{\\theta})_{1-\\alpha/2}$ with $\\hat{\\theta}^{*}$ the bootstrapped estimates of $\\theta$ and $\\hat{\\theta}$ the full-sample estimate of $\\theta$, and the resulting estimated confidence interval would be $[\\hat{\\theta}-\\delta_2, \\hat{\\theta} - \\delta_1]$. </p>\n\n<p>In essence, the main idea is this: empirical bootstrapping estimates an amount proportional to the difference between the point estimate and the actual parameter, i.e., $\\hat{\\theta}-\\theta$, and uses this difference to come up with the lower and upper CI bounds.</p>\n\n<p>The \"percentile bootstrap\" refers to the following: use $[\\hat{\\theta}^*_{\\alpha/2}, \\hat{\\theta}^*_{1-\\alpha/2}]$ as the confidence interval for $\\theta$. In this situation, we use bootstrapping to compute estimates of the parameter of interest and take the percentiles of these estimates for the confidence interval.</p>\n", "pids": ["53e99a0eb7602d970225eb61"], "flag": 1}
{"question": "Most famous statisticians", "body": "<p>What are the most important statisticians, and what is it that made them famous?<br>\n(Reply just one scientist per answer please.)</p>\n", "pids": ["53e9b572b7602d97040abf2c"], "flag": 1}
{"question": "Backpropagation with Softmax / Cross Entropy", "body": "<p>I'm trying to understand how backpropagation works for a softmax/cross-entropy output layer.</p>\n\n<p>The cross entropy error function is</p>\n\n<p>$$E(t,o)=-\\sum_j t_j \\log o_j$$</p>\n\n<p>with $t$ and $o$ as the target and output at neuron $j$, respectively. The sum is over each neuron in the output layer. $o_j$ itself is the result of the softmax function:</p>\n\n<p>$$o_j=softmax(z_j)=\\frac{e^{z_j}}{\\sum_j e^{z_j}}$$</p>\n\n<p>Again, the sum is over each neuron in the output layer and $z_j$ is the input to neuron $j$:</p>\n\n<p>$$z_j=\\sum_i w_{ij}o_i+b$$</p>\n\n<p>That is the sum over all neurons in the previous layer with their corresponding output $o_i$ and weight $w_{ij}$ towards neuron $j$ plus a bias $b$.</p>\n\n<p>Now, to update a weight $w_{ij}$ that connects a neuron $j$ in the output layer with a neuron $i$ in the previous layer, I need to calculate the partial derivative of the error function using the chain rule:</p>\n\n<p>$$\\frac{\\partial E} {\\partial w_{ij}}=\\frac{\\partial E} {\\partial o_j} \\frac{\\partial o_j} {\\partial z_{j}} \\frac{\\partial z_j} {\\partial w_{ij}}$$</p>\n\n<p>with $z_j$ as the input to neuron $j$.</p>\n\n<p>The last term is quite simple. Since there's only one weight between $i$ and $j$, the derivative is:</p>\n\n<p>$$\\frac{\\partial z_j} {\\partial w_{ij}}=o_i$$</p>\n\n<p>The first term is the derivation of the error function with respect to the output $o_j$:</p>\n\n<p>$$\\frac{\\partial E} {\\partial o_j} = \\frac{-t_j}{o_j}$$</p>\n\n<p>The middle term is the derivation of the softmax function with respect to its input $z_j$ is harder:</p>\n\n<p>$$\\frac{\\partial o_j} {\\partial z_{j}}=\\frac{\\partial} {\\partial z_{j}} \\frac{e^{z_j}}{\\sum_j e^{z_j}}$$</p>\n\n<p>Let's say we have three output neurons corresponding to the classes $a,b,c$ then $o_b = softmax(b)$ is:</p>\n\n<p>$$o_b=\\frac{e^{z_b}}{\\sum e^{z}}=\\frac{e^{z_b}}{e^{z_a}+e^{z_b}+e^{z_c}} $$</p>\n\n<p>and its derivation using the quotient rule:</p>\n\n<p>$$\\frac{\\partial o_b} {\\partial z_{b}}=\\frac{e^{z_b}*\\sum e^z - (e^{z_b})^2}{(\\sum_j e^{z})^2}=\\frac{e^{z_b}}{\\sum e^z}-\\frac{(e^{z_b})^2}{(\\sum e^z)^2}$$\n$$=softmax(b)-softmax^2(b)=o_b-o_b^2=o_b(1-o_b)$$\nBack to the middle term for backpropagation this means:\n$$\\frac{\\partial o_j} {\\partial z_{j}}=o_j(1-o_j)$$</p>\n\n<p>Putting it all together I get</p>\n\n<p>$$\\frac{\\partial E} {\\partial w_{ij}}= \\frac{-t_j}{o_j}*o_j(1-o_j)*o_i=-t_j(1-o_j)*o_i$$</p>\n\n<p>which means, if the target for this class is $t_j=0$, then I will not update the weights for this. That does not sound right.</p>\n\n<p>Investigating on this I found people having two variants for the softmax derivation, one where $i=j$ and the other for $i\\ne j$, like <a href=\"https://math.stackexchange.com/questions/945871/derivative-of-softmax-loss-function\">here</a> or <a href=\"http://peterroelants.github.io/posts/neural_network_implementation_intermezzo02/\" rel=\"noreferrer\">here</a>.</p>\n\n<p>But I can't make any sense out of this. Also I'm not even sure if this is the cause of my error, which is why I'm posting all of my calculations. I hope someone can clarify me where I am missing something or going wrong.</p>\n", "pids": ["5a9cb65d17c44a376ffb8279"], "flag": 1}
{"question": "Is this chart showing the likelihood of a terrorist attack statistically useful?", "body": "<p>I'm seeing this image passed around a lot.</p>\n\n<p>I have a gut-feeling that the information provided this way is somehow incomplete or even erroneous, but I'm not well versed enough in statistics to respond. It makes me think of this <a href=\"http://imgs.xkcd.com/comics/conditional_risk.png\">xkcd comic</a>, that even with solid historical data, certain situations can change how things can be predicted.</p>\n\n<p><a href=\"https://i.stack.imgur.com/broEo.png\"><a src=\"https://i.stack.imgur.com/broEo.png\" alt=\"What it do baby\"></a></p>\n\n<p>Is this chart as presented useful for accurately showing what the threat level from refugees is? Is there necessary statistical context that makes this chart more or less useful?</p>\n\n\n\n<p>Note: Try to keep it in layman's terms :)</p>\n", "pids": ["53e9a5e9b7602d9702f16722"], "flag": 1}
{"question": "What is wrong with extrapolation?", "body": "<p>I remember sitting in stats courses as an undergrad hearing about why extrapolation was a bad idea. Furthermore, there are a variety of sources online which comment on this. There's also a mention of it <a href=\"https://www.pmg.com/blog/googles-causal-impact-part-2-caution/\">here</a>.</p>\n\n<p>Can anyone help me understand why extrapolation is a bad idea?\nIf it is, how is it that forecasting techniques aren't statistically invalid?</p>\n", "pids": ["58437722ac44360f1082ede4"], "flag": 1}
{"question": "What are alternatives of Gradient Descent?", "body": "<p>Gradient Descent has a problem of getting stuck in Local Minima. We need to run gradient descent exponential times in order to find global minima.</p>\n\n<p>Can anybody tell me about any alternatives of gradient descent as applied in neural network learning, along with their pros and cons.</p>\n", "pids": ["63262e2690e50fcafdebefb0"], "flag": 1}
{"question": "reading an EEG dataset using EEGLAB", "body": "<p>When I'm reading the documentation of importing events in EEGLAB from a file <a href=\"http://sccn.ucsd.edu/wiki/A02:_Importing_Event_Epoch_Info\" rel=\"nofollow noreferrer\">here</a> I have noticed that when we used a stimulus , we must know which time  we will apply it , since in the dataset file , you have to identify  of what times stimulus happen . <br> I don't know if my understanding is right or not , since i didn't  deal with EEG data practically (but in 2 weeks I will), but I was  reading a theoretical topics and papers on that.\n<br> thanks in advance.</p>\n", "pids": ["61c9d0605244ab9dcb0cf543"], "flag": 1}
{"question": "Are bayesians slaves of the likelihood function?", "body": "<p>In his book \"All of Statistics\", Prof. Larry Wasserman presents the following Example (11.10, page 188). Suppose that we have a density $f$ such that $f(x)=c\\,g(x)$, where $g$ is a <strong>known</strong> (nonnegative, integrable) function, and the normalization constant $c&gt;0$ is <strong>unknown</strong>.</p>\n\n<p>We are interested in those cases where we can't compute $c=1/\\int g(x)\\,dx$. For example, it may be the case that $f$ is a pdf over a very high-dimensional sample space. </p>\n\n<p>It is well known that there are simulation techniques that allow us to sample from $f$, even though $c$ is unknown. Hence, the puzzle is: How could we estimate $c$ from such a sample?</p>\n\n<p>Prof. Wasserman describes the following Bayesian solution: let $\\pi$ be some prior for $c$. The likelihood is\n$$\n  L_x(c) = \\prod_{i=1}^n f(x_i) = \\prod_{i=1}^n \\left(c\\,g(x_i)\\right) = c^n \\prod_{i=1}^n g(x_i) \\propto c^n \\, .\n$$\nTherefore, the posterior \n$$\n  \\pi(c\\mid x) \\propto c^n \\pi(c)\n$$\ndoes not depend on the sample values $x_1,\\dots,x_n$. Hence, a Bayesian can't use the information contained in the sample to make inferences about $c$.</p>\n\n<p>Prof. Wasserman points out that \"Bayesians are slaves of the likelihood function. When the likelihood goes awry, so will Bayesian inference\".</p>\n\n<p>My question for my fellow stackers is: Regarding this particular example, what went wrong (if anything) with Bayesian methodology?</p>\n\n<p>P.S. As Prof. Wasserman kindly explained in his answer, the example is due to Ed George.</p>\n", "pids": ["53e99d51b7602d97026089b0"], "flag": 1}
{"question": "Can somebody provide a standard test to measure ones working memory &amp; short term memory", "body": "<p>I suffer from memory problem but find it difficult to undrstand whether it is more belief based or real, need a standard test to confirm.</p>\n", "pids": ["53e9a4ddb7602d9702e001ef", "53e9b5f3b7602d9704145033"], "flag": 1}
{"question": "Is it possible to derive the Michaelis-Menten equation under conditions where the product formation is reversible", "body": "<p>Text books etc generally derive the Michaelis-Menten equation for the irreversible case i.e $$\\ce{E + S &lt;=&gt; ES -&gt; E +P}$$ I can't see how to do it for the reversible case i.e  $$\\ce{E + S &lt;=&gt; ES &lt;=&gt; E +P}\\;$$ Is it possible?</p>\n", "pids": ["53e9a081b7602d9702967c80"], "flag": 1}
{"question": "Can Two Opposite Running Action Potential Cross Each Other without Annihilation in One Axon", "body": "<p>Can two opposite travelling action potential cross each other annihilation in an axon?</p>\n<p>My answer would be affirmative. If the propagation mechanism is linear as described by <a href=\"https://en.wikipedia.org/wiki/Cable_theory\" rel=\"nofollow noreferrer\">https://en.wikipedia.org/wiki/Cable_theory</a> or even <a href=\"https://en.wikipedia.org/wiki/Telegrapher%27s_equations\" rel=\"nofollow noreferrer\">https://en.wikipedia.org/wiki/Telegrapher%27s_equations</a> with approximately constant coefficients, the waves are then linearly additive and each signal should propagate unperturbed. The refractory period on each end of the axon can not possibly prevent the other end from being excited at the same time since the signal has not arrived yet.</p>\n<p>This question is inspired by the question <a href=\"https://biology.stackexchange.com/q/21137/8344\">Can a single axon propagate multiple simultaneous action potentials?</a></p>\n", "pids": ["53e9a455b7602d9702d70003"], "flag": 1}
{"question": "Is it possible to be clinically obsessed with school?", "body": "<p>I was wondering if it is possible for someone to have a clinical obsession with higher education. For example, the person who has this disorder constantly talks to others about things such as college to the point where something seems very wrong. Does a disorder like this exist? Or can it be a form of another disorder? I'm asking because I'm writing a research paper on various obsessions and would like to gain some insight on the matter.</p>\n", "pids": ["55a3a638c91b587b095df455", "5c6eb436e1cd8ef5662e80f7"], "flag": 1}
{"question": "List of situations where a Bayesian approach is simpler, more practical, or more convenient", "body": "<p>There have been many debates within statistics between Bayesians and frequentists.  I generally find these rather off-putting (although I think it has died down).  On the other hand, I've met several people who take an entirely pragmatic view of the issue, saying that sometimes it is more convenient to conduct a frequentist analysis and sometimes it's easier to run a Bayesian analysis.  I find this perspective practical and refreshing.  </p>\n\n<p>It occurs to me that it would be helpful to have a list of such cases.  Because there are too many statistical analyses, and because I assume that it is ordinarily more practical to conduct a frequentist analysis (coding a t-test in WinBUGS is considerably more involved than the single function call required to perform the frequentist-based version in R, for example), <strong>it would be nice to have a list of the situations where a Bayesian approach is simpler, more practical, and / or more convenient than a frequentist approach.</strong>  </p>\n\n\n\n<p><em>(Two answers that I have no interest in are: 'always', and 'never'.  I understand people have strong opinions, but please don't air them here.  If this thread becomes a venue for petty squabbling, I will probably delete it.  My goal here is to develop a resource that will be useful for an analyst with a job to do, not an axe to grind.)</em>  </p>\n\n<p>People are welcome to suggest more than one case, but please use separate answers to do so, so that each situation can be evaluated (voted / discussed) individually.  Answers should list: (1) <strong>what</strong> the nature of the situation is, and (2) <strong>why</strong> the Bayesian approach is simpler in this case.  Some <strong>code</strong> (say, in WinBUGS) demonstrating how the analysis would be done and why the Bayesian version is more practical would be ideal, but I expect will be too cumbersome.  If it can be done easily I would appreciate it, but please include <em>why</em> either way.  </p>\n\n<p>Finally, I recognize that I have not defined what it means for one approach to be 'simpler' than another.  The truth is, I'm not entirely sure what it should mean for one approach to be more practical than the other.  I'm open to different suggestions, just specify your interpretation when you explain why a Bayesian analysis is more convenient in the situation you discuss.  </p>\n", "pids": ["55a5120565ceb7cb02dff5c6", "56d83089dabfae2eee1f9318"], "flag": 1}
{"question": "Is there good evidence that long-term stimulant usage in children has no harmful effect when stopped?", "body": "<p>Essentially, I am looking for an RCT done on children, where they went on a stimulant drug for at least 3 years, and then stopped administering the drug.</p>\n<p>What I'm worried about is long-term lower levels of motivation - below baseline compared to people who never took the stimulant in the first place.  Or other subtle stuff that would only show up in an RCT.</p>\n", "pids": ["5c0f7219da562944ac65006b", "53e9badfb7602d970470eb48", "55a493efc91bf3b1cc3f73d6", "53e99b8db7602d9702434fe8", "55a377b92401aa93797946f5", "53e9a855b7602d970319f287", "5cf24d003a55acd1f85015f7", "53e9b866b7602d970442f905", "53e9ad41b7602d97037220cf", "53e9a7f8b7602d970313a28c", "55a6bfd665ce054aad74290c"], "flag": 1}
{"question": "How to generate networks for dynamic emotion modelling", "body": "<p>In Figure 1 (shown below) of \"Micro-Level Affect Dynamics in Psychopathology Viewed From Complex Dynamical System Theory\" by Wichers et al, they claim that the emotional/affective dynamics of networks of mentally ill individuals are more highly connected than healthy controls. These highly connected networks are more sensitive to perturbations.</p>\n\n<p><a href=\"https://i.stack.imgur.com/aNygT.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/aNygT.png\" alt=\"emotion network models\"></a></p>\n\n<p>How are these networks generated? What are the meaning behind the <code>N</code> variables?</p>\n", "pids": ["55a6c00e65ce054aad7449d2", "55a533ec65ceb7cb02e42bfe", "56d855dadabfae2eee279c57"], "flag": 1}
{"question": "Do gating mechanisms in the neocortex have individual degrees for all gated connections?", "body": "<p>For example, the upward connection between layers in the neocortex flows through the thalamus which is assumed to have a gating function.</p>\n\n<p>I wonder whether there is a single value per gate, determining the degree to which patterns can pass. Or can the gate be different for different synapses or signals at the same time? In this case, there would be more like a vector of degrees for all individual synapses of the gated nerve cord.</p>\n\n<p>Is there anything known about this?</p>\n", "pids": ["5c755226f56def97985dd66a"], "flag": 1}
{"question": "What is the Rowhammer DRAM bug and how should I treat it?", "body": "<p>DRAM chips are very tightly packed. Research has shown that neighboring bits can be flipped at random.</p>\n\n<ul>\n<li>What is the probability of the bug triggering at random in a server-grade DRAM chip with ECC (the <a href=\"http://users.ece.cmu.edu/~yoonguk/papers/kim-isca14.pdf\" rel=\"noreferrer\">CMU-Intel paper</a> cites e.g. the number 9.4x10^-14 for an unknown chip for one failure in a year's time)?</li>\n<li>How do I know whether the bug is fixed before buying memory?</li>\n<li>What should I do to counter <a href=\"https://security.stackexchange.com/questions/83409/what-are-the-security-implications-of-row-hammer-attack\">malicious attempts</a> to do privilege escalation by e.g. tenants or unprivileged users on e.g. CentOS 7?</li>\n</ul>\n\n<p>References:</p>\n\n<ul>\n<li><a href=\"http://news.softpedia.com/news/Row-Hammer-DRAM-Bug-Exploited-Unlocks-Access-to-Physical-Memory-475303.shtml\" rel=\"noreferrer\">Row Hammer DRAM Bug Exploited, Unlocks Access to Physical Memory</a></li>\n<li><a href=\"http://users.ece.cmu.edu/~yoonguk/papers/kim-isca14.pdf\" rel=\"noreferrer\">Flipping Bits in Memory Without Accessing Them: An Experimental Study of DRAM Disturbance Errors</a></li>\n<li><a href=\"https://github.com/google/rowhammer-test\" rel=\"noreferrer\">Google's PoC repo</a></li>\n<li><a href=\"http://googleprojectzero.blogspot.com/2015/03/exploiting-dram-rowhammer-bug-to-gain.html\" rel=\"noreferrer\">Project Zero writeup</a></li>\n</ul>\n", "pids": ["573696116e3b12023e5244f8"], "flag": 1}
{"question": "What are ways to assess employability of workers?", "body": "<p>Employability is typically defined as </p>\n\n<blockquote>\n  <p>the continuous fulfilling, acquiring or\n  creating of work through the optimal use of competences. (Van der Heijde &amp; Van der Heijden, 2006) </p>\n</blockquote>\n\n<p>One's employability does not only depend on one's ability to work (both physically and mentally), but also one's motivation to work and learn and the opportunity to work (Brouwers, 2012; dutch citation). </p>\n\n<p>Especially for elders, who are getting older and older, and have to work longer (i.e. until a higher age), employability is becoming incredibly relevant. They need to be able (and willing) to keep on working until their retirement, either in their current position or another less demanding job. This is a difficult job without clear insights. However, with such an incredibly broad term, it will even be difficult to gain those insights. </p>\n\n<p>Are there tools available to asses the personal factors of individuals' employability? </p>\n\n\n\n<p><a href=\"http://doc.utwente.nl/82810/1/VanderHeijdeVanderHeijden2006.pdf\" rel=\"nofollow noreferrer\">Heijde, C. M., &amp; Van Der Heijden, B. I. (2006). A competence‐based and multidimensional operationalization and measurement of employability. Human resource management, 45(3), 449-476.</a></p>\n\n<p><a href=\"http://www.flexworkresearch.org/uploads/publication/document/4726/Duurzameinzetbaarheidvandeouderewerknemer_standvanzaken.pdf\" rel=\"nofollow noreferrer\">Brouwer, S., de Lange, A., van der Mei, S., Wessels, M., Koolhaas, W., Bültmann, U., ... &amp; van der Klink, J. (2012). Duurzame inzetbaarheid van de oudere werknemer: stand van zaken. Universitair Medisch Centrum Groningen, Groningen: Rijksuniversiteit Groningen.</a></p>\n", "pids": ["53e9b505b7602d9704036015", "5aaa2d211b13da3ea920cb88", "5c0f7adfda562944ac79a4e2", "56d918a4dabfae2eee6ab5ba"], "flag": 1}
{"question": "Examples of Bayesian and frequentist approach giving different answers", "body": "<h3>Note: I <em>am</em> aware of <a href=\"https://stats.stackexchange.com/questions/31867/bayesian-vs-frequentist-interpretations-of-probability\">philosophical</a> differences between Bayesian and frequentist statistics.</h3>\n<p>For example &quot;what is the probability that the coin on the table is heads&quot; doesn't make sense in frequentist statistics, since it has either already landed heads or tails -- there is nothing probabilistic about it. So the question has no answer in frequentist terms.</p>\n<p><em>But such a difference is specifically <strong>not</strong> the kind of difference I'm asking about.</em></p>\n<p>Rather, I would like to know how their predictions for <em>well-formed</em> questions actually <em>differ</em> in the real world, <em>excluding</em> any theoretical/philosophical differences such as the example I mentioned above.</p>\n<p>So in other words:</p>\n<h3>What's an example of a question, answerable in <em>both</em> frequentist <em>and</em> Bayesian statistics, whose answer is different between the two?</h3>\n<p>(e.g. Perhaps one of them answers &quot;1/2&quot; to a particular question, and the other answers &quot;2/3&quot;.)</p>\n<p>Are there any such differences?</p>\n<ul>\n<li><p>If so, what are some examples?</p>\n</li>\n<li><p>If not, then when does it actually ever make a <em>difference</em> whether I use Bayesian or frequentist statistics when solving a particular problem?<br />\nWhy would I avoid one in favor of the other?</p>\n</li>\n</ul>\n", "pids": ["53e9ad98b7602d9703795b74", "6577660e939a5f4082096daf", "6577660e939a5f4082096daf", "53e9a6aeb7602d9702fe267e"], "flag": 1}
{"question": "Do antidepressants provide a permanent solution for depression and anxiety?", "body": "<p>Antidepressants works temporarily (as long as you take them), and also affects the cognitive behaviour. Should they be seen as a permanent solution for depression? Shouldn't we find a solution at the psychosocial level, which actually works rather than suppressing the thoughts?</p>\n", "pids": ["53e9b550b7602d970408b4ff", "5ae67c3e1b13da3b95e54fb4", "53e99eaeb7602d9702779b06", "53e99d74b7602d9702630c11", "53e9b0c7b7602d9703b3fa41"], "flag": 1}
{"question": "What should I do when my neural network doesn&#39;t generalize well?", "body": "<p>I'm training a neural network and the training loss decreases, but the validation loss doesn't, or it decreases much less than what I would expect, based on references or experiments with very similar architectures and data. How can I fix this?</p>\n\n\n\n<p>As for question</p>\n\n<blockquote>\n  <p><a href=\"https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn\">What should I do when my neural network doesn&#39;t learn?</a></p>\n</blockquote>\n\n<p>to which this question is inspired, the question is intentionally left general so that other questions about how to reduce the generalization error of a neural network <strong>down to a level which has been proved to be attainable</strong>, can be closed as duplicates of this one.</p>\n\n<p>See also dedicated thread on Meta:</p>\n\n<blockquote>\n  <p><a href=\"https://stats.meta.stackexchange.com/questions/5415/is-there-a-generic-question-to-which-we-can-redirect-questions-of-the-type-why?noredirect=1#comment16562_5415\">Is there a generic question to which we can redirect questions of the type &quot;why does my neural network not generalize well?&quot;</a></p>\n</blockquote>\n", "pids": ["599c7951601a182cd262fede", "5a73cbcc17c44a0b3035f413", "5a260c8417c44a4ba8a31b80", "58d82fced649053542fd6ec6", "599c7951601a182cd262fede", "5a9cb66717c44a376ffb8b0b", "62376b815aee126c0f0a93f6", "5c8c08c24895d9cbc6c3ec26"], "flag": 1}
{"question": "How do I test that two continuous variables are independent?", "body": "<p>Suppose I have a sample $(X_n,Y_n), n=1..N$ from the joint distribution of $X$ and $Y$. How do I test the hypothesis that $X$ and $Y$ are <strong>independent</strong>? </p>\n\n<p>No assumption is made on the joint or marginal distribution laws of $X$ and $Y$ (least of all joint normality, since in that case independence is identical to correlation being $0$).</p>\n\n<p>No assumption is made on the nature of a possible relationship between $X$ and $Y$; it may be non-linear, so the variables are <em>uncorrelated</em> ($r=0$) but <em>highly co-dependent</em> ($I=H$).</p>\n\n<p>I can see two approaches:</p>\n\n<ol>\n<li><p>Bin both variables and use <a href=\"http://en.wikipedia.org/wiki/Fisher%27s_exact_test\">Fisher's exact test</a> or <a href=\"http://en.wikipedia.org/wiki/G-test\">G-test</a>.</p>\n\n<ul>\n<li>Pro: use well-established statistical tests</li>\n<li>Con: depends on binning</li>\n</ul></li>\n<li><p>Estimate the <em>dependency</em> of $X$ and $Y$: <a href=\"http://en.wikipedia.org/wiki/Mutual_information\">$\\frac{I(X;Y)}{H(X,Y)}$</a> (this is $0$ for independent $X$ and $Y$ and $1$ when they completely determine each other).</p>\n\n<ul>\n<li>Pro: produces a number with a clear theoretical meaning</li>\n<li>Con: depends on the approximate entropy computation (i.e., binning again)</li>\n</ul></li>\n</ol>\n\n<p>Do these approaches make sense?</p>\n\n<p>What other methods people use?</p>\n", "pids": ["5e5e189893d709897ce1d9e2", "5cf48a49da56291d582ace69", "61a884146750f82b17638b2f", "53e99e13b7602d97026d9404", "53e9a57cb7602d9702ea4c54", "53e9b5f4b7602d9704148b54", "53e9a27ab7602d9702b81590", "53e99e13b7602d97026d9404"], "flag": 1}
{"question": "Is the &quot;hybrid&quot; between Fisher and Neyman-Pearson approaches to statistical testing really an &quot;incoherent mishmash&quot;?", "body": "<p>There exists a certain school of thought according to which the most widespread approach to statistical testing is a \"hybrid\" between two approaches: that of Fisher and that of Neyman-Pearson; these two approaches, the claim goes, are \"incompatible\" and hence the resulting \"hybrid\" is an \"incoherent mishmash\". I will provide a bibliography and some quotes below, but for now suffice it to say that there is <em>a lot</em> written about that in the wikipedia article on <a href=\"http://en.wikipedia.org/wiki/Statistical_hypothesis_testing#Origins_and_early_controversy\" rel=\"noreferrer\">Statistical hypothesis testing</a>. Here on CV, this point was repeatedly made by @Michael Lew (see <a href=\"https://stats.stackexchange.com/search?q=user%3A1679+mishmash\">here</a> and <a href=\"https://stats.stackexchange.com/search?q=user%3A1679+hybrid\">here</a>).</p>\n\n<p><strong>My question is: why are F and N-P approaches claimed to be incompatible and why is the hybrid claimed to be incoherent?</strong> Note that I read at least six anti-hybrid papers (see below), but still fail to understand the problem or the argument. Note also, that I am not suggesting to debate if F or N-P is a better approach; neither am I offering to discuss frequentist vs. Bayesian frameworks. Instead, the question is: <strong>accepting that both F and N-P are valid and meaningful approaches, what is so bad about their hybrid?</strong></p>\n\n\n\n<p>Here is how I understand the situation. Fisher's approach is to compute the $p$-value and take it as an evidence against the null hypothesis. The smaller the $p$, the more convincing the evidence. The researcher is supposed to combine this evidence with his background knowledge, decide if it is convincing <em>enough</em>, and proceed accordingly. (Note that Fisher's views changed over the years, but this is what he seems to have eventually converged to.) In contrast, Neyman-Pearson approach is to choose $\\alpha$ ahead of time and then to check if $p\\le\\alpha$; if so, call it significant and reject the null hypothesis (here I omit large part of the N-P story that has no relevance for the current discussion). See also an excellent reply by @gung in <a href=\"https://stats.stackexchange.com/questions/23142/when-to-use-fisher-and-neyman-pearson-framework/51823#51823\">When to use Fisher and Neyman-Pearson framework?</a></p>\n\n<p>The hybrid approach is to compute the $p$-value, report it (implicitly assuming that the smaller the better), and also call the results significant if $p\\le\\alpha$ (usually $\\alpha=0.05$) and nonsignificant otherwise. This is supposed to be incoherent. How can it be invalid to do two valid things simultaneously, beats me.</p>\n\n<p>As particularly incoherent the anti-hybridists view the widespread practice of reporting $p$-values as $p&lt;0.05$, $p&lt;0.01$, or $p&lt;0.001$ (or even $p\\ll0.0001$), where always the strongest inequality is chosen. The argument seems to be that (a) the strength of evidence cannot be properly assessed as exact $p$ is not reported, and (b) people tend to interpret the right-hand number in the inequality as $\\alpha$ and view it as type I error rate, and that is wrong. I fail to see a big problem here. First, reporting exact $p$ is certainly a better practice, but nobody really cares if $p$ is e.g. $0.02$ or $0.03$, so rounding it on a log scale is not soooo bad (and going below $\\sim 0.0001$ does not make sense anyway, see <a href=\"https://stats.stackexchange.com/questions/78839\">How should tiny p-values be reported?</a>). Second, if the consensus is to call everything below $0.05$ significant, then error rate will be $\\alpha=0.05$ and $p \\ne \\alpha$, as @gung explains in <a href=\"https://stats.stackexchange.com/questions/46856/interpretation-of-p-value-in-hypothesis-testing/46896#46896\">Interpretation of p-value in hypothesis testing</a>. Even though this is potentially a confusing issue, it does not strike me as more confusing than other issues in statistical testing (outside of the hybrid). Also, every reader can have her own favourite $\\alpha$ in mind when reading a hybrid paper, and her own error rate as a consequence. <strong>So what is the big deal?</strong></p>\n\n<p>One of the reasons I want to ask this question is because it literally <em>hurts</em> to see how much of the wikipedia article on <a href=\"http://en.wikipedia.org/wiki/Statistical_hypothesis_testing#Origins_and_early_controversy\" rel=\"noreferrer\">Statistical hypothesis testing</a> is devoted to lambasting hybrid. Following Halpin &amp; Stam, it claims that a a certain Lindquist is to blame (there is even a large scan of his textbook with \"errors\" highlighted in yellow), and of course <a href=\"http://en.wikipedia.org/wiki/Everett_Franklin_Lindquist\" rel=\"noreferrer\">the wiki article about Lindquist himself</a> starts with the same accusation. But then, maybe I am missing something.</p>\n\n\n\n<h2>References</h2>\n\n<ul>\n<li><p>Gigerenzer, 1993, <a href=\"https://www.mpib-berlin.mpg.de/volltexte/institut/dok/full/gg/ggstehfda/ggstehfda.html\" rel=\"noreferrer\">The superego, the ego, and the id in statistical reasoning</a> -- <em>introduced the term \"hybrid\" and called it \"incoherent mishmash\"</em></p>\n\n<ul>\n<li>See also more recent expositions by Gigerenzer et al.: e.g. <a href=\"http://people.umass.edu/~bioep740/yr2009/topics/Gigerenzer-jSoc-Econ-1994.pdf\" rel=\"noreferrer\">Mindless statistics</a> (2004) and <a href=\"http://library.mpib-berlin.mpg.de/ft/gg/GG_Null_2004.pdf\" rel=\"noreferrer\">The Null Ritual. What You Always Wanted to Know About\nSignificance Testing but Were Afraid to Ask</a> (2004).</li>\n</ul></li>\n<li><p>Cohen, 1994, <a href=\"http://www.sjsu.edu/faculty/gerstman/misc/Cohen1994.pdf\" rel=\"noreferrer\">The Earth Is Round ($p&lt;.05$)</a> -- <em>a very popular paper with almost 3k citations, mostly about different issues but favourably citing Gigerenzer</em></p></li>\n<li><p>Goodman, 1999, <a href=\"http://www.cs.ubc.ca/~murphyk/Teaching/Papers/goodmanPvalue.pdf\" rel=\"noreferrer\">Toward evidence-based medical statistics. 1: The P value fallacy</a></p></li>\n<li><p>Hubbard &amp; Bayarri, 2003, <a href=\"http://drsmorey.org/bibtex/upload/Hubbard:etal:2003.pdf\" rel=\"noreferrer\">Confusion over measures of evidence ($p$'s) versus errors ($\\alpha$'s) in classical statistical testing</a> -- <em>one of the more eloquent papers arguing against \"hybrid\"</em></p></li>\n<li><p>Halpin &amp; Stam, 2006, <a href=\"http://www.jstor.org/stable/20445367\" rel=\"noreferrer\">Inductive Inference or Inductive Behavior: Fisher and Neyman-Pearson Approaches to Statistical Testing in Psychological Research (1940-1960)</a> <em>[free after registration] -- blames Lindquist's 1940 textbook for introducing the \"hybrid\" approach</em></p></li>\n<li><p>@Michael Lew, 2006, <a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3419900/pdf/bph0166-1559.pdf\" rel=\"noreferrer\">Bad statistical practice in pharmacology (and other basic biomedical disciplines): you probably don't know P</a> -- <em>a nice review and overview</em></p></li>\n</ul>\n\n<h2>Quotes</h2>\n\n<blockquote>\n  <p><strong>Gigerenzer:</strong> What has become institutionalized as inferential statistics in psychology is not Fisherian statistics. It is an incoherent mishmash of some of Fisher's ideas on one hand, and some of the ideas of Neyman and E. S. Pearson on the other. I refer to this blend as the \"hybrid logic\" of statistical inference. </p>\n  \n  <p><strong>Goodman:</strong> The [Neyman-Pearson] hypothesis test approach offered scientists a\n  Faustian bargain -- a seemingly automatic way to limit the number of mistaken conclusions in the long run, but only by abandoning the ability to measure evidence [a la Fisher] and assess truth from a single experiment. </p>\n  \n  <p><strong>Hubbard &amp; Bayarri:</strong> Classical statistical testing is an anonymous hybrid of the competing and frequently contradictory approaches [...]. In particular, there is a widespread failure to appreciate the incompatibility of Fisher's evidential $p$ value with the Type I error rate, $\\alpha$, of Neyman-Pearson statistical orthodoxy. [...] As a prime example of the bewilderment arising from [this] mixing [...], consider the widely unappreciated fact that the former's $p$ value is <em>incompatible</em> with the Neyman-Pearson hypothesis test in which it has become embedded. [...] For example, Gibbons and Pratt [...] erroneously stated: \"Reporting a P-value, whether exact or within an interval, in effect permits each individual to choose his own level of significance as the maximum tolerable probability of a Type I error.\" </p>\n  \n  <p><strong>Halpin &amp; Stam:</strong> Lindquist's 1940 text was an original source of the hybridization of the Fisher and Neyman-Pearson approaches. [...] rather than adhering to any particular interpretation of statistical testing, psychologists have remained ambivalent about, and indeed largely unaware of, the conceptual difficulties implicated by the Fisher and Neyman-Pearson controversy.</p>\n  \n  <p><strong>Lew:</strong> What we have is a hybrid approach that neither controls error rates nor allows assessment of the strength of evidence. </p>\n</blockquote>\n", "pids": ["56d8701adabfae2eeeedcba5"], "flag": 1}
{"question": "Measuring entropy/ information/ patterns of a 2d binary matrix", "body": "<p>I want to measure the entropy/ information density/ pattern-likeness of a two-dimensional binary matrix. Let me show some pictures for clarification:</p>\n\n<p>This display should have a rather high entropy:</p>\n\n<p>A)</p>\n\n<p><a src=\"https://i.stack.imgur.com/Fxy5j.jpg\" alt=\"enter image description here\"></p>\n\n<p>This should have medium entropy:</p>\n\n<p>B)</p>\n\n<p><a src=\"https://i.stack.imgur.com/ptCTR.jpg\" alt=\"enter image description here\"></p>\n\n<p>These pictures, finally, should all have near-zero-entropy:</p>\n\n<p>C)</p>\n\n<p><a src=\"https://i.stack.imgur.com/E3wZ1.jpg\" alt=\"enter image description here\"></p>\n\n<p>D)</p>\n\n<p><a src=\"https://i.stack.imgur.com/SzXTx.jpg\" alt=\"enter image description here\"></p>\n\n<p>E)</p>\n\n<p><a src=\"https://i.stack.imgur.com/Ew4OE.jpg\" alt=\"enter image description here\"></p>\n\n<p>Is there some index that captures the entropy, resp. the \"pattern-likeness\" of these displays?</p>\n\n<p>Of course, each algorithm (e.g., compression algorithms; or the <a href=\"https://stats.stackexchange.com/questions/17109/measuring-entropy-information-patterns-of-a-2d-binary-matrix/17147#17147\">rotation algorithm proposed by ttnphns</a>) is sensitive to other features of the display. I am looking for an algorithm that tries to capture following properties:</p>\n\n<ul>\n<li>Rotational and axial symmetry</li>\n<li>The amount of clustering</li>\n<li>Repetitions</li>\n</ul>\n\n<p>Maybe more complicated, the algorith could be sensitive to properties of the psychological \"<a href=\"http://en.wikipedia.org/wiki/Gestalt_psychology\" rel=\"noreferrer\">Gestalt principle</a>\", in particular:</p>\n\n<ul>\n<li>The law of proximity: <a src=\"https://i.stack.imgur.com/J9Nqw.png\" alt=\"law of proximity\"></li>\n<li>The law of symmetry: Symmetrical images are perceived collectively, even in spite of distance:<a src=\"https://i.stack.imgur.com/fgCm6.jpg\" alt=\"symmetry\"></li>\n</ul>\n\n<p>Displays with these properties should get assigned a \"low entropy value\"; displays with rather random / unstructured points should get assigned a \"high entropy value\".</p>\n\n<p>I am aware that most probably no single algorithm will capture all of these features; therefore suggestions for algorithms which address only some or even only a single feature are highly welcome as well.</p>\n\n<p><strong>In particular, I am looking for <em>concrete, existing algorithms</em> or for <em>specific, implementable ideas</em> (and I will award the bounty according to these criteria).</strong></p>\n", "pids": ["56d8c9f3dabfae2eee6d24f9", "58437725ac44360f108302b9"], "flag": 1}
{"question": "Does the optimal number of trees in a random forest depend on the number of predictors?", "body": "<p>Can someone explain why we need a large number of trees in random forest when the number of predictors is large?  How can we determine the optimal number of trees?</p>\n", "pids": ["627e2e3b5aee126c0f96e984"], "flag": 1}
{"question": "Why do Convolutional Neural Networks not use a Support Vector Machine to classify?", "body": "<p>In recent years, Convolutional Neural Networks (CNNs) have become the state-of-the-art for object recognition in computer vision. Typically, a CNN consists of several convolutional layers, followed by two fully-connected layers. An intuition behind this is that the convolutional layers learn a better representation of the input data, and the fully connected layers then learn to classify this representation based into a set of labels.</p>\n\n<p>However, before CNNs started to dominate, Support Vector Machines (SVMs) were the state-of-the-art. So it seems sensible to say that an SVM is still a stronger classifier than a two-layer fully-connected neural network. Therefore, I am wondering why state-of-the-art CNNs tend to use the fully connected layers for classification rather than an SVM? In this way, you would have the best of both worlds: a strong feature representation, and a strong classifier, rather than a strong feature representation but only a weak classifier...</p>\n\n<p>Any ideas? </p>\n", "pids": ["5cede104da562983788e3ff3"], "flag": 1}
{"question": "Why is the regularization term *added* to the cost function (instead of multiplied etc.)?", "body": "<p>Whenever regularization is used, it is often added onto the cost function such as in the following cost function.\n$$\nJ(\\theta)=\\frac 1 2(y-\\theta X^T)(y-\\theta X^T)^T+\\alpha\\|\\theta\\|_2^2\n$$\nThis makes intuitive sense to me since minimize the cost function means minimizing the error (the left term) and minimizing the magnitudes of the coefficients (the right term) at the same time (or at least balancing the two minimizations).</p>\n\n<p>My question is why is this regularization term $\\alpha\\|\\theta\\|_2^2$ added onto the original cost function and not multiplied or something else which keeps the spirit of the motivation behind the idea of regularization? Is it because if we simply add the term on it is sufficiently simple and enables us to solve this analytically or is there some deeper reason? </p>\n", "pids": ["599c797f601a182cd26447c5", "5b3d98d617c44a510f80241c"], "flag": 1}
{"question": "Intuitive explanation of the bias-variance tradeoff?", "body": "<p>I am looking for an intuitive explanation of the bias-variance tradeoff, both in general and specifically in the context of linear regression.</p>\n", "pids": ["5dfb4b293a55acc4878bd217", "5d79a4dc3a55ac5af95adb8a", "5c8ffe1e4895d9cbc66f211a"], "flag": 1}
{"question": "Validity of limerance as a romantic evolutionary stage", "body": "<p>I was looking into the concept of <a href=\"https://www.wikiwand.com/en/Limerence#/overview\" rel=\"nofollow noreferrer\">limerence</a> as a stage of evolution in a romantic relationship, however I can't find any sources for it other than its origin in the book \"Love and Limerence: The Experience of Being in Love\" by Dorothy Tennov. Has there been any criticism of this as a concept, not as diagnosis for abnormal psychology? I'm somewhat skeptical of any psychological concept put forth by a single part without external validation.</p>\n", "pids": ["53e999d8b7602d970221de04", "53e99c7cb7602d970252b502", "53e9b43db7602d9703f38e0d"], "flag": 1}
{"question": "Tools to analyze RNA-seq data", "body": "<p>I hope this is a good place to ask such question. I have to do some data analysis on RNA-seq data from human cells. I am currently searching for tools to help me with that. Specifically, I would need some tools to analyze the gene expression from the data. Something to help me plot the expression of selected genes in each fastq file and compare the differences in the expression with the possibility to export the results or some command line interface for scripting. Basically I need something where I can put a fastq file and perhaps also a human genome annotation file as input and get gene expression as output. I have looked at bioconductor and it's packages and on <a href=\"https://en.wikipedia.org/wiki/List_of_RNA-Seq_bioinformatics_tools\">Wikipedia's List of RNA-Seq bioinformatics tools</a>. I suppose some of these tools have to be able to do what I need, but I have been unable to find out which one and how should they be used to achieve that. Could someone please give me some advice?</p>\n", "pids": ["57d4faaca57c569c44e9ca6b", "57d4faaca57c569c44e9ca6b"], "flag": 1}
{"question": "What happens in my retina if I press on my eyeballs?", "body": "<p>If I press my eyes I can \"see\" all kind of things: sparkling blue dots (which sometimes seem random and sometimes there seems to be a pattern in them), growing or diminishing rings of all kinds of color (I once read that these circles are also present in the retina of the non-yet-born, to provide some preparation), vague black-and-white faces, and many more, sometimes strange, sometimes for a short time recognizable forms. </p>\n\n<p>So, what strange capers are the different light receptors, or neurons in or behind the retinas of my eyes performing? </p>\n", "pids": ["53e9ba45b7602d97046555e4"], "flag": 1}
{"question": "What signal processors comprise an Event-Related Potential system for EEG?", "body": "<p>So my 30,000 ft. understanding of the EEG signal processing data flow is:</p>\n\n<ol>\n<li>Capture raw EEG data (\"raw waveforms\")</li>\n<li>Run these raw waveforms through a <strong>Signal Processing Framework</strong> that consists of 1+ \"nodes\"/processors, where each processor is doing some kind of transform on the raw waveform. In doing so, new information is unlocked from the raw waveform that was previously hidden</li>\n<li>Perform individual analyses on this unlocked data based on what suits your research/application</li>\n</ol>\n\n<p><strong>So first off, if the above understanding is misled in any way, please begin by correcting me!</strong></p>\n\n<p>Assuming I'm more or less correct, my specific application at hand is that I want to correlate certain raw waveforms with events (such as \"<em>thinking of a turtle</em>\", \"<em>moving head up and down</em>\", etc.). I <em>believe</em> <a href=\"https://en.wikipedia.org/wiki/Event-related_potential\">Event-Related Potentials</a> are what I'm looking for, but...</p>\n\n<p>What I'm struggling with is: what does my \"Signal Processing Network\" need to look like in order to implement ERP? From an architectural perspective, I'm looking for this \"network\" to take raw waveforms in as input, and to output events, like the few I mentioned above.</p>\n\n<p>Is FFT a player here? Some kinds of filters? What processors comprise an ERP system, and what does their respective \"network\" (data flow pipeline) look like?</p>\n", "pids": ["53e9a45cb7602d9702d77b29"], "flag": 1}
{"question": "Brain teaser: How to generate 7 integers with equal probability using a biased coin that has a pr(head) = p?", "body": "<p>This is a question I found on <a href=\"https://www.glassdoor.com/Interview/Microsoft-Data-Scientist-Interview-Questions-EI_IE1651.0,9_KO10,24_IP4.htm\" rel=\"noreferrer\">Glassdoor</a>: How does one generate 7 integers with equal probability using a coin that has a $\\mathbb{Pr}(\\text{Head}) = p\\in(0,1)$?</p>\n\n<p>Basically, you have a coin that may or may not be fair, and this is the only random-number generating process you have, so come up with random number generator that outputs integers from 1 to 7 where the probability of getting each of these integers is 1/7.</p>\n\n<p>Efficiency of the data-generates process matters.</p>\n", "pids": ["53e997ecb7602d9701fea681"], "flag": 1}
{"question": "How much carbon does a forest contain?", "body": "<p>Trees in a forest, alongside the fungi, animals and plants that live there in, capture atmospheric carbon dioxide and store it inside their tissues and in the soil as humus.</p>\n\n<p>It is possible to estimate the amount of carbon stored in some portion (say 100 square meters) of a <a href=\"https://en.wikipedia.org/wiki/Climax_community\" rel=\"nofollow\">climax</a> forest?</p>\n\n<p>This should depend on the specific <a href=\"https://en.wikipedia.org/wiki/Biome\" rel=\"nofollow\">biome</a>, for example Eucaliptus and Pine forests seem to contain less organic matter than broad-leaved tree forests in temperate regions.</p>\n\n<p>PS: A slightly more speculative aspect of this topic is to evaluate weather reforestation can contribute to lower the amount of carbon dioxide in the atmosphere.</p>\n", "pids": ["53e9b1eab7602d9703c7dad3"], "flag": 1}
{"question": "Why should evolution not be equated with progress?", "body": "<p>My science textbook says this:</p>\n\n<blockquote>\n  <p>Evolution should not be equated with progress. In fact, there is no real 'progress' in the idea of evolution. Evolution is simply the generation of diversity and the shaping of the diversity by environmental factors. The only progressive trend in evolution seems to be that more and more complex body designs have emerged over time. However, again it is not as if older designs are inefficient! So many of the older and simpler designs still survive [..] In other words, human beings are not the pinnacle of evolution, but simply yet another species in the teeming spectrum of life.</p>\n</blockquote>\n\n<p>I am not sure if I agree with this; after all, humans do seem to be more <strong>advanced</strong> than dogs. Many people have asked me why I thought this was true, so here is my answer: <em>Today, humans could wipe out dogs from Earth if they wanted, but you can hardly imagine  a scenario in which dogs would do the same to humans.</em></p>\n\n<p><em><strong>What am I missing here?</strong></em></p>\n", "pids": ["5f0e7def9fced0a24b595ede"], "flag": 1}
{"question": "What are good basic statistics to use for ordinal data?", "body": "<p>I have some <a href=\"http://en.wikipedia.org/wiki/Ordinal_scale#Ordinal_scale\">ordinal data</a> gained from survey questions.  In my case they are <a href=\"http://en.wikipedia.org/wiki/Likert_scale\">Likert style</a> responses (Strongly Disagree-Disagree-Neutral-Agree-Strongly Agree).  In my data they are coded as 1-5.</p>\n\n<p>I  don't think means would mean much here, so what basic summary statistics are considered usefull?</p>\n", "pids": ["53e9b7c0b7602d970436a05c"], "flag": 1}
{"question": "Recurrent vs Recursive Neural Networks: Which is better for NLP?", "body": "<p>There are Recurrent Neural Networks and Recursive Neural Networks. Both are usually denoted by the same acronym: RNN. According to <a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network#Recursive_neural_networks\">Wikipedia</a>, Recurrent NN are in fact Recursive NN, but I don't really understand the explanation.</p>\n\n<p>Moreover, I don't seem to find which is better (with examples or so) for Natural Language Processing. The fact is that, although Socher uses Recursive NN for NLP in his <a href=\"http://nlp.stanford.edu/courses/NAACL2013/\">tutorial</a>, I can't find a good implementation of recursive neural networks, and when I search in Google, most of the answers are about Recurrent NN.</p>\n\n<p>Besides that, is there another DNN which applies better for NLP, or it depends on the NLP task? Deep Belief Nets or Stacked Autoencoders? (I don't seem to find any particular util for ConvNets in NLP, and most of the implementations are with machine vision in mind).</p>\n\n<p>Finally, I would really prefer DNN implementations for C++ (better yet if it has GPU support) or Scala (better if it has Spark support) rather than Python or Matlab/Octave.</p>\n\n<p>I've tried Deeplearning4j, but it's under constant development and the documentation is a little outdated and I can't seem to make it work. Too bad because it has the \"black box\" like way of doing things, very much like scikit-learn or Weka, which is what I really want.</p>\n", "pids": ["5d25bcd73a55ac8369529045"], "flag": 1}
{"question": "What is the difference between work engagement and flow?", "body": "<p><a href=\"https://en.wikipedia.org/wiki/Work_engagement\" rel=\"nofollow noreferrer\">Work engagement</a> has three aspects: vigor, dedication, and absorption. </p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Flow_(psychology)\" rel=\"nofollow noreferrer\">Flow</a> according to wikipedia \"is the mental state of operation in which a person performing an activity is fully immersed in a feeling of energized focus\". </p>\n\n<p>What is the difference between the two concepts?</p>\n", "pids": ["53e9b22db7602d9703cc77e9", "53e9bd45b7602d97049d1981"], "flag": 1}
{"question": "Is a concept of machiavellianism useful?", "body": "<p>I can't be classified by wikipedia as someone clearly machiavellian (I'm hedonist (in the sence of general pleasure/pain, not only physical) and try not to hurt other people). Yet, I managed to score 80 on MACH-IV. But I doubt that questions are well selected. In fact almost every question is ambiguous or ill-posed (it's sometimes about belief that everyone is a kind person, I'm not an ultra-optimist, I'm realist and sometimes just about being average person).</p>\n\n<p>By the way, I could not see anything in this test that could reveal machiavellian traits. Moreover, most study show only a weak correlation between them and high score in test. The real correlation is around .2 if not lower, which makes it unreliable.</p>\n\n<p>What I'm thinking is that people with similar [to mine] philosophy also can score higher than average just for similar reasons. And it's completely weird, since philosophies are too different.</p>\n\n\n\n<p>Well, for example, I know that concepts of narcissism (but NPI still has around of half useless questions in my opinion) and psychopathy are much better defined and appropriate tests seem to be more accurate. Yet, if there is another type of personality, that may ruin lifes of other people, it can't be revealed by MACH-IV.</p>\n\n<p>In fact statistics show that mean score is around 67 or so, which is considered as high Mach. If majority are high Machs, then there is no dark triad. Also, the form of graph is symmetrical, while form of graph on NPI test is highly assymmetrical.</p>\n\n<p>So, is it just a canard or is there some evidence, that such personality type exists (and it is something that is useful in terms of psychology)? (Of course, some people may treat themselves as the only really clever ones, who should rule the world, but yet think that they look as average person; which is some kind of narcissism).</p>\n", "pids": ["53e9b03db7602d9703a9a629", "62823f4f5aee126c0f98b8fb"], "flag": 1}
{"question": "Neural networks vs support vector machines: are the second definitely superior?", "body": "<p>Many authors of papers I read affirm SVMs is superior technique to face their regression/classification problem, aware that they couldn't get similar results through NNs. Often the comparison states that</p>\n\n<p>SVMs, instead of NNs,</p>\n\n<ul>\n<li>Have a strong founding theory </li>\n<li>Reach the global optimum due to quadratic programming</li>\n<li>Have no issue for choosing a proper number of parameters</li>\n<li>Are less prone to overfitting</li>\n<li>Needs less memory to store the predictive model</li>\n<li>Yield more readable results and a geometrical interpretation</li>\n</ul>\n\n<p>Is it seriously a broadly accepted thought? Don't quote No-Free Lunch Theorem or similar statements, my question is about practical usage of those techniques.</p>\n\n<p>On the other side, which kind of abstract problem you definitely would face with NN?</p>\n", "pids": ["53e9b873b7602d970443cb5c"], "flag": 1}
{"question": "When combining p-values, why not just averaging?", "body": "<p>I recently learned about Fisher's method to combine p-values. This is based on the fact that p-value under the null follows a uniform distribution, and that $$-2\\sum_{i=1}^n{\\log X_i} \\sim \\chi^2(2n), \\text{ given } X \\sim \\text{Unif}(0,1)$$\nwhich I think is genius. But my question is why going this convoluted way? and why not (what is wrong with) just using mean of p-values and use central limit theorem? or median? I am trying to understand the genius of RA Fisher behind this grand scheme.</p>\n", "pids": ["53e9b90bb7602d97044f3ac5"], "flag": 1}
{"question": "Who are frequentists?", "body": "<p>We already had a thread asking <a href=\"https://stats.stackexchange.com/questions/167051/who-are-the-bayesians\">who are Bayesians</a> and one asking <a href=\"https://stats.stackexchange.com/questions/225002/are-we-frequentists-really-just-implicit-unwitting-bayesians\">if frequentists are Bayesians</a>, but there was no thread asking directly <em>who are frequentists</em>? This is a question that was asked by <em>@whuber</em> as a <a href=\"https://stats.stackexchange.com/questions/232339/frequentist-definition-of-probability-does-there-exist-a-formal-definition\">comment to this thread</a> and it begs to be answered. Do they exist (are there any self-identified frequentists)? Maybe they were just made-up by Bayesians who needed a scapegoat to blame when criticizing the mainstream statistics?</p>\n\n<p><strong><em>Meta-comment to the answers that were already given:</em></strong> As contrast, Bayesian statistics are <em>not only</em> defined in terms of using Bayes theorem (non-Bayesians also use it), nor about using subjectivist interpretation of probability (you wouldn't call any layperson saying things like <em>\"I bet the chance is less than 50:50!\"</em> a Bayesian) - so can we define frequentism only in terms of adopted interpretation of probability? Moreover, <a href=\"https://stats.stackexchange.com/questions/219733/what-should-be-taught-first-probability-or-statistics\">statistics $\\ne$ applied probability</a>, so should definition of frequentism be focused solely on the interpretation of probability?</p>\n", "pids": ["53e9a698b7602d9702fc8c0d"], "flag": 1}
{"question": "Box-Cox like transformation for independent variables?", "body": "<p>Is there a Box-Cox like transformation for independent variables?  That is, a transformation that optimizes the $x$ variable so that the <code>y~f(x)</code> will make a more reasonable fit for a linear model?</p>\n\n<p>If so, is there a function to perform this with <code>R</code>?</p>\n", "pids": ["6229f5635aee126c0f43add0"], "flag": 1}
{"question": "Should I normalize word2vec&#39;s word vectors before using them?", "body": "<p>After training word vectors with word2vec, is it better to normalize them before using them for some downstream applications? I.e what are the pros/cons of normalizing them?</p>\n", "pids": ["5f0e940b9fced0a24b517f33", "573696086e3b12023e51b8a9"], "flag": 1}
{"question": "How does a laser printer control the laser to produce such high resolutions?", "body": "<p>I opened up a broken laser printer yesterday to find one of the important sections (this is an example photo from Google Images), trying to learn from the design of the laser+polygon mirror motor within:</p>\n\n<p><a href=\"https://i.stack.imgur.com/jWLiX.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/jWLiX.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>I was able to find the pinout of the driver chip, and successfully got the motor running at a very high RPM, as well as the laser to reflect off the rotating mirror, forming a simple linear pattern on the end surface.</p>\n\n<p>Now, here is the part that's mysterious to me:</p>\n\n<ul>\n<li><p>The mirror is just a standard BLDC (not a stepper nor an encoder-based servo).</p></li>\n<li><p>The hexagon of mirrors is rotating at unknown/inexact speed.</p></li>\n<li><p>There is such a high speed of rotation and such a short mirror length (I measured each side of the hexagon's mirrors to be about 2 cm long).</p></li>\n</ul>\n\n<p>So how do they control the laser to reflect at the exact rotation-timing/angle of each mirror so as to (hit the photoreceptor drum at highly accurate positions and) produce printing quality in the thousands of DPI, i.e. better than 0.03 mm resolution?</p>\n\n<p>In other words, how is the timing of the on/off laser pulsing coordinated with respect to the mirror angle in the below picture?</p>\n\n<p><a href=\"https://i.stack.imgur.com/xp6UK.gif\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/xp6UK.gif\" alt=\"enter image description here\"></a></p>\n", "pids": ["558a9c19e4b0b32fcb37cfa2"], "flag": 1}
{"question": "Is there any gold standard for modeling irregularly spaced time series?", "body": "<p>In field of economics (I think) we have  ARIMA and GARCH for regularly spaced time series and Poisson, Hawkes for modeling point processes, so how about attempts for modeling irregularly (unevenly) spaced time series - are there (at least) any common practices?</p>\n<p>(If you have some knowledge in this topic you can also expand the corresponding <a href=\"http://en.wikipedia.org/wiki/Unevenly_spaced_time_series\" rel=\"nofollow noreferrer\">wiki article</a>.)</p>\n<p>I see irregular time series simply as series of pairs (value, time_of_event), so we have to model not only value to value dependencies but also value and time_of_event and timestamps themselves.</p>\n<p>Edition (about missing values and irregular spaced time series) :</p>\n<p>Answer to @Lucas Reis comment. If gaps between measurements or realizations variable are spaced due to (for example) Poisson process there is no much room for this kind of regularization, but it exists simple procedure : <code>t(i)</code> is the i-th time index of variable x (i-th time of realization x), then define gaps between times of measurements as <code>g(i)=t(i)-t(i-1)</code>, then we discretize <code>g(i)</code> using constant <code>c</code>, <code>dg(i)=floor(g(i)/c</code> and create new time series with number of blank values between old observations from original time series <code>i</code> and <code>i+1</code> equal to dg(i), but the problem is that this procedure can easily produce time series with number of missing data much larger then number of observations, so the reasonable estimation of missing observations' values could be impossible and too large <code>c</code> delete &quot;time structure/time dependence etc.&quot; of analysed problem (extreme case is given by taking <code>c&gt;=max(floor(g(i)/c))</code> which simply collapse irregularly spaced time series into regularly spaced</p>\n<p>Edition2 (just for fun):\nImage accounting for missing values in irregularly spaced time series or even case of point process.</p>\n", "pids": ["56d83782dabfae2eee4a235d"], "flag": 1}
{"question": "How does saddlepoint approximation work?", "body": "<p>How <em>does</em> saddlepoint approximation work? What sort of problem is it good for?<br>\n(Feel free to use a particular example or examples by way of illustration)</p>\n\n<p>Are there any drawbacks, difficulties, things to watch out for, or traps for the unwary?</p>\n", "pids": ["5d9edbe347c8f7664602b5e9"], "flag": 1}
{"question": "Adam optimizer with exponential decay", "body": "<p>In most Tensorflow code I have seen Adam Optimizer is used with a constant Learning Rate of <code>1e-4</code> (i.e. 0.0001). The code usually looks the following:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>...build the model...\n# Add the optimizer\ntrain_op = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n# Add the ops to initialize variables.  These will include \n# the optimizer slots added by AdamOptimizer().\ninit_op = tf.initialize_all_variables()\n\n# launch the graph in a session\nsess = tf.Session()\n# Actually intialize the variables\nsess.run(init_op)\n# now train your model\nfor ...:\n  sess.run(train_op)\n</code></pre>\n\n<p>I am wondering, whether it is useful to use exponential decay when using adam optimizer, i.e. use the following Code:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>...build the model...\n# Add the optimizer\nstep = tf.Variable(0, trainable=False)\nrate = tf.train.exponential_decay(0.15, step, 1, 0.9999)\noptimizer = tf.train.AdamOptimizer(rate).minimize(cross_entropy, global_step=step)\n# Add the ops to initialize variables.  These will include \n# the optimizer slots added by AdamOptimizer().\ninit_op = tf.initialize_all_variables()\n\n# launch the graph in a session\nsess = tf.Session()\n# Actually intialize the variables\nsess.run(init_op)\n# now train your model\nfor ...:\n  sess.run(train_op)\n</code></pre>\n\n<p>Usually, people use some kind of learning rate decay, for Adam it seems uncommon. Is there any theoretical reason for this? Can it be useful to combine Adam optimizer with decay?</p>\n", "pids": ["5550415745ce0a409eb3a739", "5736960e6e3b12023e520c34"], "flag": 1}
{"question": "Does the taste of sugar replenish willpower?", "body": "<p>In a post titled <a href=\"https://www.lesserwrong.com/posts/XKfQF73YnyMRiRf9a/willpower-depletion-vs-willpower-distraction\" rel=\"nofollow noreferrer\">Willpower Depletion vs Willpower Distraction</a> the claim is made that:</p>\n\n<blockquote>\n  <p>Basically, for a while some researchers believed that willpower\n  depletion \"is\" glucose depletion in the prefrontal cortex, but some\n  more recent experiments have failed to replicate this, e.g. by finding\n  that the mere taste of sugar is enough to \"replenish\" willpower faster\n  than the time it takes blood to move from the mouth to the brain:</p>\n</blockquote>\n\n<p>Is that claim representative of the knowledge we have from studies?</p>\n", "pids": ["5a9e68d4684d165d4bfab115"], "flag": 1}
{"question": "What are the breakthroughs in Statistics of the past 15 years?", "body": "<p>I still remember the Annals of Statistics paper on Boosting by Friedman-Hastie-Tibshirani, and the comments on that same issues by other authors (including Freund and Schapire). At that time, clearly Boosting was viewed as a breakthrough in many respects: computationally feasible, an ensemble method, with excellent yet mysterious performance. Around the same time, SVM came of age, offering a <em>framework</em> underpinned by solid theory and with plenty of variants and applications. </p>\n\n<p>That was in the marvelous 90s. In the past 15 years, it seems to me that a lot of Statistics has been a cleaning and detailing operation, but with few truly new views.</p>\n\n<p>So I'll ask two questions:</p>\n\n<ol>\n<li>Have I missed some revolutionary/seminal paper?</li>\n<li>If not, are there new approaches\nthat you think have the potential to\nchange the viewpoint of statistical\ninference?</li>\n</ol>\n\n<p>Rules: </p>\n\n<ol>\n<li>One answer per post; </li>\n<li>References or links welcome.</li>\n</ol>\n\n<p>P.S.: I have a couple of candidates for promising breakthroughs. I will post them later.</p>\n", "pids": ["53e9b017b7602d9703a73502"], "flag": 1}
{"question": "How does a chip antenna work?", "body": "<p>There are many guides to using chip antennas, with and without baluns, PCB layout considerations, etc., but I've been unable to find any information on how chip antennas work at a fundamental level, and how they're manufactured.</p>\n\n<p>Can anyone provide any insight, or links to more information?</p>\n", "pids": ["558be199e4b00c3c48df03d9", "558ac036e4b0b32fcb38a55e", "558b64a784ae84d265c3201f"], "flag": 1}
{"question": "Is it possible to do time-series clustering based on curve shape?", "body": "<p>I have sales data for a series of outlets, and want to categorise them based on the shape of their curves over time.  The data looks roughly like this (but obviously isn't random, and has some missing data):</p>\n\n<pre><code>n.quarters &lt;- 100\nn.stores &lt;- 20\nif (exists(\"test.data\")){\n  rm(test.data)\n}\nfor (i in 1:n.stores){\n  interval &lt;- runif(1, 1, 200)\n  new.df &lt;- data.frame(              \n    var0 = interval + c(0, cumsum(runif(49, -5, 5))),\n    date = seq.Date(as.Date(\"1990-03-30\"), by=\"3 month\", length.out=n.quarters),\n    store = rep(paste(\"Store\", i, sep=\"\"), n.quarters))\n  if (exists(\"test.data\")){\n    test.data &lt;- rbind(test.data, new.df)    \n  } else {\n    test.data &lt;- new.df\n  }\n}\ntest.data$store &lt;- factor(test.data$store)\n</code></pre>\n\n<p>I would like to know how I can cluster based on the <em>shape</em> of the curves in R.  I had considered the following approach:</p>\n\n<ol>\n<li>Create a new column by linearly transforming each store's var0 to a value between 0.0 and 1.0 for the entire time series.</li>\n<li>Cluster these transformed curves using the <a href=\"http://cran.r-project.org/web/packages/kml/index.html\"><code>kml</code> package</a> in R.</li>\n</ol>\n\n<p>I have two questions:</p>\n\n<ol>\n<li>Is this a reasonable exploratory approach?</li>\n<li>How can I transform my data into the longitudinal data format that <code>kml</code> will understand?  Any R snippets would be much appreciated!</li>\n</ol>\n", "pids": ["539099ec20f70186a0e1cd7e"], "flag": 1}
{"question": "Apply word embeddings to entire document, to get a feature vector", "body": "<p>How do I use a word embedding to map a document to a feature vector, suitable for use with supervised learning?</p>\n\n<p>A <em>word embedding</em> maps each word $w$ to a vector $v \\in \\mathbb{R}^d$, where $d$ is some not-too-large number (e.g., 500).  Popular <a href=\"https://en.wikipedia.org/wiki/Word_embedding\">word embeddings</a> include <a href=\"https://en.wikipedia.org/wiki/Word2vec\">word2vec</a> and <a href=\"http://nlp.stanford.edu/projects/glove/\">Glove</a>.</p>\n\n<p>I want to apply supervised learning to classify documents.  I'm currently mapping each document to a feature vector using the bag-of-words representation, then applying an off-the-shelf classifier.  I'd like replace the bag-of-words feature vector with something based on an existing pre-trained word embedding, to take advantage of the semantic knowledge that's contained in the word embedding.  Is there a standard way to do that?</p>\n\n<p>I can imagine some possibilities, but I don't know if there's something that makes the most sense.  Candidate approaches I've considered:</p>\n\n<ul>\n<li><p>I could compute the vector for each word in the document, and average all of them.  However, this seems like it might lose a lot of information.  For instance, with the bag-of-words representation, if there are a few words that are highly relevant to classification task and most words are irrelevant, the classifier can easily learn that; if I average the vectors for all the words in the document, the classifier has no chance.</p></li>\n<li><p>Concatenating the vectors for all the words doesn't work, because it doesn't lead to a fixed-size feature vector.  Also it seems like a bad idea because it will be overly sensitive to the specific placement of a word.</p></li>\n<li><p>I could use the word embedding to cluster the vocabulary of all words into a fixed set of clusters, say, 1000 clusters, where I use cosine similarity on the vectors as a measure of word similarity.  Then, instead of a bag-of-words, I could have a bag-of-clusters: the feature vector I supply to the classifer could be a 1000-vector, where the $i$th component counts the number of words in the document that are part of cluster $i$.</p></li>\n<li><p>Given a word $w$, these word embeddings let me compute a set of the top 20 most similar words $w_1,\\dots,w_{20}$ and their similarity score $s_1,\\dots,s_{20}$.  I could adapt the bag-of-words-like feature vector using this.  When I see the word $w$, in addition to incrementing the element corresponding to word $w$ by $1$, I could also increment the element corresponding to word $w_1$ by $s_1$, increment the element corresponding to word $w_2$ by $s_2$, and so on.</p></li>\n</ul>\n\n<p>Is there any specific approach that is likely to work well for document classification?</p>\n\n\n\n<p>I'm not looking for paragraph2vec or doc2vec; those require training on a large data corpus, and I don't have a large data corpus.  Instead, I want to use an existing word embedding.</p>\n", "pids": ["5550414c45ce0a409eb3a00c", "57a4e91dac44365e35c9848f", "57a4e921ac44365e35c9923c", "57a4e921ac44365e35c9923c"], "flag": 1}
{"question": "What is this unusual LCD controller technology?", "body": "<p>Preface: <strong>Even if you do not have a definite answer, I would greatly like feedback from anyone who has even seen an LCD using this technology.</strong></p>\n\n<p>I recently took apart a Canon digital camera from the late 1990s and obtained an unusual LCD display. Unlike the standard chip-on-glass controller technology used on modern LCDs, this one appears to have the <strong>chip embedded in the glass</strong>.</p>\n\n<p>Here is the camera in question, a Canon PowerShot S100 2MP Digital ELPH:</p>\n\n<p><a href=\"https://i.stack.imgur.com/e6yMu.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/e6yMu.jpg\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/3lFUO.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/3lFUO.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>Link to Amazon: <a href=\"http://rads.stackoverflow.com/amzn/click/B00004TS16\" rel=\"noreferrer\">http://www.amazon.com/Canon-PowerShot-Digital-Camera-Optical/dp/B00004TS16</a></p>\n\n<p>It appears to have first been sold on Amazon on <strong>September 4, 1999</strong>. I cannot find any other information about when it was released.</p>\n\n<p>When I took the display out, I noticed that the metal bezel around the display was only about 4mm on each side, and the flat flexible cable attached directly to the glass with no room for the standard controller chip. <strong>The display appears to have been made by Sony</strong>, as seen at the top left of the bezel and on the back of the display.</p>\n\n<p><a href=\"https://i.stack.imgur.com/FwsIW.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/FwsIW.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>I decided to remove the metal bezel, backlight, and filters and still could not find a controller chip. However, there was a black area around the display that appeared to be painted onto the top layer of the LCD, which made me curious as to what it was covering up. I decided to remove the top layer using the following procedure that has worked for me with other displays:</p>\n\n<ol>\n<li><p>Remove the top and bottom polarizers from the display.</p></li>\n<li><p>Score the center of the top of the display with a sharp tool\nparallel to the connector.</p></li>\n<li><p>Put the display in a plastic bag to aid with cleanup.</p></li>\n<li><p>Place a flat-head screwdriver over the center of the display\nparallel to the connector.</p></li>\n<li><p>Hit the handle of the screwdriver with gradually increasing strength\nuntil the top layer shatters.</p></li>\n<li><p>Remove the display from the bag and remove the shattered top layer.</p></li>\n<li><p>Clean the display to remove small glass fragments and the gel-like\nsubstance between the 2 layers.</p></li>\n</ol>\n\n<p>It worked and I was able to isolate the bottom layer. The controller integrated circuit appears to be embedded in the glass and distributed around the outside of the display. Here are some very close-up pictures:</p>\n\n<p><a href=\"https://i.stack.imgur.com/MSJwJ.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/MSJwJ.jpg\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/vMJvy.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/vMJvy.jpg\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/kMESM.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/kMESM.jpg\" alt=\"enter image description here\"></a></p>\n\n<p><a href=\"https://i.stack.imgur.com/acOUi.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/acOUi.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>I can not find any information about this technology on the internet, even just something saying that it exists. Does anyone here know what it is called, why it was used instead of chip-on-glass, when it was used, and if there is any information out there on it? <strong>Has anyone out there even seen this before?</strong></p>\n\n<p>Related question, if anyone knows why: Why do LCDs used in cameras have the pixels in a staggered arrangement (see my photos up close or look at a camera LCD yourself)?</p>\n", "pids": ["56d91314dabfae2eee47d1cd"], "flag": 1}
{"question": "PLL - why compare phases not frequencies", "body": "<p>I have a question about PLL's. The aim of PLL is to get two signals with the same frequencies (there can be a shift in phases, as I understand). So, in this case, why do you use a phase detector to compare phases, and NOT just compare frequencies?</p>\n\n<p>thank you</p>\n", "pids": ["573698516e3b12023e718d8d"], "flag": 1}
{"question": "Why don&#39;t we use lenses for RF?", "body": "<p>Radio waves are a class of electromagnetic waves.\nLight also is a class of electromagnetic waves.</p>\n<p>By shaping a material in which the speed of light changes, we can bend the propagation direction of light, we call this <strong>a lens</strong>, and we call the speed change rate refractive index <span class=\"math-container\">\\$n\\$</span>.</p>\n<p>Also for RF we can define a speed change rate as <span class=\"math-container\">\\$\\frac{1}{\\sqrt{LC}}\\$</span> or <span class=\"math-container\">\\$\\frac{1}{\\sqrt{\\epsilon_r\\mu_r}}\\$</span>.</p>\n<p>We also use the exact same destructive interference in the same way for radomes and Anti reflective coatings.</p>\n<p>So here comes the question: why don't we use lenses and  ̶m̶i̶r̶r̶o̶r̶s̶ for RF, for example for focusing RF beams instead of using complicated directive antennas?</p>\n<p>EDIT: yes, we actually use mirrors</p>\n", "pids": ["53e9b01cb7602d9703a74d28"], "flag": 1}
{"question": "Interpreting QQplot - Is there any rule of thumb to decide for non-normality?", "body": "<p>I have read enough threads on QQplots here to understand that a QQplot can be more informative than other normality tests. However, I am inexperienced with interpreting QQplots. I googled a lot; I found a lot of graphs of non-normal QQplots, but no clear rules on how to interpret them, other than what it seems to be comparison with know distributions plus \"gut feeling\". </p>\n\n<p>I would like to know if you have (or you know of) any rule of thumb to help you decide for non-normality.</p>\n\n<p>This question came up when I saw these two graphs:\n<a src=\"https://i.imgur.com/UcPyaad.jpg\" alt=\"graph 2\">\n<a src=\"https://i.imgur.com/XlPcbjB.jpg\" alt=\"graph 1\"></p>\n\n<p>I understand that the decision of non-normality depends on the data and what I want to do with them; however, my question is: generally, when do the observed departures from the straight line constitute enough evidence to make unreasonable the approximation of normality?</p>\n\n<p>For what it's worth, the Shapiro-Wilk test failed to reject the hypothesis of non-normality in both cases.</p>\n", "pids": ["56d85217dabfae2eee0b78a9"], "flag": 1}
{"question": "Do we have to tune the number of trees in a random forest?", "body": "<p>Software implementations of random forest classifiers have a number of parameters to allow users to fine-tune the algorithm's behavior, including the number of trees <span class=\"math-container\">$T$</span> in the forest. Is this a parameter that needs to be tuned, in the same way as <span class=\"math-container\">$m$</span>, the number of features to try at each split (what Leo Breiman calls <code>mtry</code>)?</p>\n", "pids": ["599c796d601a182cd263c5f6"], "flag": 1}
{"question": "Why do transformers use layer norm instead of batch norm?", "body": "<p>Both batch norm and layer norm are common normalization techniques for neural network training.</p>\n<p>I am wondering why transformers primarily use layer norm.</p>\n", "pids": ["5e451e433a55acfaed738742"], "flag": 1}
{"question": "Using deep learning for time series prediction", "body": "<p>I'm new in area of deep learning and for me first step was to read interesting articles from deeplearning.net site. In papers about deep learning, Hinton and others mostly talk about applying it to image problems. Can someone try to answer me can it be applied to problem of predicting time series values (financial, internet traffic,...) and what are important things that I should focus if it is possible?</p>\n", "pids": ["53e99bffb7602d97024ac0e6"], "flag": 1}
{"question": "Best PCA algorithm for huge number of features (&gt;10K)?", "body": "<p>I previously asked this on StackOverflow, but it seems like it might be more appropriate here, given that it didn't get any answers on SO.  It's kind of at the intersection between statistics and programming.</p>\n\n<p>I need to write some code to do PCA (Principal Component Analysis). I've browsed through the well-known algorithms and implemented <a href=\"http://en.wikipedia.org/wiki/Principal_component_analysis#Computing_principal_components_with_expectation_maximization\">this one</a>, which as far as I can tell is equivalent to the NIPALS algorithm.  It works well for finding the first 2-3 principal components, but then seems to become very slow to converge (on the order of hundreds to thousands of iterations). Here are the details of what I need:</p>\n\n<ol>\n<li><p>The algorithm must be efficient when dealing with huge numbers of features (order 10,000 to 20,000) and sample sizes on the order of a few hundred.</p></li>\n<li><p>It must be reasonably implementable without a decent linear algebra/matrix library, as the target language is D, which doesn't have one yet, and even if it did, I would prefer not to add it as a dependency to the project in question.</p></li>\n</ol>\n\n<p>As a side note, on the same dataset R seems to find all principal components very fast, but it uses singular value decomposition, which is not something I want to code myself.</p>\n", "pids": ["53e99b4ab7602d97023e94fa", "57da02330cf2ce2e6b0f19e0"], "flag": 1}
{"question": "Why implement microcontroller in FPGA?", "body": "<p>I am currently \"investigating\" FPGAs, what they can do, how they do it etc.</p>\n\n<p>In more than one place (<a href=\"http://www.fpga4fun.com/spoc.html\">for example here</a>) I have seen projects that implement a simple microcontroller with FPGA. </p>\n\n<p><strong>So my question:</strong> <br>\nI would like to know, what is the purpose of doing such implementations? Why use a microcontroller implemented in FPGA instead of having a micro on board? What are benefits? And perhaps also what are downsides?</p>\n", "pids": ["5550466b45ce0a409eb5e557"], "flag": 1}
{"question": "How large should the batch size be for stochastic gradient descent?", "body": "<p><a href=\"https://stats.stackexchange.com/questions/49528/batch-gradient-descent-versus-stochastic-gradient-descent\">I understand that stochastic gradient descent may be used to optimize a neural network using backpropagation by updating each iteration with a different sample of the training dataset.</a> <strong>How large should the batch size be?</strong></p>\n", "pids": ["53e9ada5b7602d97037a301f"], "flag": 1}
{"question": "What are the main theorems in Machine (Deep) Learning?", "body": "<p>Al Rahimi has recently given <a href=\"https://www.youtube.com/watch?v=Qi1Yry33TQE\" rel=\"noreferrer\">a very provocative talk</a> in NIPS 2017 comparing current Machine Learning to Alchemy. One of his claims is that we need to get back to theoretical developments, to have simple theorems proving foundational results. </p>\n\n<p>When he said that, I started looking for the main theorems for ML, but could not find a good reference making sense of the main results. So here is my question: what are the current main mathematical theorems (theory) in ML/DL and what do they prove? I would guess Vapnik's work would go somewhere here. As an extra, what are the main theoretical open problems?</p>\n", "pids": ["53e9a073b7602d9702958a46", "5d9edb8447c8f7664601d179"], "flag": 1}
{"question": "How is sebum secretion regulated?", "body": "<p>The principle of homeostasis in biology says that living organisms try to maintain some sort of equilibrium. Doing that requires the use of feedback mechanisms to regulate things like temperature, salinity, etc. Are there any feedback mechanisms the body uses to regulate the output of the skin's sebaceous glands? If so, what are they, and on what timescale do they operate?</p>\n", "pids": ["53e9bc80b7602d9704901623"], "flag": 1}
{"question": "When is a biased estimator preferable to unbiased one?", "body": "<p>It's obvious many times why one prefers an unbiased estimator. But, are there any circumstances under which we might actually prefer a biased estimator over an unbiased one?</p>\n", "pids": ["53e9a03bb7602d970292044b", "53e997ecb7602d9701fe7329"], "flag": 1}
{"question": "CNN architectures for regression?", "body": "<p>I've been working on a regression problem where the input is an image, and the label is a continuous value between 80 and 350. The images are of some chemicals after a reaction takes place. The color that turns out indicates the concentration of another chemical that's left over, and that's what the model is to output - the concentration of that chemical. The images can be rotated, flipped, mirrored, and the expected output should still be the same. This sort of analysis is done in real labs (very specialized machines output the concentration of the chemicals using color analysis just like I'm training this model to do).</p>\n\n<p>So far I've only experimented with models roughly based off VGG (multiple sequences of conv-conv-conv-pool blocks). Before experimenting with more recent architectures (Inception, ResNets, etc.), I thought I'd research if there are other architectures more commonly used for regression using images. </p>\n\n<p>The dataset looks like this:</p>\n\n<p><a href=\"https://i.stack.imgur.com/jd3Pj.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/jd3Pj.png\" alt=\"enter image description here\"></a></p>\n\n<p>The dataset contains about 5,000 250x250 samples, which I've resized to 64x64 so training is easier. Once I find a promising architecture, I'll experiment with larger resolution images. </p>\n\n<p>So far, my best models have a mean squared error on both training and validation sets of about 0.3, which is far from acceptable in my use case.</p>\n\n<p>My best model so far looks like this:</p>\n\n<pre><code>// pseudo code\nx = conv2d(x, filters=32, kernel=[3,3])-&gt;batch_norm()-&gt;relu()\nx = conv2d(x, filters=32, kernel=[3,3])-&gt;batch_norm()-&gt;relu()\nx = conv2d(x, filters=32, kernel=[3,3])-&gt;batch_norm()-&gt;relu()\nx = maxpool(x, size=[2,2], stride=[2,2])\n\nx = conv2d(x, filters=64, kernel=[3,3])-&gt;batch_norm()-&gt;relu()\nx = conv2d(x, filters=64, kernel=[3,3])-&gt;batch_norm()-&gt;relu()\nx = conv2d(x, filters=64, kernel=[3,3])-&gt;batch_norm()-&gt;relu()\nx = maxpool(x, size=[2,2], stride=[2,2])\n\nx = conv2d(x, filters=128, kernel=[3,3])-&gt;batch_norm()-&gt;relu()\nx = conv2d(x, filters=128, kernel=[3,3])-&gt;batch_norm()-&gt;relu()\nx = conv2d(x, filters=128, kernel=[3,3])-&gt;batch_norm()-&gt;relu()\nx = maxpool(x, size=[2,2], stride=[2,2])\n\nx = dropout()-&gt;conv2d(x, filters=128, kernel=[1, 1])-&gt;batch_norm()-&gt;relu()\nx = dropout()-&gt;conv2d(x, filters=32, kernel=[1, 1])-&gt;batch_norm()-&gt;relu()\n\ny = dense(x, units=1)\n\n// loss = mean_squared_error(y, labels)\n</code></pre>\n\n<h3>Question</h3>\n\n<p>What is an appropriate architecture for regression output from an image input?</p>\n\n<h3>Edit</h3>\n\n<p>I've rephrased my explanation and removed mentions of accuracy.</p>\n\n<h3>Edit 2</h3>\n\n<p>I've restructured my question so hopefully it's clear what I'm after</p>\n", "pids": ["5f00fc2edfae54b9a6bf7971", "5db9298f47c8f766461f956e"], "flag": 1}
{"question": "Is there any research about effect of unfamiliar environment on stress?", "body": "<p>It seems intuitive to me that there is some kind of stress when one is put in an unfamiliar place (There's probably effect on cognitive abilities too). However, I can't find any paper in psychology which discusses that potential relationship.</p>\n", "pids": ["55a47e4565ce31bc877cd228", "55a451e72401c6de3b8f30cd"], "flag": 1}
{"question": "How are propensity scores different from adding covariates in a regression, and when are they preferred to the latter?", "body": "<p>I admit I'm relatively new to propensity scores and causal analysis.</p>\n\n<p>One thing that's not obvious to me as a newcomer is how the \"balancing\" using propensity scores is mathematically different from what happens when we add covariates in a regression? What's different about the operation, and why is it (or is it) better than adding subpopulation covariates in a regression?</p>\n\n<p>I've seen some studies that do an empirical comparison of the methods, but I haven't seen a good discussion relating the mathematical properties of the two methods and why PSM lends itself to causal interpretations while including regression covariates does not. There also seems to be a lot of confusion and controversy in this field, which makes things even more difficult to pick up.</p>\n\n<p>Any thoughts on this or any pointers to good resources/papers to better understand the distinction? (I'm slowly making my way through Judea Pearl's causality book, so no need to point me to that)</p>\n", "pids": ["53e9b911b7602d97044fac7d"], "flag": 1}
{"question": "What does the term saturating nonlinearities mean?", "body": "<p>I was reading the paper <a href=\"http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\" rel=\"noreferrer\">ImageNet Classification with Deep Convolutional Neural Networks</a> and in section 3 were they explain the architecture of their Convolutional Neural Network they explain how they preferred using:</p>\n\n<blockquote>\n  <p>non-saturating nonlinearity <span class=\"math-container\">$f(x) = max(0, x). $</span></p>\n</blockquote>\n\n<p>because it was faster to train. In that paper they seem to refer to saturating nonlinearities as the more traditional functions used in CNNs, the sigmoid and the hyperbolic tangent functions (i.e. <span class=\"math-container\">$f(x) = tanh(x)$</span> and <span class=\"math-container\">$f(x) = \\frac{1}{1 + e^{-x}} = (1 + e^{-x})^{-1}$</span> as saturating). </p>\n\n<p>Why do they refer to these functions as \"saturating\" or \"non-saturating\"? In what sense are these function \"saturating\" or \"non-saturating\"? What do those terms mean in the context of convolutional neural networks? Are they used in other areas of machine learning (and statistics)? </p>\n", "pids": ["56d8ba3bdabfae2eee291a39"], "flag": 1}
{"question": "When conducting a t-test why would one prefer to assume (or test for) equal variances rather than always use a Welch approximation of the df?", "body": "<p>It seems like when the assumption of homogeneity of variance is met that the results from a Welch adjusted t-test and a standard t-test are approximately the same.  Why not simply always use the Welch adjusted t?</p>\n", "pids": ["63608e4f90e50fcafdee1041"], "flag": 1}
{"question": "Jung&#39;s Anima and Neurological Basis in Split-Brain Patients; Left-Persona and Right-Anima", "body": "<p>So, having skimmed some studies on split-brain patients, it makes me wonder about the whole \"left-brain/right-brain\" dichotomy that made its rounds in public perception some time ago.</p>\n\n<p>I'm not sure how much of that is really good science, but it looks like there's some real truth to the different sides taking on different roles and cognitive abilities.</p>\n\n<p>One thing in particular I wonder about now, is can you map Carl Jung's concept of Anima (I'll refer to the Anima, but what I have to say applies to Animus, as well) onto the right half of the brain?</p>\n\n<p>Jung's idea of Anima was essentially the male brain's mental image of \"the typical woman\". Thus it would posses typically feminine traits.</p>\n\n<p>Since the right half of the brain is associated with creativity, emotional response to (ie, recognizing) faces, and is more typically \"feminine\", would it be possible to devise an experiment with MRI to see if invoking the anima fires more neural activity on the right half of the brain?</p>\n\n<p>Say, have a subject describe \"the typical woman\" and watch activity, have them describe \"the typical man\" and some other controls to also invoke creativity and see how the neural activity compares? See if when men don a dress, their right-brain fires more activity than if they just don any other unfamiliar clothing (a hospital gown or a robe are gender-neutral but may also be unfamiliar enough to control for that part alone)?</p>\n\n<p>It's a very roundabout way of asking, but hopefully the questions kind of highlight the underlying question; </p>\n\n<p>in terms of Jungian Psychology, is it reasonable to hypothesize that you could split the hemispheres of the brain into \"persona\" and \"Anima\" as \"left\" and \"right\"? (and perhaps reversed for Persona and Animus)</p>\n\n<p>The interesting thing is that this leads to a testable hypothesis perhaps some people here already know the answer to: Is there any link between gender dysphoria and right-brain dominance? If there is, that would seem to support that hypothesis that the left hemisphere generally takes the masculine identity and the right houses the Anima (in general, though I would expect if the Anima exists as a largely separate neural network (or combined set of networks) that it would probably at least share a little activity on the left hemisphere).</p>\n", "pids": ["5f0e71869fced0a24b3ae58d", "5f0e71869fced0a24b3ae58d"], "flag": 1}
{"question": "What&#39;s the difference between Confirmation Bias and the Affect Heuristic?", "body": "<p>I've been reading \"Thinking Fast &amp; Slow,\" by Daniel Kahneman. At the end of Chapter 9, he introduces the \"Affect Heuristic,\" a concept introduced by <a href=\"https://pdfs.semanticscholar.org/7f12/9787664da49795bc3ecd517c86b31d17bac7.pdf\" rel=\"nofollow noreferrer\">Paul Slovic</a> that effectively states that people let their likes and dislikes determine their beliefs about the world.</p>\n\n<p>Isn't this just an extension of confirmation bias - e.g. that people look for confirming evidence when evaluating ideas? It seems obvious that if you like something or dislike a concept, you'll search for evidence to affirm your preexisting position. For example - if I was a conservative and I learned of a bill introduced by a liberal politician, I'd naturally make the assumption that the bill is misguided and search for evidence to confirm that assumption (and vice-versa).</p>\n\n<p>What's the difference between them? I'm having trouble defining the \"Affect Heuristic\" clearly in my mind.</p>\n", "pids": ["5de0d716df1a9c0c415bb4c9"], "flag": 1}
{"question": "Is there a word or phrase that describes emotional self harm?", "body": "<p>Is psychologically/mentally self harming yourself on purpose possible, where you look for things that trigger you (trigger your anxiety, stress or PTSD), not to desensitise yourself but to hurt yourself? Is there a word for it?</p>\n", "pids": ["53e9aae6b7602d9703465d19", "55a38f5d65ce5cd7b3ae9ffa", "53e9a317b7602d9702c1e327"], "flag": 1}
{"question": "Resources about relaxation training as used in CBT", "body": "<p>I’m looking for resources about the relaxation training component of CBT. I had a professor who spent a good deal of time on it in class, but I’m no longer attending that school and he’s notoriously unresponsive to email. I’m looking for anything about the technique as used in cognitive-behavioral therapy.</p>\n\n<p>Our professor did mention <em>The Relaxation Response</em>, a book published in the ‘70s, was the basis for the type he was teaching about.</p>\n", "pids": ["5d455ece275ded87f98044ec"], "flag": 1}
{"question": "Will some people ever be able to make our dreams visible on a screen?", "body": "<p>There are many SF-films in which dreams of people can be seen by others on a TV-screen. Don't you have to put so many information gathering devices in a person's brain for this to accomplish, that dream can't enter your brain anymore?</p>\n", "pids": ["53e9b0e6b7602d9703b609fc", "53e9b6cab7602d970425226b", "55aa8d6024017ee4447332b6", "573695886e3b12023e4a9f84"], "flag": 1}
{"question": "Preconditioning before asking a favor", "body": "<p>Suppose I want to borrow an item, such as a phone charger from someone.</p>\n\n<p>Instead of directly asking them, \"Could I borrow a charger?\"</p>\n\n<p>I first ask this question: \"Do you have a charger?\"</p>\n\n<p>The act of asking a question of fact (whether they have the item or not) will make them more willing to lend you the item.</p>\n\n<p>Is there a term or explanation for this? </p>\n\n<p>Is this related or similar to the Ben Franklin effect and Anchoring effect?</p>\n", "pids": ["5aa213cbc13b2b7cf985672a"], "flag": 1}
{"question": "Does the act of neural-repair fire off neurons?", "body": "<p><em>Disclaimer: I'm not well educated in this field, just a random curious person.  I don't know anything about neural repair save that it happens while we sleep.</em></p>\n\n<p>Anyways, the question is pretty simple: <strong>Does neural repair result in firing neurons?</strong></p>\n\n<p>Perhaps a damaged neuron being healed sometimes misfires, perhaps the little road workers that go around fixing neurons sometimes bump into things nearby and knock something loose, perhaps the processes of repairing leaves a bunch of neuro transmitters just floating in that area.. any of these could be a <em>reason for <strong>yes</em></strong>.</p>\n\n<p>A <em>reason for <strong>no</em></strong> might be \"We've studied where brain repair occurs, and where neurons are firing and there is no relation.\"</p>\n\n<p>Any solid speculation is nice too, as long as it's offered with a grain of salt.  </p>\n\n<p>I'm really just looking for something better than \"no clue.\"</p>\n", "pids": ["55a46e6465ce31bc877a79fd"], "flag": 1}
{"question": "Brain and General Sections", "body": "<p>Whereabouts in the brain gets triggered/switched on when an addictive substance is ingested/taken. I'm doing an addiction study with a couple of colleagues and would like some help with it.</p>\n", "pids": ["53e9b94db7602d9704539ed8"], "flag": 1}
{"question": "Does Raspberry Pi 4 supports pointer authentication?", "body": "<p>I know that ARM Pointer Authentication feature is supported on all ARMv8.3-A processors, and this version was presented at 10/2016. RPi 4 Model B was released last year so there is a good chance the version of the SoC processor supports this feature, but in all the specs I found the processor version is just ARMv8-A, without mentioning the sub-section.</p>\n\n<p>I'm a Software Security researcher, and I'm looking specifically for the Pointer Authentication feature so it's important to me to confirm its exists. Thanks in advance.</p>\n\n<p>EDIT: The syntax for using this feature is described in the picture below:</p>\n\n<p><a href=\"https://i.stack.imgur.com/lhyGg.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/lhyGg.png\" alt=\"enter image description here\"></a></p>\n", "pids": ["5e4e5ac53a55ac305df4b5b4"], "flag": 1}
{"question": "Adafruit 9-DOF or other accelerometer/magnetometer/gyroscope sensor for Raspberry PI 2/3 with Windows IoT", "body": "<p>I'm really new to both Raspberry and the whole electronics world: I'm experimenting with the board, using Windows IoT (since I'm quite familiar with C# as a development platform). I'm not, however, bound to this OS: I can switch to Raspian and see if I can play with Mono to use C# or change the language.</p>\n\n<p>Anyway, for my project - after blinking LEDs for a while - I'd like to connect a sensor to detect positioning and later on a camera. As for the sensor, I noticed on Adafruit that they have a nice piece which includes accel/mag/gyro: they sell it as \"for Arduino\" and I'm not yet at the point where I can tell the difference what goes well with what.</p>\n\n<p>Can I use this with Raspberry/Win? Do I have to revert to Raspian? Do I have to look for a completely different sensor?</p>\n\n<p>Thank you!</p>\n", "pids": ["599c794c601a182cd262dc69"], "flag": 1}
{"question": "People who climb the social hierarchy", "body": "<p>We know that people on top of the social hierarchy have (at least in developed countries) 30 or more years average life expectancy , more stable marriages, happier life and so on. So my question is for people who managed to get from the bottom to the top, what is their expected divorce rate, life expectancy and so on. It is more like the bottom or more like the top. Any research would help.</p>\n", "pids": ["55a4d62f612c6b12aafb5454"], "flag": 1}
{"question": "Would PCA work for boolean (binary) data types?", "body": "<p>I want to reduce the dimensionality of higher order systems and capture most of the covariance on a preferably 2 dimensional or 1 dimensional field. I understand this can be done via principal component analysis, and I have used PCA in many scenarios. However, I have never used it with boolean data types, and I was wondering if it is meaningful to do PCA with this set. So for example, pretend I have qualitative or descriptive metrics, and I assign a \"1\" if that metric is valid for that dimension, and a \"0\" if it is not (binary data). So for example, pretend you are trying to compare the Seven Dwarfs in Snow White. We have:</p>\n\n<p>Doc, Dopey, Bashful, Grumpy, Sneezy, Sleepy and Happy, and you want to arrange them based on qualities, and did so as is:</p>\n\n<p>$$\\begin{pmatrix}\n  &amp; Lactose\\ Intolerant &amp; A \\ Honor\\ Roll &amp; Athletic       &amp; Wealthy \\\\\nDoc &amp; 1 &amp; 0 &amp; 1 &amp; 1 \\\\\nDopey &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\\nBashful &amp; 1 &amp; 0 &amp; 1 &amp; 1 \\\\\nGrumpy &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\\nSneezy &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\\\\nSleepy &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\\nHappy  &amp; 1 &amp; 1 &amp; 0 &amp; 0\n\\end{pmatrix}$$</p>\n\n<p>So for example Bashful is lactose intolerant and not on the A honor roll. This is a purely hypothetical matrix, and my real matrix will have many more descriptive columns. My question is, would it still be appropriate to do PCA on this matrix as a means of finding the similarity between individuals?</p>\n", "pids": ["5550412a45ce0a409eb38f7a"], "flag": 1}
{"question": "Do lysosomes play any role in cell division?", "body": "<p>My biology textbook includes a point that lysosomes stimulates cell division without further elaborating. But studying it, I felt eerie about this function of lysosome. Then, I checked on the internet; found nothing relating cell division to lysosomes.</p>\n\n<p>Maybe, autophagy of lysosomes can play a role in this regard. Killing cells and thus 'stimulating' cell division. But this reasoning doesn't seem plausible as autophagy doesn't occur without extreme conditions.</p>\n\n<p>Nothing else is coming into my mind.</p>\n\n<p>So, is this point included in my book wrong or right? </p>\n", "pids": ["53e9a797b7602d97030d41ad"], "flag": 1}
{"question": "Understanding &quot;almost all local minimum have very similar function value to the global optimum&quot;", "body": "<p>In a <a href=\"http://www.offconvex.org/2016/03/22/saddlepoints/\">recent blog post</a> by Rong Ge, it was said that:  </p>\n\n<blockquote>\n  <p>It is believed that for many problems including learning deep nets, almost all local minimum have very similar function value to the global optimum, and hence finding a local minimum is good enough.</p>\n</blockquote>\n\n<p>Where does this belief come from?</p>\n", "pids": ["555048ef45ce0a409eb72b92", "5550413145ce0a409eb392b5"], "flag": 1}
{"question": "Resources for reliable psychology research", "body": "<p>I'm looking for resources of reliable research in psychology. I mean 'reliable' in the following two senses:</p>\n\n<p><strong>1. Replicability</strong></p>\n\n<p>It seems more and more of the famous effects that I, as a psychology-curious layman, learned about by watching intro psych lectures or in popular media fail replication. It starts to seem like anything one believes to know about psychology is as likely as not to be false. As a layman it is quite difficult to track down all of the possible effects and replications thereof. Is there some resource which tracks the replication status of psychological research and collects the different effects which are reproducible (and which aren't)? </p>\n\n<p>EDIT: I was able to find the following which is actually pretty close to what I was looking for. This is not a complete list but it is the kind of thing that I am after.</p>\n\n<p><a href=\"https://osf.io/fgjvw/\" rel=\"nofollow noreferrer\">https://osf.io/fgjvw/</a></p>\n\n<p>I found this through the links in the accepted answer to <a href=\"https://psychology.stackexchange.com/questions/893/are-there-any-journal-articles-in-psychology-that-have-promoted-and-discussed-re/896#896\">this</a> SE question, which was suggested by a commenter below. However, now the comment is gone for some reason so I cannot give credit.</p>\n\n<p><strong>2. \"Bi-partisanship\"</strong></p>\n\n<p>Some areas of psychology are politically charged. Things like gender, race, intelligence, etc.,  are understandably controversial. It seems that often professional psychologists fall down on either side of a given issue, each insisting that it was settled by the scientific community long ago in their favour. As a layman, this is rather frustrating to make sense of. Is there some \"common ground\" resource which tracks the research that all sides agree on?</p>\n", "pids": ["5c7553d0f56def979862c521", "55a64e1865ce054aad63d45e"], "flag": 1}
{"question": "Are there researched approaches to learning a subject more quickly?", "body": "<p>TLDR at bottom.</p>\n\n<p>So from my knowledge(correct me if I'm wrong) there is no evidence to suggest that we can improve general intelligence. But what about improving skills/intuition in specialized fields like programming or mathematics? </p>\n\n<p>I went through this course on coursera called Learning how to learn by Barbara Oakley(engineering professor) who suggests the following to quickly learn new subjects: </p>\n\n<ol>\n<li>Pomodoro technique 25 minutes study 5 min break</li>\n<li>Eliminate Distractions</li>\n<li>Do not neglect memory training. Recalling what you have studied is a great way to learn.</li>\n<li>Practice and consistency. </li>\n<li>Cramming is bad - it takes time to 'build neural chunks' as she says. I wasn't sure if this was based off of actual science or just conceptual. </li>\n</ol>\n\n<p>I do not like method 1 at all from my experience. Often times when I am going through technical textbooks and I have a timer randomly go off on me at 25 minutes in the session, I find myself jumping from my seat and my productivity wanes. However, timers at around 45 minutes(where my brain seems to slow down) does not have this kind of effect.</p>\n\n<p>But in Cal Newports Deep Work book, he suggests:</p>\n\n<ol>\n<li>Absolutely no distractions. Even delete social media from your life. Isolation can be a very ideal way of achieving deep levels of focus </li>\n<li>Be consistent.</li>\n<li>Do not tap in to willpower</li>\n<li>Use 'rituals' to turn the deep work mode on. </li>\n</ol>\n\n<p>From my experience, point 1 has severely reduced my ADHD symptoms and as a result my productivity has greatly improved. But even then, I still wonder to myself how much validity there are to these two professors approaches? Neither are neuroscientists, cognitive scientists, or psychology professors. I want to know if there is some kind of research, evidence(strong or weak), that there are more effective approaches to learning a specific field at a much faster pace. I have also read summaries of 'Peak' by Anders Erikson who is an apparent authority in this topic but I still haven't found anything eye opening. </p>\n\n<p><strong>Basically, is it possible to learn a subject at a much faster pace through the use of different studying techniques such as mnemonics, spaced repetition, etc.</strong></p>\n", "pids": ["56d920f1dabfae2eee9d50cb"], "flag": 1}
{"question": "Do smaller intelligent animals have a higher neuron density to account for their seeming intelligence? Otherwise, what?", "body": "<p>It seems like there's a lot of very small animals that have a much higher intelligence than what you would expect if you linearly projected intelligence as a function of brain size. There's ravens, crows and parrots which are much smaller than humans but have a recognizably high intelligence and emotional capacity. Then there's rats and general rodents like squirrels or similar animals like raccoons, and I guess an octopus to throw in which are good at problem solving and fierce fighters. Then there's also bugs like ants which are somehow very versatile and can adapt to many situations despite being that tiny, and with recent information may also have a recognizable emotional capacity like possibly bees.</p>\n\n<p>It would make sense to me if the correlation between neuron density and intelligence isn't linear, but I don't have the information to make any determinations. </p>\n", "pids": ["55a41dc6c91b587b096d54e7"], "flag": 1}
{"question": "How is 255 Tbit/s processed in optical fiber communication?", "body": "<p>I have never understood how the new record breaking data transfer speeds are achieved in terms of converting from/to electrical and optical signals.</p>\n\n<p>Suppose we have 255 Tbits of data and we want to transfer it in one second. (This is a real world achievement.) You got 255 Tbits stored in, let's say, 255 trillion capacitors (that's RAM). Now we are expected to be able to read each one successively, inquiring each bit so that one second later we have read all 255 trillion of them. This is obviously not orchestrated by a 3&nbsp;GHz processor.</p>\n\n<p>What about the receiving end? Pulses are coming at 255&nbsp;THz, yet the refresh rate of electronics trying to read an incoming signal is by far not 255&nbsp;THz. The only thing I can imagine is thousands of processors with their clock signals time division multiplexed (delayed) by less than 0.000000000001 secs. Although how to achieve such multiplexing also kind of brings me back to my problem with this thousandfold difference in frequencies.</p>\n", "pids": ["55d06aeb6963221905690d69"], "flag": 1}
{"question": "Why are non-conductive circuits designed on PCB？", "body": "<p>This is the PCB of the network communication industry.\nWhat I know now is that after adding these redundant non-conductive circuits, the performance is improved from Cat3 to CAT5e.\nI really want to know what the principle is. Thank you very much.\n<a href=\"https://i.stack.imgur.com/DgCji.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/DgCji.png\" alt=\"enter image description here\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/kkmIk.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/kkmIk.png\" alt=\"enter image description here\" /></a></p>\n", "pids": ["5a5eb5590cf20ef696a36f8f"], "flag": 1}
{"question": "Is it possible to generate light with an antenna?", "body": "<p>An antenna (e.g. a dipole) is able to radiate at a certain frequency thanks to the EM field generated by a current provided by a signal generator at such a frequency.</p>\n<p>So, for instance:</p>\n<p>Voltage source at frequency f (representing an amplifier) + Antenna made of conductors = Radiation at frequency f</p>\n<p>My question is: is it possible (or, maybe will it be possible) to generate light by using a voltage source at frequency of light (480-750THz)?</p>\n<p>All light sources I've seen are realized by using mechanisms different from EM radiation, like LEDs, LASER etc.</p>\n", "pids": ["5e16fa4bdf1a9c0c41713d63"], "flag": 1}
{"question": "How much do lithium polymer batteries expand in volume?", "body": "<p>I'm designing a device with a small lithium polymer battery (4x12x30 mm, 120 mA-h).  Looks like this:</p>\n\n<p><a href=\"https://i.stack.imgur.com/SoZQ0.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/SoZQ0.png\" alt=\"enter image description here\"></a></p>\n\n<p>I've heard that there is a rule of thumb that the space left for the battery in a case should be around 10% larger (I suppose primarily in thickness) than the nominal dimensions to allow for expansion.  Extra 10% seems quite large.</p>\n\n<ol>\n<li><p>Where does this rule of thumb come from?  Is there any official recommendation for how large a compartment to put lithium polymer cells in?</p></li>\n<li><p>How much do these batteries expand and shrink in normal use?  For example during charging/discharging cycles, temperature cycles over normal temperature range (-20C to 60C), etc.</p></li>\n<li><p>What happens if the battery is in a rigid compartment in the case of malfunction?  It's pretty common to have batteries \"puff out\" if they get shorted internally, but what happens if the battery is in a compartment that prevents expansion?  (Assume the compartment is strong enough to withstand the pressure build up)  Does the pressure/walls make the short worse, or better?</p></li>\n</ol>\n", "pids": ["56d82a33dabfae2eeef75e29", "56d82a39dabfae2eeef781c0"], "flag": 1}
{"question": "Is this really how p-values work? Can a million research papers per year be based on pure randomness?", "body": "<p>I'm very new to statistics, and I'm just learning to understand the basics, including $p$-values. But there is a huge question mark in my mind right now, and I kind of hope my understanding is wrong. Here's my thought process:</p>\n\n<p>Aren't all researches around the world somewhat like the monkeys in the \"infinite monkey theorem\"? Consider that there are 23887 universities in the world. If each university has 1000 students, that's 23 million students each year.</p>\n\n<p>Let's say that each year, each student does at least one piece of research, using hypothesis testing with $\\alpha=0.05$.</p>\n\n<p>Doesn't that mean that even if all the research samples were pulled from a random population, about 5% of them would \"reject the null hypothesis as invalid\". Wow. Think about that. That's about a million research papers per year getting published due to \"significant\" results.</p>\n\n<p>If this is how it works, this is scary. It means that a lot of the \"scientific truth\" we take for granted is based on pure randomness.</p>\n\n<p>A simple chunk of R code seems to support my understanding:</p>\n\n<pre class=\"lang-r prettyprint-override\"><code>library(data.table)\ndt &lt;- data.table(p=sapply(1:100000,function(x) t.test(rnorm(10,0,1))$p.value))\ndt[p&lt;0.05,]\n</code></pre>\n\n<p>So does this article on successful $p$-fishing: <a href=\"http://io9.com/i-fooled-millions-into-thinking-chocolate-helps-weight-1707251800\">I Fooled Millions Into Thinking Chocolate Helps Weight Loss. Here's How</a>.</p>\n\n<p>Is this really all there is to it? Is this how \"science\" is supposed to work?</p>\n", "pids": ["53e9b04eb7602d9703ab1ab3", "5a9dd650684d7e733ef88e6a", "53e9bdceb7602d9704a7f45b", "56d8f1f0dabfae2eee7ac133", "5a9e9f8b684d55eb9298e35d", "55a3d783612ca648687a9005"], "flag": 1}
{"question": "Bayesian equivalent of two sample t-test?", "body": "<p>I'm not looking for a plug and play method like BEST in R but rather a mathematical explanation of what are some Bayesian methods I can use to test the difference between the mean of two samples. </p>\n", "pids": ["6368773390e50fcafd6752d4"], "flag": 1}
{"question": "Is there a region of the brain that mediates pain in a manner reminiscent of the mesolimbic pathway?", "body": "<p>The mesolimbic dopamine pathway is a common neural pathway upon which rewards converge AKA the pleasure pathway.</p>\n\n<p>So I am trying to find a comparable pathway in the brain for pain -- is there such a thing? Ideally, one where a probe could be inserted and stimulated to induce intractable pain in the victim. Is there anything reminiscent of the mesolimbic pathway but for pain, perhaps with some sort of somatosensory mapping? </p>\n\n<p>What you never thought about using Deep Brain Stimulation to torture someone before? </p>\n", "pids": ["53e9bbcfb7602d970481ec9b"], "flag": 1}
{"question": "Beyond CBT and MBI, what are effective behavioral interventions for modern lifestyle addictions during their engagement?", "body": "<p>Some modern activities exploit the primitive mammalian reward areas in the brain. They include immediate access to social media, video games, music, sugar, pornographic material, gambling etc. Worse, excessively engaging in these activities without inhibition may enhance the neuroplasticity of the reward centers (and undermine the plasticity of areas involved in self-control, including the anterior cingulate cortex), thus leading to long-term changes of higher reward tolerance, lower self-regulatory abilities, and other exacerbating effects. Unfortunately, most worthwhile work (e.g., proactive learning, writing, thinking about new mechanisms and concepts etc.) usually doesn't offer nearly as much dopaminergic stimulation in the mammalian reward centers of the human brain. </p>\n\n<p><strong>Next to the obvious mindfulness-based interventions (e.g., being aware of the moment and noting the emotional occupation) and cognitive behavioral therapy based approaches (CBT), what interventions have proven to be effective or are likely to be effective for the use case below (*)?</strong> References to support these techniques are welcome. Perhaps some techniques from the substance abuse literature has some application. The main focus of this question mostly deals with the following situation:  </p>\n\n<p>(*) An adult is currently engaging in the addictive task and wishes to context-switch to the productive task. Additionally, the person is aware that the current (addictive) task offers a lower expected utility than the productive task. </p>\n", "pids": ["53e9aa8eb7602d9703409d9a", "5c0f8387da562944ac8c8bce", "5c0f8370da562944ac8c54b3"], "flag": 1}
{"question": "How does rectilinear activation function solve the vanishing gradient problem in neural networks?", "body": "<p>I found rectified linear unit (ReLU) praised at several places as a solution to the <a href=\"https://stats.stackexchange.com/q/130596/89550\">vanishing gradient problem</a> for neural networks. That is, one uses max(0,x) as activation function. When the activation is positive, it is obvious that this is better than, say, the sigmoid activation function, since its derivation is always 1 instead of an arbitrarily small value for large x. On the other hand, the derivation is exactly 0 when x is smaller than 0. In the worst case, when a unit is never activated, the weights for this unit would also never change anymore, and the unit would be forever useless - which seems much worse than even vanishingly small gradients. How do learning algorithms deal with that problem when they use ReLU?</p>\n", "pids": ["57a4e91dac44365e35c988cf"], "flag": 1}
{"question": "Why is softmax output not a good uncertainty measure for Deep Learning models?", "body": "<p>I've been working with Convolutional Neural Networks (CNNs) for some time now, mostly on image data for semantic segmentation/instance segmentation. I've often visualized the softmax of the network output as a \"heat map\" to see how high per pixel activations for a certain class are.\nI've interpreted low activations as \"uncertain\" / \"unconfident\" and high activations as \"certain\" / \"confident\" predictions. Basically this means interpreting the softmax output (values within $(0,1)$) as a probability or (un)certainty measure of the model. </p>\n\n<p>(<em>E.g. I've interpreted an object/area with a low softmax activation averaged over its pixels to be difficult for the CNN to detect, hence the CNN being \"uncertain\" about predicting this kind of object.</em>)</p>\n\n<p>In my perception this often worked, and adding additional samples of \"uncertain\" areas to the training results improved results on these. However <strong>I've heard quite often now from different sides that using/interpreting softmax output as an (un)certainty measure is not a good idea and is generally discouraged. Why?</strong></p>\n\n\n\n<p>EDIT: \nTo clarify what I'm asking here I'll elaborate on my insights so far in answering this question. However none of the following arguments made clear to me ** why it is generally a bad idea**, as I was repeatedly told by colleagues, supervisors and is also stated e.g. <a href=\"http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf\" rel=\"noreferrer\">here in section \"1.5\"</a></p>\n\n<blockquote>\n  <p>In classification models, the probability vector obtained at the end of the pipeline (the softmax output) is often erroneously interpreted as model confidence</p>\n</blockquote>\n\n<p>or <a href=\"https://hjweide.github.io/quantifying-uncertainty-in-neural-networks\" rel=\"noreferrer\">here in section \"Background\"</a> :</p>\n\n<blockquote>\n  <p>Although it may be tempting to interpret the values given by the final softmax layer of a convolutional neural network as confidence scores, we need to be careful not to read too much into this.</p>\n</blockquote>\n\n\n\n<p>The sources above reason that using the softmax output as uncertainty measure is bad because:</p>\n\n<blockquote>\n  <p>imperceptible perturbations to a real image can change a deep network’s softmax output to arbitrary values</p>\n</blockquote>\n\n<p>This means that softmax output isn't robust to \"imperceptible perturbations\" and hence it's output isn't usuable as probability. </p>\n\n<p>Another <a href=\"https://arxiv.org/abs/1312.6199\" rel=\"noreferrer\">paper</a> picks up on the \"softmax output = confidence\" idea and argues that with this intuition networks can be easily fooled, producing \"high confidence outputs for unrecognizable images\". </p>\n\n<blockquote>\n  <p>(...) the region (in the input domain) corresponding to a particular class may be much larger than the space in that region occupied by training examples from that class. The result of this is that an image may lie within the region assigned to a class and so be classified with a large peak in the softmax output, while still being far from images that occur naturally in that class in the training set.</p>\n</blockquote>\n\n<p>This means that data that is far away from training data should never get a high confidence, since the model \"can't\" be sure about it (as it has never seen it).</p>\n\n<p>However: Isn't this generally simply questioning the generalization properties of NNs as a whole? I.e. that the NN's with softmax loss don't generalize well to (1) \"imperceptible perturbations\" or (2) input data samples that are far away from the training data, e.g. unrecognizable images.</p>\n\n<p>Following this reasoning I still don't understand, why in practice with data that is not abstractly and artifically altered vs. the training data (i.e. most \"real\" applications), interpreting the softmax output as a \"pseudo-probability\" is a bad idea. After all, they seem to represent well what my model is sure about, even if it isn't correct (in which case I need to fix my model). And isn't model uncertainty always \"only\" an approximation?</p>\n", "pids": ["599c797a601a182cd2641eda", "58437725ac44360f1082faad", "599c797a601a182cd2641eda", "60c30d4b91e0117e30ca29fa", "53e9a93eb7602d97032928b5"], "flag": 1}
{"question": "Terminology: why do psychologists use &quot;positive&quot; and &quot;negative&quot;?", "body": "<p>In a lot of places in psychology - for example in operant conditioning and in describing symptoms of psychological disorders - various things are described as \"positive\" and \"negative\". Positive rewards/punishments or positive symptoms are things that are <em>added</em> or <em>given</em> to an individual, whereas negative rewards/punishments or symptoms are things that are <em>taken away</em> or that <em>disappear</em>. </p>\n\n<p>This terminology seems confusing - both the word \"positive\" and the word \"negative\" have other connotations in areas that psychology is concerned with, for example in describing mood. Using this particular terminology for things like the symptoms of psychological disorders, instead of less ambiguous words with more direct meanings like \"additive\" or \"subtractive\", seems confusing. Is there a particular reason why the words \"positive\" and \"negative\" continue to be used in a scientific sense over such less ambiguous alternatives?</p>\n", "pids": ["53e99b7eb7602d9702422a0d"], "flag": 1}
{"question": "Would non-neural physiological insights be considered to be in the field of neuroscience?", "body": "<p>For example, would e.g. SCR (skin conductance response) or hormone level be considered to be \"neuroscientific measures\" according to general definition of neuroscience?</p>\n", "pids": ["5c0f8243da562944ac89c3aa"], "flag": 1}
{"question": "What is a good resource on table design?", "body": "<p>I've seen various theoretical treatments of graphics, such as the <a href=\"http://rads.stackoverflow.com/amzn/click/0387987746\">Grammar of Graphics</a>. But I have seen nothing equivalent with regards to tables. Over the while I have developed an informal model of good practice in table design. \nHowever, I'd like to be able to provide a good reference to students.\nThe <a href=\"http://rads.stackoverflow.com/amzn/click/1557987912\">APA Style Manual</a> has a few tips on table design, but it is only a starting point.</p>\n\n<p>Question:\nWhat is a good resource that provides theoretical and practical advice on the presentation of numeric results in tables?</p>\n\n<p><strong>UPDATE:</strong> It would be particularly useful to have a good free online resource.</p>\n\n<p>Note: I'm not sure if this should be community wiki. I feel as if there might be a correct answer.</p>\n", "pids": ["53e9ab0eb7602d9703495499"], "flag": 1}
{"question": "Bayesian vs frequentist Interpretations of Probability", "body": "<p>Can someone give a good rundown of the differences between the Bayesian and the frequentist approach to probability?</p>\n\n<p>From what I understand:</p>\n\n<p>The frequentists view is that the data is a repeatable random sample (random variable) with a specific frequency/probability (which is defined as the relative frequency of an event as the number of trials approaches infinity). The underlying parameters and probabilities remain constant during this repeatable process and that the variation is due to variability in $X_n$ and <em>not</em> the probability distribution (which is fixed for a certain event/process).</p>\n\n<p>The bayesian view is that the <em>data</em> is fixed while the frequency/probability for a certain event can change meaning that the parameters of the distribution changes. In effect, the data that you get changes the prior distribution of a parameter which gets updated for each set of data.</p>\n\n<p>To me it seems that the frequentist approach is more practical/logical since it seems reasonable that events have a specific probability and that the variation is in our sampling.</p>\n\n<p>Furthermore, most data analysis from studies is usually done using the frequentist approach (i.e. confidence intervals, hypothesis testing with p-values etc) since it is easily understandable.</p>\n\n<p>I was just wondering whether anyone could give me a quick summary of their interpretation of bayesian vs frequentist approach including bayesian statistical equivalents of the frequentist p-value and confidence interval. In addition, specific examples of where 1 method would be preferable to the other is appreciated.</p>\n", "pids": ["5eba73be91e01108d77cf7ac"], "flag": 1}
{"question": "How to compare effectiveness of psychological treatment for psychological illness, versus medical treatment for medical illness?", "body": "<p>I'm a college student. I read somewhere that people often assume that mental health issues do not get better, and that a person ends up seeing a psychiatrist forever. So I was wondering if there was a way to compare treatments for medical vs psychological issues. </p>\n\n<p>Like let's say we pick 10 common physical illnesses and 10 common psychological illnesses. And then look at best treatments for each. For instance, assume sinus infections are the top physical illness and depression is the most common mental illness. Further assume that the best treatment for depression is CBT, and for sinus infection is nasal corticosteroids. How would I go about comparing the effectiveness of  corticosteroids for sinus infections versus CBT for depression? Is there a particular number, some effect size, or something else that I can take from one research study and compare it to the other?</p>\n\n<p>Thanks for help or clarification. </p>\n", "pids": ["55a5580f65ceb7cb02e8f860"], "flag": 1}
{"question": "Is it possible to give variable sized images as input to a convolutional neural network?", "body": "<p>Can we give images with variable size as input to a convolutional neural network for object detection? If possible, how can we do that?</p>\n\n\n\n<p>But if we try to crop the image, we will be loosing some portion of the image and if we try to resize, then, the clarity of the image will be lost. Does it mean that using inherent network property is the best if image clarity is the main point of consideration?</p>\n", "pids": ["55465d900cf2939c2fee792b"], "flag": 1}
{"question": "Is it possible to interpret the bootstrap from a Bayesian perspective?", "body": "<p>Ok, this is a question that keeps me up at night.</p>\n<p><strong>Can the bootstrap procedure be interpreted as approximating some Bayesian procedure (except for the Bayesian bootstrap)?</strong></p>\n<p>I really like the Bayesian &quot;interpretation&quot; of statistics which I find nicely coherent and easy to understand. However, I also have a weakness for the bootstrap procedure which is so simple, yet delivers reasonable inferences in many situations. I would be more happy with bootstrapping, however, if I knew that the bootstrap was approximating a posterior distribution in some sense.</p>\n<p>I know of the &quot;Bayesian bootstrap&quot; (Rubin, 1981), but from my perspective that version of the bootstrap is as problematic as the standard bootstrap. The problem is the really peculiar model assumption that you make, both when doing the classical and the Bayesian bootstrap, that is, the possible values of the distribution are only the values I've already seen. How can these strange model assumptions still yield the very reasonable inferences that bootstrap procedures yield? I have been looking for articles that have investigated the properties of the bootstrap (e.g. Weng, 1989) but I haven't found any clear explanation that I'm happy with.</p>\n<h1>References</h1>\n<p><a href=\"https://projecteuclid.org/journals/annals-of-statistics/volume-9/issue-1/The-Bayesian-Bootstrap/10.1214/aos/1176345338.full\" rel=\"nofollow noreferrer\">Donald B. Rubin (1981). The Bayesian Bootstrap.</a>\n<em>Ann. Statist.</em> Volume 9, Number 1 , 130-134.</p>\n<p><a href=\"https://www.jstor.org/stable/2241581\" rel=\"nofollow noreferrer\">Chung-Sing Weng (1989). On a Second-Order Asymptotic Property of the Bayesian Bootstrap Mean.</a>\n<em>The Annals of Statistics</em> , Vol. 17, No. 2 , pp. 705-710.</p>\n", "pids": ["5c7573fdf56def97988f9896"], "flag": 1}
{"question": "What algorithm is used in linear regression?", "body": "<p>I usually hear about \"ordinary least squares\".  Is that the most widely used algorithm used for linear regression?  Are there reasons to use a different one?</p>\n", "pids": ["5f0e4aa29fced0a24bc1ee09"], "flag": 1}
{"question": "How does the Adam method of stochastic gradient descent work?", "body": "<p>I'm familiar with basic gradient descent algorithms for training neural networks. I've read the paper proposing Adam: <a href=\"http://arxiv.org/pdf/1412.6980v8.pdf\" rel=\"noreferrer\">ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION</a>.</p>\n\n<p>While I've definitely got <em>some</em> insights (at least), the paper seems to be too high level for me overall. For example, a cost function $J(\\theta)$ is often a sum of many different functions, therefore a vast amount of calculations have to be made to optimize its value; stochastic gradient descents - as far as I'm understanding the topic - calculate the optimization only for a subset of the these functions. To me it is unclear, how Adam does this and why this results in a decreased training error for the whole of $J(\\theta)$.</p>\n\n<p>I think Adam updates its gradient by taking into account the previous gradient. They call it something like utilizing the momentum? What exactly is this momentum? According to the algorithm on page two in the paper, it is some kind of moving average, like some estimates of the first and second moments of the \"regular\" gradient?</p>\n\n<p>Practically, I would suspect that Adam enables one to use larger effective step sizes for decreasing the gradient and therefore the training error in combination with the stochastic approximation. Thus, the resulting update vector should \"jump\" around more in spatial dimensions, rather describing some curve like normal gradient descent algorithms would do.</p>\n\n<p>Can someone de-mystify how Adam works? Especially how it converges, specifically why Adam's method work and what exactly the benefit is?</p>\n", "pids": ["5550415745ce0a409eb3a739"], "flag": 1}
{"question": "Variational inference versus MCMC: when to choose one over the other?", "body": "<p>I think I get the general idea of both VI and MCMC including the various flavors of MCMC like Gibbs sampling, Metropolis Hastings etc. <a href=\"http://proceedings.mlr.press/v37/salimans15.pdf\" rel=\"nofollow noreferrer\">This</a> paper provides a wonderful exposition of both methods.</p>\n<p>I have the following questions:</p>\n<ul>\n<li>If I wish to do Bayesian inference, why would I choose one method over the other?</li>\n<li>What are the pros and cons of each of the methods?</li>\n</ul>\n<p>I understand that this is a pretty broad question, but any insights would be highly appreciated.</p>\n", "pids": ["5736960f6e3b12023e522205"], "flag": 1}
{"question": "What are the factors that cause the posterior distributions to be intractable?", "body": "<p>In Bayesian statistics, it is often mentioned that the posterior distribution is intractable and thus approximate inference must be applied. What are the factors that cause this intractability? </p>\n", "pids": ["5736960f6e3b12023e522205"], "flag": 1}
{"question": "Importance of local response normalization in CNN", "body": "<p>I've found that Imagenet and other large CNN makes use of local response normalization layers. However, I cannot find that much information about them. How important are they and when should they be used?</p>\n\n<p><strong>From <a href=\"http://caffe.berkeleyvision.org/tutorial/layers.html#data-layers\">http://caffe.berkeleyvision.org/tutorial/layers.html#data-layers</a>:</strong></p>\n\n<blockquote>\n  <p>\"The local response normalization layer performs a kind of “lateral\n  inhibition” by normalizing over local input regions. In\n  ACROSS_CHANNELS mode, the local regions extend across nearby channels,\n  but have no spatial extent (i.e., they have shape local_size x 1 x 1).\n  In WITHIN_CHANNEL mode, the local regions extend spatially, but are in\n  separate channels (i.e., they have shape 1 x local_size x local_size).\n  Each input value is divided by (1+(α/n)∑ix2i)β, where n is the size of\n  each local region, and the sum is taken over the region centered at\n  that value (zero padding is added where necessary).\"</p>\n</blockquote>\n\n<p><strong>Edit:</strong></p>\n\n<p>It seems that these kinds of layers have a minimal impact and are not used any more. Basically, their role have been outplayed by other regularization techniques (such as dropout and batch normalization), better initializations and training methods. See my answer below for more details.</p>\n", "pids": ["573696ce6e3b12023e5ce95a"], "flag": 1}
{"question": "How do I test a nonlinear association?", "body": "<p>For plot 1, I can test the association between x and y by doing a simple correlation.\n<a src=\"https://i.stack.imgur.com/E4fqq.png\" alt=\"plot 1\"></p>\n\n<p>For plot 2, where the relationship is nonlinear yet there is a clear relation between x and y, how can I test the association and label its nature? \n<a src=\"https://i.stack.imgur.com/6JzhM.png\" alt=\"plot 2\"></p>\n", "pids": ["53e99e13b7602d97026d9404"], "flag": 1}
{"question": "Encouraging Kindness in Rich People?", "body": "<p>Evidence presented in <a href=\"https://www.youtube.com/watch?v=L90R6PtxFKE\" rel=\"nofollow noreferrer\">this video</a> suggests that, statistically, rich people are more likely to be jerks than people with less money. How could this tendency be curbed, especially with regards to rich kids?</p>\n", "pids": ["55a3d231612ca6486879b45d", "56d8de5edabfae2eee01fa11", "55a469f3612ca6486895bedb", "56d8de5ddabfae2eee01f253"], "flag": 1}
{"question": "Difference between GradientDescentOptimizer and AdamOptimizer (TensorFlow)?", "body": "<p>I've written a simple <a href=\"https://en.wikipedia.org/wiki/Multilayer_perceptron\">MLP</a> in <a href=\"http://www.tensorflow.org/\">TensorFlow</a> which is modelling a <a href=\"https://en.wikipedia.org/wiki/XOR_gate\">XOR-Gate</a>.</p>\n\n<p>So for:</p>\n\n<pre><code>input_data = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\n</code></pre>\n\n<p>it should produce the following:</p>\n\n<pre><code>output_data = [[0.], [1.], [1.], [0.]]\n</code></pre>\n\n<p>The network has an input layer, a hidden layer and an output layer with 2, 5 and 1 neurons each.</p>\n\n<p>Currently I have the following cross entropy:</p>\n\n<pre><code>cross_entropy = -(n_output * tf.log(output) + (1 - n_output) * tf.log(1 - output))\n</code></pre>\n\n<p>I've also tried this simpler alternative:</p>\n\n<pre><code>cross_entropy = tf.square(n_output - output)\n</code></pre>\n\n<p>alongside with some other tries.</p>\n\n\n\n<p>However, no matter what my setup was, the error with a <code>GradientDescentOptimizer</code> was decreasing <strong>much</strong> slower than an <code>AdamOptimizer</code>.</p>\n\n<p>In fact <code>tf.train.AdamOptimizer(0.01)</code> produced really good results after 400-800 learning steps (in dependency of the learning rate, where <code>0.01</code> had the best results) while <code>tf.train.GradientDescentOptimizer</code> always needed over 2000 learning steps no matter what cross entropy calculation or learning rate was used.</p>\n\n<p><strong>Why is this so?</strong> It seems the <code>AdamOptimizer</code> is always a better choice?!</p>\n", "pids": ["53e9ada5b7602d97037a301f", "5550415745ce0a409eb3a739"], "flag": 1}
{"question": "Composer Thomas Schoenberger&#39;s Sophia Musik effect on the brain?", "body": "<p>Thomas Schoenberger claims his 'Sophia Musik' (the Ultimate Baby CDs) hav many beneficial effects on the brain.  Are you aware of this prolific composer and have any advice regarding his musical claims? </p>\n", "pids": ["53e9b6d0b7602d970425b876"], "flag": 1}
{"question": "Molecular psychology/psychiatry literature/articles", "body": "<p>I am new biology student which is on molecular biology subject on university. I would like to know something about genetic related to neurobiology, and certainly molecular psychiatry/psychology, perhaps evolution psychology. But i dont know where to start. </p>\n\n<p>Can anybody give me type to literature/articles for beginners?</p>\n", "pids": ["53e9bd7bb7602d9704a1fa02", "53e9af99b7602d97039e62b5"], "flag": 1}
{"question": "Entropy of an image", "body": "<p>What is the most information/physics-theoretical correct way to compute the entropy of an image? I don't care about computational efficiency right now - I want it theoretically as correct as possible.</p>\n\n<p>Lets start with a gray-scale image. One intuitive approach is to consider the image as a bag of pixels and compute\n$$\nH = - \\sum_k p_k log_2(p_k)\n$$\nwhere $K$ is the number of gray levels and $p_k$ is the probability associated with gray level $k$.</p>\n\n<p>There are two problems with this definition:</p>\n\n<ol>\n<li>It works for one band (i.e. gray-scale), but how should one extend it in a statistically correct way to multiple bands? For example, for 2 bands, should one base oneself on $(X_1,X_2)$ and thus on PMF using $P(X_1=x_1,X_2=x_2)$? If one has many ($B$>>2) bands then $P(X_1=x_1, ..., X_B=x_B) \\sim 1/N^B \\rightarrow H_{MAX}$, which seems wrong.</li>\n<li>Spatial information is not taken into account. For example, the images below (custody of <a href=\"http://www.johnloomis.org/ece563/notes/basics/entropy/entropy.html\" rel=\"noreferrer\">John Loomis</a>) have the same $H$, although clearly they do not convey the same information. </li>\n</ol>\n\n<p><a href=\"https://i.stack.imgur.com/hPjHn.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/hPjHn.png\" alt=\"enter image description here\"></a><a href=\"https://i.stack.imgur.com/2aysZ.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/2aysZ.png\" alt=\"enter image description here\"></a></p>\n\n<p>Anyone care to explain or give advice, or refer me to some decent reference material about the subject? I am mainly interested in a theoretically correct approach of the second problem (i.e. spatial information).</p>\n", "pids": ["58437725ac44360f108302b9", "62ac5b085aee126c0f2aacdc"], "flag": 1}
{"question": "how to weight KLD loss vs reconstruction loss in variational auto-encoder", "body": "<p>in nearly all code examples I've seen of a VAE, the loss functions are defined as follows (this is tensorflow code, but I've seen similar for theano, torch etc. It's also for a convnet, but that's also not too relevant, just affects the axes the sums are taken over):</p>\n\n<pre><code># latent space loss. KL divergence between latent space distribution and unit gaussian, for each batch.\n# first half of eq 10. in https://arxiv.org/abs/1312.6114\nkl_loss = -0.5 * tf.reduce_sum(1 + log_sigma_sq - tf.square(mu) - tf.exp(log_sigma_sq), axis=1)\n\n# reconstruction error, using pixel-wise L2 loss, for each batch\nrec_loss = tf.reduce_sum(tf.squared_difference(y, x), axis=[1,2,3])\n\n# or binary cross entropy (assuming 0...1 values)\ny = tf.clip_by_value(y, 1e-8, 1-1e-8) # prevent nan on log(0)\nrec_loss = -tf.reduce_sum(x * tf.log(y) + (1-x) * tf.log(1-y), axis=[1,2,3])\n\n# sum the two and average over batches\nloss = tf.reduce_mean(kl_loss + rec_loss)\n</code></pre>\n\n<p>However the numeric range of kl_loss and rec_loss are very dependent on latent space dims and input feature size (e.g. pixel resolution) respectively. Would it be sensible to replace the reduce_sum's with reduce_mean to get per z-dim KLD and per pixel (or feature) LSE or BCE? More importantly, how do we weight latent loss with reconstruction loss when summing together for the final loss? Is it just trial and error? or is there some theory (or at least rule of thumb) for it? I couldn't find any info on this anywhere (including the original paper). </p>\n\n\n\n<p>The issue I'm having, is that if the balance between my input feature (x) dimensions and latent space (z) dimensions is not 'optimum', either my reconstructions are very good but the learnt latent space is unstructured (if x dimensions is very high and reconstruction error dominates over KLD), or vice versa (reconstructions are not good but learnt latent space is well structured if KLD dominates).</p>\n\n<p>I'm finding myself having to normalise reconstruction loss (dividing by input feature size), and KLD (dividing by z dimensions) and then manually weighting the KLD term with an arbitrary weight factor (The normalisation is so that I can use the same or similar weight <em>independent of dimensions of x or z</em>). Empirically I've found around 0.1 to provide a good balance between reconstruction and structured latent space which feels like a 'sweet spot' to me. I'm looking for prior work in this area.</p>\n\n\n\n<p>Upon request, maths notation of above (focusing on L2 loss for reconstruction error)</p>\n\n<p>$$\\mathcal{L}_{latent}^{(i)} = -\\frac{1}{2} \\sum_{j=1}^{J}(1+\\log (\\sigma_j^{(i)})^2 - (\\mu_j^{(i)})^2 - (\\sigma_j^{(i)})^2)$$</p>\n\n<p>$$\\mathcal{L}_{recon}^{(i)} = -\\sum_{k=1}^{K}(y_k^{(i)}-x_k^{(i)})^2$$</p>\n\n<p>$$\\mathcal{L}^{(m)} = \\frac{1}{M}\\sum_{i=1}^{M}(\\mathcal{L}_{latent}^{(i)} + \\mathcal{L}_{recon}^{(i)})$$</p>\n\n<p>where $J$ is the dimensionality of latent vector $z$ (and corresponding mean $\\mu$ and variance $\\sigma^2$), $K$ is the dimensionality of the input features, $M$ is the mini-batch size, the superscript $(i)$ denotes the $i$th data point and $\\mathcal{L}^{(m)}$ is the loss for the $m$th mini-batch.</p>\n", "pids": ["5a260c0917c44a4ba8a1dfbc", "57a4e91dac44365e35c98217", "5a260c8617c44a4ba8a31c85", "599c7951601a182cd26300bc", "5736960d6e3b12023e520aaa"], "flag": 1}
{"question": "Optimized implementations of the Random Forest algorithm", "body": "<p>I have noticed that there are a few implementations of random forest such as ALGLIB, Waffles and some R packages like <code>randomForest</code>.  Can anybody tell me whether these libraries are highly optimized?  Are they basically equivalent to the random forests as detailed in <a href=\"http://statweb.stanford.edu/~tibs/ElemStatLearn/\">The Elements of Statistical Learning</a> or have a lot of extra tricks been added?</p>\n\n<p>I hope this question is specific enough.  As an illustration of the type of answer I am looking for, if somebody asked me whether the linear algebra package BLAS was highly optimized, I would say it was extremely highly optimized and mostly not worth trying to improve upon except in very specialized applications.</p>\n", "pids": ["63bfa9a690e50fcafd2d1286"], "flag": 1}
{"question": "Questions of the type &quot;What do you think he/she would think?&quot;", "body": "<p>For a study in the adoption of new technology, my student and I are developing a questionnaire that will poll respondents on their opinions of what their colleagues would think about benefits/problems of adopting a particular technology. This is research in social science/business but not strictly psychology, and as we are not psychologists, we don't know the literature. </p>\n\n<p>Have psychologists investigated questions of the type <em>What do you think other people would think?</em> We are not asking for a tutorial here, just a pointer where should we should start looking.</p>\n", "pids": ["53e99a9eb7602d970231569c"], "flag": 1}
{"question": "What is it called to attack a person then say something uplifting?", "body": "<p>Say a manager emailing the people under her in a way that to them feels degrading, and putting down. But at the end of the email its encouraging/uplifting type saying I know you are intelligent and capable people. </p>\n\n<p>So is there a name of this type of behavior to attack/degrade then at the end say something nice? </p>\n", "pids": ["55a5eba665cead59c82f953f"], "flag": 1}
{"question": "Is there a term for simulated irrationality?", "body": "<p>When 2 rational people want to accomplish their goals, they'll get compromise by meeting their goals halfway. But if one of them seems irrational, his opponent will go much farther in his concessions since he knows there's the risk of him burning everything to the ground.</p>\n\n<p><strong>Therefore, it can be advantegous to seem irrational or insane. Is there a term for behaving in such a manner on purpose?</strong></p>\n", "pids": ["53e9ac12b7602d97035d28f4"], "flag": 1}
{"question": "Is the visual cortex of a newborn baby immediately capable of object detection or is this skill learned over time, and if so, how?", "body": "<p>Is the visual cortex of newborn babies right off the bat capable of making sense of raw visual data, for instance, converting the constant stream of raw RGB images perceived by the eyes into a meaningful higher-level representation of objects in motion in a 3D world? Yes? No? If not, then does it mean this skill has to be developed over time by means of some <strong>learning mechanism</strong>?</p>\n\n<p>If the visual cortex needs time to learn advanced visual skills, how does the actual learning mechanism work? Does the visual cortex have to optimize the connections between neurons, in a way analogous to how artificial neural networks optimize their parameters through backpropagation algorithm (machine learning)? If this is the case, then where does the visual cortex get its error signals from? To make the last question clear, in machine learning the typical approach is to compute the gradient of a loss function which compares the model's prediction with the ground truth, and the model's parameters are updated by moving the parameters in the direction of the gradient. If the visual cortex is learning advanced visual skills by virtue of a similar learning mechanism, then what kind of loss function is the visual cortex optimizing?</p>\n", "pids": ["5966c66b0cf2aff42d51b618"], "flag": 1}
{"question": "Can a person with delusions completely acknowledge their delusions", "body": "<p>I wanted to ask a question for a story I'm writing;</p>\n\n<p>Can a person with delusions completely acknowledge that they have delusions? For example, if someone claims that for a long time he believed certain crucial things about his life to be true (possible things, nothing bizarre; Like his parents being dead and then seeing them at home, him going to a certain school but the school doesn't exist and he actually went to an entirely different one etc.) and then was proven otherwise. </p>\n\n<p>He has no fixations to his previous believes, he's completely open to the possibility of him not being able to differentiate reality (He was open the second he suspected something to be awry). </p>\n\n<p>Would he still fall under the delusional category? If not would it at least be considered an <em>unordinary</em> case?</p>\n", "pids": ["55a417cac91b587b096cb1d0", "55a449532401c6de3b8d2292", "55a441c32401c6de3b8b44ac"], "flag": 1}
{"question": "Why is the theory of mind named as such?", "body": "<blockquote>\n  <p><a href=\"https://en.wikipedia.org/wiki/Theory_of_mind#References\" rel=\"nofollow noreferrer\">Theory of mind</a> is the ability to attribute mental states—beliefs, intents, desires, emotions, knowledge, etc.—to oneself, and to others, and to understand that others have beliefs, desires, intentions, and perspectives that are different from one's own.</p>\n</blockquote>\n\n<p>So am I correct in saying that for a dyadic relationship, there are 2 \"theories of mind\", and for a group of $n$ person, there would be <a href=\"https://math.stackexchange.com/q/331383/157643\">$n^2-n$</a> \"theories of mind\"? I understand a system of inferences is properly called as \"theory\", but when so many people has different theory it loses the universal connotation as commonly used in \"theory of planned behavior\" or \"theory of gravitation\". Should it better be named as \"theory-forming of other's minds\"? </p>\n", "pids": ["53e9bdb3b7602d9704a62949", "53e9bbeab7602d970483e19e"], "flag": 1}
{"question": "Where to get psychology assessment resources to put into my website?", "body": "<p>I'm not a psychologist and would like to know how to get a psychological assessment to put into my website? Is there a public assessment with question data and scoring logic?</p>\n\n<p>I'm sorry if the question is obvious to psychologists, and feel free to close the question.</p>\n\n<p>I'm initially looking for assessment for students to help them choose a career path. I Googled \"student career path quiz\" and found numerous assessments, they're free as well, though I don't have the resources to create those assessments in my own website. So I guess my question is:</p>\n\n<p><strong>is there a public resource for psychological assessments, including questions, answers, scoring logic, and reporting?</strong></p>\n\n<p>To be clear: I want to put an psychological assessment in my website to assess students for choosing a career path (e.g. their personality model) one example is the <a href=\"https://openpsychometrics.org/tests/IPIP-BFFM/\" rel=\"nofollow noreferrer\">IPIP Big-Five Factor Markers by OpenPsychometrics</a> for the big five personality.</p>\n\n<p>I'm coming from a programming background, so I'll code the assessment myself. But to do it, I need the list of questions, answers, scoring functions, and reporting standard. The ones that I found have questions and answers, but I couldn't find the scoring logic and how to generate reports for such questionnaires. I'm asking if there are public questionnaires that can I take to put into my own website.</p>\n", "pids": ["55a3cc21c91b587b0962c980", "618ba2aa5244ab9dcbbc6d58"], "flag": 1}
{"question": "Test for bimodal distribution", "body": "<p>I wonder if there is any statistical test to \"test\" the significance of a bimodal distribution. I mean, How much my data meets the bimodal distribution or not? If so, is there any test in the R program?</p>\n", "pids": ["53e9b055b7602d9703ab8f44"], "flag": 1}
{"question": "What does White guilt feel like, how does it socially manifest itself &amp; is it treatable?", "body": "<p>White guilt would appear to be a genuine phenomenon which only White people can ever experience - and yet many people deny that it exists, at all, or that it is a form of phoney Liberalism or, worse, \"reverse racism\".</p>\n\n<p>However, such denials are suggestive of the very thing being denied. White guilt thus appears to feature characteristics of emotional self-indulgence, anger and the desire for forgiveness &amp; personal acceptance.</p>\n\n<p>Is White guilt the same or similar to other forms of guilt, or does it have its own unique characteristics setting it apart from other functions of the human conscience?</p>\n\n<p><a href=\"https://en.m.wikipedia.org/wiki/White_guilt\" rel=\"nofollow noreferrer\">White guilt</a></p>\n", "pids": ["53e9a1dbb7602d9702adafd0", "53e9ae04b7602d970380cc86", "56d81fdddabfae2eeeb4adf3"], "flag": 1}
{"question": "Difference between psychosis and schizophrenia", "body": "<p>Can you please illustrate the difference between the psychosis and the schizophrenia? </p>\n", "pids": ["5c757435f56def979891f59a", "6218b6de5aee126c0f7f879e"], "flag": 1}
{"question": "Kendrick et. al version of Maslow&#39;s Hierarchy", "body": "<p><a href=\"https://i.stack.imgur.com/4h6p9.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/4h6p9.png\" alt=\"updated version of Maslow's hierarchy of fundamental human motives\" /></a></p>\n<p>The above reinterpretation of the hierarchy by <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3161123/\" rel=\"nofollow noreferrer\">Kendrick et. al (2010)</a> is straightforward enough. I am trying to see if there is any work done on generalizing the top portion there beyond peaking out at parenting e.g. mate acquisition-retention and parenting applied for life pursuits like academic or professional accomplishments. Maybe subject-acquisition-retention and progeny?</p>\n<h2>References</h2>\n<p>Kenrick, D. T., Griskevicius, V., Neuberg, S. L., &amp; Schaller, M. (2010). Renovating the Pyramid of Needs: Contemporary Extensions Built Upon Ancient Foundations. <em>Perspectives on psychological science : a journal of the Association for Psychological Science, 5</em>(3), 292–314. doi: <a href=\"https://doi.org/10.1177/1745691610369469\" rel=\"nofollow noreferrer\">10.1177/1745691610369469</a></p>\n", "pids": ["5a9de82c684d7e733ef89184"], "flag": 1}
{"question": "An Example of Negative Reinforcement?", "body": "<p>In trying to understand the origins of test anxiety, a thought came up. </p>\n\n<blockquote>\n  <p>Consider an individual who has in the past performed badly in university assessment tasks. In an attempt to do better academically, the individual negatively reinforces unattainably high expectations to avoid any future feelings of inadequacy. </p>\n</blockquote>\n\n<p>Have I used the idea of negative reinforcement correctly in this instance? I have been taught the fundamental ideas of reinforcement and punishment as described by Skinner.</p>\n\n<p>Thanks :)</p>\n", "pids": ["5ae1b7bfa2e6b107866a6a75"], "flag": 1}
{"question": "Does societal view of epic musician, author&#39;s epic work affect mainly any human the way they view them overall or it&#39;s their personal life or both?", "body": "<p>I am trying to figure out this question. It's just an inquisitive thought.</p>\n\n<p>Does a musician, author, novelist, poet's personal life affect a human being's personal view of that epic figure rather than enjoying these figures' personal poetry, short story, novel, a novella, and other works?</p>\n\n<p>If no then why do epic figures are constantly criticized for their personal life? Is it fair?</p>\n", "pids": ["53e9a930b7602d970328093b"], "flag": 1}
{"question": "What is the difference between personality disorder and other types of mental illness?", "body": "<p>From <a href=\"https://www.mayoclinic.org/diseases-conditions/personality-disorders/symptoms-causes/syc-20354463\" rel=\"nofollow noreferrer\">Personality disorders - Mayo Clinic</a>:</p>\n\n<blockquote>\n  <p>A personality disorder is a type of mental disorder in which you have a rigid and unhealthy pattern of thinking, functioning and behaving. A person with a personality disorder has trouble perceiving and relating to situations and people. This causes significant problems and limitations in relationships, social activities, work and school.</p>\n</blockquote>\n\n<p>From <a href=\"https://www.mayoclinic.org/diseases-conditions/mental-illness/symptoms-causes/syc-20374968\" rel=\"nofollow noreferrer\">Mental illness - Mayo Clinic</a>:</p>\n\n<blockquote>\n  <p>Mental illness, also called mental health disorders, refers to a wide range of mental health conditions — disorders that affect your mood, thinking and behavior. Examples of mental illness include depression, anxiety disorders, schizophrenia, eating disorders and addictive behaviors.</p>\n</blockquote>\n\n<p>So I understand the personality disorders are more about having a rigid and unhealthy pattern of thinking, while mental illness in general is more about mood. However, in my understanding that mood is just automatic thinking that stems from past experience, which is no differ than personality disorder. The CBT approach, which is again fixing incorrect automatic thoughts, seems to be successful in working with both of them.</p>\n\n<p>So is there any actual difference between them? Or is that personality disorder just an extreme version of mental illness, in which the belief is more systematic (<a href=\"https://en.wikipedia.org/wiki/World_view\" rel=\"nofollow noreferrer\">world view</a> or <a href=\"https://en.wikipedia.org/wiki/Belief#Belief_systems\" rel=\"nofollow noreferrer\">belief system</a> I would say)?</p>\n\n<p><br></p>\n\n<p><sup>A minor and quick to answer question: why is personality disorder has the \"personality\" in its name? </sup></p>\n", "pids": ["5c7a69a0e1cd8e5cd2b37310", "5c3e1a33df5b8c0b3ccc4164"], "flag": 1}
{"question": "Hobbies / interests correlated with Big 5 scores?", "body": "<p>Are there any established treatments (I'm going to leave the exact terms a little bit vague because my understanding is vague) of which hobbies and interests are most likely to be attractive to someone with XYZ score on an  OCEAN / Big 5 test?</p>\n\n<p>TIA,</p>\n", "pids": ["5de0bc55df1a9c0c4159b5e2", "56d924a1dabfae2eeeb35972"], "flag": 1}
{"question": "Can somebody explain to me NUTS in english?", "body": "<p>My understanding of the algorithm is the following:</p>\n\n<p>No U-Turn Sampler (NUTS) is a Hamiltonian Monte Carlo Method. This means that it is not a Markov Chain method and thus, this algorithm avoids the random walk part, which is often deemed as inefficient and slow to converge.</p>\n\n<p>Instead of doing the random walk, NUTS does jumps of length x. Each jump doubles as the algorithm continues to run. This happens until the trajectory reaches a point where it wants to return to the starting point.</p>\n\n<p>My questions:\nWhat is so special about the U-turn?\nHow does doubling the trajectory not skip the optimized point?\nIs my above description correct?  </p>\n", "pids": ["5c756bb4f56def979840eb49"], "flag": 1}
{"question": "What makes solder harden?", "body": "<p>Soldering wire is very soft and pliable, but solder on a circuit board is hard.  Why?  I haven't been able to find a definitive answer, but some ideas that come to mind are:</p>\n\n<ul>\n<li><p>Some kind of chemical reaction that takes place when the solder is heated and then cools.  If so, what is this reaction?  Maybe with flux reacts somehow, but what about solder that doesn't have flux?</p></li>\n<li><p>The solder wire is less dense, either through being hollow or having a flux core, making it seem easier to bend.  This seems less likely, because tin whiskers seems much harder than solder wire despite being thinner.</p></li>\n</ul>\n", "pids": ["558ae20ce4b031bae1fa3f93"], "flag": 1}
{"question": "Is the electric field in a wire constant?", "body": "<p>If <span class=\"math-container\">\\$V=I\\cdot R\\$</span> according to Ohm's Law, that implies that <span class=\"math-container\">\\$\\frac{\\mathrm dV}{ \\mathrm dx} = \\frac{I \\rho}A\\$</span> across an infinitesimal length of conductor, which is constant at all points along the conductor since the current, resistivity, and area of the conductor are all constant.</p>\n<p><span class=\"math-container\">\\$\\frac{\\mathrm dV}{ \\mathrm dx}\\$</span> is also equal to the electric field, which I wouldn't think would be constant at all points along the conductor since E is a function of the distance from a source (e.g., the battery that the conductor is connected to), so I would think that E would change depending on the location of the conductor.  This change might be negligible for a short length of conductor, but over long lengths, I would expect it to be significant.</p>\n<ul>\n<li>So why is the voltage gradient constant if the electric field is not?</li>\n<li>Or is the electric field somehow constant at all points in the\nconductor?</li>\n</ul>\n", "pids": ["53e99784b7602d9701f3e166"], "flag": 1}
{"question": "Why might a 40 year old single chip processor have failed?", "body": "<p>I've had a <a href=\"https://www.radiomuseum.org/r/fluke_8050a_multimeter.html\" rel=\"noreferrer\">Fluke 8050A</a> bench multimeter sitting on a shelf in my cold, damp garage for about 30 years. It was new in 1981, last powered up in the 1980s, and the display was dead. I came across these <a href=\"http://mrmodemhead.com/blog/gallery/fluke-8050a-led-conversion/\" rel=\"noreferrer\">fine instructions</a> for display repair and thought I'd try. I was encouraged to find that the <a href=\"https://www.manualslib.com/download/821992/Fluke-8050a.html\" rel=\"noreferrer\">original Fluke manual</a> included the schematic, the layout and the calibration process.</p>\n<p>I replaced the 40-year-old NiCads and wired up one digit of the display. By this time, the DMM had had about two minutes powered on in the last 30 years. My one digit seemed sensible so I wired up the rest and turned it on. It worked! All the buttons worked and the display looked credible in all modes, so I gave it some DC input and compared it with a 6-month-old DVM.</p>\n<p><a href=\"https://i.stack.imgur.com/t5UN0.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/t5UN0.jpg\" alt=\"old and new readout\" /></a></p>\n<p>Great! Not bad drift for 40 years since last calibration!</p>\n<p>Unfortunately, everything went downhill from there. The Fluke DMM has a <a href=\"http://nice.kaze.com/MK3870.pdf\" rel=\"noreferrer\">Mostek MK3870/20</a> single chip processor which drives the display. That has 2kBytes of mask programmed ROM and 64 bytes of RAM. It's in a 40 pin plastic DIP package.</p>\n<p>After a total of maybe 5 minutes of power-on time in 30 years, the processor started to misbehave. First it displayed voltage correctly, but confused the decimal point. Then it would display the correct voltage for a fraction of a second before then displaying all zeroes. Then it displayed random output as the Fluke buttons were pressed. Then it failed to write the display at all. And finally, its 4Mhz built-in oscillator stopped oscillating. It was dead. All this happened over perhaps another 10 minutes. Measuring everything, I'm pretty confident that it's the processor chip itself that failed.</p>\n<p>A tragic tale, but at least the old DMM got to measure one last voltage before it died.</p>\n<p><strong>Is this sort of failure in a 40-year-old plastic chip to be expected? What might the actual failure mode be? Water ingress? Is there any way I might have avoided it?</strong></p>\n<hr />\n<p><strong>Those who wish to close this question as opinion-based, please note that I am not asking why my DMM is broken. I am asking what failure modes exist for a 40-year old plastic chip, long unused, and what mitigation might help.</strong></p>\n<p>Thanks!</p>\n", "pids": ["56d82531dabfae2eeed7f269"], "flag": 1}
{"question": "Laughing as a psychological defense when nervous", "body": "<p>Say a persons experienced a scarring event in their life (ptsd), and so their mind has developed defense in which they laugh uncontrollably whenever their nervous. This is similar to Joker 2019, whenever Arthur was stressed or depressed he would break out in a laughing episode. However, I began to think otherwise, because later in the film Arthur was physically abused as a child (even being tied to a radiator), which may contributed to this being a physical disorder, but I'm looking for a psychological disorder. </p>\n\n<p>What is the name/term for this condition.</p>\n\n<p>I've thought of psuedobulbar affect (PBA), but after doing research, it is a physical disorder, not purely psychological.</p>\n", "pids": ["657017ac939a5f408286520d"], "flag": 1}
{"question": "Charging Li-ion batteries in parallel", "body": "<p>I wanted some opinion on my set up here, just to make sure I got the basics right.</p>\n\n<p>I have a Li-ion battery charging circuit based on the MCP73113. This is designed to be a single-cell battery charger. </p>\n\n<p>The battery itself (3.7V, 650mAh) comes with its own PCB with Schottky diode and current regulators as protection.\nEDIT: Not a Schottky diode. Current limiter and a Protection IC.</p>\n\n<p>By design, they work together just fine.</p>\n\n<p>I have more batteries from the same manufacturer and wanted to make higher capacity packs by putting two cells in parallel. The two cells come with their own PCB, but I only kept one of them, as I soldered their leads together. It seems to work and they are charged and discharged just like regular batteries (3.7V, now 1300 mAh).</p>\n\n<p>However, not all the packs I made work smoothly and I get a failure rate of 2 in every 10 packs. They all start out normally, but occasionally when the batteries are not charged for some time, or are used up, they tend to not work anymore. So far, in only 1 pack I found the voltage to be different (both now below 2V, aka dead).</p>\n\n<p>I assume my method is not the right approach to ensure 100% success rate, so I was wondering how can this be solved. All the controllers I looked into was designed for multiple cells in series, not parallel. Am I fundamentally missing something here?</p>\n", "pids": ["53e9a620b7602d9702f4f91c"], "flag": 1}
{"question": "What can coma patients report about their experiences - if anything?", "body": "<p><a href=\"https://en.wikipedia.org/wiki/Coma\" rel=\"nofollow noreferrer\">Coma</a> is correlated to a significant inactivity of the cerebral cortex and the reticular activating system, while other parts of the brain - e.g. the limbic system - might still show considerable activity.</p>\n\n<p>My question is:</p>\n\n<blockquote>\n  <p>Are there cases where people recovered from a coma and could later plausibly report experiences they made during the coma?</p>\n</blockquote>\n\n<p>What kind of experiences would they typically report - if any? And how fine-grained can descriptions of such experiences be?</p>\n\n<p>Examples:</p>\n\n<ul>\n<li>\"I felt that I were alive.\" </li>\n<li>\"I felt horrible/relaxed.\" </li>\n<li>\"I sometimes felt hungry.\" </li>\n<li>\"I felt that my mother was there.\"</li>\n<li>\"I somehow felt she touched me.\" </li>\n<li>\"I somehow heard her say my name.\"</li>\n</ul>\n\n<p>Most surely, elaborate thoughts and complex emotions can not be recalled and plausibly reported (because they could not take place).</p>\n\n<blockquote>\n  <p>What would such reports tell us about the neural basis of\n  consciousness?</p>\n</blockquote>\n\n<p>Are there forms of recoverable coma where the cerebral cortex and/or the reticular activating system is completely mute, i.e. without any measurable coordinated neural activity?</p>\n\n<p>Do other parts of the brain necessarily show no measurable coordinated neural activity when the cerebral cortex and/or the reticular activating system doesn't?</p>\n", "pids": ["553bf9990cf2b2c73cb0539c"], "flag": 1}
{"question": "How are neurotransmitter receptors discovered?", "body": "<p>Many neurotransmitter receptors are known, for example 5-HT<sub>2a</sub>, Mu, NMDA, and so on. How have these receptors been discovered?</p>\n", "pids": ["53e9a487b7602d9702da4901"], "flag": 1}
{"question": "Plutchik&#39;s emotions from negative to positive", "body": "<p>I'm trying to order Plutchik's emotions model from the most negative to the most positive.</p>\n\n<p>These are the emotions in alphabetical order: </p>\n\n<pre><code>anger, anticipation, disgust, fear, joy, sadness, surprise, trust\n</code></pre>\n\n<p>I didn't find anything online regarding this. Can someone help me?</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 1}
{"question": "Is it possible to determine load on a stepper motor when stopped", "body": "<p>Is there a way that the torque on a stepper motor can be determined without some kind of additional force sensor.</p>\n\n<p>Additional electronics such as current shunts etc would be acceptable.</p>\n\n<p>I would like to use the stepper in a winding mechanism and want to be able to check if the stepper is under load before I swap to freewheeling mode.</p>\n\n<p>As far as I understand I would not be able to tell directly when the stepper motor is stopped directly. However I thought some kind of trick like jogging the stepper backwards and forwards a step and watching the current may be plausible.</p>\n\n<p>Does this sound plausible? Or does anyone have a better idea.</p>\n\n<p>Edit: To clarify I am not that interested in the precise value of the torque, I am more interested in checking that there is no significant torque.</p>\n", "pids": ["56d891dadabfae2eeeee82e6"], "flag": 1}
{"question": "Relationships Between Specific Behavioral Characteristics Associated With Clinical Diagnosis of Narcissists &amp; Sociopaths", "body": "<p>In the past 3½ decades, I've discussed, read, and studied a significant number of mental health practitioner claims, random anecdotal experiences, and clinical study abstract summaries &amp; reports regarding what is now called Narcissist Personality Disorder (NPD) and how this disorder relates to the psychological condition referred to as a sociopath. When I first looked into how the clinical community faced these two very similar conditions, I found most qualified sources to be mostly consistent in what they indicated.</p>\n\n<p>However, always open to opposing views, I've also read or been informed by others that seem to indicate the earlier claims have all made the same assumptions, and what was considered a common error. The conflicting sources suggested that the earlier sources all conflated the clinical behavior characteristics of the NPD condition with those exhibited by and leading to a diagnosis of a sociopath. </p>\n\n<p>In response to the resulting muddied waters, I found some clarity, at least to myself, in the notion that all Sociopaths are narcissists, but not all narcissists are sociopaths. In other words, when further confused and contradicted, I've always had a tendency to fall back onto those conclusions I arrived at years ago when first settling on a satisfactory understanding of the two. </p>\n\n<p>This understanding concluded that if a subject who was previously diagnosed with NPD was to be clinically diagnosed with the more severe condition of a sociopath, (I assume when formally diagnosed, the vernacular is more sophisticated than what I'm using here) the mental health practitioner making the determination would be required to observe, document, and assess any quantified increases in magnitudes of or changes to exhibited behavioral characteristics common to both the diagnosis of the NPD and the sociopath conditions, as well as any behavioral characteristics associated with either condition but presenting in novel form with the subject.</p>\n\n<p>From what I can remember, a number of these exhibited behaviors were very similar to, if not the same as those used in diagnosing someone with NPD, just at some sorry of elevated measure. Others were similar to those used with NPD, but would exhibit distinct differences if done so by a sociopath. Finally, some of those exhibited behaviors which contribute to the diagnosis of a sociopath seemed completely divorced from and in a few instances conflict with those suggesting a diagnosis of NPD.</p>\n\n<p>Frustratingly, what I have not retained are the specific characteristics or symptoms which triggered the very conversations I remember having. But what I do remember, and do so very clearly, was the lack of intellectual  satisfaction I always felt walking away from these discussion related to the unreconciled relationship I always felt these two conditions have to one another, where the parallels in behavior characteristics begin and where they end, or whether or not my fall back conclusion which always seemed to relation static was actually valid, at least from the clinical standpoint.</p>\n\n<p>I know I'm going to be told I can only present one question per post. As such, I'm going to get ahead of that criticism by providing my only question here:</p>\n\n<p><strong>Are there any relationships, similarities, or differences between the specific behavioral characteristics associated with a clinical diagnosis of narcissistic personality disorder (NPD) and those associated with a clinical diagnosis of a sociopath?</strong> </p>\n\n<p>That said, the following are not questions to be answered, rather meant to ensure those attempting to provide an answer have been provided a clear understanding of precisely what the single question above is trying to ask.</p>\n\n<p>The following should not be considered additional questions needed to be answered, that would be very anti-stack of me to do. Instead, the following offer additional granularity and detail in the form of drill down questions. These are meant for purposes of guidance in answering the single, not a multiple set of questions noted in bold above. </p>\n\n<p>Basically, I'm restating the same question in a few different ways at a few different levels to ensure the full breadth of the single question is understood and hopefully answered:</p>\n\n<p>1.1 - What are the actual, clinical differences between NPD and the disorder colloquially known as a sociopath?</p>\n\n<p>1.2 - Are the two conditions, NPD and the condition of sociopath, actually considered to be clinically related?</p>\n\n<p>1.3 -  Is the relationship really as simplistic as it always just a case of a narcissist exhibiting more acute levels of behavior which is common to both conditions, meet or exceeded a certain behavioral threshold, and thus jumped to the diagnosis of the more severe of the two conditions, and is now a sociopath?</p>\n\n<p>1.4 - If that's the case, what are the specific behavioral characteristics used to make this determination in the clinical setting?</p>\n\n<p>1.5 - What are the predetermined thresholds, how is the associated behavior quantified, and how are those metrics measured?</p>\n\n<p>See, those are simply all small parts of the same question. That's why they are numbered 1.X, to ensure that they are simply detailed parts of the single question in bold.</p>\n\n<p>For the record, this question is being asked to assist me in determining whether specific people I've been exposed to during my life at various times and to various effects to me, were as I suspect, likely diagnosable as sociopaths. All are narcissists, but the lines of delineation are not stated very clearly.</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 1}
{"question": "Is there an analog to the five factor model for emotion?", "body": "<p>To the best of my understanding, the five factor model of personality comes from a factor analysis on a large list of adjectives that can be used to describe an individual's personality. It is validated, in some sense, by its usefulness in predicting behavior and life outcomes in a wide range of contexts.</p>\n<p>It seems like something very similar could be done for emotion. I.e. list words describing a persons present state (angry, remorseful, sad, bitter, frustrated, etcetera) and do a factor analysis on those. Then, see if the resulting model (assuming that the analysis yields something useful) is predictive of shorter term / state dependent behavior.</p>\n<p>Has any work like this been done?</p>\n", "pids": ["5e297001df1a9c0c41e7a137"], "flag": 1}
{"question": "What does the &#39;junction&#39; of a silicon semiconductor look like in real-life?", "body": "<p>The P-N junction is a small area within a package where heating is most prominent. Junction temperature is a key parameter we try to track when operating a diode or a transistor.</p>\n<p>I am wondering what the so-called 'junction' really looks like in real-life, when you, say, cut a semiconductor in half. I was told the junction is more like a plane. Can someone elaborate?</p>\n", "pids": ["56d91ca2dabfae2eee83f2ef"], "flag": 1}
{"question": "A few questions on PIRs and other motion detectors", "body": "<p>I grew up incorrectly believing that motion detectors (as part of burglar alarm systems) were designed to detect movement, when in actual fact it is the movement of a heated (like body heat) object which causes them to trip. I also understand there are some which are so sensitive they can even detect the body heat from fingers typing on a keyboard!</p>\n<p><strong>Question #1:</strong> Are there motion detectors which just detect motion, without the moving object having to radiate heat?</p>\n<p>I ask this question because the above sensors can be blinded by a small glass picture frame placed over them, with a long pole. It would be much more difficult to bypass if they detected movement.</p>\n<p>I assume we should exclude sonar sensors since they are easily bypassed with a thin layer of fabric, such as wearing a bed sheet like a ghost, according to Myth Busters.</p>\n<p><strong>Question #2:</strong> Aside from microwave motion detectors potentially being problematic when they can detect movement through solid objects such as wooden walls, furniture, and glass which could lead to false alarms - why are they not used more frequently?</p>\n<p><strong>Question #3:</strong> Why do some PIRs in alarm systems have three LED lights yellow | red | green under the plastic sensor? I ask as perhaps they detect three different types of movement, so this might be related to the question and not off-topic.</p>\n", "pids": ["53e9a7f1b7602d97031316e9"], "flag": 1}
{"question": "If the instructions of a group intelligence test are misunderstood, are the results of that test invalid?", "body": "<p>For example, a researcher is investigating synonyms and prepares a test.  A participant undertaking the test incorrectly interprets the instructions, and understands the test to relate to antonyms rather than synonyms.</p>\n<p>Does this then make the test results invalid?</p>\n", "pids": ["56d924a3dabfae2eeeb363ad"], "flag": 1}
{"question": "Clues for genetic basis in Autism Spectrum Disorders", "body": "<p>In <a href=\"https://neurology.mhmedical.com/book.aspx?bookID=1049\" rel=\"nofollow noreferrer\">Principles of Neural Science 5th edition</a>, Chapter 3, It Is said that Autism Is a genetic disorder but which genes are involved Is not clear, how do we know there Is a genetic basis and Is not a response to environmental factors (or a combination)?</p>\n", "pids": ["5db9264447c8f766461ace0e"], "flag": 1}
{"question": "When should I use a variational autoencoder as opposed to an autoencoder?", "body": "<p>I understand the basic structure of variational autoencoder and normal (deterministic) autoencoder and the math behind them, but when and why would I prefer one type of autoencoder to the other? All I can think about is the prior distribution of latent variables of variational autoencoder allows us to sample the latent variables and then construct the new image. What advantage does the stochasticity of variational autoencoder over the deterministic autoencoder?</p>\n", "pids": ["5736986a6e3b12023e72f4f5", "57a4e921ac44365e35c9918a"], "flag": 1}
{"question": "Why do so many parasites infect definitive and intermediate hosts rather than just one host?", "body": "<p>Many parasites infect multiple host species, with one host species being the definitive host (where the parasite reproduces), and the other host species being the intermediate host (where the parasite grows to maturity). (Further details described as \"complex life cycle\" at <a href=\"https://en.wikipedia.org/wiki/Parasitic_life_cycle\" rel=\"noreferrer\">https://en.wikipedia.org/wiki/Parasitic_life_cycle</a> ) Why is this complex life cycle so common? Why wouldn't more parasites adopt a simpler life cycle of just one host? </p>\n\n<p><strike>I knew that there were some parasites that infected more than one kind of host species, but now that I am looking into it, it seems like a majority of internal parasites have this kind of life cycle. Does anyone know why?</strike></p>\n", "pids": ["53e9ae63b7602d9703880a26"], "flag": 1}
{"question": "Are pooling layers added before or after dropout layers?", "body": "<p>I'm creating a convolutional neural network (CNN), where I have a convolutional layer followed by a pooling layer and I want to apply dropout to reduce overfitting. I have this feeling that the dropout layer should be applied after the pooling layer, but I don't really have anything to back that up. Where is the right place to add the dropout layer? Before or after the pooling layer?</p>\n", "pids": ["573697826e3b12023e66901d"], "flag": 1}
{"question": "Approximate $e$ using Monte Carlo Simulation", "body": "<p>I've been looking at Monte Carlo simulation recently, and have been using it to approximate constants such as $\\pi$ (circle inside a rectangle, proportionate area).</p>\n\n<p>However, I'm unable to think of a corresponding method of approximating the value of $e$ [Euler's number] using Monte Carlo integration.</p>\n\n<p>Do you have any pointers on how this can be done?</p>\n", "pids": ["53e9a82bb7602d970317166a"], "flag": 1}
{"question": "How to set up neural network to output ordinal data?", "body": "<p>I have a neural network set up to predict something where the output variable is ordinal.  I will describe below using three possible outputs A &lt; B &lt; C.  </p>\n\n<p>It is pretty obvious how to use a neural network to output categorical data: the output is just a softmax of the last (usually fully connected) layer, one per category, and the predicted category is the one with the largest output value (this is the default in many popular models).  I have been using the same setup for ordinal values.  However, in this case the outputs often don't make sense, for example the network outputs for A and C are high but B is low: this is not plausible for ordinal values.</p>\n\n<p>I have one idea for this, which is to calculate loss based on comparing the outputs with 1 0 0 for A, 1 1 0 for B, and 1 1 1 for C.  The exact thresholds can be tuned later using another classifier (eg Bayesian) but this seems to capture the essential idea of an ordering of inputs, without prescribing any specific interval scale.</p>\n\n<p>What is the standard way of solving this problem?  Is there any research or references that describe the pros and cons of different approaches?</p>\n", "pids": ["5ff8122ad4150a363c02cb95"], "flag": 1}
{"question": "How can positive and negative mindsets influence interpersonal relationships with others?", "body": "<p>I want to know how positive and negative mindset can influence interpersonal relationships with others.  For example: if you have a negative mindset, would people not want to relate with you?</p>\n", "pids": ["5e297001df1a9c0c41e7a137", "53e9991db7602d970215bf3c"], "flag": 1}
{"question": "What percentage of fish are herbivorous vs. carnivorous?", "body": "<p>It appears that the majority of fish we eat are carnivorous, such as salmon and tuna. This got me wondering how common herbivores and carnivores are among fish species. I couldn't find an answer to this question through a cursory search of the internet.</p>\n", "pids": ["53e99ef4b7602d97027c27d9"], "flag": 1}
{"question": "Metacognitive strategy in terms of cognitive science", "body": "<p>Everything I can find about term 'metacognitive strategy' or 'metacognition' is related to teaching or learning strategies, but I wonder what does it actually mean in terms of cognitive science.</p>\n", "pids": ["5a9cb66717c44a376ffb8bab"], "flag": 1}
{"question": "Were generative adversarial networks introduced by J&#252;rgen Schmidhuber?", "body": "<p>I read on <a href=\"https://en.wikipedia.org/wiki/Generative_adversarial_networks\" rel=\"noreferrer\">https://en.wikipedia.org/wiki/Generative_adversarial_networks</a> :</p>\n\n<blockquote>\n  <p>[Generative adversarial networks] were introduced by Ian Goodfellow et al in 2014.</p>\n</blockquote>\n\n<p>but <a href=\"https://en.wikipedia.org/wiki/J%C3%BCrgen_Schmidhuber\" rel=\"noreferrer\">Jurgen Schmidhuber</a> claims to have performed similar work earlier in that direction (e.g., there was some debate at NIPS 2016 during the generative adversarial networks tutorial: <a href=\"https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Generative-Adversarial-Networks\" rel=\"noreferrer\">https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Generative-Adversarial-Networks</a> see 1h03min). </p>\n\n<p>Was the idea behind generative adversarial networks first publicly introduced by Jürgen Schmidhuber? If not, how similar were Jürgen Schmidhuber's ideas?</p>\n", "pids": ["5b3d98cc17c44a510f801d98", "5a73cb7417c44a0b3035a3d4", "5736960e6e3b12023e520fd0"], "flag": 1}
{"question": "Why clotting does not occur during Menstruation", "body": "<p>As we know when we get injured our body's clotting systems stop the bleeding. So why does it take days for menstruation to stop ? </p>\n", "pids": ["55a500fd65ceb7cb02de473c"], "flag": 1}
{"question": "Guideline to select the hyperparameters in Deep Learning", "body": "<p>I'm looking for a paper that could help in giving a guideline on how to choose the hyperparameters of a deep architecture, like stacked auto-encoders or deep believe networks. There are a lot of hyperparameters and I'm very confused on how to choose them. Also using cross-validation is not an option since training really takes a lot of time!</p>\n", "pids": ["53e9ada5b7602d97037a301f"], "flag": 1}
{"question": "Psychological explanation for exorcisms?", "body": "<p>I'm doing research on alleged testimonies and evidences of the spirit realm. In particular, I've been lately reviewing testimonies and live recordings of exorcisms, some of which I find particularly impressive. I say impressive because in my opinion the exorcisms look quite convincing, and I lack the expertise in psychology and neuroscience to provide a convincing explanation other than assuming that everything is staged (which I wouldn't be able to prove either).</p>\n<p>Common patterns are that the allegedly possessed person seems to switch personality (as though the alleged entity's personality is taking over), sometimes the exorcist and the alleged entity establish conversation, sometimes the person starts to &quot;throw up&quot; the alleged entity out of their body right before full deliverance is achieved.</p>\n<p>Here a few examples (timestamps included): <a href=\"https://youtu.be/I3paguHVtBE?t=1188\" rel=\"nofollow noreferrer\">example 1</a>, <a href=\"https://youtu.be/mAQevnUDU24\" rel=\"nofollow noreferrer\">example 2</a>, <a href=\"https://youtu.be/dtsxUcQO3v0\" rel=\"nofollow noreferrer\">example 3</a>, <a href=\"https://youtu.be/4rOYVuI6dXg\" rel=\"nofollow noreferrer\">example 4</a>, <a href=\"https://youtu.be/EteJtXUmqrE?t=202\" rel=\"nofollow noreferrer\">example 5</a>, <a href=\"https://youtu.be/Mkdaz6dVRO4?t=177\" rel=\"nofollow noreferrer\">example 6</a>, <a href=\"https://youtu.be/Ry0mU0flrJ4?t=215\" rel=\"nofollow noreferrer\">example 7</a>, <a href=\"https://youtu.be/zwKWT5ca0LE?t=1530\" rel=\"nofollow noreferrer\">example 8</a>, <a href=\"https://youtu.be/RXDX92mrGxU\" rel=\"nofollow noreferrer\">example 9</a>, <a href=\"https://v.youku.com/v_show/id_XMzA2Mjk0ODUzMg==.html\" rel=\"nofollow noreferrer\">example 10</a>, <a href=\"https://youtu.be/pIqPfZZOQsg?t=20\" rel=\"nofollow noreferrer\">example 11</a>, <a href=\"https://youtu.be/yKnxWl8500k?t=148\" rel=\"nofollow noreferrer\">example 12</a>.</p>\n<p>What is the psychological explanation for exorcisms?</p>\n<hr />\n<p>Possibly related questions:</p>\n<ul>\n<li><a href=\"https://psychology.stackexchange.com/q/3707/25376\">Is there a psychological explanation for people being &#39;overcome by the Holy Spirit&#39;?</a></li>\n<li><a href=\"https://psychology.stackexchange.com/q/25631/25376\">Is there a scientific explanation for dramatic body shaking and trembling in religious settings? (see videos for illustrative examples)</a></li>\n<li><a href=\"https://psychology.stackexchange.com/q/26179/25376\">Explanation for the &quot;spinal energy&quot; and other &quot;Kundalini awakening&quot; symptoms?</a></li>\n</ul>\n", "pids": ["5c75740ef56def97989051c3", "55a66df9612ca6eebaafd51a", "5c7573c3f56def97988d256f", "53e99ecab7602d9702794400", "55a51ea765ceb7cb02e17f7d"], "flag": 1}
{"question": "LDA vs word2vec", "body": "<p>I am trying to understand what is similarity between <a href=\"http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation\" rel=\"noreferrer\">Latent Dirichlet Allocation</a> and <a href=\"https://radimrehurek.com/gensim/models/word2vec.html\" rel=\"noreferrer\">word2vec</a> for calculating word similarity. </p>\n\n<p>As I understand, LDA maps words to a vector of probabilities of <em>latent</em> topics, while word2vec maps them to a vector of real numbers (related to singular value decomposition of pointwise mutual information, see <a href=\"http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization\" rel=\"noreferrer\">O. Levy,\nY. Goldberg, \"Neural Word Embedding as Implicit Matrix Factorization\"</a>; see also <a href=\"http://www.quora.com/How-does-word2vec-work\" rel=\"noreferrer\">How does word2vec work?</a>).</p>\n\n<p>I am interested both in theoretical relations (can one be considered a generalization, or variation of the other) and practical (when to use one but not the other).</p>\n\n<p>Related:</p>\n\n<ul>\n<li><a href=\"https://datascience.stackexchange.com/a/689/289\">What are some standard ways of computing the distance between documents? - DataScience.SE</a></li>\n</ul>\n", "pids": ["5736973f6e3b12023e62dcb1"], "flag": 1}
{"question": "Can we change a particular addiction into another addiction?", "body": "<p>My current knowledge about dopamine and serotonin came from a series of articles and web pages, a few videos also.</p>\n\n<p>As per my knowledge and readings I know that addiction is about reward, a person’s brain releases a chemical called <strong>dopamine</strong> when a person do addictive task and hence he feels momentarily good. But doing too much of it damages the receptors and hence the person cannot feel <em>happy</em> anymore by doing that addictive act but he keeps on doing it in hope of that reward.</p>\n\n<p>Now, if we treat that person so that his receptors gets healed a little and then we start giving him some medicine which releases <strong>dopamine</strong> in right amount and hence converting that person’s addition from that previous addictive task to the medicines ( well I believe this is what psychiatrist actually do, because a person who goes to a psychiatrist always ends up taking medicines whole of his life) . If it’s all about <em>feeling good</em> and the release of <strong>dopamine</strong> then it seems completely logical to treat it by medicines and some self control. Then, my question, finally, is <strong>Is it possible to cure addiction by converting it into another addiction?</strong>  </p>\n\n<p>I talked to some professionals and they said that it’s not wise to substitute a behavioural addiction with a substance addiction, but I cannot see any difference because both of these have same effect on the brain i.e. release of a <em>chemical</em>.  </p>\n\n<p>I know that there lies many many minute and significant details which I have failed to look over but I expect that the researchers, well educated and even self-learner’s will get the gist of what I have said.  </p>\n\n<p>Thank you.</p>\n", "pids": ["53e9b403b7602d9703ef6df8", "622a55c65aee126c0fecb544", "56d82a96dabfae2eeef9e139"], "flag": 1}
{"question": "relationship between mood and working memory", "body": "<p>What is the relationship between working memory and positive or negative mood as higher order affective states which can change vary slowly compared to moment-to-moment affective responses (both valence and arousal)? Are there any literature related to this?</p>\n", "pids": ["55a4694465ce31bc8779c360"], "flag": 1}
{"question": "How to efficiently generate random positive-semidefinite correlation matrices?", "body": "<p>I would like to be able to efficiently generate positive-semidefinite (PSD) correlation matrices. My method slows down dramatically as I increase the size of matrices to be generated.</p>\n\n<ol>\n<li>Could you suggest any efficient solutions? If you are aware of any examples in Matlab, I would be very thankful.</li>\n<li>When generating a PSD correlation matrix how would you pick the parameters to describe matrices to be generated? An average correlation, standard deviation of correlations, eigenvalues?</li>\n</ol>\n", "pids": ["53e9a51db7602d9702e41cde", "5daed3493a55ac025c26e5e2"], "flag": 1}
{"question": "Looking for references discussing aspect of human/animal adaptivity and its pertaining computational objectives", "body": "<p>Does anyone know some references (e.g. papers or book chapters) that discuss aspects of the adaptivity of human/animal based on studying the behavior and ideally, what computational objectives pertaining to the adaptivity of human/animal have been or can be suggested based on them?</p>\n<p>An example: Animals should adapt to their environment to survive, they should develop whatever [computation] needed to detect the hunter and escape timely. They should update their internal model (whatever we define the internal model), with changes in their environment.</p>\n", "pids": ["5ff68425d4150a363cbced59"], "flag": 1}
{"question": "Why don&#39;t allergies cause fever?", "body": "<p><strong>Allergy</strong></p>\n\n<p>To my understanding, an allergy is a hypersensitivity of the immune system causing a substance in the environment to be identified as pathogenic by the immune system while it is not pathogenic. During an allergic reaction, the immune system triggers histamine, which triggers an inflammatory response just as if the allergen was a pathogen. The resulting symptoms of an allergic response is similar to the symptoms of a cold but without fever.</p>\n\n<p><strong>Fever</strong></p>\n\n<p>To my understanding a fever is an increase in body temperature driven by the body through production of pyrogens, most often in response to a pathogen. This response might be adaptive for various reasons that I am not too interested in discussing here.</p>\n\n<p><strong>Question</strong></p>\n\n<p>According to <a href=\"https://newsinhealth.nih.gov/2014/10/cold-flu-or-allergy\" rel=\"nofollow noreferrer\">NIH</a>, an allergic response never causes a fever. Given that the fever is not directly caused by the pathogen but rather is caused by the body, why do allergies not cause fever?</p>\n\n<p>The fact that allergies don't cause fever give me the weird impression that the immune system somewhat \"understand\" the allergen is not pathogenic otherwise the immune response would be the same in the case of an allergen or a pathogen.</p>\n\n<p><strong>Un-educated guess</strong></p>\n\n<p>Allergic responses implies the firing of <a href=\"https://en.wikipedia.org/wiki/Immunoglobulin_E\" rel=\"nofollow noreferrer\">IgE</a>. IgE are typically involved in response to parasites such as helminths. Could it be that pathogens leading to an immune responses mediated via IgE never yield to fever. Why would it be the case?</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/Plasmodium_falciparum\" rel=\"nofollow noreferrer\"><em>Plasmodium falciparum</em></a> (which causes malaria) is a pathogen who causes an immune response involving IgE (according to the <a href=\"https://en.wikipedia.org/wiki/Immunoglobulin_E\" rel=\"nofollow noreferrer\">wikipedia</a>). Malaria's symptoms include high fever (according to <a href=\"https://www.mayoclinic.org/diseases-conditions/malaria/symptoms-causes/syc-20351184\" rel=\"nofollow noreferrer\">Mayo Clinic</a>). Now it would be possible that the pyrogen would be of external origin (not produced by the body but by the pathogen) or it is possible that several immunoglobulin are involved in response to <em>P. falciparum</em>. The same logic hold for <em><a href=\"https://en.wikipedia.org/wiki/Fasciola_hepatica\" rel=\"nofollow noreferrer\">Fasciola hepatica</a></em> (an helminth; common liver fluke) who also causes fever and is who's infection lead to the firing of IgE.</p>\n", "pids": ["53e9b4e0b7602d9704006826", "53e99db1b7602d97026705ad"], "flag": 1}
{"question": "Will modern-day insects grow to massive size in a high-oxygen environment?", "body": "<p>It's a reasonably well-known fact that insects grew to massive sizes due to the excessive concentration of oxygen in the prehistoric-Earth's atmosphere.</p>\n\n<p><strong>If one were to try to recreate this high-oxygen environment in a lab setting, would insects reared within grow to massive size?</strong></p>\n", "pids": ["56d8260adabfae2eeedd6543"], "flag": 1}
{"question": "What happens to plants if they are exposed to &quot;sunlight&quot; 24h a day?", "body": "<p>I just wondered if one could grow plants faster, if they were exposed to sunlight-like light all the time.</p>\n<p>In a <a href=\"https://biology.stackexchange.com/q/61329/8014\">similar question which is not the same</a>, I could confirm that plants have different processes going on at day and at night. However, it didn't answer the question about the consequences of permanent exposure to sunlight.</p>\n<p>However, I don't understand what would happen if there was light all the time. What would happen to different plants if they are exposed to &quot;sunlight&quot; 24/7?</p>\n<p>(Similarly: What is the &quot;optimal&quot; amount of sunlight time for different plants? Is it basically what is common in the environments they typically grow in?)</p>\n", "pids": ["5ecbc8349fced0a24b5141f6"], "flag": 1}
{"question": "How to model non-negative zero-inflated continuous data?", "body": "<p>I'm currently trying to apply a linear model (<code>family = gaussian</code>) to an indicator of biodiversity that cannot take values lower than zero, is zero-inflated and is continuous. Values range from 0 to a little over 0.25. As a consequence, there is quite an obvious pattern in the residuals of the model that I haven't managed to get rid of:\n<a href=\"https://i.stack.imgur.com/WPgNw.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/WPgNw.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>Does anyone have any ideas on how to solve this?</p>\n", "pids": ["5488e61c45ce147a86e5a486", "53e9ac48b7602d9703615ef2", "5e5e191193d709897ce4cbef", "5c7561d4f56def9798d90ee0"], "flag": 1}
{"question": "Personality at Birth", "body": "<p>What factors determine the personality of a newborn baby?</p>\n<p>Do all newborns exhibit identical behaviour?  If not, are genetics responsible for the differences?</p>\n<p>References consulted so far:</p>\n<ol>\n<li><p><a href=\"https://opentextbc.ca/introductiontopsychology/chapter/11-3-is-personality-more-nature-or-more-nurture-behavioral-and-molecular-genetics/#:%7E:text=on%20human%20behaviour.-,Behavioural%20genetics%20is%20based%20on%20the%20results%20of%20family%20studies,associated%20with%20which%20personality%20traits.\" rel=\"nofollow noreferrer\">Is Personality More Nature or More Nurture? Behavioural and Molecular Genetics</a></p>\n</li>\n<li><p><a href=\"https://www.verywellmind.com/are-personality-traits-caused-by-genes-or-environment-4120707\" rel=\"nofollow noreferrer\">Are Personality Traits Caused by Genes or Environment?</a></p>\n</li>\n<li><p><a href=\"https://www.psychologytoday.com/us/blog/under-the-influence/201307/do-genes-influence-personality\" rel=\"nofollow noreferrer\">Do Genes Influence Personality?</a></p>\n</li>\n</ol>\n", "pids": ["53e9b983b7602d9704571d45", "5c35f2ecdf5b8c0b3c3ad84a", "599e3a7a0cf28d9fa5721a62", "59a7758b0cf25762a5211b98", "53e9a439b7602d9702d58877", "5d1f23d43a55ac89851c1167", "55a6cb2665ce054aad75fee2", "5c8b11f84895d9cbc64a38f6"], "flag": 1}
{"question": "Who invented stochastic gradient descent?", "body": "<p>I'm trying to understand the history of <a href=\"https://en.wikipedia.org/wiki/Gradient_descent\" rel=\"noreferrer\">Gradient descent</a> and <a href=\"https://en.wikipedia.org/wiki/Stochastic_gradient_descent\" rel=\"noreferrer\">Stochastic gradient descent</a>. Gradient descent was invented in <a href=\"https://en.wikipedia.org/wiki/Augustin-Louis_Cauchy\" rel=\"noreferrer\">Cauchy</a> in 1847.<a href=\"http://gallica.bnf.fr/ark:/12148/bpt6k2982c.image.f540.pagination.langEN\" rel=\"noreferrer\">Méthode générale pour la résolution des systèmes d'équations simultanées</a>. pp. 536–538 For more information about it see <a href=\"https://www.math.uni-bielefeld.de/documenta/vol-ismp/40_lemarechal-claude.pdf\" rel=\"noreferrer\">here</a>.</p>\n\n<p>Since then gradient descent methods kept developing and I'm not familiar with their history. In particular I'm interested in the invention of stochastic gradient descent. </p>\n\n<p>A reference that can be used in an academic paper in more than welcomed.</p>\n", "pids": ["57a4e91aac44365e35c979f6"], "flag": 1}
{"question": "Is there a relationship between viewing and committing war crimes", "body": "<p>Recently, I’ve been curious if there’s any relationship between someone committing war crimes and previously viewing them.</p>\n<p>For example, the War in Afghanistan is considered asymmetrical warfare, where the enemy has no rule book in regards to international law, and the soldier has the international law as well as their own set of rules of engagements (RoE) to follow. As time goes on, many of their comrades are wounded or killed from seemingly preventable things if they didn’t have to follow a set of rules of engagement while the enemy were ignoring them (using children in wars, indiscriminate weapons, hiding in civilian crowds).</p>\n<p>Considering this then, is there a link between longer exposure to ‘dirty’ war fighting (not following international law) and the ability to carry out said rules of engagements without emotional compromise.</p>\n<p>It seems logical that as you witness warcrimes committed against yourself or the people around you, that the chances of you breaking your own RoE to have a (relatively) fair playing field against the enemy starts to increase. Particularly for soldiers in sustained combat.</p>\n<p>I don’t really have any research on this from what I’ve tried to find. I’m a mechanical engineer by trade so probably way out of my depth, so if there are good places to look for this kind of material, I’d be happy to have it sent to me. Any thoughts on this would be appreciated too!</p>\n", "pids": ["5c756ea1f56def97985eda53"], "flag": 1}
{"question": "The differences between sensory distortions and hallucinations", "body": "<p>So, the way I've understood it, &quot;sensory disturbances&quot; can be categorized as follows:</p>\n<p><a href=\"https://i.stack.imgur.com/UcUXJ.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/UcUXJ.png\" alt=\"enter image description here\" /></a></p>\n<p>Any sensory experience that isn't real goes under &quot;sensory disturbances&quot; in this diagram. If this unreal sensory experience is a distortion or misunderstanding of real, external stimuli, then it falls under &quot;<a href=\"https://en.wikipedia.org/wiki/Illusion\" rel=\"nofollow noreferrer\">illusions</a>&quot;. If the unreal sensory experience is generated in the absence of external stimuli, it is a <a href=\"https://en.wikipedia.org/wiki/Hallucination\" rel=\"nofollow noreferrer\">hallucination</a>. If the person having the hallucination believes in it, it is a true hallucination. If not, then it is just a hallucination.</p>\n<p>So, if a person perceives an object to be a different color, whether it is due to an altered state of consciousness, or if it is due confusing circumstances, is this an illusion or a hallucination? The object is real, it does have a color (which in a sense isn't real and potentially experienced differently by different people), and the person sees the color differently than what they normally would. Is this external stimuli being distorted/misinterpreted, or is it a hallucination being superimposed upon or merged with an external piece of stimuli. What if the subject doesn't see a different color, but rather a different shade of the same color?</p>\n<p>If a taste is changed from e.g. sweet to salty is it an illusion or a hallucination? If an object is perceived to move when it is not moving, is it an illusion or a hallucination.</p>\n<p>At the heart of these questions really is the question: does in the absence of external stimuli necessitate that the hallucination not involve external stimuli, or not depend on it? If the object is falsely perceived to be moving, it involves it (and in a sense depends on it too), however, it isn't the nature of the object that causes the sensory disturbance, but rather an internally created disturbance (the perception of motion) instilled into the object. But since that percept of motion, although originating from within, modified an external stimuli in order to give the final experience, is that experience then an illusion due to it coming in the form of distorted, external stimuli?</p>\n<p>Basically, I'm wondering about the nuanced border between illusions and hallucinations, if there even is one. If there isn't one, and there's a large grey area between them, then how does one differentiate between the two different categories proposed for the class of drugs that are hallucinogens? The broadest definition includes all drugs that sensory disturbances, and the most narrow definition is limited to those that produce hallucinations. How can that discussion be had in the event that there is a large gray area between illusions and hallucinations?</p>\n", "pids": ["5ecce9ae9fced0a24bdbc33f"], "flag": 1}
{"question": "Symptoms of increase leptin receptor", "body": "<p>A genetic mutation that increases leptin receptor number. Does that lead to increase appetite or weight gain?</p>\n<p>I found online that a decrease in the leptin receptor number <a href=\"https://medlineplus.gov/genetics/condition/congenital-leptin-deficiency/\" rel=\"nofollow noreferrer\">could produce a feeling of fullness</a>. So it's reasonable to assume that the increase would lead to an increase in appetite and weight gain. But I am not sure of it.</p>\n<blockquote>\n<p>Congenital leptin deficiency is a condition that causes severe obesity beginning in the first few months of life. Affected individuals are of normal weight at birth, but they are constantly hungry and quickly gain weight. Without treatment, the extreme hunger continues and leads to chronic excessive eating (hyperphagia) and obesity.</p>\n</blockquote>\n", "pids": ["5c756c8ff56def979849cfe7", "5e09a92bdf1a9c0c4169ded8"], "flag": 1}
{"question": "Is LSTM (Long Short-Term Memory) dead?", "body": "<p>From my own experience, LSTM has a long training time, and does not improve performance significantly in many real world tasks.</p>\n<p>To make the question more specific, I want to ask when LSTM will work better than other deep NN (may be with real world examples)? I know LSTM captures the sequential relationship in data, but is it really necessary?</p>\n<p>Most demos on related topic are meaningless. They just focus on toy data e.g., IMDB review, where simple logistic regression will get very good results. I do not see any value of using LSTM which has huge computational cost but marginal improvements (if there are any).</p>\n<p>Even with these toy examples, I did not find any good use cases that LSTM can solve very well but other models cannot.</p>\n", "pids": ["5dde4b463a55ac4c42972bc8", "5b67b4b417c44aac1c866e61", "5ed623da91e01198019afb3c", "5e451e433a55acfaed738742", "5b67b4b417c44aac1c866e61", "5da6eb313a55ac45909c0401", "5aed14e217c44a4438159860", "573695fe6e3b12023e5127c7", "5c8e602b4895d9cbc6e354f0", "5ede0553e06a4c1b26a83ff5"], "flag": 1}
{"question": "Psychometric scales of gender", "body": "<p>I have never read any study that has used a psychometric scale to find out the respondent's gender identity, sexual orientation or both. This makes me wonder if there are such scales or not, or if there can be such scales or not.</p>\n<p>I am more interested in scales for gender identity, for a study I am currently doing.</p>\n<p>I am not looking for qualitative studies. I would like to know if there are quantitative studies using Psychometrics that have tried to develop scales for gender identity, like we have ones for IQ, Big 5 personality, Political Conservatism etc. using factor analysis for example, or some other appropriate psychometric method? Is there any consensus on which approach/ scale is better, or is there any widely used scale? By approach I mean agreement on the main ideas behind a scale, for example there are many scales/ tests for Big 5 using different questions, but it is widely accepted that there are 5 dimensions. Anything like that for gender identity.</p>\n", "pids": ["58d108460cf22173abb92e50", "55a3855c2401aa93797b6e39"], "flag": 1}
{"question": "What is an instrumental variable?", "body": "<p>Instrumental variables are becoming increasingly common in applied economics and statistics. For the uninitiated, can we have some non-technical answers to the following questions:</p>\n\n<ol>\n<li>What is an instrumental variable?</li>\n<li>When would one want to employ an instrumental variable?</li>\n<li>How does one find or choose an instrumental variable?</li>\n</ol>\n", "pids": ["53e9b6d6b7602d9704266221"], "flag": 1}
{"question": "How to deal with hierarchical / nested data in machine learning", "body": "<p>I'll explain my problem with an example.  Suppose you want to predict the income of an individual given some attributes: {Age, Gender, Country, Region, City}. You have a training dataset like so</p>\n\n<pre><code>train &lt;- data.frame(CountryID=c(1,1,1,1, 2,2,2,2, 3,3,3,3), \n             RegionID=c(1,1,1,2, 3,3,4,4, 5,5,5,5), \n             CityID=c(1,1,2,3, 4,5,6,6, 7,7,7,8), \n             Age=c(23,48,62,63, 25,41,45,19, 37,41,31,50), \n             Gender=factor(c(\"M\",\"F\",\"M\",\"F\", \"M\",\"F\",\"M\",\"F\", \"F\",\"F\",\"F\",\"M\")),\n             Income=c(31,42,71,65, 50,51,101,38, 47,50,55,23))\ntrain\n   CountryID RegionID CityID Age Gender Income\n1          1        1      1  23      M     31\n2          1        1      1  48      F     42\n3          1        1      2  62      M     71\n4          1        2      3  63      F     65\n5          2        3      4  25      M     50\n6          2        3      5  41      F     51\n7          2        4      6  45      M    101\n8          2        4      6  19      F     38\n9          3        5      7  37      F     47\n10         3        5      7  41      F     50\n11         3        5      7  31      F     55\n12         3        5      8  50      M     23\n</code></pre>\n\n<p>Now suppose I want to predict the income of a new person who lives in City 7.  My training set has a whopping 3 samples with people in City 7 (assume this is a lot) so I can probably use the average income in City 7 to predict the income of this new individual.</p>\n\n<p>Now suppose I want to predict the income of a new person who lives in City 2. My training set only has 1 sample with City 2 so the average income in City 2 probably isn't a reliable predictor.  But I can probably use the average income in Region 1.</p>\n\n<p>Extrapolating this idea a bit, I can transform my training dataset as</p>\n\n<pre><code>    Age Gender CountrySamples CountryIncome RegionSamples RegionIncome CitySamples CityIncome\n 1:  23      M              4         52.25             3        48.00           2    36.5000\n 2:  48      F              4         52.25             3        48.00           2    36.5000\n 3:  62      M              4         52.25             3        48.00           1    71.0000\n 4:  63      F              4         52.25             1        65.00           1    65.0000\n 5:  25      M              4         60.00             2        50.50           1    50.0000\n 6:  41      F              4         60.00             2        50.50           1    51.0000\n 7:  45      M              4         60.00             2        69.50           2    69.5000\n 8:  19      F              4         60.00             2        69.50           2    69.5000\n 9:  37      F              4         43.75             4        43.75           3    50.6667\n10:  41      F              4         43.75             4        43.75           3    50.6667\n11:  31      F              4         43.75             4        43.75           3    50.6667\n12:  50      M              4         43.75             4        43.75           1    23.0000\n</code></pre>\n\n<p>So, the goal is to somehow combine the average CityIncome, RegionIncome, and CountryIncome while using the number of training samples for each to give a weight/credibility to each value. (Ideally, still including information from Age and Gender.)</p>\n\n<p>What are tips for solving this type of problem? I prefer to use tree based models like random forest or gradient boosting, but I'm having trouble getting these to perform well.</p>\n\n<h1>UPDATE</h1>\n\n<p>For anyone willing to take a stab at this problem, I've generated sample data to test your proposed solution <a href=\"https://github.com/ben519/MLPB/tree/master/Projects/AverageIncome/Data\">here</a>.</p>\n", "pids": ["5c756c85f56def9798496c02", "5e8da0c991e011f2de58385c", "619bad811c45e57ce9e83739", "56d85f97dabfae2eee71a8fe"], "flag": 1}
{"question": "Feature map for the Gaussian kernel", "body": "<p>In SVM, the Gaussian kernel is defined as:\n$$K(x,y)=\\exp\\left({-\\frac{\\|x-y\\|_2^2}{2\\sigma^2}}\\right)=\\phi(x)^T\\phi(y)$$ where $x, y\\in \\mathbb{R^n}$.\nI do not know the explicit equation of $\\phi$. I want to know it.</p>\n\n<p>I also want to know whether\n$$\\sum_ic_i\\phi(x_i)=\\phi \\left(\\sum_ic_ix_i \\right)$$ where $c_i\\in \\mathbb R$. Now, I think it is not equal, because using a kernel handles the situation where the linear classier does not work. I know $\\phi$ projects x to a infinite space. So if it still remains linear, no matter how many dimensions it is, svm still can not make a good classification.</p>\n", "pids": ["558abe1584ae84d265bf5f97", "53e9bae6b7602d9704713c20"], "flag": 1}
{"question": "Can stress situations force people to smile?", "body": "<p>I've seen many times in my life how people occasionally smile when trying to remain calm under huge stress regarding natural disasters, deaths, big losses, etc. It happened to me also.<br />\nEverything I find about it is just tips on how to <code>make yourself happy by forcing a smile</code>, but I doubt people was smiling intentionally - it was coming out naturally.<br />\nWas there any research on it? Is it a thing?</p>\n", "pids": ["53e9bc01b7602d9704862155", "53e99dbfb7602d9702681a38", "56d8ddd4dabfae2eeefe8da1"], "flag": 1}
{"question": "How to determine significant principal components using bootstrapping or Monte Carlo approach?", "body": "<p>I am interested in determining the number of significant patterns coming out of a Principal Component Analysis (PCA) or Empirical Orthogonal Function (EOF) Analysis. I am particularly interested in applying this method to climate data. The data field is a MxN matrix with M being the time dimension (e.g. days) and N being the spatial dimension (e.g. lon/lat locations). I have read of a possible bootstrap method to determine significant PCs, but have been unable to find a more detailed description. Until now, I have been applying North's Rule of Thumb (North <em>et al</em>., 1982) to determine this cutoff, but I was wondering if a more robust method was available.</p>\n\n<p>As an example: </p>\n\n<pre><code>###Generate data\nx &lt;- -10:10\ny &lt;- -10:10\ngrd &lt;- expand.grid(x=x, y=y)\n\n#3 spatial patterns\nsp1 &lt;- grd$x^3+grd$y^2\ntmp1 &lt;- matrix(sp1, length(x), length(y))\nimage(x,y,tmp1)\n\nsp2 &lt;- grd$x^2+grd$y^2\ntmp2 &lt;- matrix(sp2, length(x), length(y))\nimage(x,y,tmp2)\n\nsp3 &lt;- 10*grd$y\ntmp3 &lt;- matrix(sp3, length(x), length(y))\nimage(x,y,tmp3)\n\n\n#3 respective temporal patterns\nT &lt;- 1:1000\n\ntp1 &lt;- scale(sin(seq(0,5*pi,,length(T))))\nplot(tp1, t=\"l\")\n\ntp2 &lt;- scale(sin(seq(0,3*pi,,length(T))) + cos(seq(1,6*pi,,length(T))))\nplot(tp2, t=\"l\")\n\ntp3 &lt;- scale(sin(seq(0,pi,,length(T))) - 0.2*cos(seq(1,10*pi,,length(T))))\nplot(tp3, t=\"l\")\n\n\n#make data field - time series for each spatial grid (spatial pattern multiplied by temporal pattern plus error)\nset.seed(1)\nF &lt;- as.matrix(tp1) %*% t(as.matrix(sp1)) + \nas.matrix(tp2) %*% t(as.matrix(sp2)) + \nas.matrix(tp3) %*% t(as.matrix(sp3)) +\nmatrix(rnorm(length(T)*dim(grd)[1], mean=0, sd=200), nrow=length(T), ncol=dim(grd)[1]) # error term\n\ndim(F)\nimage(F)\n\n\n###Empirical Orthogonal Function (EOF) Analysis \n#scale field\nFsc &lt;- scale(F, center=TRUE, scale=FALSE)\n\n#make covariance matrix\nC &lt;- cov(Fsc)\nimage(C)\n\n#Eigen decomposition\nE &lt;- eigen(C)\n\n#EOFs (U) and associated Lambda (L) \nU &lt;- E$vectors\nL &lt;- E$values\n\n#projection of data onto EOFs (U) to derive principle components (A)\nA &lt;- Fsc %*% U\n\ndim(U)\ndim(A)\n\n#plot of top 10 Lambda\nplot(L[1:10], log=\"y\")\n\n#plot of explained variance (explvar, %) by each EOF\nexplvar &lt;- L/sum(L) * 100\nplot(explvar[1:20], log=\"y\")\n\n\n#plot original patterns versus those identified by EOF\nlayout(matrix(1:12, nrow=4, ncol=3, byrow=TRUE), widths=c(1,1,1), heights=c(1,0.5,1,0.5))\nlayout.show(12)\n\npar(mar=c(4,4,3,1))\nimage(tmp1, main=\"pattern 1\")\nimage(tmp2, main=\"pattern 2\")\nimage(tmp3, main=\"pattern 3\")\n\npar(mar=c(4,4,0,1)) \nplot(T, tp1, t=\"l\", xlab=\"\", ylab=\"\")\nplot(T, tp2, t=\"l\", xlab=\"\", ylab=\"\")\nplot(T, tp3, t=\"l\", xlab=\"\", ylab=\"\")\n\npar(mar=c(4,4,3,1))\nimage(matrix(U[,1], length(x), length(y)), main=\"eof 1\") \nimage(matrix(U[,2], length(x), length(y)), main=\"eof 2\")\nimage(matrix(U[,3], length(x), length(y)), main=\"eof 3\")\n\npar(mar=c(4,4,0,1)) \nplot(T, A[,1], t=\"l\", xlab=\"\", ylab=\"\")\nplot(T, A[,2], t=\"l\", xlab=\"\", ylab=\"\")\nplot(T, A[,3], t=\"l\", xlab=\"\", ylab=\"\")\n</code></pre>\n\n<p><a src=\"https://i.stack.imgur.com/NhWKf.png\" alt=\"enter image description here\"></p>\n\n<p>And, here is the method that I have been using to determine PC significance. Basically, the rule of thumb is that the difference between neighboring Lambdas must be greater than their associated error.</p>\n\n<pre><code>###Determine significant EOFs\n\n#North's Rule of Thumb\nLambda_err &lt;- sqrt(2/dim(F)[2])*L\nupper.lim &lt;- L+Lambda_err\nlower.lim &lt;- L-Lambda_err\nNORTHok=0*L\nfor(i in seq(L)){\n    Lambdas &lt;- L\n    Lambdas[i] &lt;- NaN\n    nearest &lt;- which.min(abs(L[i]-Lambdas))\n    if(nearest &gt; i){\n        if(lower.lim[i] &gt; upper.lim[nearest]) NORTHok[i] &lt;- 1\n    }\n    if(nearest &lt; i){\n        if(upper.lim[i] &lt; lower.lim[nearest]) NORTHok[i] &lt;- 1\n    }\n}\nn_sig &lt;- min(which(NORTHok==0))-1\n\nplot(L[1:10],log=\"y\", ylab=\"Lambda (dots) and error (vertical lines)\", xlab=\"EOF\")\nsegments(x0=seq(L), y0=L-Lambda_err, x1=seq(L), y1=L+Lambda_err)\nabline(v=n_sig+0.5, col=2, lty=2)\ntext(x=n_sig, y=mean(L[1:10]), labels=\"North's Rule of Thumb\", srt=90, col=2)\n</code></pre>\n\n<p><a src=\"https://i.stack.imgur.com/gE90Y.png\" alt=\"enter image description here\"></p>\n\n<p>I have found the chapter section by Björnsson and Venegas (<a href=\"http://andvari.vedur.is/~folk/halldor/PICKUP/eof.pdf\" rel=\"noreferrer\">1997</a>) on significance tests to be helpful - they refer to three categories of tests, of which the <em>dominant variance</em>-type is probably what I am hoping to use. The refer to a type of Monte Carlo approach of shuffling the time dimension and recomputing the Lambdas over many permutations. von Storch and Zweiers (1999) also refer to the a test that compares the Lambda spectrum to a reference \"noise\" spectrum. In both cases, I am a bit unsure of how this might be done, and also how the significance test is done given the confidence intervals identified by the permutations. </p>\n\n<p>Thanks for your help.</p>\n\n<p>References:\nBjörnsson, H. and Venegas, S.A. (1997). \"A manual for EOF and SVD analyses of climate data\", McGill University, CCGCR Report No. 97-1, Montréal, Québec, 52pp. <a href=\"http://andvari.vedur.is/%7Efolk/halldor/PICKUP/eof.pdf\" rel=\"noreferrer\">http://andvari.vedur.is/%7Efolk/halldor/PICKUP/eof.pdf</a> </p>\n\n<p>G.R. North, T.L. Bell, R.F. Cahalan, and F.J. Moeng. (1982). Sampling errors in the estimation of empirical orthogonal functions. Mon. Wea. Rev., 110:699–706.  </p>\n\n<p>von Storch, H, Zwiers, F.W. (1999). Statistical analysis in climate research. Cambridge University Press.</p>\n", "pids": ["53e99cedb7602d97025a3fc4"], "flag": 1}
{"question": "How to present results of a Lasso using glmnet?", "body": "<p>I would like to find predictors for a continuous dependent variable out of a set of 30 independent variables. I am using Lasso regression as implemented in the <a href=\"http://cran.r-project.org/web/packages/glmnet/index.html\">glmnet</a> package in R. Here is some dummy code:</p>\n\n<pre><code># generate a dummy dataset with 30 predictors (10 useful &amp; 20 useless) \ny=rnorm(100)\nx1=matrix(rnorm(100*20),100,20)\nx2=matrix(y+rnorm(100*10),100,10)\nx=cbind(x1,x2)\n\n# use crossvalidation to find the best lambda\nlibrary(glmnet)\ncv &lt;- cv.glmnet(x,y,alpha=1,nfolds=10)\nl &lt;- cv$lambda.min\nalpha=1\n\n# fit the model\nfits &lt;- glmnet( x, y, family=\"gaussian\", alpha=alpha, nlambda=100)\nres &lt;- predict(fits, s=l, type=\"coefficients\")\nres \n</code></pre>\n\n<p>My questions is how to interpret the output:</p>\n\n<ul>\n<li><p>Is it correct to say that in the final output all predictors that show a coefficient different from zero are related to the dependent variable? </p></li>\n<li><p>Would that be a sufficient report in the context of a journal publication? Or is it expected to provide test-statistics for the significance of the coefficients? (The context is human genetics)</p></li>\n<li><p>Is it reasonable to calculate p-values or other test-statistic to claim significance? How would that be possible? Is a procedure implemented in R? </p></li>\n<li><p>Would a simple regression plot (data points plotted with a linear fit) for every predictor be a suitable way to visualize this data?</p></li>\n<li><p>Maybe someone can provide some easy examples of published articles showing the use of Lasso in the context of some real data &amp; how to report this in a journal?</p></li>\n</ul>\n", "pids": ["55a6af1065ce054aad70f5ce"], "flag": 1}
{"question": "Are neural networks better than SVMs?", "body": "<p>For some time now I have been studying both support vector machines and neural networks and I understand the logic behind each of these techniques. Very briefly described:</p>\n<ul>\n<li><p>In a support vector machine, using the kernel-trick, you &quot;send&quot; the data into a higher dimensional space where it can be linearly separable.</p>\n</li>\n<li><p>In a neural network you perform a series of linear combinations mixed with (usually) non linear activation functions across several layers.</p>\n</li>\n</ul>\n<p>So far I have seen that neural networks tend to provide the best predictive results among machine learning alternatives. Of course, compared with other more classical tools like multivariate regression, they have some drawbacks, like providing little (if any) interpretability of the variables, while in regression the interpretability of the variables is immediate.</p>\n<p>My question is: Neural networks seem to provide better predictive results than support vector machines, and both provide the same amount of interpretability (which is <em>none</em>). Is there any situation in which using a support vector machine would be better than using a neural network?</p>\n", "pids": ["5fc7685e91e0114897921118"], "flag": 1}
{"question": "Whether &quot;group polarization&quot; and &quot;social segregation&quot; is the same?", "body": "<p>In a paper of (<a href=\"https://www.nature.com/articles/s41598-019-40990-z\" rel=\"nofollow noreferrer\">Murase, 2019</a>) use both terms &quot;group polarization&quot; and &quot;social segregation&quot;.</p>\n<p>The &quot;group polarization&quot; is explained <a href=\"https://psychology.stackexchange.com/questions/27815/what-is-the-name-of-phenomenon-that-people-state-their-initial-opinion-more-firm\">here</a>, and the author also documents about the &quot;social segregation&quot; as</p>\n<blockquote>\n<p>The relationship between homophily and segregation has been recognized\nlong ago.(...)In another approach to social segregation, opinion\ndynamics is used so that similar people can influence each other</p>\n</blockquote>\n<p>I am wondering whether these two terms &quot;<strong>group polarization</strong>&quot; and &quot;<strong>social segregation</strong>&quot; are the same?</p>\n", "pids": ["5c9210d3e1cd8edc3db5f8ed"], "flag": 1}
{"question": "Neural network references (textbooks, online courses) for beginners", "body": "<p>I want to learn Neural Networks.  I am a Computational Linguist. I know statistical machine learning approaches and can code in Python. </p>\n\n<p>I am looking to start with its concepts, and know one or two popular models which may be useful from a Computational Linguistics perspective.</p>\n\n<p>I browsed the web for reference and found a few books and materials.</p>\n\n<ul>\n<li><p>Ripley, Brian D. (1996) Pattern Recognition and Neural Networks, Cambridge</p></li>\n<li><p>Bishop, C.M. (1995) Neural Networks for Pattern Recognition, Oxford: Oxford University Press.</p></li>\n<li><p>some links, like <a href=\"http://cslab1.bc.edu/~csacademics/pdf/14Aslam.pdf\">this thesis</a>, <a href=\"http://www.psych.utoronto.ca/users/reingold/courses/ai/cache/neural2.html\">these course notes</a> (University of Toronto Psychology Department), <a href=\"http://pages.cs.wisc.edu/~bolo/shipyard/neural/local.html\">these course notes</a> (University of Wisconsin Computer Science) and <a href=\"http://www.coling-2014.org/COLING%202014%20Tutorial-fix%20-%20Tomas%20Mikolov.pdf\">this slideshow</a> (Facebook Research).</p></li>\n</ul>\n\n<p>Coursera courses are generally nice, if anyone knows anything relevant from them. I prefer materials with lucid language and ample examples. </p>\n", "pids": ["5d9edb9747c8f7664601fd1e", "573696106e3b12023e52281c", "5d9edb9747c8f7664601fd1e"], "flag": 1}
{"question": "How to assess the similarity of two histograms?", "body": "<p>Given two histograms, how do we assess whether they are similar or not?</p>\n\n<p>Is it sufficient to simply look at the two histograms?\nThe simple one to one mapping has the problem that if a histogram is slightly different and slightly shifted then we'll not get the desired result.</p>\n\n<p>Any suggestions?</p>\n", "pids": ["53e9af99b7602d97039e5c42"], "flag": 1}
{"question": "Meaning (and proof) of &quot;RNN can approximate any algorithm&quot;", "body": "<p>Recently I read that a recurrent neural network can approximate any algorithm.</p>\n\n<p>So my question is: what does this exactly mean and can you give me a reference where this is proved?</p>\n", "pids": ["56d8abc0dabfae2eeeb8c13f"], "flag": 1}
{"question": "Why use colormap viridis over jet?", "body": "<p>As announced in <a href=\"https://www.youtube.com/watch?v=xAoljeRJ3lU\">https://www.youtube.com/watch?v=xAoljeRJ3lU</a>, Matplotlib changes the default colormap from jet to viridis. </p>\n\n<p>However, I don't understand it pretty well. Maybe because I'm color blind?</p>\n\n<p>The original colormap jet looks very strong, I can feel the contrast:</p>\n\n<p><a href=\"https://i.stack.imgur.com/Dx7MU.png\"><a src=\"https://i.stack.imgur.com/Dx7MU.png\" alt=\"enter image description here\"></a></p>\n\n<p>While the new colormap viridis lacks that contrast:</p>\n\n<p><a href=\"https://i.stack.imgur.com/j5qRx.png\"><a src=\"https://i.stack.imgur.com/j5qRx.png\" alt=\"enter image description here\"></a></p>\n\n<p>Can anyone please explain it simpler for me? I need the plot for my paper. And I need a good reason to convince my supervisor (and myself) that the viridis is a better one.</p>\n", "pids": ["5736960f6e3b12023e521bcc"], "flag": 1}
{"question": "Is Dissociative Personality Disorder Alter Takeover Possible?", "body": "<p>Is it possible for an individual with <a href=\"https://www.psychiatry.org/patients-families/dissociative-disorders/what-are-dissociative-disorders\" rel=\"nofollow noreferrer\">dissociative personality disorder</a>, with two distinct personalities, for the second personality (the 'alter') to take over and become the primary personality? More specifically, can the individual's second personality delete or suppress the individual's primary personality, therefore becoming the individual's sole personality?</p>\n", "pids": ["55a4cd1065ceb7cb02d8aa35", "55a66b6465ce054aad6712c5", "55a4d43d65ceb7cb02d9401b", "53e9b344b7602d9703e1975c", "53e9a108b7602d97029f8307", "5c756aabf56def97983627d5", "6028f689af79179a99cc9009", "5c0f8e09da562944aca2cf65"], "flag": 1}
{"question": "Why are Decision Trees not computationally expensive?", "body": "<p>In <a href=\"http://www.springer.com/us/book/9781461471370\" rel=\"noreferrer\"><em>An Introduction to Statistical Learning with Applications in R</em></a>, the authors write that fitting a <a href=\"https://en.wikipedia.org/wiki/Decision_tree\" rel=\"noreferrer\">decision tree</a> is very fast, but this doesn't make sense to me. The algorithm has to go through every feature and partition it in every way possible in order to find the optimal split. For numeric features with $n$ observations, this could result in $n$ partitions for each feature.</p>\n\n<p>Am I misunderstanding how the binary splitting works? Or is there a reason that this algorithm would not take long?</p>\n", "pids": ["557c252ed19fa4669fa1b2c4"], "flag": 1}
{"question": "Yolo Loss function explanation", "body": "<p>I am trying to understand the Yolo v2 loss function:</p>\n\n<p><span class=\"math-container\">\\begin{align}\n&amp;\\lambda_{coord} \\sum_{i=0}^{S^2}\\sum_{j=0}^B \\mathbb{1}_{ij}^{obj}[(x_i-\\hat{x}_i)^2 + (y_i-\\hat{y}_i)^2 ] \\\\&amp;+ \\lambda_{coord} \\sum_{i=0}^{S^2}\\sum_{j=0}^B \\mathbb{1}_{ij}^{obj}[(\\sqrt{w_i}-\\sqrt{\\hat{w}_i})^2 +(\\sqrt{h_i}-\\sqrt{\\hat{h}_i})^2 ]\\\\\n&amp;+ \\sum_{i=0}^{S^2}\\sum_{j=0}^B \\mathbb{1}_{ij}^{obj}(C_i - \\hat{C}_i)^2 + \\lambda_{noobj}\\sum_{i=0}^{S^2}\\sum_{j=0}^B \\mathbb{1}_{ij}^{noobj}(C_i - \\hat{C}_i)^2 \\\\\n&amp;+ \\sum_{i=0}^{S^2} \\mathbb{1}_{i}^{obj}\\sum_{c \\in classes}(p_i(c) - \\hat{p}_i(c))^2 \\\\\n\\end{align}</span></p>\n\n<p>If any person can detail the function.</p>\n", "pids": ["58d82fcbd649053542fd6729", "573696026e3b12023e516718"], "flag": 1}
{"question": "Human/social behavior when one emphasizes their own superior achievements over others&#39;", "body": "<p>I'm looking for a name/category/definition of (personality?) disorder(s) that can be described with the following traits in one's (imaginary person) social/human behavior:</p>\n<ul>\n<li>this person brings up and emphasizes his own, (according to him) superior achievements whenever another person around him mentions their own success/results/etc. (relevant fact: this person's statements about his own achievements are usually true, so there is no or little exaggeration);</li>\n<li>still, this person does this in a way that likely hurts other's feelings or self-esteem (this person does this regardless of who's the other half, like friends/partner/family), maybe even permanently;</li>\n<li>when this person has to do something with the achievements of others, he also emphasizes his own role behind the success of the other half (may even claim that the other person would not have been able to achieve their results without his assistance/inspiration);</li>\n<li>finally, though this may be a bit further from the previous points, this person may also inspire other people to start doing the same things that he's already started earlier (through which he may have an edge in terms of performance, quicker results, etc.) - e.g., a hobby or a sport.</li>\n</ul>\n<p>As a follow-up question: what would be an ideal strategy to deal with (from friends/family perspective) such a person's behavior (preferably in a way that noone gets hurt)?\nNote please that I'm not looking for an answer/advice related to any personal issues or situation, the above scenarios are strictly hypothetical.</p>\n<p>As a 2nd follow-up question: I'd be also interested in the origin of such a situation/traits (like how one would develop such a behavior, e.g. through childhood events or parental issues).</p>\n<p>My research so far: tried to look for an answer online by summarizing the main points and got to &quot;Narcissistic personality disorder&quot; which (according to <a href=\"https://www.mayoclinic.org/diseases-conditions/narcissistic-personality-disorder/symptoms-causes/syc-20366662\" rel=\"nofollow noreferrer\">this site</a>) is a mental condition in which people have an inflated sense of their own importance, a deep need for excessive attention and admiration.</p>\n<p>However, I'm not 100% sure that the above traits completely match this definition since they emphasize one's superior results/role in other's success and usually are combined with mean/humiliating remarks. Also, this person rarely steers a conversation etc. in a way so that he'll have the attention/focus.</p>\n", "pids": ["53e9bc15b7602d970487bac9"], "flag": 1}
{"question": "Is a &quot;hurdle model&quot; really one model? Or just two separate, sequential models?", "body": "<p>Consider a hurdle model predicting count data <code>y</code> from a normal predictor <code>x</code>:</p>\n\n<pre><code>set.seed(1839)\n# simulate poisson with many zeros\nx &lt;- rnorm(100)\ne &lt;- rnorm(100)\ny &lt;- rpois(100, exp(-1.5 + x + e))\n\n# how many zeroes?\ntable(y == 0)\n\nFALSE  TRUE \n   31    69 \n</code></pre>\n\n<p>In this case, I have count data with 69 zeros and 31 positive counts. Nevermind for the moment that this is, by definition of the data-generation procedure, a Poisson process, because my question is about hurdle models.</p>\n\n<p>Let's say I want to handle these excess zeros by a hurdle model. From my reading about them, it seemed like hurdle models aren't actual models per se—they are just doing two different analyses sequentially. First, a logistic regression predicting whether or not the value is positive versus zero. Second, a zero-truncated Poisson regression with <em>only including the non-zero cases.</em> This second step felt wrong to me because it is (a) throwing away perfectly good data, which (b) could lead to power issues since much of the data are zeros, and (c) basically not a \"model\" in and of itself, but just sequentially running two different models.</p>\n\n<p>So I tried a \"hurdle model\" versus just running the logistic and zero-truncated Poisson regression separately. They gave me identical answers (I'm abbreviating the output, for brevity's sake):</p>\n\n<pre><code>&gt; # hurdle output\n&gt; summary(pscl::hurdle(y ~ x))\n\nCount model coefficients (truncated poisson with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  -0.5182     0.3597  -1.441   0.1497  \nx             0.7180     0.2834   2.533   0.0113 *\n\nZero hurdle model coefficients (binomial with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -0.7772     0.2400  -3.238 0.001204 ** \nx             1.1173     0.2945   3.794 0.000148 ***\n\n&gt; # separate models output\n&gt; summary(VGAM::vglm(y[y &gt; 0] ~ x[y &gt; 0], family = pospoisson()))\n\nCoefficients: \n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  -0.5182     0.3597  -1.441   0.1497  \nx[y &gt; 0]      0.7180     0.2834   2.533   0.0113 *\n\n&gt; summary(glm(I(y == 0) ~ x, family = binomial))\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.7772     0.2400   3.238 0.001204 ** \nx            -1.1173     0.2945  -3.794 0.000148 ***\n---\n</code></pre>\n\n<p>This seems off to me since many different mathematical representations of the model include the probability that an observation is non-zero in the estimation of positive count cases, but the models I ran above <em>completely ignore one another.</em> For example, this is from Chapter 5, page 128 of Smithson &amp; Merkle's <em>Generalized Linear Models for Categorical and Continuous Limited Dependent Variables</em>:</p>\n\n<blockquote>\n  <p>...Second, the probability that $y$ assumes any value (zero and the positive integers) must equal one.  This is not guaranteed in Equation (5.33).  To deal with this issue, we multiply the Poisson probability by the Bernoulli success probability $\\pi$.<br>\n  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;These issues require us to express the above hurdle model as<br>\n  $$\nP(Y=y|\\boldsymbol{x,z,\\beta,\\gamma}) = \n \\begin{cases} 1-\\hat\\pi &amp;\\text{for } y=0  \\\\\n           \\hat\\pi\\times\\frac{\\exp(-\\hat\\lambda)\\hat\\lambda^y/y!}{1-\\exp(-\\hat\\lambda)}  &amp;\\text{for } y=1,2,\\ldots\n \\end{cases}  \\tag{5.34}\n$$\n  where $\\hat\\lambda=\\exp(\\boldsymbol{x\\beta})$, $\\hat\\pi = {\\rm logit}^{-1}(\\boldsymbol{z\\gamma})$, $\\boldsymbol x$ are the covariates for the Poisson model, $\\boldsymbol z$ are the covariates for the logistic regression model, and $\\hat{\\boldsymbol{\\beta}}$ and $\\hat{\\boldsymbol{\\gamma}}$ are the respective regression coefficients....  </p>\n</blockquote>\n\n<p>By doing the two models completely separate from one another—which seems to be what hurdle models do—I don't see how $\\hat{\\pi}$ is incorporated into the prediction of positive count cases. But based on how I was able to replicate the <code>hurdle</code> function by just running two different models, I don't see how $\\text{logit}^{-1}(z\\hat{\\gamma})$ plays a role in the truncated Poisson regression at all.</p>\n\n<p>Am I understanding hurdle models correctly? They seem two be just running two sequential models: First, a logistic; Second, a Poisson, completely ignoring cases where $y = 0$. I would appreciate if someone could clear-up my confusion with the $\\hat{\\pi}$ business.</p>\n\n\n\n<p>If I am correct that that is what hurdle models are, what is the definition of a \"hurdle\" model, more generally? Imagine two different scenarios:</p>\n\n<ul>\n<li><p>Imagine modeling competitiveness of electoral races by looking at competitiveness scores (1 - (winner's proportion of vote - runner up's proportion of vote)). This is [0, 1), because there are no ties (e.g., 1). A hurdle model makes sense here, because there is one process (a) was the election uncontested? and (b) if it wasn't, what predicted competitiveness? So we first do a logistic regression to analyze 0 vs. (0, 1). Then we do beta regression to analyze the (0, 1) cases.</p></li>\n<li><p>Imagine a typical psychological study. Responses are [1, 7], like a traditional Likert scale, with a huge ceiling effect at 7. One could do a hurdle model that's logistic regression of [1, 7) vs. 7, and then a Tobit regression for all cases where observed responses are &lt; 7.</p></li>\n</ul>\n\n<p><strong>Would it be safe to call both of these situations \"hurdle\" models</strong>, even if I estimate them with two sequential models (logistic and then beta in the first case, logistic and then Tobit in the second)?</p>\n", "pids": ["56d89738dabfae2eee193458"], "flag": 1}
{"question": "Why does minimizing the MAE lead to forecasting the median and not the mean?", "body": "<p>From the <a href=\"https://otexts.org/fpp2/\" rel=\"noreferrer\"><em>Forecasting: Principles and Practice</em> textbook by Rob J Hyndman  and George Athanasopoulos</a>, specifically <a href=\"https://otexts.org/fpp2/accuracy.html\" rel=\"noreferrer\">the section on accuracy measurement</a>:</p>\n\n<blockquote>\n  <p>A forecast method that minimizes the MAE will lead to forecasts of the\n  median, while minimizing the RMSE will lead to forecasts of the mean</p>\n</blockquote>\n\n<p>Can someone give an intuitive explanation of why minimizing the MAE leads to the forecasting the median and not the mean? And what does this means in practice?</p>\n\n<p>I have asked a customer: \"what is more important for you to make mean forecasts more accurate or to avoid very inaccurate forecasts?\". He said that to made mean forecasts more accurate have higher priority. So, in this case, should I use MAE or RMSE? Before I read this citation I believed that MAE will be better for such condition. And now I doubt.</p>\n", "pids": ["53e9a33cb7602d9702c458cd"], "flag": 1}
{"question": "Measures of similarity or distance between two covariance matrices", "body": "<p>Are there any measures of similarity or distance between two symmetric covariance matrices (both having the same dimensions)?</p>\n\n<p>I am thinking here of analogues to KL divergence of two probability distributions or the Euclidean distance between vectors except applied to matrices. I imagine there would be quite a few similarity measurements.</p>\n\n<p>Ideally I would also like to test the null hypothesis that two covariance matrices are identical.</p>\n", "pids": ["53e9bc15b7602d970487bccb"], "flag": 1}
{"question": "Information gain, mutual information and related measures", "body": "<p><a href=\"http://www.cs.cmu.edu/~awm/\">Andrew More</a> <a href=\"http://www.autonlab.org/tutorials/infogain11.pdf\">defines</a> information gain as:</p>\n\n<p>$IG(Y|X) = H(Y) - H(Y|X)$</p>\n\n<p>where $H(Y|X)$ is the <a href=\"http://en.wikipedia.org/wiki/Conditional_entropy\">conditional entropy</a>. However, Wikipedia calls the above quantity <a href=\"http://en.wikipedia.org/wiki/Mutual_information\">mutual information</a>.</p>\n\n<p>Wikipedia on the other hand defines <a href=\"http://en.wikipedia.org/wiki/Information_gain\">information gain</a> as the Kullback–Leibler divergence (aka information divergence or relative entropy) between two random variables:</p>\n\n<p>$D_{KL}(P||Q) = H(P,Q) - H(P)$</p>\n\n<p>where $H(P,Q)$ is defined as the <a href=\"http://en.wikipedia.org/wiki/Cross_entropy\">cross-entropy</a>.</p>\n\n<p>These two definitions seem to be inconsistent with each other.</p>\n\n<p>I have also seen other authors talking about two additional related concepts, namely  differential entropy and relative information gain.</p>\n\n<p>What is the precise definition or relationship between these quantities? Is there a good text book that covers them all?</p>\n\n<ul>\n<li>Information gain</li>\n<li>Mutual information</li>\n<li>Cross entropy </li>\n<li>Conditional entropy</li>\n<li>Differential entropy</li>\n<li>Relative information gain </li>\n</ul>\n", "pids": ["53e9b739b7602d97042ceeda"], "flag": 1}
{"question": "Neural network with skip-layer connections", "body": "<p>I am interested in regression with neural networks.</p>\n\n<p>Neural networks with zero hidden nodes + skip-layer connections are linear models.</p>\n\n<p>What about the same neural nets but with hidden nodes ?\nI am wondering what would be the role of the skip-layer connections ?</p>\n\n<p>Intuitively, i would say that if you include the skip-layer connections, then the final model will a sum of a linear model + some non-linear parts.</p>\n\n<p>Is there any advantage or disadvantage in adding skip-layer connections to neural nets ?</p>\n", "pids": ["573696026e3b12023e515eec"], "flag": 1}
{"question": "Range of dry matter yield per kg CO2 of different plant species", "body": "<p>The photosynthetic equation tells us that for every sugar molecule produced 6 molecules of carbon dioxide are used. </p>\n\n<p>I'm interested in how much organic matter is produced by a certain quantity of CO<sub>2</sub>. Obviously there are differences between plant species so I'm basically looking for a list of plant (categories), which tells how much CO<sub>2</sub> does produce how much dry matter.</p>\n", "pids": ["53e99784b7602d9701f3e166"], "flag": 1}
{"question": "The meaning of &quot;positive dependency&quot; as a condition to use the usual method for FDR control", "body": "<p><a href=\"http://www.stat.purdue.edu/~doerge/BIOINFORM.D/FALL06/Benjamini%20and%20Y%20FDR.pdf\">Benjamini and Hochberg</a> developed the first (and still most widely used, I think) method for controlling the false discovery rate (FDR). </p>\n\n<p>I want to start with a bunch of P values, each for a different comparison, and decide which ones are low enough to be called a \"discovery\", controlling the FDR to a specified value (say 10%). One assumption of the usual method is that the set of comparisons are either independent or have \"Positive dependency\" but I can't figure out exactly what that phrase means in the context of analyzing a set of P values. </p>\n", "pids": ["56d8ebdddabfae2eee558f35"], "flag": 1}
{"question": "Why can&#39;t we always create a vaccine against a virus when an ELISA test to detect it is possible?", "body": "<p>Before precising my question, here are some facts that I presume to be true:</p>\n\n<ol>\n<li><p>A <a href=\"https://www.publichealth.org/public-awareness/understanding-vaccines/vaccines-work/\" rel=\"nofollow noreferrer\">vaccine works</a> by injecting the antigens of a virus into the body to train the immune system to recognize the virus and to be prepared to fight it if it shows up.</p></li>\n<li><p>The <a href=\"https://www.healthline.com/health/elisa-western-blot-tests-for-hiv#elisa-test-and-hiv-differentiation-assay\" rel=\"nofollow noreferrer\">ELISA test</a> indirectly recognize the presence of a virus into a blood sample by testing the presence of the antigens of the virus and the antibodies that fight against it.</p></li>\n<li><p>One of <a href=\"https://biology.stackexchange.com/a/14797/52921\">the reasons</a> there are still no vaccine against HIV is because this virus has a very high mutation rate.</p></li>\n<li><p>The ELISA test is used to detect the presence of HIV.</p></li>\n</ol>\n\n<p>I have the feeling these facts contradict themselves and I would like to know where I am misleading.</p>\n\n<p>Indeed, if we have an ELISA test for HIV, we should be able to create a vaccine because we know the antigens of the virus and we can inject a harmless version of them into our body, right?\nApparently, the answer to this question is no because the HIV virus has a high mutation rate and the antibodies produced thanks to the vaccine won't be able to fight every mutation of the virus (that's the answer that gave me my former biology teacher in high school). But if the HIV has a high mutation rate, how can we be able to produce an ELISA test for it?</p>\n", "pids": ["5c0f8d12da562944aca0c247"], "flag": 1}
{"question": "Should parsimony really still be the gold standard?", "body": "<p>Just a thought:</p>\n\n<p>Parsimonious models have always been the default go-to in model selection, but to what degree is this approach outdated? I'm curious about how much our tendency toward parsimony is a relic of a time of abaci and slide rules (or, more seriously, non-modern computers). Today's computing power enables us to build increasingly complex models with ever-greater ability for prediction. As a result of this increasing ceiling in computing power, do we really still need to gravitate toward simplicity?  </p>\n\n<p>Sure, simpler models are easier to understand and interpret, but in the age of ever-growing data sets with greater numbers of variables and a shift towards a greater focus on prediction capability, this might no longer even be achievable or necessary.  </p>\n\n<p>Thoughts?</p>\n", "pids": ["5ee8986891e011e66831c39f", "5e5e18ae93d709897ce26ee9"], "flag": 1}
{"question": "XGBoost Loss function Approximation With Taylor Expansion", "body": "<p>As an example, take the objective function of the XGBoost model on the <span class=\"math-container\">$t$</span>'th iteration:</p>\n\n<p><span class=\"math-container\">$$\\mathcal{L}^{(t)}=\\sum_{i=1}^n\\ell(y_i,\\hat{y}_i^{(t-1)}+f_t(\\mathbf{x}_i))+\\Omega(f_t)$$</span></p>\n\n<p>where <span class=\"math-container\">$\\ell$</span> is the loss function, <span class=\"math-container\">$f_t$</span> is the <span class=\"math-container\">$t$</span>'th tree output and <span class=\"math-container\">$\\Omega$</span> is the regularization. One of the (many) key steps for fast calculation is the approximation:</p>\n\n<p><span class=\"math-container\">$$\\mathcal{L}^{(t)}\\approx \\sum_{i=1}^n\\ell(y_i,\\hat{y}_i^{(t-1)})+g_tf_t(\\mathbf{x}_i)+\\frac{1}{2}h_if_t^2(\\mathbf{x}_i)+\\Omega(f_t),$$</span></p>\n\n<p>where <span class=\"math-container\">$g_i$</span> and <span class=\"math-container\">$h_i$</span> are the first and second derivatives of the loss function. </p>\n\n<p>What I'm asking for is convincing arguments to demystify why the above approximation works:</p>\n\n<p>1) How does XGBoost with the above approximation compare to XGBoost with the full objective function? What potentially interesting, higher-order behavior is lost in the approximation?</p>\n\n<p>2) It's a bit hard to visualize (and depends on the loss function) but, if the loss function has a large cubic component, then the approximation will likely fail. How is it that this doesn't cause problems for XGBoost?</p>\n", "pids": ["573696046e3b12023e517cb1"], "flag": 1}
{"question": "How does capacitance depend on AC voltage?", "body": "<p>I am aware of the dependence of some ceramic capacitors (e.g. X7R) capacitance on DC voltage. I assumed that if a high enough AC voltage is applied, capacitance changes in its rhythm causing distortion of the sine wave. So far so good.</p>\n<p>I came across <a href=\"https://eu.mouser.com/datasheet/2/281/1/GRM31C5C1H224JE02_01A-1987815.pdf\" rel=\"noreferrer\">this datasheet</a> for a C0G capacitor that also contains some general info. On p.11 there is the familiar graph of capacitance vs. DC voltage. Following that is another graph of capacitance vs. <strong>AC</strong> voltage, here it is:</p>\n<p><a href=\"https://i.stack.imgur.com/HvFM1.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/HvFM1.png\" alt=\"capacitance change vs AC RMS voltage\" /></a></p>\n<p>This seems to be an altogether different phenomenon - the most pronounced drop in capacitance is at very low AC voltages. Also, the change is apparently independent of frequency. I can't find anything on this.</p>\n<p>Does anyone know how this works? (Dielectric types, frequency dependence, DC and AC phenomena combined, etc.)</p>\n", "pids": ["5fc6e410e8bf8c1045120a45"], "flag": 1}
{"question": "What are the typical uses for a soft-processor such as MicroBlaze?", "body": "<p>I know that the FPGA-DSP combination is typically used for high-end power electronics/ultrasound/MRI/etc.  Is it possible for the soft-processor to fully replace the DSP even on lower-end FPGAs such as Spartan 3/6?</p>\n\n<p>Added: What would be the reason for having multiple softcore processors in one FPGA?</p>\n", "pids": ["558b0644e4b037c0875a9321"], "flag": 1}
{"question": "How to reach ~50nA p-p current noise in ~200mA current source?", "body": "<p>Target application is driving single-frequency laser diodes (@2.5V) which are sensitive to current noise. Current is constant, with no modulation.</p>\n<p>Strightforward solutions that first comes to mind is low-noise LDO (for example LT1963) that can reach ~40µV RMS which would give us around 4µA RMS of current noise. TPS7A4700 is better at 4µV RMS, which will give us ~400nA of RMS noise. But that is still far away from 50nA p-p.</p>\n<p>Could the rest of the gap be covered by filtering / capacitance multipliers? Or there are specific solutions to low-noise current sources that are significantly better than high-end LDO?</p>\n", "pids": ["617929705244ab9dcb051c42"], "flag": 1}
{"question": "Difference between feedback RNN and LSTM/GRU", "body": "<p>I am trying to understand different Recurrent Neural Network (RNN) architectures to be applied to time series data and I am getting a bit confused with the different names that are frequently used when describing RNNs. Is the structure of Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) essentially an RNN with a feedback loop?</p>\n", "pids": ["5550415d45ce0a409eb3aa60"], "flag": 1}
{"question": "Why is the exponential family so important in statistics?", "body": "<p>Why is the exponential family so important in statistics?</p>\n<p>I was recently reading about the <a href=\"https://en.wikipedia.org/wiki/Exponential_family\" rel=\"noreferrer\">exponential family</a> within statistics. As far as I understand, the exponential family refers to any <a href=\"https://en.wikipedia.org/wiki/Probability_distribution_function\" rel=\"noreferrer\">probability distribution function</a> that can be written in the following format (notice the &quot;exponent&quot; in this equation):</p>\n<p><a href=\"https://i.stack.imgur.com/56QQv.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/56QQv.png\" alt=\"Enter image description here\" /></a></p>\n<p>This includes common probability distribution functions such as the <a href=\"https://en.wikipedia.org/wiki/Normal_distribution\" rel=\"noreferrer\">normal distribution</a>, the <a href=\"https://en.wikipedia.org/wiki/Gamma_distribution\" rel=\"noreferrer\">gamma distribution</a>, the <a href=\"https://en.wikipedia.org/wiki/Poisson_distribution\" rel=\"noreferrer\">Poisson distribution</a>, etc. Probability distributions from the exponential family are often used as the &quot;link function&quot; in regression problems (e.g., in count data settings, the response variable can be related to the covariates through a Poisson distribution) - probability distribution functions that belong to the exponential family are often used due to their &quot;desirable mathematical properties&quot;. For example, these properties are the following:</p>\n<p><a href=\"https://i.stack.imgur.com/nCgrk.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/nCgrk.png\" alt=\"Enter image description here\" /></a></p>\n<p>Why are these properties so important?</p>\n<p><strong>A)</strong> The first property is about &quot;sufficient statistics&quot;. A &quot;sufficient statistic&quot; is a statistic that provides more information for any given data set/model parameter compared to any other statistic.</p>\n<p>I am having trouble understanding why this is important. In the case of logistic regression, the logit link function is used (part of the exponential family) to link the response variable with the observed covariates. What exactly are the &quot;statistics&quot; in this case (e.g.. in a logistic regression model, do these &quot;statistics&quot; refer to the &quot;mean&quot; and &quot;variance&quot; of the beta-coefficients of the regression model)? What are the &quot;fixed values&quot; in this case?</p>\n<p><strong>B)</strong> Exponential families have conjugate priors.</p>\n<p>In the Bayesian setting, a prior p(thetha | x) is called a conjugate prior if it is in the same family as the posterior distribution p(x | thetha). If a prior is a conjugate prior - this means that a closed form solution exists and numerical integration techniques (e.g., <a href=\"https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo\" rel=\"noreferrer\">MCMC</a>) are not required to sample the posterior distribution. Is this correct?</p>\n<p><strong>C)</strong> Is the third property essentially similar to the second property?</p>\n<p><strong>D)</strong> I don't understand the fourth property at all. <a href=\"https://en.wikipedia.org/wiki/Variational_Bayesian_methods\" rel=\"noreferrer\">Variational Bayes</a> are an alternative to MCMC sampling techniques that approximate the posterior distribution with a simpler distribution - this can save computational time for high dimensional posterior distributions with big data. Does the fourth property mean that variational Bayes with conjugate priors in the exponential family have closed form solutions? So any Bayesian model that uses the exponential family does not require MCMC - is this correct?</p>\n<p><strong>References:</strong></p>\n<ul>\n<li><em><a href=\"https://en.wikipedia.org/wiki/Exponential_family\" rel=\"noreferrer\">Exponential family</a></em></li>\n<li><em><a href=\"https://en.wikipedia.org/wiki/Sufficient_statistic\" rel=\"noreferrer\">Sufficient statistic</a></em></li>\n<li><em><a href=\"https://en.wikipedia.org/wiki/Conjugate_prior\" rel=\"noreferrer\">Conjugate prior</a></em></li>\n</ul>\n", "pids": ["5736960f6e3b12023e522205"], "flag": 1}
{"question": "Do any known viruses contain &quot;junk&quot; or parasitic genomic information?", "body": "<p>After reading about so-called \"mystery proteins\" in <a href=\"https://www.nytimes.com/interactive/2020/04/03/science/coronavirus-genome-bad-news-wrapped-in-protein.html\" rel=\"noreferrer\">this excellent summary</a> of the coronavirus genome (and acknowledging that the \"mystery\" simply reflects our lack of knowledge about a very new virus), I'm curious if any known viruses can contain parasitic genetic information \"along for the ride\", or if their genomes are selected, generally speaking, to be as informationally efficient as possible, for what is encoded? In other words, does selection pressure allow for these parasites to contain their own parasites, and are there known examples of such, if so?</p>\n", "pids": ["5d3d73e2275ded87f97d9be2", "53e9b4c4b7602d9703fe2c09"], "flag": 1}
{"question": "Estimating current draw for a single instruction", "body": "<p>I am a software engineer concerned about current draw.</p>\n<p>I am aware that there are ways to reduce the current draw of a program, for example:</p>\n<ul>\n<li><p>using a <code>hlt</code> instruction which disables the CPU until the next interrupt</p>\n</li>\n<li><p>maybe avoiding floating point so that the FPU doesn't get jiggled</p>\n</li>\n</ul>\n<p>I'm wondering if it's possible to estimate the current draw of a single instruction, so that a theoretical compiler can select the instruction which will draw less power. Existing compilers can normally optimise for speed or for size, but I have never see a compiler which can optimise for current draw. Maybe no-one's considered it, maybe no-one's done the research into every single instruction, maybe it's actually impossible.</p>\n<p>But consider for example some NMOS processor like the early 6502s. By my intuition, subtracting 0xff from 0xff would draw more power than subtracting 0x01 from 0x01 because I think the inputs to the ALU need to be precharged more or something. But knowing next to nothing about electronics I'd appreciate if someone could tell me if</p>\n<p>a) my intuition is correct</p>\n<p>b) it's practical to estimate the current draw of a CPU instruction if you know what state the CPU's in, so that you know exactly what the instruction is doing.</p>\n", "pids": ["60cd690291e011329faa2261"], "flag": 1}
{"question": "Wavelengths blocked by a certain metal mesh", "body": "<p><strong>Introduction:</strong> I've heard about a theory, according to which you can check if there is any leakage in your microwave oven by putting your mobile phone inside and call it. However, I gave it a try and the call was successful.</p>\n\n<p>I realized that the two devices are working on different frequencies (and wavelengths, of course), thus the metal mesh in the door of the oven may be unable to block anything different from the intended working frequency. I came across similar results on the Internet.</p>\n\n<p>Calculating the free-space wavelengths for 1.8 GHz and 2.45 GHz, we get ~0.167 and ~0.122 meters, respectively. This means a 40% increase in wavelength for the unintended usage. </p>\n\n<p><strong>Problem</strong>: Still, I don't understand why I was able to call my phone. First of all, I vaguely seem to remember a 'thumb of rule', namely that a metal mesh blocks electromagnetic waves of which the wavelength is in the same order of magnitude as the dimensions of the holes (or smaller). Well, that looks absolute stupidity, as the holes appear to be no more than 2-3 mm each side (almost a hundredth of the wavelengths).</p>\n\n<p>Secondly, those wavelengths are practically the same in comparison with the holes.</p>\n\n<p><strong>Question:</strong> Given the dimensions of a metal mesh, how can you determine the range of wavelengths blocked by it?</p>\n", "pids": ["53e9ba17b7602d970461c767"], "flag": 1}
{"question": "Can computer speakers emit ultrasound?", "body": "<p>Can computer speakers emit ultrasound? What is the maximum frequency that computer speakers can produce?</p>\n", "pids": ["5d9edb6447c8f76646017b12"], "flag": 1}
{"question": "Are civilian GPS signals cryptographically signed?", "body": "<p>As far as I understand, receiving enough GPS signals at the same time enables to deduce the position and the time.</p>\n<p>I guess it is possible to use an offline receiver as a very precise clock.</p>\n<p>If so, is it possible to flood this offline receiver with fake signals to make it believe it's 12:00:01 when it's actually 12:00:00?</p>\n<p>More specifically, is it possible to design a receiver that can't be attacked this way?</p>\n<p>If GPS signals (or Galileo's) are cryptographically signed, it's easy to reject non-signed signals by saving the public key of the satellites beforehand.</p>\n<p>Are the GPS signals cryptographically signed?</p>\n<p><strong>Edit:</strong> My question is not about the civilian signal being encrypted or not (meaning unreadable for people not having a secret key), but signed or not (meaning the authenticity of the signal being verifiable thanks to a public information: the public key of this satellite.)</p>\n", "pids": ["5f0df9939fced0a24b066504"], "flag": 1}
{"question": "How does LTSpice model reverse recovery time?", "body": "<p><strong>Hello everyone,</strong></p>\n\n<p>I am working on the prediction of the reverse recovery losses in a Buck converter. I have the following schematic:</p>\n\n<p><a href=\"https://i.stack.imgur.com/KN2QD.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/KN2QD.png\" alt=\"enter image description here\"></a></p>\n\n<p>You can see below a zoom on the turning-off time of the diode:</p>\n\n<p><a href=\"https://i.stack.imgur.com/v3vsV.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/v3vsV.png\" alt=\"Turning-off of the diode\"></a></p>\n\n<p>I am using the following models for the MOS and the diode:</p>\n\n<ul>\n<li><strong>.model diode d(Is=1f n=1 tt=200p)</strong></li>\n<li><strong>.model pmos pmos Vto=-0.4 Kp=40u lambda=0.05 tox=5n Cgdo=0.207n Cgso=0.207n LD=30n</strong></li>\n</ul>\n\n<p>Can someone explain me how does SPICE (I am using the latest version of LTSPICE) model reverse recovery time? I am looking for equations, aka a way to predict t<sub>RR</sub>. In their book <strong>Microelectronic Circuit Design</strong> (5th Edition), R. Jaeger and T. Blalock speak a little bit about it, p91-92-93-94 and p128-129. They give an expression for the storage time, but with this expression, I can’t predict what SPICE shows.</p>\n\n<p>Can the reverse recovery time can be seen as the time required to empty Q<sub>D</sub> = i<sub>D</sub>t<sub>T</sub> the charges stored in the diode? If yes, t<sub>RR</sub> should be the integral of the negative peak current flowing through the diode right? When I calculate this integral, it doesn’t match Q<sub>D</sub>.</p>\n\n<p>I am not looking for information from a datasheet, I would like to understand how LTSpice is doing its calculation and ultimately, I would like to be able to predict what it is doing.</p>\n\n<p>I haven’t defined parameters CJ (junction capacitance), and RS (series resistance). But still, SPICE does model a reverse recovery effect. How and why?</p>\n", "pids": ["558c4b23e4b0cfb70a1cd421"], "flag": 1}
{"question": "Exploiting stack buffer overflows on an Arduino", "body": "<p>Is it possible exploit stack buffer overflows on an Arduino board?</p>\n", "pids": ["53e9b850b7602d9704412ea6"], "flag": 1}
{"question": "Is there a term to refer to humans&#39; automatic belief of encountered information?", "body": "<p>I believe there is a universal (or, highly regular in the mechanisms of cognition) human tendency to believe a proposition just because they encountered it. I mean this in a very specific way. It’s like they mistake someone asserting something for the discovery of a fact, from the oblivion. It’s almost like when propositions are placed somewhere free from context, the human mind through evolution has developed an (advantageous) tendency to absorb information / beliefs rapidly as they are transmitted. It would be way too much of an expense of cognitive energy to have to consider all logical factors necessary for a proposition to really be true. Even intelligent people must do it, it’s necessary for day to day functioning, and survival in / keeping up with a culture. You can imagine in paleolithic times, someone might say, &quot;There are blackberries in X location,&quot; and it's almost like a computer sending a transmission which automatically gets received. The sort of &quot;scrutiny&quot; mechanisms of human thought are not always active. There are times where just because someone said something, you immediately assume it's true without realizing or thinking about it, to the extent that you might transmit that information to someone else with the sense that it is authoritative knowledge. It's almost like we can intuitively distinguish between reported knowledge vs. (at least what we consider) an absolute fact, except we don't do it accurately - we are biased in favor of absolute facts over reported knowledge.</p>\n<p>In the extreme case it’s someone just believing anything they read online indiscriminately, but there are plenty of subtle everyday cases too. Sort of like Kahneman’s “WYSIWYG” concept (what you see is what you get), or could be an acronym such as the “I know it’s true because somebody said so” phenomenon. It’s meant to be more subtle and nuanced than just the general notion of being gullible.</p>\n<p>Have any scientists discussed this aspect of human psychology?</p>\n<p>Thank you</p>\n", "pids": ["55a515c6c91bf3b1cc4e6e28", "5a9ea66c684d55eb9298e44c", "53e9b5d4b7602d9704120fc1", "53e9b221b7602d9703cb7521", "55a4d88565ceb7cb02d9e998"], "flag": 1}
{"question": "Why do SSRIs take multiple weeks to reach their full effect?", "body": "<p>What is it about SSRIs that they require 2-4 weeks for their long-term effect to become present?</p>\n<p>Is this the result of small accumulations over time in some aspect of the brain?</p>\n<p>Are there other medicines which are known to have a delayed onset of effect like this?</p>\n", "pids": ["61c90f9f5244ab9dcb54a8cb"], "flag": 1}
{"question": "Is it possible to calculate AIC and BIC for lasso regression models?", "body": "<p>Is it possible to calculate AIC or BIC values for lasso regression models and other regularized models where parameters are only partially entering the equation.  How does one determine the degrees of freedom?</p>\n\n<p>I'm using R to fit lasso regression models with the <code>glmnet()</code> function from the <code>glmnet</code> package, and I'd like to know how to calculate AIC and BIC values for a model.  In this way I might compare the values with models fit without regularization.  Is this possible to do?</p>\n", "pids": ["56d83494dabfae2eee375085"], "flag": 1}
{"question": "How are Random Forests not sensitive to outliers?", "body": "<p>I've read in a few sources, including <a href=\"http://www.listendata.com/2014/11/random-forest-with-r.html\">this one</a>, that Random Forests are not sensitive to outliers (in the way that Logistic Regression and other ML methods are, for example).</p>\n\n<p>However, two pieces of intuition tell me otherwise:</p>\n\n<ol>\n<li><p>Whenever a decision tree is constructed, all of the points must be classified.  This means that even outliers will get classified, and hence will affect the decision trees where they were selected during boosting.</p></li>\n<li><p>Bootstrapping is a part of how a RandomForest does sub-sampling.  Bootstrapping is susceptible to outliers.</p></li>\n</ol>\n\n<p>Is there any way to reconcile my intuition about its sensitivity to outliers, with sources that disagree?    </p>\n", "pids": ["5390a0b720f70186a0e4f3a9"], "flag": 1}
{"question": "What is the connection between credible regions and Bayesian hypothesis tests?", "body": "<p>In frequentist statistics, there is a close connection between confidence intervals and tests. Using inference about $\\mu$ in the $\\rm N(\\mu,\\sigma^2)$ distribution as an example, the $1-\\alpha$ confidence interval\n$$\\bar{x}\\pm t_{\\alpha/2}(n-1)\\cdot s/\\sqrt{n}$$\ncontains all values of $\\mu$ that aren't rejected by the $t$-test at the significance level $\\alpha$.</p>\n\n<p>Frequentist confidence intervals are in this sense inverted tests. (Incidentally, this means that we can interpret the $p$-value as the smallest value of $\\alpha$ for which the null value of the parameter would be included in the $1-\\alpha$ confidence interval. I find that this can be a useful way to explain what $p$-values really are to people who know a bit of statistics.)</p>\n\n<p>Reading about <a href=\"https://stats.stackexchange.com/questions/24681/what-is-the-decision-theoretic-justification-for-bayesian-credible-interval-proc\">the decision-theoretic foundation of Bayesian credible regions</a>, I started to wonder whether there is a similar connection/equivalence between credible regions and Bayesian tests.</p>\n\n<ul>\n<li>Is there a general connection? </li>\n<li>If there is no general connection, are there examples where there is a connection? </li>\n<li>If there is no general connection, how can we see this?</li>\n</ul>\n", "pids": ["56d8e95ddabfae2eee465c13", "56d8e95ddabfae2eee465c13"], "flag": 1}
{"question": "What are the differences between sparse coding and autoencoder?", "body": "<p>Sparse coding is defined as learning an over-complete set of basis vectors to represent input vectors (&lt;-- why do we want this) . What are the differences between sparse coding and autoencoder? When will we use sparse coding and autoencoder?</p>\n", "pids": ["5b8c9f0717c44af36f8b1606"], "flag": 1}
{"question": "Sampling for Imbalanced Data in Regression", "body": "<p>There have been good questions on handling imbalanced data in the <em>classification</em> context, but I am wondering what people do to sample for regression.</p>\n\n<p>Say the problem domain is very sensitive to the sign but only somewhat sensitive to the magnitude of the target. However the magnitude is important enough that the model should be regression (continuous target) not classification (positive vs. negative classes). And say in this problem domain that any set of training data will have 10x more negative than positive targets.</p>\n\n<p>In this scenario, I might oversample the positive-target examples to match the count of negative-target examples, and then train a model to differentiate the two cases. Obviously the training approach does badly on imbalanced data, so I need to do sampling of some sort. What would be a decent way to \"undo\" this oversampling when making predictions? Perhaps translating by the (negative) mean or median of the target of the natural training data?</p>\n", "pids": ["5cc03429ced107d4c60ed524"], "flag": 1}
{"question": "Can you simulate a schematic?", "body": "<p>Is there software out there that will take a schematic as input and simulate its functioning?</p>\n\n<p>I don't have a lot of cash for components and tools, so this would be a cheap and easy way for me to learn more about electronics.</p>\n", "pids": ["573698516e3b12023e718d8d"], "flag": 1}
{"question": "What is the etymology of &#39;plane&#39; e.g. data plane, control plane, etc.?", "body": "<p>My guess would be aviation (used as an analogy), but I find no source for this.</p>\n<p>Data plane was being used as early as 1965 (e.g. in this paper) <a href=\"https://ieeexplore.ieee.org/abstract/document/4038491\" rel=\"noreferrer\">https://ieeexplore.ieee.org/abstract/document/4038491</a>\n&quot;the planes prepared by the factory must anticipate all possible situations.&quot;\nThis suggests the plane is something physical?</p>\n<p>(I guess what I was really wondering is how the term has evolved from electronics cases (a physical plane of wires), through telecoms (originally physical planes), then to networking, then to nowadays we talk about a 'control plane' in Kubernetes - is this derived from the original use case in the 1965 paper?)</p>\n", "pids": ["599c7945601a182cd262a269"], "flag": 1}
{"question": "What is the &quot;capacity&quot; of a machine learning model?", "body": "<p>I'm studying this <a href=\"https://arxiv.org/pdf/1606.05908.pdf\" rel=\"noreferrer\">Tutorial on Variational Autoencoders by Carl Doersch</a>. In the second page it states:</p>\n\n<blockquote>\n  <p>One of the most popular such frameworks is the Variational Autoencoder [1, 3], the subject of this tutorial. The assumptions of this model are weak, and training is fast via backpropagation. VAEs do make an approximation, but the error introduced by this approximation is arguably small given <strong>high-capacity models</strong>. These characteristics have contributed to a quick rise in their popularity.</p>\n</blockquote>\n\n<p>I've read in the past these sort of claims about <strong>high-capacity models</strong>, but I don't seem to find any clear definition for it. I also found <a href=\"https://stackoverflow.com/questions/40337510/what-is-the-definition-of-high-capacity-cnn-or-high-capacity-architecture\">this related stackoverflow question</a> but to me the answer is very unsatisfying.</p>\n\n<p>Is there a definition for the capacity of a model? Can you measure it? </p>\n", "pids": ["599c7950601a182cd262f3f9"], "flag": 1}
{"question": "Why is max pooling necessary in convolutional neural networks?", "body": "<p>Most common convolutional neural networks contains pooling layers to reduce the dimensions of output features. Why couldn't I achieve the same thing by simply increase the stride of the convolutional layer? What makes the pooling layer necessary?</p>\n", "pids": ["5c0f8548da562944ac906795", "5c75726df56def9798810d4e", "5550412645ce0a409eb38dd9", "5a73cb6317c44a0b30358028"], "flag": 1}
{"question": "Maximum Mean Discrepancy (distance distribution)", "body": "<p>I have two data sets (source and target data) which follow different distributions. I am using MMD - that is a non-parametric distribution distance - to compute marginal distribution between the source and target data.</p>\n<p><em><strong>source data, Xs</strong></em></p>\n<p><em><strong>target data, Xt</strong></em></p>\n<p><em><strong>adaptation Matrix A</strong></em></p>\n<p>**<em>Projected data, Zs = A'<em>Xs and  Zt = A'<em>Xt</em></em></em></p>\n<p>*<strong>MMD =&gt; Distance(P(Xs),P(Xt)) = | mean(A'Xs) - mean(A'<em>Xt) |</em></strong></p>\n<p>That means: the distribution's distance between the source and target data in the original space is equivalent to the distance between means of projected source and target data in the embedded space.</p>\n<p>I have a question about the concept of MMD.</p>\n<p>In the MMD formula, why with computing distance in the latent space we could measure the distribution's distance in the original space?</p>\n<p>Thanks</p>\n", "pids": ["60dbe32d91e0117bb69ae572", "53e9b725b7602d97042bf827", "5ce2be43ced107d4c607785d"], "flag": 1}
{"question": "Can cross validation be used for causal inference?", "body": "<p>In all contexts I am familiar with cross-validation it is solely used with the goal of increasing predictive accuracy. Can the logic of cross validation be extended in estimating the unbiased relationships between variables? </p>\n\n<p>While <a href=\"http://dx.doi.org/10.1007/s10940-009-9077-7\" rel=\"nofollow noreferrer\">this</a> paper by Richard Berk demonstrates the use of a hold out sample for parameter selection in the \"final\" regression model (and demonstrates why step-wise parameter selection is not a good idea), I still don't see how that exactly ensures unbiased estimates of the effect X has on Y any more so than choosing a model based on logic and prior knowledge of the subject.</p>\n\n<p>I ask that people cite examples in which one used a hold-out sample to aid in causal inference, or general essays that may help my understanding. I also don't doubt my conception of cross validation is naive, and so if it is say so. It seems offhand the use of a hold out sample would be amenable to causal inference, but I do not know of any work that does this or how they would do this. </p>\n\n<p>Citation for the Berk Paper:</p>\n\n<p><a href=\"http://dx.doi.org/10.1007/s10940-009-9077-7\" rel=\"nofollow noreferrer\">Statistical Inference After Model Selection</a>\nby: Richard Berk, Lawrence Brown, Linda Zhao\nJournal of Quantitative Criminology, Vol. 26, No. 2. (1 June 2010), pp. 217-236. </p>\n\n<p>PDF version <a href=\"http://www-stat.wharton.upenn.edu/~lzhao/papers/MyPublication/StatInfAfterMS_JQC_2010.pdf\" rel=\"nofollow noreferrer\">here</a></p>\n\n<p><a href=\"https://stats.stackexchange.com/q/3252/1036\">This</a> question on exploratory data analysis in small sample studies by chl prompted this question. </p>\n", "pids": ["53e9a982b7602d97032ddc28"], "flag": 1}
{"question": "Does cognitive psychology define motivation in terms of information processing?", "body": "<p>I recently asked a question on biology.stackexchange.com that if an amoeba showed &quot;avoidance&quot; behavior, would this constitute a &quot;motivation&quot; to avoid something.</p>\n<p>Within a biology context, the term &quot;motivation&quot; is seen to be a primarily human characteristic associated with &quot;free will&quot;.</p>\n<p>I explained that when I said &quot;motivation&quot;, I simply meant unscripted information processing.</p>\n<p>To this, the reply was:</p>\n<blockquote>\n<p>Again, definitions are important: &quot;motivation&quot; does not ordinarily mean &quot;information processing&quot; in fields of psychology/neuroscience/biology.</p>\n</blockquote>\n<p>This surprised me.  Doesn't cognitive psychology define human &quot;motivation&quot; in terms of information processing?</p>\n<p>When I did a google search, I found this <a href=\"https://link.springer.com/chapter/10.1007/978-1-4899-0827-8_13\" rel=\"nofollow noreferrer\">reference</a>.</p>\n<p>Am I wrong? Would it be unreasonable to attempt to define &quot;motivation&quot; in terms of information processing?</p>\n", "pids": ["5ce7c1133a55ac687ab1bef4"], "flag": 1}
{"question": "Can SVM do stream learning one example at a time?", "body": "<p>I have a streaming data set, examples are available one at a time. I would need to do multi class classification on them. As soon as I fed a training example to the learning process, I have to discard the example. Concurrently, I'm also using the latest model to perform prediction on unlabelled data.</p>\n\n<p>As far as I know, a neural network is able to do stream learning by feeding examples one at a time and performing forward propagation and backward propogation on the example.</p>\n\n<p>Can a SVM perform stream learning one example at a time and discard the example straight away?</p>\n", "pids": ["53e9ae1cb7602d970382a664"], "flag": 1}
{"question": "Pooling vs. stride for downsampling", "body": "<p>Pooling and stride both can be used to downsample the image.</p>\n\n<p>Let's say we have an image of 4x4, like below\n<a href=\"https://i.stack.imgur.com/RExdf.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/RExdf.png\" alt=\"enter image description here\"></a>\nand a filter of 2x2.\nThen how do we decide whether to use (2x2 pooling) vs. (stride of 2)?</p>\n", "pids": ["5550412645ce0a409eb38dd9"], "flag": 1}
{"question": "How large an expression boost is typical from codon optimization?", "body": "<p>There are lots of different codon optimization approaches out there, and a lot of different qualitative reasons to want optimization (e.g., organism codon bias, GC content, avoiding secondary structure).</p>\n<p>One may also want to avoid optimization, however, in order to increase reusability of a component, comparability with prior results, or opportunities for error.</p>\n<p>I'd like to know how much I'm likely giving up if I decide not to codon optimize. For example, in my typical work giving up 10% is likely to be lost in the noise, but giving up 2x is worth thinking carefully about, and giving up 10x means it's a must-have.</p>\n<p>I know &quot;it depends&quot;, and there's a lot of <a href=\"https://www.genewiz.com/Public/Services/Gene-Synthesis/Codon-Optimization\" rel=\"noreferrer\">qualitative information out there</a>, but is there any way to get a good rough-order-of-magnitude estimate of the typical expression boost from codon optimization?</p>\n", "pids": ["5ff68871d4150a363cc73615"], "flag": 1}
{"question": "Why do T cells have MHC II receptors?", "body": "<p>I have seen the answer to this <a href=\"https://biology.stackexchange.com/questions/5612/do-t-cells-express-mhc-molecules\">question</a> which says that T cells do not express MHC II proteins which would make sense.</p>\n<p>However, my textbook &quot;The immune system&quot; by Peter Parham disagrees. It says that T cells do gain MHC II receptors after activation.</p>\n<p><a href=\"https://i.stack.imgur.com/oygiP.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/oygiP.png\" alt=\"enter image description here\" /></a></p>\n<blockquote>\n<p>*Activated T cells express MHC class II molecules, whereas resting T cells do not.</p>\n</blockquote>\n<p>I cannot see why this is needed. MHC II molecules are for CD4 cells (helper T cells).</p>\n<p>If the T cell presenting the antigen was a CD4 cell, then that seems useless, because this cell was already the one that could recognise this particular antigen - so why show it to others? The chance that another T cell that could recognise it too would be incredibly small no?</p>\n<p>I guess I can see the merit of a CD8 T killer cell to show the antigen, as it could alert other CD4 T cells to come assist (although cytokines seem like a better method...)</p>\n<p>So what is the purpose of T cells, in particular CD4, of showing MHC II proteins?</p>\n", "pids": ["55a4a83c612ca648689f2a44"], "flag": 1}
{"question": "Evidence for man-made global warming hits &#39;gold standard&#39;: how did they do this?", "body": "<p>This <a href=\"https://www.reuters.com/article/us-climatechange-temperatures/evidence-for-man-made-global-warming-hits-gold-standard-scientists-idUSKCN1QE1ZU\" rel=\"noreferrer\">message</a> in a Reuter's article from 25.02.2019 is currently all over the news:</p>\n\n<blockquote>\n  <p><strong>Evidence for man-made global warming hits 'gold standard'</strong></p>\n  \n  <p>[Scientists] said confidence that human activities were raising the heat at the Earth’s surface had reached a “five-sigma” level, a statistical gauge meaning there is only a one-in-a-million chance that the signal would appear if there was no warming.</p>\n</blockquote>\n\n<p>I believe that this refers to this article <a href=\"https://www.nature.com/articles/s41558-019-0424-x\" rel=\"noreferrer\">\"Celebrating the anniversary of three key events in climate change science\"</a> which contains a plot, which is shown schematically below (It is a sketch because I could not find an open source image for an original, similar free images are found <a href=\"https://www.pnas.org/content/110/1/26/tab-figures-data\" rel=\"noreferrer\">here</a>). Another article from the same research group, which seems to be a more original source, is <a href=\"http://science.sciencemag.org/content/361/6399/eaas8806\" rel=\"noreferrer\">here</a> (but it uses a 1% significance instead of <span class=\"math-container\">$5\\sigma$</span>). </p>\n\n\n\n<p>The plot presents measurements from three different research groups: Remote Sensing Systems, the Center for Satellite Applications and Research, and the University of Alabama at Huntsville. </p>\n\n<p>The plot displays three rising curves of signal to noise ratio as a function of trend length.</p>\n\n<p><a href=\"https://i.stack.imgur.com/PTw60.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/PTw60.png\" alt=\"anthropogenic signal\"></a></p>\n\n<p>So somehow scientists have measured an anthropogenic signal of global warming (or climate change?) at a <span class=\"math-container\">$5\\sigma$</span> level, which is apparently some <a href=\"https://stats.stackexchange.com/questions/31591\">scientific standard of evidence</a>.</p>\n\n<p>For me such graph, which has a high level of abstraction, raises many questions<span class=\"math-container\">$^{\\dagger}$</span>, and in general I wonder about the question <strong>'How did they do this?'</strong>. How do we explain this experiment into simple words (but not so abstract) and also explain the meaning of the <span class=\"math-container\">$5\\sigma$</span> level?</p>\n\n<p>I ask this question here because I do not want a discussion about climate. Instead I want answers regarding the statistical content and especially to clarify the <em>meaning</em> of such a statement that is using/claiming <span class=\"math-container\">$5 \\sigma$</span>.</p>\n\n\n\n<p><span class=\"math-container\">$^\\dagger$</span> What is the null hypothesis? How did they set up the experiment to get a <em>anthropogenic</em> signal? What is the effect <em>size</em> of the signal? Is it just a small signal and we only measure this now because the noise is decreasing, or is the signal increasing? What kind of assumptions are made to create the statistical model by which they determine the crossing of a 5 sigma threshold (independence, random effects, etc...)? Why are the three curves for the different research groups different, do they have different noise or do they have different signals, and in the case of the latter, what does that mean regarding the interpretation of probability and external validity?</p>\n", "pids": ["5ce2d1f0ced107d4c6482be7"], "flag": 1}
{"question": "Which genetic oscillator should I use to generate oscillations in range of 2-20 mins?", "body": "<p>I'm looking to phase-separate the expression of two enzymes and hence am looking for a multi-component genetic oscillator. However, repressilators and metabolators have a large period of around 45 mins. Smolen oscillators as described in <em>Stricker et al 2008</em>  <a href=\"https://www.nature.com/articles/nature07389\" rel=\"noreferrer\">A fast, robust and tunable synthetic gene oscillator </a> seem like something I could use, however, I'm not sure if I should, I am new to oscillators.</p>\n<p>Please let me know what kind of oscillator you would recommend for a 2-20 min period time, preferably robust. Any other relevant information or recommendations are welcome. The intended system is Synechocystsis 6803 but initial work may be done in E coli.</p>\n", "pids": ["5ce2c686ced107d4c61eb206"], "flag": 1}
{"question": "If silver nanoparticles kill bacteria by penetrating the cell membrane, why don&#39;t they also kill human cells on contact?", "body": "<p>Apparently, the silver from the nanoparticles can penetrate the cell wall of bacteria and kill them from the inside. Why, then, doesn't the same happen to human cells, e.g. the skin on my foot when I wear nanosilver-coated antibacterial socks, or the stomach lining when people drink nanosilver-treated water? Is it because the cell wall is different in bacteria than in multicellular organisms?</p>\n", "pids": ["5ce2cac1ced107d4c628097b"], "flag": 1}
{"question": "What are the most common biases humans make when collecting or interpreting data?", "body": "<p>I am an econ/stat major. I am aware that economists have tried to modify their assumptions about human behavior and rationality by identifying situations in which people don't behave rationally. For example, suppose I offer you a 100% chance of a \\$1000 loss or a 50% chance at a \\$2500 loss, people choose the \\$2500 option even though the expected value of the latter is a greater loss than a \\$1000 guaranteed loss. This is known as \"loss aversion\". Behavioral economists now study these patterns and try to identify ways humans deviate from those axioms normally assumed to constitute \"rational\" behavior. \nHere, I assume it is rational to prefer the least expected loss.  </p>\n\n<p>I was wondering if statisticians have identified common patterns in data collection that yield biased results in how people interpret data. If there was essentially a \"rational\" way to collect data, I assume there are examples where humans deviate from this and exhibit \"bias\". If so, <strong>what are the most common biases humans make when collecting or interpreting data?</strong></p>\n", "pids": ["55a6426e65ce054aad61ed22"], "flag": 1}
{"question": "How to do logistic regression in R when outcome is fractional (a ratio of two counts)?", "body": "<p>I'm reviewing a paper which has the following biological experiment. A device is used to expose cells to varying amounts of fluid shear stress. As greater shear stress is applied to the cells, more of them start to detach from the substrate. At each level of shear stress, they count the cells that remain attached, and since they know the total number of cells that were attached at the beginning, they can calculate a fractional attachment (or detachment).</p>\n\n<p>If you plot the adherent fraction vs. shear stress, the result is a logistic curve. In theory, each individual cell is a single observation, but obviously there are thousands or tens of thousand of cells, so the data set would be gigantic, if it was set up in the usual way (with each row being an observation).</p>\n\n<p>So, naturally, my question (as stated in the title) should make sense now. How do we do a logistic regression using the fractional outcome as the D.V.? Is there some automatic transform that can be done in glm?</p>\n\n<p>Along the same lines, if there were potentially 3 or more (fractional) measurements, how would one do this for a multinomial logistic regression?</p>\n", "pids": ["53e9bcb3b7602d9704932142"], "flag": 1}
{"question": "Does Telomere length shortening with age actually cause our cells to age and stop functioning properly?", "body": "<p>The human telomere, a simple repeating sequence of six bases, TTAGGG located at the ends of chromosomes <a href=\"https://www.sciencedirect.com/science/article/pii/S0022202X15300506#bb0165\" rel=\"nofollow noreferrer\">(Moyzis et al, 1988)</a> protect them from degeneration, reconstruction, fusion, and loss. It is believed that  this shortening becomes critical for a telomere on a particular chromosome, which becomes unstable and the cell stops dividing.</p>\n<p>Nevertheless, as human dermal fibroblasts of 100-years-old individuals still have a telomere length of 6–7 kb and retain proliferative capacity for about 20 doublings <a href=\"https://www.sciencedirect.com/science/article/pii/S0022202X15300506#bb0015\" rel=\"nofollow noreferrer\">(Allsopp et al, 1992)</a>. They have not reached the limit of their proliferative capacity or of telomere shortening even at such an advanced age. The telomere length of human peripheral blood lymphocytes decreases with age and shortens to about 5 kb in some individuals after age 60 years, but no individuals have been found with a mean telomere length of less than 5 kb, even among 100-years-olds. <a href=\"https://www.sciencedirect.com/science/article/pii/S0022202X15300506#bb0225\" rel=\"nofollow noreferrer\">(Vaziri et al, 1993)</a> <a href=\"https://www.sciencedirect.com/science/article/pii/S0022202X15300506#bb0120\" rel=\"nofollow noreferrer\">(Iwama et al,1998)</a></p>\n<p>Does this Telomere length shortening actually cause our cells to age and malfunction?</p>\n", "pids": ["62fb758490e50fcafd5e0671"], "flag": 1}
{"question": "Satterthwaite vs. Kenward-Roger approximations for the degrees of freedom in mixed models", "body": "<p>The <code>lmerTest</code> package provides an <code>anova()</code> function for linear mixed models with optionally Satterthwaite's (default) or Kenward-Roger's approximation of the degrees of freedom (df). What is the difference between these two approaches? When to choose which?</p>\n", "pids": ["5c0f7bbeda562944ac7b9488"], "flag": 1}
{"question": "Why doesn&#39;t regularization solve Deep Neural Nets hunger for data?", "body": "<p>An issue I've seen frequently brought up in the context of Neural Networks in general, and Deep Neural Networks in particular, is that they're \"data hungry\" - that is they don't perform well unless we have a large data set with which to train the network.</p>\n\n<p>My understanding is that this is due to the fact that NNets, especially Deep NNets, have a large number of degrees of freedom. So as a model, a NNet has a very large number of parameters, and if the number of parameters of the model is large relative to the number of training data points, there is an increased tendency to over fit. </p>\n\n<p>But why isn't this issue solved by regularization? As far as I know NNets can use L1 and L2 regularization and also have their own regularization methods like dropout which can reduce the number of parameters in the network. </p>\n\n<p>Can we choose our regularizations methods such that they enforce parsimony and limit the size of the network? </p>\n\n\n\n<p>To clarify my thinking: Say we are using a large Deep NNet to try to model our data, but the data set is small and could actually be modeled by a linear model. Then why don't the network weights converge in such a way that one neuron simulates the linear regression and all the others converge to zeros? Why doesn't regularization help with this? </p>\n", "pids": ["616809b85244ab9dcb310fad", "58d82fced649053542fd6c31", "573695fd6e3b12023e511078"], "flag": 1}
{"question": "Why would we overexpress Sir2 by overexpressing its hypomorph (dSir2-EP2300) in C. elegans?", "body": "<p>Can't we just overexpress regular Sir2 in the paper? Rather than overexpress a reduced-function gene?</p>\n\n<p>The paper is <a href=\"http://dx.doi.org/10.1038/nature10296\" rel=\"nofollow\"> <strong>Burnett C, Valentini S, Cabreiro F, Goss M, Somogyvári M, Piper MD, Hoddinott M, Sutphin GL, Leko V, McElwee JJ, et al.</strong>. 2011. Absence of effects of Sir2 overexpression on lifespan in C. elegans and Drosophila. Nature 477: 482–5.</a></p>\n", "pids": ["55a4674965ce31bc87796c35"], "flag": 1}
{"question": "Is p-value essentially useless and dangerous to use?", "body": "<p>This article \"<a href=\"http://www.nytimes.com/2014/09/30/science/the-odds-continually-updated.html\" rel=\"noreferrer\">The Odds, Continually Updated\" from NY Times</a> happened to catch my attention. To be short, it states that </p>\n\n<blockquote>\n  <p>[Bayesian statistics] is proving especially useful in approaching complex problems, including searches like the one the Coast Guard used in 2013 to find the missing fisherman, John Aldridge (though not, so far, in the hunt for Malaysia Airlines Flight 370)........, Bayesian statistics are rippling through everything from physics to cancer research, ecology to psychology...</p>\n</blockquote>\n\n<p>In the article, there are also some criticisms about the frequentist's p-value, for example:</p>\n\n<blockquote>\n  <p>Results are usually considered “statistically significant” if the p-value is less than 5 percent. But there is a danger in this tradition, said Andrew Gelman, a statistics professor at Columbia. Even if scientists always did the calculations correctly — and they don’t, he argues — accepting everything with a p-value of 5 percent means that one in 20 “statistically significant” results are nothing but random noise.</p>\n</blockquote>\n\n<p>Besides above, perhaps the most famous paper criticizing p-value is this one - <a href=\"http://www.nature.com/news/scientific-method-statistical-errors-1.14700\" rel=\"noreferrer\">\"Scientific method: Statistical errors\" by Regina Nuzzo from Nature</a>, in which a lot of scientific issues raised by p-value approach has been discussed, like reproducibility concerns, p-value hacking, etc.</p>\n\n<blockquote>\n  <p>P values, the 'gold standard' of statistical validity, are not as reliable as many scientists assume. ...... Perhaps the worst fallacy is the kind of self-deception for which psychologist Uri Simonsohn of the University of Pennsylvania and his colleagues have popularized the term P-hacking; it is also known as data-dredging, snooping, fishing, significance-chasing and double-dipping. “P-hacking,” says Simonsohn, “is trying multiple things until you get the desired result” — even unconsciously. ...... “That finding seems to have been obtained through p-hacking, the authors dropped one of the conditions so that the overall p-value would be less than .05”, and “She is a p-hacker, she always monitors data while it is being collected.”</p>\n</blockquote>\n\n<p>Another thing is an interesting plot as following from <a href=\"http://www.johnmyleswhite.com/notebook/2012/07/17/criticism-5-of-nhst-p-values-measure-effort-not-truth/\" rel=\"noreferrer\">here</a>, with the comment about the plot:</p>\n\n<blockquote>\n  <p>No matter how small your effect may be, you can always do the hard work of gathering data in order to pass the threshold of p &lt; .05. As long as the effect you're studying isn't non-existent, p-values just measure how much effort you've put into collecting data.</p>\n</blockquote>\n\n<p><a src=\"https://i.stack.imgur.com/FTYxQ.png\" alt=\"enter image description here\"></p>\n\n<p>With all above, my questions are:</p>\n\n<ol>\n<li><p>What does Andrew Gelman's argument, in the second block quote, mean precisely? Why did he interpret 5-percent p-value as \"one in 20 statistically significant results are noting but random noise\"? I am not convinced since to me p-value is used to make inference on one single study. His point seems related to multiple testing. </p>\n\n<p><strong>Update:</strong> Check Andrew Gelman's blog about this: <a href=\"http://andrewgelman.com/2014/09/30/didnt-say/\" rel=\"noreferrer\">No, I didn't say that!</a> (Credits to @Scortchi, @whuber).</p></li>\n<li><p>Given the criticisms about p-value, and also given there are a lot of information criteria, like AIC, BIC, Mallow's $C_p$ for evaluating the significance of a model (hence variables), should we not use p-value for variable selection at all but use those model selection criteria?</p></li>\n<li>Are there any good practical guidances of using p-value for statistical analysis which could lead to more reliable research results?</li>\n<li><p>Would Bayesian modeling framework a better way to pursue, as some statistician advocate? Specifically, would Bayesian approach be more likely to resolve false finding or manipulating the data issues? I am not convinced here as well since the prior is very subjective in Bayesian approach. Are there any practical and well-known studies that show Bayesian approach is better than frequentist's p-value, or at least in some particular cases?</p>\n\n<p><strong>Update:</strong> I would be particularly interested in whether there are cases that Bayesian approach is more reliable than frequentist's p-value approach. By \"reliable\", I mean the Bayesian approach is less likely to manipulate data for desired results. Any suggestions? </p></li>\n</ol>\n\n\n\n<h3>Update 6/9/2015</h3>\n\n<p>Just noticed the news, and thought it would be good to put it here for discussion.</p>\n\n<p><a href=\"http://www.nature.com/news/psychology-journal-bans-p-values-1.17001\" rel=\"noreferrer\">Psychology journal bans P values</a></p>\n\n<blockquote>\n  <p>A controversial statistical test has finally met its end, at least in one journal. Earlier this month, the editors of Basic and Applied Social Psychology (BASP) announced that the journal would no longer publish papers containing P values because the statistics were too often used to support lower-quality research.</p>\n</blockquote>\n\n<p>Along with a recent paper, <a href=\"http://www.nature.com/nmeth/journal/v12/n3/full/nmeth.3288.html\" rel=\"noreferrer\">\"The fickle P value generates irreproducible results\" from Nature</a>, about P value.</p>\n\n<h3>Update 5/8/2016</h3>\n\n<p>Back in March, the American Statistical Association (ASA) released statements on statistical significance and p-values, <strong>\"....The ASA statement is intended to steer research into a ‘post p&lt;0.05 era.’\"</strong></p>\n\n<p>This statement contains 6 principles that address the misuse of the p-value:</p>\n\n<blockquote>\n  <ol>\n  <li>P-values can indicate how incompatible the data are with a specified statistical model.</li>\n  <li>P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random\n  chance alone.</li>\n  <li>Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.</li>\n  <li>Proper inference requires full reporting and transparency.</li>\n  <li>A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.</li>\n  <li>By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.</li>\n  </ol>\n</blockquote>\n\n<p>Details: \n<a href=\"http://amstat.tandfonline.com/doi/abs/10.1080/00031305.2016.1154108\" rel=\"noreferrer\">\"The ASA's statement on p-values: context, process, and purpose\"</a>.</p>\n", "pids": ["55a6bae665ce054aad7311f2"], "flag": 1}
{"question": "Neuroligins, neurexins and synaptic gaps", "body": "<p>Further to <a href=\"https://psychology.stackexchange.com/q/28966/7604\">Are all synapses &quot;gappy&quot;, and what exactly is in the gap?</a>, I found an open access article (<a href=\"https://doi.org/10.1371/journal.pone.0003542\" rel=\"nofollow noreferrer\">Biswas et al. 2008</a>) pointing out that</p>\n<blockquote>\n<p>Vertebrate studies show neuroligins and neurexins are binding partners in a trans-synaptic cell adhesion complex, implicated in human autism and mental retardation disorders.</p>\n</blockquote>\n<p>First of all, I looked more into what neuroligins and neurexins are in the abstract of <a href=\"https://doi.org/10.1016/B978-0-12-823672-7.00008-9\" rel=\"nofollow noreferrer\">https://doi.org/10.1016/B978-0-12-823672-7.00008-9</a> then skimming through the introduction of Biswas et al, the article points out that research implicates</p>\n<blockquote>\n<p>human neuroligins and neurexins in neuro-developmental psychiatric disorders where an imbalance in E/I ratio [excitatory/inhibitory ratio] is thought to occur. Numerous studies have localised mutations to <em>neuroligin 3</em> and <em>4</em> in families affected by autism, Aspergers syndrome and X-linked mental retardation [39]–[42]. The disease mutations in <em>neuroligin 3</em> and <em>4</em> lead to loss of neurexin binding, loss of synaptogenic capability and retention in the endoplasmic reticulum [43], [44]. Recent studies have also identified a high frequency of neurexin structural variants in families affected with autism and schizophrenia [45], [46].</p>\n</blockquote>\n<p>First of all, I'd like to be pointed in the direction of literature (where available) which indicates what neuro-developmental psychiatric disorders there are where an imbalance in E/I ratio is thought to occur.</p>\n<p>Are <a href=\"https://www.cdc.gov/ncbddd/autism/facts.html\" rel=\"nofollow noreferrer\">autism spectrum disorders</a> part of them?</p>\n<p>I am happy to separate the 2 following interrelated queries from this question if it would make the answer too long, but I also wonder, does the E/I imbalance cause the neuro-developmental psychiatric disorders or do the neuro-developmental psychiatric disorders cause the E/I imbalance? If E/I imbalances are involved in autism, is the imbalance towards excitory or inhibitory, and does the imbalance get worse?</p>\n<h2>Reference</h2>\n<p>Biswas, S., Russell, R. J., Jackson, C. J., Vidovic, M., Ganeshina, O., Oakeshott, J. G., &amp; Claudianos, C. (2008). Bridging the synaptic gap: neuroligins and neurexin I in Apis mellifera. <em>Plos one, 3</em>(10), e3542. <a href=\"https://doi.org/10.1371/journal.pone.0003542\" rel=\"nofollow noreferrer\">https://doi.org/10.1371/journal.pone.0003542</a></p>\n", "pids": ["53e9af75b7602d97039b749b", "5c756763f56def9798174938", "562103090cf276a3be15e8a3", "5ee0b1ca9fced0a24b47306c", "55a3826f65ce5cd7b3ad25b1", "56d83d86dabfae2eee6e8335"], "flag": 1}
{"question": "Validity of report of reverse-transcription of Covid-19 vaccine mRNA in cultured human liver tumor-derived cells", "body": "<p>The following paper reports results suggesting that when Huh7 cells (severely karyotypically abnormal immortalized cells derived from a human liver tumor) were incubated with the Pfizer/BioNTech COVID-19 mRNA vaccine BNT162b2 the lipid nanoparticles were taken up. The paper argues that the vaccine mRNA was reverse-transcribed and suggests that the LINE 1-encoded reverse transcriptase activity might be involved.</p>\n<p><a href=\"https://www.mdpi.com/1467-3045/44/3/73\" rel=\"nofollow noreferrer\">Aldén et al. (2022) <em>Curr.Issues Mol. Biol.</em>  <strong>44</strong>, 1115–1126 “Intracellular Reverse Transcription of Pfizer BioNTech COVID-19 mRNA Vaccine BNT162b2 In Vitro in Human Liver Cell Line”</a></p>\n<p>The clinical relevance of these results, if correct, relates to the possibility that the integration of viral cDNA may occur in human liver tissue following administration of the vaccine, that the integrated gene for the virus spike protein may be subsequently expressed and could therefore be responsible for some of the rare side-effects of the vaccine.</p>\n<p>Question: Do the results really indicate reverse-transcription of viral mRNA and integration of the cDNA into the genome of this cell line? If so, to what extent is this relevant to side-effects of the vaccine administered in the clinic.</p>\n<p><em>Footnote</em> <br>\nThe publisher of this journal, MDPI, has been classified as a <a href=\"https://paolocrosetto.wordpress.com/2021/04/12/is-mdpi-a-predatory-publisher/\" rel=\"nofollow noreferrer\">borderline predatory publisher</a> — hence my scepticism — although the subject is far from my field.</p>\n", "pids": ["60b9a6a1e4510cd7c8ff7976", "628d2b205aee126c0f5416ae"], "flag": 1}
{"question": "Internal vs external cross-validation and model selection", "body": "<p>My understanding is that with cross validation and model selection we try to address two things:</p>\n\n<p><strong>P1</strong>. Estimate the expected loss on the population when training with our sample</p>\n\n<p><strong>P2</strong>. Measure and report our uncertainty of this estimation (variance, confidence intervals, bias, etc.)</p>\n\n<p>Standard practice seems to be to do repeated cross validation, since this reduces the variance of our estimator.</p>\n\n<p>However, when it comes to reporting and analysis, my understanding is that <strong>internal validation is better than external validation</strong> because:</p>\n\n<p>It is better to report:</p>\n\n<ul>\n<li>The statistics of our estimator, e.g. its confidence interval, variance, mean, etc. on the full sample (in this case the CV sample). </li>\n</ul>\n\n<p>than reporting: </p>\n\n<ul>\n<li><p>The loss of our estimator on a hold-out subset of the original sample, since:</p>\n\n<p>(i) This would be a <strong>single measurement</strong> (<strong><em>even if we pick our estimator with CV</em></strong>)</p>\n\n<p>(ii) Our estimator for this single measurement would have been trained on a set (e.g. the CV set) that is smaller than our initial sample since we have to make room for the hold-out set. This results in a <strong>more biased</strong> (pessimistic) estimation in <strong>P1</strong> .</p></li>\n</ul>\n\n<p>Is this correct? If not why? </p>\n\n<h3>Background:</h3>\n\n<p>It is easy to find textbooks that recommend dividing your sample into two sets: </p>\n\n<ul>\n<li>The <strong>CV</strong> set, which is subsequently and repeatedly divided into <strong>train</strong> and <strong>validation</strong> sets.</li>\n<li>The <strong>hold-out</strong> (test) set, only used at the end to report the estimator performance</li>\n</ul>\n\n<p>My question is an attempt to understand the merits and advantages of this textbook approach, considering that our goal is to really address the problems <strong>P1</strong> and <strong>P2</strong> at the beginning of this post. It looks to me that reporting on the hold-out test set is <strong>bad practice</strong> since the analysis of the CV sample is more informative.</p>\n\n<h3>Nested K-fold vs repeated K-fold:</h3>\n\n<p>One can in principle combine <strong>hold-out</strong> with regular <strong>K-fold</strong> to obtain  <strong>nested K-fold</strong>. This would allow us to measure the variability of our estimator, but it looks to me that for the same number of total models trained (total # of folds) repeated K-fold would yield estimators that are <strong>less biased</strong> and <strong>more accurate</strong> than nested K-fold. To see this:</p>\n\n<ul>\n<li>Repeated K-fold uses a larger fraction of our total sample than nested K-fold for the same K (i.e. it leads to lower bias)</li>\n<li>100 iterations would only give 10 measurements of our estimator in nested K-fold (K=10), but 100 measurements in K-fold (more measurements leads to lower variance in <strong>P2</strong>)</li>\n</ul>\n\n<p>What's wrong with this reasoning?</p>\n", "pids": ["53e99db8b7602d9702679800"], "flag": 1}
{"question": "Assumptions of linear models and what to do if the residuals are not normally distributed", "body": "<p>I am a little bit confused on what the assumptions of linear regression are.</p>\n<p>So far I checked whether:</p>\n<ul>\n<li>all of the explanatory variables correlated linearly with the response variable. (This was the case)</li>\n<li>there was any collinearity among the explanatory variables. (there was little collinearity).</li>\n<li>the Cook's distances of the datapoints of my model are below 1 (this is the case, all distances are below 0.4, so no influence points).</li>\n<li>the residuals are normally distributed. (this may not be the case)</li>\n</ul>\n<p>But I then read the following:</p>\n<blockquote>\n<p>violations of normality often arise either because (a) the\ndistributions of the dependent and/or independent variables are\nthemselves significantly non-normal, and/or (b) the linearity\nassumption is violated.</p>\n</blockquote>\n<p><strong>Question 1</strong>\nThis makes it sound as if the independent and depend variables need to be normally distributed, but as far as I know this is not the case. My dependent variable as well as one of my independent variables are not normally distributed. Should they be?</p>\n<p><strong>Question 2</strong>\nMy QQnormal plot of the residuals look like this:</p>\n<p><a href=\"https://i.stack.imgur.com/HRCT9.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/HRCT9.png\" alt=\"normality check of residuals\" /></a></p>\n\n<p>That slightly differs from a normal distribution and the <code>shapiro.test</code> also rejects the null hypothesis that the residuals are from a normal distribution:</p>\n<pre class=\"lang-r prettyprint-override\"><code>&gt; shapiro.test(residuals(lmresult))\nW = 0.9171, p-value = 3.618e-06\n</code></pre>\n<p>The residuals vs fitted values look like:</p>\n<p><a href=\"https://i.stack.imgur.com/AggXg.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/AggXg.png\" alt=\"residuals vs fitted\" /></a></p>\n\n<p>What can I do if my residuals are not normally distributed? Does it mean the linear model is entirely useless?</p>\n", "pids": ["5c0f7329da562944ac682374"], "flag": 1}
{"question": "Origin of &quot;5$\\sigma$&quot; threshold for accepting evidence in particle physics?", "body": "<p>News reports say that CERN <a href=\"http://www.extremetech.com/extreme/132256-cern-expected-to-announce-higgs-boson-discovery-tomorrow-morning\">will announce tomorrow</a> that the Higgs boson has been experimentally detected with 5$\\sigma$ evidence. According to that article:</p>\n\n<blockquote>\n  <p>5$\\sigma$ equates to a 99.99994% chance that the data the CMS and ATLAS\n  detectors are seeing aren’t just random noise — and a 0.00006% chance\n  that they’ve been hoodwinked; 5$\\sigma$ is the necessary certainty for\n  something to be officially labeled a scientific “discovery.”</p>\n</blockquote>\n\n<p>This isn't super rigorous, but it seems to say that physicists use standard \"hypothesis testing\" statistical methodology, setting $\\alpha$ to $0.0000006$, which corresponds to $z=5$ (two-tailed)?  Or is there some other meaning? </p>\n\n<p>In much of science, of course, setting alpha to 0.05 is done routinely. This would be equivalent to \"two-$\\sigma$\" evidence, although I've never heard of it being called that. Are there other fields (besides particle physics) where a much stricter definition of alpha is standard? Anyone know a reference for how the five-$\\sigma$ rule got accepted by particle physics?</p>\n\n<p><strong>Update:</strong> I'm asking this question for a simple reason. My book <a href=\"http://rads.stackoverflow.com/amzn/click/0199730067\">Intuitive Biostatistics</a> (like most stats books) has a section that explains how arbitrary the usual \"P&lt;0.05\" rule is. I'd like to add this example of a scientific field where a much (much!) smaller value of $\\alpha$ is considered necessary. But if the example is actually more complicated, with use of Bayesian methods (as some comments below suggest), then it wouldn't be quite apt or would require a lot more explanation. </p>\n", "pids": ["56d841dcdabfae2eee8ed438", "62181f055aee126c0fe35f52", "56d8a220dabfae2eee6d4339", "56d92622dabfae2eeebc1d93"], "flag": 1}
{"question": "Pre-training in deep convolutional neural network?", "body": "<p>Have anyone seen any literature on pre-training in deep convolutional neural network? I have only seen unsupervised pre-training in autoencoder or restricted boltzman machines.</p>\n", "pids": ["573696f46e3b12023e5f0d4d", "573696026e3b12023e5163bc"], "flag": 1}
{"question": "Why are Chromosome Territories important?", "body": "<p>Chromosomes occupy discrete regions of the nucleus, referred to as 'Chromosome Territories'. This spatial organization is emerging as a crucial aspect of <strong>gene regulation and genome stability in health and disease</strong>.</p>\n<p><a href=\"https://i.stack.imgur.com/mJTxu.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/mJTxu.jpg\" alt=\"enter image description here\" /></a></p>\n<p>But how is this the case <a href=\"https://en.wikipedia.org/wiki/Chromosome_territories\" rel=\"nofollow noreferrer\">when:</a></p>\n<blockquote>\n<p><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2829961/\" rel=\"nofollow noreferrer\">Most eukaryotes</a> seem to have Chromosome Territories, <strong>but yeast <em>S.\ncerevisiae</em> is an exception to this</strong>.</p>\n</blockquote>\n<p>So if some eukaryotes do, and some do not, what information do Chromosome Territories provide? Some literature uses the phrase '<a href=\"https://cshperspectives.cshlp.org/content/2/3/a003889\" rel=\"nofollow noreferrer\">non-random chromosome territory arrangements</a>'. Thus, I am confused.</p>\n<p>Chromosome territories are randomly arranged in some eukaryotes.</p>\n<p>How are chromosome territories crucial for <strong>gene regulation and genome stability in health and disease</strong> in some  eukaryotes, but <strong>random</strong> in other eukaryotes?</p>\n", "pids": ["5c0f7df5da562944ac80d7f1"], "flag": 1}
{"question": "Should training samples randomly drawn for mini-batch training neural nets be drawn without replacement?", "body": "<p>We define an epoch as having gone through the entirety of all available training samples, and the mini-batch size as the number of samples over which we average to find the updates to weights/biases needed to descend the gradient.</p>\n\n<p>My question is whether we should draw without replacement from the set of training examples in order to generate each mini-batch within an epoch. I feel like we should avoid replacement to ensure we actually \"draw all the samples\" to meet the end-of-epoch requirement, but am having trouble finding a definitive answer one way or another.</p>\n\n<p>I've tried googling and reading Ch. 1 of Nielsen's <em>Neural Networks and Deep Learning</em> but have not found a clear answer. In that text Nielsen does not specify that the random sampling be done without replacement, but seems to imply that it is.</p>\n\n<p>A clearer formalization of training in epochs can be found here if desired - <a href=\"https://stats.stackexchange.com/a/141265/131630\">https://stats.stackexchange.com/a/141265/131630</a></p>\n\n<p>Edit: this question seemed similar to me but it was unclear how to apply the fact that linearity of expectation is indifferent to independence to this situation - <a href=\"https://stats.stackexchange.com/questions/96533/should-sampling-happen-with-or-without-replacement\">Should sampling happen with or without replacement</a></p>\n", "pids": ["56d86d97dabfae2eeedaafae"], "flag": 1}
{"question": "What generates variation in a species?", "body": "<p>What is the biological mechanism behind the variation within sexually reproducing species? Obviously, the children are combinations, to differing degrees, of their parents. But how does the variation originate in the parents to begin with?</p>\n\n<p>I'm not referring to evolution or mutations rather I have in mind things like facial structure and personality in humans, or fur coloring in dogs. I just thought I vaguely remembered there was some kind of driver of variation... For example, does the parent produce a variety of germ cells that purposely differ from the parent's geneome?</p>\n\n<p>I just think I'm missing something here.</p>\n\n<p>(I'm familiar with DNA and genetics having taken a biology class in college and remembering much of it, I just can't seem to put my finger on this point...)</p>\n", "pids": ["53e9a8aab7602d97031fa555"], "flag": 1}
{"question": "Reaction mechanism and substrate interaction of dopamine beta-hydroxylase", "body": "<p>The reaction in which dopamine beta-hydroxylase catalyses the conversion of dopamine to norepinephrine is shown below. Dopamine hydroxylase is an enzyme, so I'm not sure if we can have a theory based on organic chemistry. On the other hand, maybe there is a theory that involves structural biology?</p>\n<p>Evolutionarily speaking - the enzyme has evolved to add OH to the beta-carbon rather than somewhere else. I'm really wondering <em>what</em> in the enzyme's shape makes the OH added to the beta carbon, rather than somewhere else. In other words, what is the structural mechanism behind substrate specificity?</p>\n<p><a src=\"https://i.stack.imgur.com/EuR7O.png\" alt=\"Reaction pathway of tyrosine oxidation to epinephrine\" /></p>\n", "pids": ["63bfb77c90e50fcafdbfed6e"], "flag": 1}
{"question": "How to perform isometric log-ratio transformation", "body": "<p>I have data on movement behaviours (time spent sleeping, sedentary, and doing physical activity) that sums to approximately 24 (as in hours per day). I want to create a variable that captures the relative time spent in each of these behaviours - I've been told that an isometric log-ratio transformation would accomplish this. </p>\n\n<p>It looks like I should use the ilr function in R, but can't find any actual examples with code. Where do I start?</p>\n\n<p>The variables I have are time spent sleeping, average sedentary time, average average light physical activity, average moderate physical activity, and average vigorous physical activity. Sleep was self-reported, while the others are averages from valid days of accelerometer data. So for these variables, cases do not sum to exactly 24. </p>\n\n<p>My guess:\nI'm working in SAS, but it looks like R will be much easier to use for this part. So first import data with only the variables of interest. \nThen use acomp() function. Then I can't figure out the syntax for the ilr() function. Any help would be much appreciated. </p>\n", "pids": ["56d850e0dabfae2eee01c8a7"], "flag": 1}
{"question": "Are there any known consequences of the right-handedness of the DNA double helix?", "body": "<p>In <a href=\"https://www.knowablemagazine.org/article/living-world/2020/how-do-bodies-map-out-left-and-right\" rel=\"noreferrer\">this</a> article it is suggested (without evidence) that the right-handedness of DNA may be the cause that <em>\"kick[s] off asymmetry in the early embryo [of snails]\".</em> </p>\n\n<p>On the one hand we know that symmetry breaking in an organism's development happens at multiple levels, from molecular to larger structural levels (see <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2829966/\" rel=\"noreferrer\">this</a>). On the other hand we also know that right-handed DNA double helix does have many notably distinct properties from their left-handed cousins (see <a href=\"https://www.ch.imperial.ac.uk/rzepa/blog/?p=3326\" rel=\"noreferrer\">this</a>). Are there any visible macroscopic asymmetries in some organisms that are known to be ultimately traceable back to DNA's handedness? More generally, what could be some consequences of the right-handedness of DNA double helix?     </p>\n", "pids": ["53e9b002b7602d9703a5a321", "53e9a423b7602d9702d3eb54", "53e99ec4b7602d970278d3d7", "53e9aa02b7602d9703370a5a", "5ce3af2cced107d4c65f1e4d", "53e9b8e8b7602d97044ca254"], "flag": 1}
{"question": "Why are bias nodes used in neural networks?", "body": "<ol>\n<li>Why are bias nodes used in neural networks? </li>\n<li>How many you should use? </li>\n<li>In which layers you should use them: all hidden layers and the output layer?</li>\n</ol>\n", "pids": ["59ae3be32bbe271c4c71b7b4", "573696ce6e3b12023e5ce95a"], "flag": 1}
{"question": "Mathematical differences between GBM, XGBoost, LightGBM, CatBoost?", "body": "<p>There exist several implementations of the GBDT family of model such as:</p>\n\n<ul>\n<li>GBM</li>\n<li>XGBoost</li>\n<li>LightGBM</li>\n<li>Catboost. </li>\n</ul>\n\n<p>What are the <strong>mathematical</strong> differences between these different implementations?</p>\n\n<p>Catboost seems to outperform the other implementations even by using only its default parameters according to <a href=\"https://catboost.yandex/#benchmark\" rel=\"noreferrer\">this bench mark</a>, but it is still very slow.</p>\n\n<p>My guess is that catboost doesn't use the dummified variables, so the weight given to each (categorical) variable is more balanced compared to the other implementations, so the high-cardinality variables don't have more weight than the others. It allows the weak categorical (with low cardinality) to enter to some trees, hence better performance. Other than that, I have no further explanation. </p>\n", "pids": ["573696046e3b12023e517cb1", "5f817800c6c3b86a50617c27"], "flag": 1}
{"question": "Good sources for learning Markov chain Monte Carlo (MCMC)", "body": "<p>Any suggestions for a good source to learn MCMC methods?</p>\n", "pids": ["53e9a3a5b7602d9702cb46d9"], "flag": 1}
{"question": "Do hot drinks cool you down?", "body": "<p>It is quite the old wives tale that drinking a hot drink cools you down. If you don't really think about it it does seem somewhat logical: increasing temperature will cause your body to try and cool down faster. This is of course flawed by the fact that you have increased your temperature before cooling it back down again.</p>\n\n<p>I have had a bit of a look, but have been unable to find any evidence that addresses the fact that drinking a hit drink may make you <em>feel</em> cooler after sweating a little bit, rather than actually changing anything about your net temperature. Basically, is the 'cool down' just the placebo effect (you feel cooler because you think you feel cooler), or is there any evidence for a 'real' effect of hot drinks cooling you down? Or is there evidence that hot drinks do nothing at all except heat you up a bit before you come right back to the same temperature?</p>\n", "pids": ["55a41cd2c91b587b096d2535"], "flag": 1}
{"question": "What is difference between &#39;transfer learning&#39; and &#39;domain adaptation&#39;?", "body": "<p>Is there any difference between 'transfer learning' and 'domain adaptation'?</p>\n\n<p>I don't know about context, but my understanding is that we have some dataset 1 and train on it, after which we have another dataset 2 for which we want to adapt our model without retraining from scratch, for which 'transfer learning' and 'domain adaptation' help solve this problem.</p>\n\n<p>According to the field of Convolutional Neural Networks:</p>\n\n<ul>\n<li><p>By 'transfer learning' I mean 'finetuning' <a href=\"http://cs231n.github.io/transfer-learning/\" rel=\"noreferrer\">[1]</a></p></li>\n<li><p>In this case <a href=\"http://jmlr.org/proceedings/papers/v37/ganin15.pdf\" rel=\"noreferrer\">[2]</a> it's unsupervised, but should 'domain adaptation' always be unsupervised?</p></li>\n</ul>\n", "pids": ["5cede073da56298378851a0d"], "flag": 1}
{"question": "Extrapolation v. Interpolation", "body": "<p>What is the difference between extrapolation and interpolation, and what is the most precise way of using these terms?</p>\n\n<p>For example, I have seen a statement in a paper using interpolation as:</p>\n\n<blockquote>\n  <p>\"The procedure interpolates the shape of the estimated function between the bin points\"</p>\n</blockquote>\n\n<p>A sentence that uses both extrapolation and interpolation is, for example:</p>\n\n<blockquote>\n  <p>The previous step where we extrapolated the interpolated function using the Kernel method to the left and right temperature tails.</p>\n</blockquote>\n\n<p>Can someone provide a clear and easy way to distinguish them and guide how to use these terms correctly with an example?</p>\n", "pids": ["5b3d98cc17c44a510f801cb2"], "flag": 1}
{"question": "How to make a reward function in reinforcement learning?", "body": "<p>While studying Reinforcement Learning, I have come across many forms of the reward function: <span class=\"math-container\">$R(s,a)$</span>, <span class=\"math-container\">$R(s,a,s')$</span>, and even a reward function that only depends on the current state. Having said that, I realized it is not very easy to 'make' or 'define' a reward function.</p>\n<p>Here are my questions:</p>\n<ol>\n<li>Are there rules on how to make reward functions?</li>\n<li>Are there other forms of the reward function? For example, a polynomial form perhaps that depends on the state?</li>\n</ol>\n", "pids": ["53e99bdcb7602d9702488d00"], "flag": 1}
{"question": "Difference In Telomeres Between A Thale Cress Plant And A Methuselah Tree", "body": "<p>From what I have read and understood telomeres cap off how many times a cell can divide before it can no longer divide and that is what causes aging.</p>\n\n<p>A <a href=\"https://en.wikipedia.org/wiki/Arabidopsis_thaliana\" rel=\"nofollow\">thale cress plant</a> apparently has a life cycle of 6 weeks before it dies, while the <a href=\"https://en.wikipedia.org/wiki/Methuselah_%28tree%29\" rel=\"nofollow\">Methuselah tree</a> has set the record at over 4,800+ years.</p>\n\n<ul>\n<li>What is the difference between these two plants regarding their telomeres?</li>\n<li>Is the cell division rate different between both plants instead of a telomeres difference?</li>\n<li>If given ideal conditions what could the potential life-span of a Methuselah tree be?</li>\n</ul>\n\n<p><em>Btw you don't have to answer all these. Just curious and looking for some insight into why the stark difference between both plants' aging.</em></p>\n", "pids": ["55a3d6ba65ce5cd7b3b97b4b"], "flag": 1}
{"question": "How to determine the confidence of a neural network prediction?", "body": "<p>To illustrate my question, suppose that I have a training set where the input has a degree of noise but the output does not, for example;</p>\n\n<pre><code># Training data\n[1.02, 1.95, 2.01, 3.06] : [1.0]\n[2.03, 4.11, 5.92, 8.00] : [2.0]\n[10.01, 11.02, 11.96, 12.04] : [1.0]\n[2.99, 6.06, 9.01, 12.10] : [3.0]\n</code></pre>\n\n<p>here the output is the gradient of the input array if it were noiseless (not the actual gradient).</p>\n\n<p>After training the network, the output should look something like this for a given input.</p>\n\n<pre><code># Expected Output\n[1.01, 1.96, 2.00, 3.06] : 95% confidence interval of [0.97, 1.03]\n[2.03, 4.11, 3.89, 3.51] : 95% confidence interval of [2.30, 4.12]\n</code></pre>\n\n<p>My question is how can a neural network be created such that it will return a predicted value and a measure of confidence, such as a variance or confidence interval?</p>\n", "pids": ["5ef876df91e0115941835ac2", "5b67b47917c44aac1c86383e", "573696006e3b12023e513cb6", "573696006e3b12023e513cb6"], "flag": 1}
{"question": "Why are lower p-values not more evidence against the null? Arguments from Johansson 2011", "body": "<p>Johansson (2011) in \"<a href=\"http://www3.nd.edu/~sjones20/JonesUND/BioStats_files/HailTheImpossible.pdf\">Hail the impossible: p-values, evidence, and likelihood</a>\" (here is also <a href=\"http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9450.2010.00852.x/abstract?deniedAccessCustomisedMessage=&amp;userIsAuthenticated=true\">link to the journal</a>) states that lower $p$-values are often considered as stronger evidence against the null. Johansson implies that people would consider evidence against the null to be stronger if their statistical test outputted a $p$-value of $0.01$, than if their statistical test outputted a $p$-value of $0.45$. Johansson lists four reasons why the $p$-value cannot be used as evidence against the null:</p>\n\n<blockquote>\n  <ol>\n  <li>$p$ is uniformly distributed under the null hypothesis and can therefore never indicate evidence for the null. </li>\n  <li>$p$ is conditioned solely on the null hypothesis and is therefore unsuited to quantify evidence, because evidence is always\n  relative in the sense of being evidence for or against a hypothesis\n  relative to another hypothesis.</li>\n  <li>$p$ designates probability of obtaining evidence (given the null), rather than strength of evidence.</li>\n  <li>$p$ depends on unobserved data and subjective intentions and therefore implies, given the evidential interpretation, that the\n  evidential strength of observed data depends on things that did not\n  happen and subjective intentions.</li>\n  </ol>\n</blockquote>\n\n<p>Unfortunately I cannot get an intuitive understanding from Johansson's article. To me a $p$-value of $0.01$ indicates there is less chance the null is true, than a $p$-value of $0.45$. Why are lower $p$-values not stronger evidence against null?  </p>\n", "pids": ["56d8701adabfae2eeeedcba5"], "flag": 1}
{"question": "How does batch size affect convergence of SGD and why?", "body": "<p>I've seen similar conclusion from many discussions, that as the minibatch size gets larger the convergence of SGD actually gets harder/worse, for example <a href=\"https://research.fb.com/publications/accurate-large-minibatch-sgd-training-imagenet-in-1-hour/\" rel=\"noreferrer\">this paper</a> and <a href=\"https://stats.stackexchange.com/a/236393/95569\">this answer</a>. Also I've heard of people using tricks like small learning rates or batch sizes in the early stage to address this difficulty with large batch sizes.</p>\n\n<p>However it seems counter-intuitive as the average loss of a minibatch can be thought of as an approximation to the expected loss over the data distribution,\n<span class=\"math-container\">$$\\frac{1}{|X|}\\sum_{x\\in X} l(x,w)\\approx E_{x\\sim p_{data}}[l(x,w)]$$</span>\nthe larger the batch size the more accurate it's supposed to be. Why in practice is it not the case?</p>\n\n\n\n<p>Here are some of my (probably wrong) thoughts that try to explain.</p>\n\n<p>The parameters of the model highly depend on each other, when the batch gets too large it will affect too many parameters at once, such that its hard for the parameters to reach a stable inherent dependency? (like the internal covariate shift problem mentioned in the <a href=\"https://arxiv.org/abs/1502.03167\" rel=\"noreferrer\">batch normalization paper</a>) </p>\n\n<p>Or when nearly all the parameters are responsible in every iteration they will tend to learn redundant implicit patterns hence reduces the capacity of the model? (I mean say for digit classification problems some patterns should be responsible for dots, some for edges, but when this happens every pattern tries to be responsible for all shapes).</p>\n\n<p>Or is it because the when the batches size gets closer to the scale of the training set, the minibatches can no longer be seen as i.i.d from the data distribution, as there will be a large probability for correlated minibatches?</p>\n\n\n\n<p><strong>Update</strong><br>\nAs pointed out in Benoit Sanchez's answer one important reason is that large minibatches require more computation to complete one update, and most of the analyses use a fix amount of training epochs for comparison.</p>\n\n<p>However <a href=\"https://pdfs.semanticscholar.org/43c9/6ccaa90b3875ce2912063b9949716f8d5824.pdf\" rel=\"noreferrer\">this paper</a> (Wilson and Martinez, 2003) shows that a larger batch size is still slightly disadvantageous even given enough amount of training epochs. Is that generally the case?\n<a href=\"https://i.stack.imgur.com/BAq9x.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/BAq9x.png\" alt=\"enter image description here\"></a></p>\n", "pids": ["58d82fced649053542fd6ec6", "58437725ac44360f1082fb93", "5c890edd4895d9cbc6ac47d1", "5a260c8617c44a4ba8a322e3"], "flag": 1}
{"question": "What do confidence intervals say about precision (if anything)?", "body": "<p>Morey et al (2015) argue that confidence intervals are misleading and there are multiple bias related to understanding of them. Among others, they describe the precision fallacy as following:</p>\n\n<blockquote>\n  <p><strong><em>The Precision fallacy</em></strong><br>\n  <em>The width of a confidence interval indicates the\n  precision of our knowledge about the parameter. Narrow confidence\n  intervals show precise knowledge, while wide confidence errors show\n  imprecise knowledge.</em></p>\n  \n  <p>There is no necessary connection between the precision of an estimate\n  and the size of a confidence interval. One way to see this is to\n  imagine two researchers — a senior researcher and a PhD student — are\n  analyzing data of $50$ participants from an experiment. As an exercise\n  for the PhD student's benefit, the senior researcher decides to\n  randomly divide the participants into two sets of $25$ so that they can\n  each separately analyze half the data set. In a subsequent meeting,\n  the two share with one another their Student's $t$ confidence intervals\n  for the mean. The PhD student's $95\\%$ CI is $52 \\pm 2$, and the senior\n  researcher's $95\\%$ CI is $53 \\pm 4$.</p>\n  \n  <p>The senior researcher notes that their results are broadly\n  consistent, and that they could use the equally-weighted mean of their\n  two respective point estimates, $52.5$, as an overall estimate of the\n  true mean.</p>\n  \n  <p>The PhD student, however, argues that their two means should not be\n  evenly weighted: she notes that her CI is half as wide and argues that\n  her estimate is more precise and should thus be weighted more heavily.\n  Her advisor notes that this cannot be correct, because the estimate\n  from unevenly weighting the two means would be different from the\n  estimate from analyzing the complete data set, which must be $52.5$. The\n  PhD student's mistake is assuming that CIs directly indicate post-data\n  precision.</p>\n</blockquote>\n\n<p>The example above seems to be misleading. If we randomly divide a sample in half, into two samples, then we would expect both sample means and standard errors to be close. In such case there should not be any difference between using weighted mean (e.g. weighted by inverse errors) and using simple arithmetic mean. However if the estimates differ and errors in one of the samples is noticeably larger, this could suggest \"issues\" with such sample.</p>\n\n<p>Obviously, in the above example, the sample sizes are the same so \"joining back\" the data by taking mean of the means is the same as taking mean of the whole sample. The problem is that the whole example follows the ill-defined logic that the sample is first divided in parts, then to be joined back again for the final estimate.</p>\n\n<p>The example can be re-phrased to lead to exactly the opposite conclusion:</p>\n\n<blockquote>\n  <p>The researcher and the student decided to split their dataset in two\n  halves and to analyze them independently. Afterwards, they compared\n  their estimates and it appeared that the sample means that they calculated\n  were very different, moreover standard error of student's estimate was\n  much greater. The student was afraid that this could suggest issues with\n  precision of his estimate, but the researcher implied that there\n  is no connection between confidence intervals and precision, so both\n  of the estimates are equally trustworthy and they can publish any one\n  of them, chosen randomly, as their final estimate.</p>\n</blockquote>\n\n<p>Stating it more formally, \"standard\" confidence intervals, like the Student's $t$, are based on errors</p>\n\n<p>$$ \\bar x \\pm c \\times \\mathrm{SE}(x) $$</p>\n\n<p>where $c$ is some constant. In such case, they are <em>directly</em> related to the precision, aren't they..?</p>\n\n<p>So my question is:<br>\n<strong><em>Is the precision fallacy really a fallacy? What do confidence intervals say about precision?</em></strong></p>\n\n\n\n<p>Morey, R., Hoekstra, R., Rouder, J., Lee, M., &amp; Wagenmakers, E.-J. (2015). The fallacy of placing confidence in confidence intervals. Psychonomic Bulletin &amp; Review, 1–21. <a href=\"https://learnbayes.org/papers/confidenceIntervalsFallacy/\">https://learnbayes.org/papers/confidenceIntervalsFallacy/</a></p>\n", "pids": ["56d8d34adabfae2eeeb63353"], "flag": 1}
{"question": "Cell proliferation limit and senescence of embryonic stem cells and fibroblasts", "body": "<p>I am trying to understand the importance of proliferation limits and cell senescence. In particular, I would like to compare the proliferation limit of Embryonic Stem cells (ES) and fibroblasts (which would be trans-differentiated) and describe how this difference plays a role when thinking about engineering organs, for example a heart transplant.</p>\n\n<p>How do ES cells and fibroblasts compare with regards to the Hayflick limit?</p>\n", "pids": ["55a4c734c91bf3b1cc466263"], "flag": 1}
{"question": "Is copy number variation dynamic?", "body": "<p>Is there any evidence showing that copy number variation changes over time? I'm wanting to model interactions in expression level as a dynamic bayesian network, but an assumption my approach will need to make is that it is static.</p>\n", "pids": ["53e9a37ab7602d9702c88221"], "flag": 1}
{"question": "Modelling longitudinal data where the effect of time varies in functional form between individuals", "body": "<p><strong>Context</strong>:</p>\n\n<p>Imagine you had a longitudinal study which measured a dependent variable (DV) once a week for 20 weeks on 200 participants. Although I'm interested in general, typical DVs that I'm thinking of include job performance following hire or various well-being measures following a clinical psychology intervention.</p>\n\n<p>I know that multilevel modelling can be used to model the relationship between time and the DV. You can also allow coefficients (e.g., intercepts, slopes, etc.) to vary between individuals and estimate the particular values for participants. But what if when visually inspecting the data you find that the relationship between time and the DV is any one of the following:</p>\n\n<ul>\n<li>different in functional form (perhaps some are linear and others are exponential or some have a discontinuity)</li>\n<li>different in error variance (some individuals are more volatile from one time point to the next)</li>\n</ul>\n\n<p><strong>Questions</strong>:</p>\n\n<ul>\n<li>What would be a good way to approach modelling data like this? </li>\n<li>Specifically, what approaches are good at identifying different types of relationships, and categorising individuals with regards to their type?</li>\n<li>What implementations exist in R for such analyses?</li>\n<li>Are there any references on how to do this: textbook or actual application?</li>\n</ul>\n", "pids": ["53e9b7c0b7602d970436a595", "53e9ba0bb7602d970460c089"], "flag": 1}
{"question": "Convolutional Layers: To pad or not to pad?", "body": "<p>AlexNet architecture uses zero-paddings as shown in the pic. However, there is no explanation in the paper why this padding is introduced.</p>\n<p><a href=\"https://i.stack.imgur.com/oJVjf.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/oJVjf.png\" alt=\"enter image description here\" /></a></p>\n<p>Standford CS 231n course teaches we use padding to preserve the spatial size:\n<a href=\"https://i.stack.imgur.com/dtybe.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/dtybe.png\" alt=\"enter image description here\" /></a></p>\n<p><strong>I am curious if that is  the only reason for zero padding?\nCan anyone explain the rationale behind zero padding? Thanks!</strong></p>\n<p><strong>Reason I am asking</strong></p>\n<p>Let's say I don't need to preserve the spatial size. Can I just remove padding then w/o loss of performance? I know it results in very fast decrease in spatial size as we go to deeper layers, but I can trade-off that by removing pooling layers as well.</p>\n", "pids": ["57a4e91dac44365e35c981bb", "573696026e3b12023e515eec", "5f7c572991e0117ac2a78c3b"], "flag": 1}
{"question": "Should final (production ready) model be trained on complete data or just on training set?", "body": "<p>Suppose I trained several models on training set, choose best one using cross validation set and measured performance on test set. So now I have one final best model. Should I retrain it on my all available data or ship solution trained only on training set? If latter, then why?</p>\n\n<p>UPDATE:\nAs @P.Windridge noted, shipping a retrained model basically means shipping a model without validation. But we can report test set performance and after that retrain the model on complete data righteously expecting the performance to be better - because we use our best model plus more data. What problems may arise from such methodology?</p>\n", "pids": ["5fa9147a91e011e83f7407b4"], "flag": 1}
{"question": "Modern reference for Kropotkin&#39;s lazy bees", "body": "<p>I have been reading through Peter Kropotkin's <em><a href=\"http://en.wikipedia.org/wiki/Mutual_Aid%3a_A_Factor_of_Evolution\">Mutual Aid: A Factor of Evolution</a></em> and he mentions a curious fact about bees (bolding by me for emphasis):</p>\n\n<blockquote>\n  <p>predatory instincts and <strong>laziness continue to exist among the bees</strong> as well, and reappear each. time that their growth is favoured by some circumstances. It is well known that there always are a <strong>number of bees which prefer a life of robbery to the laborious life of a worker</strong>; and that <strong>both periods of scarcity and periods of an unusually rich \n  supply of food</strong> lead to an increase of the robbing class. When our crops are in and there remains but little to gather in our meadows and fields, robbing bees become of more frequent occurrence; while, on the other side, about the sugar plantations of the West Indies and the sugar refineries of Europe, robbery, laziness, and very often drunkenness become quite usual with the bees. We thus see that <strong>anti-social instincts continue to exist amidst the bees as well</strong>;</p>\n</blockquote>\n\n<p>He does not provide a citation for this (and even if he did, it would be something from the late 1800s). <strong>Is there a good modern reference for the above behavior?</strong></p>\n\n<p>I would in particular be interested in something like a graph of %-robber-bees vs. plentiness-of-food (in some abstract measure of the latter) so that I could intuitively see the increase in lazy/robber bees as the environment is low on food, or as it is overly abundant and compare it to 'typical levels'.</p>\n\n<p>Theories that explain this behavior are of interest, as well, but <strong>I am primarily after experimental measures/observations to support and quantify the above quote</strong>.</p>\n", "pids": ["53e9b81cb7602d97043d0393", "53e9a2e4b7602d9702bebcb7", "53e9b2b8b7602d9703d60501"], "flag": 1}
{"question": "Data &quot;exploration&quot; vs data &quot;snooping&quot;/&quot;torturing&quot;?", "body": "<p>Many times I have come across informal warnings against \"data snooping\" (here's <a href=\"http://goo.gl/mVVNV4\">one amusing example</a>), and I think I have an intuitive idea of roughly what that means, and why it may be a problem.</p>\n\n<p>On the other hand, \"exploratory data analysis\" seems to be a perfectly respectable procedure in statistics, at least judging by the fact that a <a href=\"http://books.google.com/books/about/Exploratory_Data_Analysis.html?id=UT9dAAAAIAAJ\">book</a> with that title is still reverentially cited as a classic.</p>\n\n<p>In my line of work I often come across what looks to me like rampant \"data snooping\", or perhaps it would be better described as \"data <a href=\"http://en.wikipedia.org/wiki/Ronald_Coase#Quotations\">torture</a>\", though those doing it seem to see the same activity as entirely reasonable and unproblematic \"exploration\".</p>\n\n<p>Here's the typical scenario: costly experiment gets carried out (without much thought given to the subsequent analysis), the original researchers cannot readily discern a \"story\" in the gathered data, someone gets brought in to apply some \"statistical wizardry\", and who, after <em>slicing and dicing</em> the data every which way, finally manages to extract some publishable \"story\" from it.</p>\n\n<p>Of course, there's usually some \"validation\" thrown in the final report/paper to show that the statistical analysis is on the up-and-up, but the blatant publish-at-all-cost attitude behind it all leaves me doubtful.  </p>\n\n<p>Unfortunately, my limited understanding of the do's and don'ts of data analysis keeps me from going beyond such vague doubts, so my conservative response is to basically disregard such findings.</p>\n\n<p>My hope is that not only a better understanding of the distinction between exploration and snooping/torturing, but also, and more importantly, a better grasp of principles and techniques for detecting when that line has been crossed, will allow me to evaluate such findings in a way that can reasonably accounts for a less-than-optimal analytic procedure, and thus be able to go beyond my current rather simple-minded response of blanket disbelief.</p>\n\n\n\n<p>EDIT: Thank you all for the very interesting comments and answers.  Judging by their content, I think I may have not explained my question well enough.  I hope this update will clarify matters.</p>\n\n<p>My question here concerns not so much what <em>I</em> should do to avoid torturing <em>my</em> data (although this is a question that also interests me), but rather: how should I regard (or evaluate) results that <em>I know for a fact</em> have been arrived through such \"data torture.\"</p>\n\n<p>The situation gets more interesting in those (much rarer) cases in which, in addition, I am in the position to voice an opinion on such \"findings\" before they get submitted for publication.</p>\n\n<p>At this point the <em>most</em> I can do is say something like \"I don't know how much credence I can give to these findings, given what I know about the assumptions and procedures that went into getting them.\"  <em>This is too vague to be worth even saying.</em>  Wanting to go beyond such vagueness was the motivation for my post.</p>\n\n<p>To be fair, my doubts here are based on more than seemingly questionable statistical methods.  In fact, I see the latter more as consequence of the deeper problem: a combination of a cavalier attitude towards experimental design coupled with a categorical commitment to publishing the results as they stand (i.e. without any further experiments).  Of course, follow-up projects are always envisioned, but it is simply <strong><em>out-of-the-question</em></strong> that not a single paper will come out of, say, \"a refrigerator filled with 100,000 samples.\"</p>\n\n<p>Statistics comes into the picture only as a means towards fulfilling this supreme objective.  The only justification for latching onto the statistics (secondary as they are in the whole scenario) is that a frontal challenge to the assumption of \"publication-at-all-cost\" is simply pointless.</p>\n\n<p>In fact, I can think of only one effective response in such situations: to propose some statistical test (not requiring additional experimentation) that truly tests the quality of the analysis.  But I just don't have the chops in statistics for it.  My hope (naive in retrospect) was to find out what I could study that may enable me to come up with such tests...</p>\n\n<p>As I write this it dawns on me that, if it doesn't already exist, the world could use one new sub-branch of statistics, devoted to techniques for detecting and exposing \"data-torture\".  (Of course, I don't mean getting carried away by the \"torture\" metaphor: the issue is not \"data-torture\" per-se, but the spurious \"findings\" it can lead to .)</p>\n", "pids": ["55a50d7165ceb7cb02df7ff6"], "flag": 1}
{"question": "Statistics: How are protein species distributed over cell types?", "body": "<p>There are roughly <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4889822/\" rel=\"noreferrer\">10,000 to 20,000</a> protein species in the human <a href=\"https://en.wikipedia.org/wiki/Proteome\" rel=\"noreferrer\">proteome</a> (while I've seen also numbers of <a href=\"https://translate.google.com/translate?sl=auto&amp;tl=en&amp;u=https%3A%2F%2Fde.wikipedia.org%2Fwiki%2FProteom\" rel=\"noreferrer\">500,000 to 1,000,000</a>). Furthermore, there are roughly 200 different <a href=\"https://en.wikipedia.org/wiki/List_of_distinct_cell_types_in_the_adult_human_body\" rel=\"noreferrer\">cell types</a> in the human body. My question is: </p>\n\n<p><strong>How are the protein species distributed over the cell types?</strong></p>\n\n<p>This means specifically:</p>\n\n<p><strong>How many proteins are expressed by <em>n</em> cell types?</strong></p>\n\n<p><strong>How many cell types express <em>n</em> proteins?</strong></p>\n\n<p>Probably these numbers are not known exactly because not all the proteins may be known that a given cell type expresses.</p>\n\n<p>But there might be evidence which general form the two distribution curves do have. Are they Poisson distributions and do look more like this?</p>\n\n<p><a href=\"https://i.stack.imgur.com/Emcln.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/Emcln.png\" alt=\"enter image description here\"></a></p>\n\n<p>Or this?</p>\n\n<p><a href=\"https://i.stack.imgur.com/p8fqe.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/p8fqe.png\" alt=\"enter image description here\"></a></p>\n\n<p>Or that?</p>\n\n<p><a href=\"https://i.stack.imgur.com/6qaHC.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/6qaHC.png\" alt=\"enter image description here\"></a></p>\n\n<p>Or some other kind of distribution, e.g. Gauss or even multi-modal?</p>\n", "pids": ["5638bf7c0cf2629e52a2bbac", "5a0cf8740cf2300994d0f32f", "553c2c120cf2b2c73cb0c401", "58be7daf0cf29f7b1ca3ab4a", "5c756942f56def979827a5cf", "5c0f8ec9da562944aca43a3e"], "flag": 1}
{"question": "Why study convex optimization for theoretical machine learning?", "body": "<p>I am working on theoretical machine learning — on transfer learning, to be specific — for my Ph.D. </p>\n\n<ul>\n<li><p>Out of curiosity, why should I take a course on convex optimization?</p></li>\n<li><p>What take-aways from convex optimization can I use in my research on theoretical machine learning? </p></li>\n</ul>\n", "pids": ["5a73cb9817c44a0b3035c2df", "5a73cbcc17c44a0b3035f239"], "flag": 1}
{"question": "What is the biological basis for the perception of time?", "body": "<p>How is the \"time axis\" of memories encoded in the brain? I guess the time of the event could be \"stored\" with each event, but how is this translated into neurons etc.?</p>\n", "pids": ["55a4931165ceb7cb02d246ad", "53e9b32bb7602d9703dfe5ce"], "flag": 1}
{"question": "How do I fit a multilevel model for over-dispersed poisson outcomes?", "body": "<p>I want to fit a multilevel GLMM with a Poisson distribution (with over-dispersion) using R. At the moment I am using <a href=\"http://cran.r-project.org/web/packages/lme4/index.html\" rel=\"nofollow noreferrer\">lme4</a> but I noticed that recently the <code>quasipoisson</code> family was removed. </p>\n\n<p>I've seen elsewhere that you can model additive over-dispersion for binomial distributions by adding a random intercept with one level per observation. Does this apply to the poisson distribution as well? </p>\n\n<p>Is there a better way to do it? Are there other packages that you would recommend? </p>\n", "pids": ["55a485d1612ca6486899a28b"], "flag": 1}
{"question": "Why is the expected value named so?", "body": "<p>I understand how we get 3.5 as the expected value for rolling a fair 6-sided die.\nBut intuitively, I can expect each face with equal chance of 1/6.  </p>\n\n<p>So shouldn't the expected value of rolling a die be either of the number between 1-6 with equal probability?  </p>\n\n<p>In other words, when asked the question 'what's the expected value of throwing a fair 6-sided die?', one should answer 'oh, it can be anything between 1-6 with equal chance'. Instead it's 3.5.<br>\nIntuitively in real world, can someone explain how 3.5 is the value I should expect on throwing a die?<br>\nAgain I don't want the formula or the derivation for the expectation.</p>\n", "pids": ["53e99b36b7602d97023d8927"], "flag": 1}
{"question": "How does the eugeroic modafinil work?", "body": "<p>How does the drug, modafinil (Provigil), exert its eugeroic (wakefulness-promoting) effects? I've read that it works by increasing dopamine and histamine concentrations in the CNS and by serving as a partial agonist at the dopamine D<sub>2</sub> receptor. Perhaps by interfering with the function of orexin?</p>\n", "pids": ["55a5f61e65cead59c8316418", "53e9bc79b7602d97048f6892", "55a5e4ef65cead59c82e9f49"], "flag": 1}
{"question": "Replication or conceptual replication of card trick in Mind Field Ep 8?", "body": "<p>In <a href=\"https://www.youtube.com/watch?v=b2ng8HuPLTk\" rel=\"nofollow noreferrer\">Mind Field S1 E8</a> Michael Stevens presents a magician performing a trick with participants. Each participant is shown pairs of photographs of people and are given the forced choice of which one they preferred to work with. After being presented with all of the options, the magician performs a sleight of hand to sneak cards from the &quot;no&quot; pile into the &quot;yes&quot; pile while the participant is filling out a form. Then the participant is shown cards from the file that they believe are purely those that they said &quot;yes&quot; to, and asked to explain why they said &quot;yes&quot;. When presented with cards that the participants said &quot;no&quot; to they appear to have made up rationalizations.</p>\n<p>Are there studies that replicate this effect?</p>\n", "pids": ["53e99c1ab7602d97024caced", "55a65ec065ce054aad658d11", "55a4ed3465ceb7cb02dc2820", "55a533ec65ceb7cb02e42c47", "621922295aee126c0f88a0d1"], "flag": 1}
{"question": "Bound for Arithmetic Harmonic mean inequality for matrices?", "body": "<p><strong>NOTE:</strong> <em>This question has originally <a href=\"https://math.stackexchange.com/questions/466688/bound-for-arithmetic-harmonic-mean-inequality-for-matrices\">been posted in MSE</a>, but it did not generate any interest. It was first posted there, because the question itself is a pure matrix-algebra question.<br />\nNevertheless, since the motive has to do with statistics and econometrics, I am posting the question on Cross Validated also, in the hope that some statistics/matrix algebra savvy brain will have something to contribute.</em></p>\n<p>The framework is as follows: We have a cross-sectional i.i.d. sample <span class=\"math-container\">$\\{\\mathbf y, \\mathbf X\\}$</span>, where <span class=\"math-container\">$\\mathbf y$</span> is a <span class=\"math-container\">$N \\times 1$</span> column vector, and <span class=\"math-container\">$\\mathbf X$</span> is a <span class=\"math-container\">$N\\times K$</span> matrix. We postulate a linear relationship between <span class=\"math-container\">$\\mathbf y$</span> and  <span class=\"math-container\">$\\mathbf X$</span>,</p>\n<p><span class=\"math-container\">$$\\mathbf y = \\mathbf X \\beta + \\mathbf u $$</span>\nwhere <span class=\"math-container\">$\\mathbf u$</span> is white-noise with variance <span class=\"math-container\">$\\sigma^2$</span>, and exogenous to the regressors in the <span class=\"math-container\">$\\mathbf X$</span> matrix, and <span class=\"math-container\">$\\beta$</span> is a <span class=\"math-container\">$K\\times 1$</span> column vector of unknown constant coefficients. Under this assumption, the OLS estimator is unbiased and consistent.\nNow assume <span class=\"math-container\">$N$</span> is &quot;large&quot;, say <span class=\"math-container\">$O \\left( 10^{4} \\right)$</span> or more (samples that large have started to appear in the econometrics field also). Then a researcher could conceivably entertain the following two options:</p>\n<p><span class=\"math-container\">$A$</span>) Run <em>one</em> OLS regression using the whole sample. This tactic can be thought of as appealing to the consistency property of the OLS estimator. Call this estimator <span class=\"math-container\">$\\hat \\beta$</span>.</p>\n<p><span class=\"math-container\">$B$</span>) Divide the sample into <span class=\"math-container\">$m$</span> <em>disjoint</em> sub-samples (for simplicity, assumed of equal length, and note that their union equals the whole sample), run <span class=\"math-container\">$m$</span> regressions, and calculate the average of the <span class=\"math-container\">$m$</span> coefficient estimates she will thus obtain. This tactic can be thought of as appealing to the unbiasedness property of the OLS estimator. Call this averaging estimator <span class=\"math-container\">$\\bar b_m$</span>.</p>\n<p><em>(Note that tactic <span class=\"math-container\">$B$</span> does not fall into any re-sampling approach, like bootstrap, subsampling, or jackknife -to be exact, it has been considered as a marginal case in applying jackknife in time series, but it is not trully a jackknife method).</em></p>\n<p>I have derived a nice-looking (to me) result that shows that the variance of the whole-sample estimator is always smaller than the variance of the averaging estimator:</p>\n<p><span class=\"math-container\">$$\\text{Var}\\left(\\bar b_m\\right) &gt; \\text{Var}\\left(\\hat \\beta\\right) $$</span>\nI say it is nice-looking because the result uses the Arithmetic-Harmonic mean inequality for PD matrices, <a href=\"http://www.tandfonline.com/doi/pdf/10.1080/03081089408818331\" rel=\"noreferrer\">proven here</a>:\nSpecifically, writing <span class=\"math-container\">$Z_l= \\left(X_l'X_l\\right)^{-1}$</span> for the inverse moment matrix of the regressors from the <em>l</em>-th sample, <em>l</em>=<span class=\"math-container\">$1,...,m$</span>, denoting by <span class=\"math-container\">$A_m$</span> the arithmetic mean and by <span class=\"math-container\">$H_m$</span> the harmonic mean  of these <span class=\"math-container\">$Z$</span> matrices, it is not hard to arrive at the following:</p>\n<p><span class=\"math-container\">$$\\text{Var}\\left(\\bar b_m\\right) = \\frac1m\\sigma^2A_m &gt;  \\frac1m\\sigma^2H_m =\\text{Var}\\left(\\hat \\beta\\right) $$</span></p>\n<p>...the inequality holding in the matrix sense. Note that <span class=\"math-container\">$H_m$</span> is the harmonic mean of <span class=\"math-container\">$\\left(X_1'X_1\\right)^{-1},...,\\left(X_m'X_m\\right)^{-1} $</span>in the true matrix sense, not a matrix containing the harmonic means of the corresponding elements of the matrices it averages.</p>\n<p>So the averaging estimator <span class=\"math-container\">$\\bar b_m$</span> is always less efficient than the whole sample estimator <span class=\"math-container\">$\\hat \\beta$</span>.</p>\n<p><strong>My question: Are there any known bounds for the difference between Arithmetic-Harmonic means for matrices?</strong></p>\n<p>For real numbers they are (see the <a href=\"http://en.wikipedia.org/wiki/Variance#Relations_with_the_harmonic_and_arithmetic_means\" rel=\"noreferrer\">wiki article</a> and the original resources <a href=\"http://www.sciencedirect.com/science/article/pii/S0022247X9996688X\" rel=\"noreferrer\">here</a> and <a href=\"http://files.test.ele-math.com/articles/jmi-02-11.pdf\" rel=\"noreferrer\">here</a> ).</p>\n<p>Why? because it will be helpful in order to move to the next step and compare estimators that may be neither unbiased nor consistent, and so one is left with a criterion such as Minimum Squared Error to compare them.</p>\n<p>Any suggestion, link or reference will be really appreciated.</p>\n", "pids": ["53e9bd98b7602d9704a4592b"], "flag": 1}
{"question": "Is life expectancy linked to intelligence in animals?", "body": "<p>For example, animals that live only a few days or a few years are often not very intelligent. In contrast, the most intelligent animals seem to live longer. </p>\n\n<p>Is this true? Are there any studies to prove or disprove this statement?</p>\n", "pids": ["53e9afadb7602d97039fe4ea"], "flag": 1}
{"question": "What are variational autoencoders and to what learning tasks are they used?", "body": "<p>As per <a href=\"https://stats.stackexchange.com/questions/82416/whats-the-sense-and-the-benefit-of-auto-encoder-algorithm\">this</a> and <a href=\"https://stats.stackexchange.com/questions/102627/whats-the-difference-between-autoencoders-and-deep-autoencoders\">this</a> answer, autoencoders seem to be a technique that uses neural networks for dimension reduction. I would like to additionally know what is a <em>variational</em> autoencoder (its main differences/benefits over a \"traditional\" autoencoders) and also what are the main learning tasks these algorithms are used for.</p>\n", "pids": ["58437725ac44360f1082fcb7", "57a4e921ac44365e35c98d4b", "58d82fcbd649053542fd666a", "5a73cbcc17c44a0b3035f792", "5c2348ceda562935fc1d5722", "573695ff6e3b12023e5135b6", "5c2348ceda562935fc1d5722", "5cede108da562983788e8184"], "flag": 1}
{"question": "High Current (Speed) Transfer Buffer Recipe", "body": "<p>Does anyone know an effective buffer mix to use for high current Western transfers?  We are successfully using the vendor's premixed buffer to transfer a wide range of protein sizes to PVDF membranes at 1A/25V for 10 min.  We get great results with the vendor's expensive buffer.</p>\n\n<p>I haven't been able to find a non-proprietary recipe that works.  The best ones we have hold the 25V, but then have a decrease in conductivity (increase in resistance) where they will start at 1A, but drop to 0.4A by the end of the 10 min.  The vendor's buffer seems to hold the high current and results in better transfers.</p>\n\n<p>I don't know if it will be helpful to list all the variations I've tried in detail, but they have revolved around modifying a traditional Towbin buffer plus SDS, more glycine/Tris, or MgCl2.  These were all various suggestions from people around the department, but I haven't found much published evidence for a buffer under these conditions.</p>\n\n<p>I realize 1A (and no I don't mean 1mA) is a lot of current, but the vendor's system works really well.  Any pointers on what I might try/add would be appreciated even if you don't have a worked out protocol.</p>\n\n<p>Edit: Info from the MSDS indicates it has 3 reagents:</p>\n\n<pre><code>Listing of dangerous and non-hazardous components:\nProprietary Reagent K\n10-20%\nProprietary Reagent EB II\n5-10%\nProprietary Reagent S\n1.0-2.5%\n7732-18-5 water\n50-100%\n·\n.....\nSolvent content:\nOrganic solvents:\n0.0 %\nWater:\n74.8 %\nSolids content:\n25.2 %\n</code></pre>\n\n<p>[I'm not sure if this MSDS info should be put here, just because I'm looking for someone who has already used a high current buffer they know the formulation for, not a guess to what I have.]</p>\n", "pids": ["55a5521e65ceb7cb02e81ca8"], "flag": 1}
{"question": "Propensity score matching - What is the problem?", "body": "<p>In estimation of treatment effects a commonly used method is matching. There are of course several techniques used for matching but one of the more popular techniques is propensity-score matching.</p>\n<p>However, I sometimes stumble upon contexts where it is said that the use of propensity scores for matching is controversial and that critics have indicated that other procedures might be preferable. So I was just wondering if anyone was familiar with this criticism and perhaps could explain it or provide references.</p>\n<p>So in short, the question I am asking is: why is it problematical to use propensity scores for matching?</p>\n", "pids": ["5c7559e8f56def979881262c", "53e9ab4fb7602d97034e4ff3", "5c0f7963da562944ac76323f", "5d2e5022275ded87f95f1436"], "flag": 1}
{"question": "How can I include random effects (or repeated measures) into a randomForest", "body": "<p>I'm not even sure that the question makes much sense, but I think I saw a couple of titles of papers where they proposed random forest with random effects. Is this possible in R?</p>\n", "pids": ["56d82518dabfae2eeed73de2", "5e8da0c991e011f2de58385c"], "flag": 1}
{"question": "Are light-on-dark colour schemes for computer screens better for programmers?", "body": "<p>There is somewhat general scientific agreement that in general case for reading, dark text on light background is more readable than light on dark. </p>\n\n<blockquote>\n  <p>However, most studies have shown that dark characters on a light\n  background are superior to light characters on a dark background (when\n  the refresh rate is fairly high). For example, Bauer and Cavonius\n  (1980) found that participants were 26% more accurate in reading text\n  when they read it with dark characters on a light background.</p>\n  \n  <p>Reference: Bauer, D., &amp; Cavonius, C., R. (1980). Improving the\n  legibility of visual display units through contrast reversal. In E.\n  Grandjean, E. Vigliani (Eds.), Ergonomic Aspects of Visual Display\n  Terminals (pp. 137-142). London: Taylor &amp; Francis</p>\n  \n  <p>People with astigmatism (aproximately 50% of the population) find it\n  harder to read white text on black than black text on white. Part of\n  this has to do with light levels: with a bright display (white\n  background) the iris closes a bit more, decreasing the effect of the\n  \"deformed\" lens; with a dark display (black background) the iris opens\n  to receive more light and the deformation of the lens creates a much\n  fuzzier focus at the eye.</p>\n  \n  <p>Jason Harrison – Post Doctoral Fellow, Imager Lab Manager – Sensory\n  Perception and Interaction Research Group, University of British\n  Columbia  (source: <a href=\"http://blog.tatham.oddie.com.au/2008/10/13/why-light-text-on-dark-background-is-a-bad-idea/\" rel=\"noreferrer\">Tatham Oddie \"Why light text on dark background is a bad idea\"</a>)</p>\n</blockquote>\n\n<p>Above is however generic, not computer screens in particular. </p>\n\n<p>Most modern study I've found regarding computer screens is the studies I've found <a href=\"http://tecfa.unige.ch/tecfa/maltt/cosys-2/textes/hall04.pdf\" rel=\"noreferrer\">(\"The impact of web page text-background colour\ncombinations on readability, retention, aesthetics\nand behavioural intention\" by Hall &amp; Hanna, 2004)</a> did not measure prolonged exposure.  Also these test were performed on random people, not professionals who spend long\nhours with text (code).</p>\n\n<p>On the other hand I see, that all kinds of dark themes are quite popular, and even default in various IDEs. It seems as contradiction if so many programmers would willingly choose less ergonomic color schemes. </p>\n\n<p>So are there any studies of the subject that take in account modern screen technology and type of work typical ITC professional is doing?</p>\n\n<p>\nLoosely related to: <a href=\"https://skeptics.stackexchange.com/questions/6902/is-it-preferable-to-use-a-computer-in-a-darkened-room\">Is it preferable to use a computer in a darkened room?</a></p>\n", "pids": ["53e9b716b7602d97042afd29"], "flag": 1}
{"question": "Color and line thickness recommendations for line plots", "body": "<p>Much has been written about color blind-friendly color choices for maps, polygons, and shaded regions in general (see for example <a href=\"http://colorbrewer2.org\">http://colorbrewer2.org</a>).  I have not been able to find recommendations for line colors and varying line thickness for line graphs.  Goals are:</p>\n\n<ol>\n<li>easily distinguish lines even when they intertwine</li>\n<li>lines are easy to distinguish by individuals with the most common forms of color blindness</li>\n<li>(less important) lines are printer-friendly (see Color Brewer above)</li>\n</ol>\n\n<p>In the context of black and gray scale lines I have found it very effective to have thin black lines and thicker gray scale lines.  I would appreciate specific recommendations that include varying colors, degree of gray scale, and line thickness.  I am not as fond of varying line types (solid/dotted/dashed) but could be talked out of that opinion.</p>\n\n<p>It would be preferable to have recommendations for up to 10 curves on one graph.  Even better would be to do as Color Brewer does: allow recommendations for m lines to not be a subset of recommendations for n lines where n > m, and to vary m from 1 to 10.</p>\n\n<p><strong>Please note</strong>: I would also appreciate guidance that addresses only the line coloring part of the question.</p>\n\n<p>Some practitioners add symbols to lines every few centimeters to better distinguish different classes.  I'm not so much in favor that requires more than one feature (e.g., color + symbol type) to distinguish the classes, and would sometimes like to reserve symbols to denote different information.</p>\n\n<p>In the absence of other guidance, I propose to use the same colors recommended for polygons in colorbrewer2.org for lines, and to multiply the line width by 2.5 for lines drawn with less bright/dense colors.  I'm creating an R function that sets this up.  In addition to the color brewer colors I think I'll make the first 2 colors be solid black (thin) and gray scale (thick) although one could argue that they should be thin solid black and thin blue.  </p>\n\n<p>R functions may be found at <a href=\"http://biostat.mc.vanderbilt.edu/wiki/pub/Main/RConfiguration/Rprofile\">http://biostat.mc.vanderbilt.edu/wiki/pub/Main/RConfiguration/Rprofile</a> .  Once you define the function <code>colBrew</code> you can see how the settings work by typing</p>\n\n<pre><code>showcolBrew(number of line types)  # add grayscale=TRUE to use only grayscale\n</code></pre>\n\n<p>A function <code>latticeSet</code> is also given, for setting <code>lattice</code> graphics parameters to the new settings.  Improvements to the algorithms are welcomed.</p>\n\n<p><em>To explore</em>: R <code>dichromat</code> package: <a href=\"http://cran.r-project.org/web/packages/dichromat/\">http://cran.r-project.org/web/packages/dichromat/</a></p>\n", "pids": ["53e9baa0b7602d97046cef34", "53e9a07ab7602d97029645b5"], "flag": 1}
{"question": "Is the Gregorian calendar the &quot;most accurate calendar ever devised&quot;?", "body": "<p>This statement comes from a Joe Rogan show episode where he chats to Neil de Grasse Tyson. His statement is about the Gregorian calendar, and goes as follows:</p>\n\n<blockquote>\n  <p>\"Point is, this was hard-earned, and the whole world uses this\n  calendar, it is the most accurate calendar ever devised.\"</p>\n</blockquote>\n\n<p>I have linked both to his explanation of the Gregorian calendar, and also to where the actual quote is found. If you start listening from the explanation, the quote I've transcribed will be made about 2 minutes in. After the quote is made, he further elaborates on leap years.</p>\n\n<p><a href=\"https://youtu.be/vGc4mg5pul4?t=54m26s\" rel=\"noreferrer\">Link to explanation</a> </p>\n\n<p><a href=\"https://youtu.be/vGc4mg5pul4?t=57m23s\" rel=\"noreferrer\">Link to actual quote</a></p>\n\n<p>Also, if this question is too hard to answer definitively, is it at least a fair statement to make?</p>\n", "pids": ["53e99d73b7602d970262af4f"], "flag": 1}
{"question": "Is this picture of a bent propeller genuine?", "body": "<p>This picture has been floating around the internet recently:</p>\n\n<p><a href=\"https://i.stack.imgur.com/1cIKO.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/1cIKO.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>Is it a genuine picture or photo-shopped? Or perhaps its some sort of optical illusion similar to the wagon wheel effect?</p>\n", "pids": ["53e9bcadb7602d970492c9c6"], "flag": 1}
{"question": "What is a manifold?", "body": "<p>In dimensionality reduction technique such as Principal Component Analysis, LDA etc often the term manifold is used. What is a manifold in non-technical term? If a point $x$ belongs to a sphere whose dimension I want to reduce, and if there is a noise $y$ and $x$ and $y$ are uncorrelated, then the actual points $x$ would be far separated from each other due to the noise. Therefore, noise filtering would be required. So, dimension reduction would be performed on $z = x+y$. Therefore, over here does $x$ and $y$ belong to different manifolds?</p>\n\n<p>I am working on point cloud data that is often used in robot vision; the point clouds are noisy due to noise in acquisition and I need to reduce the noise before dimension reduction. Otherwise, I will get incorrect dimension reduction. So, what is the manifold here and is noise a part of the same manifold to which $x$ belongs?</p>\n", "pids": ["58d82fd2d649053542fd75d8"], "flag": 1}
{"question": "Did 20% of US soldiers in Vietnam use heroin, 95% of whom quit afterwards?", "body": "<p>The following claims were made around 04:50 of <a href=\"https://www.ted.com/talks/johann_hari_everything_you_think_you_know_about_addiction_is_wrong/\" rel=\"noreferrer\">this TED talk</a> by <a href=\"https://en.wikipedia.org/wiki/Johann_Hari\" rel=\"noreferrer\">Johann Hari</a>:</p>\n\n<blockquote>\n  <p>20 percent of all American troops were using loads of heroin, and if you look at the news reports from the time, they were really worried, because they thought, my God, we're going to have hundreds of thousands of junkies on the streets of the United States when the war ends; it made total sense. Now, those soldiers who were using loads of heroin were followed home. The Archives of General Psychiatry did a really detailed study, and what happened to them? It turns out they didn't go to rehab. They didn't go into withdrawal. Ninety-five percent of them just stopped.</p>\n</blockquote>\n\n<p>Are the claims true? In other words:</p>\n\n<ol>\n<li><p>Did 20% of US soldiers in Vietnam use \"loads of\" heroin?</p></li>\n<li><p>Did 95% of the US soldiers who were using \"loads of\" heroin stop using heroin afterwards?</p></li>\n</ol>\n", "pids": ["55a49d13612ca648689da51b"], "flag": 1}
{"question": "Does the production of a Tesla battery produce as much CO2 as driving 200,000 km?", "body": "<p>Recently I read on <a href=\"https://en.wikipedia.org/wiki/Greenpeace\" rel=\"noreferrer\">Greenpeace's</a> website, that the production of a 100 kWh battery, as in the Tesla Model S, produces as much CO<sub>2</sub> as driving a regular car for 200,000&nbsp;km.</p>\n\n<p>Source: <a href=\"https://wattsupwiththat.com/2017/06/20/tesla-car-battery-production-releases-as-much-co2-as-8-years-of-gasoline-driving/\" rel=\"noreferrer\">Tesla car battery production releases as much CO<sub>2</sub> as 8 years of gasoline driving</a>:</p>\n\n<blockquote>\n  <p>For every kilowatt hour of storage capacity in the battery generated\n  emissions of 150 to 200 kilos of carbon dioxide already in the\n  factory.</p>\n</blockquote>\n\n<p>(<a href=\"https://www.greenpeace.de/themen/energiewende/mobilitaet/wie-stehts-mit-dem-e-auto\" rel=\"noreferrer\">Original Greenpeace link (in German)</a>)</p>\n\n<p>Let's say you are driving a car with 8&nbsp;L / 100&nbsp;km.\nAccording to <a href=\"https://www.drivingtests.co.nz/resources/fuel-co2-calculator-carbon-dioxide-emissions-in-kg/\" rel=\"noreferrer\">this calculator</a> this would result in 16,000 liters of fuel burnt or 36,960&nbsp;kg of CO<sub>2</sub>.</p>\n\n<p>A 100 kWh battery takes about 20,000&nbsp;kg of CO<sub>2</sub> to produce. So the math seems to add up.</p>\n\n<p><strong>But is the 100 kg to 200kg of CO<sub>2</sub> for 1 kWh battery realistic?</strong></p>\n\n<p>Also, isn't this calculation missing the fact that Tesla covers a part of its factory energy with its own solar panels and plans to use 100% renewable energy in the future?</p>\n", "pids": ["55a4082e65ce5cd7b3c1170c"], "flag": 1}
{"question": "Do researchers receive no income from revenues arising from their published papers?", "body": "<p>According to this article <a href=\"http://bigthink.com/neurobonkers/a-pirate-bay-for-science\"><em>Meet the Robin Hood of Science</em></a> (about the creator of a website to bypass paper access restrictions and paywalls),</p>\n\n<blockquote>\n  <p>Elbakyan made a point that will likely come as a shock to many outside\n  the academic community: <strong>Researchers and universities don’t earn a\n  single penny from the fees charged by publishers</strong> such as Elsevier\n  for accepting their work, while Elsevier has an annual income over a\n  billion U.S. dollars. Elbakyan explains: “I would also like to mention\n  that Elsevier is not a creator of these papers. All papers on their\n  website are written by researchers, and <strong>researchers do not receive\n  money from what Elsevier collects</strong>. That is very different from the\n  music or movie industry, where creators receive money from each copy\n  sold. ...\"</p>\n</blockquote>\n\n<p>(emphasis mine)</p>\n\n<p>Is this assertion true, that researchers generally don't share the revenues arising from access to their papers?</p>\n", "pids": ["55a52d2965ceb7cb02e36097"], "flag": 1}
{"question": "Why are there no deep reinforcement learning engines for chess, similar to AlphaGo?", "body": "<p>Computers have for a long time been able to play chess using a \"brute-force\"-technique, searching to a certain depth and then evaluating the position. The AlphaGo computer however, only use an ANN to evaluate the positions (it does not do any depth-search as far as I know). Is it possible to create an chess engine that plays chess in the same way as AlphaGo plays Go? Why has no one done this? Would this program perform better than the top chess-engines (and chess players) of today?</p>\n", "pids": ["573696026e3b12023e516627", "5a73cbcc17c44a0b3035f7b3"], "flag": 1}
{"question": "What does it mean to quantitatively describe a cell?", "body": "<p>To begin this question, I will quote <em>Molecular Biology of the Cell</em> (page 38):</p>\n<blockquote>\n<p>... Biological systems are, ..., full of feedback loops, and the behavior of even the simplest of systems with feedback is remarkably difficult to predict by intuition\nalone; small changes in parameters can cause radical changes in outcome. To go from a circuit diagram to a prediction of the behavior of the system, we need detailed quantitative information, and to draw deductions from that information we need mathematics and computers.</p>\n<p>... You might think that, knowing how each protein influences each other protein,\nand how the expression of each gene is regulated by the products of others, we should soon be able to calculate how the cell as a whole will behave, just as an astronomer can calculate the orbits of the planets, or a chemical engineer can calculate the flows through a chemical plant. But any attempt to perform this feat for anything close to an entire living cell rapidly reveals the limits of our present knowledge. The information we have, plentiful as it is, is full of gaps and uncertainties. Moreover, it is largely qualitative rather than quantitative.</p>\n<p>(Johnson, A. D., Roberts, K., Lewis, J., Morgan, D., Raff, M. C., Walter, P., Alberts, B. (2015). Molecular Biology of the Cell. United States: Garland Science, Taylor and Francis Group.)</p>\n</blockquote>\n<p>Thus comes a fundamental question: what does it mean when cell biologists want to quantitatively describe a cell?</p>\n<p>In my understanding, a cell is a complex system, and a quantitative description of it invokes treatment of the cell as a mechanistic, mathematically determinate system. For example, a projectile in the context of Newtonian physics is a product of such treatment. Physicists use a series of equations to represent motion of the projectile. They also plug in initial values such as velocities and positions to supplement the equations.</p>\n<p><a href=\"https://i.stack.imgur.com/q8oJi.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/q8oJi.png\" alt=\"https://dr282zn36sxxg.cloudfront.net/datastreams/f-d%3A032a554642a41232285e6e13aba720cece7b3c87d0e78f2a90ddb95b%2BIMAGE_TINY%2BIMAGE_TINY.1\" /></a></p>\n<p>As an analogy, quantifying a cell might mean finding a series of mathematical expressions for every chemical reaction or every biochemical inside a cell, and using a set of initial conditions to calculate the overall state of the cell at its very beginning. In this way, cell biologists can theoretically calculate figures of interest for whatever chemical reaction at any point during the cell's life. Of course, such an effort would be astronomically large and complex, and not feasible at present.</p>\n<p>However, if this is what quantification of a cell means, why do Bruce Alberts and other authors cite feedback loops as a hurdle that stands in the way of quantifying a cell? How do feedback loops affect quantification of a cell?</p>\n", "pids": ["5ff68a09d4150a363ccbde44"], "flag": 1}
{"question": "Did NOAA publish a fake map with temperature data it doesn&#39;t have?", "body": "<p>At the <a href=\"https://realclimatescience.com/2017/02/nasa-noaa-climate-data-is-fake-data/\">Deplorable Climate Science Blog</a>, he claims that this map was published:\n<a href=\"https://i.stack.imgur.com/gVIii.gif\"><a src=\"https://i.stack.imgur.com/gVIii.gif\" alt=\"enter image description here\"></a></p>\n\n<p>When this is the reality\n<a href=\"https://i.stack.imgur.com/qSBnv.gif\"><a src=\"https://i.stack.imgur.com/qSBnv.gif\" alt=\"enter image description here\"></a></p>\n\n<blockquote>\n  <p>The map above (the first map) is fake. NOAA has almost no temperature data from Africa, and none from central Africa. They simply made up the record temperatures</p>\n</blockquote>\n\n<p>Is it true?  Did NOAA publish a fake map based on information it doesn't have?</p>\n", "pids": ["53e9b8f5b7602d97044d7356"], "flag": 1}
{"question": "What happens if we continuously stimulate a mimosa plant?", "body": "<p>I know there is some mechanism in humans by which we start to ignore a certain stimuli if it persists for a long time (e.g., we don't feel our shoes all the time !).</p>\n\n<p>Can the same thing happen in <em>Mimosa pudica</em>? Can it again get it's original arrangement of leaves if it is stimulated without interruption?</p>\n\n<p>I think it should do this, otherwise it will not be able to grow if it is surrounded by bushes from all the sides as it will be stimulated constantly and so will be unable to photosynthesize properly.  </p>\n", "pids": ["55a6035265cead59c8329f1a"], "flag": 1}
{"question": "How are Bayesian Priors Decided in Real Life?", "body": "<p>I always had the following question: <strong>How are Bayesian Priors decided in real life?</strong></p>\n<p>I created the following scenario to pose my question: Suppose you are researcher and you are interested in studying <strong>if the age of a giraffe can be predicted by the weight and height of a giraffe</strong> (e.g. linear regression model : age = b_o + b_1<em>height + b_2</em>weight). You arrive at a national park to record measurements on giraffes  - but after only taking measurements on a few giraffes, a terrible storm happens and you have to stop your study. You only had time to measure 15 giraffes:</p>\n<pre><code>     weight   height age\n1  2998.958 15.26611  53\n2  3002.208 18.08711  52\n3  3008.171 16.70896  49\n4  3002.374 17.37032  55\n5  3000.658 18.04860  50\n6  3002.688 17.24797  45\n7  3004.923 16.45360  47\n8  2987.264 16.71712  47\n9  3011.332 17.76626  50\n10 2983.783 18.10337  42\n11 3007.167 18.18355  50\n12 3007.049 18.11375  53\n13 3002.656 15.49990  42\n14 2986.710 16.73089  47\n15 2998.286 17.12075  52\n</code></pre>\n<p>Unfortunately, this is not enough information to complete your study. However, you do some research and find these kinds of measurements have been taking on giraffes in the past. For example:</p>\n<p><strong>Study 1</strong>: A study was done in the 1800's which measured 1000 giraffes and found that that average height of those giraffes was 17ft, the average weight was 2800 lbs and the average age was 35. However this was done in the 1800's and you are doubtful that measurement might not have been as accurate back then, and issues in the environment (e.g. poaching) might have causes giraffes to change in size.</p>\n<p><strong>Study 2</strong>: A study was done in 2010 were 50 giraffes in zoos across the world and their height was 16ft, weight was 300 lbs and age was 50 years. This study is more recent, but you are skeptical that giraffes in zoos might be different from giraffes in the wild.</p>\n<p><strong>Study 3</strong>: An expert on giraffe strongly believes that the age, height and weight of giraffes have bell shaped distributions. The expert also believes that giraffes keep growing their whole life, i.e. as age increases, so does weight and height. He does not have any concrete numbers, but he is considered the leading expert.</p>\n<p>etc.</p>\n<p><strong>Question:</strong> In this problem, is it possible to complement the limited measurements you have, along with the prior knowledge available on giraffes (while taking into consideration their reliability)? Is this problem an example of how Bayesian Models (e.g. Bayesian Regression) can be used in real life - or does this problem fundamentally lack enough data to work with?</p>\n<p>Suppose you consult several studies where the heights were recorded and manually assess the credibility of these studies (assigning &quot;low weights&quot; to studies deemed not credible, e.g. <strong>adjusted_height = credibility_score * average_recorded_height_in_study</strong>):</p>\n<pre><code>head(my_data)\n\n average_recorded_height_in_study credibility_score study_number adjusted_height\n1                         13.74253         1.0000000            1       13.742525\n2                         20.08053         0.3222523            2        6.470999\n3                         13.25037         0.5132335            3        6.800532\n4                         15.74946         0.2625349            4        4.134783\n5                         11.68657         0.5966327            5        6.972592\n6                         17.27276         1.0000000            6       17.272759\n</code></pre>\n<p>There are many tools/packages (e.g. using the R programming language) which can attempt to explore this &quot;prior information&quot; and fit distribtuion</p>\n<pre><code>library(fitdistrplus)\nlibrary(patchwork)\nlibrary(ggplot2)\n\n fg &lt;- fitdist(my_data<span class=\"math-container\">$adjusted_height, \"gamma\")\n fln &lt;- fitdist(my_data$</span>adjusted_height, &quot;lnorm&quot;)\nfg &lt;- fitdist(my_data<span class=\"math-container\">$adjusted_height, \"gamma\")\n fw &lt;- fitdist(my_data$</span>adjusted_height, &quot;weibull&quot;)\n\n par(mfrow = c(2, 2))\n plot.legend &lt;- c(&quot;Weibull&quot;, &quot;lognormal&quot;, &quot;gamma&quot;)\n\na &lt;- denscomp(list(fw, fln, fg), legendtext = plot.legend, plotstyle = &quot;ggplot&quot;)\nb &lt;- qqcomp(list(fw, fln, fg), legendtext = plot.legend, plotstyle = &quot;ggplot&quot;)\nc &lt;- cdfcomp(list(fw, fln, fg), legendtext = plot.legend, plotstyle = &quot;ggplot&quot;)\nd &lt;- ppcomp(list(fw, fln, fg), legendtext = plot.legend, plotstyle = &quot;ggplot&quot;)\n\na+b+c+d\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/uBxT0.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/uBxT0.png\" alt=\"enter image description here\" /></a></p>\n<p>The above analysis could be repeated for the other variables in the study. Here, we could see which distribution fit the data the best (e.g. using the - likelihood), and record the parameter estimates for this distribution.</p>\n<p>Is this the right idea behind how priors are incorporated into Bayesian Models in the real world? In this example that I have created, can the information from previous studies be analyzed and used to create priors for a Bayesian Linear Regression?</p>\n<p>Thanks</p>\n<p><strong>Note:</strong> Suppose the 15 giraffes you measured happened to be diseased giraffes and their height/weight measurements are not representative of the general population of giraffes - but perhaps the information encoded within the priors represent a wide range of giraffes. Thus, combining your measurements with the prior information could result in a more realistic model that could generalize to a larger population of giraffes (this fact being unknown to you at this time).</p>\n", "pids": ["5c0f7966da562944ac7640bc", "5c0f7803da562944ac731e86", "5ec3b2c79fced0a24bfae604", "6021007391e0113bfb1dc4c0", "553bf7630cf2b2c73cb04d75", "601d3d8091e01194579224f1", "5cff8b7a3a55ac38cc40ea87", "5c1366b7da56295a089e99c6", "55a5132165ceb7cb02e00d9e", "5a14e17c0cf2dcc70c058d2c", "5ce3ae56ced107d4c65e7cb0"], "flag": 1}
{"question": "Who first used/invented p-values?", "body": "<p>I am attempting to write a series of blog posts on p-values and I thought it would be interesting to go back to where it all started - which appears to be Pearson's 1900 paper. If you are familiar with that paper, you'll remember that this covers goodness-of-fit testing.</p>\n\n<p>Pearson is a bit loose with his language when it comes to p-values. He repeatedly uses the \"odds\" when describing how to interpret his p-value. For example, on p.168 when talking about the results of repeat rolls of 12 dice, he says \"<em>...which leads us to P=.0000016, or the <strong>odds</strong> are 62,499 to 1 against such a system of deviation on a random selection. With such <strong>odds</strong> it would be reasonable to conclude that the dice exhibit bias towards the higher points.</em>\"</p>\n\n<p>In this article, he refers to earlier work, including an 1891 book on least squares by Merriman.</p>\n\n<p>But Pearson does lay out the calculus for p-values (w.r.t. chi-squared goodness of fit testing).</p>\n\n<p>Was Pearson the first person to conceive of p-values? When I do a search on p-values, Fisher is mentioned - and his work was in the 1920s.</p>\n\n<p>Edited: and a thank you for the mention of Laplace - he did not seem to address the null hypothesis  (Pearson appears to do so implicitly, although he never used that term in his 1900 paper). Pearson looked at goodness of fit testing from: assuming the counts are derived from an unbiased process, what is the probability that the observed counts (and counts more deviant) arise from the assumed distribution?</p>\n\n<p>His treatment of the probabilities/odds (he converts the probabilities to odds) suggests he is working with an implicit idea of the null hypothesis. Crucially, he also mentions that the probability arising from the x^2 value shows the odds \"against a system of deviations as improbable or more improbable than this one\" - language we recognise now - with respect to his calculated p-values.</p>\n\n<p>Did Arbuthnot go that far?</p>\n\n<p>Feel free to put your comments in as answers. It would be nice to see a discussion.</p>\n", "pids": ["5f0e58b29fced0a24b07b757"], "flag": 1}
{"question": "Is there any advantage of having mitochondria for aerobic respiration?", "body": "<p>If we consider the pathway of breakdown of glucose which includes glycolysis, the citric acid cycle and the electron transport chain, all these processes takes place in some  prokaryotes and eukaryotes. In prokaryotes all these processes take place in cytoplasm while in eukaryotes the last two processes take place in mitochondria.</p>\n\n<p>So is there any advantage of performing the last two processes in the mitochondria? Does it yield more energy? If there is no advantage, what is the point of having a mitochondria (at least for this process)?</p>\n", "pids": ["64d641e23fda6d7f0621f063"], "flag": 1}
{"question": "There are linear and rotary molecular motors in the cells. Do any of them have a fixed or stable frequency or speed?", "body": "<p>Are there any linear, rotary or oscillatory molecular motors in the cells which can have fixed frequeny and which can be used as a reference for elapsed time timer? This question is with relevence to my earlier question 'Is there a realtime molecular clock within the genome to co-ordinate the developmental sequences in an embryo?'</p>\n", "pids": ["55a532c365ceb7cb02e418bc"], "flag": 1}
{"question": "Intuitive explanation of &quot;Statistical Inference&quot;", "body": "<p>What is the cleanest, easiest way to explain someone the concept of Inference? What does it intuitively mean?</p>\n<p>How would you go to explain it to the layperson, or to a person who has studied a very basic probability and statistics course?</p>\n<p>something that would contribute to making it also 'intuitively' clear would be greatly appreciated!</p>\n", "pids": ["5f44ec9e91e011872f85edf8"], "flag": 1}
{"question": "What are attention mechanisms exactly?", "body": "<p>Attention mechanisms have been used in various Deep Learning papers in the last few years. Ilya Sutskever, head of research at Open AI, has enthusiastically praised them: \n<a href=\"https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0\" rel=\"noreferrer\">https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0</a></p>\n\n<p>Eugenio Culurciello at Purdue University has claimed that RNNs and LSTMs should be abandoned in favor of purely attention-based neural networks:</p>\n\n<p><a href=\"https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0\" rel=\"noreferrer\">https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0</a></p>\n\n<p>This seems an exaggeration, but it's undeniable that purely attention-based models have done quite well in sequence modeling tasks: we all know about the aptly named paper from Google, <a href=\"https://arxiv.org/abs/1706.03762\" rel=\"noreferrer\">Attention is all you need</a></p>\n\n<p>However, what <em>exactly</em> are attention-based models? I've yet to find a clear explanation of such models. Suppose I want to forecast the new values of a multivariate time series, given its historical values. It's quite clear how to do that with an RNN having LSTM cells. How would I do the same with an attention-based model?</p>\n", "pids": ["58d82fced649053542fd6fbf", "599c7987601a182cd2648373", "5c5ce4fd17c44a400fc38785"], "flag": 1}
{"question": "The origin of &quot;99 cents&quot;", "body": "<p>I've seen two competing theories on the origin of pricing products at <code>$&lt;desired dollar amount minus 1&gt;.99</code> (i.e. charging $19.99 instead of $20, of $5.99 instead of $6):</p>\n\n<ol>\n<li>Psychological pricing scheme used by retailers to make products seem one dollar less expensive than they really are.</li>\n<li>As an anti theft measure; forcing store clerks to ring up orders and open cash drawers (to give customers their one cent change); rather than just pocketing the money.</li>\n</ol>\n\n<p>Neither of these responses seem plausible to me.</p>\n\n<p>In the first case, retailers are expecting people to ignore the 99 cents, but when most people check to see whether or not they have enough money in the bank are going to take these things into account. Even if there's a slight edge to be had by losing that penny, I can't believe it'd be more than the potential thousands that one cent is multiplied into when you're selling thousands of copies of a product. Plus, most mentally add a few cents for sales tax and other things anyway.</p>\n\n<p>In the second, I fail to see what additional security forcing someone to open the cash drawer really offers. One could easily have a bunch of pennies lying around and still be able to pull off the same theft scheme. Most retailers have computerized systems and security cameras for these purposes now anyway.</p>\n\n<p>Do any hard data exist which proves or disproves either of these claims, or which supports a third, heretofore unmentioned claim?</p>\n", "pids": ["53e9b3dab7602d9703ec9bfb"], "flag": 1}
{"question": "Does microwaving food create particles that are not created when warming food by conventional means?", "body": "<p>I was reading <em>\"Szlachetne Zdrowie\"</em> (No 7/2019) which is a Polish health magazine released by <em>\"Nasz Dziennik\"</em>, which is a Catholic, very conservative newspaper of questionable quality. I read the chapter about microwaving written by Barbara Zielonka. She is a food technologist and claims that:</p>\n\n<blockquote>\n  <p>Microwaves frequency cause changes in organic compounds structure (isomers of those compounds might be created) and disintegration of many of them, with new, unknown chemical compounds unknown to nature being created. Food heated in microwave contains particles that are not created during conventional heating of the food (conduction, convection, radiation), where heat is transmitted from outside to the inside of the product.</p>\n</blockquote>\n\n<p>(my own loose translation from Polish to English)</p>\n\n<p>Also she claims that in The Lancet, there was some research showing that when the milk was microwaved, the amino acid proline in the milk changed its form from L-proline to D-proline and created so called \"cis isomers\". D-proline might be toxic, she claims. She also claims that the article in The Lancet is stating that <em>\"conversion of trans forms to cis forms might be dangerous, because cis amino acids are embedding themselves into peptides and proteins instead of trans isomers\"</em>.</p>\n\n<p>I was unable to locate that article in The Lancet.</p>\n\n<p>So the bottom line is: is it true that microwaving food can create some kind of chemical compounds that are not created when heating the food in traditional ways? If yes, then should we be worried? Could any be dangerous, such as the mentioned D-proline? I thought that microwaving is safe because it is just making water molecules vibrate and thus warming up the food. On the other hand I am very sceptical of the mentioned source where I found this article, but it mentioned The Lancet and it got me interested.</p>\n", "pids": ["56d8dcabdabfae2eeef71d84"], "flag": 1}
{"question": "What are &quot;residual connections&quot; in RNNs?", "body": "<p>In Google's paper <em><a href=\"https://arxiv.org/abs/1609.08144\" rel=\"noreferrer\">Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</a></em>, it is stated</p>\n\n<blockquote>\n  <p>Our LSTM RNNs have $8$ layers, with residual connections between layers ...</p>\n</blockquote>\n\n<p>What are <em>residual connections</em>? Why residual connections between layers?</p>\n\n<p>Ideally, I am looking for a simple and intuitive explanation first, possibly accompanied by schematic representations. </p>\n\n<p>The details can, of course, be found in the original papers, but I thought this question(s) would be beneficial to the community.</p>\n", "pids": ["573696026e3b12023e515eec", "5a260c8117c44a4ba8a30771", "573696026e3b12023e515eec", "58d82fced649053542fd7340", "605078ba91e0111e1cd4698a"], "flag": 1}
{"question": "Do wooden building fires get hotter than 600&#176;C?", "body": "<p>After the recent <a href=\"https://en.wikipedia.org/wiki/Notre-Dame_de_Paris_fire\" rel=\"noreferrer\">Notre-Dame de Paris fire</a>, there has been a heavily re-posted tweet going around in response to an earlier claim that a golden cross did not melt or deform - due to an act of God.</p>\n\n<p><a href=\"https://twitter.com/aSciEnthusiast/status/1118256899730870278\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/PZoy7.jpg\" alt=\"Screenshot of a tweet and response\"></a></p>\n\n<blockquote>\n  <p>Kaylee Crain: \"After all the aftermath and destruction of the Notre Dame fire, the alter and cross remained untouched. Please explain to me how you don’t believe in God after seeing this.\"</p>\n  \n  <p>Dan Broadbent: \"Because the melting point of gold is 1064°C and a wood fire burns at around 600°C\"</p>\n</blockquote>\n\n<p>The <a href=\"http://www.dhftargets.com/conversion_4.htm\" rel=\"noreferrer\">melting point of gold</a> varies based on purity, and can thus be lower than 1064°C.</p>\n\n<p>However; <strong>do wooden buildings, such as the Notre Dame Cathedral, burn at temperatures above 600°C?</strong></p>\n\n<p>I'm obviously not interested in any debate over whether this was an \"Act of God\" or other unprovable matters.</p>\n\n<p><em>In terms of personal research, what I have found is that while wood itself will not burn much hotter than 600°C, once it turns to charcoal - it can then reach over 1100°C. However I don't know enough about physics/chemistry or fires, to make a reasonable judgement on how that applies in a real-life fire.</em></p>\n", "pids": ["53e9b520b7602d9704052c87", "53e9a8ccb7602d970321acf1"], "flag": 1}
{"question": "Imputation of missing values for PCA", "body": "<p>I used the <code>prcomp()</code> function to perform a PCA (principal component analysis) in R. However, there's a bug in that function such that the <code>na.action</code> parameter does not work. <a href=\"https://stackoverflow.com/questions/12078291/r-function-prcomp-fails-with-nas-values-even-though-nas-are-allowed\">I asked for help on stackoverflow</a>; two users there offered two different ways of dealing with <code>NA</code> values. However, the problem with both solutions is that when there is an <code>NA</code> value, that row is dropped and not considered in the PCA analysis. My real data set is a matrix of 100 x 100 and I do not want to lose a whole row just because it contains a single <code>NA</code> value.</p>\n\n<p>The following example shows that the <code>prcomp()</code> function does not return any principal components for row 5 as it contains a <code>NA</code> value.</p>\n\n<pre><code>d       &lt;- data.frame(V1 = sample(1:100, 10), V2 = sample(1:100, 10), \n                      V3 = sample(1:100, 10))\nresult  &lt;- prcomp(d, center = TRUE, scale = TRUE, na.action = na.omit)\nresult$x                                # $\nd$V1[5] &lt;- NA                           # $\nresult  &lt;- prcomp(~V1+V2, data=d, center = TRUE, scale = TRUE, na.action = na.omit)\nresult$x\n</code></pre>\n\n<p>I was wondering if I can set the <code>NA</code> values to a specific numerical value when <code>center</code> and <code>scale</code> are set to <code>TRUE</code> so that the <code>prcomp()</code> function works and does not remove rows containing <code>NA</code>'s, but also does not influence the outcome of the PCA analysis.</p>\n\n<p>I thought about replacing <code>NA</code> values with the median value across a single column, or with a value very close to 0. However, I am not sure how that influences the PCA analysis.</p>\n\n<p>Can anybody think of a good way of solving that problem?</p>\n", "pids": ["53e99cedb7602d97025a3fc4"], "flag": 1}
{"question": "How to compute SVD of a huge sparse matrix?", "body": "<p>What is the best way to compute singular value decomposition (SVD) of a very large positive matrix (65M x 3.4M) where data is extremely sparse?</p>\n\n<p>Less than 0.1% of the matrix is non zero. I need a way that:</p>\n\n<ul>\n<li>will fit into memory (I know that online methods exists)</li>\n<li>will be computed in a reasonable time: 3,4 days</li>\n<li>will be accurate enough however accuracy is not my main concern and I would like to be able to control how much resources I put into it.</li>\n</ul>\n\n<p>It would be great to have a Haskell, Python, C# etc. library which implements it. I am not using mathlab or R but if necessary I can go with R.</p>\n", "pids": ["53e9b3b2b7602d9703e999b3"], "flag": 1}
{"question": "Importance of predictors in multiple regression: Partial $R^2$ vs. standardized coefficients", "body": "<p>I am wondering what the exact relationship between partial $R^2$ and coefficients in a linear model is and whether I should use only one or both to illustrate the importance and influence of factors.</p>\n\n<p>As far as I know, with <code>summary</code> I get estimates of the coefficients, and with <code>anova</code> the sum of squares for each factor - the proportion of the sum of squares of one factor divided by the sum of the sum of squares plus residuals is partial $R^2$ (the following code is in <code>R</code>).</p>\n\n<pre><code>library(car)\nmod&lt;-lm(education~income+young+urban,data=Anscombe)\n    summary(mod)\n\nCall:\nlm(formula = education ~ income + young + urban, data = Anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-60.240 -15.738  -1.156  15.883  51.380 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.868e+02  6.492e+01  -4.418 5.82e-05 ***\nincome       8.065e-02  9.299e-03   8.674 2.56e-11 ***\nyoung        8.173e-01  1.598e-01   5.115 5.69e-06 ***\nurban       -1.058e-01  3.428e-02  -3.086  0.00339 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 26.69 on 47 degrees of freedom\nMultiple R-squared:  0.6896,    Adjusted R-squared:  0.6698 \nF-statistic: 34.81 on 3 and 47 DF,  p-value: 5.337e-12\n\nanova(mod)\nAnalysis of Variance Table\n\nResponse: education\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nincome     1  48087   48087 67.4869 1.219e-10 ***\nyoung      1  19537   19537 27.4192 3.767e-06 ***\nurban      1   6787    6787  9.5255  0.003393 ** \nResiduals 47  33489     713                      \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n</code></pre>\n\n<p>The size of the coefficients for 'young' (0.8) and 'urban' (-0.1, about 1/8 of the former, ignoring '-') does not match the explained variance ('young' ~19500 and 'urban' ~6790, i.e. around 1/3).</p>\n\n<p>So I thought I would need to scale my data because I assumed that if a factor's range is much wider than another factor's range their coefficients would be hard to compare:</p>\n\n<pre><code>Anscombe.sc&lt;-data.frame(scale(Anscombe))\nmod&lt;-lm(education~income+young+urban,data=Anscombe.sc)\nsummary(mod)\n\nCall:\nlm(formula = education ~ income + young + urban, data = Anscombe.sc)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.29675 -0.33879 -0.02489  0.34191  1.10602 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.084e-16  8.046e-02   0.000  1.00000    \nincome       9.723e-01  1.121e-01   8.674 2.56e-11 ***\nyoung        4.216e-01  8.242e-02   5.115 5.69e-06 ***\nurban       -3.447e-01  1.117e-01  -3.086  0.00339 ** \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.5746 on 47 degrees of freedom\nMultiple R-squared:  0.6896,    Adjusted R-squared:  0.6698 \nF-statistic: 34.81 on 3 and 47 DF,  p-value: 5.337e-12\n\nanova(mod)\nAnalysis of Variance Table\n\nResponse: education\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nincome     1 22.2830 22.2830 67.4869 1.219e-10 ***\nyoung      1  9.0533  9.0533 27.4192 3.767e-06 ***\nurban      1  3.1451  3.1451  9.5255  0.003393 ** \nResiduals 47 15.5186  0.3302                      \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1    \n</code></pre>\n\n<p>But that doesn't really make a difference, partial $R^2$ and the size of the coefficients (these are now <em>standardized coefficients</em>) still do not match:</p>\n\n<pre><code>22.3/(22.3+9.1+3.1+15.5)\n# income: partial R2 0.446, Coeff 0.97\n9.1/(22.3+9.1+3.1+15.5)\n# young:  partial R2 0.182, Coeff 0.42\n3.1/(22.3+9.1+3.1+15.5)\n# urban:  partial R2 0.062, Coeff -0.34\n</code></pre>\n\n<p><strong>So is it fair to say that 'young' explains three times as much variance as 'urban' because partial $R^2$ for 'young' is three times that of 'urban'?</strong> Why is the coefficient of 'young' then not three times that of 'urban' (ignoring the sign)?</p>\n\n<p>I suppose the answer for this question will then also tell me the answer to my initial query: Should I use partial $R^2$ or coefficients to illustrate the relative importance of factors? (Ignoring direction of influence - sign - for the time being.)</p>\n\n<p><strong>Edit:</strong></p>\n\n<p>Partial eta-squared appears to be another name for what I called partial $R^2$. <a href=\"http://www.inside-r.org/packages/cran/heplots/docs/etasq\">etasq {heplots}</a> is a useful function that produces similar results:</p>\n\n<pre><code>etasq(mod)\n          Partial eta^2\nincome        0.6154918\nyoung         0.3576083\nurban         0.1685162\nResiduals            NA\n</code></pre>\n", "pids": ["56d92ad1dabfae2eeed7731a"], "flag": 1}
{"question": "Is the exact value of a &#39;p-value&#39; meaningless?", "body": "<p>I had a discussion with a statistician back in 2009 where he stated that the exact value of a p-value is irrelevant: the only thing that is important is whether it is significant or not. I.e. one result cannot be more significant than another; your samples for example, either come from the same population or don't.</p>\n<p>I have some qualms with this, but I can perhaps understand the ideology:</p>\n<ol>\n<li><p>The 5% threshold is arbitrary, i.e. that p = 0.051 is not significant and that p = 0.049 is, shouldn't really change the conclusion of your observation or experiment, despite one result being significant and the other not significant.</p>\n<p>The reason I bring this up now is that I'm studying for an MSc in Bioinformatics, and after talking to people in the field, there seems to be a determined drive to get an exact p-value for every set of statistics they do. For instance, if they 'achieve' a p-value of p &lt; 1.9×10<sup>-12</sup>, they want to demonstrate HOW significant their result is, and that this result is SUPER informative. This issue exemplified with questions such as: <a href=\"https://stackoverflow.com/questions/6970705/why-cant-i-get-a-p-value-smaller-than-2-2e-16\">Why can't I get a p-value smaller than 2.2e-16?</a>, whereby they want to record a value that indicates that by chance alone this would be MUCH less than 1 in a trillion. But I see little difference in demonstrating that this result would occur less than 1 in a trillion as opposed to 1 in a billion.</p>\n</li>\n<li><p>I can appreciate then that p &lt; 0.01 shows that there is less than 1% chance that this would occur, whereas p &lt; 0.001 indicates that a result like this is even more unlikely than the aforementioned p-value, but should your conclusions drawn be completely different? After all they are both significant p-values. The only way I can conceive of wanting to record the exact p-value is during a Bonferroni correction whereby the threshold changes due to the number of comparisons made, thus decreasing the type I error. But even still, why would you want to show a p-value that is 12 orders of magnitude smaller than your threshold significance?</p>\n</li>\n<li><p>And isn't applying the Bonferroni correction in itself slightly arbitrary too? In the sense that initially the correction is seen as very conservative, and therefore there are other corrections that one can choose to access the significance level that the observer could use for their multiple comparisons. But because of this, isn't the point at which something becomes significant essentially variable depending upon what statistics the researcher wants to use. Should statistics be so open to interpretation?</p>\n</li>\n</ol>\n<p>In conclusion, shouldn't statistics be less subjective (although I guess the need for it to be subjective is as a consequence of a multivariate system), but ultimately I want some clarification: can something be more significant than something else? And will p &lt; 0.001 suffice in respect to trying to record the exact p-value?</p>\n", "pids": ["56d8701adabfae2eeeedcba5"], "flag": 1}
{"question": "AIC versus cross validation in time series: the small sample case", "body": "<p>I am interested in model selection in a time series setting. For concreteness, suppose I want to select an ARMA model from a pool of ARMA models with different lag orders. The ultimate <strong>intent is forecasting</strong>.</p>\n\n<p>Model selection can be done by</p>\n\n<ol>\n<li>cross validation,</li>\n<li>use of information criteria (AIC, BIC),</li>\n</ol>\n\n<p>among other methods.</p>\n\n<p>Rob J. Hyndman provides a way to do <a href=\"http://robjhyndman.com/hyndsight/crossvalidation/\" rel=\"noreferrer\">cross validation for time series</a>. For relatively small samples, the sample size used in cross validation may be <strong>qualitatively different</strong> than the original sample size. For example, if the original sample size is 200 observations, then one could think of starting cross validation by taking the first 101 observations and expanding the window to 102, 103, ..., 200 observations to obtain 100 cross-validation results. Clearly, a model that is reasonably parsimonious for 200 observation may be too large for 100 observations and thus its validation error will be large. Thus cross validation is likely to systematically favour too-parsimonious models. This is an <strong>undesirable effect due to the mismatch in sample sizes</strong>.</p>\n\n<p>An alternative to cross validation is using information criteria for model selection. Since I care about forecasting, I would use AIC. Even though AIC is asymptotically equiv­a­lent to min­i­miz­ing the out-​​of-​​sample one-​​step fore­cast MSE for time series mod­els (according to <a href=\"http://robjhyndman.com/hyndsight/aic/\" rel=\"noreferrer\">this post</a> by Rob J. Hyndman), I doubt this is relevant here since the sample sizes I care about are not that large...</p>\n\n<p><strong>Question:</strong> should I choose AIC over time series cross validation for small/medium samples?</p>\n\n<p>A few related questions can be found <a href=\"https://stats.stackexchange.com/questions/8807/cross-validating-time-series-analysis\">here</a>, <a href=\"https://stats.stackexchange.com/questions/14099/using-k-fold-cross-validation-for-time-series-model-selection\">here</a> and <a href=\"https://stats.stackexchange.com/questions/17932/calculating-forecast-error-with-time-series-cross-validation\">here</a>.</p>\n", "pids": ["5954fa6a0cf2bacabb7fd851"], "flag": 1}
{"question": "How should an individual researcher think about the false discovery rate?", "body": "<p>I've been trying to wrap my head around how the False Discovery Rate (FDR) should inform the conclusions of the individual researcher. For example, if your study is underpowered, should you discount your results even if they're significant at $\\alpha = .05$? Note: I'm talking about the FDR in the context of examining the results of multiple studies in aggregate, <em>not</em> as a method for multiple test corrections.</p>\n\n<p>Making the (maybe generous) assumption that $\\sim.5$ of hypotheses tested are actually true, the FDR is a function of both the type I and type II error rates as follows:</p>\n\n<p>$$\\text{FDR} = \\frac{\\alpha}{\\alpha+1-\\beta}.$$</p>\n\n<p>It stands to reason that if a study is sufficiently <em>underpowered</em>, we should not trust the results, even if they are significant, as much as we would those of an adequately powered study. So, <a href=\"http://arxiv.org/abs/1407.5296\" rel=\"noreferrer\">as some statisticians would say</a>, there are circumstances under which, \"in the long run\", we might publish many significant results that are false if we follow the traditional guidelines. If a body of research is characterized by consistently underpowered studies (e.g., the candidate gene $\\times$ environment interaction <a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3222234/\" rel=\"noreferrer\">literature of the previous decade</a>), even replicated significant findings can be suspect.</p>\n\n<p>Applying the R packages <code>extrafont</code>, <code>ggplot2</code>, and <code>xkcd</code>, I think this might be usefully conceptualized as an <strong>issue of perspective:</strong>\n<a src=\"https://i.stack.imgur.com/9XU6k.png\" alt=\"A significant result...\"></p>\n\n<p><a src=\"https://i.stack.imgur.com/Jtyuh.png\" alt=\"Not so sure...\"></p>\n\n<p>Given this information, <strong>what should an individual researcher do next</strong>? If I have a guess of what the size of the effect I'm studying should be (and therefore an estimate of $1 - \\beta$, given my sample size), should I adjust my $\\alpha$ level until the FDR = .05? Should I publish results at the $\\alpha = .05$ level even if my studies are underpowered and leave consideration of the FDR to consumers of the literature?</p>\n\n<p>I know this is a topic that has been discussed frequently, both on this site and in the statistics literature, but I can't seem to find a consensus of opinion on this issue.</p>\n\n\n\n<p><strong>EDIT:</strong> In response to @amoeba's comment, the FDR can be derived from the standard type I/type II error rate contingency table (pardon its ugliness):</p>\n\n<pre><code>|                            |Finding is significant |Finding is insignificant |\n|:---------------------------|:----------------------|:------------------------|\n|Finding is false in reality |alpha                  |1 - alpha                |\n|Finding is true in reality  |1 - beta               |beta                     |\n</code></pre>\n\n<p>So, if we are presented with a significant finding (column 1), the chance that it is false in reality is alpha over the sum of the column.</p>\n\n<p>But yes, we can modify our definition of the FDR to reflect the (prior) probability that a given hypothesis is true, though study power $(1 - \\beta)$ still plays a role:</p>\n\n<p>$$\\text{FDR} = \\frac{\\alpha \\cdot (1- \\text{prior})}{\\alpha \\cdot (1- \\text{prior}) + (1-\\beta) \\cdot \\text{prior}}$$</p>\n", "pids": ["573695f76e3b12023e50b97d"], "flag": 1}
{"question": "Is rejecting the hypothesis using p-value equivalent to hypothesis not belonging to the confidence interval?", "body": "<p>While formally deriving the confidence interval of an estimate, I ended up with a formula that resembles very closely the way $p$-value is computed.</p>\n\n<p>Thus the question: are they formally equivalent? I.e. is rejecting an hypotheses $H_0 = 0$ with a critical value $\\alpha$ equivalent to $0$ not belonging to the confidence interval with critical value $\\alpha$?</p>\n", "pids": ["56d85cabdabfae2eee5bcd7c"], "flag": 1}
{"question": "Why will ridge regression not shrink some coefficients to zero like lasso?", "body": "<p>When explaining LASSO regression, the diagram of a diamond and circle is often used. It is said that because the shape of the constraint in LASSO is a diamond, the least squares solution obtained might touch the corner of the diamond such that it leads to a shrinkage of some variable. However, in ridge regression, because it is a circle, it will often not touch the axis. I could not understand why it cannot touch the axis or maybe have a lower probability than LASSO to shrink certain parameters. <strong>On top of that, why do LASSO and ridge have lower variance than ordinary least squares?</strong> The above is my understanding of ridge and LASSO and I might be wrong. Can someone help me understand why these two regression methods have lower variance? </p>\n", "pids": ["5c610875da56297340b3bda6"], "flag": 1}
{"question": "Is homosexuality innate?", "body": "<p>There is a <a href=\"https://www.pewresearch.org/fact-tank/2015/03/06/americans-are-still-divided-on-why-people-are-gay/\" rel=\"nofollow noreferrer\">widespread belief that one chooses to be a homosexual</a>, and that <a href=\"https://en.wikipedia.org/wiki/Ex-gay\" rel=\"nofollow noreferrer\">people can successfully overcome such feelings</a>.</p>\n<p>On the other hand, some scientific studies have shown that <a href=\"https://www.unl.edu/rhames/courses/ppoint/sexual-selection.pdf\" rel=\"nofollow noreferrer\">finger length may be linked with sexuality</a>:</p>\n<blockquote>\n<p>It has long been suspected that high levels of\nandrogenic steroids in the uterine environment have\na musculizing effect on the fetus.</p>\n</blockquote>\n<p>Furthermore, several psychiatric organizations claim it is not a choice, but disagree on whether it is completely innate, affected by early childhood, or whether we really have any clue at all!</p>\n<p>So, as far as we know now, is homosexuality a matter of choice, nature, or nuture?</p>\n", "pids": ["53e9bdefb7602d9704aa47da", "55a53f02c91bf3b1cc52e55b", "55a3d11fc91b587b096356f9"], "flag": 1}
{"question": "What is the reason that the Adam Optimizer is considered robust to the value of its hyper parameters?", "body": "<p>I was reading about the <a href=\"https://arxiv.org/abs/1412.6980\" rel=\"noreferrer\">Adam optimizer</a> for Deep Learning and came across the following sentence in the new book <em><a href=\"http://www.deeplearningbook.org/\" rel=\"noreferrer\">Deep Learning</a></em> by Bengio, Goodfellow and Courville:</p>\n\n<blockquote>\n  <p>Adam is generally regarded as being fairly robust to the choice of hyper parameters, though the learning rate sometimes needs to be changed  from the suggested default.</p>\n</blockquote>\n\n<p>if this is true its a big deal because hyper parameter search can be really important (in my experience at least) in the statistical performance of a deep learning system. Thus, my question is, why is Adam Robust to such important parameters? Specially $\\beta_1$ and $\\beta_2$? </p>\n\n<p>I've read the Adam paper and it doesn't provide any explanation to why it works with those parameters or why its robust. Do they justify that elsewhere?</p>\n\n<p>Also, as I read the paper, it seems that the number of hyper parameters they tried where very small, for $\\beta_1$ only 2 and for $\\beta_2$ only 3. How can this be a thorough empirical study if it only works on 2x3 hyper parameters?</p>\n", "pids": ["5550415745ce0a409eb3a739"], "flag": 1}
{"question": "Do violent video games cause violent behavior?", "body": "<p>I have been following this question casually over the past couple of years, and it seemed to me that there was no strong consensus either way on the subject. However, I recently read an <a href=\"http://www.gamepro.com/article/news/216849/editorial-pros-cons-schwarzenegger-v-ema/\">editorial</a> from one of the scientists involved in the Supreme Court case, Schwarzenegger vs. EMA, arguing that the evidence for psychological and physical damage to children is strong.</p>\n\n<p>On the other hand, a quick check of the <a href=\"http://en.wikipedia.org/wiki/Video_game_violence\">wikipedia article</a> on the subject seemed to confirm my original impression, that there was still significant controversy on the subject.</p>\n", "pids": ["55a38f5d65ce5cd7b3ae9f1a", "5f50c4359fced0a24b9c1c83", "5c8b51da4895d9cbc680db12", "5a9d3f1f684d7fe2ff403c91", "56d87304dabfae2eee031276", "5a9d3f2a684d7fe2ff403c93", "5a9d3b9c684d7fe2ff403bf8", "5a9d3f41684d7fe2ff403c97"], "flag": 1}
{"question": "About CNN, kernels and scale/rotation invariance", "body": "<p>I have a couple of questions that are confusing me regarding the CNN.<br>\n1) The features extracted using CNN are scale and rotation invariant?<br>\n2) The Kernels we use to convolution with our data are already defined in the literature? what kind of these kernels are? is it different for every application?</p>\n", "pids": ["5b8c9f5317c44af36f8b7585", "5b67b4b417c44aac1c8671de", "5b8c9f4a17c44af36f8b71df"], "flag": 1}
{"question": "Do 1 in 2 Swiss citizens have guns and do they have the lowest crime rate?", "body": "<p>I came across a facebook post by an Australian political party that states</p>\n\n<blockquote>\n  <ul>\n  <li>1 in 2 citizens in Switzerland have guns</li>\n  <li>Lowest crime rate in the world</li>\n  </ul>\n</blockquote>\n\n<p>Are the above two statements true?</p>\n\n<p><a href=\"https://i.stack.imgur.com/GFsgo.png\"><a src=\"https://i.stack.imgur.com/GFsgo.png\" alt=\"Swiss citizens and guns\"></a></p>\n\n<p>(<a href=\"https://www.facebook.com/LibDemAus/photos/a.379420617671.162815.134050922671/10154409578597672/?type=3\">source</a>)</p>\n", "pids": ["55a4754d65ce31bc877b972c"], "flag": 1}
{"question": "Distinguishing between two groups in statistics and machine learning: hypothesis test vs. classification vs. clustering", "body": "<p>Assume I have two data groups, labeled A and B (each containing e.g. 200 samples and 1 feature), and I want to know if they are different. I could:</p>\n\n<ul>\n<li><p>a) perform a statistical test (e.g. t-test) to see if they are statistically different.</p></li>\n<li><p>b) use supervised machine learning (e.g. support vector classifier or random forest classifier). I can train this on a part of my data and verify it on the rest. If the machine learning algorithm classifies the rest correctly afterwards, I can be sure that the samples are differentiable.</p></li>\n<li><p>c) use an unsupervised algorithm (e.g. K-Means) and let it divide all data into two samples. I can then check if these two found samples agree with my labels, A and B.</p></li>\n</ul>\n\n<p>My questions are:</p>\n\n<ol>\n<li>How are these three different ways overlapping/exclusive?  </li>\n<li>Are b) and c) useful for any scientific arguments? </li>\n<li>How could I get a “significance“ for the difference between samples A and B out of methods b) and c)? </li>\n<li>What would change if the data had multiple features rather than 1 feature? </li>\n<li>What happens if they contain a different number of samples, e.g. 100 vs 300?</li>\n</ol>\n", "pids": ["573696126e3b12023e524f25", "5c756d21f56def97984fa721"], "flag": 1}
{"question": "Can degrees of freedom be a non-integer number?", "body": "<p>When I use GAM, it gives me residual DF is $26.6$ (last line in the code). What does that mean? Going beyond GAM example, In general, can the number of degrees of freedom be a non-integer number? </p>\n\n<pre><code>&gt; library(gam)\n&gt; summary(gam(mpg~lo(wt),data=mtcars))\n\nCall: gam(formula = mpg ~ lo(wt), data = mtcars)\nDeviance Residuals:\n    Min      1Q  Median      3Q     Max \n-4.1470 -1.6217 -0.8971  1.2445  6.0516 \n\n(Dispersion Parameter for gaussian family taken to be 6.6717)\n\n    Null Deviance: 1126.047 on 31 degrees of freedom\nResidual Deviance: 177.4662 on 26.6 degrees of freedom\nAIC: 158.4294 \n\nNumber of Local Scoring Iterations: 2 \n\nAnova for Parametric Effects\n            Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nlo(wt)     1.0 847.73  847.73  127.06 1.239e-11 ***\nResiduals 26.6 177.47    6.67                      \n</code></pre>\n", "pids": ["56d8402bdabfae2eee81d210"], "flag": 1}
{"question": "Is gun control effective?", "body": "<p>I have seen numerous arguments about gun control, in the sense of laws restricting gun ownership or possession, and whether widespread gun possession affects crime rates, and each side is happy to pull out studies that are favorable to their side.  I really haven't felt I could trust any of them.</p>\n\n<p>I hope this isn't too much of a hot potato, but are there any serious scientific studies available?  Or at least reasonably unbiased?</p>\n", "pids": ["53e99b50b7602d97023f43d9"], "flag": 1}
{"question": "Were World War II scrap drives in the United States truly necessary for the procurement of raw materials?", "body": "<p>I’ve been reading up on World War II scrap drive efforts in the United States, and am wondering if these (mostly) community-based efforts actually contributed enough raw materials to the war effort for them to actually be viable?</p>\n\n<p>Meaning, I am assuming that these drives brought communities together and provided a sense of “I am doing something!” for the war effort, <strong>but if—all things being equal—no recycling happened past the usual efforts a community has, would the war effort have been stymied as a result? If a neighborhood didn’t collectively scrap their iron fences, would a tank truly have not been built as a result?</strong> </p>\n\n<p>I have come across articles like these—for example—online that seem to be stating similar claims; article title linked with quote below:</p>\n\n<ul>\n<li><p><a href=\"https://uwsslec.libguides.com/c.php?g=416691&amp;p=2839329\" rel=\"noreferrer\"><strong>Scrap Metal and Rubber Drives</strong> (University of Wisconsin System School Library Education Consortium)</a></p>\n\n<blockquote>\n  <p>“On the home front, sacrifice was a common theme throughout the years of the war. Scrap metal drives were conducted throughout the US to gather materials to build tanks, ships, planes and weapons.”</p>\n</blockquote></li>\n<li><p><a href=\"https://blogs.loc.gov/now-see-hear/2015/01/scrap-for-victory/\" rel=\"noreferrer\"><strong>Scrap for Victory! (Library of Congress Blogs)</strong></a></p>\n\n<blockquote>\n  <p>“During World War II scrap drives were a popular way for everyone to contribute to the war effort. By recycling unused or unwanted metal for example, the government could build ships, airplanes and other equipment needed to fight the war.”</p>\n</blockquote></li>\n<li><p><a href=\"http://www.sarahsundin.com/make-it-do-scrap-drives-in-world-war-ii-2/\" rel=\"noreferrer\"><strong>Make It Do – Scrap Drives in World War II</strong> (Author Sarah Sundin’s Website)</a></p>\n\n<blockquote>\n  <p>“Scrap drives were a vital part of the American war effort.”</p>\n</blockquote></li>\n</ul>\n\n<p>All of these pieces talk about the scrap drives matter-of-factly as being a “thing” but none really address whether or not these efforts were simply “team building” exercises at best? They all seem to implicitly agree that scrap drive efforts were necessary.</p>\n\n<p>That said, I did stumble upon <a href=\"https://mashable.com/2016/02/03/wwii-scrap-metal/#ZL6HdnD_.qq4\" rel=\"noreferrer\">this Mashable piece (“1942: Scrap metal drives”)</a> that is mainly a pile of pictures but also includes this claim—that I tend to agree with—but doesn’t provide citations or context for the claim:</p>\n\n<blockquote>\n  <p>“Ultimately, the effect of these scrap metal drives on actual war production was marginal at best. Their true value was in galvanizing citizen morale and a sense of patriotic unity, and making everyone feel a part of the war effort.”</p>\n</blockquote>\n\n<p>So are there any citable (and hopefully fact and statistic backed) sources out there that focus on the idea that these scrap drives were more of a morale boosting effort than a truly necessary act of sacrifice for a war effort?</p>\n\n<p>Including a cool pic (below) of a dog and two kids collecting scrap items (presumably) around Boston just for the hell of it.</p>\n\n<p><a href=\"https://i.stack.imgur.com/ZUCio.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/ZUCio.jpg\" alt=\"Photo credited as Leslie Jones/Boston Public Library\"></a></p>\n", "pids": ["53e9a70bb7602d9703042a2c"], "flag": 1}
{"question": "Intuitive explanation of how UMAP works, compared to t-SNE", "body": "<p>I have a PhD in molecular biology. My studies recently started to involve high dimensional data analysis. I got the idea of how t-SNE works (thanks to a <a href=\"https://www.youtube.com/watch?v=NEaUSP4YerM\" rel=\"noreferrer\">StatQuest video on YouTube</a>) but can't seem to wrap my mind around <a href=\"https://github.com/lmcinnes/umap\" rel=\"noreferrer\">UMAP</a> (I listened to the <a href=\"https://www.youtube.com/watch?v=nq6iPZVUxZU\" rel=\"noreferrer\">UMAP creator's talk</a> online but didn't find it easy to understand). I went back to <a href=\"https://arxiv.org/pdf/1802.03426.pdf\" rel=\"noreferrer\">original paper</a> describing it but it was too much math for me. </p>\n\n<p>Can anybody shed some light on the issue? I am looking or an intuitive explanation, similar to the StatQuest video linked above.</p>\n", "pids": ["5ac1829d17c44a1fda917e2e"], "flag": 1}
{"question": "R: Problem with runif: generated number repeats (more often than expected) after less than 100 000 steps", "body": "<p>After executing the code</p>\n<pre><code>RNGkind(kind=&quot;Mersenne-Twister&quot;)  # the default anyway\nset.seed(123)\nn = 10^5\nx = runif(n)\nprint(x[22662] == x[97974])\n</code></pre>\n<p><code>TRUE</code> is output!</p>\n<p>If I use, e.g., <code>RNGkind(kind=&quot;Knuth-TAOCP-2002&quot;)</code> similarly happens: I get &quot;only&quot; 99 995 different values in <code>x</code>. Given the periods of both random generators, the results seem highly unlikely.</p>\n<p>Am I doing something wrong? I need to generate at least one million random numbers.</p>\n<p>I am using Windows 8.1 with R version 3.6.2; Platform: x86_64-w64-mingw32/x64 (64-bit) and RStudio 1.2.5033.</p>\n<hr />\n<p>Additional findings:</p>\n<ol>\n<li>Having a bag with <span class=\"math-container\">$n$</span> different balls, we choose a ball <span class=\"math-container\">$m$</span> times and put it back every time. The probability <span class=\"math-container\">$p_{n, m}$</span> that all chosen balls are different is equal to <span class=\"math-container\">${n\\choose m} / (n^m m!)$</span>.</li>\n<li>R documentation points to a link where the implementation of Mersenne-Twister for 64-bit machines is available: <a href=\"http://www.math.sci.hiroshima-u.ac.jp/%7Em-mat/MT/emt64.html\" rel=\"nofollow noreferrer\">http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt64.html</a></li>\n</ol>\n<p>The uniform sampling from <span class=\"math-container\">$[0, 1]$</span> interval is obtained via choosing a random 64-bit integer first, so I computed the above probabilities for the 64-bit and (when <span class=\"math-container\">$p_{2^{64}, 10^5}$</span> turned out to be rather low) 32-bit case:\n<span class=\"math-container\">$$\np_{2^{64}, 10^5}\\doteq 0.9999999999972... \\qquad p_{2^{32}, 10^5} \\doteq 0.3121...\n$$</span></p>\n<p>Then, I tried 1000 random seeds and compute the proportion of the cases when all generated numbers are different: 0.303.</p>\n<p>So, currently, I assume that for some reason, 32-bit integers are actually used.</p>\n", "pids": ["5fae6eb9d4150a363ceddb2d"], "flag": 1}
{"question": "How can we explain the &quot;bad reputation&quot; of higher-order polynomials?", "body": "<p>We all must have heard it by now - when we start learning about statistical models overfitting data, the first example we are often given is about &quot;polynomial functions&quot; (e.g., see the picture <a href=\"https://ardianumam.wordpress.com/2017/09/22/deriving-polynomial-regression-with-regularization-to-avoid-overfitting/\" rel=\"noreferrer\">here</a>):</p>\n<p><a href=\"https://i.stack.imgur.com/L2ApS.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/L2ApS.png\" alt=\"Enter image description here\" /></a></p>\n<p>We are warned that although higher-degree polynomials can fit training data quite well, they surely will overfit and generalize poorly to the test data.</p>\n<p>Why does this happen? Is there a mathematical justification as to why (higher-degree) polynomial functions overfit the data? The closest explanation I could find online was something called <a href=\"https://en.wikipedia.org/wiki/Runge%27s_phenomenon\" rel=\"noreferrer\">&quot;Runge's phenomenon&quot;</a>, which suggests that higher-order polynomials tend to &quot;oscillate&quot; a lot - does this explain why polynomial functions are known to overfit data?</p>\n<p>I understand that there is a whole field of &quot;regularization&quot; that tries to fix these overfitting problems (e.g., penalization can prevent a statistical model from &quot;hugging&quot; the data too closely) - but just using mathematical intuition, why are polynomials known to overfit the data?</p>\n<p>In general, &quot;functions&quot; (e.g., the response variable you are trying to predict using <a href=\"https://en.wikipedia.org/wiki/Machine_learning\" rel=\"noreferrer\">machine learning</a> algorithms) can be approximated using older methods like <a href=\"https://en.wikipedia.org/wiki/Fourier_series\" rel=\"noreferrer\">Fourier series</a>, <a href=\"https://en.wikipedia.org/wiki/Taylor_series\" rel=\"noreferrer\">Taylor series</a> and newer methods like <a href=\"https://en.wikipedia.org/wiki/Artificial_neural_network\" rel=\"noreferrer\">neural networks</a>. I believe that there are theorems that guarantee that Taylor series, polynomials and neural networks can &quot;arbitrarily approximate&quot; any function. Perhaps neural networks can promise smaller errors for simpler complexity?</p>\n<p>But are there mathematical reasons behind higher-order polynomials (e.g., polynomial regression) being said to have a bad habit of overfitting, to the extent that they have become very unpopular? Is this solely explainable by Runge's phenomenon?</p>\n<p><strong>Reference:</strong></p>\n<p>Gelman, A. and Imbens, G. (2019) <a href=\"https://www.tandfonline.com/doi/abs/10.1080/07350015.2017.1366909\" rel=\"noreferrer\">Why high order polynomials should not be used in regression discontinuity designs</a>. <em>Journal of Business and Economic Statistics</em> <strong>37(3)</strong>, pp. 447-456. (An NBER working paper version is available <a href=\"https://www.nber.org/system/files/working_papers/w20405/w20405.pdf\" rel=\"noreferrer\">here</a>)</p>\n", "pids": ["53e9b9a6b7602d9704594df9"], "flag": 1}
{"question": "Is computer science a branch of mathematics?", "body": "<p>I have been wondering, is computer science a branch of mathematics? No one has ever adequately described it to me. It all seems very math-like to me. My second question is, are there any books about computer science/programming that are very rigorous and take an axiomatic approach? Basically, putting computer science and programming on a rigorous foundation.</p>\n", "pids": ["53e99d04b7602d97025b6467"], "flag": 0}
{"question": "What is the geometric interpretation of the transpose?", "body": "<p>I can follow the definition of the transpose algebraically, i.e. as a reflection of a matrix across its diagonal, or in terms of dual spaces, but I lack any sort of geometric understanding of the transpose, or even symmetric matrices.</p>\n\n<p>For example, if I have a linear transformation, say on the plane, my intuition is to visualize it as some linear distortion of the plane via scaling and rotation. I do not know how this distortion compares to the distortion that results from applying the transpose, or what one can say if the linear transformation is symmetric. Geometrically, why might we expect orthogonal matrices to be combinations of rotations and reflections?</p>\n", "pids": ["56d84ae7dabfae2eeed4e4a0"], "flag": 0}
{"question": "Are there any series whose convergence is unknown?", "body": "<p>Are there any infinite series about which we don't know whether it converges or not? Or are the convergence tests exhaustive, so that in the hands of a competent mathematician any series will eventually be shown to converge or diverge?</p>\n<p>EDIT: People were kind enough to point out that without imposing restrictions on the terms it's trivial to find such &quot;open problem&quot; sequences. So, to clarify, what I had in mind were sequences whose terms are composed of &quot;simple&quot; functions, the kind you would find in an introductory calculus text: exponential, factorial, etc.</p>\n", "pids": ["5df755b93a55ac545fca4523"], "flag": 0}
{"question": "The &quot;Amazing Hidden Power&quot; of Random Search?", "body": "<p><strong>I have the following question that compares random search optimization with gradient descent optimization:</strong></p>\n<p>Based on the (amazing) answer provided over here <a href=\"https://stats.stackexchange.com/questions/193306/optimization-when-cost-function-slow-to-evaluate\">Optimization when Cost Function Slow to Evaluate</a> , I realized something really interesting about Random Search:</p>\n<blockquote>\n<h1>Random Search</h1>\n<p>Even when the cost function is expensive to evaluate, random search\ncan still be useful. Random search is dirt-simple to implement. The\nonly choice for a researcher to make is setting the the <em>probability</em>\n<span class=\"math-container\">$p$</span> that you want your results to lie in some <em>quantile</em> <span class=\"math-container\">$q$</span>; the rest\nproceeds automatically using results from basic probability.</p>\n<p>Suppose your quantile is <span class=\"math-container\">$q = 0.95$</span> and you want a <span class=\"math-container\">$p=0.95$</span>\nprobability that the model results are in top <span class=\"math-container\">$100\\times (1-q)=5$</span>\npercent of all hyperparameter tuples. The probability that all <span class=\"math-container\">$n$</span>\nattempted tuples are <strong>not</strong> in that window is <span class=\"math-container\">$q^n = 0.95^n$</span> (because\nthey are chosen independently at random from the same distribution),\nso the probability that <em>at least one</em> tuple is in that region is <span class=\"math-container\">$1 - 0.95^n$</span>. Putting it all together, we have</p>\n<p><span class=\"math-container\">$$ 1 - q^n \\ge p \\implies n \\ge \\frac{\\log(1 - p)}{\\log(q)} $$</span></p>\n<p>which in our specific case yields <span class=\"math-container\">$n \\ge 59$</span>.</p>\n<p>This result is why most people recommend <span class=\"math-container\">$n=60$</span> attempted tuples for\nrandom search. It's worth noting that <span class=\"math-container\">$n=60$</span> is comparable to the\nnumber of experiments required to get good results with Gaussian\nprocess-based methods when there are a moderate number of parameters.\nUnlike Gaussian processes, the number of queries tuples does not\nchange with the number of hyperparameters to search over; indeed, for\na large number of hyperparameters, a Gaussian process-based method can\ntake many iterations to make headway.</p>\n<p>Since you have a probabilistic characterization of how good the\nresults are, this  result can be a persuasive tool to convince your\nboss that running additional experiments will yield diminishing\nmarginal returns.</p>\n</blockquote>\n<p>Using random search, you can mathematically show that:  <strong>regardless of how many dimensions your function has, there is a 95% probability that only 60 iterations are needed to obtain an answer in the top 5% of all possible solutions!</strong></p>\n<ul>\n<li><p>Suppose there are 100 possible solutions to your optimization function (this does not depend on the number of dimensions). An example of a solution is <span class=\"math-container\">$(X_1 = x_1, X_2 = x_2.... X_n = x_n)$</span>.</p>\n</li>\n<li><p>The top 5% of solutions will include the top 5 solutions (i.e. the 5 solutions that provide the 5 lowest values of the function you want to optimize)</p>\n</li>\n<li><p>The probability of at least encountering one of the top 5 solutions in &quot;<span class=\"math-container\">$n$</span> iterations&quot; :  <span class=\"math-container\">$\\boldsymbol{1 - [(1 - 5/100)^n]}$</span></p>\n</li>\n<li><p>If you want this probability <span class=\"math-container\">$= 0.95$</span>, you can solve for <span class=\"math-container\">$n$</span>: $\\boldsymbol{1 - [(1 - 5/100)^n] = 0.95}</p>\n</li>\n<li><p>Thus, <strong><span class=\"math-container\">$\\boldsymbol{n = 60}$</span> iterations!</strong></p>\n</li>\n</ul>\n<p>But the fascinating thing is, <span class=\"math-container\">$\\boldsymbol{n = 60}$</span> <strong>iterations</strong>  is still valid regardless of how many solutions exist. For instance, even if 1,000,000,000 solutions exist – you still only need 60 iterations to ensure a 0.95 probability of encountering a solution in the top 5% of all solutions!</p>\n<ul>\n<li><p><span class=\"math-container\">$\\boldsymbol{1 - [(1 - ( (0.05 \\times 1000000000) /1000000000 )^{n} )] = 0.95}$</span></p>\n</li>\n<li><p><strong>&quot;<span class=\"math-container\">$\\boldsymbol{n}$</span>&quot; will still be 60 iterations!</strong></p>\n</li>\n</ul>\n<p><strong>My Question:</strong> Based on this amazing &quot;hidden power&quot; of random search, and further taking into consideration that random search is much faster than gradient descent since random search does not require you to calculate the derivatives of multidimensional complex loss functions (e.g., neural networks) : <strong>Why do we use gradient descent instead of random search for optimizing the loss functions in neural networks?</strong></p>\n<p>The only reason that I can think of, is that if the ranked distribution of the optimization values are &quot;heavily negative skewed&quot;, then the top 1% might be significantly better than the top 2%–5%, and the amount of iterations required to encounter a solution in the top 1% will also be significantly larger:</p>\n<p><a href=\"https://i.stack.imgur.com/U4FRR.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/U4FRR.png\" alt=\"enter image description here\" /></a></p>\n<p>But even with such a distribution of optimization scores, would gradient descent still have its advantages? Does gradient descent (or stochastic gradient descent) really have the ability to compete with this &quot;hidden power&quot; of random search? If certain conditions are met, due to its attractive theoretical properties (e.g., convergence) – does gradient descent have the ability to reach the best solution (not best 5%, but the best solution) much faster than random search? Or in real life applications with non-convex and noisy objective functions, do these &quot;attractive theoretical properties&quot; of gradient descent generally not apply, and once again – the &quot;amazing hidden power&quot; of random search wins again?</p>\n<p><strong>In short :  Based on this amazing &quot;hidden power&quot; (and speed) of random search, why do we use gradient descent instead of random search for optimizing the loss functions in neural networks?</strong></p>\n<p>Can someone please comment on this?</p>\n<p><strong>Note:</strong> Based on the sheer volume of literature which insists and praises the ability of stochastic gradient descent, I am assuming that stochastic gradient descent does have many advantages compared to random search.</p>\n<p><strong>Note:</strong> Related Question that resulted from an answer provided to this question: <a href=\"https://stats.stackexchange.com/questions/561528/no-free-lunch-theorem-and-random-search\">No Free Lunch Theorem and Random Search</a></p>\n", "pids": ["5c75755bf56def97989e3bd4", "5ce3af3dced107d4c65f2ce3", "5ac1829d17c44a1fda918142", "58437725ac44360f1082fb93"], "flag": 1}
{"question": "A math contest problem $\\int_0^1\\ln\\left(1+\\frac{\\ln^2x}{4\\,\\pi^2}\\right)\\frac{\\ln(1-x)}x \\ \\mathrm dx$", "body": "<p>A friend of mine sent me a math contest problem that I am not able to solve (he does not know a solution either). So, I thought I might ask you for help.</p>\n\n<blockquote>\n  <p>Prove:\n  $$\\int_0^1\\ln\\left(1+\\frac{\\ln^2x}{4\\,\\pi^2}\\right)\\frac{\\ln(1-x)}x dx=-\\pi^2\\left(4\\,\\zeta'(-1)+\\frac23\\right).$$</p>\n</blockquote>\n", "pids": ["53e9aa32b7602d97033a0825"], "flag": 0}
{"question": "Why does Bayesian Optimization perform poorly in more than 20 Dimensions?", "body": "<p>I have been studying <strong>Bayesian Optimization</strong> lately and made the following notes about this topic:</p>\n<ul>\n<li><p>Unlike deterministic functions, real world functions are constructed using physical measurements</p>\n</li>\n<li><p>Measurements can always have error (e.g. human error,  design and experiment error, random error, measurement error) - if you record the same measurements at the same conditions but at a future time, it's very likely that these measurements might be different from the previous measurements</p>\n</li>\n<li><p>Thus, an objective function that is based on physical measurements is naturally &quot;unstable&quot; - two people might record the same measurements, end up with different values, and as a result end up with two different objective functions.</p>\n</li>\n<li><p>A &quot;noisy&quot; function is also an &quot;unstable&quot; function - if we were top optimize this &quot;noisy function&quot;, the optimization results might not correspond to natural system we are studying due to inherent errors while recording measurements. This means that in some sense, we are dealing with a more complicated version of &quot;apples and oranges&quot;.</p>\n</li>\n<li><p>Bayesian Optimization attempts to solve this problem by using the recorded measurements as &quot;pegs&quot; and fitting a &quot;circus tent&quot; over these measurements through the form of a Gaussian Process. This sort of acts like &quot;probabilistic smoothing&quot; and tries to statistically account for all possible uncaptured variations in the measurements that exist - provided the assumption of the &quot;data generating process&quot; being well represented by a Gaussian Process is somewhat true.</p>\n</li>\n<li><p>Thus, Bayesian Optimization tries to &quot;smoothens out&quot; the noise/variation/error in the objective function,  adding a natural &quot;robustness&quot; to the final optimization solution. All this means is that Bayesian Optimization has the potential to give us better results.</p>\n</li>\n</ul>\n<p><strong>Advantages of Bayesian Optimization:</strong></p>\n<ul>\n<li>Robustness (as descibed above)</li>\n<li>Does not require the objective function to be differentiable (i.e. useful in discrete and combinatorial optimization problems)</li>\n<li>Since it does not calculate the derivative, it has the potential to be more &quot;computationally efficient&quot; compared to gradient based optimization methods.</li>\n</ul>\n<p><strong>Disadvantages of Bayesian Optimization:</strong></p>\n<ul>\n<li>Requires the true objective function to be well modelled by a Gaussian Process</li>\n<li><strong>Empirically has been observed to perform poorly on high dimensional objective functions (i.e. higher than 20 dimensions) - however, I don't understand why.</strong></li>\n</ul>\n<p>I have often heard this claim being made about Bayesian Optimization performing poorly in more than 20 dimensions, but I have never been able to understand why this is. I tried to consult some references online:</p>\n<p><strong>1)</strong> <strong>&quot;High-Dimensional Bayesian Optimization with Sparse\nAxis-Aligned Subspaces&quot; (Eriksson et al 2021)</strong></p>\n<ul>\n<li><p><em>&quot;High-dimensional BO presents a particular challenge, in part because the curse of dimensionality makes it difficult to define—as well as do inference over—a suitable class of surrogate models.&quot;</em></p>\n</li>\n<li><p><em>&quot;While BO has become a workhorse algorithm that is employed in a wide variety of settings, successful applications are often limited to low-dimensional problems, e.g. fewer\nthan twenty dimensions [Frazier, 2018]. Applying BO to high-dimensional problems remains a significant challenge. The difficulty can be traced to both of the algorithm components mentioned above, although we postulate that suitable function priors are especially important for good performance. In particular, in order for BO to be sample-efficient in high-dimensional spaces, it is crucial to define surrogate models that are sufficiently parsimonious that they can be inferred from a small number of query points. An overly\nflexible class of models is likely to suffer from overfitting, which severely limits its effectiveness in decision-making. Likewise, an overly rigid class of models is unlikely to\ncapture enough features of the objective function. A compromise between flexibility and parsimony is essential.&quot;</em></p>\n</li>\n</ul>\n<p><strong>2)</strong> &quot;<strong>High-dimensional Bayesian optimization using low-dimensional feature spaces&quot; (Moriconi et al, 2020)</strong></p>\n<ul>\n<li><em>&quot;However, BO (Bayesian Optimization) is practically limited to optimizing 10–20 parameters. To scale BO to high dimensions,\nwe usually make structural assumptions on the decomposition of the objective\nand/or exploit the intrinsic lower dimensionality of the problem, e.g. by using\nlinear projections. We could achieve a higher compression rate with nonlinear\nprojections, but learning these nonlinear embeddings typically requires much\ndata. This contradicts the BO objective of a relatively small evaluation budget.&quot;</em></li>\n</ul>\n<p><strong>3)</strong> <strong>&quot;A Tutorial on Bayesian Optimization&quot; (Frazier, 2018)</strong></p>\n<ul>\n<li><p><em>&quot;It (Bayesian Optimization) is best-suited for optimization over continuous domains of less than 20&quot;</em></p>\n</li>\n<li><p><em>&quot;The input x is in R-d for a value of d that is not too large. Typically d ≤ 20 in most successful applications of BayesOpt.&quot;</em></p>\n</li>\n</ul>\n<p><strong>My Question :</strong> No where in these papers do they explain why &quot;20 Dimensions&quot; seems to be a relevant threshold for deciding the conditions in which the performance of Bayesian Optimization begins to deteriorate.</p>\n<ul>\n<li><p>Can someone please explain why &quot;20 Dimensions&quot; is said to be the maximum threshold for Bayesian Optimization?</p>\n</li>\n<li><p>Even though some explanations are provided that explain the difficulty of Bayesian Optimization in higher dimensions - can someone please help me understand this in more detail?</p>\n</li>\n</ul>\n<p><strong>References:</strong><br/>\n<a href=\"https://arxiv.org/abs/2103.00349\" rel=\"noreferrer\">High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces</a> (<a href=\"https://arxiv.org/pdf/2103.00349.pdf\" rel=\"noreferrer\">PDF</a>)<br/>\n<a href=\"https://arxiv.org/abs/1807.02811\" rel=\"noreferrer\">A Tutorial on Bayesian Optimization</a> (<a href=\"https://arxiv.org/pdf/1807.02811.pdf\" rel=\"noreferrer\">PDF</a>)<br/>\n<a href=\"https://arxiv.org/abs/1902.10675\" rel=\"noreferrer\">High-dimensional Bayesian optimization using low-dimensional feature spaces</a> (<a href=\"https://arxiv.org/pdf/1902.10675.pdf\" rel=\"noreferrer\">PDF</a>)</p>\n", "pids": ["618b38575244ab9dcb710df2"], "flag": 1}
{"question": "What were some major mathematical breakthroughs in 2016?", "body": "<p>As the year is slowly coming to an end, I was wondering which great advances have there been in mathematics in the past 12 months. As researchers usually work in only a limited number of fields in mathematics, one often does not hear a lot of news about advances in other branches of mathematics. A person who works in complex analysis might not be aware of some astounding advances made in probability theory, for example. Since I am curious about other fields as well, even though I do not spend a lot of time reading about them, I wanted to hear about some major findings in distinct fields of mathematics. </p>\n\n<p>I know that the question posed by me does not allow a unique answer since it is asked in broad way. However, there are probably many interesting advances in all sorts of branches of mathematics that have been made this year, which I might have missed on and I would like to hear about them. Furthermore, I think it is sensible to get a nice overview about what has been achieved this year without digging through thousands of different journal articles. </p>\n", "pids": ["5c61097cda56297340b7b679", "5c756a69f56def9798338b9d"], "flag": 0}
{"question": "Are Italians genetically separated from other Europeans?", "body": "<p>I was reading the Wikipedia article about the <a href=\"http://en.wikipedia.org/wiki/Genetic_history_of_Italy\" rel=\"nofollow noreferrer\">genetic history of Italy</a>, and I found it interesting. There are, however, a few things that puzzle me, because they seem to contradict each other.</p>\n<p>For example, it states that, because of the Alps forming a natural barrier, Italy is, along with Finland, a genetic island in Europe. Does this mean Italians and Finns are genetically separated from all other Europeans, and to what extent?</p>\n<p>Later in the same article it says that</p>\n<blockquote>\n<p>In Italy as elsewhere in Europe the most common haplogroup is haplogroup H</p>\n</blockquote>\n<p>which would seem to contradict the genetic island theory. After all, Italy has been colonized by countless populations throughout its history, which might suggest the Alps didn't really stop the gene flow from neighboring countries (not to mention that other European countries are equally separated by mountains, like Spain).</p>\n<p>I have no background in genetics whatsoever, so please excuse my ignorance. I am just trying to understand an article that seems very confusing and throws lots of different information together.</p>\n<hr />\n<p><strong>EDIT</strong>: Thanks for the quick reply! I've found <a href=\"http://www.nytimes.com/2008/08/13/science/13visual.html\" rel=\"nofollow noreferrer\">another link</a>, which seems to be more reliable than Wikipedia's unverified claim, though it still sounds like a weird theory to me.</p>\n", "pids": ["56d9282edabfae2eeec7ed11"], "flag": 1}
{"question": "Open problems in General Relativity", "body": "<p>I would like to know if there are some open mathematical problems in General Relativity, that are important from the point of view of Physics. </p>\n\n<p>Is there something that still needs to be justified mathematically in order to have solid foundations? </p>\n", "pids": ["56d901f5dabfae2eeedd6580", "5c7569c8f56def97982d2cb9"], "flag": 0}
{"question": "Evaluate $\\int_0^1 \\frac{\\log \\left( 1+x^{2+\\sqrt{3}}\\right)}{1+x}\\mathrm dx$", "body": "<p>I am trying to find a closed form for</p>\n\n<p>$$\\int_0^1 \\frac{\\log \\left( 1+x^{2+\\sqrt{3}}\\right)}{1+x}\\mathrm dx = 0.094561677526995723016 \\cdots$$</p>\n\n<p>It seems that the answer is\n$$\\frac{\\pi^2}{12}\\left( 1-\\sqrt{3}\\right)+\\log(2) \\log \\left(1+\\sqrt{3} \\right)$$</p>\n\n<p>Mathematica is unable to give a closed form for the indefinite integral.</p>\n\n<p>How can we prove this result? Please help me.</p>\n\n<p><strong>EDIT</strong></p>\n\n<p>Apart from this result, the following equalities are also known to exist:\n$$\\begin{align*}\n\\int_0^1 \\frac{\\log \\left( 1+x^{4+\\sqrt{15}}\\right)}{1+x}\\mathrm dx &amp;=\\frac{\\pi^2}{12} \\left( 2-\\sqrt{15}\\right)+\\log \\left( \\frac{1+\\sqrt{5}}{2}\\right)\\log \\left(2+\\sqrt{3} \\right) \\\\ &amp;\\quad +\\log(2)\\log\\left( \\sqrt{3}+\\sqrt{5}\\right)\n\\\\ \\int_0^1 \\frac{\\log \\left( 1+x^{6+\\sqrt{35}}\\right)}{1+x}\\mathrm dx &amp;= \\frac{\\pi^2}{12} \\left( 3-\\sqrt{35}\\right)+\\log \\left(\\frac{1+\\sqrt{5}}{2} \\right)\\log \\left(8+3\\sqrt{7} \\right) \\\\\n&amp;\\quad +\\log(2) \\log \\left( \\sqrt{5}+\\sqrt{7}\\right)\n\\end{align*}$$</p>\n\n<p>Please take a look <a href=\"http://tieba.baidu.com/p/1700279486?pn=1\">here</a>.</p>\n", "pids": ["53e9b655b7602d97041b5fad"], "flag": 0}
{"question": "How to prove: if $a,b \\in \\mathbb N$, then $a^{1/b}$ is an integer or an irrational number?", "body": "<p>It is well known that <span class=\"math-container\">$\\sqrt{2}$</span> is irrational, and by modifying the proof (replacing 'even' with 'divisible by <span class=\"math-container\">$3$</span>'), one can prove that <span class=\"math-container\">$\\sqrt{3}$</span> is irrational, as well.  On the other hand, clearly <span class=\"math-container\">$\\sqrt{n^2} = n$</span> for any positive integer <span class=\"math-container\">$n$</span>.  It seems that any positive integer has a square root that is either an integer or irrational number.</p>\n\n<blockquote>\n  <ol>\n  <li>How do we prove that if <span class=\"math-container\">$a \\in  \\mathbb N$</span>, then <span class=\"math-container\">$\\sqrt a$</span> is an integer or an irrational number?</li>\n  </ol>\n</blockquote>\n\n<p>I also notice that I can modify the proof that <span class=\"math-container\">$\\sqrt{2}$</span> is irrational to prove that <span class=\"math-container\">$\\sqrt[3]{2}, \\sqrt[4]{2}, \\cdots$</span> are all irrational.  This suggests we can extend the previous result to other radicals.</p>\n\n<blockquote>\n  <ol start=\"2\">\n  <li>Can we extend 1? That is, can we show that for any <span class=\"math-container\">$a, b \\in \\mathbb{N}$</span>, <span class=\"math-container\">$a^{1/b}$</span> is either an integer or irrational?</li>\n  </ol>\n</blockquote>\n", "pids": ["53e99aa6b7602d970231e980"], "flag": 0}
{"question": "How much cost would artificial pollination add to common products (fruits etc.)?", "body": "<p>I've read about ecosystem services and their possible valuation - statements like \"honeybee pollination service in the US is worth 1.6 billion dollars\".</p>\n\n<p>Is data available on how this would affect the cost a consumer pays for a given product? For example if the humans must do all pollination of fruits themselves, how would that affect the retail cost of these fruit?</p>\n", "pids": ["56d92895dabfae2eeeca127e", "55a4a671c91bf3b1cc4245d4"], "flag": 1}
{"question": "Examples of mathematical discoveries which were kept as a secret", "body": "<p>There could be several personal, social, philosophical and even political reasons to keep a mathematical discovery as a secret. </p>\n\n<p>For example it is completely expected that if some mathematician find a proof of $P=NP$, he is not allowed by the government to publish it as same as a usual theorem in a well-known public journal because of high importance and possible uses of this special proof in breaking security codes which gives an undeniable upper hand to the state intelligence services with respect to other countries. Also by some social reasons publishing such a proof publicly is not suitable because many hackers and companies may use it to access confidential information which could make a total chaos in the community and economy. </p>\n\n<p>The example shows that in principle it is possible to have some very significant brilliant mathematical proofs by some genius mathematicians which we are not even aware of. But in some cases these \"secrets\" unfold by an accident or just because they lost their importance when some time passed and the situation changed.</p>\n\n<blockquote>\n  <p><strong>Question:</strong> What are examples of mathematical discoveries which were kept as a secret when they discovered and then became unfolded after a while by any reasons?</p>\n</blockquote>\n", "pids": ["53e9b0d1b7602d9703b480d9"], "flag": 0}
{"question": "Some users are mind bogglingly skilled at integration. How did they get there?", "body": "<p>Looking through old problems, it is not difficult to see that some users are beyond incredible at computing integrals. It only took a couple seconds to dig up an example like <a href=\"https://math.stackexchange.com/questions/562694/integral-int-11-frac1x-sqrt-frac1x1-x-ln-left-frac2-x22-x1\">this</a>.</p>\n\n<p>Especially in a world where most scientists compute their integrals numerically, I find it astounding that people exist that can solve these problems analytically. Sometimes it is a truly bizarre contour, some examples use auxiliary functions and differentiation under the integral sign in a way that feels more like integration by wizardry.</p>\n\n<p>Some of these users seem to have mastered an incredibly large number of special functions to a level of fluency that is almost unimaginable to me. Manipulations involving the error function almost looks like the work of an infant compared to some of these seemingly casual manipulations involving the Airy function, Barnes G function, the Legendre chi function and many more. Every time I read a post by them, it turns into an exercise in reading about yet another special function I have never heard of. </p>\n\n<p>My question is what sort of material do you have to study, or what kind of area do you have to work in to get so good? To me, it doesn't seem as obvious as saying something like, \"oh, they know this material because they are a topologist\". </p>\n", "pids": ["53e9b30ab7602d9703dd06e1", "5cc82305ced107d4c60820ab", "56d8512fdabfae2eee0408ca"], "flag": 0}
{"question": "Are there any open mathematical puzzles?", "body": "<p>Are there any (mathematical) puzzles that are still unresolved? I only mean questions that are accessible to and understandable by the complete layman and which have not been solved, despite serious efforts, by mathematicians (or laymen for that matter)?</p>\n\n<p>My question does not ask for puzzles that have been shown to have either no solution or multiple solutions (or have been shown to be ambiguously formulated).</p>\n", "pids": ["53e9b123b7602d9703ba0260"], "flag": 0}
{"question": "Which one result in mathematics has surprised you the most?", "body": "<p>A large part of my fascination in mathematics is because of some very surprising results that I have seen there.</p>\n\n<p>I remember one I found very hard to swallow when I first encountered it, was what is known as the <a href=\"http://en.wikipedia.org/wiki/Banach%E2%80%93Tarski_paradox\">Banach Tarski Paradox</a>. It states that you can separate a ball $x^2+y^2+z^2 \\le 1$ into finitely many disjoint parts, rotate and translate them and rejoin (by taking <em>disjoint</em> union), and you end up with exactly two complete balls of the same radius!</p>\n\n<p>So I ask you which are your most surprising moments in maths?</p>\n\n<ul>\n<li>Chances are you will have more than one. May I request post multiple answers in that case, so the voting system will bring the ones most people think as surprising up. Thanks!</li>\n</ul>\n", "pids": ["53e9b428b7602d9703f1fb76", "53e9a05fb7602d97029425ae", "53e9b153b7602d9703bd9763"], "flag": 0}
{"question": "What&#39;s new in higher dimensions?", "body": "<p><em>This is a very speculative/soft question; please keep this in mind when reading it. Here \"higher\" means \"greater than 3\".</em></p>\n\n<p>What I am wondering about is what <em>new</em> geometrical phenomena are there in higher dimensions. When I say new I mean phenomena which are counterintuitive or not analogous to their lower dimensional counterparts. A good example could be <a href=\"http://mathworld.wolfram.com/HyperspherePacking.html\" rel=\"noreferrer\">hypersphere packing</a>.</p>\n\n<p>My main (and sad) impression is that almost all phenomena in higher dimensions could be thought intuitively by dimensional analogy. See for example, <a href=\"http://eusebeia.dyndns.org/4d/vis/10-rot-1\" rel=\"noreferrer\">this link</a>:</p>\n\n<p><a href=\"https://i.stack.imgur.com/Tk7J4.gif\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/Tk7J4.gif\" alt=\"Rotation of a 3-cube in the YW plane\"></a></p>\n\n<p>What this implies (for me) is the boring consequence that there is no new conceptual richness in higher dimensional geometry beyond the fact than the  numbers are larger (for example my field of study is string compactifications and though, at first sight, it could sound spectacular to use orientifolding which set a loci of fixed points which are O3 and O7 planes; the reasoning is pretty much the same as in lower dimensions...)</p>\n\n<p>However the question of higher dimensional geometry is very related (for me) to the idea of beauty and complexity: these projections to 2-D of higher dimensional objects totally amazes me (for example this orthonormal projection of a <a href=\"https://i.pinimg.com/originals/a3/ac/9f/a3ac9fdf2dd062ebf4e9fab843ddf1c4.jpg\" rel=\"noreferrer\">12-cube</a>) and makes me think there must be interesting higher dimensional phenomena...</p>\n\n<p><a href=\"https://i.stack.imgur.com/jU5pes.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/jU5pes.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>I would thank anyone who could give me examples of beautiful ideas implying “visualization” of higher dimensional geometry…</p>\n", "pids": ["5c756933f56def97982704e3"], "flag": 0}
{"question": "Why is the eigenvector of a covariance matrix equal to a principal component?", "body": "<p>If I have a covariance matrix for a data set and I multiply it times one of it's eigenvectors.  Let's say the eigenvector with the highest eigenvalue.  The result is the eigenvector or a scaled version of the eigenvector.  </p>\n\n<p>What does this really tell me?  Why is this the principal component?  What property makes it a principal component?  Geometrically, I understand that the principal component (eigenvector) will be sloped at the general slope of the data (loosely speaking).  Again, can someone help understand why this happens?  </p>\n", "pids": ["53e9bac2b7602d97046f1a00"], "flag": 0}
{"question": "Simple theorems that are instances of deep mathematics", "body": "<p>So, <a href=\"https://math.stackexchange.com/questions/2217868/how-important-is-it-to-remember-computational-tricks-as-a-pure-mathematician/2217916#2217916\">this</a> question asks about how useful computational tricks are to mathematics research, and several people's response was &quot;well, computational tricks are often super cool theorems in disguise.&quot; So what &quot;computational tricks&quot; or &quot;easy theorems&quot; or &quot;fun patterns&quot; turn out to be important theorems?</p>\n<p>The ideal answer to this question would be a topic that can be understood at two different levels that have a great gulf in terms of sophistication between them, although the simplistic example doesn't have to be &quot;trivial.&quot;</p>\n<p>For example, the unique prime factorization theorem is often proven from the division algorithm through Bezout's lemma and the fact that <span class=\"math-container\">$p\\mid ab\\implies p\\mid a$</span> or <span class=\"math-container\">$p\\mid b$</span>. A virtually identical proof allows you to establish that every Euclidean Domain is a unique factorization domain, and the problem as a whole - once properly abstracted - gives rise to the notion of ideals and a significant amount of ring theory.</p>\n<p>For another example, it's well known that finite dimensional vector spaces are uniquely  determined by their base field and their dimension. However, a far more general theorem in Model Theory basically lets you say &quot;given a set of objects that have a dimension-like parameter that are situated in the right manner, every object with finite &quot;dimension&quot; is uniquely determined by its minimal example and the &quot;dimension.&quot; I don't actually quite remember the precise statement of this theorem, so if someone wants to explain in detail how vector spaces are a particular example of <span class=\"math-container\">$k$</span>-categorical theories for every finite <span class=\"math-container\">$k$</span> that would be great.</p>\n<p><strong>From the comments:</strong> In a certain sense I'm interested in the inverse question as <a href=\"https://mathoverflow.net/questions/42512/awfully-sophisticated-proof-for-simple-facts\">this</a> Math Overflow post. Instead of being interested in deep mathematics that produce horribly complicated proofs of simple ideas, I want simple ideas that contain within them, or generalize to, mathematics of startling depth.</p>\n", "pids": ["56d834addabfae2eee37d97b"], "flag": 0}
{"question": "Elementary proof that $\\mathbb{R}^n$ is not homeomorphic to $\\mathbb{R}^m$", "body": "<p>It is very elementary to show that $\\mathbb{R}$ isn't homeomorphic to $\\mathbb{R}^m$ for $m&gt;1$: subtract a point and use the fact that connectedness is a homeomorphism invariant.</p>\n\n<p>Along similar lines, you can show that $\\mathbb{R^2}$ isn't homeomorphic to $\\mathbb{R}^m$ for $m&gt;2$ by subtracting a point and checking if the resulting space is simply connected. Still straightforward, but a good deal less elementary.</p>\n\n<p>However, the general result that $\\mathbb{R^n}$ isn't homeomorphic to $\\mathbb{R^m}$ for $n\\neq m$, though intuitively obvious, is usually proved using sophisticated results from algebraic topology, such as invariance of domain or extensions of the Jordan curve theorem.</p>\n\n<p>Is there a more elementary proof of this fact? If not, is there intuition for why a proof is so difficult?</p>\n", "pids": ["56d83396dabfae2eee31b7c8"], "flag": 0}
{"question": "Proving an alternating Euler sum: $\\sum_{k=1}^{\\infty} \\frac{(-1)^{k+1} H_k}{k} = \\frac{1}{2} \\zeta(2) - \\frac{1}{2} \\log^2 2$", "body": "<p>Let $$A(p,q) = \\sum_{k=1}^{\\infty} \\frac{(-1)^{k+1}H^{(p)}_k}{k^q},$$\nwhere $H^{(p)}_n = \\sum_{i=1}^n i^{-p}$, the $n$th $p$-harmonic number.  The $A(p,q)$'s are known as <em>alternating <a href=\"http://mathworld.wolfram.com/EulerSum.html\" rel=\"noreferrer\">Euler sums</a></em>.</p>\n\n<blockquote>\n  <p>Can someone provide a nice proof that \n  $$A(1,1) = \\sum_{k=1}^{\\infty} \\frac{(-1)^{k+1} H_k}{k} = \\frac{1}{2} \\zeta(2) - \\frac{1}{2} \\log^2 2?$$</p>\n</blockquote>\n\n<p>I worked for a while on this today but was unsuccessful.  Summation by parts, swapping the order of summation, and approximating $H_k$ by $\\log k$ were my best ideas, but I could not get any of them to work.  (Perhaps someone else can?)  I would like a nice proof in order to complete <a href=\"https://math.stackexchange.com/questions/274742/evaluate-int-01-ln1-x-ln-x-ln1x-mathrmdx/275641#275641\">my answer here</a>.</p>\n\n<p>Bonus points for proving $A(1,2) = \\frac{5}{8} \\zeta(3)$ and $A(2,1) =  \\zeta(3) - \\frac{1}{2}\\zeta(2) \\log 2$, as those are the other two alternating Euler sums needed to complete my answer.</p>\n\n<p><HR>\n<strong>Added</strong>: I'm going to change the accepted answer to robjohn's $A(1,1)$ calculation as a proxy for the three answers he gave here.  Notwithstanding the other great answers (especially the currently most-upvoted one, the one I first accepted), robjohn's approach is the one I was originally trying.  I am pleased to see that it can be used to do the $A(1,1)$, $A(1,2)$, and $A(2,1)$ derivations.</p>\n", "pids": ["53e9b655b7602d97041b5fad"], "flag": 0}
{"question": "Why is $1$ not a prime number?", "body": "<p>Why is $1$ not considered a prime number?</p>\n\n<p>Or, why is the definition of prime numbers given for integers greater than $1$?</p>\n", "pids": ["56d89d38dabfae2eee480ecb"], "flag": 0}
{"question": "Is there any integral for the Golden Ratio?", "body": "<p>I was wondering about important/famous mathematical constants, like <span class=\"math-container\">$e$</span>, <span class=\"math-container\">$\\pi$</span>, <span class=\"math-container\">$\\gamma$</span>, and obviously the <a href=\"https://en.wikipedia.org/wiki/Golden_ratio\" rel=\"noreferrer\">golden ratio</a> <span class=\"math-container\">$\\phi$</span>.\nThe first three ones are really well known, and there are lots of integrals and series whose results are simply those constants. For example:</p>\n\n<p><span class=\"math-container\">$$ \\pi = 2 e \\int\\limits_0^{+\\infty} \\frac{\\cos(x)}{x^2+1}\\ \\text{d}x$$</span></p>\n\n<p><span class=\"math-container\">$$ e = \\sum_{k = 0}^{+\\infty} \\frac{1}{k!}$$</span></p>\n\n<p><span class=\"math-container\">$$ \\gamma = -\\int\\limits_{-\\infty}^{+\\infty} x\\ e^{x - e^{x}}\\ \\text{d}x$$</span></p>\n\n<p>Is there an interesting integral<sup>*</sup> (or some series) whose result is simply <span class=\"math-container\">$\\phi$</span>?</p>\n\n<p>* <em>Interesting integral</em> means that things like</p>\n\n<p><span class=\"math-container\">$$\\int\\limits_0^{+\\infty} e^{-\\frac{x}{\\phi}}\\ \\text{d}x$$</span></p>\n\n<p>are not a good answer to my question.</p>\n", "pids": ["53e9a7ddb7602d970311b599"], "flag": 0}
{"question": "Why is $\\infty \\cdot 0$ not clearly equal to $0$?", "body": "<p>I did a bit of math at school and it seems like an easy one - what am I missing?</p>\n\n<p><span class=\"math-container\">$$n\\times m = \\underbrace{n+n+\\cdots +n}_{m\\text{ times}}$$</span></p>\n\n<p><span class=\"math-container\">$$\\quad n\\times 0 = \\underbrace{0 + 0 + \\cdots+ 0}_{n\\text{ times}} = 0$$</span></p>\n\n<p>(i.e add <span class=\"math-container\">$0$</span> to <span class=\"math-container\">$0$</span> as many times as you like, result is <span class=\"math-container\">$0$</span>)</p>\n\n<p>So I thought an infinite number of <span class=\"math-container\">$0$</span>'s cannot be anything but <span class=\"math-container\">$0$</span>? But someone claims different but couldn't offer a reasonable explanation why. Google results seemed a bit iffy on the subject - hopefully this question will change that.</p>\n", "pids": ["56d903d0dabfae2eeee94e60"], "flag": 0}
{"question": "Good books and lecture notes about category theory.", "body": "<p>What are the best books and lecture notes on category theory?</p>\n", "pids": ["56d89901dabfae2eee27435f", "5e01e1d13a55ac7df0019645"], "flag": 0}
{"question": "How to find ${\\large\\int}_0^1\\frac{\\ln^3(1+x)\\ln x}x\\mathrm dx$", "body": "<p>Please help me to find a closed form for this integral:\n$$I=\\int_0^1\\frac{\\ln^3(1+x)\\ln x}x\\mathrm dx\\tag1$$\nI suspect it might exist because there are similar integrals having closed forms:\n$$\\begin{align}\\int_0^1\\frac{\\ln^3(1-x)\\ln x}x\\mathrm dx&amp;=12\\zeta(5)-\\pi^2\\zeta(3)\\tag2\\\\\n\\int_0^1\\frac{\\ln^2(1+x)\\ln x}x\\mathrm dx&amp;=\\frac{\\pi^4}{24}-\\frac16\\ln^42+\\frac{\\pi^2}6\\ln^22-\\frac72\\zeta(3)\\ln2-4\\operatorname{Li}_4\\!\\left(\\tfrac12\\right)\\tag3\\\\\n\\int_0^1\\frac{\\ln^3(1+x)\\ln x}{x^2}\\mathrm dx&amp;=\\frac34\\zeta(3)-\\frac{63}4\\zeta(3)\\ln2+\\frac{23\\pi^4}{120}\\\\&amp;-\\frac34\\ln^42-2\\ln^32+\\frac{3\\pi^2}4\\ln^22-18\\operatorname{Li}_4\\!\\left(\\tfrac12\\right).\\tag4\\end{align}$$\nThanks!</p>\n", "pids": ["53e99784b7602d9701f3e166"], "flag": 0}
{"question": "Is there a categorical definition of submetry?", "body": "<p>(Updated to include effective epimorphism.)</p>\n\n<blockquote>\n  <p>This question is prompted by the <a href=\"https://math.stackexchange.com/questions/169205/why-dont-analysts-do-category-theory\">recent discussion</a> of why analysts don't use category theory. It demonstrates what happens when an analyst tries to use category theory.</p>\n</blockquote>\n\n<p>Consider the category <strong>CpltMet</strong> in which the objects are <em>complete</em> metric spaces and morphisms are 1-Lipschitz maps; the maps $f:X\\to Y$ such that $d_Y(f(a),f(b))\\le d_X(a,b)$ for all $a,b\\in X$. Note that in this category monomorphisms are injective 1-Lipschitz maps, and epimorphisms are 1-Lipschitz maps with dense range, but not necessarily surjective. </p>\n\n<p>An isometric embedding is a map $f:X\\to Y$ such that $d_Y(f(a),f(b)) = d_X(a,b)$ for all $a,b\\in X$. I can describe such maps in the arrow-speak as follows. $f:X\\to Y$ is an isometric embedding iff the following holds: whenever $f$ factors through an epimorphism $g:X\\to Z$ (meaning $f=h\\circ g$ for some $h:Z\\to Y$), $g$ is an isomorphism. (Proof is given in Note 1.) If there is a better categorical description of isometric embeddings, I'd like to see it. </p>\n\n<p>A <strong>submetry</strong> is a map $f:X\\to Y$ such that for every $a\\in X$ and every $r\\ge 0$ we have $f(B_X(a,r))=B_Y(f(a),r)$ where $B$ denotes a closed ball. (See Note 2 about the definition). To appreciate this definition, consider the following. </p>\n\n<ul>\n<li>isometric embeddings are characterized by the condition $f^{-1}(B_Y(f(a),r))=B_X(a,r)$, mirroring the definition of submetry.</li>\n<li>among 1-Lipschitz maps, submetries are characterized by the 2-point lifting property:<br>\nfor every $y_0,y_1\\in Y$ and every $x_0\\in f^{-1}(y_0)$ there exists $x_1\\in f^{-1}(y_1)$ such that $d_X(x_0,x_1)=d_Y(y_0,y_1)$. </li>\n<li>for linear operators between Banach spaces, the adjoint of an isometric embedding is a submetry (the proof is an exercise with Hahn-Banach).  </li>\n</ul>\n\n<blockquote>\n  <p>My question is: can the submetries be defined categorically, preferably in a way that makes them a dual class to isometric embeddings?   </p>\n</blockquote>\n\n<p>The problem is that reversing the arrows in the above definition of an isometric embedding gives a wider class of maps than submetries. Indeed, the reversed definition is: $f:Y\\to X$  does not factor through any monomorphism $g:Z\\to X$ unless $g$ is an isomorphism. But this holds, for example, for the function $f:\\mathbb R\\to \\mathbb R$ defined by \n$$\n(*)\\qquad \\qquad  f(x)=\\begin{cases} x+1,\\quad &amp;x\\le -1 \\\\ 0,\\quad &amp;|x|\\le 1 \\\\ x-1,\\quad &amp;x\\ge 1\n\\end{cases}$$\nwhich is <strong>not</strong> a submetry in the standard metric of the real line. (See Note 3 for the proof.) Maybe I'm reversing arrows in a \"wrong\" description of isometric embeddings.</p>\n\n \n\n<p>Note 1. If $f$ preserves distances, then so does $g$; having dense range, $g$ must be onto because $X$ is complete; hence, $g$ is an isomorphism. Conversely, if $f$ decreases distances somewhere, let $Z$ be the same set as $X$ with the metric $(d_X(a,b)+d_Y(f(a),f(b)))/2$. The identity map $g:X\\to Z$ is an epimorphism, $f$ factors through it, but $g$ is not an isomorphism.</p>\n\n<p>Note 2. I am following the original definition of submetry given by Berestovskii (\"Submetries of space-forms of nonnegative curvature\", 1987). If one uses open balls instead of closed, the class is enlarged to <em>weak submetries</em>. In <em>Riemannian Geometry</em> by Petersen the term submetry is used for more general maps, which I would call weak local submetries. </p>\n\n<p>Note 3. Proof: Suppose $f=g\\circ h$ where $g: Z\\to \\mathbb R$ is a monomorphism. Then $h$ maps $[-1,1]$ into a single point $z\\in Z$. When $a\\le -1$ and $b\\ge 1$, the triangle inequality yields $d_Z(h(a),h(b))\\le |a-b|-2=|f(a)-f(b)|$. Hence, $g$ must be an isomorphism. </p>\n\n<p>Note 4. Following the immersion:submersion terminology of differential geometry, I'd like to call an isometric embedding an <em>immetry</em>, but I'm not sure that the neologism would catch on.</p>\n\n \n\n<p>Following the suggestion by @t.b., I considered the concept of an <a href=\"http://ncatlab.org/nlab/show/effective+epimorphism\" rel=\"noreferrer\">effective epimorphism</a>. Unfortunately, the undesirable map defined by (*) appears to be effective. Indeed, let $R=\\{(x,y)\\in\\mathbb R^2: f(x)=f(y)\\}$. The orthogonal projections $\\pi_x,\\pi_y : R\\to \\mathbb R$ are 1-Lipschitz and satisfy $f\\circ \\pi_x=f\\circ \\pi_y$ by construction. As far as I can tell, $\\pi_x$ and $\\pi_y$ qualify as a kernel pair for which $f$ is a coequalizer. </p>\n", "pids": ["5bbacbad17c44aecc4eb0126"], "flag": 0}
{"question": "Is $2048$ the highest power of $2$ with all even digits (base ten)?", "body": "<p>I have a friend who turned <span class=\"math-container\">$32$</span> recently.  She has an obsessive compulsive disdain for odd numbers, so I pointed out that being <span class=\"math-container\">$32$</span> was pretty good since not only is it even, it also has no odd factors.  That made me realize that <span class=\"math-container\">$64$</span> would be an even better age for her, because it's even, has no odd factors, and has no odd <em>digits</em>.  I then wondered how many other powers of <span class=\"math-container\">$2$</span> have this property.  The only higher power of <span class=\"math-container\">$2$</span> with all even digits that I could find was <span class=\"math-container\">$2048.$</span>  </p>\n\n<p>So is there a larger power of <span class=\"math-container\">$2$</span> with all even digits?  If not, how would you go about proving it?</p>\n\n<p>I tried examining the last <span class=\"math-container\">$N$</span> digits of powers of <span class=\"math-container\">$2$</span> to look for a cycle in which there was always at least one odd digit in the last <span class=\"math-container\">$N$</span> digits of the consecutive powers.  Unfortunately, there were always a very small percentage of powers of <span class=\"math-container\">$2$</span> whose last <span class=\"math-container\">$N$</span> digits were even.</p>\n\n<p><strong>Edit:</strong> Here's a little more info on some things I found while investigating the <span class=\"math-container\">$N$</span> digit cycles.</p>\n\n<p><span class=\"math-container\">$N$</span>: <span class=\"math-container\">$2,3,4,5,6,7,8,9$</span></p>\n\n<p>Cycle length: <span class=\"math-container\">$20,100,500,2500,12500,62520,312500,1562500,\\dotsc, 4\\cdot 5^{N-1}$</span></p>\n\n<p>Number of suffixes with all even digits in cycle: <span class=\"math-container\">$10, 25, 60, 150, 370, 925, 2310,5780,\\sim4\\cdot2.5^{N-1}$</span>  </p>\n\n<p>It seems there are some interesting regularities there.  Unfortunately, one of the regularities is those occurrences of all even numbers!  In fact, I was able to find a power of <span class=\"math-container\">$2$</span> in which the last <span class=\"math-container\">$33$</span> digits were even <span class=\"math-container\">$(2^{3789535319} = \\dots 468088628828226888000862880268288)$</span>. </p>\n\n<p>Yes it's true that it took a power of <span class=\"math-container\">$2$</span> with over a billion digits to even get the last <span class=\"math-container\">$33$</span> to be even, so it would seem any further powers of <span class=\"math-container\">$2$</span> with all even digits are extremely unlikely.  But I'm still curious as to how you might prove it.</p>\n\n<p><strong>Edit 2:</strong> Here's another interesting property I noticed.  The next digit to the left of the last <span class=\"math-container\">$N$</span> digits will take on every value of its parity as the <span class=\"math-container\">$N$</span> digits cycle each time.  Let me illustrate.</p>\n\n<p>The last <span class=\"math-container\">$2$</span> digits cycle every <span class=\"math-container\">$20$</span> powers.  Now examine the following:</p>\n\n<p><span class=\"math-container\">$2^7 =    128$</span><br>\n<span class=\"math-container\">$2^{27} = \\dots 728$</span><br>\n<span class=\"math-container\">$2^{47} = \\dots 328$</span><br>\n<span class=\"math-container\">$2^{67} = \\dots 928$</span><br>\n<span class=\"math-container\">$2^{87} = \\dots 528$</span><br>\n<span class=\"math-container\">$2^{107} = \\dots 128$</span>  </p>\n\n<p>Notice that the hundreds place starts out odd and then proceeds to take on every odd digit as the final 2 digits cycle.</p>\n\n<p>As another example, let's look at the fourth digit (knowing that the last 3 digits cycle every 100 powers.)</p>\n\n<p><span class=\"math-container\">$2^{18} = 262144$</span>, \n<span class=\"math-container\">$2^{118} = \\dots 6144$</span>, \n<span class=\"math-container\">$2^{218} = \\dots 0144$</span>, \n<span class=\"math-container\">$2^{318} = \\dots 4144$</span>, \n<span class=\"math-container\">$2^{418} = \\dots 8144$</span>, \n<span class=\"math-container\">$2^{518} = \\dots 2144$</span>  </p>\n\n<p>This explains the power of 5 in the cycle length as each digit must take on all five digits of its parity.</p>\n\n<p><strong>EDIT 3:</strong>  It looks like the <span class=\"math-container\">$(N+1)$</span><sup>st</sup> digit takes on all the values <span class=\"math-container\">$0-9$</span> as the last <span class=\"math-container\">$N$</span> digits complete half a cycle.  For instance, the last <span class=\"math-container\">$2$</span> digits cycle every <span class=\"math-container\">$20$</span> powers, so look at the third digit every <span class=\"math-container\">$10$</span> powers:</p>\n\n<p><span class=\"math-container\">$2^{8}\t= 256$</span>, \n<span class=\"math-container\">$2^{18} = \\dots 144$</span>, \n<span class=\"math-container\">$2^{28}\t= \\dots 456$</span>, \n<span class=\"math-container\">$2^{38}\t= \\dots 944$</span>, \n<span class=\"math-container\">$2^{48}\t= \\dots 656$</span>, \n<span class=\"math-container\">$2^{58}\t= \\dots 744$</span>, \n<span class=\"math-container\">$2^{68}\t= \\dots 856$</span>, \n<span class=\"math-container\">$2^{78}\t= \\dots 544$</span>, \n<span class=\"math-container\">$2^{88}\t= \\dots 056$</span>, \n<span class=\"math-container\">$2^{98}\t= \\dots 344$</span>  </p>\n\n<p>Not only does the third digit take on every value 0-9, but it also alternates between odd and even every time (as the Edit 2 note would require.)  Also, the N digits cycle between two values, and each of the N digits besides the last one alternates between odd and even.  I'll make this more clear with one more example which looks at the fifth digit:</p>\n\n<p><span class=\"math-container\">$2^{20}\t= \\dots 48576$</span>, \n<span class=\"math-container\">$2^{270}\t= \\dots 11424$</span>, \n<span class=\"math-container\">$2^{520}\t= \\dots 28576$</span>, \n<span class=\"math-container\">$2^{770}\t= \\dots 31424$</span>, \n<span class=\"math-container\">$2^{1020}\t= \\dots 08576$</span>, \n<span class=\"math-container\">$2^{1270}\t= \\dots 51424$</span>, \n<span class=\"math-container\">$2^{1520}\t= \\dots 88576$</span>, \n<span class=\"math-container\">$2^{1770}\t= \\dots 71424$</span>, \n<span class=\"math-container\">$2^{2020}\t= \\dots 68576$</span>, \n<span class=\"math-container\">$2^{2270}\t= \\dots 91424$</span></p>\n\n<p><strong>EDIT 4:</strong> Here's my next non-rigorous observation.  It appears that as the final N digits cycle 5 times, the <span class=\"math-container\">$(N+2)$</span><sup>th</sup> digit is either odd twice and even three times, or it's odd three times and even twice.  This gives a method for extending an all even suffix.  </p>\n\n<p>If you have an all even N digit suffix of <span class=\"math-container\">$2^a$</span>, and the (N+1)<sup>th</sup> digit is odd, then one of the following will have the (N+1)<sup>th</sup> digit even:</p>\n\n<p><span class=\"math-container\">$2^{(a+1*4*5^{N-2})}$</span>, \n<span class=\"math-container\">$2^{(a+2*4*5^{N-2})}$</span>, \n<span class=\"math-container\">$2^{(a+3*4*5^{N-2})}$</span></p>\n\n<p><strong>Edit 5:</strong> It's looking like there's no way to prove this conjecture solely by examining the last N digits since we can always find an arbitrarily long, all even, N digit sequence.  However, all of the digits are distributed so uniformly through each power of 2 that I would wager that not only does every power of 2 over 2048 have an odd digit, but also, every power of 2 larger than <span class=\"math-container\">$2^{168}$</span> has <em>every digit</em> represented in it somewhere.</p>\n\n<p>But for now, let's just focus on the parity of each digit.  Consider the value of the <span class=\"math-container\">$k^{th}$</span> digit of <span class=\"math-container\">$2^n$</span> (with <span class=\"math-container\">$a_0$</span> representing the 1's place.)  </p>\n\n<p><span class=\"math-container\">$$\na_k = \\left\\lfloor\\frac{2^n}{10^k}\\right\\rfloor \\text{ mod 10}\\Rightarrow a_k = \\left\\lfloor\\frac{2^{n-k}}{5^k}\\right\\rfloor \\text{ mod 10}\n$$</span></p>\n\n<p>We can write \n<span class=\"math-container\">$$2^{n-k} = d\\cdot5^k + r$$</span>\nwhere <span class=\"math-container\">$d$</span> is the divisor and <span class=\"math-container\">$r$</span> is the remainder of <span class=\"math-container\">$2^{n-k}/5^k$</span>.  So\n<span class=\"math-container\">$$\na_k \\equiv \\frac{2^{n-k}-r}{5^k} \\equiv d \\pmod{10}\n$$</span>\n<span class=\"math-container\">$$\\Rightarrow a_k \\equiv d \\pmod{2}$$</span>\nAnd\n<span class=\"math-container\">$$d\\cdot5^k = 2^{n-k} - r \\Rightarrow d \\equiv r \\pmod{2}$$</span>\nRemember that <span class=\"math-container\">$r$</span> is the remainder of <span class=\"math-container\">$2^{n-k} \\text{ div } {5^k}$</span> so </p>\n\n<p><span class=\"math-container\">$$\\text{The parity of $a_k$ is the same as the parity of $2^{n-k}$ mod $5^k$.}$$</span></p>\n\n<p>Now we just want to show that for any <span class=\"math-container\">$2^n &gt; 2048$</span> we can always find a <span class=\"math-container\">$k$</span> such that <span class=\"math-container\">$2^{n-k} \\text{ mod }5^k$</span> is odd.</p>\n\n<p>I'm not sure if this actually helps or if I've just sort of paraphrased the problem.</p>\n\n<p><strong>EDIT 6:</strong> Thinking about <span class=\"math-container\">$2^{n-k}$</span> mod <span class=\"math-container\">$5^k$</span>, I realized there's a way to predict some odd digits.  </p>\n\n<p><span class=\"math-container\">$$2^a \\pmod{5^k} \\text{ is even for } 1\\le a&lt; log_2 5^k$$</span></p>\n\n<p>The period of <span class=\"math-container\">$2^a \\pmod{5^k}$</span> is <span class=\"math-container\">$4\\cdot5^{k-1}$</span> since 2 is a primitive root mod <span class=\"math-container\">$5^k$</span>.  Also </p>\n\n<p><span class=\"math-container\">$$2^{2\\cdot5^{k-1}} \\equiv -1 \\pmod{5^k}$$</span></p>\n\n<p>So multiplying any <span class=\"math-container\">$2^a$</span> by <span class=\"math-container\">$2^{2\\cdot5^{k-1}}$</span> flips its parity mod <span class=\"math-container\">$5^k$</span>.  Therefore  <span class=\"math-container\">$2^a \\pmod{5^k}\\text{ }$</span> is odd for</p>\n\n<p><span class=\"math-container\">$$1 + 2\\cdot5^{k-1} \\le a&lt; 2\\cdot5^{k-1} + log_2 5^k$$</span></p>\n\n<p>Or taking the period into account, <span class=\"math-container\">$2^a \\pmod{5^k} \\text{ }$</span> is odd for any integer <span class=\"math-container\">$b\\ge0$</span> such that</p>\n\n<p><span class=\"math-container\">$$1 + 2\\cdot5^{k-1} (1 + 2b) \\le a&lt; 2\\cdot5^{k-1} (1 + 2b) + log_2 5^k$$</span></p>\n\n<p>Now for the <span class=\"math-container\">$k^{th}$</span> digit of <span class=\"math-container\">$2^n$</span> (<span class=\"math-container\">$ k=0 \\text{ } $</span> being the 1's digit), we're interested in the parity of <span class=\"math-container\">$2^{n-k}$</span> mod <span class=\"math-container\">$5^k$</span>.  Setting <span class=\"math-container\">$ a =n-k \\text{  } $</span> we see that the <span class=\"math-container\">$k^{th}$</span> digit of <span class=\"math-container\">$2^n$</span> is odd for integer <span class=\"math-container\">$b\\ge0$</span> such that</p>\n\n<p><span class=\"math-container\">$$1 + 2\\cdot5^{k-1} (1 + 2b) \\le n - k &lt; 2\\cdot5^{k-1} (1 + 2b) + log_2 5^k$$</span></p>\n\n<p>To illustrate, here are some guaranteed odd digits for different <span class=\"math-container\">$2^n$</span>:  </p>\n\n<p>(k=1 digit): <span class=\"math-container\">$ 2\\cdot5^0 + 2 = 4 \\le n \\le 5 $</span><br>\n(k=2 digit): <span class=\"math-container\">$ 2\\cdot5^1 + 3 = 13 \\le n \\le 16 $</span><br>\n(k=3 digit): <span class=\"math-container\">$ 2\\cdot5^2 + 4 = 54 \\le n \\le 59 $</span><br>\n(k=4 digit): <span class=\"math-container\">$ 2\\cdot5^3 + 5 = 255 \\le n \\le 263 $</span>  </p>\n\n<p>Also note that these would repeat every <span class=\"math-container\">$4\\cdot5^{k-1}$</span> powers.</p>\n\n<p>These guaranteed odd digits are not dense enough to cover all of the powers, but might this approach be extended somehow to find more odd digits?</p>\n\n<p><strong>Edit 7:</strong> The two papers that Zander mentions below make me think that this is probably a pretty hard problem.</p>\n", "pids": ["53e9b247b7602d9703ce7ab5"], "flag": 0}
{"question": "How to prove $\\int_0^1\\tan^{-1}\\left[\\frac{\\tanh^{-1}x-\\tan^{-1}x}{\\pi+\\tanh^{-1}x-\\tan^{-1}x}\\right]\\frac{dx}{x}=\\frac{\\pi}{8}\\ln\\frac{\\pi^2}{8}?$", "body": "<p>How can one prove that\n<span class=\"math-container\">$$\\int_0^1 \\tan^{-1}\\left[\\frac{\\tanh^{-1}x-\\tan^{-1}x}{\\pi+\\tanh^{-1}x-\\tan^{-1}x}\\right]\\frac{dx}{x}=\\frac{\\pi}{8}\\ln\\frac{\\pi^2}{8}?$$</span></p>\n", "pids": ["60f16b0b91e011963c8d4528"], "flag": 0}
{"question": "Past open problems with sudden and easy-to-understand solutions", "body": "<p>What are some examples of mathematical facts that had once been open problems for a significant amount of time and thought hard or unsolvable by contemporary methods, but were then unexpectedly solved thanks to some out-of-the-box flash of genius, and the proof is actually short (say, one page or so) and uses elementary mathematics only?</p>\n", "pids": ["53e998cdb7602d9702105f91"], "flag": 0}
{"question": "Induction on Real Numbers", "body": "<p>One of my Fellows asked me whether total induction is applicable to real numbers, too ( or at least all real numbers ≥ 0) . We only used that for natural numbers so far. \nOf course you have to change some things in the inductive step, when you want to use it on real numbers.</p>\n\n<p>I guess that using induction on real numbers isn't really possible, since $[r,r+\\epsilon]$ with $\\epsilon > 0$, $r \\in \\mathbb R$ is never empty.</p>\n\n<p>Can you either give a good reason, why it isn't possible or provide an example where it is used?</p>\n", "pids": ["56d873d5dabfae2eee0916ef", "53e99a92b7602d9702309b1e"], "flag": 0}
{"question": "When to learn category theory?", "body": "<p>I'm a undergraduate who wishes to learn category theory but I only have basic knowledge of linear algebra and set theory, I've also had a short course on number theory which used some basic concepts about groups and modular arithmetic. Is it too early to start learning category theory? should I wait to take a course on abstract algebra?</p>\n\n<p>Is it very important to use category theory facts in a first course in group theory, ring theory, fields and Galois theory, modules and tensor products (each of those is a one semester course), would that make it a 'better' course?</p>\n\n<p>I was unsure to learn category theory early but this post <a href=\"https://math.stackexchange.com/questions/213/mathematical-subjects-you-wish-you-learned-earlier\">Mathematical subjects you wish you learned earlier</a> inspired me to ask you given my background.</p>\n", "pids": ["56d84ce1dabfae2eeee474ea"], "flag": 0}
{"question": "Different ways to prove there are infinitely many primes?", "body": "<p>This is just a curiosity. I have come across multiple proofs of the fact that there are infinitely many primes, some of them were quite trivial, but some others were really, really fancy. I'll show you what proofs I have and I'd like to know more because I think it's cool to see that something can be proved in so many different ways.</p>\n\n<p>Proof 1 : Euclid's. If there are finitely many primes then $p_1 p_2 ... p_n + 1$ is coprime to all of these guys. This is the basic idea in most proofs : generate a number coprime to all previous primes.</p>\n\n<p>Proof 2 : Consider the sequence $a_n = 2^{2^n} + 1$. We have that \n$$\r\n2^{2^n}-1 = (2^{2^1} - 1) \\prod_{m=1}^{n-1} (2^{2^m}+1),\r\n$$ \nso that for $m &lt; n$, $(2^{2^m} + 1, 2^{2^n} + 1) \\, | \\, (2^{2^n}-1, 2^{2^n} +1) = 1$. Since we have an infinite sequence of numbers coprime in pairs, at least one prime number must divide each one of them and they are all distinct primes, thus giving an infinity of them.</p>\n\n<p>Proof 3 : (Note : I particularly like this one.) Define a topology on $\\mathbb Z$ in the following way : a set $\\mathscr N$ of integers is said to be open if for every $n \\in \\mathscr N$ there is an arithmetic progression $\\mathscr A$ such that $n \\in \\mathscr A \\subseteq \\mathscr N$. This can easily be proven to define a topology on $\\mathbb Z$. Note that under this topology arithmetic progressions are open and closed. Supposing there are finitely many primes, notice that this means that the set\n$$\r\n\\mathscr U \\,\\,\\,\\, \\overset{def}{=} \\,\\,\\, \\bigcup_{p} \\,\\, p \\mathbb Z\r\n$$\nshould be open and closed, but by the fundamental theorem of arithmetic, its complement in $\\mathbb Z$ is the set $\\{ -1, 1 \\}$, which is not open, thus giving a contradiction. </p>\n\n<p>Proof 4 : Let $a,b$ be coprime integers and $c &gt; 0$. There exists $x$ such that $(a+bx, c) = 1$. To see this, choose $x$ such that $a+bx \\not\\equiv 0 \\, \\mathrm{mod}$ $p_i$ for all primes $p_i$ dividing $c$. If $a \\equiv 0 \\, \\mathrm{mod}$ $p_i$, since $a$ and $b$ are coprime, $b$ has an inverse mod $p_i$, call it $\\overline{b}$. Choosing $x \\equiv \\overline{b} \\, \\mathrm{mod}$ $p_i$, you are done. If $a \\not\\equiv 0 \\, \\mathrm{mod}$ $p_i$, then choosing $x \\equiv 0 \\, \\mathrm{mod}$ $p_i$ works fine. Find $x$ using the Chinese Remainder Theorem. </p>\n\n<p>Now assuming there are finitely many primes, let $c$ be the product of all of them. Our construction generates an integer coprime to $c$, giving a contradiction to the fundamental theorem of arithmetic.</p>\n\n<p>Proof 5 : Dirichlet's theorem on arithmetic progressions (just so that you not bring it up as an example...)</p>\n\n<p>Do you have any other nice proofs?</p>\n", "pids": ["62302c1c5aee126c0fbd391e"], "flag": 0}
{"question": "Does Electromagnetic Hypersensitivity (EHS) exist?", "body": "<p><a href=\"http://www.dailymail.co.uk/health/article-3148311/The-lady-allergic-ELECTRICITY-Woman-50-dons-protective-suit-veil-outside-claims-Wi-Fi-kill-her.html\">A recent article from Daily Mail</a> cited the case of a woman claiming to be allergic to Wi-Fi, and that it could even kill her. This claim sounded ridiculous and absurd to me. Quoting parts of the exact text: </p>\n\n<blockquote>\n  <ul>\n  <li><p>Jackie Lindsey, 50, <strong>claims she has electromagnetic hypersensitivity</strong> (EHS).</p></li>\n  <li><p>Says the condition - not recognized by doctors in the UK - <strong>means she is allergic to electricity and Wi-Fi and phones could cause shock</strong>.</p></li>\n  <li><p>She has diagnosed herself with electromagnetic hypersensitivity (EHS), and says anyone using Wi-Fi or a mobile phone signal around her could <strong>cause her to have an attack similar to an anaphylactic shock</strong>.</p></li>\n  <li><p>Four per cent of the population are severely affected by the condition while 30 to 40 per cent are mildly affected.</p></li>\n  </ul>\n</blockquote>\n\n<p>The Daily Mail also features other articles along the same lines in the past:</p>\n\n<ul>\n<li><p><a href=\"http://www.dailymail.co.uk/health/article-1387972/Woman-allergic-electricity-Cancer-survivor-sensitive-gadgets-lives-candlelight.html\">2011: The cancer survivor allergic to modern life: Mother is so sensitive to electric gadgets she has to live by candlelight</a></p></li>\n<li><p><a href=\"http://www.dailymail.co.uk/femail/article-2331369/The-women-say-allergic-modern-life-Blinding-headaches-Violent-sickness-Even-blackouts-So-wi-fi-mobile-phones-TV-screens-blame.html\">2013: The women who say they are allergic to modern life</a></p></li>\n<li><p><a href=\"http://www.dailymail.co.uk/news/article-2308193/The-cell-phone-free-town-West-Virginia-sees-influx-residents-allergic-electronic-devices.html\">2013: The cellphone-free town in West Virginia that offers people who are 'allergic' to radio waves escape from the modern world</a></p></li>\n</ul>\n\n<p>Does electromagnetic hypersensitivity exist? Does it severely affect 4% of the human population?</p>\n", "pids": ["53e9990db7602d970214962f", "55a5199265ceb7cb02e0eb37"], "flag": 1}
{"question": "Infiniteness of non-twin primes.", "body": "<p>Well, we all know the twin prime conjecture.\nThere are infinitely many primes $p$, such that $p+2$ is also prime.\nWell, I actually got asked in a discrete mathematics course, to prove that there are infinitely many primes $p$ such that $p + 2$ is NOT prime.</p>\n", "pids": ["53e9ac05b7602d97035c82a1"], "flag": 0}
{"question": "Best bandit algorithm?", "body": "<p>The most well-known bandit algorithm is upper confidence bound (UCB) which popularized this class of algorithms.  Since then I presume there are now better algorithms.  What is the current best algorithm (in terms of either empirical performance or theoretical bounds)?  Is this algorithm optimal in some sense?</p>\n", "pids": ["53e9ac5bb7602d970362af62"], "flag": 1}
{"question": "Can non-random samples be analyzed using standard statistical tests?", "body": "<p>Many clinical studies are based on non-random samples. However, most standard tests (e.g. t-tests, ANOVA, linear regression, logistic regression) are based on the assumption that samples contain \"random numbers\". Are results valid if these non-random samples were analyzed by standard tests? Thank you. </p>\n", "pids": ["53e9bc31b7602d97048a048b", "53e9a18db7602d9702a7fc1c"], "flag": 1}
{"question": "Fisher&#39;s Fundamental Theorem of Natural Selection", "body": "<p><a href=\"http://en.wikipedia.org/wiki/Ronald_Fisher\" rel=\"nofollow\">Ronald Fisher</a> discovered what he, with humility, called the <a href=\"http://en.wikipedia.org/wiki/Fisher%27s_fundamental_theorem_of_natural_selection\" rel=\"nofollow\">Fundamental Theorem of Natural Selection</a>. This theorem says (in its modern terminology):</p>\n\n<blockquote>\n  <p>The rate of increase in the mean fitness of any organism at any time ascribable to natural selection acting through changes in gene frequencies is exactly equal to its genetic variance in fitness at that time.</p>\n</blockquote>\n\n<p>As I understand it, it sounds alike the standard equation that we learn in the first class of <em>Introduction to evolutionary biology</em></p>\n\n<p>$$R = S \\cdot \\frac{V_G}{V_p}$$</p>\n\n<p>In words: the response to selection equals the selection differential times the genetic variance of the trait under consideration divided by the total phenotypic variance of the trait under consideration</p>\n\n<p><strong>But how can we prove/demonstrate that Fisher's fundamental theorem of natural selection holds true?</strong></p>\n\n<p>I don't ask for empirical evidences that support this claim but for a theoretical/mathematical proof/demonstration of this claim.</p>\n", "pids": ["60e2dd605244ab9dcbfd0259"], "flag": 1}
{"question": "GULO only for mammals?", "body": "<p>I am not a biology student, but just want to know if GULO gene are present only in mammals or all species possess it ?</p>\n\n<p>And is GULO gene active in human fetus?</p>\n", "pids": ["62bd7f715aee126c0f4ba20e"], "flag": 1}
{"question": "Does a &quot;cubic&quot; matrix exist?", "body": "<p>Well, I've heard that a \"cubic\" matrix would exist and I thought: would it be like a magic cube? And more: does it even have a determinant - and other properties? I'm a young student, so... please don't get mad at me if I'm talking something stupid.</p>\n\n<p>Thank you.</p>\n\n<p>P.S. I'm 14 years old. I don't know that much about mathematics, but I swear I'll try to understand your answers. I just know the basics about PreCalculus.</p>\n", "pids": ["53e99e21b7602d97026e2996"], "flag": 0}
{"question": "Are women physically weaker?", "body": "<p>I've always thought that &quot;women are weaker<sup>1</sup> than men in general&quot; was a biological fact (supposedly stemming/evolving from the social structure of prehistoric humans)</p>\n<p>Is there any reputable research done which demonstrates (or disproves) that the average woman has the same strength as the average man?</p>\n<p><sup>1 In this post, &quot;weaker&quot; means &quot;physically weaker&quot;, and refers only to cis women (not transgender women)</sup></p>\n", "pids": ["53e9ac33b7602d97035fc14f"], "flag": 1}
{"question": "Does watching television damage the eyes?", "body": "<p>Is there any evidence that watching television for too long or while sitting too close weakens the eyes (leading to myopia, for example) ?</p>\n", "pids": ["548913d045ce471f90b165fc"], "flag": 1}
{"question": "Why are There No &quot;Triernions&quot; (3-dimensional analogue of complex numbers / quaternions)?", "body": "<p>Since there are  complex numbers (2 dimensions) and quaternions (4 dimensions), it follows intuitively that there ought to be something in between for 3 dimensions (\"triernions\"). </p>\n\n<p>Yet no one uses these. Why is this?</p>\n", "pids": ["53e9b4fab7602d970402a9a3"], "flag": 0}
{"question": "Is it possible to have life in vacuum?", "body": "<p>I just got struck by curiosity now: Intuition says no, but I've never had confirmation of it. </p>\n", "pids": ["53e9a4b2b7602d9702dd1ab7"], "flag": 1}
{"question": "Examples of problems that are easier in the infinite case than in the finite case.", "body": "<p>I am looking for examples of problems that are easier in the infinite case than in the finite case. I really can't think of any good ones for now, but I'll be sure to add some when I do.</p>\n", "pids": ["53e9b2a3b7602d9703d4ee5e"], "flag": 0}
{"question": "What are some examples of evolving networks in biology?", "body": "<p>I'm a master student working on networks analysis in general. A network is something that has nodes and there are links between the nodes. Nodes and links could have attributes. An evolving network is one that changes overtime (new nodes and links are added..etc). An example of that is Facebook. Nodes are users and links represent the friendship relationship. Users have attributes (gender, age, etc.). A Facebook network as you know is an example of a social network. </p>\n\n<p>The issue is that so many people studied traditional evolving networks like social networks, the web, or transportation networks. Currently I'm looking for novel examples of evolving networks to study them. So I thought there might be some examples in <em>biology</em> that could represent some kind of an evolving network. </p>\n\n<p>So my question: Can you give me examples in <em>biology</em> for evolving networks? I'm aware of metabolic networks, but that is also heavily studied, I need something else.</p>\n", "pids": ["53e9a366b7602d9702c73945"], "flag": 1}
{"question": "Strategies for Effective Self-Study", "body": "<p>I have a long-term goal of acquiring graduate-level knowledge in Analysis, Algebra and Geometry/Topology. Once that is achieved, I am interested in applying this knowledge to both pure and applied mathematics. In particular, I am interested in various aspects of smooth manifolds, co/homology and mathematical physics. I have acquired a smattering of knowledge in all of these areas but feel that I need to become more focused to make make coherent progress. I have a very bad habit of picking up a book, reading a bit, working out a few details, and then moving on to other random topics in other random books. In doing this, I don't really feel like I accomplish much. </p>\n\n<p>To rectify this admittedly undisciplined approach, I have decided to select core source material from each of the three major areas listed above and focus on it until I have assimilated all the information in that material. For analysis, I have selected Amann and Eschers' Analysis, volumes I, II, and III. I made this choice because out of the analysis texts I have surveyed, theirs seems to be the most comprehensive and treats elementary and advanced analysis as a unified discipline. </p>\n\n<p>My basic strategy is to treat each theorem, example, etc. as a problem and give a fair amount of effort to proving before consulting the text. I think this is probably the best way to approach the material for maximum understanding but it requires a considerable amount of time. There are probably thousands of these sorts of \"problems\" among the three volumes. Ulitimately, I would like to end up with a notebook (which would probably number in the thousands of pages) that contains all of the details to all of the theorems completely worked out, as much as possible, with my own thoughts. Again, this seems like it will take forever and my time on this earth is unfortunately finite. I'm reasonably confident though that the production of such a set of notes would lead to at least a fair level of mastery of the material in question.</p>\n\n<p>Can anyone suggest an alternate strategy that might be more effective in terms of time but that would lead to a comparable level of mastery?</p>\n\n<p>It is also a problem that I might actually prove a fact completely on my own but then, a month later, might not be able to recall it in a time of need. What strategies are helpful for best ingraining this material (other than the obvious \"Work lots of problems\" approach)? </p>\n\n<p>Would appreciate any tips or pointers.</p>\n", "pids": ["53e9b12ab7602d9703ba96d1"], "flag": 0}
{"question": "Examples of mathematical results discovered &quot;late&quot;", "body": "<p>What are examples of mathematical results that were discovered surprisingly late in history? Maybe the result is a straightforward corollary of an established theorem, or maybe it's just so simple that it's surprising no one thought of it sooner.</p>\n\n<p>The example that makes me ask is the 2011 paper <a href=\"https://plus.google.com/117663015413546257905/posts/gPRDA8xprtA\">John Baez mentioned</a> called \"Two semicircles fill half a circle\", which proves a fairly simple geometrical fact similar to those that have been pondered for thousands of years.</p>\n", "pids": ["56d86bf4dabfae2eeecdf938"], "flag": 0}
{"question": "Produce an explicit bijection between rationals and naturals", "body": "<p>I remember my professor in college challenging me with this question, which I failed to answer satisfactorily: I know there exists a bijection between the rational numbers and the natural numbers, but can anyone produce an explicit formula for such a bijection?</p>\n", "pids": ["53e9a7d5b7602d9703111ea7", "5c757e28f56def9798b5dc0f"], "flag": 0}
{"question": "What are good books to learn graph theory?", "body": "<p>What are some of the best books on graph theory, particularly directed towards an upper division undergraduate student who has taken most the standard undergraduate courses? I'm learning graph theory as part of a combinatorics course, and would like to look deeper into it on my own. Thank you.</p>\n", "pids": ["5c6be54ae1cd8e041d3baac2"], "flag": 0}
{"question": "What are the issues in modern set theory?", "body": "<p>This is spurred by the comments to my answer <a href=\"https://math.stackexchange.com/questions/24507/why-did-mathematicians-take-russells-paradox-seriously/24546#24546\">here</a>.  I'm unfamiliar with set theory beyond Cohen's proof of the independence of the continuum hypothesis from ZFC.  In particular, I haven't witnessed any real interaction between set-theoretic issues and the more conventional math I've studied, the sort of place where you realize \"in order to really understand this problem in homotopy theory, I need to read about large cardinals.\"  I've even gotten the feeling from several professional mathematicians I've talked to that set theory is no longer relevant, and that if someone were to find some set-theoretic flaw in their axioms (a non-standard model or somesuch), they would just ignore it and try again with different axioms.</p>\n\n<p>I also don't personally care for the abstraction of set theory, but this is a bad reason to judge anything, especially at this early stage in my life, and I feel like I'd be more interested if I knew of some ways it interacted with the rest of the mathematical world.  So:</p>\n\n<ul>\n<li>What do set theorists today care about?</li>\n<li>How does set theory interact with the rest of mathematics?</li>\n<li>(more subjective but) Would mathematicians working outside of set theory benefit from thinking about large cardinals, non-standard models, or their ilk?</li>\n<li>Could you recommend any books or papers that might convince a non-set theorist that the subject as it's currently practiced is worth studying?</li>\n</ul>\n\n<p>Thanks a lot!</p>\n", "pids": ["53e9be0fb7602d9704ac831d"], "flag": 0}
{"question": "Real life applications of Topology", "body": "<p>The other day I and my friend were having an argument. He was saying that there is no real life application of Topology at all whatsoever. I want to disprove him, so posting the question here.</p>\n\n<p>What are the various real life applications of topology?</p>\n", "pids": ["53e9996fb7602d97021b1f24", "53e9b587b7602d97040c7efb"], "flag": 0}
{"question": "In calculus, which questions can the naive ask that the learned cannot answer?", "body": "<p>Number theory is known to be a field in which many questions that can be understood by secondary-school pupils have defied the most formidable mathematicians' attempts to answer them.</p>\n\n<p><strong>Calculus</strong> is not known to be such a field, as far as I know. (For now, let's just assume this means the basic topics included in the staid and stagnant conventional first-year calculus course.)</p>\n\n<p>What are</p>\n\n<ol>\n<li>the most prominent and </li>\n<li>the most readily comprehensible</li>\n</ol>\n\n<p>questions that can be understood by those who know the concepts taught in first-year calculus and whose solutions are unknown?</p>\n\n<p>I'm not looking for problems that people who know only first-year calculus can solve, but only for questions that they can understand.  It would be acceptable to include questions that can be understood only in a somewhat less than logically rigorous way by students at that level.</p>\n", "pids": ["56d8d4b0dabfae2eeec191e9"], "flag": 0}
{"question": "What are some examples of a mathematical result being counterintuitive?", "body": "<p>As I procrastinate studying for my Maths Exams, I want to know what are some cool examples of where math counters intuition.</p>\n\n<p>My first and favorite experience of this is Gabriel's Horn that you see in intro Calc course, where the figure has finite volume but infinite surface area (I later learned of Koch's snowflake which is a 1d analog). I just remember doing out the integrals for it and thinking that it was unreal. I later heard the remark that you can fill it with paint, but you can't paint it, which blew my mind.</p>\n\n<p>Also, philosophically/psychologically speaking, why does this happen? It seems that our intuition often guides us and is often correct for \"finite\" things, but when things become \"infinite\" our intuition flat-out fails.</p>\n", "pids": ["53e9a8b1b7602d9703202b13"], "flag": 0}
{"question": "Calculating the integral $\\int_0^\\infty \\frac{\\cos x}{1+x^2}\\, \\mathrm{d}x$ without using complex analysis", "body": "<p>Suppose that we do not know anything about the complex analysis (numbers). In this case, how to calculate the following integral in closed form?\n<span class=\"math-container\">$$\\int_0^\\infty\\frac{\\cos x}{1+x^2}\\,\\mathrm{d}x$$</span></p>\n", "pids": ["53e9b895b7602d970446b2ad", "53e9ade2b7602d97037e97ef", "5c755156f56def97985bb1f6"], "flag": 0}
{"question": "Are there real world applications of finite group theory?", "body": "<p>I would like to know whether there are examples where finite group theory can be directly applied to solve real world problems outside of mathematics.  (Sufficiently applied mathematics such as cryptography, coding theory, or statistics still count.)</p>\n<p>Let me clarify: I am not interested in applications of <em>elementary group theory</em> which happen to involve finite groups (e.g. cyclic/dihedral/easy groups as molecular symmetries).  I am interested in applications of topics specifically coming from <em>finite group theory</em> as a discipline, like one might see in <a href=\"http://books.google.com/books/about/Finite_Group_Theory.html?id=pCLhYaMUg8IC\" rel=\"nofollow noreferrer\">Isaacs</a>, <a href=\"http://books.google.com/books?id=jr6EMAEACAAJ&amp;dq=endliche%20gruppen&amp;hl=en&amp;sa=X&amp;ei=0kE5UfudCOWVyAGZ_ICABQ&amp;ved=0CD4Q6AEwAg\" rel=\"nofollow noreferrer\">Huppert</a>, or <a href=\"http://books.google.com/books?id=lqyCjUFY6WAC\" rel=\"nofollow noreferrer\">Robinson</a>.</p>\n<p>&quot;The Schur multiplier has order <span class=\"math-container\">$2640,$</span> so we should point the laser that way.&quot;</p>\n<p>&quot;Is this computer system secure?&quot;  &quot;No - Frobenius kernels are nilpotent.&quot;</p>\n<p>I'm aware of <a href=\"https://mathoverflow.net/questions/11784/fun-applications-of-representations-of-finite-groups\">this MO post</a>, but many of the applications listed there are inside mathematics or fall in the &quot;applications of easy groups&quot; category.  It is entirely possible that what I'm looking for doesn't exist, and that finite group theory is still an untouchable, pure subject, like number theory in the days of G. H. Hardy.  But perhaps not.  Does anyone know of any applications of the higher level stuff?</p>\n", "pids": ["53e9a28ab7602d9702b91853", "53e9bc96b7602d9704915ef1", "53e99abeb7602d970233c10c", "53e9a9a9b7602d970330819d"], "flag": 0}
{"question": "Grothendieck &#39;s question - any update?", "body": "<p>I was reading Barry Mazur's <a href=\"http://www-groups.dcs.st-and.ac.uk/%7Ehistory/Biographies/Mazur_Barry.html\" rel=\"noreferrer\">biography</a> and come across this part:</p>\n<p><em>Grothendieck was exceptionally patient with me, for when we first met I knew next to nothing about algebra. In one of his first conversations with me, he raised the question (asked of him by Washnitzer) of whether a smooth proper algebraic variety defined over a real quadratic field could yield topologically different differentiable manifolds realized by the two possible imbeddings of the number field into the reals. What a perfect question, at least for me! Not that I answered it. But it was surely one of the very few algebro-geometric questions that I then had the background to appreciate. ... the question provided quite an incentive for a topologist to look at algebraic geometry. I began to learn the elements of algebraic geometry working with Mike Artin.</em></p>\n<p>Is the problem still open? I am an algebraic topology student so it feels very surprising someone will come up with a question like this. But I am at a loss how to experimentally find some toy examples one can work by hand.</p>\n", "pids": ["61ca016c5244ab9dcb6696d9"], "flag": 0}
{"question": "What is the smallest unknown natural number?", "body": "<p>There are several unknown numbers in mathematics, such as optimal constants in some inequalities.\nOften it is enough to some estimates for these numbers from above and below, but finding the exact values is also interesting.\nThere are situations where such unknown numbers are necessarily natural numbers, for example in Ramsey theory.\nFor example, we know that there is a smallest integer $n$ such that any graph with $n$ vertices contains a complete or an independent subgraph of 10 vertices, but we don't know the exact value of $n$.</p>\n\n<p>What kinds of unknown small (less than 100, say) integers are there?\nWhat are the smallest unknown constants which are known to be integers?\nOr, more rigorously, what is the smallest upper bound for an unknown but definable number that is known to be an integer?</p>\n\n<p>I know that asking for the smallest unknown integer is ill-defined since we do not know the exact values.\nThe more rigorous version of the question is well-posed, but I do not want to keep anyone from offering interesting examples even if they are clearly not going to win the race for the lowest upper bound.</p>\n\n<p>An answer should contain a definition of an integer quantity (or a family of them) and known lower and upper bounds (both of which should be integers, not infinite).\nConjectures about the actual value are also welcome.\nI have given one example below to give an idea of what I'm looking for.</p>\n", "pids": ["5f00e46bdfae54b9a6bf6b34", "5c7574bbf56def979897a366"], "flag": 0}
{"question": "Why are mathematical proofs that rely on computers controversial?", "body": "<p>There are many theorems in mathematics that have been proved with the assistance of computers, take the famous <a href=\"http://en.wikipedia.org/wiki/Four_color_theorem\">four color theorem</a> for example. Such proofs are often controversial among some mathematicians. Why is it so?</p>\n\n<p>I my opinion, shifting from manual proofs to computer-assisted proofs is a giant leap forward for mathematics. Other fields of science rely on it heavily. Physics experiments are simulated in computers. Chemical reactions are simulated in supercomputers. Even evolution can be simulated in an advanced enough computer. All of this can help us understand these phenomena better. </p>\n\n<p>But why are mathematicians so reluctant?</p>\n", "pids": ["53e9b12ab7602d9703ba96d1", "53e99d04b7602d97025b6467"], "flag": 0}
{"question": "An integral involving Airy functions $\\int_0^\\infty\\frac{x^p}{\\operatorname{Ai}^2 x + \\operatorname{Bi}^2 x}\\mathrm dx$", "body": "<p>I need your help with this integral:\n$$\\mathcal{K}(p)=\\int_0^\\infty\\frac{x^p}{\\operatorname{Ai}^2 x + \\operatorname{Bi}^2 x}\\mathrm dx,$$\nwhere $\\operatorname{Ai}$, $\\operatorname{Bi}$ are <a href=\"http://mathworld.wolfram.com/AiryFunctions.html\">Airy functions</a>:\n$$\\operatorname{Ai}\\,x=\\frac{1}{\\pi}\\int_0^\\infty\\cos\\left(x\\,z+\\frac{z^3}{3}\\right)\\,\\mathrm dz,$$\n$$\\operatorname{Bi}\\,x=\\frac{1}{\\pi}\\int_0^\\infty\\left(\\sin\\left(x\\,z+\\frac{z^3}{3}\\right)+\\exp\\left(x\\,z-\\frac{z^3}{3}\\right)\\right)\\,\\mathrm dz.$$\nI am not sure that $\\mathcal{K}(p)$ has a general closed form, but I hope so, because approximate numerical calculations suggest these conjectured values:\n$$\\mathcal{K}(3)\\stackrel?=\\frac{5\\,\\pi^2}{32},\\ \\ \\mathcal{K}(6)\\stackrel?=\\frac{565\\,\\pi^2}{512}.$$</p>\n", "pids": ["53e9af33b7602d970396f647"], "flag": 0}
{"question": "What is the algebraic intuition behind Vieta jumping in IMO1988 Problem 6?", "body": "<p>Problem 6 of the 1988 International Mathematical Olympiad notoriously asked:</p>\n\n<blockquote>\n  <p>Let $a$ and $b$ be positive integers and $k=\\frac{a^2+b^2}{1+ab}$. Show that if $k$ is an integer then $k$ is a perfect square.</p>\n</blockquote>\n\n<p>The usual way to show this involves a technique called <em>Vieta jumping</em>. See <a href=\"https://en.wikipedia.org/wiki/Vieta_jumping\">Wikipedia</a> or <a href=\"https://math.stackexchange.com/questions/483771/imo-1988-problem-6\">this MSE post</a>.</p>\n\n<p>I can follow the Vieta jumping proof, but it seems a bit strained to me. You play around with equations that magically work out at the end. I don't see how anyone could have come up with that problem using that proof.</p>\n\n<p>Is there a natural or canonical way to see the answer to the problem, maybe using (abstract) algebra or more powerful tools? In addition, how can someone come up with a problem like this?</p>\n", "pids": ["53e9b350b7602d9703e25430"], "flag": 0}
{"question": "Theorems with an extraordinary exception or a small number of sporadic exceptions", "body": "<p>The <a href=\"https://en.wikipedia.org/wiki/Line_graph#Whitney_isomorphism_theorem\" rel=\"noreferrer\">Whitney graph isomorphism theorem</a> gives an example of an extraordinary exception: a very general statement holds except for <strong>one</strong> very specific case.</p>\n\n<p>Another example is the <a href=\"http://en.wikipedia.org/wiki/Classification_of_finite_simple_groups#Statement_of_the_classification_theorem\" rel=\"noreferrer\">classification theorem for finite simple groups</a>: a very general statement holds except for <strong>very few (26)</strong> sporadic cases. </p>\n\n<p>I am looking for more of <strong>this kind</strong> of theorems-with-not-so-many-sporadic-exceptions </p>\n\n<blockquote>\n  <p>(<strong><em>added:</em></strong>) where the exceptions don't come in a row and/or\n  in the beginning - but are scattered truly <a href=\"https://en.wiktionary.org/wiki/sporadically\" rel=\"noreferrer\">sporadically</a>.</p>\n</blockquote>\n\n<p>(A late thanks to Asaf!)</p>\n", "pids": ["56d852ccdabfae2eee1135f0", "53e9a0adb7602d9702993a04"], "flag": 0}
{"question": "Mathematicians ahead of their time?", "body": "<p>It is said that in every field there’s that person who was years ahead of their time. For instance, Paul Morphy (born 1837) is said to have retired from chess because he found no one to match his technique that very much resembled modern chess theory.</p>\n<p>So, who was the Paul Morphy of mathematics?</p>\n", "pids": ["56d903d0dabfae2eeee94e60"], "flag": 0}
{"question": "Can the golden ratio accurately be expressed in terms of $e$ and $\\pi$", "body": "<p>I was playing around with numbers when I noticed that $\\sqrt e$ was <strike>very</strike> somewhat close to $\\phi$\n<br> And so, I took it upon myself to try to find a way to express the golden ratio in terms of the infamous values, $\\large\\pi$ and $\\large e$<br>\nThe closest that I've come so far is:\n$$\n\\varphi \\approx \\sqrt e - \\frac{\\pi}{(e+\\pi)^e - \\sqrt e}\n$$</p>\n\n<p>My question is,<br> Is there a better <sub><sup>(more precise and accurate)</sup></sub> way of expressing $\\phi$ in terms of $e$ and $\\pi$ ?</p>\n", "pids": ["53e99784b7602d9701f3e166"], "flag": 0}
{"question": "Unusual mathematical terms", "body": "<p>From time to time, I come across some unusual mathematical terms. I know something about <a href=\"http://en.wikipedia.org/wiki/Attractor#Strange_attractor\">strange attractors</a>. I also know what <a href=\"http://mathworld.wolfram.com/WitchofAgnesi.html\">Witch of Agnesi</a> is. However, what prompted me to write this question is that I was really perplexed when I read the other day about <a href=\"http://en.wikipedia.org/wiki/Monstrous_moonshine\">monstrous moonshine</a>, and this is so far my favorite, out of similar terms.</p>\n\n<p>Some others:</p>\n\n<ul>\n<li><a href=\"http://en.wikipedia.org/wiki/Cantor_set#Cantor_dust\">Cantor dust</a></li>\n<li><a href=\"http://en.wikipedia.org/wiki/Gabriel%27s_Horn\">Gabriel's Horn</a> (also known as Torricelli's trumpet)</li>\n<li><a href=\"http://en.wikipedia.org/wiki/Koch_snowflake\">Koch snowflake</a></li>\n<li><a href=\"http://en.wikipedia.org/wiki/Knaster%E2%80%93Kuratowski_fan\">Knaster–Kuratowski fan</a> (also known as Cantor's leaky tent or Cantor's\nteepee depending on the presence or absence of the apex; there is also Cantor's leaki<em>er</em> tent)</li>\n</ul>\n\n<p>Are there more such unusual terms in mathematics?</p>\n\n\n\n<p><em>Jan 17 update:</em> for fun, word cloud of all terms mentioned here so far:</p>\n\n<p><a src=\"https://i.stack.imgur.com/4PWGl.jpg\" alt=\"enter image description here\"></p>\n\n<p>and another, more readable:</p>\n\n<p><a src=\"https://i.stack.imgur.com/kytdI.png\" alt=\"enter image description here\"></p>\n", "pids": ["53e9a9beb7602d970331cdcf"], "flag": 0}
{"question": "Non-textbook Math book recommendation to read to my kids", "body": "<p>I'm looking for a book to read to my kids.\nNOT a kids book, but not too mature for a kid. My youngest kid that reads with me is 6 and the eldest is 10.</p>\n\n<p>I'm looking for a book that is good literature, and is hard to put down. \nAlso maybe a book that makes the subject in school more interesting. Not just tedious memorization, but presenting it in a way that makes the child excited about what he/she is learning. And not a book that teaches the subject, (math etc....) but a book that teaches how it got started or why it's important. </p>\n\n<p>Are there any books like these you that you have read that made you excited about math? If so please tell me.</p>\n", "pids": ["606eea5491e011aa47b6acad"], "flag": 0}
{"question": "Is there any conjecture that has been proved to be solvable/provable but whose direct solution/proof is not yet known?", "body": "<p>In mathematics, is there any conjecture about the existence of an object that was proven to exist but that has not been explicitly constructed to this day? Here <em>object</em> could be any mathematical object, such as a number, function, algorithm, or even proof.</p>\n", "pids": ["53e998cdb7602d9702105f91"], "flag": 0}
{"question": "Difference between &quot;≈&quot;, &quot;≃&quot;, and &quot;≅&quot;", "body": "<p>In mathematical notation, what are the usage differences between the various <a href=\"http://en.wikipedia.org/wiki/Approximation#Unicode\"><em>approximately-equal</em></a> signs \"≈\", \"≃\", and \"≅\"?</p>\n\n<p>The Unicode standard lists all of them inside the Mathematical Operators Block.</p>\n\n<ul>\n<li><strong>≈</strong> : ALMOST EQUAL TO (U+2248)</li>\n<li><strong>≃</strong> : ASYMPTOTICALLY EQUAL TO (U+2243)</li>\n<li><strong>≅</strong> : APPROXIMATELY EQUAL TO (U+2245)</li>\n</ul>\n", "pids": ["56d89901dabfae2eee27435f"], "flag": 0}
{"question": "Estimating parameters of Student&#39;s t-distribution", "body": "<p>What are the maximum-likelihood estimators for the parameters of Student's t-distribution? Do they exist in closed form? A quick Google search didn't give me any results.</p>\n\n<p>Today I am interested in the univariate case, but probably I will have to extend the model to multiple dimensions.</p>\n\n<p>EDIT: I am actually mostly interested in the location and scale parameters. For now I can assume that the degrees of freedom parameter is fixed, and possibly use some numeric scheme to find the optimal value later.</p>\n", "pids": ["5fe1d35e91e0119a161eddf7"], "flag": 1}
{"question": "Can a limit of an integral be moved inside the integral?", "body": "<p>After coming across this question: <a href=\"https://math.stackexchange.com/questions/253671/how-to-verify-this-limit\">How to verify this limit</a>, I have the following question:</p>\n<blockquote>\n<p>When taking the limit of an integral, is it valid to move the limit inside the integral, providing the limit does not affect the limits of integration?</p>\n</blockquote>\n<p>For instance in the question, the OP is trying to determine that:</p>\n<p><span class=\"math-container\">$$\\lim_{n\\to\\infty}\\int_{0}^{1}{\\frac{dx}{(1+\\frac{x}{n})^{n}}}=1-\\rm{e}^{-1}$$</span></p>\n<p>The answers to the question involve evaluating the integral and then taking the limit to prove the result; but I was wondering if it would be valid to move the integral inside the limit, that is:</p>\n<p><span class=\"math-container\">$$\\lim_{n\\to\\infty}{\\int_{0}^{1}{\\frac{dx}{(1+\\frac{x}{n})^{n}}}}=\\int_{0}^{1}{\\lim_{n\\to\\infty}\\frac{dx}{(1+\\frac{x}{n})^{n}}}=\\int_{0}^{1}{\\frac{dx}{{\\rm{e}}^x}}=\\rm{e}^{0}-\\rm{e}^{-1}=1-\\rm{e}^{-1}$$</span></p>\n<p>As required. So is this a valid technique, or is it just coincidental that this works?</p>\n<p><strong>Check :</strong></p>\n<p><span class=\"math-container\">$\\displaystyle\\begin{align}\\lim\\limits_{n\\to\\infty}\\int_0^1&amp;\\dfrac{dx}{\\left(1+\\dfrac xn\\right)^n}=\\lim\\limits_{n\\to\\infty}\\left[\\dfrac{-n}{n-1}\\left(1+\\dfrac xn\\right)^{1-n}\\,\\right]_0^1=\\\\\n&amp;=\\lim\\limits_{n\\to\\infty}\\dfrac{-n}{n-1}\\left[\\left(1+\\dfrac1n\\right)^{1-n}-1\\right]=\\\\\n&amp;=\\lim\\limits_{n\\to\\infty}\\dfrac n{n-1}\\left[1-\\left(1+\\dfrac1n\\right)^{1-n}\\,\\right]=\\\\\n&amp;=\\lim\\limits_{n\\to\\infty}\\dfrac n{n-1}\\left[1-\\dfrac{\\left(1+\\dfrac1n\\right)}{\\left(1+\\dfrac1n\\right)^n}\\,\\right]=\\\\\n&amp;=1\\cdot\\left[1-\\dfrac1{\\rm{e}}\\right]=\\\\\n&amp;=1-\\rm{e}^{-1}\n\\end{align}$</span></p>\n<p><span class=\"math-container\">$\\displaystyle\\begin{align}\\int_0^1 \\lim\\limits_{n\\to\\infty}\\dfrac{dx}{\\left(1+\\dfrac xn\\right)^n}&amp;=\\int_0^1\\dfrac{dx}{{\\rm{e}}^x}=\\bigg[\\!-{\\rm{e}}^{-x}\\bigg]_0^1=\\\\\n&amp;=\\rm{e}^0-\\rm{e}^{-1}=1-\\rm{e}^{-1}\n\\end{align}$</span></p>\n", "pids": ["5ff68d39d4150a363cd4c6ad"], "flag": 0}
{"question": "Why do I get zero variance of a random effect in my mixed model, despite some variation in the data?", "body": "<p>We’ve run a mixed effects logistic regression using the following syntax;</p>\n\n<pre><code># fit model\nfm0 &lt;- glmer(GoalEncoding ~ 1 + Group + (1|Subject) + (1|Item), exp0,\n             family = binomial(link=\"logit\"))\n# model output\nsummary(fm0)\n</code></pre>\n\n<p>Subject and Item are the random effects. We’re getting an odd result which is the coefficient and standard deviation for the subject term are both zero;</p>\n\n<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace\nApproximation) [glmerMod]\nFamily: binomial  ( logit )\nFormula: GoalEncoding ~ 1 + Group + (1 | Subject) + (1 | Item)\nData: exp0\n\nAIC      BIC      logLik deviance df.resid \n449.8    465.3   -220.9    441.8      356 \n\nScaled residuals: \nMin     1Q Median     3Q    Max \n-2.115 -0.785 -0.376  0.805  2.663 \n\nRandom effects:\nGroups  Name        Variance Std.Dev.\nSubject (Intercept) 0.000    0.000   \nItem    (Intercept) 0.801    0.895   \nNumber of obs: 360, groups:  Subject, 30; Item, 12\n\nFixed effects:\n                Estimate Std. Error z value Pr(&gt;|z|)    \n (Intercept)     -0.0275     0.2843    -0.1     0.92    \n GroupGeMo.EnMo   1.2060     0.2411     5.0  5.7e-07 ***\n ---\n Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Correlation of Fixed Effects:\n             (Intr)\n GroupGM.EnM -0.002\n</code></pre>\n\n<p>This should not be happening because obviously there is variation across subjects. When we run the same analysis in stata</p>\n\n<pre><code>xtmelogit goal group_num || _all:R.subject || _all:R.item\n\nNote: factor variables specified; option laplace assumed\n\nRefining starting values: \n\nIteration 0:   log likelihood = -260.60631  \nIteration 1:   log likelihood = -252.13724  \nIteration 2:   log likelihood = -249.87663  \n\nPerforming gradient-based optimization: \n\nIteration 0:   log likelihood = -249.87663  \nIteration 1:   log likelihood = -246.38421  \nIteration 2:   log likelihood =  -245.2231  \nIteration 3:   log likelihood = -240.28537  \nIteration 4:   log likelihood = -238.67047  \nIteration 5:   log likelihood = -238.65943  \nIteration 6:   log likelihood = -238.65942  \n\nMixed-effects logistic regression               Number of obs      =       450\nGroup variable: _all                            Number of groups   =         1\n\n                                                Obs per group: min =       450\n                                                               avg =     450.0\n                                                               max =       450\n\nIntegration points =   1                        Wald chi2(1)       =     22.62\nLog likelihood = -238.65942                     Prob &gt; chi2        =    0.0000\n\n------------------------------------------------------------------------------\n        goal |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]\n-------------+----------------------------------------------------------------\n   group_num |   1.186594    .249484     4.76   0.000     .6976147    1.675574\n       _cons |  -3.419815   .8008212    -4.27   0.000    -4.989396   -1.850234\n------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects Parameters  |   Estimate   Std. Err.     [95% Conf. Interval]\n-----------------------------+------------------------------------------------\n_all: Identity               |\n               sd(R.subject) |   7.18e-07   .3783434             0           .\n-----------------------------+------------------------------------------------\n_all: Identity               |\n                 sd(R.trial) |   2.462568   .6226966      1.500201    4.042286\n------------------------------------------------------------------------------\nLR test vs. logistic regression:     chi2(2) =   126.75   Prob &gt; chi2 = 0.0000\n\nNote: LR test is conservative and provided only for reference.\nNote: log-likelihood calculations are based on the Laplacian approximation.\n</code></pre>\n\n<p>the results are as expected with a non-zero coefficient / s.e. for the Subject term.</p>\n\n<p>Originally we thought this might be something to do with the coding of the Subject term, but changing this from a string to an integer did not make any difference.</p>\n\n<p>Obviously the analysis is not working properly, but we are unable to pin down the source of the difficulties. (NB someone else on this forum has been experiencing a similar issue, but this thread remains unanswered <a href=\"https://stats.stackexchange.com/questions/113610/instability-in-glmer-model-at-zero-random-effect-variance\">link to question</a>)</p>\n", "pids": ["56d909abdabfae2eee0e2e86"], "flag": 1}
{"question": "A strange integral: $\\int_{-\\infty}^{+\\infty} {dx \\over 1 + \\left(x + \\tan x\\right)^2} = \\pi.$", "body": "<p>While browsing on <a href=\"http://integralsandseries.prophpbb.com/post3169.html\" rel=\"noreferrer\">Integral and Series</a>, I found a strange integral posted by @<a href=\"https://math.stackexchange.com/users/9340/sos440\">Sangchul Lee</a>. His post doesn't have a response for more than a month, so I decide to post it here. I hope he doesn't mind because the integral looks very interesting to me. I hope for you too. :-)</p>\n\n<p><a src=\"https://i.stack.imgur.com/SMxR6.png\" alt=\"enter image description here\"></p>\n\n<p>$$\\mbox{How does one prove}\\quad\n\\int_{-\\infty}^{\\infty}\n{{\\rm d}x \\over 1 + \\left[\\,x + \\tan\\left(\\, x\\,\\right)\\,\\right]^{2}} = \\pi\\quad\n{\\large ?}\n$$</p>\n\n<p>Please don't ask me, I really have no idea how to prove it. I hope users here can find the answer to prove the integral. I'm also interested in knowing any references related to this integral. Thanks in advance.</p>\n", "pids": ["53e99ad7b7602d9702359566"], "flag": 0}
{"question": "Mathematical precise definition of a PDE being elliptic, parabolic or hyperbolic", "body": "<p>what is the general definition for some partial differential equation being called elliptic, parabolic or hyperbolic - in particular, if the PDE is nonlinear and above second-order.</p>\n\n<p>So far, I have not found any precise definition in literature.</p>\n", "pids": ["53e9a5e2b7602d9702f10702", "53e9a2fab7602d9702c0358e"], "flag": 0}
{"question": "Conjectured formula for the Fabius function", "body": "<p>The <a href=\"https://en.wikipedia.org/wiki/Fabius_function\" rel=\"noreferrer\">Fabius function</a> is the unique  function <span class=\"math-container\">${\\bf F}:\\mathbb R\\to[-1, 1]$</span> satisfying the following conditions:</p>\n\n<ul>\n<li>a functional–integral equation<span class=\"math-container\">$\\require{action}\n\\require{enclose}{^{\\texttip{\\dagger}{a poet or philosopher could say \"it knows and replays its own future\"}}}$</span> <span class=\"math-container\">$\\displaystyle{\\bf F}(x)={\\small\\int_0^{2{\\tiny\\text{ }}x}}{\\bf F}\\left(t\\right)dt,\\,$</span> and</li>\n<li>a normalization condition <span class=\"math-container\">${\\bf F}(1)=1.$</span></li>\n</ul>\n\n<p>It is noteworthy that despite being <a href=\"https://en.wikipedia.org/wiki/Smoothness\" rel=\"noreferrer\">smooth</a> (class <span class=\"math-container\">$C^\\infty$</span>)<span class=\"math-container\">${^{\\texttip{\\dagger}{i.e. continuous and having continuous derivatives of any order}}}$</span> everywhere, <span class=\"math-container\">${\\bf F}(x)$</span> is not <a href=\"https://en.wikipedia.org/wiki/Analytic_function#Real_versus_complex_analytic_functions\" rel=\"noreferrer\">real-analytic</a> at any point <span class=\"math-container\">$x\\ge0$</span> — its <a href=\"https://en.wikipedia.org/wiki/Taylor_series\" rel=\"noreferrer\">Taylor series</a> there is either <a href=\"https://en.wikipedia.org/wiki/Divergent_series\" rel=\"noreferrer\">divergent</a>, or a polynomial with a finite number of terms.<span class=\"math-container\">${^{\\texttip{\\dagger}{the latter happens at dyadic rational points}}}$</span></p>\n\n<p>Unlike some other functions that appear specifically constructed for that purpose, the Fabius function naturally occurs in research of several seemingly unrelated problems — perhaps, this is why it has been discovered and re-discovered independently many times by several mathematicians. It also has some practical applications in computational mathematics.</p>\n\n<p><a href=\"https://i.stack.imgur.com/RGqBP.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/RGqBP.png\" alt=\"Fabius function\"></a></p>\n\n<p>The Fabius function <span class=\"math-container\">${\\bf F}(x)$</span> is constant <span class=\"math-container\">$0$</span> for all <span class=\"math-container\">$x\\le0,$</span>  but some authors prefer to define it only on <span class=\"math-container\">$[0,\\infty)$</span> or only on <span class=\"math-container\">$[0,1].$</span> Some authors study a very closely related Rvachev<span class=\"math-container\">${^{\\texttip{\\dagger}{also variously spelled as Rvachëv or Rvachyov, a.k.a. \"atomic function\"}}}$</span> function <span class=\"math-container\">$\\operatorname{up}(x)$</span> defined as <span class=\"math-container\">$\\operatorname{up}(x) = {\\bf F}(x+1)$</span> for <span class=\"math-container\">$-1\\le x\\le1$</span> and <span class=\"math-container\">$\\operatorname{up}(x) = 0$</span> otherwise.</p>\n\n<p>It is known that the Fabius function assumes rational values at <a href=\"https://en.wikipedia.org/wiki/Dyadic_rational\" rel=\"noreferrer\">dyadic rational</a> arguments — efficient algorithms to compute those values have been published or posted online, and have been discussed on this site.<a href=\"https://arxiv.org/abs/1609.07999\" rel=\"noreferrer\"><span class=\"math-container\">$^{[1]}$</span></a><a href=\"https://arxiv.org/abs/1702.05442\" rel=\"noreferrer\"><span class=\"math-container\">$\\!^{[2]}$</span></a><a href=\"https://arxiv.org/abs/1702.06487\" rel=\"noreferrer\"><span class=\"math-container\">$\\!^{[3]}$</span></a><a href=\"http://math.colgate.edu/~integers/s51/s51.pdf\" rel=\"noreferrer\"><span class=\"math-container\">$\\!^{[4]}$</span></a><a href=\"https://math.stackexchange.com/q/240687/19661\"><span class=\"math-container\">$\\!^{[5]}$</span></a><a href=\"https://math.stackexchange.com/q/218832/19661\"><span class=\"math-container\">$\\!^{[6]}$</span></a><a href=\"https://math.stackexchange.com/q/2497242/19661\"><span class=\"math-container\">$\\!^{[7]}$</span></a><a href=\"https://mathematica.stackexchange.com/q/120331/7288\"><span class=\"math-container\">$\\!^{[8]}$</span></a><a href=\"https://mathoverflow.net/q/261649/9550\"><span class=\"math-container\">$\\!^{[9]}$</span></a></p>\n\n<p>I have been looking for a non-recursive, self-contained formula for the Fabius function for quite a long time. After lots of experimentation and looking for patterns in its values I came up with a conjectured empirical formula. Let<span class=\"math-container\">${^{\\texttip{\\dagger}{the superscript 𝑚 is just an index here, not to be confused with a power}}}$</span>\n<span class=\"math-container\">$$\\mathscr F^m_n = \\frac1{2^{n^2}\\left(\\frac12;{\\tiny\\text{ }}\\frac12\\right)_n}\\,\\sum _{k=0}^n\\frac{\\binom n k_{1/2}}{2^{{\\tiny\\text{ }}k{\\tiny\\text{ }}(k-1)}(n+k)!}\\,\\sum _{\\ell=0}^{2^k{\\tiny\\text{ }}m-1}\\,(-1)^{s_2\\left(\\ell\\right)}\\,\\left(\\ell-2^km+\\tfrac12\\right)^{n+k}{\\small,}\\tag{$\\small\\spadesuit$}$$</span>\nwhere <span class=\"math-container\">$k,\\,\\ell,\\,m,\\,n$</span> are non-negative integers, <span class=\"math-container\">$\\displaystyle\\small\\left(a;{\\tiny\\text{ }}q\\right)_n=\\prod_{k=0}^{n-1} (1-a{\\tiny\\text{ }}q^k)$</span> is the <a href=\"https://en.wikipedia.org/wiki/q-Pochhammer_symbol\" rel=\"noreferrer\"><em>q</em>-Pochhammer symbol</a><span class=\"math-container\">${^{\\texttip{\\dagger}{it assumes only rational values in this formula}}}$</span>, <span class=\"math-container\">${\\binom n k}_q=\\displaystyle\\small\\frac{\\left(q;{\\tiny\\text{ }}q\\right)_n}{\\left(q;{\\tiny\\text{ }}q\\right)_k\\left(q;{\\tiny\\text{ }}q\\right)_{n-k}}\\vphantom{\\Huge|}$</span> is the <a href=\"https://en.wikipedia.org/wiki/q-binomial_coefficient\" rel=\"noreferrer\"><em>q</em>-binomial coefficient</a><span class=\"math-container\">${^{\\texttip{\\dagger}{it assumes only rational values in this formula}}}$</span>, and <span class=\"math-container\">$s_2(n)\\vphantom{\\Huge|}$</span> is the <a href=\"https://en.wikipedia.org/wiki/Digit_sum\" rel=\"noreferrer\">sum of</a> <a href=\"https://en.wikipedia.org/wiki/Binary_number\" rel=\"noreferrer\">binary digits</a><span class=\"math-container\">${^{\\texttip{\\dagger}{i.e. the number of 1's in the base-2 representation}}}$</span> of <span class=\"math-container\">$n$</span> (note that <span class=\"math-container\">$(-1)^{s_2\\left(n\\right)} = t_n\\vphantom{\\Huge|}$</span> is just the signed version of the <a href=\"https://en.wikipedia.org/wiki/Thue%E2%80%93Morse_sequence\" rel=\"noreferrer\">Thue–Morse sequence</a>, satisfying recurrence <span class=\"math-container\">$t_0 = 1,\\,t_n = (-1)^n \\, t_{\\lfloor n/2\\rfloor};\\vphantom{\\Huge|}$</span> see also<a href=\"https://en.wikipedia.org/wiki/Evil_number\" rel=\"noreferrer\"><span class=\"math-container\">${^{[10]}}$</span></a><a href=\"https://en.wikipedia.org/wiki/Odious_number\" rel=\"noreferrer\"><span class=\"math-container\">${\\!^{[11]}}$</span></a><a href=\"https://oeis.org/A010060\" rel=\"noreferrer\"><span class=\"math-container\">${\\!^{[12]}}$</span></a>).</p>\n\n<p>I conjecture that for all non-negative integers <span class=\"math-container\">$m,\\,n,$</span> the following identity holds:\n<span class=\"math-container\">$${\\bf F}\\!\\left({\\small\\frac m{2^n}}\\right)=\\mathscr F^m_n.\\tag{$\\small\\diamondsuit$}$$</span>\nNote that there is no requirement for <span class=\"math-container\">$\\frac m{2^n}$</span> to be a proper irreducible fraction — it might well be that <span class=\"math-container\">$m$</span> is even, or <span class=\"math-container\">$m&gt;2^n$</span>. I have not been able to rigorously prove it yet, but it produces exact rational values that agree with those computed using known correct algorithms for all dyadic rational arguments I have tried. Of course, this formula did not just appear out of the blue — its structure was inspired by known algorithms, and it went a long way to this relatively concise form (at some point it had about <span class=\"math-container\">$5$</span> levels of nested summations/products).</p>\n\n<ul>\n<li>Can we prove that <span class=\"math-container\">$\\small(\\diamondsuit)$</span> is indeed a correct representation of the Fabius function at dyadic rationals?</li>\n<li>If the conjecture is difficult to tackle at once, we can try to at least prove that the function defined by <span class=\"math-container\">$\\small(\\spadesuit)$</span> shares some known properties with the Fabius function, e.g.:\n\n<ul>\n<li><span class=\"math-container\">$0\\le\\mathscr F^m_n\\le1,$</span></li>\n<li><span class=\"math-container\">$\\mathscr F^m_n = \\mathscr F^{2{\\tiny\\text{ }}m}_{n+1}\\vphantom{\\Large|}$</span> — the result is the same across all representations of a rational number <span class=\"math-container\">$\\frac m{2^n}$</span>,</li>\n<li><span class=\"math-container\">$\\mathscr F^m_n = 1-\\mathscr F^{(2^n-m)}_n\\vphantom{\\Large|}$</span> for all <span class=\"math-container\">$\\small0\\le m\\le2^{n}$</span> — rotation symmetry,</li>\n<li><span class=\"math-container\">$\\mathscr F^m_n = \\mathscr F^{(2^{n+1}-m)}_n\\vphantom{\\Large|}$</span> for all <span class=\"math-container\">$\\small0\\le m\\le2^{n+1}$</span> — reflection symmetry,</li>\n<li>for a fixed <span class=\"math-container\">$n,$</span> and <span class=\"math-container\">$\\small0\\le m\\le2^n$</span> the values of <span class=\"math-container\">$\\mathscr F^m_n\\vphantom{\\Large|}$</span> strictly increase,</li>\n<li>all points <span class=\"math-container\">$\\small\\left(\\frac m{2^n},\\,\\mathscr F^m_n\\right)\\vphantom{\\Large|}$</span> lie on a continuous curve — for any convergent sequence of dyadic rationals <span class=\"math-container\">$\\frac m{2^n}\\vphantom{\\Large|}$</span>, the sequence of corresponding values <span class=\"math-container\">$\\mathscr F^m_n\\vphantom{\\Large|}$</span> also converges.</li>\n</ul></li>\n</ul>\n\n\n\n<p>If the conjecture <span class=\"math-container\">$\\small(\\diamondsuit)$</span> it true, then for all <span class=\"math-container\">$0\\le x\\le1$</span> (not necessary rational)\n<span class=\"math-container\">$${\\bf F}\\!\\left(x\\right)=\\lim_{n\\to\\infty}\\,\\frac1{2^{n^2}\\left(\\frac12;{\\tiny\\text{ }}\\frac12\\right)_n}\\,\\sum _{k=0}^n\\frac{\\binom n k_{1/2}}{2^{{\\tiny\\text{ }}k{\\tiny\\text{ }}(k-1)}(n+k)!}\\,\\sum _{\\ell=0}^{\\left\\lfloor2^{n+k}{\\tiny\\text{ }}x-1\\right\\rfloor}\\,(-1)^{s_2\\left(\\ell\\right)}\\,\\left(\\ell-2^{n+k}{\\tiny\\text{ }}x+\\tfrac12\\right)^{n+k}.\\tag{$\\small\\heartsuit$}$$</span>\nFor dyadic rational <span class=\"math-container\">$x$</span> the limit is trivial, because the sequence under the limit becomes constant for large enough <span class=\"math-container\">$n$</span>. Also, there is a known series (by Rvachev) that expresses values of the Fabius function for all <span class=\"math-container\">$0\\le x\\le1$</span> via its values at negative powers of <span class=\"math-container\">$2$</span>:\n<span class=\"math-container\">$${\\bf F}\\!\\left(x\\right)=\\sum _{n=1}^\\infty\\frac{(-1)^{\\left\\lfloor 2^n{\\tiny\\text{ }}x\\right\\rfloor }-1}{2}\\,(-1)^{s_2\\left(\\lfloor2^n{\\tiny\\text{ }}x\\rfloor\\right)}\\;\\sum_{k=0}^n\\frac{2^{\\frac{k{\\tiny\\text{ }}(k+1)}2}}{k!}\\,\\left(x-2^{-n}\\left\\lfloor 2^n{\\tiny\\text{ }}x\\right\\rfloor\\right)^k\\;{\\bf F}\\!\\left(2^{{\\tiny\\text{ }}k-n}\\right).\\tag{$\\small\\clubsuit$}$$</span>\nAgain, for dyadic rational <span class=\"math-container\">$x$</span> this series terminates after a finite number of terms, producing an exact rational value.</p>\n", "pids": ["5d80b6cf3a55acb8a2d7807b"], "flag": 0}
{"question": "What does &quot;independent observations&quot; mean?", "body": "<p>I'm trying to understand what the <strong>assumption of independent observations</strong> means.  Some definitions are:  </p>\n\n<ol>\n<li>\"Two events are independent if and only if $P(a \\cap b) = P(a) * P(b)$.\" (<a href=\"http://www.nedarc.org/statisticalhelp/statisticalTermsDictionary.html\" rel=\"noreferrer\">Statistical Terms Dictionary</a>)</li>\n<li>\"the occurrence of one event doesn't change the probability for another\" (<a href=\"http://en.wikipedia.org/wiki/Independence_(probability_theory)\" rel=\"noreferrer\">Wikipedia</a>).</li>\n<li>\"sampling of one observation does not affect the choice of the second observation\" (<a href=\"http://davidmlane.com/hyperstat/A124488.html\" rel=\"noreferrer\">David M. Lane</a>).</li>\n</ol>\n\n<p>An example of dependent observations that's often given is students nested within teachers as below. Let's assume that teachers influence students but students don't influence one another.</p>\n\n<p><strong>So how are these definitions violated for these data?</strong> Sampling [grade  = 7] for [student = 1] does not affect the probability distribution for the grade that will be sampled next. (Or does it? And if so, then what does observation 1 predict regarding the next observation?) </p>\n\n<p><strong>Why would the observations be independent if I had measured</strong> <code>gender</code> <strong>instead of</strong> <code>teacher_id</code><strong>?</strong> Don't they affect the observations in the same way?</p>\n\n  \n\n<pre><code>teacher_id   student_id   grade\n         1            1       7\n         1            2       7\n         1            3       6\n         2            4       8\n         2            5       8\n         2            6       9\n</code></pre>\n", "pids": ["53e9abf1b7602d97035af45a"], "flag": 1}
{"question": "Is there a characterization of groups with the property $\\forall N\\unlhd G,\\:\\exists H\\leq G\\text{ s.t. }H\\cong G/N$?", "body": "<p>A common mistake for beginning group theory students is the belief that a quotient of a group <span class=\"math-container\">$G$</span> is necessarily isomorphic to a subgroup of <span class=\"math-container\">$G$</span>.  Is there a characterization of the groups in which this property holds?</p>\n\n<p>If this question is too broad, I might ask if such a characterization exists for <span class=\"math-container\">$p$</span>-groups.</p>\n\n\n\n<p><em>History</em>: I originally posed the opposite question, regarding groups for which <span class=\"math-container\">$\\exists N\\unlhd G\\,:\\, \\not\\exists H \\unlhd G\\, \\text{  s.t. } H \\cong G/N$</span>, and crossposted this to <a href=\"https://mathoverflow.net/questions/119045/is-there-a-characterization-of-groups-in-which-at-least-one-subgroup-is-not-an-en\">MO</a>.  I received an answer there to the (now omitted) peripheral question about probability, which shows that most finite groups probably have this property.  After this, I changed the question to its current state, as this smaller collection of groups is more likely to be characterizable.</p>\n", "pids": ["53e9b414b7602d9703f0d063"], "flag": 0}
{"question": "Why is xgboost overfitting in my task? Is it fine to accept this overfitting?", "body": "<p>My set-up is the following:</p>\n<p>I am following  the guide lines in &quot;Applied Predictive Modeling&quot;. Thus I have filtered correlated features and end up with the following:</p>\n<ul>\n<li>4900 data points in the training set and 1600 data points in the test set.</li>\n<li>I have 26 features and the target is a continuous variable.</li>\n</ul>\n<p>I apply 5-fold cross-validation to train models using the <code>caret</code> package.\nWhen I apply a MARS model then I get a mean absolute error (MAE) of approximately 4 on the training set as well as on the test set.</p>\n<p>However applying XGBgboost (either the tree algorithm or the linear one) I get something like 0.32 (!) on the training set and 2.4 on the test set.</p>\n<p>Thus if the test error is 8 times the training error then I would say: I have overfit the training data. Still I get a smaller error on test anyways.</p>\n<p>I use the following parameters on xgboost:</p>\n<ul>\n<li><code>nrounds = 1000</code> and <code>eta = 0.01</code> (increasing nrounds and decreasing eta could help but I run out of memory and run time is too long)</li>\n<li><code>max_depth = 16</code>: if I compare other posts and the default of 6 then this looks large but the problem is pretty complex - maybe 16 is not too large in this case.</li>\n<li><code>colsample_bytree = 0.7</code>,<code>subsample = 0.8</code> and <code>min_child_weight = 5</code>: doing this I try to reduce overfit.</li>\n</ul>\n<p>If I reduce max_depth then train and test-error get closer but still there is a large gap and the test-error is larger (a bit above 3).</p>\n<p>Using the linear booster I get the roughly the same train and test error on optimal parameters:</p>\n<ul>\n<li><code>lambda = 90</code> and `alpha = 0: found by cross-validation, lambda should prevent overfit.</li>\n<li><code>colsample_bytree = 0.8</code>,<code>subsample = 0.8</code> and <code>min_child_weight = 5</code>: doing this I try to reduce overfit.</li>\n</ul>\n<p>My feeling is that XGBoost still overfits - but the training error and as far as I can see in the real time test (I have used the XGBoost models and an ensemble of them in reality for 4 days) looks ok-ish (the error is larger than the test error but there are is more uncertainty in real life about the forecast of features and other variables).</p>\n<p>What do you think: can I accept overfit if (if this is possible) real life performance is superior? Does XGBoost in my setting tend to overfit?</p>\n", "pids": ["5cede100da562983788dfdda"], "flag": 1}
{"question": "Are these solutions of $2 = x^{x^{x^{\\:\\cdot^{\\:\\cdot^{\\:\\cdot}}}}}$ correct?", "body": "<blockquote>\n  <p>Find $x$ in\n  $$ \\Large 2 = x^{x^{x^{\\:\\cdot^{\\:\\cdot^{\\:\\cdot}}}}}$$</p>\n</blockquote>\n\n<p>A trick to solve this is to see that\n$$\\large\n2 = x^{x^{x^{\\:\\cdot^{\\:\\cdot^{\\:\\cdot}}}}}\n\\quad\\implies\\quad\n2 = x^{\\Big(x^{x^{x^{\\:\\cdot^{\\:\\cdot^{\\:\\cdot}}}}}\\Big)} = x^2\n\\quad\\implies\\quad\nx = \\pm \\sqrt{2}\n$$</p>\n\n<p>Are these solutions correct? If not, why? If yes, are there other solutions?</p>\n\n\n\n<p>PS: An extension of this discussion can be found in <a href=\"https://math.stackexchange.com/questions/89375/what-we-can-say-about-sqrt2-sqrt2-sqrt2-ldots\">What we can say about $(-\\sqrt{2})^{(-\\sqrt{2})^{(-\\sqrt{2})^\\ldots}}$?</a></p>\n", "pids": ["62173ec65aee126c0f86e0e1"], "flag": 1}
{"question": "Hanging a picture on the wall using two nails in such a way that removing any nail makes the picture fall down", "body": "<p>A friend of mine told me that it's possible to hang a picture on the wall from a string using two nails in such a way that removing either of the two nails will make both the string and picture fall down. My friend also told me that I need to be acquainted with the concept of fundamental groups to understand the solution. The problem is that I'm not. Is there really no solution to this straightforward problem that doesn't require acquaintance with fundamental groups?</p>\n", "pids": ["53e9982cb7602d970204de3a"], "flag": 0}
{"question": "How could stochastic gradient descent save time compared to standard gradient descent?", "body": "<p>Standard Gradient Descent would compute gradient for the entire training dataset.</p>\n\n<pre><code>for i in range(nb_epochs):\n  params_grad = evaluate_gradient(loss_function, data, params)\n  params = params - learning_rate * params_grad\n</code></pre>\n\n<p><em>For a pre-defined number of epochs, we first compute the gradient vector weights_grad of the loss function for the whole dataset w.r.t. our parameter vector params.</em></p>\n\n<p>Stochastic Gradient Descent in contrast performs a parameter update for each training example x(i) and label y(i).</p>\n\n<pre><code>for i in range(nb_epochs):\n  np.random.shuffle(data)\n  for example in data:\n    params_grad = evaluate_gradient(loss_function, example, params)\n    params = params - learning_rate * params_grad\n</code></pre>\n\n<p>SGD is said to be much faster. However, I do not understand how it can be much faster if we still have a loop over all data points. Does the computation of the gradient in GD is much slower than computation of GD for each data point separately?</p>\n\n<p>Code comes from <a href=\"http://sebastianruder.com/optimizing-gradient-descent/index.html#shufflingandcurriculumlearning\" rel=\"noreferrer\">here</a>.</p>\n", "pids": ["5ede0553e06a4c1b26a83f7b"], "flag": 1}
{"question": "What are the applications of functional analysis?", "body": "<p>I recently had a course on functional analysis. I was thinking of studying the mathematical applications of functional analysis. I came to know it had some applications on calculus of variations. I am not specifically interested in applications of functional analysis on pure branches of mathematics but rather interested in applied mathematics.</p>\n\n<p>Can anyone give a brief on what are the mathematical applications of functional analysis? Also, please suggest some good books for it.</p>\n", "pids": ["5c757377f56def97988a0a0a"], "flag": 0}
{"question": "Factorial of a matrix: what could be the use of it?", "body": "<p>Recently on this site, the <a href=\"https://math.stackexchange.com/q/1634488/264509\">question was raised</a> how we might define the factorial operation $\\mathsf{A}!$ on a square matrix $\\mathsf{A}$. The <a href=\"https://math.stackexchange.com/a/1634551/264509\">answer</a>, perhaps unsurprisingly, involves the <a href=\"https://en.wikipedia.org/wiki/Gamma_function\" rel=\"noreferrer\">Gamma function</a>.</p>\n\n<p>What use might it be to take the factorial of a matrix?  Do any applications come to mind, or does this – for now* – seem to be restricted to the domain of recreational mathematics?</p>\n\n<p><sup>(*Until e.g. theoretical physics turns out to have a use for this, as happened with <a href=\"https://en.wikipedia.org/wiki/Calabi%E2%80%93Yau_manifold\" rel=\"noreferrer\">Calabi–Yau manifolds</a> and <a href=\"https://en.wikipedia.org/wiki/Superstring_theory\" rel=\"noreferrer\">superstring theory</a>...)</sup></p>\n", "pids": ["5cede0f0da562983788ced83"], "flag": 0}
{"question": "Integral $\\int_1^\\infty\\operatorname{arccot}\\left(1+\\frac{2\\pi}{\\operatorname{arcoth}x-\\operatorname{arccsc}x}\\right)\\frac{\\mathrm dx}{\\sqrt{x^2-1}}$", "body": "<p>Consider the following integral:\n<span class=\"math-container\">$$\\mathcal{I}=\\int_1^\\infty\\operatorname{arccot}\\left(1+\\frac{2\\,\\pi}{\\operatorname{arcoth}x\\,-\\,\\operatorname{arccsc}x}\\right)\\frac{\\mathrm dx}{\\sqrt{x^2-1}}\\,,$$</span>\nwhere <span class=\"math-container\">$\\operatorname{arccsc}$</span> is the <a href=\"http://en.wikipedia.org/wiki/Inverse_cosecant\" rel=\"noreferrer\">inverse cosecant</a>, <span class=\"math-container\">$\\operatorname{arccot}$</span> is the <a href=\"http://en.wikipedia.org/wiki/Inverse_cotangent\" rel=\"noreferrer\">inverse cotangent</a> and <span class=\"math-container\">$\\operatorname{arcoth}x$</span> is the <a href=\"http://en.wikipedia.org/wiki/Inverse_hyperbolic_cotangent#Logarithmic_representation\" rel=\"noreferrer\">inverse hyperbolic cotangent</a>.</p>\n<p>Approximate numerical integration suggests a possible closed form:\n<span class=\"math-container\">$$\\mathcal{I}\\stackrel?=\\frac{\\pi\\,\\ln\\pi}4-\\frac{3\\,\\pi\\,\\ln2}8.$$</span>\nI was not able to rigorously establish the equality, but the value is correct up to at least <span class=\"math-container\">$900$</span> decimal digits.</p>\n<blockquote>\n<p>Is it the correct exact value of the integral <span class=\"math-container\">$\\,\\mathcal{I}$</span>?</p>\n</blockquote>\n", "pids": ["60f16b0b91e011963c8d4528", "60f16b0b91e011963c8d4528"], "flag": 0}
{"question": "Why does Friedberg say that the role of the determinant is less central than in former times?", "body": "<p>I am taking a proof-based introductory course to Linear Algebra as an undergrad student of Mathematics and Computer Science. The author of my textbook (Friedberg's <em>Linear Algebra</em>, 4th Edition) says in the introduction to Chapter 4:</p>\n\n<blockquote>\n  <p>The determinant, which has played a prominent role in the theory of linear algebra, is a special scalar-valued function defined on the set of square matrices. <strong>Although it still has a place in the study of linear algebra and its applications, its role is less central than in former times.</strong> </p>\n</blockquote>\n\n<p>He even sets up the chapter in such a way that you can skip going into detail and move on:</p>\n\n<blockquote>\n  <p>For the reader who prefers to treat determinants lightly, Section 4.4 contains the essential properties that are needed in later chapters.</p>\n</blockquote>\n\n<p>Could anyone offer a didactic and simple explanation that refutes or asserts the author's statement?</p>\n", "pids": ["53e997f1b7602d9701fee72b", "53e9b90ab7602d97044ed4e8"], "flag": 0}
{"question": "Simplest proof of Taylor&#39;s theorem", "body": "<p>I have for some time been trawling through the Internet looking for an aesthetic proof of Taylor's theorem.</p>\n\n<p>By which I mean this: there are plenty of proofs that introduce some arbitrary construct: no mention is given of from whence this beast came.  and you can logically hack away line by line until the thing is solved. but this kind of proof is ugly.  a beautiful proof should rise naturally from the ground.</p>\n\n<p>I've seen one proof claiming to do it from the fundamental theorem of calculus. It looked messy.</p>\n\n<p>I've seen several attempts to use integration by parts repeatedly. But surely it would be tidier to do this without bringing in  all of that extra machinery.</p>\n\n<p>The nicest two approaches seem to involve using the mean value theorem and Rolle's theorem.  but I can't find a lucid presentation of either approach.</p>\n\n<p>Maybe my brain is unusually stupid, and the approaches on Wikipedia etc are perfectly good enough for everyone else. </p>\n\n<p>Does anyone have a crystal clear understanding of this phenomenon? Or a web-link to such an understanding?</p>\n\n<p><em>*EDIT*: Eventually a Cambridge mathematician explained it to me in a way that I could understand, and I have written up the proof <a href=\"http://mathpad.wikidot.com/taylor\" rel=\"noreferrer\">here</a>. To my mind it is the most instructional proof I have encountered, yet putting it as an answer received mostly downvotes. It seems strange to me that no one else seems to concur.  But it should be up to the keenest mathematical minds to choose which answer should be accepted. It shouldn't be up to me. Therefore I will bow to the wisdom of the community, and accept the currently most-upvoted answer. I have learned from Machine Learning that a \"Committee of Experts\" outperforms any one expert, and I am certainly no expert.</em></p>\n", "pids": ["53e9b1f8b7602d9703c8cdfa"], "flag": 0}
{"question": "Inter-rater reliability for ordinal or interval data", "body": "<p>Which inter-rater reliability methods are most appropriate for ordinal or interval data?</p>\n\n<p>I believe that \"Joint probability of agreement\" or \"Kappa\" are designed for nominal data. Whilst \"Pearson\" and \"Spearman\" can be used, they are mainly used for two raters (although they can be used for more than two raters).</p>\n\n<p>What other measures are suitable for ordinal or interval data, i.e. more than two raters?</p>\n", "pids": ["5c0f8785da562944ac9559cf"], "flag": 1}
{"question": "Conjectures (or intuitions) that turned out wrong in an interesting or useful way", "body": "<p>The question \n<a href=\"https://math.stackexchange.com/questions/2394388/what-seemingly-innocuous-results-in-mathematics-require-advanced-proofs\">What seemingly innocuous results in mathematics require advanced proofs?</a> prompts me to ask about conjectures or, less formally, beliefs or intuitions, that turned out wrong in interesting or useful ways.</p>\n\n<p>I have several in mind, but will provide just one here now, as an example.</p>\n\n<p>For centuries mathematicians tried to show that Euclid's parallel postulate followed from his others. When Lobachevsky,  Bolyai and Gauss discovered that you could do interesting geometry just as consistent as Euclid when the parallel postulate failed a whole new world was open for exploration.</p>\n\n<p>One example per answer, please. If you want to post several, answer repeatedly.</p>\n\n<p>Related:</p>\n\n<p><a href=\"https://math.stackexchange.com/questions/514/conjectures-that-have-been-disproved-with-extremely-large-counterexamples\">Conjectures that have been disproved with extremely large counterexamples?</a></p>\n", "pids": ["56d83f40dabfae2eee7acb59", "53e9a058b7602d970293ab2d"], "flag": 0}
{"question": "High frequency human genetic oscillators?", "body": "<p>The most well studied genetic oscillators in human genomes are involved in regulating the circadian clock (which operates on an approximately 24-hour cycle) and cell cycle activity (with single cycles usually lasting several hours to many days). Are there any known genetic oscillators in humans (or other mammals) that operate on shorter timescales? </p>\n", "pids": ["55a5c96765ce60f99bf5597b", "5f0e27619fced0a24b4de8b6"], "flag": 1}
{"question": "General request for a book on mathematical history, for a VERY advanced reader.", "body": "<p>I am aware that there are answered similar questions on here, however I am specifically after a text that would be engaging for a professor of mathematics, also Fellow of the Royal Society (FRS).</p>\n\n<p>He is unwell and in the hospital, and I would like to get him something to pass the time. However anything aimed at undergraduate / postgraduate level is going to be far too patronising. Honestly, I'm not sure if there exists such a book, but if anyone has any recommendations, I would be extremely grateful. </p>\n", "pids": ["5c75727ef56def9798819d45", "5effc916dfae5482196fc65f"], "flag": 0}
{"question": "Combinatorial proof that $\\sum \\limits_{k=0}^n \\binom{2k}{k} \\binom{2n-2k}{n-k} (-1)^k = 2^n \\binom{n}{n/2}$ when $n$ is even", "body": "<p>In <a href=\"https://math.stackexchange.com/questions/80092/how-can-i-express-sum-k-0n-binom-1-2k-1k-binom-1-2n-k-without-u/80101#80101\">my answer here</a> I prove, using generating functions, a statement equivalent to \n$$\\sum_{k=0}^n \\binom{2k}{k} \\binom{2n-2k}{n-k} (-1)^k = 2^n \\binom{n}{n/2}$$\nwhen $n$ is even.  (Clearly the sum is $0$ when $n$ is odd.)  The nice expression on the right-hand side indicates that there should be a pretty combinatorial proof of this statement.  The proof should start by associating objects with even parity and objects with odd parity counted by the left-hand side.  The number of leftover (unassociated) objects should have even parity and should \"obviously\" be $2^n \\binom{n}{n/2}$.  I'm having trouble finding such a proof, though.  So, my question is</p>\n\n<blockquote>\n  <p>Can someone produce a combinatorial proof that, for even $n$, $$\\sum_{k=0}^n \\binom{2k}{k} \\binom{2n-2k}{n-k} (-1)^k = 2^n \\binom{n}{n/2}?$$</p>\n</blockquote>\n\n<p><em>Some thoughts so far:</em> </p>\n\n<p>Combinatorial proofs for $\\sum_{k=0}^n \\binom{2k}{k} \\binom{2n-2k}{n-k}  = 4^n$ are given by <a href=\"https://math.stackexchange.com/questions/37971/identity-involving-binomial-coefficients/37984#37984\">Phira here</a> and by <a href=\"https://math.stackexchange.com/questions/72367/proof-of-a-combinatorial-identity-sum-i-0n-2i-choose-i2n-i-choose-n/72661#72661\">Brian M. Scott here</a>.  The proofs are basically equivalent.  In Phira's argument, both sides count the number of paths of length $2n$ starting from $(0,0)$ using steps of $(1,1)$ and $(1,-1)$.  By conditioning on the largest value of $2k$ for which a particular path returns to the horizontal axis at $(2k,0)$ and using the facts that there are $\\binom{2k}{k}$ paths from $(0,0)$ to $(2k,0)$ and $\\binom{2n-2k}{n-k}$ paths of length $2n-2k$ that start at the horizontal axis but never return to the axis we obtain the left-hand side.</p>\n\n<p>With these interpretations of the central binomial coefficients $2^n \\binom{n}{n/2}$ could count (1) paths that do not return to the horizontal axis by the path's halfway point of $(n,0)$, or (2) paths that touch the point $(n,0)$.  But I haven't been able to construct the association that makes these the leftover paths (nor do all of these paths have even parity anyway).  So perhaps there's some other interpretation of $2^n \\binom{n}{n/2}$ as the number of leftover paths.</p>\n\n<p><HR></p>\n\n<p><strong>Update.</strong> <em>Some more thoughts</em>:</p>\n\n<p>There's another way to view the identity $\\sum_{k=0}^n \\binom{2k}{k} \\binom{2n-2k}{n-k}  = 4^n$.  Both sides count the number of lattice paths of length $n$ when north, south, east, and west steps are allowed.  The right side is obvious. The left side has a similar interpretation as before: $\\binom{2k}{k}$ counts the number of NSEW lattice paths of length $k$ that end on the line $y=0$, and $\\binom{2n-2k}{n-k}$ counts the number of NSEW lattice paths of length $n-k$ that never return to the line $y =0$.  So far, this isn't much different as before.  However, $2^n \\binom{n}{n/2}$ has an intriguing interpretation: It counts the number of NSEW lattice paths that end on the diagonal $y = x$ (or, equivalently, $y = -x$).  So maybe there's an involution that leaves these as the leftover paths.  (Proofs of all of these claims can be found on <a href=\"http://mikespivey.wordpress.com/2012/01/04/morelatticestat/\" rel=\"noreferrer\">this blog post</a>, for those who are interested.)</p>\n", "pids": ["5c6107c2da56297340b15b4c"], "flag": 0}
{"question": "$x^y = y^x$ for integers $x$ and $y$", "body": "<p>We know that $2^4 = 4^2$ and $(-2)^{-4} = (-4)^{-2}$. Is there another pair of integers $x, y$ ($x\\neq y$) which satisfies the equality $x^y = y^x$?</p>\n", "pids": ["56d8e28bdabfae2eee1be4f7"], "flag": 0}
{"question": "$\\sum k! = 1! +2! +3! + \\cdots + n!$ ,is there a generic formula for this?", "body": "<p>I came across a question where I needed to find the sum of the factorials of the first <span class=\"math-container\">$n$</span> numbers. So I was wondering if there is any generic formula for this?</p>\n<p>Like there is a generic formula for the series:</p>\n<p><span class=\"math-container\">$$ 1 + 2 + 3 + 4 + \\cdots + n = \\frac{n(n+1)}{2} $$</span></p>\n<p>or</p>\n<p><span class=\"math-container\">$$ 1^{2} + 2^{2} + 3^{2} + 4^{2} + \\cdots + n^{2} = \\frac{n(n+1)(2n + 1)}{6} $$</span></p>\n<blockquote>\n<p>Is there is any formula for:</p>\n<p><span class=\"math-container\">$$ 1! +2! +3! + 4! + \\cdots + n! $$</span></p>\n<p>and</p>\n<p><span class=\"math-container\">$$ {1!}^2 +{2!}^2 +{3!}^2 + \\cdots + {n!}^2 $$</span>?</p>\n</blockquote>\n<p>Thanks in advance.</p>\n<p>If not, is there any research on making this type of formula?\nBecause I am interested.</p>\n", "pids": ["53e9a488b7602d9702da86f8"], "flag": 0}
{"question": "Laplace, Legendre, Fourier, Hankel, Mellin, Hilbert, Borel, Z...: unified treatment of transforms?", "body": "<p>I understand \"transform methods\" as recipes, but beyond this they are a big mystery to me.  </p>\n\n<p>There are two aspects of them I find bewildering.</p>\n\n<p>One is the sheer number of them.  Is there a unified framework that includes all these transforms as special cases?</p>\n\n<p>The second one is heuristic: what would lead anyone to <em>discover</em> such a transform in the course of solving a problem?</p>\n\n<p>(My hope is to find a unified treatment of the subject that simultaneously addresses both of these questions.)</p>\n", "pids": ["53e9a33db7602d9702c49c99"], "flag": 0}
{"question": "Conjecture $_2F_1\\left(\\frac14,\\frac34;\\,\\frac23;\\,\\frac13\\right)=\\frac1{\\sqrt{\\sqrt{\\frac4{\\sqrt{2-\\sqrt[3]4}}+\\sqrt[3]{4}+4}-\\sqrt{2-\\sqrt[3]4}-2}}$", "body": "<p>Using a numerical search on my computer I discovered the following inequality:\n$$\\left|\\,{_2F_1}\\left(\\frac14,\\frac34;\\,\\frac23;\\,\\frac13\\right)-\\rho\\,\\right|&lt;10^{-20000},\\tag1$$\nwhere $\\rho$ is the positive root of the polynomial equation\n$$12\\,\\rho^8-12\\,\\rho^4-8\\,\\rho^2-1=0,\\tag2$$\nthat can be expressed in radicals:\n$$\\rho=\\frac1{\\sqrt{\\sqrt{\\frac4{\\sqrt{2-\\sqrt[3]{4\\vphantom{\\large1}}}}+\\sqrt[3]{4}+4}-\\sqrt{2-\\sqrt[3]4}-2}}.\\tag3$$\nBased on this inequality I conjecture that the actual difference is the exact zero, i.e.\n$$\\color{#808080}{_2F_1\\left(\\frac14,\\frac34;\\,\\frac23;\\,\\frac13\\right)=\\rho}.\\tag4$$\nI looked up in <a href=\"http://dlmf.nist.gov/15.4\">DLMF</a> and <a href=\"http://mathworld.wolfram.com/HypergeometricFunction.html\">MathWorld</a>, but did not find a known special value with exactly these parameters. It also appears that CAS like <em>Maple</em> or <em>Mathematica</em> do not know this identity.</p>\n\n\n\n<p>Could you please suggest any ideas how to prove the conjecture $(4)$?</p>\n\n\n\n<p><em>Update:</em> I can propose even more general conjecture:\n$$\\color{#808080}{27\\,(x-1)^2\\cdot{_2F_1}\\left(\\tfrac14,\\tfrac34;\\tfrac23;x\\right)^8+18\\,(x-1)\\cdot{_2F_1}\\left(\\tfrac14,\\tfrac34;\\tfrac23;x\\right)^4-8\\cdot{_2F_1}\\left(\\tfrac14,\\tfrac34;\\tfrac23;x\\right)^2=1}$$</p>\n", "pids": ["53e9a6dfb7602d970301744e"], "flag": 0}
{"question": "How to compute the confidence interval of the ratio of two normal means", "body": "<p>I want to derive the limits for the $100(1-\\alpha)\\%$ confidence interval for the ratio of two means.<br>\nSuppose, $X_1 \\sim N(\\theta_1, \\sigma^2)$ and $X_2 \\sim N(\\theta_2, \\sigma^2)$\nbeing independent, the mean ratio $\\Gamma = \\theta_1/\\theta_2$. I tried to solve:\n$$\\text{Pr}(-z(\\alpha/2)) \\leq X_1 - \\Gamma X_2 / \\sigma  \\sqrt {1 + \\gamma^2} \\leq z(\\alpha/2)) = 1 - \\alpha$$ but that equation couldn't be solved for many cases (no roots). Am I doing something wrong? Is there a better approach? Thanks</p>\n", "pids": ["53e9b7b4b7602d970435a66a"], "flag": 1}
{"question": "Why should we prove obvious things?", "body": "<p>Obviously, there are obvious things in mathematics. Why we should prove them?</p>\n\n<ul>\n<li>Prove that $\\lim\\limits_{n\\to\\infty}\\dfrac{1}{n}=0$?</li>\n<li>Prove that $f(x)=x$ is continuous on $\\mathbb{R}$?</li>\n<li>$\\dotsc$</li>\n</ul>\n\n<p>Just to list few examples.</p>\n", "pids": ["56d82338dabfae2eeecaa708"], "flag": 1}
{"question": "What are some mathematical topics that involve adding and multiplying pictures?", "body": "<p>Let me give you an example of what I mean. Flag algebras are a tool used in extremal graph theory which involve writing inequalities that look like:</p>\n\n<p><a href=\"https://i.stack.imgur.com/rFEwb.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/rFEwb.png\" alt=\"flag algebra inequality\"></a></p>\n\n<p>(It's not too important to my question what this inequality means, but let me give you some context. Informally, the things we're adding and multiplying are probabilities that a random group of vertices in a large graph will induce some specific small subgraph. To make some manipulations rigorously justified, this is not precisely what we mean; instead, they are the limits of such probabilities over a convergent sequence of graphs.)</p>\n\n<p>Aside from being potentially useful in solving math problems I'm curious about, I enjoy using, thinking about, and even looking at statements about flag algebras, because these equations and inequalities just look so cool! Instead of multiplying, adding, and comparing letters and numbers, we get to do the same thing to pictures of things.</p>\n\n<p>So my question is: <strong>what are some other topics in mathematics where we get to do the same thing?</strong></p>\n\n<p>Obviously, you can always give any name you like to a variable, like those math problems you see on facebook where cherry plus banana is equal to three times hamburger. I'm not interested in examples like this, because there's nothing special about those variable names. Instead I'm interested in cases satisfying the following conditions:</p>\n\n<ul>\n<li>Mathematicians actually working with these objects commonly represent the things they are adding or multiplying or whatever (in general, performing algebraic manipulations on) by pictures.</li>\n<li>The pictures used to represent these objects are actually helpful for understanding what the objects are.</li>\n</ul>\n\n<p>It's okay if it's not adding or multiplying specifically we're doing, as long as we're manipulating the pictures in ways traditionally reserved for numbers or variables. For example, the things represented by pictures could be elements of some algebraic object (group, ring, etc.)</p>\n", "pids": ["5c864a7f4895d9cbc642dafd", "5ce2c849ced107d4c6228c89", "5c7856344895d9cbc6925eaf", "56d86c13dabfae2eeecee546", "56d92353dabfae2eeeab35c6", "53e9ac69b7602d970363b01e"], "flag": 0}
{"question": "Introduction to structural equation modeling", "body": "<p>I am asked by colleagues some help in this subject, that I don’t really know. They made hypotheses on the role of some latent variables in one study, and a referee asked them to formalize this in SEM. As what they need doesn’t seem too difficult, I think I’ll give it a shot ... for now, I am just looking for a good introduction to the subject!</p>\n<p>Google wasn’t really my friend on this.</p>\n<p>PS: I read <a href=\"http://socserv.mcmaster.ca/jfox/Misc/sem/SEM-paper.pdf\" rel=\"nofollow noreferrer\">Structural Equation Modeling\nWith the sem Package in R</a> by John Fox, and <a href=\"http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-sems.pdf\" rel=\"nofollow noreferrer\">this text</a> by the same author. I think this can be sufficient for my purpose, anyway any other references are welcome.</p>\n", "pids": ["5fdc7fcad4150a363ce2da97"], "flag": 1}
{"question": "Do &quot;Parabolic Trigonometric Functions&quot; exist?", "body": "<p>The parametric equation</p>\n\n<p>$$\\begin{align*}\nx(t) &amp;= \\cos t\\\\\ny(t) &amp;= \\sin t\n\\end{align*}$$</p>\n\n<p>traces the unit circle centered at the origin ($x^2+y^2=1$).   Similarly, </p>\n\n<p>$$\\begin{align*}\nx(t) &amp;= \\cosh t\\\\\ny(t) &amp;= \\sinh t\n\\end{align*}$$</p>\n\n<p>draws the right part of a regular hyperbola ($x^2-y^2=1$).  The hyperbolic trigonometric functions are very similar to the standard trigonometric function.</p>\n\n<p>Do similar functions exist that trace parabolas (because it is another conic section) when set up as parametric equations like the above functions?  If so, are they also similar to the standard and hyperbolic trigonometric functions?</p>\n", "pids": ["53e9b049b7602d9703aaa1d3"], "flag": 0}
{"question": "Python module for change point analysis", "body": "<p>I'm looking for a Python module that performs a change-point analysis on a time-series. There are a number of different algorithms and I'd like to explore the efficacy of some of them without having to hand-roll each of the algorithms.</p>\n\n<p>Ideally I'd like some modules like the <a href=\"http://cran.r-project.org/web/packages/bcp/index.html\">bcp</a> (Bayesian Change Point) or <a href=\"http://cran.r-project.org/web/packages/strucchange/index.html\">strucchange</a> packages in R. I expected to find some in Scipy but I haven't been able to turn up anything.</p>\n\n<p>I'm surprised that there aren't any facilities in:</p>\n\n<ul>\n<li><a href=\"http://statsmodels.sourceforge.net/stable/tsa.html\">statsmodels.tsa</a>: Time series statistical analysis tools</li>\n<li><a href=\"http://pytseries.sourceforge.net/\">scikits.timeseries</a>: Time series analysis tools to extend scipy</li>\n<li><a href=\"http://docs.scipy.org/doc/scipy-0.12.0/reference/signal.html\">scipy.signal</a>: signal processing tools in scipy</li>\n</ul>\n\n<p>Are there any modules with change point detection algorithms in Python?</p>\n", "pids": ["5a9cb66717c44a376ffb8a4b"], "flag": 1}
{"question": "Accommodating entrenched views of p-values", "body": "<p>Sometimes in reports I include a disclaimer about the p-values and other inferential statistics I've provided.  I say that since the sample wasn't random, then such statistics would not strictly apply.  My specific wording is usually given in a footnote:  </p>\n\n<blockquote>\n  <p>\"While, strictly speaking, inferential\n  statistics are only applicable in the\n  context of random sampling, we follow\n  convention in reporting significance\n  levels and/or confidence intervals as\n  convenient yardsticks even for\n  nonrandom samples. See Michael Oakes's\n  <em>Statistical inference: A commentary for the social and behavioural\n  sciences</em>  (NY: Wiley, 1986).</p>\n</blockquote>\n\n<p>On a couple of occasions--once for a peer-reviewed paper, once or twice in a non-academic setting--the editor or reviewer objected to this disclaimer, calling it confusing, and felt that the inferential findings should simply stand as written (and be given the mantle of authority).  Has anyone else encountered this problem and found a good solution?  On the one hand, people's understanding of p-values is generally dismal, even in the context of random sampling, so perhaps it doesn't matter much what we say.  On the other, to contribute further to misunderstandings seems to make one part of the problem. I should add that I frequently deal with survey studies, where random assignment does not apply and where Monte Carlo simulations would often fail to address the issue of representativeness.</p>\n", "pids": ["56d8701adabfae2eeeedcba5", "56d8701adabfae2eeeedcba5"], "flag": 1}
{"question": "Why maximum likelihood and not expected likelihood?", "body": "<p>Why is it so common to obtain maximum likelihood estimates of parameters, but you virtually never hear about <em>expected</em> likelihood parameter estimates (i.e., based on the <em>expected value</em> rather than the <em>mode</em> of a likelihood function)? Is this primarily for historical reasons, or for more substantive technical or theoretical reasons?</p>\n\n<p>Would there be significant advantages and/or disadvantages to using expected likelihood estimates rather than maximum likelihood estimates?</p>\n\n<p>Are there some areas in which expected likelihood estimates <em>are</em> routinely used?</p>\n", "pids": ["53e9bb1cb7602d9704754ef9"], "flag": 1}
{"question": "How to initialize the elements of the filter matrix?", "body": "<p>I'm trying to better understand convolutional neural networks better by writing up Python code that doesn't depend on libraries (like Convnet or TensorFlow), and I'm getting stuck in the literature on how to choose values for the kernel matrix, when performing a convolution on an image. </p>\n\n<p>I'm trying to understand the implementation details in the step between <em>feature maps</em> in the image below showing the layers of a CNN. </p>\n\n<p><a href=\"https://i.stack.imgur.com/K8grq.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/K8grq.png\" alt=\"Convolutional neural network layers\"></a></p>\n\n<p>According to this diagram:</p>\n\n<p><a href=\"https://i.stack.imgur.com/I7DBr.gif\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/I7DBr.gif\" alt=\"Convolving an image\"></a></p>\n\n<p>The kernel matrix kernel \"steps\" over the image, creating a feature map, where each pixel is the sum of all element-wise products between each weight of the kernel (or filter matrix) and the corresponding pixel value of the input image.</p>\n\n<p>My question is: <em>how do we initialize the weights of the kernel (or filter) matrix?</em></p>\n\n<p>In the demonstration above, they are simply 1s and 0s, but I assume this is simplified from the diagram's sake. </p>\n\n<p>Are these weights trained in some preprocessing step? Or chosen explicitly by the user?</p>\n", "pids": ["573696f46e3b12023e5f0d4d"], "flag": 1}
{"question": "Is it possible to find an infinite set of points in the plane where the distance between any pair is rational?", "body": "<p>The question is written like this:</p>\n\n<blockquote>\n  <p>Is it possible to find an infinite set of points in the plane, not all on the same straight line, such that the distance between <strong>EVERY</strong> pair of points is rational?</p>\n</blockquote>\n\n<p>This would be so easy if these points could be on the same straight line, but I couldn't get any idea to solve the question above(not all points on the same straight line). I believe there must be a kind of concatenation between the points but  I couldn't figure it out.</p>\n\n<p>What I tried is totally mess. I tried to draw some triangles and to connect some points from one triangle to another, but in vain.</p>\n\n<p><strong>Note:</strong> I want to see a real example of such an infinite set of points in the plane that can be an answer for the question. A graph for these points would be helpful.</p>\n", "pids": ["53e9b84ab7602d9704409fd6"], "flag": 0}
{"question": "Pseudo Proofs that are intuitively reasonable", "body": "<p>What are nice &quot;proofs&quot; of true facts that are not really rigorous but give the right answer and still make sense on some level? Personally, I consider them to be guilty  pleasures. Here are examples of what I have in mind:</p>\n<ol>\n<li><p><span class=\"math-container\">$s=\\sum_{i=0}^\\infty \\delta^i=1/(1-\\delta)$</span>.</p>\n<p>&quot;Proof:&quot; <span class=\"math-container\">$s=1+\\delta+\\delta^2+\\cdots=1+\\delta s$</span> and hence <span class=\"math-container\">$s=1/(1-\\delta)$</span>.</p>\n</li>\n<li><p><span class=\"math-container\">$(f\\circ g)'(x)=f'(g(x))g'(x)$</span>.</p>\n<p>&quot;Proof:&quot; <span class=\"math-container\">$\\displaystyle\\lim\\limits_{h\\to 0}\\frac{f(g(x+h))-f(g(x))}{h}=\\lim\\limits_{h\\to 0}\\bigg(\\frac{f(g(x+h))-f(g(x))}{g(x+h)-g(x)}\\frac{g(x+h)-g(x)}{h}\\bigg).$</span></p>\n</li>\n<li><p><span class=\"math-container\">$[0,1]$</span> is uncountable.</p>\n<p>&quot;Proof:&quot; Pick a number from <span class=\"math-container\">$[0,1]$</span> randomly. Every number has the same probability. If this probability were positive, there would be finitely many such numbers such that the probability of picking one of them exceeds <span class=\"math-container\">$1$</span>, which cannot be. So the probability of picking each number is <span class=\"math-container\">$0$</span>. If <span class=\"math-container\">$[0,1]$</span> were countable, the probability of picking any real number would be <span class=\"math-container\">$0=0+0+0+\\cdots$</span>. But by picking from a uniform distribution, I will get a real number with certainty.</p>\n</li>\n</ol>\n<p>It might be helpful to indicate where the lapses in rigor are and why the method works anyways.</p>\n", "pids": ["53e9ace2b7602d97036c269d"], "flag": 0}
{"question": "Why does this &quot;miracle method&quot; for matrix inversion work?", "body": "<p>Recently, I answered <a href=\"https://math.stackexchange.com/q/1378132/80762\">this question about matrix invertibility</a> using a solution technique I called a &quot;<strong>miracle method</strong>.&quot; The question and answer are reproduced below:</p>\n<blockquote>\n<p><strong>Problem:</strong> Let <span class=\"math-container\">$A$</span> be a matrix satisfying <span class=\"math-container\">$A^3 = 2I$</span>. Show that <span class=\"math-container\">$B = A^2 - 2A + 2I$</span> is invertible.</p>\n<p><strong>Solution:</strong> Suspend your disbelief for a moment and suppose <span class=\"math-container\">$A$</span> and <span class=\"math-container\">$B$</span> were scalars, not matrices. Then, by power series expansion, we would simply be looking for\n<span class=\"math-container\">$$ \\frac{1}{B} = \\frac{1}{A^2 - 2A + 2} = \\frac{1}{2}+\\frac{A}{2}+\\frac{A^2}{4}-\\frac{A^4}{8}-\\frac{A^5}{8} + \\cdots$$</span>\nwhere the coefficient of <span class=\"math-container\">$A^n$</span> is\n<span class=\"math-container\">$$ c_n = \\frac{1+i}{2^{n+2}} \\left((1-i)^n-i (1+i)^n\\right). $$</span>\nBut we know that <span class=\"math-container\">$A^3 = 2$</span>, so\n<span class=\"math-container\">$$ \\frac{1}{2}+\\frac{A}{2}+\\frac{A^2}{4}-\\frac{A^4}{8}-\\frac{A^5}{8} + \\cdots = \\frac{1}{2}+\\frac{A}{2}+\\frac{A^2}{4}-\\frac{A}{4}-\\frac{A^2}{4} + \\cdots $$</span>\nand by summing the resulting coefficients on <span class=\"math-container\">$1$</span>, <span class=\"math-container\">$A$</span>, and <span class=\"math-container\">$A^2$</span>, we find that\n<span class=\"math-container\">$$ \\frac{1}{B} = \\frac{2}{5} + \\frac{3}{10}A + \\frac{1}{10}A^2. $$</span>\nNow, what we've just done should be total nonsense if <span class=\"math-container\">$A$</span> and <span class=\"math-container\">$B$</span> are really matrices, not scalars. But try setting <span class=\"math-container\">$B^{-1} = \\frac{2}{5}I + \\frac{3}{10}A + \\frac{1}{10}A^2$</span>, compute the product <span class=\"math-container\">$BB^{-1}$</span>, and you'll find that, <strong>miraculously</strong>, this answer works!</p>\n</blockquote>\n<p>I discovered this solution technique some time ago while exploring a similar problem in Wolfram <em>Mathematica</em>. However, I have no idea why any of these manipulations should produce a meaningful answer when scalar and matrix inversion are such different operations. <strong>Why does this method work?</strong> Is there something deeper going on here than a serendipitous coincidence in series expansion coefficients?</p>\n", "pids": ["600505679e795ef57845c995"], "flag": 0}
{"question": "What is the oldest open problem in geometry?", "body": "<p>Geometry is one of the oldest branches of mathematics, and many famous problems have been proposed and solved in its long history.</p>\n\n<p>What I would like to know is: <strong>What is the oldest open problem in geometry?</strong></p>\n\n<p>Also <em>(soft questions)</em>: Why is it so hard? Which existing tools may be helpful to handle it? If twenty great geometers of today gathered to work together in the problem, would they (probably) be able to solve it?</p>\n\n<p>P.S. The problem can be of any area of geometry (discrete, differential, etc...)</p>\n", "pids": ["5cc987c7e1cd8e57f5439775"], "flag": 0}
{"question": "Has the journal Science endorsed the Garden of Forking Pathes Analyses?", "body": "<p>The idea of <em>adaptive data analysis</em> is that you alter your plan for analyzing the data as you learn more about it. In the case of exploratory data analysis (EDA), this is generally a good idea (you are often looking for unforeseen patterns in the data), but for a confirmatory study, this is widely accepted as a very flawed method of analysis (unless all the steps are clearly defined and properly planned out in advanced).</p>\n\n<p>That being said, adaptive data analysis <strong>is</strong> typically how many researchers actually conduct their analyses, much to the dismay of statisticians. As such, if one could do this in a statistical valid manner, it would revolutionize statistical practice.</p>\n\n<p>The following <em>Science</em> article claims to have found a method for doing such (I apologize for the paywall, but if you are at a university, you likely have access): <a href=\"http://science.sciencemag.org/content/349/6248/636\">Dwork et al, 2015, The reusable holdout: Preserving validity in adaptive data analysis</a>.</p>\n\n<p>Personally, I've always been skeptical of statistics articles published in <em>Science</em>, and this one is no different. In fact, after reading through the article twice, including the supplementary material, I cannot understand (at all) why the authors claim that their method prevents over-fitting. </p>\n\n<p>My understanding is that they have a holdout dataset, which they will reuse. They seem to claim by \"fuzzing\" the output of the confirmatory analysis on the holdout dataset, over-fitting will be prevented (it is worth noting that the fuzzing seems to be just adding noise <em>if the calculated statistic on the training data is sufficiently far from the calculated statistic on the holdout data</em>). As far as I can tell, there is no real reason this should prevent over-fitting. </p>\n\n<p>Am I mistaken on what the authors are proposing? Is there some subtle effect that I'm overlooking? Or has <em>Science</em>  endorsed the worst statistical practice to date? </p>\n", "pids": ["5e01fdc7df1a9c0c416638fa", "57a4e91dac44365e35c98266"], "flag": 1}
{"question": "Algebra: Best mental images", "body": "<blockquote>\n  <p>I'm curious how people think of Algebras (in the universal sense, i.e., monoids, groups, rings, etc.). Cayley diagrams of groups with few generators are useful for thinking about group actions on itself. I know that a categorical approach is becoming more mainstream. For me, lattice theory is my fallback. </p>\n</blockquote>\n\n<p>Lattice theory is useful to remember the diamond morphism theorem and lattice morphism theorem. Whenever I need to remember if a group can be expressed as a semidirect product I look for two subgroups where their meet is the bottom of the subgroup lattice, the join is the top of this lattice and one of those subgroups is contained in the normal sublattice. I find this easier than to remember the formal definition since I've translated it to relations that are spacial in the lattice. Now I'm studying ideal theory and commutative algebra. </p>\n\n<blockquote>\n  <p>I think of the zero set $\\mathbb(V)$ as an up-set of the smallest prime ideal containing the element. I'm curious if this is a general way others have gone about thinking \"algebraically\". </p>\n</blockquote>\n", "pids": ["56d88702dabfae2eee9605bd"], "flag": 0}
{"question": "Why not use the third derivative for numerical optimization?", "body": "<p>If Hessians are so good for optimization (see e.g. <a href=\"https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization\" rel=\"noreferrer\">Newton's method</a>), why stop there? Let's use the third, fourth, fifth, and sixth derivatives? Why not?</p>\n", "pids": ["5ce3aa49ced107d4c6584122"], "flag": 1}
{"question": "A bestiary about adjunctions", "body": "<p>What is your favourite adjoint? Following Mac Lane philosophy <em>adjoints are everywhere</em>, so I would like to draw a (possibly but unprobably) exhaustive list of adjunctions one faces in studying Mathematics. For the sake of clarity I would like you to follow a general scheme, a very naive example of which can be the following:</p>\n\n<ol>\n<li>Functors F and G between cats C and D</li>\n<li>Is the adjunction a (co)reflection?</li>\n<li>Does the left adjoint admit a left adjoint on its own?</li>\n<li>Anything you want to add</li>\n</ol>\n\n<p>Obviously you are totally free to expand it, revert it...</p>\n\n<p>I would also like to grasp something more than a mere enumeration: i.e. listing all adjunctions $\\mathbf{Groups}\\leftrightarrows\\mathbf{Sets}$, $\\mathbf{Monoids}\\leftrightarrows\\mathbf{Sets}$,  $\\mathbf{Mod}_R\\leftrightarrows\\mathbf{Sets}$ is certainly a good thing, but it would be slightly better to say that all these pairs come from a \"general scheme of adjunction\"\n$$\r\n\\text{generated object} \\dashv \\text{forgetful functor}\r\n$$\nwhich can be (if I'm not wrong) studied for a general type of algebraic structure. Hence it would be better to write some sort of \"reference card\" about:</p>\n\n<ol>\n<li>The diagonal functor $\\Delta_\\mathbf J\\colon \\mathbf C\\to \\mathbf C^\\mathbf J$ sending $C\\in\\text{Ob}_\\mathbf C$ into the constant diagram over $C$ admits both a left and right adjoint (direct and inverse limit).</li>\n<li>Once you fixed a set $J$, here is an adjunction between $\\mathbf{Sets}/J$ and $\\mathbf{Sets}^J$ defined by functors $L\\colon h\\in \\mathbf{Sets}/J\\mapsto \\big(h^\\leftarrow(\\{j\\}\\big)_{j\\in J}$ and $M\\colon \\{H_j\\}_{j\\in J}\\mapsto \\big(\\coprod_{j\\in J} H_j\\to J\\big)\\in \\mathbf{Sets}/J$, which turns out to be an equivalence</li>\n<li>There exists an adjunction between $\\mathrm{PSh}(X)$ and $\\mathbf{Top}/X$ for any topological space $X$ ($\\text{bundle of germs}\\dashv\\text{(pre)sheaf of sections}$), which turns out to be an equivalence if we restrict...</li>\n<li>Given a ring $R$ the functor $R[\\;\\;]\\colon \\mathbf{Groups}\\to \\mathbf{Rings}$ sending a group in its group ring admits a right adjoint, namely $U\\colon R\\mapsto R^\\times$ (units in $R$).</li>\n<li>The inclusion functor $\\mathbf{Kelley}\\to\\mathbf{Top}$ admits a right adjoint, the <em>kelleyfication</em> of a topological space</li>\n<li>(Following Gabriel&amp;Zisman) The inclusion functor between (small) categories $\\mathbf{cat}$ and (small) groupoids $\\mathbf{Gpds}$, admits both a left adjoint ($\\mathbf{C}\\mapsto \\mathbf{C}[\\text{Mor}_\\mathbf{C}^{-1}]$ in the notation used for the <a href=\"http://en.wikipedia.org/wiki/Calculus_of_fractions\">calculus of fractions</a>) and a right adjoint ($\\mathbf{C}\\mapsto \\mathbf{C}^\\times$, sending a category in the groupoid obtained deleting every noninvertible arrow).</li>\n<li>... </li>\n</ol>\n\n<p>Feel free to say this is a silly or boring question.</p>\n", "pids": ["56d86ff0dabfae2eeeec750a"], "flag": 0}
{"question": "Difference between rungs two and three in the Ladder of Causation", "body": "<p>In Judea Pearl's \"Book of Why\" he talks about what he calls the Ladder of Causation, which is essentially a hierarchy comprised of different levels of causal reasoning.  The lowest is concerned with patterns of association in observed data (e.g., correlation, conditional probability, etc.), the next focuses on intervention (what happens if we deliberately change the data generating process in some prespecified way?), and the third is counterfactual (what would happen in another possible world if something had or had not happened)?</p>\n\n<p>What I'm not understanding is how rungs two and three differ.  If we ask a counterfactual question, are we not simply asking a question about intervening so as to <em>negate</em>  some aspect of the observed world?</p>\n", "pids": ["624a61cc5aee126c0f90dd85"], "flag": 1}
{"question": "Is my model any good, based on the diagnostic metric ($R^2$/ AUC/ accuracy/ RMSE etc.) value?", "body": "<p>I've fitted my model and am trying to understand whether it's any good. I've calculated the recommended metrics to assess it (<span class=\"math-container\">$R^2$</span>/ AUC / accuracy / prediction error / etc) but do not know how to interpret them. In short, how do I tell if my model is any good based on the metric? Is an <span class=\"math-container\">$R^2$</span> of 0.6 (for example) sufficient to let me proceed to draw inferences or base scientific/business decisions? </p>\n\n\n\n<p>This question is intentionally broad, to cover a wide variety of situations that members frequently encounter; such questions could be closed as duplicates of this one. Edits to broaden the scope beyond the metrics mentioned here are welcome, as are additional answers - particularly those that offer insight about other classes of metrics.</p>\n", "pids": ["5c75586af56def9798751a88", "53e9bc1bb7602d9704885e12"], "flag": 1}
{"question": "Multi-layer perceptron vs deep neural network", "body": "<p>This is a question of terminology. Sometimes I see people refer to deep neural networks as \"multi-layered perceptrons\", why is this? A perceptron, I was taught, is a single layer classifier (or regressor) with a binary threshold output using a specific way of training the weights (not back-prop). If the output of the perceptron doesn't match the target output, we add or subtract the input vector to the weights (depending on if the perceptron gave a false positive or a false negative). It's a quite primitive machine learning algorithm. The training procedure doesn't appear to generalize to a multi-layer case (at least not without modification). A deep neural network is trained via backprop which uses the chain rule to propagate gradients of the cost function back through all of the weights of the network. </p>\n\n<p>So, the question is. Is a \"multi-layer perceptron\" the same thing as a \"deep neural network\"? If so, why is this terminology used? It seems to be unnecessarily confusing. In addition, assuming the terminology is somewhat interchangeable, I've only seen the terminology \"multi-layer perceptron\" when referring to a feed-forward network made up of fully connected layers (no convolutional layers, or recurrent connections). How broad is this terminology? Would one use the term \"multi-layered perceptron\" when referring to, for example, Inception net? How about for a recurrent network using LSTM modules used in NLP?   </p>\n", "pids": ["573696046e3b12023e517573"], "flag": 1}
{"question": "Is there a great mathematical example for a 12-year-old?", "body": "<p>I've just been working with my 12-year-old daughter on Cantor's diagonal argument, and countable and uncountable sets.</p>\n\n<p>Why? Because the maths department at her school is outrageously good, and set her the task of researching a mathematician, and understanding some of the maths they did - the real thing.</p>\n\n<p>So what else could we have done - thinking that we know our multiplication tables and fractions, but aren't yet completely confident with equations which have letters for unknown numbers?</p>\n\n<p>I did think of proving that there are infinitely many primes - we can follow an argument - other suggestions welcome.</p>\n\n<p>And incidentally, tell your local high school to do this ...</p>\n", "pids": ["56d883cfdabfae2eee7d1c60"], "flag": 0}
{"question": "Computation of the marginal likelihood from MCMC samples", "body": "<p>This is a recurring question (see <a href=\"https://stats.stackexchange.com/questions/129109/marginal-likelihood-from-the-gibbs-output\">this post</a>, <a href=\"https://stats.stackexchange.com/questions/60172/robust-mcmc-estimator-of-marginal-likelihood\">this post</a> and <a href=\"https://stats.stackexchange.com/questions/153777/approximating-the-marginal-likelihood-in-bayesian-model-comparison\">this post</a>), but I have a different spin.</p>\n\n<p>Suppose I have a bunch of samples from a generic MCMC sampler. For each sample $\\theta$, I know the value of the log likelihood $\\log f(\\textbf{x} | \\theta)$ and of the log prior $\\log f(\\theta)$. If it helps, I also know the value of the log likelihood per data point, $\\log f(x_i | \\theta)$ (this information helps with certain methods, such as WAIC and PSIS-LOO).</p>\n\n<p>I want to obtain a (crude) estimate of the marginal likelihood, just with the samples that I have, and <em>possibly</em> a few other function evaluations (but without rerunning an <em>ad hoc</em> MCMC).</p>\n\n<p>First of all, let's clear the table. We all know that the harmonic estimator is the <a href=\"https://radfordneal.wordpress.com/2008/08/17/the-harmonic-mean-of-the-likelihood-worst-monte-carlo-method-ever/\">worst estimator ever</a>. Let's move on.\nIf you are doing Gibbs sampling with priors and posteriors in closed form, you can use <a href=\"http://apps.olin.wustl.edu/faculty/chib/papers/chib95.pdf\">Chib's method</a>; but I am not sure how to generalize outside of those cases. There are also methods that require you to modify the sampling procedure (such as via <a href=\"https://darrenjw.wordpress.com/2013/10/01/marginal-likelihood-from-tempered-bayesian-posteriors/\">tempered posteriors</a>), but I am not interested in that here.</p>\n\n<p>The approach I am thinking of consists of approximating the underlying distribution with a parametric (or nonparametric) shape $g(\\theta)$, and then figuring out the normalization constant $Z$ as a 1-D optimization problem (i.e., the $Z$ that minimizes some error between $Z g(\\theta)$ and $f(\\textbf{x}|\\theta) f(\\theta)$, evaluated on the samples). In the simplest case, suppose that the posterior is roughly multivariate normal, I can fit $g(\\theta)$ as a multivariate normal and get something similar to a Laplace approximation (I might want to use a few additional function evaluations to refine the position of the mode). However, I could use as $g(\\theta)$ a more flexible family such as a variational mixture of multivariate $t$ distributions.</p>\n\n<p>I appreciate that this method works only if $Z g(\\theta)$ is a reasonable approximation to $f(\\textbf{x}|\\theta) f(\\theta)$, but any reason or cautionary tale of why it would be very unwise to do it? Any reading that you would recommend?</p>\n\n<p>The fully nonparametric approach uses some nonparametric family, such as a Gaussian process (GP), to approximate $\\log f(\\textbf{x}|\\theta) + \\log f(\\theta)$ (or some other nonlinear transformation thereof, such as the square root), and <a href=\"http://mlg.eng.cam.ac.uk/zoubin/papers/RasGha03.pdf\">Bayesian quadrature</a> to implicitly integrate over the underlying target (see <a href=\"https://papers.nips.cc/paper/4657-active-learning-of-model-evidence-using-bayesian-quadrature.pdf\">here</a> and <a href=\"https://papers.nips.cc/paper/5483-sampling-for-inference-in-probabilistic-models-with-fast-bayesian-quadrature.pdf\">here</a>). This seems to be an interesting alternative approach, but analogous in spirit (also, note that GPs would be unwieldy in my case).</p>\n", "pids": ["53e9a1dbb7602d9702ad5b19", "61c712b75244ab9dcb11b631", "53e9a98eb7602d97032ec5e3"], "flag": 1}
{"question": "Is it possible to formulate category theory without set theory?", "body": "<p>I have never understood why set theory has so many detractors, or what is gained by avoiding its use.</p>\n<p>It is well known that the naive concept of a set as a collection of objects leads to logical paradoxes (when dealing with infinite sets) that can only be resolved by defining the concept of a set according to a system of axioms.</p>\n<p>With this context, can someone please help me to understand the following passage from <a href=\"http://www.maths.ed.ac.uk/%7Eaar/papers/maclanecat.pdf\" rel=\"noreferrer\">Categories for the Working Mathematician</a>, Chapter 1, first two paragraphs (emphasis added):</p>\n<blockquote>\n<p>First we describe categories directly, by  means of axioms, <strong>without using any set theory</strong>, and call them &quot;metacategories&quot;.  Actually we being with a simpler notion, a (meta)graph.</p>\n<p>A <em>metagraph</em> consists of <em>objects</em> a,b,c..., <em>arrows</em> f,g,h..., and two operations as follows:</p>\n</blockquote>\n<p>Is it really possible to avoid the use of set theory in the foundations of category theory simply by using the phrase &quot;<em>objects</em> a,b,c ...&quot; instead?</p>\n<p>Thanks!</p>\n", "pids": ["62abf7af5aee126c0f66644c"], "flag": 0}
{"question": "Have we wiped out 60% of vertebrate populations since 1970?", "body": "<p>According to <a href=\"https://www.theguardian.com/environment/2018/oct/30/humanity-wiped-out-animals-since-1970-major-report-finds?CMP=share_btn_tw\" rel=\"noreferrer\">The Guardian</a> (reporting an analysis by WWF) humanity stands on the verge of an ecological catastrophe as:</p>\n\n<blockquote>\n  <p>Humanity has wiped out 60% of mammals, birds, fish and reptiles since 1970, leading the world’s foremost experts to warn that the annihilation of wildlife is now an emergency that threatens civilisation.</p>\n</blockquote>\n\n<p>While catastrophic declines in some species are well known (from overfishing, for example) this seems like a big claim. And even overfishing has been <a href=\"https://www.ft.com/content/c0da63a0-6bc5-11e7-b9c7-15af748b60d0\" rel=\"noreferrer\">contained and even reversed</a> by tighter regulation.</p>\n\n<p>So is the claim true?</p>\n", "pids": ["53e9be35b7602d9704af0605"], "flag": 1}
{"question": "What are the branches of statistics?", "body": "<p>In mathematics, there are branches such as algebra, analysis, topology, etc. In machine learning there is supervised, unsupervised, and reinforcement learning. Within each of these branches, there are finer branches that further divide the methods. </p>\n\n<p>I am having trouble drawing a parallel with statistics. What would be the main branches of statistics (and sub-branches)? A perfect partition is likely not possible, but anything is better than a big blank map. </p>\n\n<p>Visual examples: <a href=\"https://i.stack.imgur.com/JcGdC.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/JcGdC.png\" alt=\"enter image description here\"></a> <a href=\"https://i.stack.imgur.com/iDqMQ.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/iDqMQ.png\" alt=\"enter image description here\"></a></p>\n", "pids": ["5d9edbf547c8f7664602d414"], "flag": 1}
{"question": "Did the Indonesian army have a virginity test for female recruits?", "body": "<p>The original article is on <a href=\"https://www.newsweek.com/indonesian-army-two-finger-virginity-tests-female-recruits-1618611\" rel=\"noreferrer\">Newsweek</a> which I personally consider a reliable source.</p>\n<blockquote>\n<p>The virginity check, which extended to military fiancées, involves someone placing two fingers into the vagina to determine whether or not they've had intercourse, due to the state of the hymen.</p>\n</blockquote>\n", "pids": ["5c75730cf56def97988630d7"], "flag": 1}
{"question": "Why do we not care about completeness, sufficiency of an estimator as much anymore?", "body": "<p>When we begin to learn Statistics, we learn about seemingly important class of estimators that satisfy the properties sufficiency and completeness. However, when I read recent articles in Statistics I can hardly find any papers that address complete sufficient statistics. Why would we not care about completeness, sufficiency of an estimator as much anymore? </p>\n", "pids": ["5c75755ef56def97989e5f75", "5c6108dcda56297340b542fe"], "flag": 1}
{"question": "Why Not Prune Your Neural Network?", "body": "<p>Han <em>et al</em>. (2015) used a method of iterative pruning to reduce their network to only 10% of its original size with no loss of accuracy by removing weights with very low values, since these changed very little. As someone new to the machine learning area, why wouldn't you do this (unless your network is already very small)? It seems to me that for deep learning your network would be smaller, faster, more energy efficient, etc. at no real cost. Should we all use this method for larger neural networks?</p>\n", "pids": ["5def6ca63a55ac6095fe05e8", "5c75755bf56def97989e3bd4"], "flag": 1}
{"question": "Is memory unimportant in doing mathematics?", "body": "<p>The title says it all.\nI often heard people say something like memory is unimportant in doing mathematics. However, when I tried to solve mathematical problems, I often used known theorems whose proofs I forgot.   </p>\n\n<p><strong>EDIT</strong>\nSome of you may think that using theorems whose proofs one has <em>forgotten</em> does not seem to support importance of memory. My point is that it is not only useful, but often necessary to remember theorems(not their proofs) to solve mathematical problems. For example, you can't solve many problems of finite groups without using Sylow's theorem.</p>\n", "pids": ["53e9b6cbb7602d970425856d", "53e99a6db7602d97022da070"], "flag": 0}
{"question": "Help understanding Algebraic Geometry", "body": "<p>I while ago I started reading Hartshorne's Algebraic Geometry and it almost immediately  felt like I hit a brick wall. I have some experience with category theory and abstract algebra but not with algebraic or projective geometry.</p>\n\n<p>I'm wondering if any of you out there know of any articles, blog posts or whatever offering a light, intuitive and geometric introduction the subject. I really wanna get back to Hartshorne's book cause I am very curious about the categorical description.</p>\n\n<p>I have provided the first few problems I ran into to give you an idea of where I come from. Of course if you can answer any of the questions that would be welcome.</p>\n\n<p>First of all I'm having trouble grasping the very basic notion of a continuous function with respect to the Zariski topology. I don't which they are or know how to conceptualize them. I get how the rational polynomials work but I don't know if they are a subclass of the continuous functions or if they exhaust them. Any help in this regard is welcome.</p>\n\n<p>Further I couldn't really get the projective part. I guess part of my problem comes from the fact that this is a set theoretic quotient of an algebra, which is then interpreted as an algebraic object. At least that's what I read, might be wrong. \nI seem to get lost during this transition and I don't know how to relate, are there any universal properties involved, whats the big picture?</p>\n\n<p>Thanks in Advance</p>\n\n<p>Edit1:\nAlso, where is the hyperbolic geometry in all this?</p>\n\n<p>Edit2: I want to express my gratitude towards all the people who have takes their time to give me recommendations and sympathy. Thank you!</p>\n", "pids": ["53e999fab7602d9702241e43"], "flag": 0}
{"question": "Why does $\\cos(x) + \\cos(y) - \\cos(x + y) = 0$ look like an ellipse?", "body": "<p>The <a href=\"http://www.wolframalpha.com/input/?i=plot+cos%28x%29+%2B+cos%28y%29+-+cos%28x+%2B+y%29+%3D+0+from+x%3D-10+to+10+from+y+%3D-10+to+10\">solution set</a> of $\\cos(x) + \\cos(y) - \\cos(x + y) = 0$ looks like an ellipse. Is it actually an ellipse, and if so, is there a way of writing down its equation (without any trig functions)?</p>\n\n<p>What motivates this is the following example. The <a href=\"http://www.wolframalpha.com/input/?i=plot+cos%28x%29+-+cos%283x+%2B+2y%29+%3D+0\">solution set</a> of $\\cos(x) - \\cos(3x + 2y) = 0$ looks like two straight lines, and indeed we can determine the equations of those lines.</p>\n\n<p>$$\n\\begin{align}\n\\cos(x) &amp;= \\cos(3x + 2y) \\\\\n\\implies x &amp;= \\pm (3x + 2y) \\\\\n\\implies x + y &amp;= 0 \\text{ or } 2x + y = 0\n\\end{align}\n$$</p>\n\n<p>Can we do a similar thing for the first equation?</p>\n", "pids": ["53e9aa8eb7602d97034097f6"], "flag": 0}
{"question": "Pseudo R squared formula for GLMs", "body": "<p>I found a formula for pseudo $R^2$ in the book <a href=\"http://www.maths.bath.ac.uk/~jjf23/ELM/\">Extending the Linear Model with R, Julian J. Faraway</a> (p. 59).</p>\n\n<p>$$1-\\frac{\\text{ResidualDeviance}}{\\text{NullDeviance}}$$. </p>\n\n<p><strong>Is this a common formula for pseudo $R^2$ for GLMs?</strong></p>\n", "pids": ["53e997cbb7602d9701fbb299", "53e9a0fbb7602d97029e91eb"], "flag": 1}
{"question": "Teenager solves Newton dynamics problem - where is the paper?", "body": "<p>From <a href=\"http://www.ottawacitizen.com/Teen+solves+Newton+year+riddle/6685617/story.html\">Ottawa Citizen</a> (and <a href=\"http://www.google.com/search?q=Shouryya+Ray\">all over</a>, really):</p>\n\n<blockquote>\n  <p>An Indian-born teenager has won a research award for solving a\n  mathematical problem first posed by Sir Isaac Newton more than 300\n  years ago that has baffled mathematicians ever since.</p>\n  \n  <p>The solution devised by Shouryya Ray, 16, makes it possible to\n  calculate exactly the path of a projectile under gravity and subject\n  to air resistance.</p>\n</blockquote>\n\n<p>This subject is of particular interest to me.  I have been unable to locate his findings via the Internet. Where can I read his actual mathematical work?</p>\n\n<p>Edit:<br>\nSo has he written an actual paper, and if so, will anyone get to read it?</p>\n", "pids": ["56d8f4f8dabfae2eee8d379a"], "flag": 0}
{"question": "Does $\\Bbb{CP}^{2n} \\mathbin{\\#} \\Bbb{CP}^{2n}$ ever support an almost complex structure?", "body": "<p>This question has now been <a href=\"https://mathoverflow.net/q/216272/40804\">crossposted</a> to MathOverflow, in the hopes that it reaches a larger audience there.</p>\n\n<p>$\\Bbb{CP}^{2n+1} \\mathbin{\\#} \\Bbb{CP}^{2n+1}$ supports a complex structure: $\\Bbb{CP}^{2n+1}$ has an orientation-reversing diffeomorphism (complex conjugation!), so this is diffeomorphic to the blowup of $\\Bbb{CP}^{2n+1}$ at one point.</p>\n\n<p>On the other hand, $\\Bbb{CP}^2 \\mathbin{\\#} \\Bbb{CP}^2$ does not even support an almost complex structure: Noether's formula demands that its first Chern class $c_1^2 = 2\\chi + 3\\sigma = 14$, but if $c_1 = ax_1 + bx_2$ (where $x_1, x_2$ generate $H^2$, $x_1^2 = x_2^2$ is the positive generator of $H^4$, and $x_1x_2 = 0$), then $c_1^2 = a^2 + b^2$, and you cannot write $14$ as a sum of two squares.</p>\n\n<p>Using a higher-dimensional facsimile of the same proof, I wrote down a proof <a href=\"https://math.stackexchange.com/a/1413059/98602\">here</a> that $\\Bbb{CP}^4 \\mathbin{\\#} \\Bbb{CP}^4$ does not admit an almost complex structure. The computations using any similar argument would, no doubt, become absurd if I increased the dimension any more. </p>\n\n<p>Can any $\\Bbb{CP}^{2n} \\mathbin{\\#} \\Bbb{CP}^{2n}$ support an almost complex structure? </p>\n", "pids": ["5c757211f56def97987d7d45"], "flag": 0}
{"question": "Unsolved Problems due to Lack of Computational Power", "body": "<p>I was recently reading up about computational power and its uses in maths particularly to find counterexamples to conjectures. I was wondering are there any current mathematical problems which we are unable to solve due to our lack of computational power or inaccessibility to it.</p>\n\n<p><strong>What exactly am I looking for?</strong> </p>\n\n<p>Problems of which we know that they can be solved with a finite (but very long) computation? </p>\n\n<p>(e. g. <strong>NOT</strong> the Riemann hypothesis or twin prime conjecture)</p>\n\n<p>I am looking for specific examples.</p>\n", "pids": ["56d8309cdabfae2eee2009ac"], "flag": 0}
{"question": "Examples of errors in MCMC algorithms", "body": "<p>I'm investigating a method for automatic checking of Markov chain Monte Carlo methods, and I would like some examples of mistakes that can occur when constructing or implementing such algorithms. Bonus points if the incorrect method was used in a published paper.</p>\n\n<p>I'm particularly interested in cases where the error means that the chain has the incorrect invariant distribution, though other types of errors (e.g. chain not ergodic) would be of interest as well.</p>\n\n<p>An example of such an error would be failing to output a value when Metropolis-Hastings rejects a proposed move.</p>\n", "pids": ["53e99b36b7602d97023d868a", "53e9b295b7602d9703d3cc7b"], "flag": 1}
{"question": "Number of monic irreducible polynomials of prime degree $p$ over finite fields", "body": "<blockquote>\n  <p>Suppose $F$ is a field s.t $\\left|F\\right|=q$. Take $p$ to be some prime. How many monic irreducible polynomials of degree $p$ do exist over $F$?</p>\n</blockquote>\n\n<p>Thanks!</p>\n", "pids": ["5d9edb5847c8f76646015445"], "flag": 0}
{"question": "Understanding the intuition behind math", "body": "<p>I'm currently a Calculus III student. I enjoy math a lot, but only when I understand its beauty and meaning. However, so many times I have no idea what it is I am learning about, althought I am still able to solve problems pertaining to those topics. I'm memorizing the sounds this language makes, but I dont understand them. I think a big reason why most children and teenagers really dread math over any other subject is because the only thing that is taught to them is equations and numbers, and to them is not being explained its significance. For if people really knew what it all meant, then they'd realize it's probably the most important think they should ever study. Even in college, at this relatively high level of math, they <em>still</em> do not preach its meaning, but rather scare you into cramming pages after pages of material so you can pass the next exam. When you have passed the exam, then it is safe for you to forget the material you just absorbed. This is the reason I often find myself bored of studying my current topics. For some things, I see the intuition behind it, and those are the things that keep me interested in calculus, but its often so hard to come up with a good meaning of what I'm learning all by myself.</p>\n\n<p>It took mankind hundreds and thousands of years to come to where we are with math, so I dont expect to understand its true meaning in an hour, but I'd really like to. The school curriculum, here in America at least, doesnt teach meaning or utility. This is the reason so many youngsters always ask \"when will we ever need to use this stuff?\"-what a naive question this I learned to be. So I guess what I'm trying to say is that I've grown bored of this material, as we often cram 2 full sections of a topic in one day. Its impossible to keep up with its meaning, but if I am to survive this course along with more advanced courses to come, I must be able to understand its meaning. My textbook doesn't help me with this issue though- no math book can really teach intuition, but they dont even attempt to. They barely even go into the history of the current topic, and thats one of my favorite parts-I like to read about how a normal man came up with this theory that revolutionized the world. It makes math feel human to me, and that I too can understand it like men before me. </p>\n\n<p>Most of the question answerers on this site are mathematicians, if not at least one in training. This means you have come to where you are by understanding what you have learned in the past. How have you done this? How have you been able to connect all the pieces? What are some good resources that will help in what I hope to do? How do I stop being a robot, and actually connect with what I'm learning?</p>\n", "pids": ["53e9b12ab7602d9703ba96d1"], "flag": 0}
{"question": "How does a non-mathematician go about publishing a proof in a way that ensures it to be up to the mathematical community&#39;s standards?", "body": "<p>I'm a computer science student who is a maths hobbyist. I'm convinced that I've proven a major conjecture. The problem lies in that I've never published anything before and am not a mathematician by profession. Knowing full well that my proof may be fallacious, erroneous, or simply lacking mathematical formality, what advice would you give me?</p>\n", "pids": ["5f0e52ce9fced0a24b7ee876", "53e9b701b7602d970429a1e8"], "flag": 0}
{"question": "Connection between Fisher metric and the relative entropy", "body": "<p>Can someone <strong>prove</strong> the following connection between Fisher information metric and the relative entropy (or KL divergence) in a purely mathematical rigorous way?</p>\n\n<p><span class=\"math-container\">$$D( p(\\cdot , a+da) \\parallel p(\\cdot,a) ) =\\frac{1}{2} g_{i,j} \\, da^i \\, da^j + (O( \\|da\\|^3)$$</span>\nwhere <span class=\"math-container\">$a=(a^1,\\dots, a^n), da=(da^1,\\dots,da^n)$</span>, <span class=\"math-container\">$$g_{i,j}=\\int \\partial_i (\\log p(x;a)) \\partial_j(\\log p(x;a))~ p(x;a)~dx$$</span> and <span class=\"math-container\">$g_{i,j} \\, da^i \\, da^j := \\sum_{i,j}g_{i,j} \\, da^i \\, da^j$</span> is the Einstein summation convention.</p>\n\n<p>I found the above in the nice blog of <a href=\"http://johncarlosbaez.wordpress.com/2010/10/23/information-geometry-part-2/\" rel=\"noreferrer\">John Baez</a> where Vasileios Anagnostopoulos says about that in the comments.</p>\n", "pids": ["53e9ba01b7602d9704600c1a"], "flag": 1}
{"question": "Do hot peppers kill cancer?", "body": "<p>While browsing Health.SE, I came across an <a href=\"https://health.stackexchange.com/a/180/6439\">answer</a> that makes the following claim:</p>\n\n<blockquote>\n  <p>A 2007 study by Nottingham University<sup>2</sup> found that spicy foods can help kill cancer cells. Capsaicin, which is what makes many foods spicy, attacks the mitochondria of the cancer cells, triggering their death.</p>\n</blockquote>\n\n<p>This footnote links to <a href=\"http://news.bbc.co.uk/2/hi/6244715.stm\" rel=\"noreferrer\">this BBC article</a>, which claims that</p>\n\n<blockquote>\n  <p>They found capsaicin, an ingredient of jalapeno peppers, triggers cancer cell death by attacking mitochondria - the cells' energy-generating boiler rooms.</p>\n</blockquote>\n\n<p>This news article does not provide their sources except for a '2007 study by Nottingham University'. I was unable to find anything about this study using Google. I also tried <a href=\"https://scholar.google.com/scholar?q=inauthor%3A%22bates%22+capsaicin+mitochondria&amp;btnG=&amp;hl=en&amp;as_sdt=1%2C33\" rel=\"noreferrer\">searching through Google Scholar</a> and did not find anything about this.</p>\n\n<p>So, I'm skeptical. If this was really discovered in 2007, why haven't I heard of it being used at all? Why can't I find the study?</p>\n\n<p><strong>Do hot peppers kill cancer cells?</strong></p>\n", "pids": ["53e9baf6b7602d9704728b2c"], "flag": 1}
{"question": "Rigour in mathematics", "body": "<p>Mathematics is very rigorous and everything must be proven properly even things that may seem true and obvious.</p>\n\n<p>Can you give me examples of conjectures/theories that seemed true but through rigorous mathematical proving it was shown otherwise?</p>\n", "pids": ["5d9edbf547c8f7664602d4a6"], "flag": 0}
{"question": "On Ramanujan&#39;s curious equality for $\\sqrt{2\\,(1-3^{-2})(1-7^{-2})(1-11^{-2})\\cdots} $", "body": "<p>In <em>Ramanujan's Notebooks</em>, Vol IV, p.20, there is the rather curious relation for primes of form $4n-1$,</p>\n\n<p>$$\\sqrt{2\\,\\Big(1-\\frac{1}{3^2}\\Big) \\Big(1-\\frac{1}{7^2}\\Big)\\Big(1-\\frac{1}{11^2}\\Big)\\Big(1-\\frac{1}{19^2}\\Big)} = \\Big(1+\\frac{1}{7}\\Big)\\Big(1+\\frac{1}{11}\\Big)\\Big(1+\\frac{1}{19}\\Big)$$</p>\n\n<p>Berndt asks: <em>if this is an isolated result, or are there others?</em> After some poking with <em>Mathematica</em>, it turns out that, together with $p= 2$, we can use the primes  of form $4n+1$,</p>\n\n<p>$$\\sqrt{2\\,\\Big(1-\\frac{1}{2^6}\\Big) \\Big(1-\\frac{1}{5^2}\\Big)\\Big(1-\\frac{1}{13^2}\\Big)\\Big(1-\\frac{1}{17^2}\\Big)} = \\Big(1+\\frac{1}{5}\\Big)\\Big(1+\\frac{1}{13}\\Big)\\Big(1+\\frac{1}{17}\\Big)$$</p>\n\n<p>(<em>Now why did Ramanujan miss this $4n+1$ counterpart</em>?) More generally, given,</p>\n\n<p>$$\\sqrt{m\\,\\Big(1-\\frac{1}{n^2}\\Big) \\Big(1-\\frac{1}{a^2}\\Big)\\Big(1-\\frac{1}{b^2}\\Big)\\Big(1-\\frac{1}{c^2}\\Big)} = \\Big(1+\\frac{1}{a}\\Big)\\Big(1+\\frac{1}{b}\\Big)\\Big(1+\\frac{1}{c}\\Big)$$</p>\n\n<blockquote>\n  <p><strong>Q:</strong> Let $p =a+b+c,\\;q = a b + a c + b c,\\;r =abc$. For the special case $m = 2$, are there <strong><em>infinitely</em></strong> many integers $1&lt;a&lt;b&lt;c$ such that,\n  $$n =\\sqrt{\\frac{2(p-q+r-1)}{p-3q+r-3}}$$\n  and $n$ is an integer? (For general $m$, see T. Andrew's comment below.)</p>\n</blockquote>\n\n<p><strong>Note:</strong> A search with <em>Mathematica</em> reveals numerous solutions, even for prime $a,b,c$. It is highly suggestive there may be in fact parametric solutions.</p>\n", "pids": ["5d2e1677275ded87f95e0b50"], "flag": 0}
{"question": "How do Bayesians compare distributions?", "body": "<p>So, I think that I have a decent grasp of the basics of frequentist probability and statistical analysis (and how badly it can be used). In a frequentist world, it makes sense to ask such a question as \"is this distribution different from that distribution\", because distributions are assumed to be real, objective and unchanging (for a given situation, at least), and so we can figure out how likely it is that one sample is drawn from a distribution shaped like another sample.</p>\n\n<p>In the Bayesian world view, we only care about what <em>we</em> expect to see, given our past experiences (I'm still a bit vague on this part, but I understand the concept of Bayesian updating). If that is so, how can a Bayesian say \"this set of data is different from that set of data\"?</p>\n\n<p>For the purposes of this question, I don't care about statistical significance, or similar, just how to quantify difference. I'm equally interested in parametric and non-parametric distributions.</p>\n", "pids": ["619bac931c45e57ce9e04c76"], "flag": 1}
{"question": "Best Algebraic Geometry text book? (other than Hartshorne)", "body": "<p>Lifted from <a href=\"https://mathoverflow.net/questions/2446\">Mathoverflow</a>:</p>\n\n<p>I think (almost) everyone agrees that Hartshorne's Algebraic Geometry is still the best.\nThen what might be the 2nd best? It can be a book, preprint, online lecture note, webpage, etc.</p>\n\n<p>One suggestion per answer please. Also, please include an explanation of why you like the book, or what makes it unique or useful.</p>\n", "pids": ["56d892c9dabfae2eeef5beb8", "5f0e58529fced0a24bfed9bd", "5f0dd1c09fced0a24bf2805f", "5f0e418e9fced0a24be4f0ac"], "flag": 0}
{"question": "Prove that $\\int_{0}^{1}\\sin{(\\pi x)}x^x(1-x)^{1-x}\\,dx =\\frac{\\pi e}{24} $", "body": "<p>I've found <a href=\"https://math.stackexchange.com/a/505439/153012\">here</a> the following integral.</p>\n\n<p>$$I = \\int_{0}^{1}\\sin{(\\pi (1-x))}x^x(1-x)^{1-x}\\,dx=\\int_{0}^{1}\\sin{(\\pi x)}x^x(1-x)^{1-x}\\,dx=\\frac{\\pi e}{24}$$</p>\n\n<p>I've never seen it before and I also didn't find the evaluation on math.se. How could we verify it?</p>\n\n<p>If it is a well-known integral, then could you give a reference?</p>\n", "pids": ["5c7559c6f56def97987fc0aa", "657048e9939a5f408247f24d"], "flag": 0}
{"question": "Is there such a thing as proof by example (not counter example)", "body": "<p>Is there such a logical thing as proof by example?</p>\n\n<p>I know many times when I am working with algebraic manipulations, I do quick tests to see if I remembered the formula right.</p>\n\n<p>This works and is completely logical for counter examples. One specific counter example disproves the general rule. One example might be whether $(a+b)^2 = a^2+b^2$. This is quickly disproven with most choices of a counter example. </p>\n\n<p>However, say I want to test something that is true like $\\log_a(b) = \\log_x(b)/\\log_x(a)$. I can pick some points a and b and quickly prove it for one example. If I test a sufficient number of points, I can then rest assured that it does work in the general case. <strong>Not that it probably works, but that it does work assuming I pick sufficiently good points</strong>. (Although in practice, I have a vague idea of what makes a set of sufficiently good points and rely on that intuition/observation that it it should work)</p>\n\n<p>Why is this thinking \"it probably works\" <strong>correct</strong>?</p>\n\n<p>I've thought about it, and here's the best I can come up with, but I'd like to hear a better answer:</p>\n\n<blockquote>\n  <p>If the equation is false (the two sides aren't equal), then there is\n  going to be constraints on what a and b can be. In this example it is\n  one equation and two unknowns. If I can test one point, see it fits\n  the equation, then test another point, see it fits the equation, and\n  test one more that doesn't \"lie on the path formed by the other two\n  tested points\", then I have proven it.</p>\n</blockquote>\n\n<p>I remember being told in school that this is not the same as proving the general case as I've only proved it for specific examples, but thinking about it some more now, I am almost sure it is a rigorous method to prove the general case provided you pick the right points and satisfy some sort of \"not on the same path\" requirement for the chosen points.</p>\n\n<p>edit: Thank you for the great comments and answers. I was a little hesitant on posting this because of \"how stupid a question it is\" and getting a bunch of advice on why this won't work instead of a good discussion. I found the polynomial answer the most helpful to my original question of whether or not this method could be rigorous, but I found the link to the small numbers intuition quiz pretty awesome as well.</p>\n\n<p>edit2: Oh I also originally tagged this as linear-algebra because the degrees of freedom nature when the hypothesis is not true. But I neglected to talk about that, so I can see why that was taken out. When a hypothesis is not true (ie polynomial LHS does not equal polynomial RHS), the variables can't be anything, and there exists a counter example to show this. By choosing points that slice these possibilities in the right way, it's proof that the hypothesis is true, at least for polynomials. The points have to be chosen so that there is no possible way the polynomial can meet all of them. If it still meets these points, the only possibility is that the polynomials are the same, proving the hypothesis by example. I would imagine there is a more general version of this, but it's probably harder than writing proofs the more straightforward way in a lot of cases. Maybe \"by example\" is asking to be stoned and fired. I think \"brute force\" was closer to what I was asking, but I didn't realize it initially.</p>\n", "pids": ["56d869e2dabfae2eeebe2f87"], "flag": 0}
{"question": "What does it take to divide by $2$?", "body": "<blockquote>\n  <p><em><strong>Theorem 1</strong> [ZFC, classical logic]:</em> If $A,B$ are sets such that $\\textbf{2}\\times A\\cong \\textbf{2}\\times B$, then $A\\cong B$.</p>\n</blockquote>\n\n<p>That's because the axiom of choice allows for the definition of cardinality $|A|$ of any set $A$, and for $|A|\\geq\\aleph_0$ we have $|\\textbf{2}\\times A|=|A|$.</p>\n\n<blockquote>\n  <p><em><strong>Theorem 2</strong>:</em> Theorem 1 still holds in ZF with classical logic.</p>\n</blockquote>\n\n<p>This is less trivial and explained in Section 5 of <a href=\"https://math.dartmouth.edu/~doyle/docs/three/three.pdf\" rel=\"noreferrer\">Division by Three</a> - however, though the construction does not involve any choices, it <em>does</em> involve the law of excluded middle.</p>\n\n<blockquote>\n  <p><strong><em>Question:</em></strong> Are there <em>intuitionistic</em> set theories in which one can prove $$\\textbf{2}\\times A\\cong \\textbf{2}\\times B\\quad\\Rightarrow\\quad A\\cong B\\quad\\text{?}$$ </p>\n</blockquote>\n\n<p>For example, is this statement true in elementary topoi or can it be proved in some intuitionistic type theory?</p>\n\n<blockquote>\n  <p>In his comment below Kyle indicated that the statement is unprovable in some type theory - does somebody know the argument or a reference for that?</p>\n</blockquote>\n\n<p><em>Edit</em> See also the related question <a href=\"https://math.stackexchange.com/questions/1114752/does-a-times-a-cong-b-times-b-imply-a-cong-b\">Does $A\\times A\\cong B\\times B$ imply $A\\cong B$?</a> about 'square roots'</p>\n", "pids": ["5c7574abf56def979896fe40"], "flag": 0}
{"question": "What&#39;s the goal of mathematics?", "body": "<p>Are we just trying to prove every theorem or find theories which lead to a lot of creativity or what?</p>\n\n<p>I've already read G. H. Hardy <em>Apology</em> but I didn't get an answer from it.</p>\n", "pids": ["53e99acab7602d970234b95f", "53e9b12ab7602d9703ba96d1"], "flag": 0}
{"question": "What is a good book to study linear algebra?", "body": "<p>I'm looking for a book to learn Algebra. The programme is the following. The units marked with a $\\star$ are the ones I'm most interested in (in the sense I know nothing about) and those with a $\\circ$ are those which I'm mildly comfortable with. The ones that aren't marked shouldn't be of importance. Any important topic inside a unite will be boldfaced.</p>\n\n<p><strong>U1:</strong> <em>Vector Algebra.</em>\nPoints in the $n$-dimensional space. Vectors. Scalar product. Norm. Lines and planes. Vectorial product.</p>\n\n<p>$\\circ$ <strong>U2:</strong> <em>Vector Spaces.</em>\nDefinition. Subspaces. Linear independence. Linear combination. Generating systems. Basis. Dimesion. Sum and intersection of subspaces. Direct sum. Spaces with inner products.</p>\n\n<p>$\\circ$  <strong>U3:</strong> <em>Matrices and determinants.</em>\nMatrix Spaces. Sum and product of matrices. Linear ecuations. Gauss-Jordan elimination. Range. <strong>Roché Frobenius Theorem. Determinants. Properties. Determinant of a product. Determinants and inverses.</strong></p>\n\n<p>$\\star$ <strong>U4:</strong> <em>Linear transformations.</em>\nDefinition. Nucleus and image. Monomorphisms, epimorphisms and isomorphisms. Composition of linear transformations. Inverse linear tranforms.</p>\n\n<p><strong>U5:</strong> <em>Complex numbers and polynomials.</em>\nComplex numbers. Operations. Binomial and trigonometric form. De Möivre's Theorem. \nSolving equations. Polynomials. Degree. Operations. Roots. Remainder theorem. Factorial decomposition. FTA. <strong>Lagrange interpolation.</strong></p>\n\n<p>$\\star$ <strong>U6:</strong> <em>Linear transformations and matrices.</em>\nMatrix of a linear transformation. Matrix of the composition. Matrix of the inverse. Base changes. </p>\n\n<p>$\\star$ <strong>U7:</strong> <em>Eigen values and eigen vectors</em>\nEigen values and eigen vectors. Characteristc polynomial. Aplications. Invariant subspaces. Diagonalization. </p>\n\n<p>To let you know, I own a copy of Apostol's Calculus $\\mathrm I $ which has some of those topics, precisely:</p>\n\n<ul>\n<li>Linear Spaces</li>\n<li>Linear Transformations and Matrices.</li>\n</ul>\n\n<p>I also have a copy of Apostol's second book of Calc $\\mathrm II$which continues with</p>\n\n<ul>\n<li>Determinants</li>\n<li>Eigenvalues and eigenvectors</li>\n<li>Eigenvalues of operators in Euclidean spaces.</li>\n</ul>\n\n<p>I was reccommended <em>Linear Algebra</em> by Armando Rojo and have <em>Linear Algebra</em> by <a href=\"http://www.uv.es/~ivorra/\">Carlos Ivorra</a>, which seems quite a good text. </p>\n\n<p>What do you reccomend? </p>\n", "pids": ["53e9b991b7602d970457eebb"], "flag": 0}
{"question": "How to search for a New York area 20th century building by its appearance?", "body": "<p>I have these photos I inherited from my father of a building near a water feature that was taken around June 1958 in the New York City area, in a roll of film that is right before some photos of West Point.  I tried searching <a href=\"https://www.google.com/search?q=white+historical+building+garden+west+point&amp;tbm=isch&amp;ved=2ahUKEwjg7di11IPmAhUVmp4KHS4PABYQ2-cCegQIABAA&amp;oq=white+historical+building+garden+west+point\" rel=\"noreferrer\">Google Images with a bunch of terms</a> in various combinations and was unsuccessful.  The terms I tried included:</p>\n\n<ul>\n<li>Botanical Gardens</li>\n<li>New York</li>\n<li>Building</li>\n<li>Historical</li>\n<li>White</li>\n<li>Hudson River</li>\n<li>West Point</li>\n</ul>\n\n<p>There is a building that probably can be used to identify the location:</p>\n\n<p><a href=\"https://i.stack.imgur.com/OGf9p.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/OGf9p.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>The next photo shows the same building in the background behind the tree and has a water feature with statue of a human figure, that from prior picture's vantage point appears to be raised above the surrounding area by several feet:</p>\n\n<p><a href=\"https://i.stack.imgur.com/91mF1.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/91mF1.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>Ideas on how to better search for a building by its appearance?</p>\n", "pids": ["53e9b2ccb7602d9703d77fd2"], "flag": 1}
{"question": "Do harmonic numbers have a “closed-form” expression?", "body": "<p>One of the joys of high-school mathematics is summing a complicated series to get a “closed-form” expression. And of course many of us have tried summing the harmonic series $H_n =\\sum \\limits_{k \\leq n} \\frac{1}{k}$, and failed. But should we necessarily fail? </p>\n\n<blockquote>\n  <p>More precisely, is it known that $H_n$ <em>cannot</em> be written in terms of the elementary functions, say, the rational functions, $\\exp(x)$ and $\\ln x$? If so, how is such a theorem proved? </p>\n</blockquote>\n\n<p><strong>Note</strong>. When I started writing the question, I was going to ask if it is known that the harmonic function cannot be represented simply as a rational function? But this is easy to see, since $H_n$ grows like $\\ln n+O(1)$, whereas no rational function grows logarithmically.</p>\n\n<p><strong>Added note:</strong> This <a href=\"https://math.stackexchange.com/questions/155/\">earlier question</a> asks a similar question for “elementary integration”. I guess I am asking if there is an analogous theory of “elementary summation”. </p>\n", "pids": ["53e99b16b7602d97023abf44"], "flag": 0}
{"question": "Why PCA of data by means of SVD of the data?", "body": "<p>This question is about an efficient way to compute principal components.</p>\n\n<ol>\n<li><p>Many texts on linear PCA advocate using singular-value decomposition of the <em>casewise data</em>. That is, if we have data $\\bf X$ and want to replace the variables (its <em>columns</em>) by principal components, we do SVD: $\\bf X=USV'$, singular values (sq. roots of the eigenvalues) occupying the main diagonal of $\\bf S$, right eigenvectors $\\bf V$ are the orthogonal rotation matrix of axes-variables into axes-components, left eigenvectors $\\bf U$ are like $\\bf V$, only for cases. We can then compute component values as $ \\bf C=XV=US$.</p></li>\n<li><p>Another way to do PCA of variables is via decomposition of $\\bf R=X'X$ square matrix (i.e. $\\bf R$ <a href=\"https://stats.stackexchange.com/a/22520/3277\">can be</a> <em>correlations</em> or <em>covariances</em> etc., between the variables ). The decomposition may be eigen-decomposition or singular-value decomposition: with square symmetric positive semidefinite matrix, they will give the same result $\\bf R=VLV'$ with eigenvalues as the diagonal of $\\bf L$, and $\\bf V$ as described earlier. Component values will be $\\bf C=XV$.</p></li>\n</ol>\n\n<p>Now, my question: if data $\\bf X$ is a big matrix, and number of cases is (which is often a case) much greater than the number of variables, then way (1) <strong>is expected to be much slower</strong> than way (2), because way (1) applies a quite expensive algorithm (such as SVD) to a big matrix; it computes and stores huge matrix $\\bf U$ which we really doesn't need in our case (the PCA of variables). <strong>If</strong> so, then <strong>why</strong> so many texbooks seem to advocate or just mention only way (1)? Maybe it <em>is</em> efficient and I'm missing something?</p>\n", "pids": ["53e9ad9eb7602d9703799589"], "flag": 1}
{"question": "Research done by high-school students", "body": "<p>I'm giving a talk soon to a group of high-school students about open problems in mathematics that high-school students could understand.  To inspire them, I would like to give them examples of high-school students who have made original contributions in mathematics.  One example I have is the 11th-grader from Hawai'i named <a href=\"http://math.hawaii.edu/wordpress/11th-grader-creates-new-math-formulas-to-win-hawaii-state-science-fair/\" rel=\"noreferrer\">Kang Ying Liu</a> who in 2010 &quot;discover[ed] nine new geometric formulas for describing triangle inequalities.&quot;</p>\n<p>Do you have any other examples of high-school students who have made original contributions in mathematics?</p>\n", "pids": ["53e9b326b7602d9703df5229"], "flag": 0}
{"question": "Colliding Bullets", "body": "<p>I saw this problem yesterday on <a href=\"https://www.reddit.com/r/mathriddles/comments/3sa4ci/colliding_bullets/\" rel=\"noreferrer\">reddit</a> and I can't come up with a reasonable way to work it out.</p>\n<hr />\n<blockquote>\n<p>Once per second, a bullet is fired starting from <span class=\"math-container\">$x=0$</span> with a uniformly random speed in <span class=\"math-container\">$[0,1]$</span>. If two bullets collide, they both disappear. If we fire <span class=\"math-container\">$N$</span> bullets, what is the probability that at least one bullet escapes to infinity? What if we fire an infinite number of bullets?</p>\n</blockquote>\n<p><strong>Attempt.</strong></p>\n<ul>\n<li><p>If <span class=\"math-container\">$N$</span> is two, then it's equal to the probability that the first bullet is faster than the second, which is <span class=\"math-container\">$\\dfrac{1}{2}$</span>.</p>\n</li>\n<li><p>If <span class=\"math-container\">$N$</span> is odd, the probability of three bullets or more colliding in the same spot is <span class=\"math-container\">$0$</span>, so we can safely ignore this event. And since collisions destroy two bullets then there will be an odd number of bullets at the end. So at least one escapes to infinity.</p>\n</li>\n</ul>\n<p>For infinite bullets, I suspect that no single bullet will escape to infinity, but that they'll reach any arbitrarily big number. Although, I'm not sure on how I'd begin proving it.</p>\n<p>Is there a closed form solution for even <span class=\"math-container\">$N$</span>? Or some sort of asymptotic behavior?</p>\n", "pids": ["5c757103f56def9798744c68"], "flag": 0}
{"question": "How to solve an nth degree polynomial equation", "body": "<p>The typical approach of solving a quadratic equation is to solve for the roots</p>\n\n<p>$$x=\\frac{-b\\pm\\sqrt{b^{2}-4ac}}{2a}$$</p>\n\n<p>Here, the degree of x is given to be 2</p>\n\n<p>However, I was wondering on how to solve an equation if the degree of x is given to be n.</p>\n\n<p>For example, consider this equation:</p>\n\n<p>$$a_0 x^{n} + a_1 x^{n-1} + \\dots + a_n = 0$$</p>\n", "pids": ["5c82db0e4895d9cbc637e2b3", "53e9b196b7602d9703c22edb"], "flag": 0}
{"question": "Nobody told me that self teaching could be so damaging...", "body": "<p>Even though I've been teaching myself math for a couple of years now I only just started (a month ago) at the university. My experience is rather mixed.</p>\n\n<p>For starters, I'd like to mention that I'm 21 years old. As I understand it, this is not too young and not too old. Having said that, I can't help but feel jealous of all the young people who populate my courses. In one of my courses, the percentage of students under 18 is around 40% (haven't checked rigorously). The thing is I don't think that it would have bothered me so much if I hadn't felt like the academy is holding me back. </p>\n\n<p>When I learn by myself from books, I just go from one thing I didn't understand to the next and no minute felt wasted. Ignoring the fact that I can already solve the test of three courses I'm in (I tried to avoid them but I have to do them), I find myself more often than not writing down homework solutions to problems I wouldn't have spent a minute on since I knew they weren't an issue. The pace is so slow that I regret having started at the university in the first place (with the exception of one course).</p>\n\n<p>I understand that in some way this is something I did to myself (by teaching myself these things beforehand). I'd like advice or some support since I'm pretty close to taking back my decision to learn at the university. So far it feels like half the fun of math for twice the time (and all those little kids have the time since by my age they'll be doctoral students...). I really miss those self teaching days.</p>\n\n<p>I feel like if I would only be given a chance to study at my pace, I could finish the degree in a year and a half and have much more fun doing it...</p>\n\n<p>What am I to do?</p>\n\n<p>EDIT: It may be worth mentioning that I got exemption from several courses due to past studies I did in an open university (one where you learn alone from books).</p>\n", "pids": ["53e9982cb7602d970204fd07", "56d8e96bdabfae2eee46b620"], "flag": 0}
{"question": "Does $\\zeta(3)$ have a connection with $\\pi$?", "body": "<p><strong>The problem</strong></p>\n\n<p>Can be <span class=\"math-container\">$\\zeta(3)$</span> written as <span class=\"math-container\">$\\alpha\\pi^\\beta$</span>, where (<span class=\"math-container\">$\\alpha,\\beta \\in \\mathbb{C}$</span>), <span class=\"math-container\">$\\beta \\ne 0$</span> and <span class=\"math-container\">$\\alpha$</span> doesn't depend of <span class=\"math-container\">$\\pi$</span> (like <span class=\"math-container\">$\\sqrt2$</span>, for example)?</p>\n\n<p><strong>Details</strong></p>\n\n<p>Several <span class=\"math-container\">$\\zeta$</span> values are connected with <span class=\"math-container\">$\\pi$</span>, like:</p>\n\n<p><span class=\"math-container\">$\\zeta$</span>(2)=<span class=\"math-container\">$\\pi^2/6$</span></p>\n\n<p><span class=\"math-container\">$\\zeta$</span>(4)=<span class=\"math-container\">$\\pi^4/90$</span></p>\n\n<p><span class=\"math-container\">$\\zeta$</span>(6)=<span class=\"math-container\">$\\pi^6/945$</span></p>\n\n<p>...</p>\n\n<p>and so on for all even numbers.</p>\n\n<p>See this mathworld link to more details: <a href=\"http://mathworld.wolfram.com/RiemannZetaFunction.html\" rel=\"noreferrer\">Riemann Zeta Function</a></p>\n\n<p>So the question is, could <span class=\"math-container\">$\\zeta(3)$</span> be written as:</p>\n\n<blockquote>\n  <p><span class=\"math-container\">$$\\zeta(3)=\\alpha\\pi^\\beta$$</span>\n  <span class=\"math-container\">$$\\alpha,\\beta \\in \\mathbb{C}$$</span>\n  <span class=\"math-container\">$$\\beta \\ne 0$$</span>\n  <span class=\"math-container\">$$\\alpha \\text{ not dependent of } \\pi$$</span></p>\n</blockquote>\n\n<p>See <span class=\"math-container\">$\\alpha$</span> not essencially belongs <span class=\"math-container\">$\\mathbb{Q}$</span> and <span class=\"math-container\">$\\alpha,\\beta$</span> could be real numbers too.</p>\n\n<p>When I wrote <span class=\"math-container\">$\\alpha$</span> is not dependent of <span class=\"math-container\">$\\pi$</span> it's a strange and a hard thing to be defined, but maybe <span class=\"math-container\">$\\alpha$</span> can be written using <span class=\"math-container\">$e$</span> or <span class=\"math-container\">$\\gamma$</span> or <span class=\"math-container\">$\\sqrt2$</span> or some other constant.</p>\n\n<p><strong>Edit:</strong></p>\n\n<p>Maybe <strong>this still a open question</strong>. If</p>\n\n<p><span class=\"math-container\">$ \\sum_{k = 0}^{2} (-1)^{k} \\frac{B_{2k} \\ B_{2- 2k + 2}}{(2k)! \\ (2  - 2k + 2)!}$</span></p>\n\n<p>in <span class=\"math-container\">$-4 \\sum_{k = 0}^{2} (-1)^{k} \\frac{B_{2k} \\ B_{2- 2k + 2}}{(2k)! \\ (2  - 2k + 2)!}\\pi^3$</span> be of the form <span class=\"math-container\">$\\frac{\\delta}{\\pi^3}$</span> with <span class=\"math-container\">$\\delta$</span> <em>not dependent</em> of <span class=\"math-container\">$\\pi$</span></p>\n\n<p>and <span class=\"math-container\">$- 2 \\sum_{k \\geq 1} \\frac{k^{-3}}{e^{2 \\pi k} - 1}$</span> <em>not dependent</em> of <span class=\"math-container\">$\\pi$</span> too, this question still hard and open.</p>\n\n<p><strong>Edit 2:</strong></p>\n\n<p>I discovered a result, but later I've seen that this is something already known, either way, it is an interesting one to have it here.</p>\n\n<blockquote>\n  <p><span class=\"math-container\">$$\\zeta(3)=-4\\pi^2\\zeta'(-2)$$</span></p>\n</blockquote>\n\n<p>but, if <span class=\"math-container\">$\\zeta'(-2)$</span> is of the form <span class=\"math-container\">$\\frac{\\alpha}{\\pi^2}$</span>, with <span class=\"math-container\">$\\alpha$</span> not dependent of <span class=\"math-container\">$\\pi$</span>, then this still remains as a hard and an open question.</p>\n\n<p>I have a conjecture that <span class=\"math-container\">$\\zeta'(-2)$</span> will not cancel the <span class=\"math-container\">$\\pi^2$</span> term, but since I wasn't able to prove it and I can't use it here.</p>\n\n<p>We can express <span class=\"math-container\">$\\zeta$</span> of odd numbers with <span class=\"math-container\">$\\zeta'$</span> in a easy way, with a \"closed\" form like this one.</p>\n", "pids": ["53e9aee4b7602d970390ddbb"], "flag": 0}
{"question": "Unexpected use of topology in proofs", "body": "<p>One day I was reading an article on the infinitude of prime numbers in the <a href=\"https://proofwiki.org/wiki/Number_of_Primes_is_Infinite/Proof_2\" rel=\"noreferrer\">Proof Wiki</a>. The article introduced a proof that used only topology to prove the infinitude of primes, and I found it very interesting and satisfying. I'm wondering, if there are similar proofs that use topology where it's not obvious that it can be applied. I'm sure that seeing such proofs could also strengthen my intuition with topology.</p>\n\n<p>So my question is: \"Which theorems, not directly linked with topology, have interesting proofs that use topology?\".</p>\n\n<p>Thanks in advance!</p>\n", "pids": ["5c610981da56297340b7ca7b", "56d86f57dabfae2eeee7e015"], "flag": 0}
{"question": "Applications of complex numbers to solve non-complex problems", "body": "<p>Recently I asked a question regarding the diophantine equation $x^2+y^2=z^n$ for $x, y, z, n \\in \\mathbb{N}$, which to my surprise was answered with the help complex numbers. I find it fascinating that for a question which only concerns integers, and whose answers can only be integers, such an elegant solution comes from the seemingly unrelated complex numbers - looking only at the question and solution one would never suspect that complex numbers were lurking behind the curtain!</p>\n\n<p>Can anyone give some more examples where a problem which seems to deal entirely with real numbers can be solved using complex numbers behind the scenes? One other example which springs to mind for me is solving a homogeneous second order differential equation whose coefficients form a quadratic with complex roots, which in some cases gives real solutions for real coefficients but requires complex arithmetic to calculate.</p>\n\n<p>(If anyone is interested, the original question I asked can be found here: <a href=\"https://math.stackexchange.com/questions/2072371/x2y2-zn-find-solutions-without-pythagoras\">$x^2+y^2=z^n$: Find solutions without Pythagoras!</a>)</p>\n\n<p><strong>EDIT:</strong></p>\n\n<p>I just wanted to thank everyone for all the great answers! I'm working my way through all of them, although some are beyond me for now! </p>\n", "pids": ["56d8279fdabfae2eeee713d5"], "flag": 0}
{"question": "Bayesian lasso vs ordinary lasso", "body": "<p>Different implementation software are available for <strong>lasso</strong>. I know a lot discussed about bayesian approach vs frequentist approach in different forums. My question is very specific to lasso - <strong><em>What are differences or advantages of baysian lasso vs regular lasso</em></strong>? </p>\n\n<p>Here are two example of implementation in the package: </p>\n\n<pre><code># just example data\nset.seed(1233)\nX &lt;- scale(matrix(rnorm(30),ncol=3))[,]\nset.seed(12333)\nY &lt;- matrix(rnorm(10, X%*%matrix(c(-0.2,0.5,1.5),ncol=1), sd=0.8),ncol=1)\n\nrequire(monomvn) \n## Lasso regression\nreg.las &lt;- regress(X, Y, method=\"lasso\")\n\n## Bayesian Lasso regression\nreg.blas &lt;- blasso(X, Y)\n</code></pre>\n\n<p>So when should I go for one or other methods ? Or they are same ? </p>\n", "pids": ["5c0f7345da562944ac68644d", "58437722ac44360f1082edd6"], "flag": 1}
{"question": "Does a Fourier transformation on a (pseudo-)Riemannian manifold make sense?", "body": "<p>the Fourier transformation of a scalar function with respect to one variable might be defined as</p>\n\n<p>$\\mathcal{F}\\left[w\\right](\\omega )\\equiv \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty}w(t)e^{-\\mathrm{i}\\omega t}dt$\r</p>\n\n<p>In physics, this transformation along with its generalization, the Laplace transformation, has a tremendous importance because of its feature to turn linear partial differential equations into algebraic ones.</p>\n\n<p>Now, suppose that we have a pseudo-Riemannian manifold $\\mathcal{M}$ where $\\det{g_{\\mu\\nu}} = -1$ holds like in special and general relativity.</p>\n\n<p>I am wondering, what would be the generalization of the Fourier transformation of scalar functions or forms? </p>\n\n<p>The difficulty I have with this question is that a three-dimensional slicing of $\\mathcal{M}$ is not unique, so how to take the integral in an invariant form? What will happen to the differntials $dx^{\\mu}$, e.g. $dt,dx^i\\rightarrow d\\omega dx^i$ in some sense?</p>\n\n<p>Any insight would be well appreciated.<br>\nThank you in advance</p>\n\n<p>Robert</p>\n", "pids": ["53e99eb5b7602d970277d995", "53e9b564b7602d970409b26d", "5f039b16dfae54360a4687cb"], "flag": 0}
{"question": "Are commutative C*-algebras really dual to locally compact Hausdorff spaces?", "body": "<p>Several online sources (e.g. <a href=\"http://en.wikipedia.org/wiki/Locally_compact_space#The_point_at_infinity\">Wikipedia</a>, the <a href=\"http://ncatlab.org/nlab/show/locally+compact+space\">nLab</a>) assert that the Gelfand representation defines a contravariant equivalence from the category of (non-unital) commutative $C^{\\ast}$-algebras to the category of locally compact Hausdorff (LCH) spaces. This seems wrong to me. </p>\n\n<p>The naive choice is to take all continuous maps between LCH spaces. This doesn't work. For example, the constant map $\\mathbb{R} \\to \\bullet$ does not come from a morphism $\\mathbb{C} \\to C_0(\\mathbb{R})$, the problem being that composing with the map $\\bullet \\to \\mathbb{C}$ sending $\\bullet$ to $1$ gives a function on $\\mathbb{R}$ which doesn't vanish at infinity. It is necessary for us to restrict our attention to <a href=\"http://en.wikipedia.org/wiki/Proper_map\">proper maps</a>.</p>\n\n<p>But this still doesn't work. If $A, B$ are any commutative $C^{\\ast}$-algebras we can consider the morphism\n$$A \\ni a \\mapsto (a, 0) \\in A \\times B.$$</p>\n\n<p>This morphism does not define a map on Gelfand spectra; if $\\lambda : A \\times B \\to \\mathbb{C}$ is a character factoring through the projection $A \\times B \\to B$, then composing with the above morphism gives the zero map $A \\to \\mathbb{C}$. This contradicts the nLab's <a href=\"http://ncatlab.org/nlab/show/Gelfand+duality\">claim</a> that taking Gelfand spectra gives a functor into locally compact Hausdorff spaces (if one requires that the morphisms are defined everywhere on the latter category). </p>\n\n<p>The correct statement appears to be that commutative $C^{\\ast}$-algebras are contravariantly equivalent to the category $\\text{CHaus}_{\\bullet}$ of pointed compact Hausdorff spaces; the functor takes an algebra to the Gelfand spectrum of its unitization (we adjoin a unit whether or not the algebra already had one). There is an inclusion of the category of LCH spaces and proper maps into this category but it is not an equivalence because maps $(C, \\bullet) \\to (D, \\bullet)$ in $\\text{CHaus}_{\\bullet}$ may send points other than the distinguished point of $C$ to the distinguished point of $D$. </p>\n\n<p>So do sources mean something else when they claim the equivalence with locally compact Hausdorff spaces? </p>\n", "pids": ["53e9ba4ab7602d97046618cc"], "flag": 0}
{"question": "$\\forall n\\in\\mathbb N:n^x\\in\\mathbb Q$ implies $x\\in\\mathbb Z$ - elementary proof?", "body": "<p>Consider the following two problems:</p>\n\n<blockquote>\n  <ol>\n  <li>Show that if for some $x\\in\\mathbb R$ and for each $n\\in\\mathbb N$ we have $n^x\\in\\mathbb N$, then $x\\in\\mathbb N$.</li>\n  <li>Show that if for some $x\\in\\mathbb R$ and for each $n\\in\\mathbb N$ we have $n^x\\in\\mathbb Q$, then $x\\in\\mathbb Z$.</li>\n  </ol>\n</blockquote>\n\n<p>The first of those is a somewhat infamous Putnam problem (A6 from 1971) and there is an elementary proof of this using calculus of differences and mean value results, which you can read <a href=\"https://mks.mff.cuni.cz/kalva/putnam/psoln/psol716.html\" rel=\"noreferrer\">here</a>.</p>\n\n<p>As mentioned in an answer <a href=\"https://math.stackexchange.com/q/378130/127263\">here</a>, the second problem follows from the six exponentials theorem, even if we only require $2^x,3^x,5^x$ to be rational. However, this solution is <em>very</em> non-elementary, and I suspect that using all values of $n$ we might be able to give an easier proof, just like we can for the first problem (though I'm aware the linked proof doesn't generalize).</p>\n\n<p>Is it possible to solve the second problem with elementary means?</p>\n", "pids": ["6209c8255aee126c0f1e7eb8"], "flag": 0}
{"question": "Has a virus ever escaped a high-level virus lab &quot;such as the one in Wuhan&quot;?", "body": "<p>As somewhat unclearly <a href=\"https://www.dailymail.co.uk/news/article-8211291/U-S-government-gave-3-7million-grant-Wuhan-lab-experimented-coronavirus-source-bats.html\" rel=\"noreferrer\">related</a> in the Daily Mail:</p>\n\n<blockquote>\n  <p>Dr Keusch, Professor of Medicine and International Health at Boston University's Schools of Medicine and Public Health, stressed that no release of viruses from a high-level lab, such as the one in Wuhan, 'has ever happened'.</p>\n</blockquote>\n\n<p>I think he's referring to the BSL-4 labs. As a quick breakdown/check on lab numbers by safety level; <a href=\"https://www.nap.edu/read/13315/chapter/26\" rel=\"noreferrer\">just in the the UK in 2007</a> there were 600 BLS-3 labs, but only ten BSL-4. Not all of them were operating and there's a safety sub-level for those that can operate at ACDP4--meaning BSL-4 and using pathogens that can infect humans (only 5 of those in the UK then, four of which were in operation); the other were SAPO4 (for animal pathogens). The Wuhan lab Keusch mentions next is BSL-4. So I'm thinking the claim refers only to BSL-4.</p>\n\n<p>Examples of BSL-3 breaches include <a href=\"https://www.newyorker.com/science/elements/the-risks-of-building-too-many-bio-labs\" rel=\"noreferrer\">FMD at PIADC</a>--DavePhd's answer-- or SARS from a lab in Beijing, 2004, included in LangLangC's answer. In fact that accident was one of the reasons that China built its first BSL-4, the one in Wuhan, operational at this level <a href=\"https://www.sciencedirect.com/science/article/pii/S2590053619300291\" rel=\"noreferrer\">since 2018</a>.</p>\n\n<p>So is the claim (still) true for BSL-4 labs (worldwide)? (There were approximately 60 BSL-4 labs in the world, as of 2018.)</p>\n", "pids": ["64d641fe3fda6d7f06226db4"], "flag": 1}
{"question": "$n$th derivative of $e^{1/x}$", "body": "<p>I am trying to find the $n$'th derivative of $f(x)=e^{1/x}$. When looking at the first few derivatives I noticed a pattern and eventually found the following formula</p>\n\n<p>$$\\frac{\\mathrm d^n}{\\mathrm dx^n}f(x)=(-1)^n e^{1/x} \\cdot \\sum _{k=0}^{n-1} k! \\binom{n}{k} \\binom{n-1}{k} x^{-2 n+k}$$</p>\n\n<p>I tested it for the first $20$ derivatives and it got them all. Mathematica says that it is some hypergeometric distribution but I don't want to use that. Now I am trying to verify it by induction but my algebra is not good enough to do the induction step.</p>\n\n<p>Here is what I tried for the induction (incomplete, maybe incorrect)</p>\n\n<p>$\\begin{align*}\r\n\\frac{\\mathrm d^{n+1}}{\\mathrm dx^{n+1}}f(x)&amp;=\\frac{\\mathrm d}{\\mathrm dx}(-1)^n e^{1/x} \\cdot \\sum _{k=0}^{n-1} k! \\binom{n}{k} \\binom{n-1}{k} x^{-2 n+k}\\\\\r\n&amp;=(-1)^n e^{1/x} \\cdot \\left(\\sum _{k=0}^{n-1} k! \\binom{n}{k} \\binom{n-1}{k} (-2n+k) x^{-2 n+k-1}\\right)-e^{1/x} \\cdot \\sum _{k=0}^{n-1} k! \\binom{n}{k} \\binom{n-1}{k} x^{-2 (n+1)+k}\\\\\r\n&amp;=(-1)^n e^{1/x} \\cdot \\sum _{k=0}^{n-1} k! \\binom{n}{k} \\binom{n-1}{k}((-2n+k) x^{-2 n+k-1}-x^{-2 (n+1)+k)})\\\\\r\n&amp;=(-1)^{n+1} e^{1/x} \\cdot \\sum _{k=0}^{n-1} k! \\binom{n}{k} \\binom{n-1}{k}(2n x-k x+1) x^{-2 (n+1)+k}\r\n\\end{align*}$</p>\n\n<p>I don't know how to get on from here.</p>\n", "pids": ["56d856fadabfae2eee303142"], "flag": 0}
{"question": "Can every group be represented by a group of matrices?", "body": "<blockquote>\n  <p>Can every group be represented by a group of matrices?</p>\n</blockquote>\n\n<p>Or are there any counterexamples? Is it possible to prove this from the group axioms?</p>\n", "pids": ["53e99e6ab7602d970272edc1"], "flag": 0}
{"question": "Striking applications of linearity of expectation", "body": "<p>Linearity of expectation is a very simple and &quot;obvious&quot; statement, but has many non-trivial applications, e.g., to analyze randomized algorithms (for instance, the <a href=\"https://en.wikipedia.org/wiki/Coupon_collector%27s_problem#Calculating_the_expectation\" rel=\"noreferrer\">coupon collector's problem</a>), or in some proofs where dealing with non-independent random variables would otherwise make any calculation daunting.</p>\n<p>What are the cleanest, most elegant, or striking applications of the linearity of expectation you've encountered?</p>\n", "pids": ["5a9cb65d17c44a376ffb8330"], "flag": 0}
{"question": "Can $\\sqrt{p}^{\\sqrt{p}^{\\sqrt{p}}}$ be an integer, if $p$ is a non-square positive integer?", "body": "<p>Can $\\sqrt{p}^{\\sqrt{p}^{\\sqrt{p}}}$ be an <em>integer</em>, when $p$ is a non-square positive integer? </p>\n\n<p>Of course, it seems it would never but is there a proof of the fact, or maybe we have some spooky $p$ that makes it valid?</p>\n", "pids": ["56d88efddabfae2eeed792dc", "53e9b495b7602d9703f9b901"], "flag": 0}
{"question": "Did hominids and non-avian dinosaurs ever coexist?", "body": "<p>Although the extinction of the non-avian dinosaurs is dated at <a href=\"https://en.wikipedia.org/wiki/Cretaceous%E2%80%93Paleogene_extinction_event\" rel=\"noreferrer\">~66 million years</a> ago there are a number of purported cave drawings that I've found online that (if verified and interpreted in a certain way!) could suggest that hominids and non-avian dinosaurs were present on the Earth at the same time.</p>\n\n<p>One debunked case of human-dinosaur interaction can been found in this <a href=\"https://skeptics.stackexchange.com/questions/28697/did-paleontologist-stan-taylor-discover-human-footprints-dated-from-the-period-o\">question</a> on 'human footprints' found alongside dinosaur footprints.</p>\n\n<p><a href=\"https://el-libertario.webnode.es/en/dinosaurs-coexisting-with-men/\" rel=\"noreferrer\">This website</a> (and <a href=\"http://historysevidenceofdinosaursandmen.weebly.com/visual.html\" rel=\"noreferrer\">another site</a>) shows a number of examples of cave paintings of what is purported to be dinosaurs. It's easy to see how early cave painters could have exaggerated anatomical features to represent an extant animal in some rudimentary form and make the animal look like what would appear to us as a dinosaur.</p>\n\n<p>The depiction of dragons in mythology and folklore (<a href=\"https://en.wikipedia.org/wiki/List_of_dragons_in_mythology_and_folklore\" rel=\"noreferrer\">see here</a> and <a href=\"https://en.wikipedia.org/wiki/Dragon#Sources_of_inspiration_for_dragon_myths\" rel=\"noreferrer\">here</a>) is well documented, but the earliest references to these don't span much further back than 5000 years ago. Although zoomorphic depictions of man-animals appear as far back as 35,000 years, see <a href=\"https://en.wikipedia.org/wiki/Lion-man\" rel=\"noreferrer\">here</a>, I'm unsure whether other figurative representations of animals were around at the time i.e. to explain why dinosaur paintings may appear in caves.</p>\n\n<p>Furthermore, in the New World, there were many large mammals that rapidly became extinct as a result of fast human colonization (see <a href=\"https://rads.stackoverflow.com/amzn/click/0393317552\" rel=\"noreferrer\">Jared Diamond's book Gun's, Germs and Steel</a>), some of which were painted in caves.</p>\n\n<p>Did non-avian dinosaurs and hominids overlap in time?</p>\n", "pids": ["53e99dc5b7602d97026845be"], "flag": 1}
{"question": "Simplest way to get the lower bound $\\pi &gt; 3.14$", "body": "<p>Inspired from <a href=\"https://math.stackexchange.com/a/2471364/72031\">this answer</a> and my comment to it, I seek alternative ways to establish $\\pi&gt;3.14$. The goal is to achieve simpler/easy to understand approaches as well as to minimize the calculations involved. The method in my comment is based on Ramanujan's series $$\\frac{4}{\\pi}=\\frac{1123}{882}-\\frac{22583}{882^{3}}\\cdot\\frac{1}{2}\\cdot\\frac{1\\cdot 3}{4^{2}}+\\frac{44043}{882^{5}}\\cdot\\frac{1\\cdot 3}{2\\cdot 4}\\cdot\\frac{1\\cdot 3\\cdot 5\\cdot 7}{4^{2}\\cdot 8^{2}}-\\dots\\tag{1}$$ This is quite hard to understand (at least in my opinion, see the <a href=\"http://paramanands.blogspot.com/2012/03/modular-equations-and-approximations-to-pi-part-1.html\" rel=\"noreferrer\">blog posts</a> to convince yourself) but achieves the goal of minimal calculations with evaluation of just the first term being necessary.</p>\n\n<p>On the other end of spectrum is the reasonably easy to understand series\n$$\\frac\\pi4=1-\\frac13+\\frac15-\\cdots\\tag2$$\nBut this requires a large number of terms to get any reasonable accuracy. I would like a happy compromise between the two and approaches based on other ideas apart from series are also welcome.</p>\n\n\n\n<p>A <a href=\"https://math.stackexchange.com/q/1366301/72031\">previous question</a> of mine gives an approach to estimate the error in truncating the Leibniz series $(2)$ and it gives bounds for $\\pi$ with very little amount of calculation. However it requires the use of continued fractions and proving the desired continued fraction does require some effort.</p>\n\n\n\n<p>Another set of approximations to $\\pi$ from below are obtained using <a href=\"http://paramanands.blogspot.com/2012/03/ramanujans-class-invariants.html\" rel=\"noreferrer\">Ramanujan's class invariant</a> $g_n$ namely $$\\pi\\approx\\frac{24}{\\sqrt{n}}\\log(2^{1/4}g_n)\\tag{3}$$ and $n=10$ gives the approximation $\\pi\\approx 3.14122$ but this approach has a story similar to that of equation $(1)$.</p>\n", "pids": ["56d877addabfae2eee24680b"], "flag": 0}
{"question": "Can math be subjective?", "body": "<p>Often times in math, ever since Kindergarten and before, math has been defined by the fact that there are only one answer for problems. For example: $1+1=2$ and $\\frac{d}{dx}x^2=2x$. What I am showing by these two examples are two questions that are from completely different areas of math. However, they both have have only one solution. Problems with multiple answers doesn't necessarily mean they are subjective though, such as $|x|=2,$ which has two solutions. My question is that are any such problems that depend entirely on perspective? If all subjective math problems follow a certain pattern, please tell me what that pattern is. I really have no idea of any examples of this and I would really be interested to see one. Thank you very much.</p>\n", "pids": ["53e9b12ab7602d9703ba96d1", "53e9bd92b7602d9704a37e80"], "flag": 0}
{"question": "Good introductory book on geometric algebra", "body": "<p>The title of the question already says it all but I would like to add that I would really like the book to be more about geometric algebra than its applications : it should contain theorems' proofs. Just adding that I have never taken a course on geometric algebra. I'm a 2nd year engineering student, so a \"beginner\" book style will be very good!!! Also mentioning what would be the prerequisites for mastering the branch is appreciated. Thanks.</p>\n", "pids": ["5c6109acda56297340b880b4"], "flag": 0}
{"question": "What is the solution of $\\cos(x)=x$?", "body": "<p>There is an unique solution with <span class=\"math-container\">$x$</span> being approximately <span class=\"math-container\">$0.739085$</span>. But is there also a closed-form solution?</p>\n", "pids": ["5c757363f56def9798895169", "56d855bbdabfae2eee269a35", "62c3abbb5aee126c0fc96f56"], "flag": 0}
{"question": "Are there other kinds of bump functions than $e^\\frac1{x^2-1}$?", "body": "<p>I've only seen the bump function $e^\\frac1{x^2-1}$ so far.  Where could I find examples of functions $C^∞$ on $\\mathbb{R}$ that are zero everywhere except on $(-1,1)$?</p>\n\n<p>Are there others that do not involve the exponential function?  Are there any with a closed form integral?  Is there a preferred function?</p>\n", "pids": ["5c756f16f56def9798637460"], "flag": 0}
{"question": "What is the fastest/most efficient algorithm for estimating Euler&#39;s Constant $\\gamma$?", "body": "<p>What is the fastest algorithm for estimating Euler's Constant $\\gamma \\approx0.57721$?</p>\n\n<p>Using the definition:</p>\n\n<p>$$\\lim_{n\\to\\infty} \\sum_{x=1}^{n}\\frac{1}{x}-\\log n=\\gamma$$</p>\n\n<p>I finally get $2$ decimal places of accuracy when $n\\geq180$.  The third correct decimal place only comes when $n \\geq638$.  Clearly, this method is not very efficient (it can be expensive to compute $\\log$).</p>\n\n<p>What is the best method to use to numerically estimate $\\gamma$ efficiently?</p>\n", "pids": ["53e9a812b7602d97031543b3", "53e9bba7b7602d97047ef220"], "flag": 0}
{"question": "Examples of group-theoretic results more easily obtained through topology or geometry", "body": "<p>Earlier, I was looking at a question here about the abelianization of a certain group $X$. Since $X$ was the fundamental group of a closed surface $\\Sigma$, it was easy to compute $X^{ab}$ as $\\pi_1(\\Sigma)^{ab} = H_1(\\Sigma)$, then use the usual machinery to compute $H_1(\\Sigma)$. That made me curious about other compelling examples of solving purely (for some definition of 'purely') algebraic questions that are accessible via topology or geometry. The best example I can think of the Nielsen-Schreier theorem, which is certainly provable directly but has a very short proof by recasting the problem in terms of the fundamental group of a wedge product of circles. Continuing this line of reasoning leads to things like graphs of groups, HNN-extensions, and other bits of geometric group theory.</p>\n\n<p>What are some other examples, at any level, of ostensibly purely group-theoretic results that have compelling, shorter topological proofs? The areas are certainly closely connected; I'm looking more for what seem like completely algebraic problems that turn out to have completely topological resolutions.</p>\n", "pids": ["61c853e75244ab9dcb27eab9"], "flag": 0}
{"question": "When can we not treat differentials as fractions? And when is it perfectly OK?", "body": "<h2>Background</h2>\n<p>I am a first year calculus student so I would prefer if answers remained in Layman's terms.</p>\n<p>It is common knowledge and seems to me a mantra that I keep hearing over and over again to &quot;not treat differentials/derivatives as fractions&quot;.</p>\n<p>I am of course, in particular, referring to <strong>Leibniz notation</strong>.</p>\n<p>However, aside from a quick response such as &quot;oh, it's because its not a fraction but rather a type of operator&quot;, I never really got a full answer as to <em>why</em> we can't treat it as such. It just kind of sits at the edge of taboo in my mind where it sometimes gets used and sometimes doesn't.</p>\n<p>Confusion is further compounded when a lot of things seem to just <em>work out</em> if we treat them just as fractions (e.g. u-substitution/related-rates)</p>\n<hr />\n<h2>Example</h2>\n<blockquote>\n<p>Air is being pumped into a balloon at a rate of <span class=\"math-container\">$100cm^3/s$</span>. We want the rate of change of radius when the radius is at <span class=\"math-container\">$25cm$</span>.</p>\n</blockquote>\n<p><span class=\"math-container\">$$\\text{we are given}\\ \\frac{dv}{dt}=100cm^3/s$$</span>\n<span class=\"math-container\">$$\\text{we want}\\ \\frac{dr}{dt}\\ \\text{when}\\ r=25cm$$</span>\nThus we will solve this by using the relation <span class=\"math-container\">$v=\\frac{4}{3}\\pi r^3$</span>\n<span class=\"math-container\">$$\\frac{dv}{dt}=\\frac{dv}{dr}\\frac{dr}{dt}$$</span>\n<span class=\"math-container\">$$\\frac{dv}{dt}\\frac{dr}{dv}=\\frac{dr}{dt}$$</span>\n<span class=\"math-container\">$$100\\frac{1}{4\\pi r^2}=\\frac{1}{25\\pi}$$</span>\nSo the answer is <span class=\"math-container\">$\\frac{dr}{dt}=\\frac{1}{25\\pi}$</span> when <span class=\"math-container\">$r=25cm$</span></p>\n<p><em>*Note the manipulation of derivatives just as if they were common fractions using algebra.</em></p>\n<hr />\n<h2>Question</h2>\n<p><strong>When exactly can I treat differentials/derivatives as fractions and when can I not?</strong></p>\n<p>Please keep in mind that at the end of the day, I am a first year college student. An answer that is easy to understand is preferred over one that is more mathematically rigorous but less friendly to a beginner such as me.</p>\n", "pids": ["5c757361f56def9798893b96"], "flag": 0}
{"question": "Did the CIA blow up a Siberian pipeline in 1982?", "body": "<p>The Telegraph claimed in 2004 that the <a href=\"https://www.telegraph.co.uk/news/worldnews/northamerica/usa/1455559/CIA-plot-led-to-huge-blast-in-Siberian-gas-pipeline.html\" rel=\"noreferrer\">CIA blew up a Russian gas pipeline in Siberia</a>, by tricking the operator into installing booby-trapped software.</p>\n\n<blockquote>\n  <p>Thomas Reed, a former US Air Force secretary who was in Ronald Reagan's National Security Council, discloses what he called just one example of the CIA's \"cold-eyed economic warfare\" against Moscow in a memoir to be published next month.</p>\n  \n  <p>Leaked extracts in yesterday's Washington Post describe how the operation caused \"the most monumental non-nuclear explosion and fire ever seen from space\" in the summer of 1982.</p>\n  \n  <p>Mr Reed writes that the software \"was programmed to reset pump speeds and valve settings to produce pressures far beyond those acceptable to pipeline joints and welds\".</p>\n</blockquote>\n\n<p>They quote a \"Thomas Reed\" and the Washington Post as a source, but that site is behind some kind of paywall or geoblock so I can't actually access it.</p>\n\n<p>Did this actually happen?</p>\n", "pids": ["5c7578c4f56def9798a55836"], "flag": 1}
{"question": "Real world application of Fourier series", "body": "<p>What are some real world applications of Fourier series? Particularly the complex Fourier integrals? </p>\n", "pids": ["55a4049565ce5cd7b3c0c2d9", "53e9b45eb7602d9703f5e990"], "flag": 0}
{"question": "Why are (representations of ) quivers such a big deal?", "body": "<p><a href=\"http://en.wikipedia.org/wiki/Quiver_%28mathematics%29\" rel=\"noreferrer\">Quivers</a> are directed graphs where loops and multi-arrows are allowed. And we can talk about representations of quivers by assigning each vertex a vector space and each arrow a homomorphism. Moreover, Gabriel gives <a href=\"http://en.wikipedia.org/wiki/Gabriel%27s_theorem\" rel=\"noreferrer\">a complete classification</a> of quivers of finite type using just five Dynkin diagrams.</p>\n\n<p>Although these are both deep and surprising, but I am not sure why quivers deserve so much attention. The only potential application I can think of (although highly unlikely to be true) that they might be useful to answer certain questions in category theory since the notion of quivers are similar to categories, and a representation is very much like a functor from a quiver to some $\\mathcal{k}$-$\\operatorname{vect}$. </p>\n\n<p>So I wonder whether someone can give a hint why quivers deserve so much attention? Do they naturally show up in problems? And do representations of quivers really help to solve these problems?</p>\n", "pids": ["53e99875b7602d97020ad0d8"], "flag": 0}
{"question": "Is $dx\\,dy$ really a multiplication of $dx$ and $dy$?", "body": "<p>On the answers of the question <a href=\"https://math.stackexchange.com/questions/21199/is-dy-dx-not-a-ratio\">Is $\\frac{\\textrm{d}y}{\\textrm{d}x}$ not a ratio?</a> it was told that <span class=\"math-container\">$\\frac{dy}{dx}$</span> cannot be seen as a quotient, even though it looks like a fraction. My question is: does <span class=\"math-container\">$dxdy$</span> in the double integral represent a multiplication of differentials? The problem then can be generalized for a multiple integral.</p>\n", "pids": ["5c756cd3f56def97984cb9b3"], "flag": 0}
{"question": "How did early mathematicians make it without Set theory?", "body": "<p>It is said that Cauchy was a pioneer of rigour in calculus and a founder of complex analysis. Yet if baffles me as set theory was an invention of the 1870s, 20 years after the death of Cauchy. Currently the beginning of most concepts in mathematics begins with the concept of set. Furthermore the concept of groups whose foundations were laid by Galois and Abel were done so long before set theory.</p>\n\n<p>I hope there is a genral way to answer these questions</p>\n\n<p>1) We define functions with a domain and range both being sets. But when Cauchy used the symbol 'f(x)', what did it really mean to him? As Cauchy was notorious for his rigorous approach, it is hard to believe that he may have just used the word function ambiguously with intuitive satisfaction.</p>\n\n<p>(If the following question makes the topic too broad I'd be more than happy to list it as a separate question.</p>\n\n<p>2)To a certain extent I can even brush away the idea of functions before sets. But I simply cannot grasp how the concept of group was formulated without a set and I'm puzzled as to how Galois and Abel were independently able to frame methods to prove the unsolvability of the quintic (these days the proof makes generous use of set theory)without sets.</p>\n\n<p>In these days where N, Z, Q and R all sets, how did the early masters do what they did? How on earth was calculus made rigorous without the sets of different numbers?</p>\n", "pids": ["5b67c927ab2dfb7a202aa69a"], "flag": 0}
{"question": "On the problem of polynomial bijection from $\\mathbb Q\\times\\mathbb Q$ to $\\mathbb Q$", "body": "<p>The question titled <a href=\"https://mathoverflow.net/questions/21003/polynomial-bijection-from-mathbb-q-times-mathbb-q-to-mathbb-q\">\"Polynomial bijection from $\\mathbb Q\\times\\mathbb Q$ to $\\mathbb Q$\"</a> \nwhich was posed on <em>MathOverflow</em> attracted quite a lot of attention (and may be the question with most wrong answers ever asked on the website according to the comments of other users).</p>\n\n<p>I have gone through some of the comments and realized that this question is related to the \"<em>abc</em> conjecture\" as well as to the \"Bombieri-Lang conjecture\".</p>\n\n<p>Would you explain (in a way that is precise but <em>accessible to an undergraduate student</em>)</p>\n\n<ul>\n<li><p>why is this problem so difficult and what its solution would imply;</p></li>\n<li><p>what are its relationships with the \"<em>abc</em> conjecture\" and the \"Bombieri-Lang conjecture\";</p></li>\n<li><p>and what are the major reference papers on the topic (have there been any major progresses recently in ideas and methods to tackle the question)?</p></li>\n</ul>\n\n<p>I see that it also not known if there is an <em>injection</em>. What are the differences between the problems in respect with the three points listed above?</p>\n", "pids": ["53e9aae5b7602d970346336f"], "flag": 0}
{"question": "Sharing a pepperoni pizza with your worst enemy", "body": "<p>You are about to eat a pepperoni pizza, which is sliced into eight pieces. Each pepperoni will unambiguously belong to some slice (no pepperoni is \"between\" slices).</p>\n\n<p>The caveat is that you have to share the pizza with your worst enemy, and you want to secure more pieces of pepperoni than he does. Slices are chosen as follows: First you choose any slice. Then your enemy chooses a slice adjacent to the slice that you just chose. Next, you choose a slice adjacent to one of the two chosen slices, and so on.</p>\n\n<p>How do you make sure you get at least as much pepperoni as your opponent? In this case, a solution is as follows: Number the slices $1, 2, 1, 2, 1, 2, 1, 2$, such that any two consecutive slices have different labels. Add the number of pepperonis on all slices with the label $1$, and add the number of pepperonis on all slices with the label $2$. If e.g. the number of pepperonis on the slices numbered $1$ is largest, you choose some slice with the number $1$. Your enemy can then only choose a slice with the number $2$, to which you respond by choosing the next adjacent slice with the number $1$, and so forth.</p>\n\n<p>This works, whenever there is an even number of slices.</p>\n\n<p>My question is, is there a winning strategy, when the number of slices is odd?</p>\n", "pids": ["53e9afacb7602d97039f97b1"], "flag": 0}
{"question": "Zero divided by zero must be equal to zero", "body": "<p>What is wrong with the following argument (if you don't involve ring theory)?</p>\n\n<p><strong>Proposition 1</strong>: $\\frac{0}{0} = 0$</p>\n\n<p><strong>Proof</strong>: Suppose that $\\frac{0}{0}$ is not equal to $0$</p>\n\n<p>$\\frac{0}{0}$ is not equal to $0 \\Rightarrow \\frac{0}{0} = x$ , some $x$ not equal to $0$ $\\Rightarrow$ $2(\\frac{0}{0}) = 2x$  $\\Rightarrow$  $\\frac{2\\cdot 0}{0} = 2x$ $\\Rightarrow$ $\\frac{0}{0} = 2x$ $\\Rightarrow$ $x = 2x$ $\\Rightarrow$ $ x = 0$ $\\Rightarrow$[because $x$ is not equal to $0$]$\\Rightarrow$ contradiction</p>\n\n<p>Therefore, it is not the case that $\\frac{0}{0}$ is not equal to $0$</p>\n\n<p>Therefore, $\\frac{0}{0} = 0$. </p>\n\n<p>Q.E.D.</p>\n\n\n\n<p><em>Update (2015-12-01) after your answers:</em></p>\n\n<p><strong>Proposition 2</strong>: $\\frac{0}{0}$ is not a real number</p>\n\n<p><strong>Proof</strong> <em>[Update (2015-12-07): Part 1 of this argument is not valid, as pointed out in the comments below]</em>: </p>\n\n<p>Suppose that $\\frac{0}{0}= x$, where $x$ is a real number.</p>\n\n<p>Then, either $x = 0$ or $x$ is not equal to $0$.</p>\n\n<p>1) Suppose $x = 0$, that is $\\frac{0}{0} = 0$</p>\n\n<p>Then, $1 = 0 + 1 = \\frac{0}{0} + \\frac{1}{1} = \\frac{0 \\cdot 1}{0 \\cdot 1} + \\frac{1 \\cdot 0}{1 \\cdot 0} = \\frac{0 \\cdot 1 + 1 \\cdot 0}{0 \\cdot 1} = \\frac{0 + 0}{0} = \\frac{0}{0} = 0 $</p>\n\n<p>Contradiction</p>\n\n<p>Therefore, it is not the case that $x = 0$.</p>\n\n<p>2) Suppose that $x$ is not equal to $0$.</p>\n\n<p>$x = \\frac{0}{0} \\Rightarrow 2x = 2 \\cdot \\frac{0}{0} = \\frac{2 \\cdot 0}{0} = \\frac{0}{0} = x \\Rightarrow x = 0 \\Rightarrow$ contradiction</p>\n\n<p>Therefore, it is not the case that $x$ is a real number that is not equal to $0$.</p>\n\n<p>Therefore, $\\frac{0}{0}$ is not a real number. </p>\n\n<p>Q.E.D.</p>\n\n\n\n<p><em>Update (2015-12-02)</em></p>\n\n<p>If you accept the (almost) usual definition, that for all real numbers $a$, $b$ and $c$, we have $\\frac{a}{b}=c$ iff $ a=cb $, then I think the following should be enough to exclude $\\frac{0}{0}$ from the real numbers.</p>\n\n<p><strong>Proposition 3</strong>: $\\frac{0}{0}$ is not a real number</p>\n\n<p><strong>Proof</strong>: Suppose that $\\frac{0}{0} = x$, where $x$ is a real number.</p>\n\n<p>$\\frac{0}{0}=x \\Leftrightarrow x \\cdot 0 = 0 = (x + 1) \\cdot 0 \\Leftrightarrow \\frac{0}{0}=x+1$</p>\n\n<p>$ \\therefore x = x + 1 \\Leftrightarrow 0 = 1 \\Leftrightarrow \\bot$</p>\n\n<p>Q.E.D.</p>\n\n\n\n<p><em>Update (2015-12-07):</em></p>\n\n<p>How about the following improvement of Proposition 1 (it should be combined with a new definition of division and fraction, accounting for the $\\frac{0}{0}$-case)?</p>\n\n<p><strong>Proposition 4</strong>: Suppose $\\frac{0}{0}$ is defined, so that $\\frac{0}{0} \\in \\mathbb{R}$, and that the rule $a \\cdot \\frac{b}{c} = \\frac{a \\cdot b}{c}$ holds for all real numbers $a$, $b$ and $c$.\nThen, $\\frac{0}{0} = 0$</p>\n\n<p><strong>Proof</strong>: Suppose that $\\frac{0}{0}=x$, where $x \\ne 0$.</p>\n\n<p>$x = \\frac{0}{0} \\Rightarrow 2x = 2 \\cdot \\frac{0}{0} = \\frac{2 \\cdot 0}{0} = \\frac{0}{0} = x \\Rightarrow x = 0 \\Rightarrow \\bot$</p>\n\n<p>$\\therefore \\frac{0}{0}=0$</p>\n\n<p>Q.E.D.</p>\n\n\n\n<p>Suggested <strong>definition</strong> of division of real numbers:</p>\n\n<p>If $b \\ne 0$, then</p>\n\n<p>$\\frac{a}{b}=c$ iff $a=bc$</p>\n\n<p>If $a=0$ and $b=0$, then</p>\n\n<p>$\\frac{a}{b}=0$</p>\n\n<p>If $a \\ne 0$ and $b=0$, then $\\frac{a}{b}$ is undefined.</p>\n\n\n\n<p>A somewhat more minimalistic version:</p>\n\n<p><strong>Proposition 5</strong>. If $\\frac{0}{0}$ is defined, so that $\\frac{0}{0} \\in \\mathbb{R}$, then $\\frac{0}{0}=0$.</p>\n\n<p><strong>Proof</strong>: Suppose $\\frac{0}{0} \\in \\mathbb{R}$ and that $\\frac{0}{0}=a \\ne 0$.</p>\n\n<p>$a = \\frac{0}{0} = \\frac{2 \\cdot 0}{0} = 2a \\Rightarrow a = 0 \\Rightarrow \\bot$</p>\n\n<p>$\\therefore \\frac{0}{0}=0$</p>\n\n<p>Q.E.D.</p>\n", "pids": ["599c7a85601a182cd26c0e98"], "flag": 0}
{"question": "Mind maps of Advanced Mathematics and various branches thereof", "body": "<p>I would like to get a list of mind maps of advanced mathematics topics. As an example, I have posted one <a href=\"http://space.mit.edu/home/tegmark/toe.gif\">below</a>. I would be happy if you post such other maps. Making one and posting it here is also encouraged.</p>\n\n<p>However, I am specifically not interested in those diagrams that pertain to either high school mathematics or an intricate web of highly specialized theorems. \n<a src=\"https://i.stack.imgur.com/I5rYA.gif\" alt=\"enter image description here\"></p>\n\n<p>Many thanks!</p>\n", "pids": ["53e9bd92b7602d9704a37e80"], "flag": 0}
{"question": "Examples of famous problems resolved easily", "body": "<p>Have there been examples of seemingly long standing hard problems, answered quite easily possibly with tools existing at the time the problems were made? More modern examples would be nice. An example could be Hilbert's basis theorem. Another could be Dwork's p-adic technique for rationality of zeta functions from algebraic varieties.</p>\n", "pids": ["53e9a570b7602d9702e983bf", "53e9ad77b7602d9703768553"], "flag": 0}
{"question": "Open math problems which high school students can understand", "body": "<p>I request people to list some moderately and/or very famous open problems which high school students,perhaps with enough contest math background, can understand, classified by categories as on arxiv.org. Please include statement of the theorems,if possible, and if there are specific terms, please state what they mean.</p>\n\n<p>Thank you.I am quite inquisitive to know about them and I asked this question after seeing how Andrew J.Wiles was fascinated by Fermat's last theorem back in high school.</p>\n", "pids": ["56d890b4dabfae2eeee551b8"], "flag": 0}
{"question": "Are there any interesting semigroups that aren&#39;t monoids?", "body": "<p>Are there any interesting and natural examples of semigroups that are not monoids (that is, they don't have an identity element)?</p>\n\n<p>To be a bit more precise, I guess I should ask if there are any interesting examples of semigroups <span class=\"math-container\">$(X, \\ast)$</span> for which there is not a monoid <span class=\"math-container\">$(X, \\ast, e)$</span> where <span class=\"math-container\">$e$</span> is in <span class=\"math-container\">$X$</span>. I don't consider an example like the set of real numbers greater than <span class=\"math-container\">$10$</span> (considered under addition) to be a sufficiently 'natural' semigroup for my purposes; if the domain can be extended in an obvious way to include an identity element then that's not what I'm after.</p>\n", "pids": ["604b601b6f90b7f6cad6d378"], "flag": 0}
{"question": "Can we use MLE to estimate Neural Network weights?", "body": "<p>I just started to study about stats and models stuff. Currently, my understanding is that we use MLE to estimate the best parameter(s) for a model. However, when I try to understand how the neural networks work, it seems like they commonly use another approach to estimate the parameters instead. Why don't we use MLE or is it possible to use MLE at all?</p>\n", "pids": ["5550412e45ce0a409eb3916f"], "flag": 1}
{"question": "Does the image format (png, jpg, gif) affect how an image recognition neural net is trained?", "body": "<p>I'm aware that there's been lots of advances with regards to image recognition, image classification, etc with deep, convolutional neural nets.</p>\n\n<p>But if I train a net on, say, PNG images, will it <strong>only work for</strong> images so encoded? <strong>What other image properties</strong> affect this? (alpha channel, interlacing, resolution, etc?)</p>\n", "pids": ["57a4e921ac44365e35c9930a"], "flag": 1}
{"question": "Textbooks on higher category theory", "body": "<p>What textbooks on <a href=\"http://ncatlab.org/nlab/show/higher+category+theory\">higher category theory</a> are there? What books do you recommend? I am looking for self-contained introductions, no research reports. There are lots of informal summaries and arXiv papers, but I am really only asking for textbooks here.</p>\n\n<p>I know of Lurie's <em><a href=\"http://www.math.harvard.edu/~lurie/\">Higher Topos Theory</a></em>, which \"only\" treats $(\\infty,1)$-categories. I am looking for books which treat $\\infty$-categories in general. Then I know of Leinster's <em><a href=\"http://www.maths.ed.ac.uk/~tl/hohc/\">Higher Operads, Higher Categories</a></em>, which is from 2004. Is it still up to date? Is Leinster's book the best introduction to the subject? What do you think of <em><a href=\"http://cheng.staff.shef.ac.uk/guidebook/\">Higher-Dimensional Categories: an illustrated guide book</a></em> by Cheng and Lauda, which is also from 2004 and still a draft? Is it too informal when one really wants to work with the concepts?</p>\n\n<p>Bonus question: Meanwhile, is there some \"preferred\" definition of an $\\infty$-category among the dozen definitions which have been studied?</p>\n", "pids": ["5c757145f56def979876c2ca", "56d8de86dabfae2eee02ebe7", "56d89901dabfae2eee27435f", "53e9ab4fb7602d97034e0f4b", "56d89e6ddabfae2eee517146"], "flag": 0}
{"question": "What&#39;s the difference between variance scaling initializer and xavier initializer?", "body": "<p>In Tensorflow's implementation of <a href=\"https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_utils.py\" rel=\"noreferrer\">ResNet</a>, I find they use variance scaling initializer, I also find xavier initializer is popular. I don't have too much experience on this, which is better in practice?</p>\n", "pids": ["573696f46e3b12023e5f0d4d"], "flag": 1}
{"question": "Real world applications of category theory", "body": "<p>I was reading some basic information from Wiki about category theory and honestly speaking I have a very weak knowledge about it. As it sounds interesting, I will go into the theory to learn more if it is actually useful in practice.</p>\n\n<p>My question is to know if category theory has some applications in practice, namely in engineering problems.</p>\n\n<p>I have already read this <a href=\"https://math.stackexchange.com/questions/280166/applications-of-category-theory-and-topoi-topos-theory-in-reality\">Applications of category theory and topoi/topos theory in reality</a> </p>\n\n<p>and the answers are only about programming which are not very interesting from my point of view.</p>\n\n<p>Any comments are welcomed, thanks in advance.</p>\n", "pids": ["53e9ab13b7602d97034994f5", "53e9affab7602d9703a505ba", "5ac1829d17c44a1fda917e2e"], "flag": 0}
{"question": "Famous papers in algebraic geometry", "body": "<p>I'm reading the Mathoverflow thread \"<a href=\"https://mathoverflow.net/questions/28268/do-you-read-the-masters\">Do you read the masters?</a>\", and it seems the answer is a partial \"yes\".</p>\n\n<p>Some \"masters\" are mentioned, for example Riemann and Zariski. In particular, a paper by Zariski is mentioned, but not its title nor where it was published, so I have been unable to locate it (on \"simple points\").</p>\n\n<p><strong>What are some famous papers by the masters that should</strong> (and could) <strong>be read by a student learning algebraic geometry?</strong> I'm currently at the level of the first three chapters of Hartshorne (that is, I know something about varieties, schemes and sheaf cohomology).</p>\n\n<p><strong>Edit</strong>: I should probably add that I'd like specific titles. The advice \"anything by Serre\" is unfortunaly not very helpful, considering Serre's productivity.</p>\n", "pids": ["53e9a7ebb7602d970312dd33"], "flag": 0}
{"question": "What does the term &quot;undefined&quot; actually mean?", "body": "<p>I have read many articles on many sites and in many books to understand what <strong>undefined</strong> means? On some sites of Maths, I read that it could be any number. and on some sites, I read that it may be some undefined thing; and there are more definitions. But they all have clashes with each other that all are defining the term &quot;undefined&quot; in different ways. So which concept is right for the word &quot;undefined&quot; in criteria of Maths among the following five?</p>\n<blockquote>\n<p>1-<em>A number divided by zero may be any number (real or imaginary)</em></p>\n<p>2-<em>A number divided by zero may be an entity which is not defined yet.</em></p>\n<p>3-<em>Division of a number by zero does not make sense.</em></p>\n<p>4-<em>If <span class=\"math-container\">$x=a/0$</span>, then no solution exists!</em></p>\n<p>5-<em>It may give a third type of number other than real or imaginary</em> [I have not read this definition in any book or site but it's my thought.]</p>\n</blockquote>\n<p>This query popped up into my mind while my teacher was solving a question from my book, I am showing it to you along with my teacher's work.</p>\n<p>Q- Prove that the roots of the following equation are real.</p>\n<p><span class=\"math-container\">$x^2-2x(m+\\frac{1}{m})+3=0$</span> where, <span class=\"math-container\">$m$</span> is any real number.</p>\n<p>Teacher's attempt:</p>\n<blockquote>\n<p>For roots to be real,</p>\n<p><span class=\"math-container\">$b^2-4ac&gt;0$</span></p>\n<p><span class=\"math-container\">$\\implies 4(m^2+\\frac{1}{m^2}-1)&gt;0$</span></p>\n<p><span class=\"math-container\">$\\implies 4(m^2+\\frac{1}{m^2}-2+1)&gt;0$</span></p>\n<p><span class=\"math-container\">$\\implies 4[ (m-\\frac{1}{m})^2+1 ]&gt;0$</span>.</p>\n</blockquote>\n<p>My teacher let us write that inequality is satisfied for all <span class=\"math-container\">$m$</span> belongs to real number however if <span class=\"math-container\">$m=0$</span>, <span class=\"math-container\">$\\frac{1}{m}$</span> is undefined. So if &quot;undefined&quot; means that <strong>&quot;a number divided by zero may be any real or imaginary number&quot;</strong> so then I can confess only for real numbers that inequality is satisfied for all <span class=\"math-container\">$m$</span> belonging to real numbers and not for imaginary numbers since we can't make sense of a statement like this <span class=\"math-container\">$i&gt;0$</span> but if the term &quot;undefined&quot;, in Maths, is defined as &quot;Senseless&quot; or &quot;something else not known&quot; then I strongly apprehend that why my teacher let us write that Inequality is satisfied for all <span class=\"math-container\">$m$</span> belonging to real numbers?</p>\n", "pids": ["53e9a62eb7602d9702f5d996"], "flag": 0}
{"question": "Book recommendation on plane Euclidean geometry", "body": "<p>I consider myself relatively good at math, though I don't know it at a high level (yet). One of my problems is that I'm not very comfortable with geometry, unlike algebra, or to restate, I'm much more comfortable with algebra than geometry. I think that's mainly because my geometry education was sparse through the years, lacking in consistency etc. So I'd like to revise (and learn more) all at once, catching the basic axioms, understanding why such is such, etc. Essentially, a moderately rigorous textbook in plain Euclidean geometry (nothing fancy). Please don't say \"The Elements\" - I have browsed it at the bookstore, it is quite good, but not really what I'm looking for right now.</p>\n", "pids": ["56d85572dabfae2eee247658"], "flag": 0}
{"question": "Can&#39;t deep learning models now be said to be interpretable? Are nodes features?", "body": "<p>For statistical and machine learning models, there are multiple levels of interpretability: 1) the algorithm as a whole, 2) parts of the algorithm in general 3) parts of the algorithm on particular inputs, and these three levels split into two parts each, one for training and one for function eval. The last two parts are much closer than to the first. I'm asking about #2, which usually leads to better understanding of #3). (if those are not what 'interpretability' means then what should I be thinking?)</p>\n\n<p>As far as interpretability goes, logistic regression is one of the easiest to interpret. Why did this instance pass the threshold? Because that instance had this particular positive feature and it has a larger coefficient in the model. It's so obvious!</p>\n\n<p>A neural network is  the classic example of a model that is difficult to interpret. What do all those coefficients <em>mean</em>? They all add up in such complicated crazy ways that it is hard to say what any particular coefficient is really doing.</p>\n\n<p>But with all the deep neural nets coming out, it feels like things are becoming clearer. The DL models (for say vision) seem to capture things like edges or orientation in early layers, and in later layers it seems like some nodes are actually semantic (like the proverbial <a href=\"https://en.wikipedia.org/wiki/Grandmother_cell\" rel=\"noreferrer\">'grandmother cell'</a>). For example:</p>\n\n<p><a href=\"https://i.stack.imgur.com/oVU9c.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/oVU9c.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>(<a href=\"http://sdat.ir/en/sdat-blog/item/1-deep-learning\" rel=\"noreferrer\">from 'Learning About Deep Learning'</a>)</p>\n\n<p>This is a graphic (<a href=\"https://www.google.com/search?q=image+deep+learning+cat&amp;tbm=isch\" rel=\"noreferrer\">of many out there</a>) created by hand for presentation so I am very skeptical. But it is evidence that <em>somebody</em> thinks that is how it works.</p>\n\n<p>Maybe in the past there just weren't enough layers for us to find recognizable features; the models were successful, just not easy to post-hoc analyze particular ones.</p>\n\n<p>But maybe the graphic is just wishful thinking. Maybe NNs are truly inscrutable.</p>\n\n<p>But the many graphics with their nodes labeled with pictures are also really compelling.  </p>\n\n<p><strong>Do DL nodes really correspond to features?</strong></p>\n", "pids": ["5550417845ce0a409eb3b9b3", "5c8d2b304895d9cbc641dcc2", "53e9a93eb7602d97032928b5", "5550415645ce0a409eb3a69e", "5c86de294895d9cbc6a752c1", "58d82fced649053542fd6ec1", "573696026e3b12023e515eec"], "flag": 1}
{"question": "What does &#39;linear&#39; mean in Linear Algebra?", "body": "<p>Why Linear Algebra named in that way?\nEspecially, why we call it <code>linear</code>? What does it mean?</p>\n", "pids": ["53e9b74bb7602d97042ea564"], "flag": 0}
{"question": "Methods to see if a polynomial is irreducible", "body": "<p>Given a polynomial over a field, what are the methods to see it is irreducible? Only two comes to my mind now. First is Eisenstein criterion. Another is that if a polynomial is irreducible mod p then it is irreducible. Are there any others?</p>\n", "pids": ["5feb40efd4150a363c638b4e", "5fc77914a84b2957c5ba3a45"], "flag": 0}
{"question": "What are examples of unexpected algebraic numbers of high degree occured in some math problems?", "body": "<p>Recently I asked <a href=\"https://math.stackexchange.com/questions/386207/what-is-the-role-of-mathematical-intuition-and-common-sense-in-questions-of-irra\">a question</a> about a possible transcendence of the number $\\Gamma\\left(\\frac{1}{5}\\right)\\Gamma\\left(\\frac{4}{15}\\right)/\\left(\\Gamma\\left(\\frac{1}{3}\\right)\\Gamma\\left(\\frac{2}{15}\\right)\\right)$, which, to my big surprise, turned out to be an algebraic number, but not some decent algebraic number like $\\left(\\sqrt{5}-1\\right)/2$, but an enormous one with the minimal polynomial of degree 120 and a coefficient exceeding $10^{15}$.</p>\n\n<p>So, my question: are there other interesting examples of numbers occurred in some math problems that were expected likely to be transcendental, but later unexpectedly were proven to be algebraic with a huge minimal polynomial.</p>\n", "pids": ["5550417645ce0a409eb3b823"], "flag": 0}
{"question": "Differences between heavy tail and fat tail distributions", "body": "<p>I thought heavy tail = fat tail, but some articles I read gave me a sense that they aren't.</p>\n\n<p>One of them says: heavy tail means the distribution have infinite jth moment for some integer j. Additionally all the dfs in the pot-domain of attraction of a Pareto df are heavy-tailed. \nIf the density has a high central peak and long tails, then the kurtosis is typically large. A df with kurtosis larger than 3 is fat-tailed or leptokurtic.\nI still don't have a concrete distinction between these two (heavy tail vs. fat tail). Any thoughts or pointers to relevant articles would be appreciated.</p>\n", "pids": ["5de632503a55ac4f55c254f9", "55a58230612c6b12ab1f420f"], "flag": 1}
{"question": "How do people come up with difficult math Olympiad questions?", "body": "<p>The problems that appear in difficult math competitions such as the IMO or the Putnam exam are usually very difficult and require some ingenuity to solve. They also usually don't look like they can be solved by simply knowing more advanced theory and the such.</p>\n\n<p>How do people typically come up with these problems? Do they arise naturally from advanced mathematics (the somewhat infamous 'grasshopper problem' from the 2009 IMO comes to mind - to my not exactly knowledgeable mind this problem looks like it popped out of basically nowhere)? What is the perspective that mathematicians take when seemingly \"inventing\" these problems with no theoretical motivation to them whatsoever?</p>\n", "pids": ["53e9a82cb7602d970317653a", "53e9a10db7602d97029f96b2"], "flag": 0}
{"question": "Generalizing Ramanujan&#39;s proof of Bertrand&#39;s Postulate: Can Ramanujan&#39;s approach be used to show a prime between $4x$ and $5x$ for $x \\ge 3$", "body": "<p>Perhaps, I've been thinking too long about <a href=\"https://web.archive.org/web/20200224014929/http://www.zyymat.com:80/ramanujans-proof-of-bertrands-postulate.html\" rel=\"nofollow noreferrer\">Ramanujan's proof</a>, but it appears to me that his argument can be generalized beyond <span class=\"math-container\">$x$</span> and <span class=\"math-container\">$2x$</span>.  My argument below attempts to show that for <span class=\"math-container\">$x \\ge 1331$</span>, there is always a prime between <span class=\"math-container\">$4x$</span> and <span class=\"math-container\">$5x$</span>.</p>\n<p>I can use a similar argument to establish there is a prime between <span class=\"math-container\">$2x$</span> and <span class=\"math-container\">$3x$</span> and between <span class=\"math-container\">$3x$</span> and <span class=\"math-container\">$4x$</span>.  Based on some rough estimates, it looks it should also work to prove a prime between <span class=\"math-container\">$5x$</span> and <span class=\"math-container\">$6x$</span> as well as a prime between <span class=\"math-container\">$6x$</span> and <span class=\"math-container\">$7x$</span>.</p>\n<p>Since I am still getting up to speed on analytic number theory, I will be very glad if someone can point out the mistake that I am making in my reasoning.  I am not yet able to find it.</p>\n<p>Let <span class=\"math-container\">$$\\vartheta(x) = \\sum_{p \\le x}\\ln(p)$$</span></p>\n<p>Let <span class=\"math-container\">$$\\psi(x) = \\sum_{n=1}^{\\infty}\\vartheta(x^{\\frac{1}{n}})$$</span></p>\n<p>Following Ramanujan [see (6)]:</p>\n<p><span class=\"math-container\">$$\\psi(x) - 2\\psi(\\sqrt{x}) \\le \\vartheta(x) \\le \\psi(x)$$</span></p>\n<p>Analogous to Ramanujan's statement about:</p>\n<p><span class=\"math-container\">$$\\ln(\\lfloor{x}\\rfloor]!) - \\ln(\\lfloor\\frac{x}{2}\\rfloor!) - \\ln(\\lfloor\\frac{x}{2}\\rfloor!) = \\psi(x) - \\psi(\\frac{x}{2}) + \\psi(\\frac{x}{3}) - \\psi(\\frac{x}{4}) + \\ldots$$</span></p>\n<p>Here's my restatement in terms of <span class=\"math-container\">$4x$</span> and <span class=\"math-container\">$5x$</span>:</p>\n<p><span class=\"math-container\">$$\\ln(\\lfloor\\frac{x}{4}\\rfloor!) - \\ln(\\lfloor\\frac{x}{5}\\rfloor!) - \\ln(\\lfloor\\frac{x}{20}\\rfloor!) = \\psi(\\frac{x}{4}) - \\psi(\\frac{x}{5}) + \\psi(\\frac{x}{8}) - \\psi(\\frac{x}{10}) + \\ldots$$</span></p>\n<p>where for each successive term we can see:</p>\n<p><span class=\"math-container\">$$\\psi(\\frac{x}{4}) \\ge \\psi(\\frac{x}{5}) \\ge \\psi(\\frac{x}{8}) \\ge \\psi(\\frac{x}{10}) \\ge  \\ldots$$</span></p>\n<p>Since, for any integer <span class=\"math-container\">$v \\ge 1$</span>, we have:</p>\n<p><span class=\"math-container\">$$\\psi(\\frac{x}{20v+4}) - \\psi(\\frac{x}{20v+5}) + \\psi(\\frac{x}{20v+8})-\\psi(\\frac{x}{20v+10})+\\psi(\\frac{x}{20v+12}) -\\psi(\\frac{x}{20v+15}) + \\psi(\\frac{x}{20v+16}) - \\psi(\\frac{x}{20v+20}) + \\ldots$$</span></p>\n<p>That is, a decreasing sequence of real numbers tending to 0, where each successive term has an alternating sign.</p>\n<p>So, based on reasoning found <a href=\"https://math.stackexchange.com/a/354350/48606\">here</a>, it follows:</p>\n<p><span class=\"math-container\">$$\\psi(\\frac{x}{4}) - \\psi(\\frac{x}{5}) + \\psi(\\frac{x}{8}) - \\psi(\\frac{x}{10}) + \\psi(\\frac{x}{12}) \\ge \\ln(\\lfloor\\frac{x}{4}\\rfloor!) - \\ln(\\lfloor\\frac{x}{5}\\rfloor!) -\\ln(\\lfloor\\frac{x}{20}\\rfloor!)$$</span></p>\n<p>From <span class=\"math-container\">$\\psi(x) - 2\\psi(\\sqrt{x}) \\le \\vartheta(x) \\le \\psi(x)$</span>, it follows that:</p>\n<p><span class=\"math-container\">$$\\psi(\\frac{x}{4}) - \\psi(\\frac{x}{5}) + \\psi(\\frac{x}{8}) - \\psi(\\frac{x}{10}) + \\psi(\\frac{x}{12}) \\le \\vartheta(\\frac{x}{4}) - \\vartheta(\\frac{x}{5}) + 2\\psi(\\sqrt{\\frac{x}{4}}) + \\psi(\\frac{x}{8}) - \\psi(\\frac{x}{10}) + \\psi(\\frac{x}{12})$$</span></p>\n<p>Using the same reasoning as above, it can be noted that:</p>\n<p><span class=\"math-container\">$$\\psi(\\frac{x}{10}) - \\psi(\\frac{x}{12}) \\le \\ln(\\lfloor\\frac{x}{10}\\rfloor!) - \\ln(\\lfloor\\frac{x}{12}\\rfloor!) - \\ln(\\lfloor\\frac{x}{60}\\rfloor!)$$</span></p>\n<p>So that we have:</p>\n<p><span class=\"math-container\">$$\\psi(\\frac{x}{4}) - \\psi(\\frac{x}{5}) + \\psi(\\frac{x}{8}) - \\psi(\\frac{x}{10}) + \\psi(\\frac{x}{12}) \\le \\vartheta(\\frac{x}{4}) - \\vartheta(\\frac{x}{5}) + 2\\psi(\\sqrt{\\frac{x}{4}}) + \\psi(\\frac{x}{8}) - [ \\ln(\\lfloor\\frac{x}{10}\\rfloor!) - \\ln(\\lfloor\\frac{x}{12}\\rfloor!) - \\ln(\\lfloor\\frac{x}{60}\\rfloor!) ]$$</span></p>\n<p>which implies:</p>\n<p><span class=\"math-container\">$$\\vartheta(\\frac{x}{4}) - \\vartheta(\\frac{x}{5}) \\ge \\ln(\\lfloor\\frac{x}{4}\\rfloor!) - \\ln(\\lfloor\\frac{x}{5}\\rfloor!) -\\ln(\\lfloor\\frac{x}{20}\\rfloor!) - 2\\psi(\\sqrt{\\frac{x}{4}}) - \\psi(\\frac{x}{8}) + \\ln(\\lfloor\\frac{x}{10}\\rfloor!) - \\ln(\\lfloor\\frac{x}{12}\\rfloor!) - \\ln(\\lfloor\\frac{x}{60}\\rfloor!)$$</span></p>\n<p>From <a href=\"https://projecteuclid.org/journals/illinois-journal-of-mathematics/volume-6/issue-1/Approximate-formulas-for-some-functions-of-prime-numbers/10.1215/ijm/1255631807.full\" rel=\"nofollow noreferrer\">Rosser and Schoenfeld (1961)</a>, we know that (see Theorem 12):</p>\n<p><span class=\"math-container\">$$\\psi(x) &lt; 1.03883x$$</span></p>\n<p>So that:</p>\n<p><span class=\"math-container\">$$\\vartheta(\\frac{x}{4}) - \\vartheta(\\frac{x}{5}) \\ge \\ln(\\lfloor\\frac{x}{4}\\rfloor!) - \\ln(\\lfloor\\frac{x}{5}\\rfloor!) -\\ln(\\lfloor\\frac{x}{20}\\rfloor!) - 2(1.03883)(\\sqrt{\\frac{x}{4}}) - (1.03883)(\\frac{x}{8}) + \\ln(\\lfloor\\frac{x}{10}\\rfloor!) - \\ln(\\lfloor\\frac{x}{12}\\rfloor!) - \\ln(\\lfloor\\frac{x}{60}\\rfloor!)$$</span></p>\n<p>Based on <a href=\"https://en.wikipedia.org/wiki/Stirling_approximation\" rel=\"nofollow noreferrer\">Stirling's Approximation</a> and my reasoning found <a href=\"https://math.stackexchange.com/questions/355598/analyzing-the-lower-bound-of-a-logarithm-of-factorials-using-stirlings-approxim\">here</a>, it follows that <span class=\"math-container\">$\\vartheta(\\frac{x}{4}) - \\vartheta(\\frac{x}{5}) &gt; 0$</span> for <span class=\"math-container\">$x \\ge 1331$</span></p>\n<p>I have also verified that for <span class=\"math-container\">$1331 &gt; x &gt; 2$</span>, there is always a prime between <span class=\"math-container\">$5x$</span> and <span class=\"math-container\">$4x$</span> so if my argument is valid, this would be enough to establish that there is always a prime between <span class=\"math-container\">$5x$</span> and <span class=\"math-container\">$4x$</span> for <span class=\"math-container\">$x \\ge 3$</span>.</p>\n<p>Is this approach valid?</p>\n<hr />\n<p><strong>Update:</strong> I have found my mistake.  The following step is invalid:</p>\n<p><span class=\"math-container\">$$\\psi(\\frac{x}{4}) - \\psi(\\frac{x}{5}) + \\psi(\\frac{x}{8}) - \\psi(\\frac{x}{10}) + \\psi(\\frac{x}{12}) \\le \\vartheta(\\frac{x}{4}) - \\vartheta(\\frac{x}{5}) + 2\\psi(\\sqrt{\\frac{x}{4}}) + \\psi(\\frac{x}{8}) - [ \\ln(\\lfloor\\frac{x}{10}\\rfloor!) - \\ln(\\lfloor\\frac{x}{12}\\rfloor!) - \\ln(\\lfloor\\frac{x}{60}\\rfloor!) ]$$</span></p>\n<p><strong>Edit:</strong> I have added a clarification below on what type of answer I am looking for to this question.</p>\n<p><strong>Clarification:</strong> I am especially interested in one of these answers to this question:</p>\n<ul>\n<li>Is this approach already &quot;well-understood&quot; (in which case, I would be interested in a reference)</li>\n<li>Does this approach have &quot;a major gap&quot; (if so, which part of the argument is wrong or needs additional detail)</li>\n<li>Could it be interesting &quot;if it shows...&quot; (what result is needed for this approach to be interesting to mathematician).</li>\n<li>How could it be &quot;improved and made more clear...&quot; (what theorems or analytic techniques would strengthen or clarify the argument)</li>\n<li>If the argument looks good, what would be the recommended next step from here?</li>\n</ul>\n", "pids": ["53e9bb53b7602d97047950f0"], "flag": 0}
{"question": "What important ideas came since Nelder and McCullagh&#39;s book Generalized Linear Models (a 40 year old book)?", "body": "<p>I read not too long ago Nelder and McCullagh's book <em>Generalized Linear Models</em> and thought the book was fantastic and I consider it a useful manual on the subject. Not surprising that's the case, considering Nelder's one of the authors.</p>\n<p>However, the book <em>is</em> 40 years old, and surely things have changed since when the book came out. Simon Wood's book, <em>Generalized Additive Models</em>, is very good, but the book focuses on GAMs, not GLMs. (Yes, GAMs generalize GLMs, but I do think focusing on GLMs specifically is worthwhile.)</p>\n<p>Hence, what would be the most important developments since Nelder and McCullagh's book came out regarding GLM theory and application? What am I missing from just reading that book? How should I supplement my knowledge?</p>\n", "pids": ["55a4d82dc91bf3b1cc4813f4"], "flag": 1}
{"question": "Is there a chain rule for integration?", "body": "<p>I know the chain rule for derivatives. The way as I apply it, is to get rid of specific 'bits' of a complex equation in stages, i.e I will derive the $5$th root first in the equation $(2x+3)^5$ and continue with the rest.</p>\n\n<p>I wonder if there is something similar with integration. I tried to integrate that way $(2x+3)^5$ but it doesn't seem to work. Well, it works in the first stage, i.e it's fine to raise in the power of $6$ and divide with $6$ to get rid of the power $5$, but afterwards, if we would apply the chain rule, we should multiply by the integral of $2x+3$!, But it doesn't work like that, we just need to multiply by $1/2$ and that's it.</p>\n\n<p>So my question is, is there chain rule for integrals? I want to be able to calculate integrals of complex equations as easy as I do with chain rule for derivatives.</p>\n", "pids": ["5c7573cef56def97988d9779"], "flag": 0}
{"question": "String Theory: What to do?", "body": "<p>This is going to be a relatively broad/open-ended question, so I apologize before hand if it is the wrong place to ask this.</p>\n\n<p>Anyways, I'm currently a 3rd year undergraduate starting to more seriously research possible grad schools.  I find myself in somewhat of a weird spot as my primary interests lie in physics, but I usually can't stand the imprecision with which most physicists do physics.  I eventually would like to do work relevant to the quest of finding a theory of everything, but because I do not like the lack of rigor in physics, I have decided not to go to graduate school in physics.  However, when looking at the research interests of faculty members, I've found that most institutions have zero, one, or occasionally two (mathematics) faculty members working in this area.  Am I just not looking in the right places?  Where I am to go if I am looking to get into a field like String Theory from a mathematician's perspective?</p>\n\n<p>As a separate but related question, I've found the prerequites for string theory to be quite daunting.  At this point, I feel as if it will be at least another year or two before I can even start learning the fundamentals of the theory (I won't even be taking a course in QFT until next year).  To be honest, I am starting to feel a little scared that I won't have enough time to do my thesis work in a field related to string theory.  Compared to algebraic topology or something, which I took last year, this year and next I could be learning more advanced aspects of the field so that by the time I got to grad school I could immediately jump in and start tackling a problem, whereas with string theory I feel as if I won't be able to really do this until my third year of grad school or so.  Is this something I should actually be worried about, or am I worrying about nothing?</p>\n\n<p>Also, if any of you have studied string theory, I would be interested in knowing what subjects I should study to prepare myself and textboks that you recommend for studying from.  I would prefer textbooks about physics written by a mathematician or at least a great deal of mathematical rigor, although I am willling to compromise.</p>\n\n<p>Thanks before hand for all the help/suggestions.  I am interested to hear mathematicians' take on this.</p>\n\n<p>EDIT:  A comment made me think that I should point out that I am ultimately interested in a theory of everything, not string theory per se.  At this point, because I have so much to learn, I think that if I head in the direction of string theory (learn things like QFT, GR, Conformal Field Theory, Supersymmetry, etc.) I can't go wrong.  It won't be for awhile until I have to really make a choice between candidates for a TOE.</p>\n", "pids": ["53e9ab00b7602d97034835fd", "53e9a2b3b7602d9702bbc984", "56d83cc7dabfae2eee69f64b", "61ca3d3a5244ab9dcb194d0c"], "flag": 0}
{"question": "Why use Monte Carlo method instead of a simple grid?", "body": "<p>when integrating a function or in complex simulations, I have seen the Monte Carlo method is widely used. I'm asking myself why one doesn't generate a grid of points to integrate a function instead of drawing random points. Wouldn't that bring more exact results?</p>\n", "pids": ["5f8e9a109e795e9e76f6f572"], "flag": 1}
{"question": "Sum of all elements in a matrix", "body": "<p>The <a href=\"http://en.wikipedia.org/wiki/Trace_%28linear_algebra%29\">trace</a> is the sum of the elements on the diagonal of a matrix. Is there a similar operation for the sum of <em>all</em> the elements in a matrix?</p>\n", "pids": ["53e9b923b7602d970450c644"], "flag": 0}
{"question": "Proof (claimed) for Riemann hypothesis on ArXiv", "body": "<p>Has anyone noticed the paper <a href=\"https://arxiv.org/abs/1608.01555\">On the zeros of the zeta function and eigenvalue problems</a> by M. R. Pistorius, available on ArXiv?</p>\n\n<p>The author claims a proof of RH, and also a growth condition on the zeros.\nIt was posted two weeks ago, and I expected it would have been shot down by now. Has there been any discussion or attempt at verification of this preprint?</p>\n", "pids": ["5c7567aef56def979819fc4a"], "flag": 0}
{"question": "Why are some coins Reuleaux triangles?", "body": "<p>Peter Taylor pointed out at <a href=\"https://matheducators.stackexchange.com/a/14228/511\">MathEduc</a> that some <a href=\"https://en.wikipedia.org/wiki/Bermudian_dollar\" rel=\"noreferrer\">BD</a>$1 coins from 1997 are <a href=\"https://en.wikipedia.org/wiki/Reuleaux_triangle\" rel=\"noreferrer\">Reuleaux triangles</a>:\n<hr />\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \n<a href=\"https://i.stack.imgur.com/9u3cs.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/9u3cs.jpg\" alt=\"Coin\"></a>\n<br />\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; \n<sup>\n(Image from <a href=\"https://de.ucoin.net/coin/bermuda-1-dollar-1997/?tid=50025\" rel=\"noreferrer\">de.ucoin.net</a>.)\n</sup>\n<hr />\nDoes anyone know why they were shaped this way? Was there some\npragmatic reason connected to its constant-width property? Or was it just a design/aesthetic decision?</p>\n", "pids": ["53e99e45b7602d97027068cc"], "flag": 0}
{"question": "Is complex analysis more &quot;real&quot; than real analysis?", "body": "<p>In physics, in the past, complex numbers were used only to remember or simplify formulas and computations. But after the birth of quantum physics, they found that a thing as real as &quot;matter&quot; itself had to be described by complex wave functions and there's no way to describe it using only real numbers.</p>\n<p>In mathematics, in real analysis, there's examples like the function <span class=\"math-container\">$f(x)=\\frac{1}{1+x^2}$</span>, and why this function does not have the &quot;smoothness&quot; of the exponential function, polynomials, or the sine and cosine functions, why it has a radius of convergence equals 1 despite the fact that this function is infinitely differentiable. You can't see the reality of this function until you see it through the field of complex analysis, where you can observe that <span class=\"math-container\">$f$</span> is not that smooth because it has 2 singularities in the complex plane.</p>\n<p>I am just asking for examples like this such that when you see it in the narrow &quot;window&quot; of real analysis, you can't see the &quot;reality&quot; until you view it from the window of complex analysis. I am just starting to self learn complex analysis and I find it more natural than real analysis and it tells you the &quot;truth&quot; behind a lot of things.</p>\n", "pids": ["56d832d3dabfae2eee2d8624"], "flag": 0}
{"question": "Do about 100 Germans die every year due to risky masturbation?", "body": "<p>EveningStandard claims in <a href=\"https://www.standard.co.uk/news/world/at-least-100-germans-a-year-die-while-masturbating-a3761716.html\" rel=\"noreferrer\" title=\"Masturbation &#39;kills up to 100 Germans a year&#39;, new study shows\"><em>Masturbation 'kills up to 100 Germans a year', new study shows</em></a> that up to 100 Germans a year die to masturbation for using risky methods like auto-erotic asphyxiation or electric shock.</p>\n\n<p>Similar claims can be found in these sources, among others:</p>\n\n<ul>\n<li><p>Dailymail: <a href=\"http://www.dailymail.co.uk/news/article-5367569/Masturbation-kills-100-Germans-year-study-finds.html\" rel=\"noreferrer\"><em>Masturbation kills 100 Germans every year: Study discovers bizarre ways people died pleasuring themselves including a man who tried to melt sliced cheese over himself</em></a></p></li>\n<li><p>The Sun: <a href=\"https://www.thesun.co.uk/news/5531736/german-100-dead-masturbation/\" rel=\"noreferrer\"><em>Up to 100 Germans are killed every year… by extreme MASTURBATING</em></a></p></li>\n</ul>\n\n<p>Are up to 100 Germans per year killed by using risky techniques for masturbating?</p>\n", "pids": ["5c757079f56def97986f5466"], "flag": 1}
{"question": "How large a training set is needed?", "body": "<p>Is there a common method used to determine how many training samples are required to train a classifier (an LDA in this case) to obtain a minimum threshold generalization accuracy?</p>\n\n<p>I am asking because I would like to minimize the calibration time usually required in a brain-computer interface.</p>\n", "pids": ["55a50d7165ceb7cb02df7ff6", "55a50d7165ceb7cb02df7ff6"], "flag": 1}
{"question": "Call a number &quot;holy&quot; if it contains no $666$ in its decimal expansion. Are there infinitely many holy powers of $2$?", "body": "<p>We call a number \"holy\" if it contains no <span class=\"math-container\">$666$</span> in its decimal expansion, and \"unholy\" otherwise. For instance, <span class=\"math-container\">$12366621$</span> and <span class=\"math-container\">$666609$</span> are unholy, while <span class=\"math-container\">$7777$</span> and <span class=\"math-container\">$66166266366$</span> are holy.</p>\n\n<blockquote>\n  <p><strong>Question</strong>: Is the set <span class=\"math-container\">$$\\{2^n \\ | \\ n \\in \\mathbb N, 2^n \\text{ is holy}\\}$$</span> infinite?</p>\n</blockquote>\n\n<p>Of course, tons of similar questions can be asked by changing the number <span class=\"math-container\">$666$</span>, the base <span class=\"math-container\">$2$</span>, and the base for extension (we asked for decimal, so the default was <span class=\"math-container\">$10$</span>). I do not feel that I am the first one asking this, and I appreciate it if someone gives me references if applicable.</p>\n\n<p>But my thought is the following:</p>\n\n<blockquote>\n  <p><strong>Conjecture</strong>: No.</p>\n</blockquote>\n\n<p>I will share my reasoning at the end of the post, but let us first see some facts:</p>\n\n<p><strong>Smallest unholy instances</strong>:\n<span class=\"math-container\">$$\n\\begin{aligned}\n2^{157} &amp;= 182687704\\color{magenta}{666}362864775460604089535377456991567872\\\\\n2^{192} &amp;= 6277101735386680763835789423207\\color{magenta}{666}416102355444464034512896\n\\end{aligned}\n$$</span></p>\n\n<p>Then, we witnessed a cluster of unholy powers: <span class=\"math-container\">$2^{218}, 2^{220}, 2^{222}, 2^{224}, 2^{226}$</span>, and then kept holy for a while, until we hit the unholy <span class=\"math-container\">$2^{243}$</span>.</p>\n\n<p><strong>Largest holy instances</strong>: I did not throw in a lot of CPU time to pursue holy numbers, nor did I try hard enough to optimize my programs, but among the <span class=\"math-container\">$3715$</span> holy powers of <span class=\"math-container\">$2$</span>, the largest of them are\n<span class=\"math-container\">$$2^{25357}, 2^{25896}, 2^{26051}, 2^{26667}, 2^{29784}.$$</span></p>\n\n<p>I tested up to around <span class=\"math-container\">$2^{110000}$</span>, but that is all I got. It probably will be reasonable for an average computer to test up to say <span class=\"math-container\">$2^{10^6}$</span> or <span class=\"math-container\">$2^{10^7}$</span>, but I will be surprised to see a new holy number.</p>\n\n<p><strong>Statistics</strong>: For an integer <span class=\"math-container\">$n$</span>, let <span class=\"math-container\">$H(n)$</span> be the number of holy powers of <span class=\"math-container\">$2$</span> up to <span class=\"math-container\">$2^n$</span>.</p>\n\n<pre><code>n      | H(n)     || n      | H(n)     || n      | H(n)\n 1000  |  875     || 11000  | 3567     || 21000  | 3700\n 2000  | 1560     || 12000  | 3602     || 22000  | 3703\n 3000  | 2059     || 13000  | 3621     || 23000  | 3705\n 4000  | 2442     || 14000  | 3645     || 24000  | 3707\n 5000  | 2747     || 15000  | 3655     || 25000  | 3709\n 6000  | 2984     || 16000  | 3670     || 26000  | 3712\n 7000  | 3171     || 17000  | 3682     || 27000  | 3714\n 8000  | 3332     || 18000  | 3689     || 28000  | 3714\n 9000  | 3440     || 19000  | 3693     || 29000  | 3714\n10000  | 3514     || 20000  | 3695     || 30000  | 3715\n</code></pre>\n\n<p>A plot of this:\n<a href=\"https://i.stack.imgur.com/RW00O.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/RW00O.png\" alt=\"enter image description here\"></a></p>\n\n<p><strong>The heuristics of the conjecture</strong>:</p>\n\n<p>This is definitely not close to a proof at all, and I still hope if rigorous arguments exists:</p>\n\n<p>The idea is that we want to estimate, for an integer <span class=\"math-container\">$n$</span>, the probability <span class=\"math-container\">$P(n)$</span> that <span class=\"math-container\">$2^n$</span> is holy, and then compute <span class=\"math-container\">$\\sum_{n=1}^\\infty P(n)$</span>.</p>\n\n<p>We know that <span class=\"math-container\">$2^n$</span> has <span class=\"math-container\">$O(n\\ln 2)$</span> decimal digits, so there are <span class=\"math-container\">$O(n\\ln 2)$</span> groups of three. For each group there is a <span class=\"math-container\">$1-10^{-3}$</span> chance to be not <span class=\"math-container\">$666$</span>, so very roughly\n<span class=\"math-container\">$$\nP(n) = (1-10^{-3})^{n\\ln 2} \\approx e^{-10^{-3}\\ n\\ln 2}.\n$$</span></p>\n\n<p>And note that\n<span class=\"math-container\">$$\n\\sum_{n=1}^\\infty P(n) \\approx \\int_{n=0}^\\infty e^{-10^{-3}\\ x\\ln 2} dx &lt; \\infty.\n$$</span></p>\n\n<p>The red \"estimation line\" in the figure above follows from this integral.</p>\n\n<p>Of course, one can easily argue the properness of the heuristic above:</p>\n\n<ul>\n<li>The distribution of the digits close to the left are not uniform; they are  affected by the growth of logarithmic functions.</li>\n<li>The distribution of the digits close to the right are not uniform; they are affected by the pattern of <span class=\"math-container\">$2^n \\pmod{10^k}$</span>.</li>\n<li><span class=\"math-container\">$P(n)$</span> and <span class=\"math-container\">$P(n+i)$</span> are not independent, partially because of the awful choice of the number <span class=\"math-container\">$666$</span>: <span class=\"math-container\">$6\\cdots 6 \\times 2^2 = 26\\cdots 64$</span>.</li>\n</ul>\n\n<p>Any thoughts are appreciated.</p>\n", "pids": ["5c7569cef56def97982d6dfc"], "flag": 0}
{"question": "How to test if my distribution is multimodal?", "body": "<p>When I plot a histogram of my data, it has two peaks:  </p>\n\n<p><a src=\"https://i.stack.imgur.com/p4C8d.jpg\" alt=\"histogram\"></p>\n\n<p>Does that mean a potential multi-modal distribution? I ran the <code>dip.test</code> in R (<code>library(diptest)</code>), and the output is:  </p>\n\n<pre><code>D = 0.0275, p-value = 0.7913\n</code></pre>\n\n<p>I can conclude that my data have a multi-modal distribution?</p>\n\n<p>DATA</p>\n\n<pre><code>10346 13698 13894 19854 28066 26620 27066 16658  9221 13578 11483 10390 11126 13487 \n15851 16116 24102 30892 25081 14067 10433 15591  8639 10345 10639 15796 14507 21289 \n25444 26149 23612 19671 12447 13535 10667 11255  8442 11546 15958 21058 28088 23827 \n30707 19653 12791 13463 11465 12326 12277 12769 18341 19140 24590 28277 22694 15489 \n11070 11002 11579  9834  9364 15128 15147 18499 25134 32116 24475 21952 10272 15404 \n13079 10633 10761 13714 16073 23335 29822 26800 31489 19780 12238 15318  9646 11786 \n10906 13056 17599 22524 25057 28809 27880 19912 12319 18240 11934 10290 11304 16092 \n15911 24671 31081 27716 25388 22665 10603 14409 10736  9651 12533 17546 16863 23598 \n25867 31774 24216 20448 12548 15129 11687 11581\n</code></pre>\n", "pids": ["5c756afaf56def9798394dad"], "flag": 1}
{"question": "History of uninformative prior theory", "body": "<p>I am writing a short theoretical essay for a Bayesian Statistics course (in an Economics M.Sc.) on uninformative priors and I am trying to understand which are the steps in the development of this theory.</p>\n\n<p>By now, my timeline is made three main steps: Laplace's indifference principle (1812), Non-Invariant priors (Jeffreys (1946)), Bernardo reference prior (1979).</p>\n\n<p>From my literature review, I've understood that indifference principle (Laplace) was the first tool used to represent lack of prior information but the missing requirement of invariance has led to its abandonment until the 40s, when Jeffreys introduced his method, which has the desired property of invariance. The arise of paradoxes of marginalization due to the careless use of improper prior in the 70s pushed Bernardo to elaborate his reference prior theory to deal with this issue. </p>\n\n<p>Reading the literature, every author cites different contributes: Jaynes' maximum entropy, Box and Tiao's data-translated likelihood, Zellner, ... </p>\n\n<p>In your opinion, what are the crucial steps I am missing? </p>\n\n<p><strong>EDIT</strong>: I add my (main) references, if someone needs:</p>\n\n<p>1) <a href=\"http://www.stat.cmu.edu/~kass/papers/rules.pdf\" rel=\"nofollow noreferrer\">The selection of prior by formal rules, Kass, Wasserman</a></p>\n\n<p>2) <a href=\"http://www.stats.org.uk/priors/noninformative/YangBerger1998.pdf\" rel=\"nofollow noreferrer\">A catalogue of non informative priors, Yang, Berger</a></p>\n\n<p>3) <a href=\"http://www.stats.org.uk/priors/noninformative/Syversveen1998.pdf\" rel=\"nofollow noreferrer\">Noninformative Bayesians Priors Interpretation and Problems with Construction and Applications</a></p>\n\n<p><strong>EDIT 2</strong>: Sorry for the 2 year delay but here you can find my essay <a href=\"https://drive.google.com/open?id=0BzhibAJu8x4YeS1uRU5PTU0zU2c\" rel=\"nofollow noreferrer\">here</a></p>\n", "pids": ["53e9b254b7602d9703cf6315"], "flag": 1}
{"question": "Has any previously unknown result been proven by an automated theorem prover?", "body": "<p>The <a href=\"http://en.wikipedia.org/wiki/Automated_theorem_proving\">Wikipedia page on automated theorem proving</a> states:</p>\n\n<blockquote>\n  <p>Despite these theoretical limits, in practice, theorem provers can solve many hard problems...</p>\n</blockquote>\n\n<p>However it is not clear whether these 'hard problems' are new. Do computer-generated proofs contribute anything to 'human-generated' mathematics?</p>\n\n<p>I am aware of the four-color theorem but as mentioned on the Wikipedia page, perhaps it is more an example of proof-verification than automated reasoning. But maybe this is still the best example?</p>\n", "pids": ["5736960e6e3b12023e52175c"], "flag": 0}
{"question": "Infinite product of measurable spaces", "body": "<ol>\n<li><p>Suppose there is a family (can be\ninfinite) of measurable spaces. What\nare the usual ways to define a sigma\nalgebra on their Cartesian product?</p>\n</li>\n<li><p>There is one way in the context of\ndefining product measure on\n<a href=\"https://planetmath.org/InfiniteProductMeasure\" rel=\"nofollow noreferrer\">planetmath</a>. Let <span class=\"math-container\">$(E_i, B_i)$</span> be\nmeasurable spaces, where <span class=\"math-container\">$i \\in I$</span>\nis an index set, possibly infinite.\nWe define their product as follows:</p>\n<ul>\n<li><p>let <span class=\"math-container\">$E= \\prod_{i \\in I} E_i$</span>  , the    Cartesian product of <span class=\"math-container\">$E_i$</span>,</p>\n</li>\n<li><p>let <span class=\"math-container\">$B=\\sigma((B_i)i \\in I)$</span> , the    smallest sigma algebra\ncontaining    subsets of <span class=\"math-container\">$E$</span> of the\nform <span class=\"math-container\">$\\prod_{i    \\in I}B_i$</span>  where\n<span class=\"math-container\">$B_i=E_i$</span> for all    but a finite\nnumber of <span class=\"math-container\">$i \\in I$</span> .</p>\n</li>\n</ul>\n<p>I was wondering why it is required\nthat &quot;<span class=\"math-container\">$B_i=E_i$</span> for all but a finite\nnumber of <span class=\"math-container\">$i \\in I$</span>&quot;?</p>\n</li>\n</ol>\n<p>Thanks and regards!</p>\n<hr />\n<p>ADDED:</p>\n<p>I was wondering if the product sigma algebra defined in 2 is the smallest sigma algebra such that any tuple composed of one measurable set from each individual sigma algebra is measurable?</p>\n", "pids": ["56d8e289dabfae2eee1bd66b"], "flag": 0}
{"question": "Is there an explicit isomorphism between $L^\\infty[0,1]$ and $\\ell^\\infty$?", "body": "<blockquote>\n  <p>Is there an explicit isomorphism between $L^\\infty[0,1]$ and\n  $\\ell^\\infty$?</p>\n</blockquote>\n\n<p>In some sense, this is a follow-up to my answer to <a href=\"https://math.stackexchange.com/q/97126/\">this question</a> where the non-isomorphism between the spaces $L^r$ and $\\ell^s$ for $1 \\leq r,s \\lt \\infty$, unless $r$ and $s$ are both two was discussed (among other things).</p>\n\n<p>There is the somewhat surprising fact that the Banach spaces $X = L^\\infty[0,1]$ and $Y = \\ell^\\infty$ are\nisomorphic. More precisely, there are mutually inverse bounded linear\nmaps $T:  X \\to Y$ and $S: Y \\to X$ (see below for a proof of\nexistence). </p>\n\n<blockquote>\n  <p>Is there a direct and explicit way to prove this? In other words: I'm wondering\n    whether there is an explicit and natural expression for either $S$ or $T$.</p>\n</blockquote>\n\n<p>Here's the argument I know: Using Pe&#322;czy&#324;ski's decomposition technique one can prove that\n$X = L^\\infty$ and $Y = \\ell^\\infty$ are isomorphic as Banach spaces:</p>\n\n<ol>\n<li><p>Choose a countable partition $[0,1] = \\bigcup_{n=0}^\\infty E_n$\ninto disjoint sets of positive measure and send $(x_n)_{n \\in\n\\mathbb{N}} \\in \\ell^\\infty$ to $\\sum_{n=0}^\\infty x_n [E_n]$ to get\nan isometric embedding $i: Y \\hookrightarrow X$. Since $\\ell^\\infty$\nis injective, its image is complemented, in particular, this yields a\ndecomposition $X \\cong Y \\oplus \\widetilde{Y}$.</p></li>\n<li><p>Choose a dense sequence $(f_n)_{n \\in \\mathbb{N}}$ of the unit sphere of $L^1[0,1]$. For\n$h \\in L^\\infty[0,1]$ let $j(h) = \\left( \\int f_n \\, h \\right)_{n \\in\n\\mathbb{N}} \\in \\ell^\\infty$ to get an isometric map $j: L^\\infty[0,1] \\to\n\\ell^\\infty$. Since $L^\\infty[0,1]$ is injective, its image is\ncomplemented in $\\ell^\\infty$, so this yields a\ndecomposition $Y \\cong X \\oplus \\widetilde{X}$.</p></li>\n<li><p>Observe that $X \\cong X \\oplus X$ since $L^\\infty[0,1] =\nL^\\infty[0,1/2] \\oplus L^\\infty[1/2,1] \\cong L^\\infty [0,1] \\oplus\nL^\\infty [0,1]$ and $Y \\cong Y \\oplus Y$ by decomposing $\\mathbb{N}$\ninto the sets of even and odd numbers. Thus, Pe&#322;czy&#324;ski's argument yields:\n$$X \\cong Y \\oplus \\widetilde{Y} \\cong (Y \\oplus Y) \\oplus\n\\widetilde{Y} \\cong Y \\oplus (Y \\oplus \\widetilde{Y}) \\cong Y \\oplus\nX$$\nand \n$$Y \\cong X \\oplus \\widetilde{X} \\cong (X \\oplus X) \\oplus\n\\widetilde{X} \\cong X \\oplus (X \\oplus \\widetilde{X}) \\cong X \\oplus\nY$$\nso that $X \\cong Y \\oplus X \\cong X \\oplus Y \\cong Y$.</p></li>\n</ol>\n\n<p>Of course, one can trace through this argument and &ldquo;construct&rdquo; an  isomorphism, but the resulting maps are rather messier than what I'm looking for. A further deficit of this argument is that the appeal to injectivity properties makes this inherently non-constructive.</p>\n\n<p>Any simplifications of this argument or pointers to the literature would be welcome.</p>\n", "pids": ["53e9b5a8b7602d97040eb9de"], "flag": 0}
{"question": "Evaluating $\\int_0^{\\frac{\\pi}{2}}\\ln\\left(\\frac{\\ln^2\\sin\\theta}{\\pi^2+\\ln^2\\sin\\theta}\\right)\\,\\frac{\\ln\\cos\\theta}{\\tan\\theta}\\,d\\theta$", "body": "<p><strong>Prove</strong></p>\n<p><span class=\"math-container\">$$\\int_0^{\\frac{\\pi}{2}}\\ln\\left(\\frac{\\ln^2\\sin\\theta}{\\pi^2+\\ln^2\\sin\\theta}\\right)\\,\\frac{\\ln\\cos\\theta}{\\tan\\theta}\\,d\\theta = \\frac{\\pi^2}{4}$$</span></p>\n", "pids": ["53e9aa32b7602d97033a0825"], "flag": 0}
{"question": "Conjectural closed-form representations of sums, products or integrals", "body": "<p>What are some examples of infinite sums, products or definite integrals that have conjectural closed form representations that were confirmed by numerical calculations up to whatever maximum precision anybody tried but still remain unproved? </p>\n\n<p>I am also interested in values of special functions at certain points that have conjectural representations in terms of simpler functions (e.g. special values of hypergeometric functions, <a href=\"http://mathworld.wolfram.com/MeijerG-Function.html\" rel=\"noreferrer\">Meijer G-function</a> or <a href=\"http://mathworld.wolfram.com/FoxH-Function.html\" rel=\"noreferrer\">Fox H-function</a> that representable in terms of elementary functions and well-known constants like $\\pi$, $e$, <a href=\"http://mathworld.wolfram.com/CatalansConstant.html\" rel=\"noreferrer\">Catalan</a>, <a href=\"http://mathworld.wolfram.com/Euler-MascheroniConstant.html\" rel=\"noreferrer\">Euler–Mascheroni</a>, <a href=\"http://mathworld.wolfram.com/Glaisher-KinkelinConstant.html\" rel=\"noreferrer\">Glaisher–Kinkelin</a> or <a href=\"http://mathworld.wolfram.com/KhinchinsConstant.html\" rel=\"noreferrer\">Khinchin</a>).</p>\n\n<p>To give some examples:</p>\n\n<ul>\n<li><a href=\"http://www.emis.ams.org/journals/EM/expmath/volumes/12/12.4/Guillera.pdf\" rel=\"noreferrer\">Gourevitch conjecture</a> mentioned at <a href=\"https://mathoverflow.net/questions/100265/not-especially-famous-long-open-problems-which-anyone-can-understand/100290#100290\">MathOverflow</a>:\n$$\\sum_{n=0}^\\infty \\frac{1+14n+76n^2+168n^3}{2^{20n}}\\binom{2n}{n}^7\\stackrel{?}{=}\\frac{32}{\\pi^3}.$$</li>\n<li><a href=\"http://mathworld.wolfram.com/RiemannHypothesis.html\" rel=\"noreferrer\">Riemann hypothesis</a> (in an unusual form, also mentioned at <a href=\"https://mathoverflow.net/questions/39944/collection-of-equivalent-forms-of-riemann-hypothesis/57944#57944\">MathOverflow</a>)\n$$\\int_{0}^{\\infty}\\frac{(1-12t^2)}{(1+4t^2)^3}\\int_{1/2}^{\\infty}\\log|\\zeta(\\sigma+it)|~d\\sigma ~dt\\stackrel{?}{=}\\frac{\\pi(3-\\gamma)}{32}.$$</li>\n<li>Another conjecture from <a href=\"https://mathoverflow.net/questions/100265/not-especially-famous-long-open-problems-which-anyone-can-understand/100330#100330\">MathOverflow</a> attributed to <em>J. M. Borwein, D. H. Bailey, <a href=\"http://books.google.com/books/about/Mathematics_by_Experiment_2nd_Edition.html?id=sdq0JcexDTsC\" rel=\"noreferrer\">Mathematics by Experiment: Plausible Reasoning in the 21st Century</a></em>:\n$$\\frac{\\displaystyle\\int_{\\pi/3}^{\\pi/2}\\log\\left|\\frac{\\tan t+\\sqrt{7}}{\\tan t-\\sqrt{7}}\\right|dt}{\\displaystyle\\sum_{n=1}^\\infty\\left(\\frac n7\\right)\\frac{1}{n^2}}\\stackrel{?}{=}\\frac{7\\sqrt{7}}{24},$$\nwhere $(\\frac{n}{7})$ denotes the <a href=\"http://en.wikipedia.org/wiki/Legendre_symbol\" rel=\"noreferrer\">Legendre symbol</a>.</li>\n</ul>\n", "pids": ["53e9b02fb7602d9703a8e034", "53e9a169b7602d9702a5a3a2", "56d87506dabfae2eee11c0c1"], "flag": 0}
{"question": "Why is the error function defined as it is?", "body": "<p>$\\newcommand{\\erf}{\\operatorname{erf}}$\nThis may be a very na&iuml;ve question, but here goes.</p>\n\n<p>The <a href=\"http://en.wikipedia.org/wiki/Error_function\">error function</a> $\\erf$ is defined by\n$$\\erf(x) = \\frac{2}{\\sqrt{\\pi}} \\int_0^x e^{-t^2}dt.$$\nOf course, it is closely related to the normal cdf\n$$\\Phi(x) = P(N &lt; x) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^x e^{-t^2/2}dt$$\n(where $N \\sim N(0,1)$ is a standard normal) by the expression $\\erf(x) = 2\\Phi(x \\sqrt{2})-1$.</p>\n\n<p>My question is:</p>\n\n<blockquote>\n  <p>Why is it natural or useful to define $\\erf$ normalized in this way?</p>\n</blockquote>\n\n<p>I may be biased: as a probabilist, I think much more naturally in terms of $\\Phi$.  However, anytime I want to compute something, I find that my calculator or math library only provides $\\erf$, and I have to go check a textbook or Wikipedia to remember where all the $1$s and $2$s go.  Being charitable, I have to assume that $\\erf$ was invented for some reason other than to cause me annoyance, so I would like to know what it is.  If nothing else, it might help me remember the definition.</p>\n\n<p>Wikipedia says:</p>\n\n<blockquote>\n  <p><em>The standard normal cdf is used more often in probability and statistics, and the error function is used more often in other branches of mathematics.</em></p>\n</blockquote>\n\n<p>So perhaps a practitioner of one of these mysterious \"other branches of mathematics\" would care to enlighten me. </p>\n\n<p>The most reasonable expression I've found is that\n$$P(|N| &lt; x) = \\erf(x/\\sqrt{2}).$$\nThis at least gets rid of all but one of the apparently spurious constants, but still has a peculiar $\\sqrt{2}$ floating around.</p>\n", "pids": ["53e9b91eb7602d970450413c"], "flag": 1}
{"question": "Coordinate-free proof of $\\operatorname{Tr}(AB)=\\operatorname{Tr}(BA)$?", "body": "<blockquote>\n  <p>I am searching for a short <em>coordinate-free</em>  proof of <span class=\"math-container\">$\\operatorname{Tr}(AB)=\\operatorname{Tr}(BA)$</span> for linear operators  <span class=\"math-container\">$A$</span>, <span class=\"math-container\">$B$</span> between finite dimensional vector spaces of the same dimension. </p>\n</blockquote>\n\n<p>The usual proof is to represent the operators as matrices and then use matrix multiplication. I want a coordinate-free proof. That is, one that does not  make reference to an explicit matrix representation of the operator. I define trace as the sum of the eigenvalues of an operator.</p>\n\n<p>Ideally, the proof the should be shorter and require fewer preliminary lemmas than the one given in <a href=\"http://terrytao.wordpress.com/2013/01/13/matrix-identities-as-derivatives-of-determinant-identities/\" rel=\"noreferrer\">this blog post</a>.</p>\n\n<p>I would be especially interested in a proof that generalizes to the trace class of operators on a Hilbert space.</p>\n", "pids": ["56d8430cdabfae2eee97df4d"], "flag": 0}
{"question": "Are line search methods used in deep learning? Why not?", "body": "<p>A lot of tutorials online talk about gradient descent and almost all of them use a fixed step size (learning rate $\\alpha$). Why is there no use of line search (such as <a href=\"https://en.wikipedia.org/wiki/Backtracking_line_search\" rel=\"noreferrer\">backtracking line search</a> or exact line search)?</p>\n", "pids": ["58437722ac44360f1082f47f", "5c757cfcf56def9798a94a5c", "5cf48a1cda56291d5827d542"], "flag": 1}
{"question": "Is it a new type of induction? (Infinitesimal induction) Is this even true?", "body": "<p>Suppose we want to prove Euler's Formula with induction for all positive real numbers. <br>\nAt first this seems baffling, but an idea struck my mind today. \n<br></p>\n\n<blockquote>\n  <p><strong>Prove:</strong> $$e^{ix}=\\cos x+i\\sin x \\ \\ \\ \\forall \\ \\ x\\geq0$$</p>\n</blockquote>\n\n<p>For $x=0$, we have $$1=1$$\nSo the equality holds. <br>\nNow let us assume that the given equality holds for some $x=k$. <br>\n$$e^{ik}=\\cos k+i\\sin k$$\nNow, this is where I added my \"own\" axiom. Please answer whether this \"axiom\" is true or not. Now this equality must hold for $x=k+\\Delta k$ also, for some infinitely small positive change $\\Delta k$ (infinitesimal).\n<br>\nSo $e^{i(k+\\Delta k)}=e^{ik}.e^{i\\Delta k}=(\\cos k+i\\sin k)(\\cos\\Delta k+i\\sin\\Delta k)$\n<br> $$=\\cos k\\cos\\Delta k-\\sin k\\sin\\Delta k+i\\sin k\\cos\\Delta k+i\\cos k\\sin \\Delta k$$\n$$=\\cos(k+\\Delta k)+i\\sin(k+\\Delta k)$$\nSo we proved it for $x=k+\\Delta k$, and hence it must hold for all $x\\geq0$. <br>\nSo is this approach correct, and is this a new type of induction?</p>\n\n\n\n<p>Most of the comments below are indicating that the proof above is wrong. But we see the Euler's Formula does hold for all $x\\geq0$, so can someone give a good counter example where this proof doesn't work. Or in other words, these statements are used to prove a wrong equality.?</p>\n\n\n\n<p><strong>Update:</strong> Okay, some comments below are suggesting that Euler's Formula <strong>is</strong> definitely true. So if we prove somehow that $$e^{i\\Delta k}=\\cos\\Delta k+i\\sin\\Delta k$$ then? But how can we prove it for infinitesimal? Will the concept of limits be used? Can someone solve this mystery?</p>\n", "pids": ["5ce2b2baced107d4c6e3e9c5"], "flag": 0}
{"question": "Interesting but short math papers?", "body": "<p>Is it ok to start a list of interesting, but short mathematical papers, e.g. papers that are in the neighborhood of 1-3 pages? I like to read them here and there throughout the day to learn a new result.</p>\n<p>For example, I recently read and liked <a href=\"http://alpha.math.uga.edu/%7Epete/Jungnickel92.pdf\" rel=\"nofollow noreferrer\">On the Uniqueness of the Cyclic Group of Order n</a> (Dieter Jungnickel, <em>The American Mathematical Monthly</em> Vol. 99, No. 6 (Jun. - Jul., 1992), pp. 545-547, <a href=\"https://www.jstor.org/stable/2324062\" rel=\"nofollow noreferrer\">jstor</a>, doi: <a href=\"https://dx.doi.org/10.2307%2F2324062\" rel=\"nofollow noreferrer\">10.2307/2324062</a>).</p>\n", "pids": ["56d886d8dabfae2eee94b327", "56d92448dabfae2eeeb14651", "53e9aa8eb7602d9703409cfe", "53e9a5cdb7602d9702ef9c9e"], "flag": 0}
{"question": "Why is the determinant of a symplectic matrix 1?", "body": "<p>Suppose <span class=\"math-container\">$A \\in M_{2n}(\\mathbb{R})$</span>. and<span class=\"math-container\">$$J=\\begin{pmatrix}\n0 &amp; E_n\\\\ \n -E_n&amp;0 \n\\end{pmatrix}$$</span>\nwhere <span class=\"math-container\">$E_n$</span> represents identity matrix.</p>\n<p>if <span class=\"math-container\">$A$</span> satisfies <span class=\"math-container\">$$AJA^T=J.$$</span></p>\n<p>How to figure out <span class=\"math-container\">$$\\det(A)=1~?$$</span></p>\n<p>My approach:</p>\n<p>I have tried to separate <span class=\"math-container\">$A$</span> into four submartix:<span class=\"math-container\">$$A=\\begin{pmatrix}A_1&amp;A_2 \\\\A_3&amp;A_4 \\end{pmatrix}$$</span>\nand I must add a assumption that <span class=\"math-container\">$A_1$</span> is invertible.\nby elementary transfromation:<span class=\"math-container\">$$\\begin{pmatrix}A_1&amp;A_2 \\\\ A_3&amp;A_4\\end{pmatrix}\\rightarrow \\begin{pmatrix}A_1&amp;A_2 \\\\ 0&amp;A_4-A_3A_1^{-1}A_2\\end{pmatrix}$$</span></p>\n<p>we have:\n<span class=\"math-container\">$$\\det(A)=\\det(A_1)\\det(A_4-A_3A_1^{-1}A_2).$$</span>\nFrom<span class=\"math-container\">$$\\begin{pmatrix}A_1&amp;A_2 \\\\ A_3&amp;A_4\\end{pmatrix}\\begin{pmatrix}0&amp;E_n \\\\ -E_n&amp;0\\end{pmatrix}\\begin{pmatrix}A_1&amp;A_2 \\\\ A_3&amp;A_4\\end{pmatrix}^T=\\begin{pmatrix}0&amp;E_n \\\\ -E_n&amp;0\\end{pmatrix}.$$</span>\nwe get two equalities:<span class=\"math-container\">$$A_1A_2^T=A_2A_1^T$$</span> and <span class=\"math-container\">$$A_1A_4^T-A_2A_3^T=E_n.$$</span></p>\n<p>then <span class=\"math-container\">$$\\det(A)=\\det(A_1(A_4-A_3A_1^{-1}A_2)^T)=\\det(A_1A_4^T-A_1A_2^T(A_1^T)^{-1}A_3^T)=\\det(A_1A_4^T-A_2A_1^T(A_1^T)^{-1}A_3^T)=\\det(E_n)=1,$$</span></p>\n<p>but I have no idea to deal with this problem when <span class=\"math-container\">$A_1$</span> is not invertible.</p>\n", "pids": ["56d8c96bdabfae2eee690feb"], "flag": 0}
{"question": "Real life usage of Benford&#39;s Law", "body": "<p>I recently discovered Benford's Law. I find it very fascinating. I'm wondering what are some of the real life uses of Benford's law. Specific examples would be great.</p>\n", "pids": ["53e9bdb3b7602d9704a61287", "53e9b030b7602d9703a8efad"], "flag": 0}
{"question": "An infinite series plus a continued fraction by Ramanujan", "body": "<p>Here is a famous problem posed by Ramanujan</p>\n\n<blockquote>\n  <p>Show that $$\\left(1 + \\frac{1}{1\\cdot 3} + \\frac{1}{1\\cdot 3\\cdot 5} + \\cdots\\right) + \\left(\\cfrac{1}{1+}\\cfrac{1}{1+}\\cfrac{2}{1+}\\cfrac{3}{1+}\\cfrac{4}{1+\\cdots}\\right) = \\sqrt{\\frac{\\pi e}{2}}$$</p>\n</blockquote>\n\n<p>The first series seems vaguely familiar if we consider the function $$f(x) = x + \\frac{x^{3}}{1\\cdot 3} + \\frac{x^{5}}{1\\cdot 3\\cdot 5} + \\cdots$$ and note that $$f'(x) = 1 + xf(x)$$ so that $y = f(x)$ satisfies the differential equation $$\\frac{dy}{dx} - xy = 1, y(0) = 0$$ The integrating factor here comes to be $e^{-x^{2}/2}$ so that $$ye^{-x^{2}/2} = \\int_{0}^{x}e^{-t^{2}/2}\\,dt$$ and hence $$f(x) = e^{x^{2}/2}\\int_{0}^{x}e^{-t^{2}/2}\\,dt$$ Thus the sum of the first series is $$f(1) = \\sqrt{e}\\int_{0}^{1}e^{-t^{2}/2}\\,dt$$ But I have no idea about the continued fraction and still more I am not able to figure out how it would simplify to $\\sqrt{\\pi e/2}$ at the end.</p>\n\n<p>Please provide any hints or suggestions.</p>\n\n<p><strong>Update</strong>: We have $$\\begin{aligned}f(1) &amp;= \\sqrt{e}\\int_{0}^{1}e^{-t^{2}/2}\\,dt = \\sqrt{e}\\int_{0}^{\\infty}e^{-t^{2}/2}\\,dt - \\sqrt{e}\\int_{1}^{\\infty}e^{-t^{2}/2}\\,dt\\\\\n&amp;= \\sqrt{\\frac{\\pi e}{2}} - \\sqrt{e}\\int_{1}^{\\infty}e^{-t^{2}/2}\\,dt\\end{aligned}$$ and hence we finally need to establish $$\\sqrt{e}\\int_{1}^{\\infty}e^{-t^{2}/2}\\,dt = \\cfrac{1}{1+}\\cfrac{1}{1+}\\cfrac{2}{1+}\\cfrac{3}{1+}\\cfrac{4}{1+\\cdots}$$ On further searching in Ramanujan's Collected Papers I found the following formula $$\\int_{0}^{a}e^{-x^{2}}\\,dx = \\frac{\\sqrt{\\pi}}{2} - \\cfrac{e^{-a^{2}}}{2a+}\\cfrac{1}{a+}\\cfrac{2}{2a+}\\cfrac{3}{a+}\\cfrac{4}{2a+\\cdots}$$ and it seems helpful here. But unfortunately proving this formula seems to be another big challenge for me.</p>\n", "pids": ["53e9b879b7602d97044488ed"], "flag": 0}
{"question": "Solutions to $\\binom{n}{5} = 2 \\binom{m}{5}$", "body": "<p>In <em>Finite Mathematics</em> by Lial et al. (10th ed.), problem 8.3.34 says:</p>\n\n<blockquote>\n  <p>On National Public Radio, the <em>Weekend Edition</em> program posed the\n  following probability problem: Given a certain number of balls, of\n  which some are blue, pick 5 at random.  The probability that all 5 are\n  blue is 1/2.  Determine the original number of balls and decide how\n  many were blue.</p>\n</blockquote>\n\n<p>If there are $n$ balls, of which $m$ are blue, then the probability that 5 randomly chosen balls are all blue is $\\binom{m}{5} / \\binom{n}{5}$.  We want this to be $1/2$,\nso $\\binom{n}{5} = 2\\binom{m}{5}$; equivalently,\n$n(n-1)(n-2)(n-3)(n-4) = 2 m(m-1)(m-2)(m-3)(m-4)$.\nI'll denote these quantities as $[n]_5$ and $2 [m]_5$ (this is a notation for the so-called \"falling factorial.\")</p>\n\n<p>A little fooling around will show that $[m+1]_5 = \\frac{m+1}{m-4}[m]_5$.\nSolving $\\frac{m+1}{m-4} = 2$ shows that the only solution with $n = m + 1$ has $m = 9$, $n = 10$.</p>\n\n<p><strong>Is this the only solution?</strong></p>\n\n<p>You can check that $n = m + 2$ doesn't yield any integer solutions, by using the quadratic formula to solve $(m + 2)(m  +1) = 2(m - 3)(m - 4)$.  I have ruled out $n = m + 3$ or $n = m + 4$ with similar checks.  For $n \\geq m + 5$, solutions would satisfy a quintic equation, which of course has no general formula to find solutions.</p>\n\n<p>Note that, as $n$ gets bigger, the ratio of successive values of $\\binom{n}{5}$ gets smaller; $\\binom{n+1}{5} = \\frac{n+1}{n-4}\\binom{n}{5}$\nand $\\frac{n+1}{n-4}$ is less than 2—in fact, it approaches 1. So it seems possible that, for some $k$, $\\binom{n+k}{5}$ could be $2 \\binom{n}{5}$.</p>\n\n<p>This is now <a href=\"https://mathoverflow.net/questions/128036/solutions-to-binomn5-2-binomm5\">a question at MathOverflow</a>.</p>\n", "pids": ["56d84b50dabfae2eeed845b1", "53e9b51bb7602d970404f7fc"], "flag": 0}
{"question": "What are ways to compute polynomials that converge from above and below to a continuous and bounded function on $[0,1]$?", "body": "<h2>Main Question</h2>\n<p>Suppose <span class=\"math-container\">$f:[0,1]\\to [0,1]$</span> is continuous and belongs to a large class of functions (for example, the <span class=\"math-container\">$k$</span>-th derivative, <span class=\"math-container\">$k\\ge 0$</span>, is continuous, Lipschitz continuous, concave, strictly increasing, bounded variation, and/or in the Zygmund class, or <span class=\"math-container\">$f$</span> is real analytic).</p>\n<p>Then, <strong>compute the Bernstein coefficients of two sequences of polynomials (<span class=\"math-container\">$g_n$</span>, <span class=\"math-container\">$h_n$</span>) of degree 2, 4, 8, ..., <span class=\"math-container\">$2^i$</span>, ... that converge to <span class=\"math-container\">$f$</span>, one from above and one from below (<span class=\"math-container\">$\\lim_n g_n = \\lim_n h_n = f$</span>), and satisfy: <span class=\"math-container\">$(g_{2n}-g_{n})$</span> and <span class=\"math-container\">$(h_{n}-h_{2n})$</span> are polynomials with non-negative Bernstein coefficients once they are rewritten to polynomials in Bernstein form of degree exactly <span class=\"math-container\">$2n$</span>.</strong> Assume <span class=\"math-container\">$0\\lt f(\\lambda)\\lt 1$</span> or <span class=\"math-container\">$f$</span> is polynomially bounded.</p>\n<p>The convergence rate must be <span class=\"math-container\">$O(1/n^{r/2})$</span> if the class has only functions with Lipschitz-continuous <span class=\"math-container\">$(r-1)$</span>-th derivative.  The method may not introduce transcendental or trigonometric functions (as with Chebyshev interpolants).</p>\n<p>Without loss of generality, the following special cases are of interest to me:</p>\n<ul>\n<li>The class has only functions with Lipschitz continuous <span class=\"math-container\">$r$</span>-th derivative where <span class=\"math-container\">$r$</span> is 2 to 5.</li>\n<li><span class=\"math-container\">$B_n(W_n)$</span> is a linear combination or iterated Boolean sum of Bernstein polynomials.  Examples:<span class=\"math-container\">$W_n = 2 f - B_n(f)$</span> and <span class=\"math-container\">$r$</span> is 3 or 4, or <span class=\"math-container\">$W_n = B_n(B_n(f))+3(f-B_n(f))$</span> and <span class=\"math-container\">$r$</span> is 5 or 6, where <span class=\"math-container\">$B_n(f)$</span> is the Bernstein polynomial of degree <span class=\"math-container\">$n$</span> of a function <span class=\"math-container\">$f$</span>. (See Güntürk and Li 2021.)</li>\n<li><span class=\"math-container\">$W_n$</span> or <span class=\"math-container\">$B_n(W_n)$</span> is a linear operator that is not positive and preserves polynomials of a higher degree than linear functions (e.g., the operator studied by Tachev (2022) preserves quadratic functions).</li>\n</ul>\n<h2>Background</h2>\n<p>We're given a coin that shows heads with an unknown probability, <span class=\"math-container\">$\\lambda$</span>. The goal is to use that coin (and possibly also a fair coin) to build a &quot;new&quot; coin that shows heads with a probability that depends on <span class=\"math-container\">$\\lambda$</span>, call it <span class=\"math-container\">$f(\\lambda)$</span>. This is the <em>Bernoulli factory problem</em>, and it can be solved only for certain functions <span class=\"math-container\">$f$</span>. (For example, flipping the coin twice and taking heads only if exactly one coin shows heads, we can simulate the probability <span class=\"math-container\">$2\\lambda(1-\\lambda)$</span>.)</p>\n<p>Specifically, the only functions that can be simulated this way <strong>are continuous and polynomially bounded on their domain, and map <span class=\"math-container\">$[0, 1]$</span> or a subset thereof to <span class=\"math-container\">$[0, 1]$</span></strong>, as well as <span class=\"math-container\">$f=0$</span> and <span class=\"math-container\">$f=1$</span>. These functions are called <em>factory functions</em> in this question. (A function <span class=\"math-container\">$f(x)$</span> is <em>polynomially bounded</em> if both <span class=\"math-container\">$f$</span> and <span class=\"math-container\">$1-f$</span> are bounded below by min(<span class=\"math-container\">$x^n$</span>, <span class=\"math-container\">$(1-x)^n$</span>) for some integer <span class=\"math-container\">$n$</span> (Keane and O'Brien 1994). This implies that <span class=\"math-container\">$f$</span> admits no roots on (0, 1) and can't take on the value 0 or 1 except possibly at 0 and/or 1.)</p>\n<p>In this question, a polynomial <span class=\"math-container\">$P(x)$</span> is written in <em>Bernstein form of degree <span class=\"math-container\">$n$</span></em> if it is written as— <span class=\"math-container\">$$P(x)=\\sum_{k=0}^n a_k {n \\choose k} x^k (1-x)^{n-k},$$</span> where <span class=\"math-container\">$a_0, ..., a_n$</span> are the polynomial's <em>Bernstein coefficients</em>.</p>\n<p>The degree-<span class=\"math-container\">$n$</span> <em>Bernstein polynomial</em> of an arbitrary function <span class=\"math-container\">$f(x)$</span> has Bernstein coefficients <span class=\"math-container\">$a_k = f(k/n)$</span>.  In general, this Bernstein polynomial differs from <span class=\"math-container\">$f$</span> even if <span class=\"math-container\">$f$</span> is a polynomial.</p>\n<h2>Polynomials that approach a factory function</h2>\n<p>An <a href=\"https://peteroupc.github.io/bernoulli.html#General_Factory_Functions\" rel=\"nofollow noreferrer\"><strong>algorithm</strong></a> simulates a factory function <span class=\"math-container\">$f(\\lambda)$</span> via two sequences of polynomials that converge from above and below to that function. Roughly speaking, the algorithm works as follows:</p>\n<ol>\n<li>Generate U, a uniform random variate in <span class=\"math-container\">$[0, 1]$</span>.</li>\n<li>Flip the input coin (with a probability of heads of <span class=\"math-container\">$\\lambda$</span>), then build an upper and lower bound for <span class=\"math-container\">$f(\\lambda)$</span>, based on the outcomes of the flips so far. In this case, these bounds come from two degree-<span class=\"math-container\">$n$</span> polynomials that approach <span class=\"math-container\">$f$</span> as <span class=\"math-container\">$n$</span> gets large, where <span class=\"math-container\">$n$</span> is the number of coin flips so far in the algorithm.</li>\n<li>If U is less than or equal to the lower bound, return 1. If U is greater than the upper bound, return 0. Otherwise, go to step 2.</li>\n</ol>\n<p>The result of the algorithm is 1 with probability <em>exactly</em> equal to <span class=\"math-container\">$f(\\lambda)$</span>, or 0 otherwise.</p>\n<p>However, the algorithm requires the polynomial sequences to meet certain requirements; among them, the sequences must be of Bernstein-form polynomials that converge from above and below to a factory function.  See the formal statement, next.</p>\n<p></p>\n<h3>Formal Statement</h3>\n<p>More formally, there must exist two sequences of polynomials, namely—</p>\n<ul>\n<li><span class=\"math-container\">$g_{n}(\\lambda): =\\sum_{k=0}^{n}a(n, k){n \\choose k}\\lambda^{k}(1-\\lambda)^{n-k}$</span>, and</li>\n<li><span class=\"math-container\">$h_{n}(\\lambda): =\\sum_{k=0}^{n}b(n, k){n \\choose k}\\lambda^{k}(1-\\lambda)^{n-k}$</span>,</li>\n</ul>\n<p>for every integer <span class=\"math-container\">$n\\ge1$</span>, such that—</p>\n<ol>\n<li><span class=\"math-container\">$a(n, k)\\le b(n, k)$</span>,</li>\n<li><span class=\"math-container\">$\\lim_{n}g_{n}(\\lambda)=\\lim_{n}h_{n}(\\lambda)=f(\\lambda)$</span> whenever <span class=\"math-container\">$0\\le\\lambda\\le 1$</span>, and</li>\n<li><span class=\"math-container\">$(g_{n+1}-g_{n})$</span> and <span class=\"math-container\">$(h_{n}-h_{n+1})$</span> are polynomials with nonnegative Bernstein coefficients once they are rewritten to polynomials in Bernstein form of degree exactly <span class=\"math-container\">$n+1$</span> (see end notes),</li>\n</ol>\n<p>where <span class=\"math-container\">$f(\\lambda)$</span> is continuous on <span class=\"math-container\">$[0, 1]$</span> (Nacu and Peres 2005; Holtz et al. 2011), and the goal is to find the appropriate values for <span class=\"math-container\">$a(n, k)$</span> and <span class=\"math-container\">$b(n, k)$</span>.</p>\n<p></p>\n<h3>A Matter of Efficiency</h3>\n<p>However, ordinary Bernstein polynomials converge to a function at the rate <span class=\"math-container\">$\\Omega(1/n)$</span> in general, a result known since Voronovskaya (1932) and a rate that will lead to an <strong>infinite expected number of coin flips in general</strong>.  (See also my <a href=\"https://peteroupc.github.io/bernsupp.html\" rel=\"nofollow noreferrer\"><strong>supplemental notes</strong></a>.)</p>\n<p>But Lorentz (1966) showed that if the function is positive and has a continuous <span class=\"math-container\">$k$</span>-th derivative, there are polynomials with nonnegative Bernstein coefficients that converge at the rate <span class=\"math-container\">$O(1/n^{k/2})$</span> (and thus can enable a <strong>finite expected number of coin flips</strong> if the function is &quot;smooth&quot; enough).</p>\n<p>Thus, people have developed alternatives, including linear combinations and iterated Boolean sums of Bernstein polynomials, to improve the convergence rate. These include Micchelli (1973), Guan (2009), Güntürk and Li (2021a, 2021b), the &quot;Lorentz operator&quot; in Holtz et al. (2011), Draganov (2014), and Tachev (2022).</p>\n<p>These alternative polynomials usually include results where the error bound is the desired <span class=\"math-container\">$O(1/n^{k/2})$</span>, but nearly all those results (e.g., Theorem 4.4 in Micchelli; Theorem 5 in Güntürk and Li) have hidden constants with no upper bounds given, making them unimplementable (that is, it can't be known beforehand whether a given polynomial will come close to the target function within a user-specified error tolerance). (See end notes.)</p>\n<h3>A Conjecture on Polynomial Approximation</h3>\n<p>The following is a conjecture that could help reduce this problem to the problem of finding explicit error bounds when approximating a function by polynomials.</p>\n<p>Let <span class=\"math-container\">$f(\\lambda):[0,1]\\to(0,1)$</span> have <span class=\"math-container\">$r\\ge 1$</span> continuous derivatives, let <span class=\"math-container\">$M$</span> be the maximum of the absolute value of <span class=\"math-container\">$f$</span> and its derivatives up to the <span class=\"math-container\">$r$</span>-th derivative, and denote the Bernstein polynomial of degree <span class=\"math-container\">$n$</span> of a function <span class=\"math-container\">$g$</span> as <span class=\"math-container\">$B_n(g)$</span>. Let <span class=\"math-container\">$W_{2^0}(\\lambda), W_{2^1}(\\lambda), ..., W_{2^i}(\\lambda),...$</span> be a sequence of functions on [0, 1] that converge uniformly to <span class=\"math-container\">$f$</span>.</p>\n<p>For each integer <span class=\"math-container\">$n\\ge 1$</span> that's a power of 2, suppose that there is <span class=\"math-container\">$D&gt;0$</span> such that— <span class=\"math-container\">$$|f(\\lambda)-B_n(W_n(\\lambda))| \\le DM/n^{r/2},$$</span> whenever <span class=\"math-container\">$0\\le \\lambda\\le 1$</span>.</p>\n<p>Then, a <a href=\"https://peteroupc.github.io/bernsupp.html#A_Conjecture_on_Polynomial_Approximation\" rel=\"nofollow noreferrer\"><strong>conjecture</strong></a> is that there is <span class=\"math-container\">$C_0\\ge D$</span> such that for every <span class=\"math-container\">$C\\ge C_0$</span>, there are polynomials <span class=\"math-container\">$g_n$</span> and <span class=\"math-container\">$h_n$</span> (for each <span class=\"math-container\">$n\\ge 1$</span>) as follows: (A) <span class=\"math-container\">$g_n$</span> and <span class=\"math-container\">$h_n$</span> have Bernstein coefficients <span class=\"math-container\">$W_n(k/n) - CM/n^{r/2}$</span> and <span class=\"math-container\">$W_n(k/n) + CM/n^{r/2}$</span>, respectively (<span class=\"math-container\">$0\\le k\\le n$</span>), if <span class=\"math-container\">$n$</span> is a power of 2, and <span class=\"math-container\">$g_n=g_{n-1}$</span> and <span class=\"math-container\">$h_n=h_{n-1}$</span> otherwise; (B) <span class=\"math-container\">$\\lim_n g_n =\\lim_n h_n=f$</span>; (C) <span class=\"math-container\">$(g_{n+1}-g_{n})$</span> and <span class=\"math-container\">$(h_{n}-h_{n+1})$</span> are polynomials with non-negative Bernstein coefficients once they are rewritten to polynomials in Bernstein form of degree exactly <span class=\"math-container\">$n+1$</span>. (See end notes.)</p>\n<p>Equivalently (see also Nacu and Peres 2005), there is <span class=\"math-container\">$C_1&gt;0$</span> such that the inequality <span class=\"math-container\">$(PB)$</span> (see below) holds true for each integer <span class=\"math-container\">$n\\ge 1$</span> that's a power of 2 (see &quot;Main Question&quot; above).</p>\n<p>My goal is to see not just whether this conjecture is true, but also which value of <span class=\"math-container\">$C_0$</span> (or <span class=\"math-container\">$C_1$</span>) suffices for the conjecture, especially for any combination of the special cases mentioned at the end of &quot;Main Question&quot;, above.</p>\n<h3>Strategies</h3>\n<p>The following are some ways to answer these questions:</p>\n<ol>\n<li>Finding a sequence of functions <span class=\"math-container\">$(W_n(f))$</span> and an explicit and tight upper bound on <span class=\"math-container\">$C_1&gt;0$</span> such that, for each integer <span class=\"math-container\">$n\\ge 1$</span> that's a power of 2— <span class=\"math-container\">$$\\left|\\left(\\sum_{i=0}^k W_n\\left(\\frac{i}{n}\\right)\\sigma_{n,k,i}\\right)-W_{2n}\\left(\\frac{k}{2n}\\right)\\right|=|\\mathbb{E}[W_n(X_k/n)] - W_{2n}(\\mathbb{E}[X_k/n])|\\le \\frac{C_1 M}{n^{r/2}},\\tag{PB}$$</span> whenever <span class=\"math-container\">$0\\le k\\le 2n$</span>, where <span class=\"math-container\">$M = \\max(L, \\max|f^{(0)}|, ...,\\max|f^{(r-1)}|)$</span>, <span class=\"math-container\">$L$</span> is <span class=\"math-container\">$\\max|f^{(r)}|$</span> or the Lipschitz constant of <span class=\"math-container\">$f^{(r-1)}$</span>, <span class=\"math-container\">$X_k$</span> is a hypergeometric(<span class=\"math-container\">$2n$</span>, <span class=\"math-container\">$k$</span>, <span class=\"math-container\">$n$</span>) random variable, and <span class=\"math-container\">$\\sigma_{n,k,i} = {n\\choose i}{n\\choose {k-i}}/{2n \\choose k}=\\mathbb{P}(X_k=i)$</span> is the probability that <span class=\"math-container\">$X_k$</span> equals <span class=\"math-container\">$i$</span>. (<strong>See end notes as well as &quot;<a href=\"https://peteroupc.github.io/bernsupp.html#Proofs_for_Polynomial_Building_Schemes\" rel=\"nofollow noreferrer\"><strong>Proofs for Polynomial-Building Schemes</strong></a>.</strong>)</li>\n<li>Suppose that, for each integer <span class=\"math-container\">$n\\ge 1$</span> that's a power of 2, there is a polynomial of degree <span class=\"math-container\">$n$</span>, <span class=\"math-container\">$P_{n}(f)$</span>, that is within <span class=\"math-container\">$E(n)$</span> of <span class=\"math-container\">$f(\\lambda)$</span>. (For example, <span class=\"math-container\">$P_{n}(f)$</span> could be a linear combination of Bernstein polynomials.) Then I believe another way to answer this question is to find <span class=\"math-container\">$C&gt;0$</span> such that the non-negative polynomial <span class=\"math-container\">$Q_{n}(f) = (P_{2n}(f) + E(n) + E(2n)) - P_{n}(f)$</span>, when rewritten to a degree-<span class=\"math-container\">$(2n)$</span> polynomial in Bernstein form, has Bernstein coefficients no greater than <span class=\"math-container\">$CM/n^{r/2}$</span>, where <span class=\"math-container\">$M$</span> and <span class=\"math-container\">$r$</span> are as above.  In that case, I believe solving the problem will rely on bounds on the derivatives of <span class=\"math-container\">$f$</span>, <span class=\"math-container\">$P_{n}(f)$</span>, and/or <span class=\"math-container\">$Q_{n}(f)$</span>.</li>\n</ol>\n<h3>Examples of Functions to Ponder</h3>\n<p>The following are examples of functions worth pondering for these questions:</p>\n<ul>\n<li><span class=\"math-container\">$f(\\lambda)=\\sin(\\lambda\\pi/2)=\\cos((1-\\lambda)\\pi/2)$</span>, which equals 0 at 0 and 1 at 1.</li>\n<li>Functions whose <span class=\"math-container\">$k$</span>-th derivative (<span class=\"math-container\">$k\\ge 0$</span>) is continuous but not Lipschitz continuous at 0 (and <span class=\"math-container\">$\\lambda$</span> can equal 0), such as if that derivative is <span class=\"math-container\">$\\lambda^\\alpha$</span>, where <span class=\"math-container\">$0&lt;\\alpha&lt;1$</span>, or <span class=\"math-container\">$\\lim_{z\\to\\lambda} z-z \\ln(z)$</span>, or <span class=\"math-container\">$\\lim_{z\\to\\lambda} -1/(2 \\ln(z/2))$</span>.</li>\n<li>The function <span class=\"math-container\">$1/2-(1-2\\lambda)^{\\alpha}\\beta/2$</span> if <span class=\"math-container\">$\\lambda&lt;1/2$</span> and <span class=\"math-container\">$1/2+(2\\lambda-1)^{\\alpha}\\beta/2$</span> otherwise, where <span class=\"math-container\">$\\alpha&gt;0$</span> and <span class=\"math-container\">$0\\lt\\beta\\le 1$</span>.</li>\n</ul>\n<h2>Remarks</h2>\n<ul>\n<li>A <a href=\"https://mathoverflow.net/questions/407179/using-the-holtz-method-to-build-polynomials-that-converge-to-a-continuous-functi\">related question</a> seeks a practical way to apply the Holtz method.</li>\n<li>A <a href=\"https://mathoverflow.net/questions/409174/concave-functions-series-representation-and-converging-polynomials\">related question</a> seeks ways to build a Bernoulli factory algorithm for concave functions and other functions by finding a series of nonnegative functions (such as polynomials), each of which has a simple Bernoulli factory algorithm and has a known upper bound.</li>\n<li>This question is one of <a href=\"https://peteroupc.github.io/bernreq.html\" rel=\"nofollow noreferrer\">numerous open questions</a> about the Bernoulli factory problem.  Answers to them will greatly improve my pages on Bernoulli factories.</li>\n<li>Theorem 26 of Nacu and Peres (2005) and the proof of Keane and O'Brien (1994) give general ways to simulate continuous factory functions <span class=\"math-container\">$f(\\lambda)$</span> on the interval <span class=\"math-container\">$[0, 1]$</span>. The former is limited to functions that are bounded away from 0 and 1, while the latter is not. However, both methods don't provide simple formulas that work for a whole class of factory functions. For this and other reasons, given below, both methods are impractical:\n<ul>\n<li>Before a given function <span class=\"math-container\">$f$</span> can be simulated, the methods require computing the necessary degree of approximation (finding <span class=\"math-container\">$k_a$</span> or <span class=\"math-container\">$s_i$</span> for each polynomial <span class=\"math-container\">$a$</span> or <span class=\"math-container\">$i$</span>, respectively). This work has to be repeated for <em>each</em> function <span class=\"math-container\">$f$</span> to be simulated.</li>\n<li>Computing the degree of approximation involves, among other things, checking whether the approximating polynomial is &quot;close enough&quot; to <span class=\"math-container\">$f$</span>, which can require either symbolic maximization or a numerical optimization that calculates rigorous upper and lower bounds. This computation gets more and more time-intensive with increasing degree.</li>\n<li>For a given <span class=\"math-container\">$f$</span>, it's not guaranteed whether the <span class=\"math-container\">$k_a$</span>'s (or <span class=\"math-container\">$s_i$</span>'s) will show a pattern or keep that pattern &quot;forever&quot; — especially since only a finite number of approximation degrees can be computed with these methods.</li>\n</ul>\n</li>\n</ul>\n<h2>References</h2>\n<ul>\n<li>Łatuszyński, K., Kosmidis, I., Papaspiliopoulos, O., Roberts, G.O., &quot;Simulating events of unknown probabilities via reverse time martingales&quot;, arXiv:0907.4018v2 [stat.CO], 2009/2011.</li>\n<li>Keane, M. S., and O'Brien, G. L., &quot;A Bernoulli factory&quot;, <em>ACM Transactions on Modeling and Computer Simulation</em> 4(2), 1994.</li>\n<li>Holtz, O., Nazarov, F., Peres, Y., &quot;New Coins from Old, Smoothly&quot;, Constructive Approximation 33 (2011).</li>\n<li>Nacu, Şerban, and Yuval Peres. &quot;Fast simulation of new coins from old&quot;, The Annals of Applied Probability 15, no. 1A (2005): 93-115.</li>\n<li>Micchelli, C. (1973). The saturation class and iterates of the Bernstein polynomials. Journal of Approximation Theory, 8(1), 1-18.</li>\n<li>Guan, Zhong. &quot;<a href=\"https://arxiv.org/pdf/0909.0684\" rel=\"nofollow noreferrer\">Iterated Bernstein polynomial approximations</a>.&quot; arXiv preprint arXiv:0909.0684 (2009).</li>\n<li>Güntürk, C. Sinan, and Weilin Li. &quot;<a href=\"https://arxiv.org/pdf/2112.09183\" rel=\"nofollow noreferrer\">Approximation with one-bit polynomials in Bernstein form</a>&quot; arXiv preprint arXiv:2112.09183 (2021).</li>\n<li>C.S. Güntürk, W. Li, &quot;<a href=\"https://arxiv.org/pdf/2112.09181.pdf\" rel=\"nofollow noreferrer\">Approximation of functions with one-bit neural networks</a>&quot;, arXiv:2112.09181 [cs.LG], 2021.</li>\n<li>Draganov, Borislav R. &quot;On simultaneous approximation by iterated Boolean sums of Bernstein operators.&quot; Results in Mathematics 66, no. 1 (2014): 21-41.</li>\n<li>Farouki, R.T., and Rajan, V.T., &quot;Algorithms for polynomials in Bernstein form&quot;, Computer Aided Geometric Design 5(1), 1988.</li>\n<li>Tachev, Gancho. &quot;<a href=\"https://doi.org/10.3934/mfc.2022061\" rel=\"nofollow noreferrer\">Linear combinations of two Bernstein polynomials</a>&quot;, Mathematical Foundations of Computing, 2022.</li>\n<li>Lee, Sang Kyu, Jae Ho Chang, and Hyoung-Moon Kim. &quot;Further sharpening of Jensen's inequality.&quot; Statistics 55, no. 5 (2021): 1154-1168.</li>\n</ul>\n<hr />\n<p>(**) An exception is Chebyshev interpolants, but my implementation experience shows that Chebyshev interpolants are far from being readily convertible to Bernstein form without using transcendental functions or paying attention to the difference between first vs. second kind, Chebyshev points vs. coefficients, and the interval [-1, 1] vs. [0, 1].  For purposes of this question, Chebyshev interpolants are impractical, and so are other approximating functions that introduce transcendental functions.  By contrast, other schemes (which are of greater interest to me) involve polynomials that are already in Bernstein form or that use only rational arithmetic to transform to Bernstein form (these include so-called &quot;iterated Bernstein&quot; polynomials and &quot;one-bit&quot; polynomials).  Indeed, unlike with rational arithmetic (where arbitrary precision is trivial), transcendental functions require special measures to support arbitrary accuracy, such as constructive/recursive reals — floating-point numbers won't do for purposes of this question.</p>\n<p>(***) This corresponds to the so-called <em>iterated Bernstein polynomial</em> of order 2 or order 3 (Güntürk and Li 2021) for which I have appeared to find <a href=\"https://mathoverflow.net/questions/424272/explicit-and-fast-error-bounds-for-polynomial-approximation\">explicit error bounds</a>.</p>\n<p>(****) This condition is equivalent in practice to the following statement (Nacu &amp; Peres 2005). For every integer <span class=\"math-container\">$k\\in[0,2n]$</span> and every integer <span class=\"math-container\">$n\\ge 1$</span> that's a power of 2, <span class=\"math-container\">$a(2n, k)\\ge\\mathbb{E}[a(n, X_{n,k})]= \\left(\\sum_{i=0}^k a(n,i) {n\\choose i}{n\\choose {k-i}}/{2n\\choose k}\\right)$</span> and <span class=\"math-container\">$b(2n, k)\\le\\mathbb{E}[b(n, X_{n,k})]$</span>, where <span class=\"math-container\">$X_{n,k}$</span> is a hypergeometric(<span class=\"math-container\">$2n$</span>, <span class=\"math-container\">$k$</span>, <span class=\"math-container\">$n$</span>) random variable.  A hypergeometric(<span class=\"math-container\">$2n$</span>, <span class=\"math-container\">$k$</span>, <span class=\"math-container\">$n$</span>) random variable is the number of &quot;good&quot; balls out of <span class=\"math-container\">$n$</span> balls taken uniformly at random, all at once, from a bag containing <span class=\"math-container\">$2n$</span> balls, <span class=\"math-container\">$k$</span> of which are &quot;good&quot;.  See also my <a href=\"https://mathoverflow.net/questions/429037/bounds-on-the-expectation-of-a-function-of-a-hypergeometric-random-variable\"><strong>MathOverflow question</strong></a> on finding bounds for hypergeometric variables.</p>\n<p>(*5) If <span class=\"math-container\">$W_n(0)=f(0)$</span> and <span class=\"math-container\">$W_n(1)=f(1)$</span> for every <span class=\"math-container\">$n$</span>, then the inequality <span class=\"math-container\">$(A)$</span> is automatically true when <span class=\"math-container\">$k=0$</span> and <span class=\"math-container\">$k=2n$</span>, so that the statement has to be checked only for <span class=\"math-container\">$0\\lt k\\lt 2n$</span>.  If, in addition, <span class=\"math-container\">$W_n$</span> is symmetric about 1/2, so that <span class=\"math-container\">$W_n(\\lambda)=W_n(1-\\lambda)$</span> whenever <span class=\"math-container\">$0\\le \\lambda\\le 1$</span>, then the statement has to be checked only for <span class=\"math-container\">$0\\lt k\\le n$</span> (since the values <span class=\"math-container\">$\\sigma_{n,k,i} = {n\\choose i}{n\\choose {k-i}}/{2n \\choose k}$</span> are symmetric in that they satisfy <span class=\"math-container\">$\\sigma_{n,k,i}=\\sigma_{n,k,k-i}$</span>).</p>\n<p>This question is a problem of finding the <em>Jensen gap</em> of <span class=\"math-container\">$W_n$</span> for certain kinds of hypergeometric random variables.  Lee et al. (2021) deal with a problem very similar to this one and find results that take advantage of <span class=\"math-container\">$f$</span>'s (here, <span class=\"math-container\">$W_n$</span>'s) smoothness, but unfortunately assume the variable is supported on an <em>open</em> interval, rather than a <em>closed</em> one (namely <span class=\"math-container\">$[0,1]$</span>) as in this question.</p>\n", "pids": ["61bff4265244ab9dcb79c44d", "53e9adf6b7602d9703803761"], "flag": 0}
{"question": "What do cones have to do with quadratics? Why is $2$ special?", "body": "<p>I've always been nagged about the two extremely non-obviously related definitions of conic sections (i.e. it seems so mysterious/magical that somehow slices of a cone are related to degree 2 equations in 2 variables). Recently I came across the following pages/videos:</p>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=pQa_tWZmlGs&amp;ab_channel=3Blue1Brown\" rel=\"nofollow noreferrer\">This 3B1B video about ellipses</a>, which reignited my desire to understand conics</li>\n<li><a href=\"https://math.stackexchange.com/questions/2226760/why-are-quadratic-equations-the-same-as-right-circular-conic-sections\">Why are quadratic equations the same as right circular conic sections?</a>, which offers a very computational approach to trying to resolve this question</li>\n<li><a href=\"https://www.youtube.com/watch?v=QJYmyhnaaek&amp;vl=en&amp;ab_channel=3Blue1Brown\" rel=\"nofollow noreferrer\">Another 3B1B video on visualizing Pythagorean triples</a> (i.e. finding the rational points of a circle)</li>\n<li>and <a href=\"https://www.youtube.com/watch?v=_-feKGb6-gc&amp;ab_channel=TheAbelPrize\" rel=\"nofollow noreferrer\">Manjul Bhargava's lecture on the Birch-Swinnerton-Dyer Conjecture</a>, where minutes ~10-15 discuss the complete solution to the problems of rational points on conics.</li>\n</ul>\n<p>While 3B1B's video makes a lot of sense and is very beautiful from a geometric standpoint, it does not talk about any of the other conics, or discuss the relationship with &quot;degree 2&quot;. Moreover, the 2nd 3B1B video I linked and then Bhargava's lecture highlights &quot;degree 2&quot; as something we understand well, compared to higher degrees (reminds me a little bit of Fermat's last theorem and the non-existence of solutions for <span class=\"math-container\">$n&gt;2$</span>).</p>\n<p>So, I suppose my questions are as follows:</p>\n<ol>\n<li>Why, from an intuitive standpoint, should we expect cones to be deeply related to zero-sets of degree 2 algebraic equations?</li>\n</ol>\n<p>and more generally:</p>\n<ol start=\"2\">\n<li>Is there some deep reason why &quot;<span class=\"math-container\">$2$</span>&quot; is so special? I've often heard the quip that &quot;mathematics is about turning confusing things into linear algebra&quot; because linear algebra is &quot;the only subject mathematicians completely understand&quot;; but it seems we also understand a lot of nice things about quadratics as well  -- we have the aforementioned relationship with cones, a complete understanding of rational points, and the Pythagorean theorem (oh! and I just thought of quadratic reciprocity). 2 is also special in <a href=\"https://mathoverflow.net/questions/160811/what-is-exceptional-about-the-prime-numbers-2-and-3\">all sorts of algebraic contexts</a>, as well as being the <a href=\"https://math.stackexchange.com/questions/1199630/a-finite-field-extension-of-mathbb-r-is-either-mathbb-r-or-isomorphic-to\">only possible finite degree extension of <span class=\"math-container\">$\\mathbb R$</span></a>, leading to in particular <span class=\"math-container\">$\\mathbb C$</span> being 2-dimensional.</li>\n</ol>\n<p>Also interesting to note that many equations in physics are related to <span class=\"math-container\">$2$</span> (the second derivative, or inverse square laws), though that may be a stretch. I appreciate any ideas you share!</p>\n<p><span class=\"math-container\">$$\\rule{5cm}{0.4pt}$$</span></p>\n<p>EDIT 3/12/21: was just thinking about variances, and <a href=\"https://stats.stackexchange.com/questions/46019/why-squared-residuals-instead-of-absolute-residuals-in-ols-estimation?noredirect=1&amp;lq=1\">least squares regression</a>. &quot;<span class=\"math-container\">$2$</span>&quot; is extremely special in these areas: <a href=\"https://stats.stackexchange.com/questions/118/why-square-the-difference-instead-of-taking-the-absolute-value-in-standard-devia\">Why square the difference instead of taking the absolute value in standard deviation?</a>, <a href=\"https://mathoverflow.net/questions/1048/why-is-it-so-cool-to-square-numbers-in-terms-of-finding-the-standard-deviation\">Why is it so cool to square numbers (in terms of finding the standard deviation)?</a>, and the absolutely mindblowing animation of the physical realization of PCA with Hooke's law: <a href=\"https://stats.stackexchange.com/a/140579/264044\">Making sense of principal component analysis, eigenvectors &amp; eigenvalues</a>.</p>\n<p>In these links I just listed, seems like the most popular (but still not very satisfying to me) answer is that it's convenient (smooth, easy to minimize, variances sum for independent r.v.'s, etc), a fact that may be a symptom of a deeper connection with the Hilbert-space-iness of <span class=\"math-container\">$L^2$</span>. Also maybe something about how dealing with squares, Pythagoras gives us that <a href=\"https://stats.stackexchange.com/a/33654/264044\">minimizing reconstruction error is the same as maximizing projection variance in PCA</a>. Honorable mentions to <a href=\"https://mathoverflow.net/a/1089/112504\">Qiaochu Yuan's answer about rotation invariance</a>, and <a href=\"https://mathoverflow.net/a/211137/112504\">Aaron Meyerowitz's answer about the arithmetic mean being the unique minimizer of sum of squared distances from a given point.</a> As for the incredible alignment with our intuition in the form of the animation with springs and Hooke's law that I linked, I suppose I'll chalk that one up to coincidence, or <a href=\"https://www.youtube.com/watch?v=1qeWugmiGt4&amp;ab_channel=6Fxc24\" rel=\"nofollow noreferrer\">some sort of SF</a> ;)</p>\n<p><span class=\"math-container\">$$\\rule{5cm}{0.4pt}$$</span></p>\n<p>EDIT 2/11/22:\nI was thinking about Hilbert spaces, and then wondering again why they behave so nice, namely they have the closest point lemma (leading to orthogonal decomposition <span class=\"math-container\">$\\mathcal H = \\mathcal M \\oplus \\mathcal M^\\perp$</span> for closed subspaces <span class=\"math-container\">$\\cal M$</span>), or orthonormal bases (leading to Parseval's identity, convergence of a series of orthogonal elements if and only if the sum of the squared lengths converge), and I came to the conclusion that the key result each time seemed to be the <strong>Pythagorean theorem</strong> (e.g. the parallelogram law is an easy corollary of Pythag). So that begs the questions, why is the Pythagorean theorem so special? The linked article in the accepted answer of this question:  <a href=\"https://math.stackexchange.com/questions/2176723/what-does-the-pythagorean-theorem-really-prove\">What does the Pythagorean Theorem really prove?</a> tells us essentially the <strong>Pythagorean theorem boils down to the fact that right triangles can be subdivided into two triangles both similar to the original</strong>.</p>\n<p>The fact that this subdivision is reached by projecting the vertex onto the hypotenuse (projection deeply related to inner products) is likely also significant... ahh, indeed by the &quot;commutativity of projection&quot;, projecting a leg onto the hypotenuse is the same as projecting the hypotenuse onto the leg, but by orthogonality of the legs, the projection of the hypotenuse onto the leg is simply the leg itself! The <strong>square</strong> comes from the fact that projection scales proportionally to the scaling of each vector, and there are <strong>two</strong> vectors involved in the operation of projection.</p>\n<p>I suppose this sort of &quot;algebraic understanding&quot; of the projection explains the importance of &quot;2&quot; more than the geometry, since just knowing about the &quot;self-similarity of the subdivisions&quot; of the right triangle, one then has to wonder why say tetrahedrons or other shapes in other dimensions don't have this &quot;self-similarity of the subdivisions&quot; property. However it is still not clear to me why <strong>projection seems to be so fundamentally &quot;2-dimensional&quot;</strong>. Perhaps 1-dimensionally, there is the &quot;objective&quot; perception of the vector, and 2-dimensionally there is the &quot;subjective&quot; perception of one vector in the eyes of another, and there's just no good 3-dimensional perception for 3 vectors?</p>\n<p>There might also be some connection between the importance of projection and the importance of the Riesz representation theorem (all linear &quot;projections&quot; onto a 1-dimensional subspace, i.e. linear functionals, are actually literal projections against a vector in the space).</p>\n<p><span class=\"math-container\">$$\\rule{5cm}{0.4pt}$$</span></p>\n<p>EDIT 2/18/22: again touching on the degree 2 Diophantine equations I mentioned above, a classical example is the number of ways to write <span class=\"math-container\">$k$</span> as the sum of <span class=\"math-container\">$n$</span> squares <span class=\"math-container\">$r_n(k)$</span>. There are a <a href=\"https://users.ox.ac.uk/%7Equee4127/theta.pdf\" rel=\"nofollow noreferrer\">number of nice results</a> for this, the most famous being Fermat's 2-square theorem, and Jacobi's 4-square theorem. A key part of this proof was the use of the Poisson summation formula for the Euler/Jacobi theta function <span class=\"math-container\">$\\theta(\\tau) := \\sum_{n=-\\infty}^\\infty e^{i \\pi n^2 \\tau}$</span>, which depends on/is heavily related to the fact that Gaussians are stable under the Fourier transform. I still don't understand intuitively why this is the case (see <a href=\"https://math.stackexchange.com/questions/347630/intuitively-why-is-the-gaussian-the-fourier-transform-of-itself\">Intuitively, why is the Gaussian the Fourier transform of itself?</a>), but there seems to be some relation to Holder conjugates and <span class=\"math-container\">$L^p$</span> spaces (or in the Gaussian case, connections to <span class=\"math-container\">$L^2$</span>), since those show up in <a href=\"https://terrytao.wordpress.com/2021/01/23/246b-notes-2-some-connections-with-the-fourier-transform/#fo\" rel=\"nofollow noreferrer\">generalizations to the Hardy uncertainty principle</a> (<strong>“completing the square”, again an algebraic nicety of squares</strong>, was used in the proof of Hardy, and the Holder conjugates may have to do with the inequality <span class=\"math-container\">$-x^p + xu \\leq u^q$</span> -— Problem 4.1 in Stein and Shakarchi’s Complex analysis, where the LHS basically comes from computing the Fourier transform of <span class=\"math-container\">$e^{-x^p}$</span>) Of course why the Gaussian itself appears everywhere is another question altogether: <a href=\"https://mathoverflow.net/questions/40268/why-is-the-gaussian-so-pervasive-in-mathematics\">https://mathoverflow.net/questions/40268/why-is-the-gaussian-so-pervasive-in-mathematics</a>.</p>\n<p>This (squares leading to decent theory of <span class=\"math-container\">$r_n(k)$</span>, and squares leading to nice properties of the Gaussian) is probably also connected to the fact that <span class=\"math-container\">$\\int_{\\mathbb R} e^{-x^2} d x$</span> has a nice explicit value, namely <span class=\"math-container\">$\\sqrt \\pi$</span>. I tried seeing if there was a connection between this value of <span class=\"math-container\">$\\pi$</span> and the value of <span class=\"math-container\">$\\pi$</span> one gets from calculating the area of a circle &quot;shell-by-shell&quot; <span class=\"math-container\">$\\frac 1{N^2} \\sum_{k=0}^N r_2(k) \\to \\pi$</span>, but I couldn't find anything: <a href=\"https://math.stackexchange.com/questions/4385791/gaussian-integral-using-euler-jacobi-theta-function-and-r-2k-number-of-repr\">Gaussian integral using Euler/Jacobi theta function and $r_2(k)$ (number of representations as sum of 2 squares)</a>.</p>\n<p><span class=\"math-container\">$$\\rule{5cm}{0.4pt}$$</span></p>\n<p>EDIT 10/13/22: I was recently learning about Riemannian geometry, and indeed the <a href=\"https://en.wikipedia.org/wiki/Metric_tensor\" rel=\"nofollow noreferrer\">metric tensor</a> is a <strong>bi</strong>linear form (cf. above discussion on inner products), and the <a href=\"https://en.wikipedia.org/wiki/Riemann_curvature_tensor\" rel=\"nofollow noreferrer\">Riemann curvature tensor</a> (or curvature in general) is all about the <strong>second</strong> (covariant) derivative. <a href=\"https://terrytao.wordpress.com/2008/03/26/285g-lecture-0-riemannian-manifolds-and-curvature/\" rel=\"nofollow noreferrer\">Taking traces</a> we arrive at the Ricci curvature tensor (used in no less important things than Einstein's general relativity, whose &quot;classical approximation&quot; Newtonian gravity follows an inverse <strong>square</strong> law; and Perelman's proof of the Poincare conjecture!) or scalar curvature, which can be interpreted geometrically as the <strong>second-order</strong> change in volume of balls/base of cones (see <a href=\"https://math.stackexchange.com/a/469005/405572\">https://math.stackexchange.com/a/469005/405572</a> or Equation (10) of <a href=\"https://arxiv.org/pdf/2201.04923v1.pdf\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/2201.04923v1.pdf</a>).</p>\n<p>And of course like Ricci flow we also have the heat/diffusion differential equations (and the Schrodinger equation, <a href=\"https://physics.stackexchange.com/a/505164/222958\">quoting James Gleck</a>, is &quot;diffusion through imaginary time&quot;), and endless equations involving the Laplacian, all second-order differential equations (how AMAZING that the two great pillars of 20th century physics, general relativity and quantum mechanics both have at their hearts second-order differential equations! And the fact that observables in quantum mechanics are <a href=\"https://physics.stackexchange.com/questions/678152/what-is-the-actual-use-of-hilbert-spaces-in-quantum-mechanics\">modeled as operators on <strong>Hilbert</strong> spaces</a>). Relating to the Laplacian, we have the important concept of <a href=\"https://en.wikipedia.org/wiki/Harmonic_function\" rel=\"nofollow noreferrer\">harmonicity</a>, with beautiful manifestations/consequences in <a href=\"https://terrytao.wordpress.com/2016/10/02/math-246a-notes-3-cauchys-theorem-and-its-consequences/#holosmooth\" rel=\"nofollow noreferrer\">complex analysis, or PDEs, in the form of elliptic regularity</a>. Besides tensors of 2nd derivatives, we have the ever-present <a href=\"https://en.wikipedia.org/wiki/Hessian_matrix\" rel=\"nofollow noreferrer\">Hessian matrix</a> of second derivatives. I'll end with some quotes from a MO answer I linked here in a comment several months ago (<a href=\"https://mathoverflow.net/a/171743/112504\">https://mathoverflow.net/a/171743/112504</a>) which tries to argue that &quot;Polynomials are useful because quadratic polynomials are useful.&quot;:</p>\n<blockquote>\n<p>So the question becomes: why are quadratic polynomials useful? There seem to be two different but interacting reasons. The first is that quadratic functions of a real variable are always either convex or concave and therefore have a unique maximum or minimum. The second is that quadratic functions are intimately related to bilinear forms and therefore can be accessed using linear algebra. The combination of these two reasons seems to explain the success of quadratic algebra in analysis and geometry (e.g. Hilbert spaces, Riemannian manifolds)</p>\n</blockquote>\n", "pids": ["56d890fddabfae2eeee7b3c4"], "flag": 0}
{"question": "Do error bars on probabilities have any meaning?", "body": "<p>People often say some event has a 50-60% chance of happening. Sometimes I will even see people give explicit error bars on probability assignments. Do these statements have any meaning or are they just a linguistic quirk of discomfort choosing a specific number for something that is inherently unknowable?</p>\n", "pids": ["53e9b9f5b7602d97045f2084", "53e99a43b7602d970229fa85"], "flag": 1}
{"question": "What does closed form solution usually mean?", "body": "<p>This is motivated by <a href=\"https://math.stackexchange.com/questions/8933\">this question</a> and the fact that I have no access to Timothy Chow's paper <em><a href=\"http://www.jstor.org/pss/2589148\" rel=\"noreferrer\">What Is a Closed-Form Number?</a></em> indicated there by\nQiaochu Yuan.</p>\n\n<p>If an equation $f(x)=0$ has no closed form solution, what does it normally\nmean? Added: $f$ may depend (and normally does) on parameters. </p>\n\n<p>To me this is equivalent to say that one cannot solve it for $x$ in\nthe sense that there is no elementary expression $g(c_{1},c_{2},\\ldots\n,c_{p})$ consisting only of a finite number of polynomials, rational\nfunctions, roots, exponentials, logarithmic and trigonometric functions,\nabsolute values, integer and fractional parts, such that </p>\n\n<p>$f(g(c_{1},c_{2},\\ldots ,c_{p}))=0$.</p>\n", "pids": ["53e9a9f0b7602d970335659b"], "flag": 0}
{"question": "Was Grothendieck familiar with Stone&#39;s work on Boolean algebras?", "body": "<p>In short, my question is:</p>\n\n<blockquote>\n  <p>Was Grothendieck familiar with Stone's work on Boolean algebras?</p>\n</blockquote>\n\n<p><strong>Background:</strong></p>\n\n<p>In an answer to Pierre-Yves Gaillard's question <em><a href=\"https://math.stackexchange.com/q/55259/\">Did Zariski really define the Zariski topology on the prime spectrum of a ring?</a></em> I let myself get carried away and explained a result of Grothendieck that (for me) implies that Grothendieck certainly was familiar with Stone's work on spectra and even proved theorems with it. Qiaochu suggested that I ask a question and answer myself (apparently <a href=\"http://blog.stackoverflow.com/2011/07/its-ok-to-ask-and-answer-your-own-questions/\">officially encouraged</a>, see his remark), so I'm doing that in order to avoid an off-topic answer to Pierre-Yves's question. </p>\n\n<p>Qiaochu's accepted answer quotes excerpts from Johnstone's <em><a href=\"http://books.google.com/books?id=CiWwoLNbpykC\" rel=\"noreferrer\">Stone spaces</a></em> that seem to imply that Grothendieck never quoted Stone. Precisely I'm having the following passage in mind:</p>\n\n<blockquote>\n  <p>But again, one will not find any reference to Stone in the work of Grothendieck, even though his use of the word 'spectrum' is an obvious echo of <a href=\"http://www.ams.org/mathscinet-getitem?mr=2023\" rel=\"noreferrer\">[Stone 1940]</a>, and Grothendieck, with his background in functional analysis, must have been familiar with Stone's work in that field.</p>\n</blockquote>\n\n<p>I did <em>not</em> seriously try to verify or falsify the first part of the sentence (and please do provide references if you happen to know of them). My own long answer addresses the second part of the sentence and tries to make a point that <em>must have been</em> should be replaced by <em>was</em>.</p>\n\n<p>Now fire away and complain about this being a nitpick, but I'm trying to explain a nice and interesting piece of mathematics and both Jonas Meyer and Qiaochu Yuan said I should post this answer, so: that's what I'm doing here.</p>\n", "pids": ["62173edc5aee126c0f872723", "621752915aee126c0fc0de34"], "flag": 0}
{"question": "Continuous generalization of the negative binomial distribution", "body": "<p><a href=\"https://en.wikipedia.org/wiki/Negative_binomial_distribution\" rel=\"noreferrer\">Negative binomial (NB) distribution</a> is defined on non-negative integers and has probability mass function$$f(k;r,p)={\\binom {k+r-1}{k}}p^{k}(1-p)^{r}.$$ Does it make sense to consider a continuous distribution on non-negative reals defined by the same formula (replacing $k\\in \\mathbb N_0$ by $x\\in\\mathbb R_{\\ge 0}$)? The binomial coefficient can be rewritten as a product of $(k+1)\\cdot\\ldots\\cdot(k+r-1)$, which is well-defined for any real $k$. So we would have a PDF $$f(x;r,p)\\propto\\prod_{i=1}^{r-1}(x+i)\\cdot p^{x}(1-p)^{r}.$$\nMore generally, we can replace the binomial coefficient with Gamma functions, allowing for non-integer values of $r$:\n$$f(x;r,p)\\propto\\frac{\\Gamma(x+r)}{\\Gamma(x+1)\\Gamma(r)}\\cdot p^{x}(1-p)^{r}.$$</p>\n\n<p>Is it a valid distribution? Does it have a name? Does it have any uses? Is it maybe some compound or a mixture? Are there closed formulas for the mean and the variance (and the proportionality constant in the PDF)? </p>\n\n<p><em>(I am currently studying <a href=\"http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2006387\" rel=\"noreferrer\">a paper that uses NB mixture model</a> (with fixed $r=2$) and fits it via EM. However, the data are integers after some normalization, i.e. not integers. Nevertheless, the authors apply the standard NB formula to compute the likelihood and get very reasonable results, so everything seems to work out just fine. I found it very puzzling. Note that this question is <strong>not</strong> about NB GLM.)</em></p>\n", "pids": ["5c136694da56295a089e56c9"], "flag": 1}
{"question": "Which derivatives are eventually periodic?", "body": "<p>Which derivatives are eventually periodic?</p>\n\n<p>I have noticed that is $a_{n}=f^{(n)}(x)$, the sequence $a_{n}$ becomes eventually periodic for a multitude of $f(x)$. </p>\n\n<p>If $f(x)$ was a polynomial, and $\\operatorname{deg}(f(x))=n$, note that $f^{(n)}(x)=C$ if $C$ is a constant. This implies that  $f^{(n+i)}(x)=0$ for every $i$ which is a natural number. </p>\n\n<p>If $f(x)=e^x$, note that $f(x)=f'(x)$. This implies that $f^{(n)}(x)=e^x$ for every natural number $n$. </p>\n\n<p>If $f(x)=\\sin(x)$, note that $f'(x)=\\cos(x), f''(x)=-\\sin(x), f'''(x)=-\\cos(x), f''''(x)=\\sin(x)$.</p>\n\n<p>This implies that $f^{(4n)}(x)=f(x)$ for every natural number $n$. </p>\n\n<p>In a similar way, if $f(x)=\\cos(x)$, $f^{(4n)}(x)=f(x)$ for every natural number $n$.</p>\n\n<p>These appear to be the only functions whose derivatives become eventually periodic. </p>\n\n<p>What are other functions whose derivatives become eventually periodic? What is known about them? Any help would be appreciated. </p>\n", "pids": ["5d9edb7947c8f7664601b034"], "flag": 0}
{"question": "What&#39;s the intuition behind contrastive learning or approach?", "body": "<p>Maybe a noobs query, but recently I have seen a surge of papers w.r.t contrastive learning (a subset of semi-supervised learning).</p>\n<p>Some of the prominent and recent research papers which I read, which detailed this approach are:</p>\n<ul>\n<li>Representation Learning with Contrastive Predictive Coding\n@ <a href=\"https://arxiv.org/abs/1807.03748\" rel=\"noreferrer\">https://arxiv.org/abs/1807.03748</a></li>\n<li>SimCLR-v1: A Simple Framework for Contrastive Learning of Visual Representations @ <a href=\"https://arxiv.org/abs/2002.05709\" rel=\"noreferrer\">https://arxiv.org/abs/2002.05709</a></li>\n<li>SimCLR-v2: Big Self-Supervised Models are Strong Semi-Supervised Learners @ <a href=\"https://arxiv.org/abs/2006.10029\" rel=\"noreferrer\">https://arxiv.org/abs/2006.10029</a></li>\n<li>MoCo-v1: Momentum Contrast for Unsupervised Visual Representation Learning @ <a href=\"https://arxiv.org/abs/1911.05722\" rel=\"noreferrer\">https://arxiv.org/abs/1911.05722</a></li>\n<li>MoCo-v2: Improved Baselines with Momentum Contrastive Learning @ <a href=\"https://arxiv.org/abs/2003.04297\" rel=\"noreferrer\">https://arxiv.org/abs/2003.04297</a></li>\n<li>PIRL: Self-Supervised Learning of Pretext-Invariant Representations @ <a href=\"https://arxiv.org/abs/1912.01991\" rel=\"noreferrer\">https://arxiv.org/abs/1912.01991</a></li>\n</ul>\n<p>Could you guys give a detailed explanation of this approach vs transfer learning and others?\nAlso, why it's gaining traction amongst the ML research community?</p>\n", "pids": ["5e67655391e011e0d1791392"], "flag": 1}
{"question": "Why second order SGD convergence methods are unpopular for deep learning?", "body": "<p>It seems that, especially for deep learning, there are dominating very simple methods for optimizing SGD convergence like ADAM - nice overview: <a href=\"http://ruder.io/optimizing-gradient-descent/\" rel=\"nofollow noreferrer\">http://ruder.io/optimizing-gradient-descent/</a></p>\n<p>They <strong>trace only single direction</strong> - discarding information about the remaining ones, they <strong>do not try to estimate distance from near extremum</strong> - which is suggested by gradient evolution (<span class=\"math-container\">$\\rightarrow 0$</span> in extremum), and could help with the crucial choice of step size.</p>\n<p>Both these missed opportunities could be exploited by second order methods - trying to locally model parabola in simultaneously multiple directions (not all, just a few), e.g. near saddle attracting in some directions, repulsing in the others. Here are some:</p>\n<ul>\n<li>L-BFGS: <a href=\"http://aria42.com/blog/2014/12/understanding-lbfgs\" rel=\"nofollow noreferrer\">http://aria42.com/blog/2014/12/understanding-lbfgs</a></li>\n<li>TONGA: <a href=\"https://papers.nips.cc/paper/3234-topmoumoute-online-natural-gradient-algorithm\" rel=\"nofollow noreferrer\">https://papers.nips.cc/paper/3234-topmoumoute-online-natural-gradient-algorithm</a></li>\n<li>K-FAC: <a href=\"https://arxiv.org/pdf/1503.05671.pdf\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/1503.05671.pdf</a></li>\n<li>saddle-free Newton: <a href=\"https://arxiv.org/pdf/1406.2572\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/1406.2572</a></li>\n<li>my second order local parametrization: <a href=\"https://arxiv.org/pdf/1901.11457\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/1901.11457</a></li>\n</ul>\n<p>But still first order methods dominate (?), I have heard opinions that second order just don't work for deep learning (?)</p>\n<p>There are mainly 3 challenges (any more?): <strong>inverting Hessian</strong>, <strong>stochasticity</strong> of gradients, and handling <strong>saddles</strong>. All of them should be resolved if locally modelling parametrization as parabolas in a few promising directions (I would like to use): update this parametrization based on calculated gradients, and perform proper step based on this parametrization. This way extrema can be in updated parameters - no Hessian inversion, slow evolution of parametrization allows to accumulate statistical trends from gradients, we can model both curvatures near saddles: correspondingly attract or repulse, with strength depending on modeled distance.</p>\n<p><strong>Should we go toward second order methods for deep learning?</strong></p>\n<p>Why is it so difficult to make them more successful than simple first order methods - could we <strong>identify these challenges</strong> ... resolve them?</p>\n<p>As there are many ways to realize second order methods, which seems the most promising?</p>\n<p>Update: Overview of SGD convergence methods including 2nd order: <a href=\"https://www.dropbox.com/s/54v8cwqyp7uvddk/SGD.pdf\" rel=\"nofollow noreferrer\">https://www.dropbox.com/s/54v8cwqyp7uvddk/SGD.pdf</a></p>\n<p>Update: There are criticized huge 2nd order methods, but we can work on the opposite end of cost spectrum: make tiny steps from successful 1st order methods, like just cheap <a href=\"https://arxiv.org/abs/1907.07063\" rel=\"nofollow noreferrer\">online parabola model</a> in single direction e.g. of momentum method for smarter choice of step size - are there interesting approaches for such 2nd order enhancement of 1st order methods?\n<a href=\"https://i.stack.imgur.com/ai1ks.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/ai1ks.png\" alt=\"enter image description here\" /></a></p>\n<p>Update: 2D example of SGD augmented with 2nd order information from sequence of gradients (<a href=\"https://github.com/JarekDuda/SGD-OGR-Hessian-estimator\" rel=\"nofollow noreferrer\">github</a>):\n<a href=\"https://i.stack.imgur.com/ooAGS.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/ooAGS.png\" alt=\"enter image description here\" /></a></p>\n", "pids": ["5cede0fbda562983788dadf1", "5ce2d20aced107d4c6493fc1", "5ed623da91e01198019afbe0", "6576c085939a5f4082a215a3", "57a4e91aac44365e35c979f6"], "flag": 1}
{"question": "Cauchy&#39;s integral formula for Cayley-Hamilton Theorem", "body": "<p>I'm just working through Conway's book on complex analysis and I stumbled across this lovely exercise:</p>\n\n<blockquote>\n  <p>Use Cauchy's Integral Formula to prove the Cayley-Hamilton Theorem: If $A$ is an $n \\times n$ matrix over $\\mathbb C$ and $f(z)  = \\det(z-A)$ is the characteristic polynomial of $A$ then $f(A) = 0$. (This exercise was taken from a paper by C. A. McCarthy, <em>Amer. Math. Monthly</em>, <strong>82</strong> (1975), 390-391)</p>\n</blockquote>\n\n<p>Unfortunately, I was not able to find said paper. I'm completely lost with this exercise. I can't even start to imagine how one could possibly make use of Cauchy here...</p>\n\n<p>Thanks for any hints.</p>\n\n<p>Regards, S.L.</p>\n", "pids": ["5ce2d133ced107d4c6401868"], "flag": 0}
{"question": "Non-power-of-2 FFT&#39;s?", "body": "<p>If I have a program that can compute FFT's for sizes that are powers of 2, how can I use it to compute FFT's for other sizes?</p>\n\n<p>I have read that I can supposedly zero-pad the original points, but I'm lost as to how this gives me the correct answer. If I transform a function with 5 points, I expect to get back a 5-point DFT, and I don't understand how I can extract that from the 8-point DFT (which was calculated with zero-padding).</p>\n", "pids": ["6356bf6b90e50fcafd235df8"], "flag": 0}
{"question": "Do negative probabilities/probability amplitudes have applications outside quantum mechanics?", "body": "<p>Quantum Mechanics has generalized probability theory to negative/imaginary numbers, mostly to explain interference patterns, wave/particle duality and generally weird things like that. It can be seen more abstractly, however, as a noncommutative generalisation of Bayesian probability (quote from Terrence Tao). I'm curious about these things, though by no means an expert. Does this have any applications outside Quantum Mechanics? Just curious.</p>\n", "pids": ["53e9ab73b7602d970351631c"], "flag": 1}
{"question": "The resemblance between Mordell&#39;s theorem and Dirichlet&#39;s unit theorem", "body": "<p>The first one states that if $E/\\mathbf Q$ is an elliptic curve, then $E(\\mathbf Q)$ is a finitely generated abelian group. </p>\n\n<p>If $K/\\mathbf Q$ is a number field, Dirichlet's theorem says (among other things) that the group of units $\\mathcal O_K^\\times$ is finitely generated. </p>\n\n<p>The proof of Mordell's theorem and the proof of Dirichlet's theorem are somewhat similar (a covolume calculation in one case, and what feels to me like bounding a covolume in the other).</p>\n\n<p>How can these two objects be realized as instances of the same construction?  Could it be done so well as to reduce the proof of Mordell-Weil and Dirichlet's theorems to a single proof?</p>\n\n<p>In the correspondence between the class number formula and the conjectured formula for the leading term of $L(E/\\mathbf Q, s)$ , it appears that $\\mathcal O_K^\\times$ really does play the role of $E(\\mathbf Q)$ (regulator corresponds to regulator, torsion to torsion). From my understanding, the general belief is that these two objets are analogous. But I'm having a hard time putting them on the same footing. </p>\n\n<p>In fact, there is a generalization of the Birch &amp; Swinnerton-Dyer conjecture to any abelian variety over $\\mathbf Q$, but in this case the conjectured leading term of the $L$-function is symmetric in $A$ and $\\breve{A}$ (where $\\breve{A}$ is the dual abelian variety). This conjecture degenerates to the BSD conjecture in the case of an elliptic curve, which is self-dual. </p>\n\n<p>But $\\mathcal O^\\times$ isn't an abelian variety. At best, $\\mathcal O_K^\\times$ can be thought as the $\\mathcal O_K$-valued points of the group scheme $\\mathbf G_m = \\text{Spec }(\\mathbf Z[x,y]/(xy-1))$. But: (1), $\\mathbf G_m$ isn't an abelian variety over any field, and (2), we are looking at its points in the ring of integers of a number field, rather than in a field. So, why should we expect it to be the same as $E(\\mathbf Q)$?</p>\n\n<p>Or, perhaps $E(\\mathbf Q)$ and $\\mathcal O_K^\\times$ the wrong objects to be trying to compare? </p>\n", "pids": ["53e9b2b2b7602d9703d5e973"], "flag": 0}
{"question": "Definition of autocorrelation time (for effective sample size)", "body": "<p>I've found two definitions in the literature for the autocorrelation time of a weakly stationary time series:</p>\n\n<p>$$\n\\tau_a = 1+2\\sum_{k=1}^\\infty \\rho_k \\quad \\text{versus} \\quad \\tau_b = 1+2\\sum_{k=1}^\\infty \\left|\\rho_k\\right|\n$$</p>\n\n<p>where $\\rho_k = \\frac{\\text{Cov}[X_t,X_{t+h}]}{\\text{Var}[X_t]}$ is the autocorrelation at lag $k$.  </p>\n\n<p>One application of the autocorrelation time is to find the \"effective sample size\": if you have $n$ observations of a time series, and you know its autocorrelation time $\\tau$, then you can pretend that you have</p>\n\n<p>$$\nn_\\text{eff} = \\frac{n}{\\tau}\n$$</p>\n\n<p>independent samples instead of $n$ correlated ones for the purposes of finding the mean.  Estimating $\\tau$ from data is non-trivial, but there are a few ways of doing it (see <a href=\"http://arxiv.org/abs/1011.0175\">Thompson 2010</a>).</p>\n\n<p>The definition without absolute values, $\\tau_a$, seems more common in the literature; but it admits the possibility of $\\tau_a&lt;1$.  Using R and the \"coda\" package:</p>\n\n<pre><code>require(coda)\nts.uncorr &lt;- arima.sim(model=list(),n=10000)         # white noise \nts.corr &lt;- arima.sim(model=list(ar=-0.5),n=10000)    # AR(1)\neffectiveSize(ts.uncorr)                             # Sanity check\n    # result should be close to 10000\neffectiveSize(ts.corr)\n    # result is in the neighborhood of 30000... ???\n</code></pre>\n\n<p>The \"effectiveSize\" function in \"coda\" uses a definition of the autocorrelation time equivalent to $\\tau_a$, above.  There are some other R packages out there that compute effective sample size or autocorrelation time, and all the ones I've tried give results consistent with this:  that an AR(1) process with a negative AR coefficient has <em>more</em> effective samples than the correlated time series.  This seems strange.  </p>\n\n<p>Obviously, this can never happen in the $\\tau_b$ definition of autocorrelation time.</p>\n\n<p>What is the correct definition of autocorrelation time?  Is there something wrong with my understanding of effective sample sizes?  The $n_\\text{eff} &gt; n$ result shown above seems like it must be wrong... what's going on?</p>\n", "pids": ["56d870a0dabfae2eeef1cfbd"], "flag": 1}
{"question": "Why are neural networks described as black-box models?", "body": "<p>I often hear people talking about neural networks as something as a black-box that you don't understand what it does or what they mean. I actually I can't understand what they mean by that! If you understand how back-propagation works, then how is it a black-box? </p>\n\n<p>Do they mean that we don't understand how the weights that were computed or what?</p>\n", "pids": ["5736960e6e3b12023e520c34"], "flag": 1}
{"question": "Fermat&#39;s Last Theorem near misses?", "body": "<p>I've recently seen a video of Numberphille channel on Youtube about Fermat's Last Theorem. It talks about how there is a given &quot;solution&quot; for the Fermat's Last Theorem for <span class=\"math-container\">$n&gt;2$</span> in the animated series The Simpsons.</p>\n<p>Thanks to Andrew Wiles, we all know that's impossible. The host tells that the solution that appears in the episode is actually a near miss.</p>\n<p>There are two near-miss solutions and they are:</p>\n<p><span class=\"math-container\">$$3987^{12} + 4365^{12} \\stackrel{?}{=} 4472^{12}$$</span></p>\n<p><span class=\"math-container\">$$1782^{12} + 1841^{12} \\stackrel{?}{=} 1922^{12}$$</span></p>\n<p>Anyone who knows modular arithmetic can check that those solutions are wrong, even without a calculator. You can check that <span class=\"math-container\">$87^{12} \\equiv 81 \\pmod{100}$</span> and <span class=\"math-container\">$65^{12} \\equiv 25 \\pmod {100}$</span>, while <span class=\"math-container\">$72^{12} \\equiv 16 \\pmod {100}$</span>. So we have:\n<span class=\"math-container\">$$\n81 + 25 \\stackrel{?}{\\equiv} 16 \\pmod {100}\n$$</span>\n<span class=\"math-container\">$$\n106 \\stackrel{?}{\\equiv} 16 \\pmod {100}\n$$</span>\nwhich is obviously wrong.</p>\n<p>For the second example it's even easier. We know that LHS is an addition of an even and odd number, and the RHS is even number, which is impossible, because we know that the addition of an even and an odd number will provide an odd number.</p>\n<p>But what's made me most interested in this is the following. Using a calculator I expanded the equations and I get:</p>\n<p><span class=\"math-container\">$$3987^{12} + 4365^{12} \\stackrel{?}{=} 4472^{12}$$</span></p>\n<p><span class=\"math-container\">$$63976656349698612616236230953154487896987106 \\stackrel{?}{=} 63976656348486725806862358322168575784124416$$</span></p>\n<p><span class=\"math-container\">$$1211886809373872630985912112862690 \\stackrel{?}{=} 0$$</span></p>\n<p>And you'll immediately conclude that those numbers aren't even close, their difference is a 33-digit number. But bearing in mind that we are working with really, really big numbers, it's probably better to take relative difference. So we really want to find the ratio of LHS and RHS:\n<span class=\"math-container\">$$\n\\frac{63976656349698612616236230953154487896987106}{63976656348486725806862358322168575784124416} \\approx 1.00000000002\n$$</span>\nSomehow that's impressive, but if take a look into the second example the things start to get more interesting:</p>\n<p><span class=\"math-container\">$$\n1782^{12} + 1841^{12} \\stackrel{?}{=} 1922^{12}\n$$</span>\n<span class=\"math-container\">$$\n2541210258614589176288669958142428526657 \\stackrel{?}{=} 2541210259314801410819278649643651567616\n$$</span></p>\n<p>As we can see the first 9 digits are exactly the same and the apsolute difference is: <span class=\"math-container\">$700212234530608691501223040959$</span>. But if we take a relative difference or ratio we'll get:\n<span class=\"math-container\">$$\n\\frac{2541210258614589176288669958142428526657}{2541210259314801410819278649643651567616} \\approx 0.9999999997244572\n$$</span>\nAnd this is pretty amazing, because if we make comparison using smaller number this is the same as comparing <span class=\"math-container\">$10\\, 000\\, 000\\, 000$</span> and <span class=\"math-container\">$10\\, 000\\, 000\\, 001$</span></p>\n<p>Probably there are many more, probably infinite amount of such &quot;close&quot; examples, but are there any known examples? Is there any list of them?</p>\n<p>And as user17762 commented it would be nice to find a bound <span class=\"math-container\">$\\phi(n) = \\inf\\{\\left| x^n + y^n - z^n\\right| : x,y,z \\in \\mathbb{Z}\\}$</span>, although I would be more interested in finding the ratio bound, such that the ratio is closer to <span class=\"math-container\">$1$</span></p>\n<p>Also as user17762 pointed Taxicab can be used to provide a really close examples for <span class=\"math-container\">$n=3$</span>, but what about other values for <span class=\"math-container\">$n$</span>?</p>\n", "pids": ["5f0e62bf9fced0a24becccb7"], "flag": 0}
{"question": "How were &#39;old-school&#39; mathematics graphics created?", "body": "<p>I really enjoy the style of technical diagrams in many mathematics books published in the mid-to-late 20th century. For example, and as a starting point, here is a picture that I just saw today: </p>\n\n<p><a src=\"https://i.stack.imgur.com/CspxI.png\" alt=\"From Berry and Howls in Nonlinearity 3 (1990) 281-291\"></p>\n\n<p>Does anybody know how this graphic was created? Were equations used for the surfaces and then a plotting program used? How was the line-hatching achieved? Here is a another gorgeous picture from David Hilbert's \"Geometry and the Imagination\": </p>\n\n<p><a src=\"https://i.stack.imgur.com/X9u5O.png\" alt=\"Hilbert&#39;s book\"></p>\n\n<p>Again, how was this created? Was it done by hand, then scanned in? </p>\n\n<p>More pressingly: how do <em>I</em> create these kinds of images? Certainly, most of us are familiar with Matlab, Geogebra, gnuplot, or other software for creating mathematical figures, as we are also familiar with vector-based programs like Inkscape and Adobe Illustrator. I've looked at 'old-school' programs like <a href=\"http://ipe7.sourceforge.net/\" rel=\"noreferrer\">IPE</a> (a little bit like XFig), but still, I don't find them as attractive as the examples above. There is then LaTeX solutions like TikZ. I guess they must surely be hand-drawn, but I would like to know about the process for how these were drawn (and the equipment used). </p>\n\n<p>By way of note, there is <a href=\"http://golem.ph.utexas.edu/category/2010/03/modeling_surface_diagrams.html\" rel=\"noreferrer\">an article here</a> about trying to use 3d modeling programs and shaders to duplicate hand-drawn figures. </p>\n", "pids": ["53e9a922b7602d9703275ef1"], "flag": 0}
{"question": "Other interesting consequences of $d=163$?", "body": "<p><strong><em>Question</em></strong>: Any other interesting consequences of $d=163$ having class number $h(-d)=1$ aside from the list below?</p>\n\n<p>Let $\\tau = \\tfrac{1+\\sqrt{-163}}{2}$. We have (see notes at end of list),</p>\n\n<p>$$e^{\\pi\\sqrt{163}}\\approx 640320^3+743.99999999999925\\dots\\tag{1}$$</p>\n\n<p>$$B(n) = 4n^2+163\\tag{2}$$</p>\n\n<p>$$F(n) = n^2+n+41\\tag{3a}$$</p>\n\n<p>$$P(n) = 9n^2-163\\cdot3n+163\\cdot41\\tag{3b}$$</p>\n\n<p>$$1^2+40^2=42^2-163\\tag{4}$$</p>\n\n<p>$$u^3-6u^2+4u \\approx 1.999999999999999999999999999999977\\dots\\tag{5}$$</p>\n\n<p>$$5y^6 - 640320y^5 - 10y^3 + 1 =0\\tag{6}$$</p>\n\n<p>$$163(12^3+640320^3) = 12^2\\cdot \\color{blue}{545140134}^2\\tag{7}$$</p>\n\n<p>$$12\\sum_{n=0}^\\infty (-1)^n \\frac{(6n)!}{n!^3(3n)!}  \\frac{\\color{blue}{545140134}\\,n+13591409}{(640320^3)^{n+1/2}} = \\frac{1}{\\pi}\\tag{8}$$</p>\n\n<p>$$12\\sum_{n=0}^\\infty (-1)^n\\, G_1  \\frac{\\color{blue}{545140134}\\,(n+m)+13591409}{(640320^3)^{n+m+1/2}} = \\frac{1}{2^6}\\ln\\left(\\frac{3^{21}\\cdot5^{13}\\cdot29^5}{2^{38}\\cdot23^{11}}\\right)\\tag{9}$$</p>\n\n<p>$$\\frac{E_{4}(\\tau)}{\\left(E_2(\\tau)-\\frac{6}{\\pi\\sqrt{163}}\\right)^2}=\\frac{5\\cdot23\\cdot29\\cdot163}{2^2\\cdot3\\cdot181^2}\\tag{10a}$$</p>\n\n<p>$$\\frac{E_{6}(\\tau)}{\\left(E_2(\\tau)-\\frac{6}{\\pi\\sqrt{163}}\\right)^3}=\\frac{7\\cdot11\\cdot19\\cdot127\\cdot163^2}{2^9\\cdot181^3}\\tag{10b}$$</p>\n\n<p>$$640320 = 2^6\\cdot 3\\cdot 5\\cdot 23\\cdot 29\\tag{11a}$$</p>\n\n<p>$$\\color{blue}{545140134}/163 = 2\\cdot 3^2\\cdot 7\\cdot 11\\cdot 19\\cdot 127\\tag{11b}$$</p>\n\n<p>$$x^3-6x^2+4x-2=0,\\;\\;\\text{where}\\; x = e^{\\pi i/24}\\frac{\\eta(\\tau)}{\\eta(2\\tau)}=5.31863\\dots\\tag{12}$$</p>\n\n<p>$$x = 2+2\\sqrt[3]{a+2\\sqrt[3]{a+2\\sqrt[3]{a+2\\sqrt[3]{a+\\cdots}}}} = 5.31863\\dots\\;\\text{where}\\;a=\\tfrac{5}{4}\\tag{13}$$</p>\n\n<p>$$\\frac{x^{24}-256}{x^{16}} = 640320\\tag{14}$$</p>\n\n<p>$$K(k_{163}) = \\frac{\\pi}{2} \\sqrt{\\sum_{n=0}^\\infty  \\frac{(2n)!^3}{n!^6}  \\frac{1}{x^{24n}} }=1.57079\\dots\\tag{15a}$$</p>\n\n<p>$$K(k_{163}) = \\frac{\\pi}{2} \\frac{x^2 }{640320^{1/4}}  \\sqrt{\\sum_{n=0}^\\infty  \\frac{(6n)!}{n!^3(3n)!}  \\frac{1}{(-640320^3)^{n}} }\\tag{15b}$$</p>\n\n<p>$$K(k_{163}) = \\frac{\\pi}{2} \\frac{x^2 }{640320^{1/4}}\\,_2F_1(\\tfrac{1}{6},\\tfrac{5}{6},1,\\alpha) \\tag{16a}$$</p>\n\n<p>$$\\frac{\\,_2F_1(\\tfrac{1}{6},\\tfrac{5}{6},1,1-\\alpha)}{\\,_2F_1(\\tfrac{1}{6},\\tfrac{5}{6},1,\\alpha)}=-\\frac{1+\\sqrt{-163}}{2}\\,i \\tag{16b}$$</p>\n\n<p>$$\\alpha = \\frac{1}{2}\\Big(1-\\sqrt{1+1728/640320^3}\\Big)\\tag{17}$$</p>\n\n<p>$$K(k_{163}) = \\frac{\\pi}{2} \\frac{x^2 }{163^{1/4}(2\\pi)^{41}}\\Gamma(\\tfrac{1}{163})\\,\\Gamma(\\tfrac{4}{163})\\,\\Gamma(\\tfrac{6}{163})\\dots\\Gamma(\\tfrac{161}{163})  \\tag{18}$$</p>\n\n<p>$$\\frac{(e^{\\pi\\sqrt{163}})^{1/24}}{x} = 1+\\cfrac{q}{1-q+\\cfrac{q^3-q^2}{1+\\cfrac{q^5-q^3}{1+\\cfrac{q^7-q^4}{1+ \\ddots}}}}\\tag{19}$$</p>\n\n<p>$$\\frac{(e^{\\pi\\sqrt{163}})^{1/8}}{x^2}\\frac{\\eta(\\tau)}{e^{\\pi i/24}} = \\cfrac{1}{1-\\cfrac{q}{1+q-\\cfrac{q^2}{1+q^2-\\cfrac{q^3}{1+q^3-\\ddots}}}}\\tag{20}$$</p>\n\n<p>$$\\frac{(e^{\\pi\\sqrt{163}})^{1/8}}{\\sqrt{2}\\,\\big(1/k_{163}-1\\big)^{1/8}} = \\cfrac{1}{1+\\cfrac{q}{1+q+\\cfrac{q^2}{1+q^2+\\cfrac{q^3}{1+q^3+\\ddots}}}}\\tag{21}$$</p>\n\n<p>$$\\text{Moonshine}_{\\,d}=163\\tag{22}$$</p>\n\n<p><em>Notes</em>:</p>\n\n<ol>\n<li>The exact value of the j-function $j(\\tau)=-640320^3= -12^3(231^2-1)^3$.</li>\n<li>Is prime for $0\\leq n \\leq 19$. (OEIS <a href=\"http://oeis.org/A057604\" rel=\"noreferrer\">link</a>)</li>\n<li>Euler's polynomial (a) is prime for $0\\leq n \\leq 39$, while (b) is prime for $1\\leq n \\leq 40$ (but yields different values from the former).</li>\n<li>As observed by Adam Bailey and Mercio <a href=\"https://math.stackexchange.com/questions/165698/on-the-diophantine-equation-a2b2-c2k#comment387693_167805\">in this comment</a>, Euler's polynomial implies the smallest positive integer $c$ to the Diophantine equation $a^2+b^2=c^2-163$ can't be $c&lt;41$.</li>\n<li>Where $u=(e^{\\pi\\sqrt{163}}+24)^{1/24}$.</li>\n<li>Where $y\\approx\\frac{1}{5}(e^{\\pi\\sqrt{163}}+6)^{1/3}$. (The sextic factors over $\\sqrt{5}$ hence has a solvable Galois group).</li>\n<li>The perfect square appears in the pi formula.</li>\n<li>By the Chudnovsky brothers (based on Ramanujan's formulas).</li>\n<li>By J. Guillera in this <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?rep=rep1&amp;type=pdf&amp;doi=10.1.1.211.6376\" rel=\"noreferrer\">paper</a>. Let $G_1 = 12^{3n} (\\frac{1}{2}+m)_n (\\frac{1}{6}+m)_n  (\\frac{5}{6}+m)_n (m+1)_n^{-3}$ where $m = \\frac{1}{2}$ and $(x)_n$ is the <a href=\"http://mathworld.wolfram.com/PochhammerSymbol.html\" rel=\"noreferrer\">Pochhammer symbol</a>.</li>\n<li>$E_n$ are Eisenstein series. More details in this <a href=\"https://mathoverflow.net/questions/107467/eisenstein-series-and-163\">MO post</a>.</li>\n<li>The prime factors of $j(\\tau)$ and $j(\\tau)-12^3$ .</li>\n<li>$\\eta(\\tau)$ is the Dedekind eta function.</li>\n<li>Expressing <em>x</em> as infinite nested cube roots. The continued fraction of $x-2$ was also described by H. M. Stark as <em>exotic</em>. See OEIS <a href=\"http://oeis.org/A002937\" rel=\"noreferrer\">link</a>.</li>\n<li>Based on a formula for the j-function using eta quotients.  </li>\n<li>$K(k_d)$ is the <a href=\"http://sites.google.com/site/tpiezas/0026\" rel=\"noreferrer\">complete elliptic integral of the first kind</a>.</li>\n<li>$\\,_2F_1(a,b;c;z)$ is the hypergeometric function.</li>\n<li>$\\alpha$ is a \"singular moduli\" of signature 6.</li>\n<li>Is a product of 81 gamma function $\\Gamma(n)$ given in the link above.</li>\n<li>A special case of the <em>Heine continued fraction</em> where as usual $q = e^{2\\pi i \\tau}$ and <em>x</em> as above.</li>\n<li>The general form is by M. Naika(?).</li>\n<li>Ramanujan's <em>octic continued fraction</em> and $k_{163}=k$ is the value such that $\\frac{K'(k)}{K(k)}=\\sqrt{163}$.</li>\n<li>As observed by Conway and Norton, the <a href=\"http://sites.google.com/site/tpiezas/0022\" rel=\"noreferrer\">moonshine functions</a> <em>span a linear space of dimension 163</em>. (The relevance of 163 is still speculative though.)</li>\n</ol>\n", "pids": ["53e9bb36b7602d9704773a70"], "flag": 0}
{"question": "Big list: books where we &quot;...start from a mathematically amorphous problem and combine ideas from sources to produce new mathematics...&quot;", "body": "<p>What books are there like like Radin's <a href=\"http://www.ams.org/bookstore-getitem/item=STML-1\" rel=\"nofollow noreferrer\"><em>Miles of Tiles</em></a> , which share these particular features:</p>\n<p><strong>Theme:</strong> &quot;In this book, we try to display the value (and joy!) of starting from a mathematically amorphous problem and combining ideas from diverse sources to produce new and significant mathematics--mathematics unforeseen from the motivating problem ... &quot;</p>\n<p><strong>Style:</strong> The common thread throughout this book is <code>&lt;insert topic here&gt;</code>...the presentation uses many different areas of mathematics and physics to analyze features of <code>&lt;insert topic here&gt;</code>...[as] understanding <code>&lt;insert topic here&gt;</code> requires an unusual variety of specialties...this interdisciplinary approach also leads to new mathematics seemingly unrelated to <code>&lt;insert topic here&gt;</code>...</p>\n<p><strong>Readership:</strong> Advanced undergraduates, graduate students, and research mathematicians.</p>\n", "pids": ["53e99acab7602d970234b446"], "flag": 0}
{"question": "What is the use of hyperreal numbers?", "body": "<p>For sometime I have been trying to come to terms with the concept of hyperreal numbers. It appears that they were invented as an alternative to the $\\epsilon-\\delta$ definitions to put the processes of calculus on a sound footing.</p>\n\n<p>From what I have read about hyperreal numbers I understand that they are an extension of real number system and include all real numbers and infinitesimals and infinities.</p>\n\n<p>I am wondering if hyperreal numbers are used only as a justification for the use of infinitesimals in calculus or do they serve to have some other applications also (of which I am not aware of)?</p>\n\n<p>Like when we extend our number system from $\\mathbb{N}$ to $\\mathbb{C}$ at each step there is some deficiency in the existing system which is removed in the next larger system. Thus $\\mathbb{Z}$ enables subtraction which is not always possible in $\\mathbb{N}$ and $\\mathbb{Q}$ enables division which is not always possible in $\\mathbb{Z}$. The reasons to go from $\\mathbb{Q}$ to $\\mathbb{R}$ are non-algebraic in nature. The next step from $\\mathbb{R}$ to $\\mathbb{C}$ is trivial and is based on need to enable square roots, but since the existing $\\mathbb{R}$ is so powerful, the new system of complex numbers exploits this power to create rich field of complex analysis.</p>\n\n<blockquote>\n  <p>Does the system of hyperreal numbers use the existing power of $\\mathbb{R}$ to lead to a richer theory (something like the complex analysis I mentioned earlier)? Or does it serve only as an alternative to $\\epsilon, \\delta$ definitions? In other words what role do the non-real hyperreal numbers play in mathematics?</p>\n</blockquote>\n\n<p>Since I am novice in this subject of hyperreal numbers, I would want answers which avoid too much symbolism and technicalities and focus on the essence.</p>\n", "pids": ["5c7561baf56def9798d800a2"], "flag": 0}
{"question": "Are people with a PhD least likely to be vaccinated in the US?", "body": "<p>According to Unherd's <a href=\"https://unherd.com/thepost/the-most-vaccine-hesitant-education-group-of-all-phds/\" rel=\"noreferrer\">summary</a> of a CMU study</p>\n<blockquote>\n<p>[Title:] The most vaccine-hesitant group of all? PhDs</p>\n<p>[...] more surprising is the breakdown in vaccine hesitancy by level of education. It finds that the association between hesitancy and education level follows a U-shaped curve with the highest hesitancy among those least and most educated. People with a master’s degree had the least hesitancy, and the highest hesitancy was among those holding a Ph.D.</p>\n<p><a href=\"https://i.stack.imgur.com/2mZA5.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/2mZA5.png\" alt=\"enter image description here\" /></a></p>\n</blockquote>\n<p>The National Review <a href=\"https://www.nationalreview.com/corner/the-most-vaccine-hesitant-group-of-all-ph-d-s/\" rel=\"noreferrer\">also reproduced</a> the graph above, with even fewer details.</p>\n<p>I suspect the study only concerned Covid-19 vaccines, but that's not too clear in Unherd's take. So is this a true relationship in general (between PhDs and vaccines in the US), or particular to one specific period and vaccine?</p>\n<p>As a &quot;sanity check&quot; I looked for surveys inside universities, and <a href=\"https://wayne.edu/coronavirus/july-2021-vaccination-survey-report.pdf\" rel=\"noreferrer\">found one</a>, which doesn't quite match those  findings above that supposedly was using a nation-wide representative sample. In this Wayne State survey, graduate students and post-docs had less hesitancy than undergraduates, and faculty had even less than both:</p>\n<p><a href=\"https://i.stack.imgur.com/JBQYi.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/JBQYi.png\" alt=\"enter image description here\" /></a></p>\n<p>Granted industry-working PhDs would not be capture in the latter. There's also the issue that a university faculty is substantially older than students.</p>\n", "pids": ["613b36ef5244ab9dcba25839"], "flag": 1}
{"question": "Does every bijection of $\\mathbb{Z}^2$ extend to a homeomorphism of $\\mathbb{R}^2$?", "body": "<blockquote>\n  <p>Given a bijection $f\\colon \\mathbb{Z}^2 \\to \\mathbb{Z}^2$, does there always exist a homeomorphism $h\\colon\\mathbb{R}^2\\to\\mathbb{R}^2$ that agrees with $f$ on $\\mathbb{Z}^2$?</p>\n</blockquote>\n\n<p>I don't see any immediate obstruction, but there are certain bijections that seem difficult to extend, such as\n$$\nf(a,b) \\;=\\; \\begin{cases} (a,b) &amp; \\text{if }b\\geq 0, \\\\[3pt] (-a,b) &amp; \\text{if }b&lt;0.\\end{cases}\n$$\nNote that it's possible to map any finite set of points $p_1,\\ldots,p_n$ to any other finite set $q_1,\\ldots,q_n$ by a homeomorphism of $\\mathbb{R}^2$, so it's quite important here that $\\mathbb{Z}^2$ is infinite.</p>\n\n<p>Of course, one can more generally ask whether any bijection between discrete subsets of $\\mathbb{R}^2$ extends to a homeomorphism.</p>\n", "pids": ["6306e8c890e50fcafdebd7be"], "flag": 0}
{"question": "What is $\\tau(A_n)$?", "body": "<p>Suppose G is a finite group. Define $\\tau(G)$ as the minimal number, such that $\\forall X \\subset G$ if $|X| &gt; \\tau(G)$, then $XXX = \\langle X \\rangle$.\nWhat is $\\tau(A_n)$?</p>\n\n<p>Similar problems for some  different classes of groups are already answered:</p>\n\n<p>1)  $\\tau(\\mathbb{Z}_n) = \\lceil \\frac{n}{3} \\rceil + 1$ (this is a number-theoretic fact proved via arithmetic progressions)</p>\n\n<p>2) Gowers, Nikolov and Pyber proved the fact that $\\tau(SL_n(\\mathbb{Z}_p)) = 2|SL_n(\\mathbb{Z}_p)|^{1-\\frac{1}{3(n+1)}}$ (this fact is proved with linear algebra)</p>\n\n<p>However, I have never seen anything like that for $A_n$. It will be interesting to know if there is something...</p>\n", "pids": ["56d8cb95dabfae2eee79c2b7"], "flag": 0}
{"question": "Has anyone ever actually seen this Daniel Biss paper?", "body": "<p>A student asked me about a paper by Daniel Biss (MIT Ph.D. and Illinois state senator) proving that \"circles are really just bloated triangles.\" The only published source I could find was the young adult novel <em><a href=\"https://books.google.com/books?id=3O40B12Q4xoC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false\">An Abundance of Katherines</a></em> by John Green, which includes the following sentence:</p>\n\n<p><em>Daniel [Biss] is world famous in the math world, partly because of a paper he published a few years ago that apparently proves that circles are basically fat, bloated triangles.</em></p>\n\n<p>This is probably just Green's attempt to replicate something Biss told him about topology (an example of homotopy, perhaps).</p>\n\n<p>But the statement seems to have intrigued students and non-mathematicians online. So I'm curious: has anyone seen such a paper? Is this a simplified interpretation of a real result (maybe in <em><a href=\"http://annals.math.princeton.edu/2003/158-3/p04\">The homotopy type of the matroid grassmannian</a></em>?).</p>\n", "pids": ["53e9b115b7602d9703b93037"], "flag": 0}
{"question": "What are the assumptions of the permutation test?", "body": "<p>It's often stated that permutation tests have no assumptions, however this is certainly not true. For example if my samples are somehow correlated, I can imagine that permuting their labels would not be the correct thing to do. Only think I found about this problem is this sentence from Wikipedia: \"An important assumption behind a permutation test is that the observations are exchangeable under the null hypothesis.\" Which I don't understand.</p>\n\n<p>What are the assumptions of permutation tests? And how are these assumptions connected to different possible permutation schemes? </p>\n", "pids": ["6066f011e4510cd7c8aad771", "64381a03d6db87a146a04655"], "flag": 1}
{"question": "Unexpected appearances of $\\pi^2 /~6$.", "body": "<blockquote>\n<p>&quot;The number <span class=\"math-container\">$\\frac 16 \\pi^2$</span> turns up surprisingly often and frequently in unexpected places.&quot; - Julian Havil, <em>Gamma: Exploring Euler's Constant</em>.</p>\n</blockquote>\n<hr />\n<p>It is well-known, especially in 'pop math,' that\n<span class=\"math-container\">$$\\zeta(2)=\\frac1{1^2}+\\frac1{2^2}+\\frac1{3^2}+\\cdots = \\frac{\\pi^2}{6}.$$</span>\n<a href=\"http://www.cs.nthu.edu.tw/%7Ewkhon/random/tutorial/pi-squared-over-six.pdf\" rel=\"noreferrer\">Euler's proof of which</a> is nice. <strong>I would like to know where else this constant appears non-trivially.</strong> This is a bit broad, so here are the specifics of my question:</p>\n<ol>\n<li>We can fiddle with the zeta function at arbitrary even integer values to eek out a <span class=\"math-container\">$\\zeta(2)$</span>. I would consider these 'appearances' of <span class=\"math-container\">$\\frac 16 \\pi^2$</span> to be redundant and ask that they not be mentioned unless you have some wickedly compelling reason to include it.</li>\n<li>By 'non-trivially,' I mean that I do not want converging series, integrals, etc. where it is obvious that <span class=\"math-container\">$c\\pi$</span> or <span class=\"math-container\">$c\\pi^2$</span> with <span class=\"math-container\">$c \\in \\mathbb{Q}$</span> can simply be 'factored out' in some way such that it looks like <span class=\"math-container\">$c\\pi^2$</span> was included after-the-fact so that said series, integral, etc. would equal <span class=\"math-container\">$\\frac 16 \\pi^2$</span>. For instance, <span class=\"math-container\">$\\sum \\frac{\\pi^2}{6\\cdot2^n} = \\frac 16 \\pi^2$</span>, but clearly the appearance of <span class=\"math-container\">$\\frac 16\\pi^2$</span> here is contrived. (But, if you have an answer that seems very interesting but you're unsure if it fits the 'non-trivial' bill, keep in mind that nobody will actually stop you from posting it.)</li>\n</ol>\n<p>I hope this is specific enough. <strong>This was my attempt at formally saying 'I want to see all the interesting ways we can make <span class=\"math-container\">$\\frac 16 \\pi^2$</span>.'</strong> With all that being said, I will give my favorite example as an answer below! :<span class=\"math-container\">$)$</span></p>\n<hr />\n<p>There used to be a chunk of text explaining why this question should be reopened here. It was reopened, so I removed it.</p>\n", "pids": ["53e9979bb7602d9701f660d3"], "flag": 0}
{"question": "Collection: Results on stopping times for Brownian motion (with drift)", "body": "<p>The aim of this question is to collect results on stopping times of Brownian motion (possibly with drift), with a focus on distributional properties:</p>\n\n<ul>\n<li>distributions of stopping times (Laplace transform, moments,..)</li>\n<li>distributional properties of the stopped process (computation/finiteness of moments, ...)</li>\n</ul>\n\n<p>Many of the results, which I have in mind, are typical homework problems. </p>\n\n<blockquote>\n  <p>What is the motivation for such a collection? </p>\n</blockquote>\n\n<p>There is a number of \"classical\" stopping times for Brownian motion, but unfortunately these stopping times don't have a specific name (apart from \"exit time\", \"hitting time\", ... - which is also not very specific), and this makes it hard to find results here on StackExchange. Sometimes, when I'm looking for a result, I know that it is <em>somewhere</em> here on MSE but I'm simply not able to find it. For other questions, which are asked very frequently in MSE, it is often difficult to find a good \"old\" answer.</p>\n\n<p>In any case, I believe that it would be a benefit to make the knowledge easier to access - both for students (who are trying to solve their homework problems) as for the \"teachers\" (who are answering questions on MSE).</p>\n\n<p>To make this list a helpful tool (e.g. for answering questions) please make sure to give a short but concise description of each result which you list in your answer.</p>\n", "pids": ["56d8ea57dabfae2eee4c34b2"], "flag": 0}
{"question": "What can we learn about the human brain from artificial neural networks?", "body": "<p>I know my question/title is not very specific, so I will try to clearify it:</p>\n\n<p>Artificial neural networks have relatively strict designs. Of course, generally, they are influenced by biology and try to build a mathematical model of real neural networks, but our understanding of real neural networks is insufficient for building exact models. Therefore, we can not conceive exact models or anything that comes \"near\" real neural networks.</p>\n\n<p>As far as I know, all artificial neural networks are far away from real neural networks. Standard, classic fully-connected MLPs are not present in biology. Recurrent neural networks have a lack of real neuroplasticity, each neuron of a RNN has the same \"feedback architecture\" while real neurons save and share their information rather individually. Convolutional neural networks are effective and popular, but (for example) image processing in the human brain consists of only a few convolution layers while modern solutions (like GoogLeNet) already use tens of layers...and although they are producing great results for computers, they are not even close to human performance. Especially when we think of a \"per-layer-performance\", as we need a fairly high amount of layers and data reduction compared to real neural networks.</p>\n\n<p>Additionally, to my knowledge, even modular, self-extending / self-restructuring artificial neural networks are rather \"fixed and static\" compared to the huge adaptability of real neural networks. The biological neuron normally has thousands of dendrites connecting the neuron to a huge variety of different areas and other neurons. Artificial neural networks are way more \"straightforward\".</p>\n\n<p>So, is there anything we can learn about the human brain / real neural networks from artificial neural networks? Or is it just some attempt to create software that performs better than classic, static algorithms (or even do things where such algorithms fail)?</p>\n\n<p>Can someone supply (preferably scientific) sources about this topic?</p>\n\n<p>EDIT: More answers are highly appreciated (:</p>\n", "pids": ["5c2348ceda562935fc1d55d9"], "flag": 1}
{"question": "What optimization methods work best for LSTMs?", "body": "<p>I've been using theano to experiment with LSTMs, and was wondering what optimization methods (SGD, Adagrad, Adadelta, RMSprop, Adam, etc) work best for LSTMs? Are there any research papers on this topic?</p>\n\n<p>Also, does the answer depend on the type of application I am using the LSTM for? If so, I am using LSTMs for text classification (where the text is first converted into word vectors).</p>\n\n<p>Finally, would the answers be the same or different for RNNs?\nAny pointers to research papers, or personal insight would be highly appreciated!</p>\n\n<p>LSTMs seem to be quite powerful and I am interested in learning more about how to best use them.</p>\n", "pids": ["599c7f09601a182cd28e6395"], "flag": 1}
{"question": "Partial differential equations in &quot;pure mathematics&quot;", "body": "<p>One thing I have noticed about PDEs is that they come from Mathematical Physics in general. Almost all the equations I see in <a href=\"https://en.wikipedia.org/wiki/Partial_differential_equation\" rel=\"nofollow noreferrer\"> Wikipedia </a> follow this pattern. I can't help wondering whether there are PDE's arising &quot;naturally&quot; in &quot;pure&quot; mathematics like Geometry, Topology, etc.?  Of course, I can always write an arbitrary surface as one or more PDE's, but they don't seem to drive much research in the subject, afaik. I understand that PDE's originated in Physics, but hasn't the subject grown away from physical models into more abstract examples?</p>\n", "pids": ["53e9b355b7602d9703e33083"], "flag": 0}
{"question": "Representing interaction effects in directed acyclic graphs", "body": "<p><a href=\"https://en.wikipedia.org/wiki/Directed_acyclic_graph\" rel=\"nofollow noreferrer\">Directed acyclic graphs</a> (DAGs; e.g., Greenland, et al, 1999) are a part of a formalism of causal inference from the counterfactual interpretation of causality camp. In these graphs the presence of an arrow from variable <span class=\"math-container\">$A$</span> to variable <span class=\"math-container\">$B$</span> asserts that variable <span class=\"math-container\">$A$</span> directly causes (some change in risk of) variable <span class=\"math-container\">$B$</span>, and the absence of such an arrow asserts that variable <span class=\"math-container\">$A$</span> does not directly cause (some change in risk of) variable <span class=\"math-container\">$B$</span>.</p>\n<p>As an example, the statement &quot;tobacco smoke exposure directly causes a change in risk of mesothelioma&quot; is represented by the black arrow from &quot;tobacco smoke exposure&quot; to &quot;mesothelioma&quot; in the <strong>not a DAG</strong> causal diagram below.</p>\n<p>Likewise, the statement &quot;asbestos exposure directly causes a change in risk of mesothelioma&quot; is represented by the black arrow from &quot;asbestos exposure&quot; to &quot;mesothelioma&quot; in the <strong>not a DAG</strong> causal graph below.</p>\n<p>I use the term <strong>not a DAG</strong> to describe the below causal graph because of the red arrow, which I intend to assert something like &quot;asbestos exposure causes <em>a change in the direct causal effect of</em> tobacco smoke exposure on risk of mesothelioma&quot; (asbestos does physical damage to the cells of the lung that, in addition to directly causing a change in risk of mesothelioma, also renders the cells more susceptible to the carcinogenic harms of tobacco smoke exposure with the result that exposure to both asbestos and tobacco result in an increase in risk that is more than the sum of the two separate risks), and this does not quite fit with the formal meaning of causal arrows in DAGs I described at the start of my question (i.e. because the red arrow does not terminate in a <em>variable</em>).</p>\n<p><a href=\"https://i.stack.imgur.com/22JP4.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/22JP4.png\" alt=\"Not a Directed Acyclic Graph: tobacco smoke exposure causes increased mesothelioma risk; asbestos exposure causes increased mesothelioma risk; asbestos exposure causes an increase in the causal effect of tobacco on mesothelioma risk.\" /></a></p>\n<p><strong>How does one correctly represent interaction effects within the visual formalism of a DAG?</strong></p>\n<p><strong>References</strong><br></p>\n<p>Greenland, S., Pearl, J., and Robins, J. M. (1999). <a href=\"https://www.jstor.org/stable/3702180\" rel=\"nofollow noreferrer\">Causal diagrams for epidemiologic research</a>. <em>Epidemiology</em>, 10(1):37–48.</p>\n", "pids": ["56d831d7dabfae2eee277502", "5d89e9483a55acd95282fe6e", "628d28005aee126c0f4de840", "5ff1c78a19519e9c395f3a15", "5e15a8353a55ac40c85f62d4"], "flag": 1}
{"question": "Why is the Hilbert Cube homogeneous?", "body": "<p>The Hilbert Cube $H$ is defined to be $[0,1]^{\\mathbb{N}}$, i.e., a countable product of unit intervals, topologized with the product topology.</p>\n\n<p>Now, I've read that the Hilbert Cube is homogeneous.  That is, given two points $p, q\\in H$, there is a homeomorphism $f:H\\rightarrow H$ with $f(p)=q$.</p>\n\n<p>What's confusing to me is that it seems like there seems to be a stratification of points.  That is, there are</p>\n\n<ol>\n<li><p>Points contained in $(0,1)^{\\mathbb{N}}$</p></li>\n<li><p>Points which have precisely $n$ coordinate a $0$ or $1$ for n a fixed natural number.</p></li>\n<li><p>Point which have countably many coordinates equaling $0$ or $1$ and countably many not and</p></li>\n<li><p>Points which have n many coordinates NOT equal to $0$ or $1$.</p></li>\n</ol>\n\n<p>Now, for fixed $p$ and $q$ both in class $1$ or $3$ (or fix an n and use class $2$ or $4$), it's clear to me that there is a homeomorphism taking $p$ to $q$, simply by swapping around factors and using the fact that $(0,1)$ is clearly homogeneous.</p>\n\n<p>But what are the homeomorphisms which mix the classes?  In particular, what homemorphism takes $(0,0,0,\\ldots )$ to $(1/2, 1/2,1/2,\\ldots )$?</p>\n\n<p>Said another way, for any natural number $n&gt;1$, $[0,1]^n$ is NOT homogeneous, precisely because of these boundary points.  What allows you to deal with the boundary points in the infinite product case?</p>\n\n<p>As always, feel free to retag, and thanks in advance!</p>\n\n<p><strong>Edit</strong>  In the off chance that someone stumbles across this question, I just wanted to provide a rough idea of the answer, as garnered from the link Pete provided in his answer.</p>\n\n<p>If one has a point of the form $(1,p)$ in $[0,1] \\times [0,1]$, then there is a self homeomorphism of $[0,1]\\times[0,1]$ taking $(1,p)$ to $(q,1)$ with $q\\neq 0, 1$.  For example, one can use a \"square rotation\".  From here, the idea is simple:  given a point in $H$ of the form $(1, p_2, p_3, p_4,\\ldots )$, apply the square rotation on the first two factors to get a new point of the form $(q_1, 1, p_2, p_3,\\ldots )$.  Now, apply the square rotation on the second two factors to get a new point of the form $(q_1, q_2, 1, p_3,\\ldots )$.  The point is that after $k$ iterations, the first $k$ coordinates are all in the interior.</p>\n\n<p>Now one proves a techinical lemma that states that the infinite composition of these homeomorphisms is a well defined homeomorphism.  The infinite composition maps the point $(1, p_2, \\ldots )$ to a point of the form $(q_1, q_2,\\ldots )$ which lies on the \"interior\" of $H$.  Finally, using the fact that $(0,1)$ is clearly homogeneous, one can easily map $(q_1, q_2,\\ldots )$ to $(1/2,1/2,\\ldots )$.</p>\n", "pids": ["56d8892cdabfae2eeea7650f"], "flag": 0}
{"question": "Intuitive Explanation of Bessel&#39;s Correction", "body": "<p>When calculating a sample variance a factor of <span class=\"math-container\">$N-1$</span> appears instead of <span class=\"math-container\">$N$</span> (see this <a href=\"http://en.wikipedia.org/wiki/Sample_variance#Population_variance_and_sample_variance\" rel=\"nofollow noreferrer\">link</a> ).  Does anybody have an intuitive way of explaining this to students who need to use this fact but maybe haven't taken a statistics course?</p>\n", "pids": ["53e997ecb7602d9701fe7329"], "flag": 0}
{"question": "Can gradient descent be applied to non-convex functions?", "body": "<p>I'm just learning about optimization, and having trouble understanding the difference between convex and non-convex optimization. From my understanding, a convex function is one where \"the line segment between any two points on the graph of the function lies above or on the graph\". In this case, a gradient descent algorithm could be used, because there is a single minimum and the gradients will always take you to that minimum.</p>\n\n<p>However, what about the function in this figure:</p>\n\n<p><a href=\"https://i.stack.imgur.com/VjaWt.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/VjaWt.png\" alt=\"enter image description here\"></a></p>\n\n<p>Here, the blue line segment crosses below the red function. However, the function still has a single minimum, and so gradient descent would still take you to this minimum.</p>\n\n<p>So my questions are:</p>\n\n<p>1) Is the function in this figure convex, or non-convex?</p>\n\n<p>2) If it is non-convex, then can convex optimization methods (gradient descent) still be applied?</p>\n", "pids": ["5736960c6e3b12023e51ee32"], "flag": 1}
{"question": "Example of a closed subspace of a Banach space which is not complemented?", "body": "<p>In this post, all vector spaces are assumed to be real or complex.</p>\n\n<p>Let $(X, ||\\cdot||)$ be a Banach space, $Y \\subset X$ a closed subspace. $Y$ is called $\\underline{\\mathrm{complemented}}$, if there is a closed subspace $Z \\subset X$ such that $X =Y \\oplus Z$ as topological vector spaces.</p>\n\n<p>If $H$ is a Hilbert space every closed subspace $Y$ is complemented; the orthogonal complement $Y^{\\bot}$ is a closed subspace of $H$ and we have $H=Y \\oplus Y^{\\bot}$. A famous theorem of Lindenstrauß and Tzafriri (which can be found in their article \"On the complemented subspaces problem\", Isreal Journal of Mathematics, Vol. 9, No.2, pp. 263-269) asserts that the converse is true as well. More precisely, if $(X, ||\\cdot||)$ is a Banach space such that every closed subspace is complemented then $||\\cdot||$ is induced by a scalarproduct, i.e. $(X,||\\cdot||)$ is a Hilbert space.</p>\n\n<p>Now to my question. Can you give me an example of a Banach space $(X,||\\cdot||)$, which is not a Hilbert space, and of a closed subspace $Y \\subset X$ which is not complemented? It is easily seen that $Y$ must be both infinite-dimensional and infinite-codimensional, for every finite-dimensional and every (closed) finite-codimensional subspace is complemented.</p>\n\n<p>I thought about something like $c_{0} \\subset (\\ell^{\\infty}, ||\\cdot||_{\\infty})$ the closed subspace of null sequences in the Banach space of bounded sequences but couldn't produce a proof that no closed complement exists in that case. Can you help me either proving that $c_{0}$ is not complemented (if that's true at all) or by giving me a different example?</p>\n", "pids": ["53e9a4e4b7602d9702e05756"], "flag": 0}
{"question": "Approximating the error function erf by analytical functions", "body": "<p>The <a href=\"http://de.wikipedia.org/wiki/Error_function\" rel=\"noreferrer\">Error function</a> </p>\n\n<p>$\\mathrm{erf}(x)=\\frac{2}{\\sqrt{\\pi}}\\int_0^x e^{-t^2}\\,dt$</p>\n\n<p>shows up in many contexts, but can't be represented using <a href=\"http://en.wikipedia.org/wiki/Elementary_functions\" rel=\"noreferrer\">elementary functions</a>. </p>\n\n<p>I compared it with another function $f$ which also starts linearly, has $f(0)=0$ and converges against the constant value 1 fast, <a href=\"http://en.wikipedia.org/wiki/Tanh\" rel=\"noreferrer\">namely</a></p>\n\n<p>$\\tanh{(x)} = \\frac {e^x - e^{-x}} {e^x + e^{-x}}$.</p>\n\n<p>Astoningishly to me, I found that they never differ by more than $|\\Delta f|=0.0812$ and converge against each other exponentially fast!</p>\n\n<p>I consider $\\tanh{(x)}$ to be the somewhat prettyier function, and so I wanted to find an approximation to $\\text{erf}$ with \"nice functions\" by a short expression. I \"naturally\" tried </p>\n\n<p>$f(x)=A\\cdot\\tanh(k\\cdot x^a-d)$</p>\n\n<p>Changing $A=1$ or $d=0$ on it's own makes the approximation go bad and the exponent $a$ is a bit difficult to deal with. However, I found that for $k=\\sqrt{\\pi}\\log{(2)}$ the situation gets \"better\". I obtained that $k$ value by the requirement that \"norm\" given by  </p>\n\n<p>$\\int_0^\\infty\\text{erf}(x)-f(x)dx,$</p>\n\n<p>i.e. the difference of the functions areas, should valish. With this value, the maximal value difference even falls under $|\\Delta f| = 0.03$. And however you choose the integration bounds for an interval, the area difference is no more than $0.017$.</p>\n\n<p><a src=\"https://i.imgur.com/Kko1GOG.png\" alt=\"enter image description here\"></p>\n\n<p>Numerically speaking and relative to a unit scale, the functions $\\text{erf}$ and $\\tanh{(\\sqrt{\\pi}\\log{(2)}x)}$ are essentially the same.</p>\n\n\n\n<p>My question is if I can find, or if there are known, substitutions for this non-elementary function in terms of elementary ones. In the sense above, i.e. the approximation is compact/rememberable while the values are even better, from a numerical point of view. </p>\n\n<p>The purpose being for example, that if I see somewhere that for a computation I have to integrate erf, that I can think to myself \"oh, yeah that's maybe complicated, but withing the bounds of $10^{-3}$ usign e.g. $\\tanh(k\\cdot x)$ is an incredible accurate approximation.\"</p>\n", "pids": ["628d2a315aee126c0f524838"], "flag": 0}
{"question": "$2\\times2$ matrices are not big enough", "body": "<p><a href=\"http://www.agnesscott.edu/lriddle/women/todd.htm\" rel=\"noreferrer\">Olga Tausky-Todd</a> had once said that</p>\n\n<blockquote>\n  <p><strong>\"If an assertion about matrices is false, there is usually a 2x2 matrix that reveals this.\"</strong></p>\n</blockquote>\n\n<p>There are, however, assertions about matrices that are true for $2\\times2$ matrices but not for the larger ones. I came across one nice little <a href=\"https://math.stackexchange.com/questions/577163/how-prove-this-matrix-inequality-detb0\">example</a> yesterday. Actually, every student who has studied first-year linear algebra should know that there are even assertions that are true for $3\\times3$ matrices, but false for larger ones --- <a href=\"http://en.wikipedia.org/wiki/Rule_of_Sarrus\" rel=\"noreferrer\">the rule of Sarrus</a> is one obvious example; a <a href=\"https://math.stackexchange.com/questions/254731/schurs-complement-of-a-matrix-with-no-zero-entries\">question</a> I answered last year provides another.</p>\n\n<p>So, here is my question. <em>What is your favourite assertion that is true for small matrices but not for larger ones?</em> Here, $1\\times1$ matrices are ignored because they form special cases too easily (otherwise, Tausky-Todd would have not made the above comment). The assertions are preferrably simple enough to understand, but their disproofs for larger matrices can be advanced or difficult.</p>\n", "pids": ["53e9a698b7602d9702fcaa2b"], "flag": 0}
{"question": "With categorical data, can there be clusters without the variables being related?", "body": "<p>When trying to explain cluster analyses, it is common for people to misunderstand the process as being related to whether the variables are correlated.  One way to get people past that confusion is a plot like this:</p>\n<p><a href=\"https://i.stack.imgur.com/QOO7I.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/QOO7I.png\" alt=\"enter image description here\" /></a></p>\n<p>This clearly displays the difference between the question of whether there are clusters and the question of whether the variables are related.  However, this only illustrates the distinction for continuous data.  I'm having trouble thinking of an analog with categorical data:</p>\n  \n<pre class=\"lang-r prettyprint-override\"><code>ID  property.A  property.B\n1   yes         yes\n2   yes         yes\n3   yes         yes\n4   yes         yes\n5   no          no\n6   no          no\n7   no          no\n8   no          no\n</code></pre>\n<p>We can see that there are two clear clusters: people with both property A and B, and those with neither.  However, if we look at the variables (e.g., with a chi-squared test), they are clearly related:</p>\n<pre class=\"lang-r prettyprint-override\"><code>tab\n#      B\n# A     yes no\n#   yes   4  0\n#   no    0  4\nchisq.test(tab)\n# X-squared = 4.5, df = 1, p-value = 0.03389\n</code></pre>\n<p>I find I am at a loss for how to construct an example with categorical data that is analogous to the one with continuous data above.  Is it even possible to have clusters in purely categorical data without the variables being related as well?  What if the variables have more than two levels, or as you have larger numbers of variables?  If the clustering of observations does necessarily entail relationships between the variables and vice versa, does that imply that clustering is not really worth doing when you only have categorical data (i.e., should you just analyze the variables instead)?</p>\n<hr />\n<p><em>Update:</em> I left a lot out of the original question because I wanted to just focus on the idea that a simple example could be created that would be immediately intuitive even to someone who was largely unfamiliar with cluster analyses.  However, I recognize that a lot of clustering is contingent on choices of distances and algorithms, etc.  It may help if I specify more.</p>\n<p>I recognize that Pearson's correlation is really only appropriate for continuous data.  For the categorical data, we could think of a chi-squared test (for a two-way contingency table) or a log-linear model (for multi-way contingency tables) as a way to assess the independence of the categorical variables.</p>\n<p>For an algorithm, we could imagine using k-medoids / PAM, which can be applied to both the continuous situation and the categorical data.  (Note that, part of the intention behind the continuous example is that any reasonable clustering algorithm should be able to detect those clusters, and if not, a more extreme example should be possible to construct.)</p>\n<p>Regarding the conception of distance, I assumed Euclidean for the continuous example, because it would be the most basic for a naive viewer.  I suppose the distance that is analogous for categorical data (in that it would be the most immediately intuitive) would be simple matching.  However, I am open to discussions of other distances if that leads to a solution or just an interesting discussion.</p>\n", "pids": ["56d8a453dabfae2eee7ec570"], "flag": 1}
{"question": "What is importance sampling?", "body": "<p>I'm trying to learn reinforcement learning and this topic is really confusing to me. I have taken an introduction to statistics, but I just couldn't understand this topic intuitively. </p>\n", "pids": ["5d9edc1647c8f7664603298a"], "flag": 1}
{"question": "is a net stronger than a transfinite sequence for characterizing topology?", "body": "<p>For metric spaces, knowledge of the convergence of sequences determines the topology completely. A set is closed in the metric topology if and only if it is closed under the limit of convergent sequences operation. Put another way, a map between metric spaces is continuous if and only if it preserves limits of sequences.</p>\n\n<p>For general topological spaces, this result no longer holds. Spaces for which it does hold are called <a href=\"http://en.wikipedia.org/wiki/Sequential_space\">sequential spaces</a>. Spaces are usually not sequential because they are not first countable. In such spaces, there are \"not enough\" numbers in the countable index set to extend into these very large spaces and reach every limit point. For example, if $\\omega_1$ is the first uncountable ordinal, then $\\omega_1+1$ is a topological space under the order topology, and $\\omega_1$ is a limit point, but no sequence of ordinals reaches $\\omega_1$. The topology of this space is not characterized by limits of sequences.</p>\n\n<p>This defect is usually fixed by replacing the notion of a sequence with the more general notion of a net, which is like a sequence but indexed by an arbitrary directed set, instead of the natural numbers. Since the net's index set is arbitrary, it can be of any cardinality and therefore nets can reach those faraway limit points in non first countable spaces, and the result is restored: a function between topological spaces is continuous iff it preserves limits of nets. A set is closed iff it is closed under limit of nets.</p>\n\n<p>But if the problem is that the cardinality of the space is too high for sequences to do the job, the most conservative generalization that suggests itself to me is to just increase the cardinality of the index set; the transfinite sequence, indexed by an arbitrary ordinal. So my question is: is this strong enough? Is it just a matter of convenience? Nets require less machinery, and are natural because e.g. the neighborhoods of a point constitute a net, whereas transfinites require a detour into unrelated areas of set theory. But nets are not totally ordered, and there may be times it would be nice to have a totally ordered index set for our sequence-like object.</p>\n\n<p>So can we say that a set in an arbitrary topological space is closed iff it's closed under taking limits of arbitrary convergent transfinite sequences? Is there a space with a set which is closed under limit of transfinite sequence, but not limit of net?</p>\n", "pids": ["53e99838b7602d9702062474"], "flag": 0}
{"question": "Efficiently finding two squares which sum to a prime", "body": "<p>The web is littered with any number of pages (<a href=\"http://planetmath.org/proofofthueslemma\">example</a>) giving an existence and uniqueness proof that a pair of squares can be found summing to primes congruent to 1 mod 4 (and also that there are no such pairs for primes congruent to 3 mod 4).</p>\n\n<p>However, none of the stuff I've read on the topic offers any help with actually efficiently finding (ie other than a straight search up to sqrt(p)) the concrete values of such squares.</p>\n\n<p>What's the best way to actually find them ?</p>\n", "pids": ["53e9be6cb7602d9704b2d04b", "53e9a7bab7602d97030f9e3d"], "flag": 0}
{"question": "AUC and class imbalance in training/test dataset", "body": "<p>I just start to learn the Area under the ROC curve (AUC). I am told that AUC is not reflected by data imbalance. I think it means that AUC is insensitive to imbalance in test data, rather than imbalance in training data.</p>\n\n<p>In other words, only changing the distribution of positive and negative classes in the <strong>test</strong> data, the AUC value may not change much. But if we change the distribution in the <strong>training</strong> data, the AUC value may largely change. The reason is that the classifier cannot be learned well. In this case, we have to use undersampling and oversampling. Am I right? I just want to make sure my understanding on AUC is correct.</p>\n", "pids": ["56d83786dabfae2eee4a3af2", "5dea04109e795e693620e95c"], "flag": 1}
{"question": "Why not just dump the neural networks and deep learning?", "body": "<p>Fundamental problem with deep learning and neural networks in general.</p>\n\n<ol>\n<li><p>The solutions that fit training data are infinite. We don't have precise mathematical equation that is satisfied by only a single one and that we can say generalizes best. Simply speaking we don't know which generalizes best.</p></li>\n<li><p>Optimizing weights is not a convex problem, so we never know we end up with a global or a local minimum.</p></li>\n</ol>\n\n<p>So why not just dump the neural networks and instead search for a better ML model? Something that we understand, and something that is consistent with a set of mathematical equations? Linear and SVM do not have this mathematical drawbacks and are fully consistent with a a set of mathematical equations. Why not just think on same lines (need not be linear though) and come up with a new ML model better than Linear and SVM and neural networks and deep learning?</p>\n", "pids": ["555048ef45ce0a409eb72b92"], "flag": 1}
{"question": "Why is this combination of nearest-integer functions --- surprisingly --- continuous?", "body": "<p>Alright, I didn't know the best way to formulate my question. Basically, whilst doing some physics research, I naturally came upon the function</p>\n\n<p>$$ f(x) = 2x[x] - [x]^2 $$</p>\n\n<p>where I use $[x]$ as notation for the `nearest-integer function' (i.e. rounding off). Usually this function has to have a caveat of how we exactly define the value for $x \\in \\frac{1}{2} \\mathbb Z$, but <em>interestingly</em> for this function it does not matter, since it turns out to be continuous! In fact, it turns out $f(x)$ is exactly given by the glued function of taking all the tangent lines of $x^2$ at integer values of $x$:</p>\n\n<p><a href=\"https://i.stack.imgur.com/xMXv9.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/xMXv9.png\" alt=\"enter image description here\"></a>\n(Note: due to properties of $x^2$, the tangent lines exactly intersect at half-integer values of $x$.)</p>\n\n<p>So my question is not <em>literally</em> `why is it continuous?', but rather: considering it is continuous, and considering that that is not a generic property of functions which are defined in terms of nearest-integer functions, is there a better (i.e. more insightful) way of expressing $f(x)$? Relatedly, is there some part of mathematics where functions similar to these naturally arise?</p>\n", "pids": ["5b8c9ede17c44af36f8afa09"], "flag": 0}
{"question": "What is the best rest position for two elevators in a 10-story building?", "body": "<h2>Situation</h2>\n\n<ul>\n<li>My apartment block has ten stories.</li>\n<li>The first ground level is 1, the highest story is 10.</li>\n<li>There are two equivalent elevators, spanning all stories.</li>\n</ul>\n\n<p><strong>Current configuration:</strong> One elevator always rests at level 1, the other at level 10.</p>\n\n<h2>Thoughts</h2>\n\n<p>I am pretty sure that this is a bad configuration and I started thinking about a better one. While keeping one elevator always on the first level seems very reasonable, I think the one on the tenth level is very inefficient.</p>\n\n<p>An efficient configuration would be where most people would wait  as little as possible to reach their level. One example situation that occurs is that, someone walks 30m in front of me outside the building and takes the first elevator and then I have to wait for the second one to come down from 10 to 1.</p>\n\n<h2>Modeling</h2>\n\n<p>Let's further assume:</p>\n\n<ul>\n<li>People only use the elevator to get from their story to the ground level (1) and from ground level back to their story.</li>\n<li>The number of elevator users is the same for all levels.</li>\n<li>The usage over time is uniform.</li>\n</ul>\n\n<h2>My Calculation</h2>\n\n<p>I did a \"numerical calculation\" (spreadsheet) and found that if I optimize one elevator $U$ for people going up and one elevator for people going down $D$, then elevator $U$ should always be on floor 1 and elevator $D$ should be on floor 6. I compared all start levels for people wanting to go down from 2-10 and an elevator on level 6 has the minimum number of traversed levels.</p>\n\n<p>So for the story $s \\in \\{2..10\\}$ where the person <strong>s</strong>tarts his descent and $r \\in \\{1..10\\}$ the story where the elevator <strong>r</strong>ests we need to find\n$$min \\left(\\sum_{s=2}^{10} (s-1)+|s-r|\\right)$$</p>\n\n<p>The values over $r$ are:\n<a href=\"https://i.stack.imgur.com/zNcBS.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/zNcBS.png\" alt=\"enter image description here\"></a></p>\n\n<h2>Questions</h2>\n\n<p>Taking into account the points in <em>Situation</em> and <em>Modeling</em>:</p>\n\n<ol>\n<li>Is there a better position for elevator $D$ than level 6?</li>\n<li>And maybe even something better for $U$ even though it's position on the first floor seems \"very optimal\"?</li>\n</ol>\n", "pids": ["5c755274f56def97985eae73", "53e9b52db7602d9704061fe9", "5c7569cdf56def97982d66e7", "5b8c9f1617c44af36f8b304a", "56d8f21fdabfae2eee7bd2cf", "53e9abbfb7602d970356f65f"], "flag": 0}
{"question": "Is low emotional intelligence associated with right-wing and prejudiced attitudes?", "body": "<p>Accordiing to <a href=\"https://crafty.diply.com/66262/people-with-low-emotional-intelligence-tend-to-hold-right-wing-v\" rel=\"noreferrer\">Diply</a>, </p>\n\n<blockquote>\n  <p>Researchers in Belgium have linked a lack of emotional intelligence with right-wing political views, reports PsyPost. The study, published in Emotion, found that those who lack the ability to understand and manage emotions are more likely to have right-wing and prejudiced attitudes.</p>\n</blockquote>\n\n<p>The referenced <a href=\"https://www.psypost.org/2019/09/people-with-lower-emotional-intelligence-are-more-likely-to-hold-right-wing-views-study-finds-54369\" rel=\"noreferrer\">PsyPost</a> article says:</p>\n\n<blockquote>\n  <p>The researchers found that individuals with weaker emotional abilities — particularly emotional understanding and management — tended to score higher on a measure of right-wing authoritarianism and social dominance orientation.</p>\n</blockquote>\n\n<p>I can only see the abstract of the study itself:</p>\n\n<ul>\n<li>Van Hiel, A., De keersmaecker, J., Onraet, E., Haesevoets, T., Roets, A., &amp; Fontaine, J. R. J. (2019). <a href=\"https://psycnet.apa.org/record/2018-41368-001\" rel=\"noreferrer\">The relationship between emotional abilities and right-wing and prejudiced attitudes.</a> <em>Emotion</em>, 19(5), 917-922.\n<a href=\"http://dx.doi.org/10.1037/emo0000497\" rel=\"noreferrer\">http://dx.doi.org/10.1037/emo0000497</a></li>\n</ul>\n\n<blockquote>\n  <p>Previous research revealed that cognitive abilities are negatively\n  related to right-wing and prejudiced attitudes. No study has, however,\n  investigated if emotional abilities also show such a relationship,\n  although this can be expected based on both classic and recent\n  literature. The aim of the present study was 2-fold: (a) to\n  investigate the relationship between emotional abilities and\n  right-wing and prejudiced attitudes, and (b) to pit the effects of\n  emotional and cognitive abilities on these attitudes against each\n  other. Results from 2 adult samples (n = 409 and 574) in which\n  abilities scores were collected in individual testing sessions,\n  revealed that emotional abilities are significantly and negatively\n  related to social-cultural and economic-hierarchical right-wing\n  attitudes, as well as to blatant ethnic prejudice. These relationships\n  were as strong as those found for cognitive abilities. For\n  economic-hierarchical right-wing attitudes, emotional abilities were\n  even the only significant correlate. It is therefore concluded that\n  the study of emotional abilities has the potential to significantly\n  advance our understanding of right-wing and prejudiced attitudes.</p>\n</blockquote>\n\n<p>The first line of the abstract seems to take it for granted that cognitive abilities are negatively related to right-wing and prejudiced attitudes, and then they go on from there. I see the accepted answer to <em><a href=\"https://skeptics.stackexchange.com/questions/38143/are-liberal-left-wing-people-more-intelligent-than-conservative-right-wing-peopl\">Are liberal/left-wing people more intelligent than conservative/right-wing people?</a></em> indicates otherwise.</p>\n\n<p>I'm struggling to understand if the link to emotional intelligence still applies, considering that the negative link to cognitive abilities may not.</p>\n", "pids": ["56d92caddabfae2eeee1889c", "56d92caddabfae2eeee1889c"], "flag": 1}
{"question": "Is a neural network essential for deep learning?", "body": "<p>I received preliminary materials on deep learning in my class. It was written as follows. This raised me the question of the basic meaning of the word deep learning.</p>\n<blockquote>\n<p>Deep learning is a machine learning method using a multi-layer neural network.</p>\n</blockquote>\n<ol>\n<li>Is a neural network essential for deep learning?</li>\n<li>Isn't it possible to do deep learning without a neural network by using PCA? (Example: PCANet)</li>\n</ol>\n<p>I'm confused by similar terms like deep learning and deep neural networks. I have a month to start school and I can't contact my teacher during that time. I would appreciate it if you could tell me.</p>\n", "pids": ["53e9aa41b7602d97033ae9d9", "5dfb4b2f3a55acc4878bd36d"], "flag": 1}
{"question": "Inference after using Lasso for variable selection", "body": "<p>I'm using Lasso for feature selection in a relatively low dimensional setting (n >> p). After fitting a Lasso model, I want to use the covariates with nonzero coefficients to fit a model with no penalty. I'm doing this because I want unbiased estimates which Lasso cannot give me. I'd also like p-values and confidence intervals for the unbiased estimate.</p>\n\n<p>I'm having trouble finding literature on this topic. Most of the literature I find is about putting confidence intervals on the Lasso estimates, not a refitted model.</p>\n\n<p>From what I've read, simply refitting a model using the whole dataset leads to unrealistically small p-values/std errors. Right now, sample splitting (in the style of Wasserman and Roeder(2014) or Meinshausen et al. (2009)) seems to be a good course of action, but I'm looking for more suggestions. </p>\n\n<p>Has anyone encountered this issue? If so, could you please provide some suggestions.</p>\n", "pids": ["5efda22591e01191d3d26d33", "5c756edff56def9798615872"], "flag": 1}
{"question": "Why does topology rarely come up outside of topology?", "body": "<p>I am currently taking topology and it seems like a completely different branch of math than anything else I have encountered previously. </p>\n\n<p>I find it a little strange that things are not defined more concretely. For example, a topological space is defined as a set $X$ with a collection of open sets $\\tau$ satisfying some properties such as the empty set and $X$ are in $\\tau$, intersection of two open sets are in $\\tau$, and unions of open sets is in $\\tau$. </p>\n\n<p>So, it seems that a lot of things are topological spaces, such as the real line equipped with a collection of open sets. But I have not seen anyone bringing this up in other areas of mathematics such as linear algebra, calculus, differential equations or analysis or complex analysis. Sure, open sets and closed sets are brought up but the concept of \"topology\", \"base\", etc. etc. are missing entirely.</p>\n\n<p>As you scratch the surface a little more you encounter things such as the subspace topology, product topology, order topology and open sets are defined differently with respect to each of them. But nonetheless outside of a course in topology, you never encounter these concepts.</p>\n\n<p>Is there a reason why topology is not essential for other courses that I have mentioned? Is there a good reference that meshes serious topology (as in Munkres) with more applied area of mathematics?</p>\n", "pids": ["573696856e3b12023e590d42", "5f0e2d7d9fced0a24be108c0"], "flag": 0}
{"question": "Patterns of the zeros of the Faulhaber polynomials (modified)", "body": "<p><a href=\"http://en.wikipedia.org/wiki/Faulhaber%27s_formula\" rel=\"nofollow noreferrer\">Faulhaber polynomial</a> of order <span class=\"math-container\">$p \\in \\Bbb{N}$</span> is defined as the unique polynomial of degree <span class=\"math-container\">$p+1$</span> satisfying</p>\n<p><span class=\"math-container\">$$ S_{p}(n) = \\sum_{k=1}^{n} k^p $$</span></p>\n<p>for <span class=\"math-container\">$n = 1, 2, 3, \\cdots$</span>. For example,</p>\n<p><span class=\"math-container\">\\begin{align*}\nS_0(x) &amp;= x, \\\\\nS_1(x) &amp;= \\frac{x(x+1)}{2}, \\\\\nS_2(x) &amp;= \\frac{x(x+1)(2x+1)}{6}, \\\\\nS_3(x) &amp;= \\frac{x^2 (x+1)^2}{4}.\n\\end{align*}</span></p>\n<p>In order to grasp some intuition on the partial decomposition of <span class=\"math-container\">$1/S_p (x)$</span>, I tried plotting the complex zeros of <span class=\"math-container\">$S_p (x)$</span>. The following graphics shows the distribution of the zeros of <span class=\"math-container\">$S_{800}(x)$</span>.</p>\n<p><a src=\"https://i.stack.imgur.com/BjdAi.png\" alt=\"enter image description here\" /></p>\n<p>(The precision of the calculated zeros <span class=\"math-container\">$z_j$</span> of <span class=\"math-container\">$S_{800}(z)$</span> above satisfy <span class=\"math-container\">$|f(z_j)| \\leq 10^{-300}$</span>.)</p>\n<p>It turns out that they exhibits a very neat, yet still a strange pattern as seen above.</p>\n<p>So far I have never heard of the topic related to this pattern, and I want to know (out of curiosity) if there are some results concerning the pattern of zeros of <span class=\"math-container\">$S_p(x)$</span>.</p>\n", "pids": ["56d8f158dabfae2eee76f1a3", "5f0e344b9fced0a24b890ce4"], "flag": 0}
{"question": "How to model this odd-shaped distribution (almost a reverse-J)", "body": "<p>My dependent variable shown below doesn't fit any stock distribution that I know of.  Linear regression produces somewhat non-normal, right-skewed residuals that relate to predicted Y in an odd way (2nd plot).  Any suggestions for transformations or other ways to obtain most valid results and best predictive accuracy?  If possible I'd like to avoid clumsy categorizing into, say, 5 values (e.g., 0, lo%, med%, hi%, 1).</p>\n\n<p><a src=\"https://i.stack.imgur.com/MCCWG.jpg\" alt=\"enter image description here\"></p>\n\n<p><a src=\"https://i.stack.imgur.com/dF7gd.jpg\" alt=\"enter image description here\"></p>\n", "pids": ["5c0f7286da562944ac6634d6"], "flag": 1}
{"question": "Closed form for ${\\large\\int}_0^1\\frac{\\ln(1-x)\\,\\ln(1+x)\\,\\ln(1+2x)}{1+2x}dx$", "body": "<p>Here is another integral I'm trying to evaluate:\n$$I=\\int_0^1\\frac{\\ln(1-x)\\,\\ln(1+x)\\,\\ln(1+2x)}{1+2x}dx.\\tag1$$\nA numeric approximation is:\n$$I\\approx-0.19902842515384155925817158058508204141843184171999583129...\\tag2$$\n(click <a href=\"http://goo.gl/tAYBDQ\">here</a> to see more digits).</p>\n\n<p>Unfortunately, so far I have made no progress in finding a closed form for it. Could you please suggest any ideas how to do that?</p>\n", "pids": ["61d65e0b5244ab9dcbf1610b"], "flag": 0}
{"question": "How To Present Algebraic Topology To Non-Mathematicians?", "body": "<p>I am writing my master thesis in algebraic topology (fundamental groups), and, as a system in my school, students must write one page about their theses explaining for non-mathematicians the purpose of the study (in general) and why it is important in the real life. I don't know actually how shall I start, because I'm not allowed to use some mathematical terminologies like \"Topological Space\", for instance. My teacher told me it's important to convince the \"politicians\" to support financially the research in the department of mathematics mainly in algebraic topology to show them that we are doing something useful. Furthermore; it is to make the new students like this kind of mathematics.</p>\n\n<p>So any suggestion or idea will be very appreciated! </p>\n", "pids": ["56d8693cdabfae2eeeb94143"], "flag": 0}
{"question": "Is the complement of countably many disjoint closed disks path connected?", "body": "<blockquote>\n  <p>Let $\\{D_n\\}_{n=1}^\\infty$ be a family of pairwise disjoint closed disks in $\\mathbb{R}^2$.  Is the complement\n  $$\n\\mathbb{R}^2 -\\bigcup_{n=1}^\\infty D_n\n$$\n  always path connected?</p>\n</blockquote>\n\n<p>Here &ldquo;disk&rdquo;  means a round, geometric disk.  (As shown below, the answer is no if we allow arbitrary topological disks.)</p>\n\n<p>Note that the union $\\bigcup_{n=1}^\\infty D_n$ can be dense in the plane.  For example, it's possible to find a collection of disjoint closed disks of positive radius whose union contains $\\mathbb{Q}\\times\\mathbb{Q}$.</p>\n\n<p>It is easy to show that the complement of a countable set of points in the plane is always path connected. In particular, if $S \\subset\\mathbb{R}^2$ is countable, then there is always \npath between any two points in $\\mathbb{R}^2-S$ consisting of two line segments.</p>\n\n<p>It is <em>not</em> true that the complement of a countable set of disjoint line segments  is path connected, as shown in the following figure.</p>\n\n<p><a src=\"https://i.stack.imgur.com/7yb7e.png\" alt=\"enter image description here\"></p>\n\n<p>By thickening the line segments slightly, one can find a countable collection of disjoint topological disks whose complement is not path connected.</p>\n", "pids": ["53e9a9a9b7602d9703307174"], "flag": 0}
{"question": "Comparison of ranked lists", "body": "<p>Suppose that two groups, comprising $n_1$ and $n_2$ each rank a set of 25 items from most to least important. What are the best ways to compare these rankings?</p>\n\n<p>Clearly, it is possible to do 25 Mann-Whitney U tests, but this would result in 25 test results to interpret, which may be too much (and, in strict use, brings up questions of multiple comparisons). It is also not completely clear to me that the ranks satisfy all the assumptions of this test.</p>\n\n<p>I would also be interested in pointers to literature on rating vs. ranking.</p>\n\n<p>Some context: These 25 items all relate to education and the two groups are different types of educators. Both groups are small.</p>\n\n<p>EDIT in response to @ttnphns:</p>\n\n<p>I did not mean to compare the total rank of items in group 1 to group 2 - that would be a constant, as @ttnphns points out. But the rankings in group 1 and group 2 will differ; that is, group 1 may rank item 1 higher than group 2 does. </p>\n\n<p>I could compare them, item by item, getting mean or median rank of each item and doing 25 tests, but i wondered if there was some better way to do this.</p>\n", "pids": ["56d84708dabfae2eeeb66acc"], "flag": 1}
{"question": "What other tricks and techniques can I use in integration?", "body": "<p>So far, I know and can use a reasonable number of 'tricks' or techniques when I solve integrals. Below are the tricks/techniques that I know for indefinite and definite integrals separately.</p>\n<hr />\n<p><strong>Indefinite integrals</strong></p>\n<ul>\n<li>Standard integrals, such as those of polynomial, trigonometric, logarithmic and exponential functions, including usage of trig identies.</li>\n<li>Basic substitution.</li>\n<li>Weierstrass and Euler substitutions.</li>\n<li>Integration by parts.</li>\n<li><span class=\"math-container\">$$\\int\\frac{1}{x+x^n}dx=\\int\\frac{x^{-n}}{1+x^{1-n}}dx=\\frac{1}{1-n}\\ln\\lvert 1+x^{1-n}\\rvert+C$$</span></li>\n<li><span class=\"math-container\">$$\\int\\frac{1}{x^{\\frac{a+b}{a+b}}\\cdot x^{\\frac{a}{a+b}}+x^{\\frac{b}{a+b}}}dx=\\int \\frac{x^{-\\frac{b}{a+b}}}{\\left(x^{\\frac{a}{a+b}}\\right)^2+1}dx=\\arctan x^{\\frac{a}{a+b}}+C$$</span></li>\n<li>Substitution\n<span class=\"math-container\">$u=\\frac{1-x}{1+x}$</span> for integrals involving <span class=\"math-container\">$\\ln$</span> and/or the bounds <span class=\"math-container\">$0$</span> and <span class=\"math-container\">$1$</span>.</li>\n<li>Reduction formulae.</li>\n<li><span class=\"math-container\">$$\\int e^x(f(x)+f'(x))dx=e^xf(x)+C$$</span></li>\n<li>Writing <span class=\"math-container\">$\\sin$</span>'s and <span class=\"math-container\">$\\cos$</span>'s as complex exponentials.</li>\n<li><span class=\"math-container\">$$\\int\\frac{a\\sin x+b\\cos x}{c\\sin x+d\\cos x}dx=Ax+B\\ln\\lvert c\\sin x+d\\cos x\\rvert+C$$</span>\nwhere <span class=\"math-container\">$$A=\\frac{ac+bd}{c^2+d^2}~~~B=\\frac{bc-ad}{c^2+d^2}$$</span>\nwhich can be found using simultaneous equations.</li>\n</ul>\n<p><strong>Definite integrals</strong></p>\n<ul>\n<li>Differentiation under the integral sign ('Feynman's technique')</li>\n<li><span class=\"math-container\">$$\\int_a^b f(x)dx=\\int_a^bf(a+b-x)dx$$</span></li>\n<li>Usage of power series to evaluate integrals such as <span class=\"math-container\">$\\int_0^1\\frac{\\ln(1-x)}{x}dx$</span> and the like.</li>\n<li>Making use of even or odd function properties.</li>\n<li>(My newest personal favourite) For even functions <span class=\"math-container\">$f(x)$</span> and <span class=\"math-container\">$g(x)$</span>, and an odd function <span class=\"math-container\">$h(x)$</span>: <span class=\"math-container\">$$\\int_{-a}^a\\frac{f(x)}{1\\pm g(x)^{h(x)}}dx=\\int_{0}^a f(x)~dx$$</span> which allows us to evaluate wonderful things like\n<span class=\"math-container\">$$\\int_{-\\infty}^{\\infty}\\frac{e^{-x^2}}{1+\\pi^{\\sin x} }dx=\\frac{\\sqrt{\\pi}}{2}$$</span></li>\n</ul>\n<hr />\n<blockquote>\n<h2>Question:</h2>\n<p>Do you know any other integration techniques or tricks that I can use whose usage don't rely on anything beyond <strong>high school calculus</strong>* or perhaps the first year of a Mathematics degree course?</p>\n</blockquote>\n<p>I know that a similar question has been asked <a href=\"https://math.stackexchange.com/questions/942263/really-advanced-techniques-of-integration-definite-or-indefinite\">here</a> and <a href=\"https://math.stackexchange.com/questions/70974/lesser-known-integration-tricks\">here</a> but I've looked through them and nothing beyond what I have written above was mentioned, apart from some techniques I couldn't understand such as residue calculus and contour integrals.</p>\n<p>Many thanks for your help.</p>\n<hr />\n<p>*<strong>Roughly what I mean by high school level calculus:</strong></p>\n<p><strong>INCLUDED</strong></p>\n<ul>\n<li>Integration of polynomials and the basic trigonometric functions, such as <span class=\"math-container\">$\\sin x$</span>, <span class=\"math-container\">$\\cos x$</span>, <span class=\"math-container\">$\\tan x$</span>, <span class=\"math-container\">$\\sec x$</span>, <span class=\"math-container\">$\\operatorname{cosec} x$</span>, <span class=\"math-container\">$\\cot x$</span>, <span class=\"math-container\">$\\sec^2 x$</span>, <span class=\"math-container\">$\\sec x\\tan x$</span>, <span class=\"math-container\">$\\operatorname{cosec} x\\cot x$</span>, <span class=\"math-container\">$\\operatorname{cosec}^2 x.$</span></li>\n<li>Integration of all <span class=\"math-container\">$x^n$</span> including <span class=\"math-container\">$n=1$</span>. Integration of exponentials.</li>\n<li>Integration by parts.</li>\n<li>Integration using substitution, such as using trigonometric/hyperbolic substitutions, and Weierstrass and Euler substitutions (this also includes integration by 'inspection' which is really just substitution but when the individual doesn't need to substitute anything).</li>\n<li>Integration using partial fractions and logarithms, such as <span class=\"math-container\">$\\int\\frac{f'(x)}{f(x)}dx$</span>.</li>\n<li>Reduction formulae. Ability to understand and use the concepts of even and odd functions in integration. Improper integrals.</li>\n<li>Integrating which results in elementary functions.</li>\n</ul>\n<p><strong>NOT INCLUDED</strong></p>\n<ul>\n<li>Fourier, Laplace and Mellin transforms.</li>\n<li>Indefinite integrals that include non-elementary functions in the solution.</li>\n<li>Contour integration.</li>\n<li>Residue calculus and similar methods.</li>\n</ul>\n", "pids": ["5c7570a3f56def979870ea31"], "flag": 0}
{"question": "What is $\\, _4F_3\\left(1,1,1,\\frac{3}{2};\\frac{5}{2},\\frac{5}{2},\\frac{5}{2};1\\right)$?", "body": "<p>I have been trying to evaluate the series $$\\, _4F_3\\left(1,1,1,\\frac{3}{2};\\frac{5}{2},\\frac{5}{2},\\frac{5}{2};1\\right) = 1.133928715547935...$$ using integration techniques, and I was wondering if there is any simple way of finding a closed-form evaluation of this hypergeometric series.  What is a closed-form expression for the above series?  </p>\n", "pids": ["5f01aa05dfae54360a4567ed", "6577661a939a5f4082099bad"], "flag": 0}
{"question": "Is $\\operatorname{height} \\mathfrak{p} + \\dim A / \\mathfrak{p} = \\dim A$ true?", "body": "<blockquote>\n  <p>Let $A$ be an integral domain of finite Krull dimension. Let $\\mathfrak{p}$ be a prime ideal. Is it true that $$\\operatorname{height} \\mathfrak{p} + \\dim A / \\mathfrak{p} = \\dim A$$\n  where $\\dim$ refers to the Krull dimension of a ring? </p>\n</blockquote>\n\n<p>Hartshorne states it as Theorem 1.8A in Chapter I (for the case $A$ a finitely-generated $k$-algebra which is an integral domain) and cites Matsumura and Atiyah–Macdonald, but I haven't been able to find anything which looks relevant in either. (Disclaimer: I know nothing about dimension theory, and very little commutative algebra.) If it is true (under additional assumptions, if need be), where can I find a complete proof?</p>\n\n<p>It is obvious that $$\\operatorname{height} \\mathfrak{p} + \\dim A/\\mathfrak{p} \\le \\dim A$$ by a lifting argument, but the reverse inequality is eluding me.  Localisation doesn't seem to be the answer, since localisation can change the dimension...</p>\n", "pids": ["5c756dfff56def9798586610", "5c61089bda56297340b4483c"], "flag": 0}
{"question": "Show $\\int_{0}^{\\frac{\\pi}{2}}\\frac{x^{2}}{x^{2}+\\ln^{2}(2\\cos(x))}dx=\\frac{\\pi}{8}\\left(1-\\gamma+\\ln(2\\pi)\\right)$", "body": "<p>Here is an interesting, albeit tough, integral I ran across. It has an interesting solution which leads me to think it is doable. But, what would be a good strategy?.</p>\n\n<p>$$\\int_{0}^{\\frac{\\pi}{2}}\\frac{x^{2}}{x^{2}+\\ln^{2}(2\\cos(x))}dx=\\frac{\\pi}{8}\\left(1-\\gamma+\\ln(2\\pi)\\right)$$</p>\n\n<p>This looks rough. What would be a good start?.  I tried various subs in order to get it into some sort of shape to use series, LaPlace, something, but made no real progress.</p>\n\n<p>I even tried writing a geometric series. But that didn't really result in anything encouraging.</p>\n\n<p>$$\\int_{0}^{\\frac{\\pi}{2}}\\sum_{n=0}^{\\infty}(-1)^{k}\\left(\\frac{\\ln(2\\cos(x))}{x}\\right)^{2k}$$</p>\n\n<p>Thanks all. </p>\n", "pids": ["53e9bac9b7602d97046f8eb6", "56d84629dabfae2eeeafc830"], "flag": 0}
{"question": "Evaluating $\\int_0^1 \\log \\log \\left(\\frac{1}{x}\\right) \\frac{dx}{1+x^2}$", "body": "<p>Show that <span class=\"math-container\">$\\displaystyle{\\int_0^1 \\log \\log \\left(\\frac{1}{x}\\right) \\frac{dx}{1+x^2} = \\frac{\\pi}{2}\\log \\left(\\sqrt{2\\pi} \\Gamma\\left(\\frac{3}{4}\\right) / \\Gamma\\left(\\frac{1}{4}\\right)\\right)}$</span></p>\n\n<p>This question was posted as part of this question: </p>\n\n<p><a href=\"https://math.stackexchange.com/questions/121473/solve-the-integral-displaystyles-k-1k-int-01-log-sin-pi-xk-dx\">Solve the integral $S_k = (-1)^k \\int_0^1 (\\log(\\sin \\pi x))^k dx$</a></p>\n\n<p>I cannot think of a change of variable nor other integrating methods. Maybe there is a known method that I am missing. </p>\n", "pids": ["5cc82305ced107d4c60820ab"], "flag": 0}
{"question": "What are the applications of continued fractions?", "body": "<p>What is the most motivating way to introduce continued fractions? Are there any real life applications of continued fractions?</p>\n", "pids": ["53e9aeabb7602d97038d20d3", "56d8eec0dabfae2eee67af4f"], "flag": 0}
{"question": "Why is the continuum hypothesis believed to be false by the majority of modern set theorists?", "body": "<p>A quote from <a href=\"http://rads.stackoverflow.com/amzn/click/0122384407\">Enderton</a>:</p>\n\n<blockquote>\n  <p>One might well question whether there is any meaningful sense in which one can say that the continuum hypothesis is either true or false for the \"real\" sets. Among those set-theorists nowadays who feel that there is a meaningful sense, the majority seems to feel that the continuum hypothesis is false.</p>\n</blockquote>\n\n<p>I am interested in the motivation behind this belief. In other words, what advances in set-theory could make one favor this option over the other?</p>\n", "pids": ["53e9a9e6b7602d9703347756", "5f0dd50b9fced0a24b3cd62c"], "flag": 0}
{"question": "Why are functions with vanishing normal derivative dense in smooth functions?", "body": "<p><strong>Question</strong></p>\n\n<blockquote>\n  <p>Let $M$ be a compact Riemannian manifold with piecewise smooth boundary. Why are smooth functions with vanishing normal derivative dense in $C^\\infty(M)$ in the $H^1$ norm?</p>\n</blockquote>\n\n<p>Here I define $C^\\infty(M)$ to be those functions which have all orders of derivative continuous on $M$ and smooth in its interior. For example, $(x\\mapsto \\sin(\\pi x))\\in C^\\infty([0,1])$ but $(x\\mapsto \\sqrt{x})\\notin C^\\infty([0,1])$.</p>\n\n<p>I have <a href=\"https://mathoverflow.net/questions/286412/why-are-functions-with-vanishing-normal-derivative-dense-in-smooth-functions\">crossposted this to MathOverflow</a>.</p>\n\n\n\n<p><strong>Background</strong></p>\n\n<p>This is inspired by my belief that the form domain of the Friedrichs extension of the Neumann Laplacian on $M$ is equal to $H^1(M)$. If my belief is wrong, I would certainly accept as answer a counterexample, preferably with some discussion/references.</p>\n\n<p>Here are the approaches I'm exploring.</p>\n\n<ul>\n<li>Given $u\\in C^\\infty(M)$ construct a function that agrees away from an $\\epsilon$ neighborhood of $\\partial M$, but has been modified to have zero normal derivative. This is described below, but runs into some trouble at corners and with smoothing.</li>\n<li>Given $u\\in C^\\infty(M)$, find some $\\eta$ supported on an $\\epsilon$ neighborhood of $\\partial M$ such that $\\nabla\\eta|_{\\partial M}$ is equal to the projection of $\\nabla u|_{\\partial M}$ onto the normal direction and $\\eta$ and $|\\nabla\\eta|$ uniformly bounded in $\\epsilon$. Then $u - \\eta$ will be the desired approximation and uniform boundedness will imply $\\|u - (u-\\eta)\\|_{H^1}\\to 0$. I'm not sure if this is a search for an integrable harmonic vector field or if it's a constrained optimization problem.</li>\n<li>Simply show that any $u\\in C^\\infty(M)$ that is perpendicular to all smooth functions with vanishing normal derivative must be zero. In order to do this, I think it still runs into the same fundamental difficulty as the others, which is constructing functions with vanishing normal derivative supported on an $\\epsilon$-neighborhood of the boundary.</li>\n</ul>\n\n<p>(I'm also happy to simply have a reference to follow up. A reference for domains in $\\mathbb{R}^n$ should be fine, too, and just a partition of unity away from a Riemannian manifold.)</p>\n\n\n\n<p><strong>Current Approach</strong></p>\n\n<p>The approach I'm considering right now is an elaboration on possibility (2) from my list. The sketch is: set the boundary condition that $\\nabla\\eta$ on the boundary be equal to the normal component of $\\nabla u$ and find an integrable harmonic vector field $E$ satisfying that boundary condition. Then cut off $E$ so it is only supported in a neighborhood of $\\partial M$, and let $\\eta$ be so that $E = \\nabla\\eta$.</p>\n\n<p>Intuition is that the maximum principle will control $|E|$ and $|\\eta|$, so that $\\eta$ will be bounded above in the $H^1$ norm by a constant times the volume of the $\\epsilon$-neighborhood of $\\partial M$.</p>\n\n<p>Another approach is inspired by zhw's comment below: approximate $\\nabla u$ among $L^2$ vector fields, multiply it by a cutoff function so it is supported in the interior of $M$, and then integrate it to approximate $u$. This should work with some tweaking in $[0,1]$ but I'm not sure how well it will work in general.</p>\n\n\n\n<p><strong>Older work</strong></p>\n\n<p>My approach has been as follows. The intuition is to take an arbitrary smooth function, restrict it to the complement of a collar neighborhood, then extend the restriction to the collar neighborhood so that the value is constant on inward-normal geodesics. However I'm running into issues at corners.</p>\n\n<p>Let $\\epsilon &gt; 0$ be such that $\\{p\\in M\\ |\\ d(p,\\partial M) &lt; \\epsilon\\}$ is a collar neighborhood of $\\partial M$. Let $e_\\epsilon(p)$ for $p\\in\\partial M$ be the smaller of $\\epsilon$ or the greatest time parameter such that the inward normal geodesic collides with no other inward normal geodesic. Let $N$ be the set of inward normal vectors on $\\partial M$ whose lengths are no greater than $e_\\epsilon$. The interior of the set $\\operatorname{exp}(N)$ is foliated by geodesics. Edit- Note this is not necessarily true if the manifold has inward corners.</p>\n\n<p>Given a smooth, continuous function $u$ on $M$, define $\\bar{u}$ to be the restriction of $u$ in the complement of $\\operatorname{exp}(N)$ and on each geodesic leaf of the interior of $\\operatorname{exp}(N)$ define $\\bar{u}$ to take the value that $u$ takes on the inward limit of that leaf.</p>\n\n<p>Here's trouble. As $\\bar{u}$ need not be smooth, I'd like to mollify it. Edit- I had a detail incorrect. A standard mollifier produces a function defined on compact subsets of the interior of $M$. So the mollifier has to be modified. One idea I'm following up on is varying the support of the mollifying function based on distance to $\\partial M$. I'm skeptical, as varying the mollifying function will add another component to the gradient, but if it works I'll post as an answer.</p>\n", "pids": ["5d9edb9747c8f7664601fbf6"], "flag": 0}
{"question": "Spotting crankery", "body": "<p>Underwood Dudley published a book called <a href=\"http://rads.stackoverflow.com/amzn/click/0883855070\" rel=\"noreferrer\">mathematical cranks</a> that talks about faux proofs throughout history. While it seems to be mostly for entertainment than anything else, I feel it has become more relevant in modern mathematics. Especially with the advent of arXiv, you can obtain research papers before they are peer reviewed by a journal. So how does one tell between a crank proof and a genuine proof? This seems to be <a href=\"https://mathoverflow.net/questions/6912/6916#6916\">tough to discern in general</a>. </p>\n\n<p>For instance Perelman's proof was not submitted to any journal but published online. How did professional mathematicians discern that it was a genuine proof? </p>\n\n<p>So how does one spot a <a href=\"http://en.wikipedia.org/wiki/Crank_%28person%29\" rel=\"noreferrer\">crank proof</a>? It seems that John Baez <a href=\"http://math.ucr.edu/home/baez/crackpot.html\" rel=\"noreferrer\">once (humorously) proposed a \"crackpot checklist\"</a>. Would this seem like a fair criterion?</p>\n", "pids": ["53e9bd76b7602d9704a12cfa", "53e9acccb7602d97036ab597"], "flag": 0}
{"question": "Are elementary and generalized hypergeometric functions sufficient to express all algebraic numbers?", "body": "<p>Are (integers) plus (elementary functions) plus (generalized hypergeometric functions) sufficient to represent any algebraic number?</p>\n\n<p>For example, the real algebraic number $\\alpha\\in(-1,0)$ satisfying\n$$65536\\,\\alpha^{10}+327680\\,\\alpha^9+327680\\,\\alpha^8-655360\\,\\alpha\n  ^7-983040\\,\\alpha^6+16720896\\,\\alpha^5\\\\+20983040\\,\\alpha^4-655360\\,\\alpha\n  ^3-109155805\\,\\alpha^2-30844195\\,\\alpha +16762589=0$$\ncan be represented as\n$$\\alpha={_4F_3}\\left(\\begin{array}c\\frac15,\\frac25,\\frac35,\\frac45\\\\\\frac12,\\frac34,\\frac54\\end{array}\\middle|\\frac1{\\sqrt5}\\right)-\\frac{1+\\sqrt5}2.$$\n(see <a href=\"http://en.wikipedia.org/wiki/Bring_radical\" rel=\"noreferrer\">Bring radical</a> for details)</p>\n\n\n\n<p>Here are answers where I used some particular cases when this representation is possible: <a href=\"https://math.stackexchange.com/a/388916/19661\">[1]</a>, <a href=\"https://math.stackexchange.com/a/506492/19661\">[2]</a>. These cases are motivating to try to find a general method applicable to all algebraic numbers.</p>\n", "pids": ["53e9af59b7602d9703998388"], "flag": 0}
{"question": "Fractional Calculus: Motivation and Foundations.", "body": "<p><em>If this is too broad, I apologise; let's keep it focused on the basics if necessary.</em></p>\n\n<blockquote>\n  <p>What's the motivation and the <strong>rigorous foundations</strong> behind <a href=\"http://en.wikipedia.org/wiki/Fractional_calculus\" rel=\"noreferrer\">fractional calculus</a>?</p>\n</blockquote>\n\n<p>It seems very weird &amp; beautiful to me. Did it arise from some set of <a href=\"https://math.stackexchange.com/questions/7296/applications-of-fractional-calculus?rq=1\">applications</a>? If so (and even if not), <a href=\"https://math.stackexchange.com/questions/399266/what-is-the-physical-meaning-of-fractional-calculus#399266\">here's a suitable question</a> concerning its \"physical meaning\" and history.</p>\n\n<p>The Wikipedia article makes it look quite clear-cut: stick $\\Gamma$ into <a href=\"http://en.wikipedia.org/wiki/Cauchy_formula_for_repeated_integration\" rel=\"noreferrer\">Cauchy's formula for repeated integration</a>. But why <em>can</em> we do that? <strong>Why is it listed under \"Heuristics\"?</strong> I know the <a href=\"http://en.wikipedia.org/wiki/Gamma_function\" rel=\"noreferrer\">Gamma function</a> generalises the factorial, but that's as much as I understand.</p>\n\n<p><em>\"Why ask?\"</em></p>\n\n<p>Because I like to see how different areas of Mathematics fit together. I like the way fractional calculus seems to take integration &amp; differentiation and ask, \"well, do we really need to do these things a natural number of times?\" - and so on. So I'm just curious :)</p>\n", "pids": ["56d818f3dabfae2eee861142"], "flag": 0}
{"question": "Why are ideals more important than subrings?", "body": "<p>I have read that subgroups, subrings, submodules, etc. are <a href=\"http://en.wikipedia.org/wiki/Substructure\">substructures</a>.</p>\n\n<p>But if you look at the definition of the Noetherian rings and Noetherian modules, Noetherian rings are defined with ideals and Noetherian modules are defined with submodules. Isn't it awkward? Why does submodule correspond to ideal, not subring? Is there any definition of Noetherian with subrings?</p>\n\n<p>As I'm studying commutative algebra, it looks like ideals are more important than subrings. But why is it ideal, not subring (which seems to correspond to all other substructures)? Though I am not very familiar with <a href=\"http://en.wikipedia.org/wiki/Pseudo-ring\">pseudo-rings</a>, is it true that ideal is a sub-pseudo-ring (or sub-rng) and thus we can view ideal as a kind of substructure?</p>\n", "pids": ["53e9a7cfb7602d970310ab9e"], "flag": 1}
{"question": "How to cite preprints from arXiv?", "body": "<p>Obviously when writing a math research paper it is good to cite one's references. However, with the advent of arXiv, oftentimes a paper is only available on arXiv while is awaits the long process of peer-review. But here a problem arises: how does one cite an arXiv preprint? </p>\n\n<p>Note: I would be nice if a bibTeX template was included.</p>\n", "pids": ["56d87009dabfae2eeeed469b"], "flag": 0}
{"question": "Why is the topological pressure called pressure?", "body": "<p>Let us consider a compact topological space $X$, and a continuous function $f$ acting on $X$. One of the most important quantities related to such a topological dynamical system is the entropy.</p>\n\n<p>For any probability measure $\\mu$ on $X$, one can define the measure-theoretic (or Kolmogorov-Sinai) <a href=\"http://www.scholarpedia.org/article/Kolmogorov-Sinai_entropy\">entropy</a>. Without reference to any measure, one can define the <a href=\"http://www.scholarpedia.org/article/Topological_entropy\">topological entropy</a>, which has the good property of being and invariant under homeomorphism. These two notions are related <em>via</em> a variational principle:</p>\n\n<p>$$h_\\mathrm{top} (f) = \\sup_{\\{\\mu\\ \\mathrm{inv.}\\}} h_\\mu (f),$$</p>\n\n<p>and are also related to the physical notion of entropy of a system (well, the KS entropy is, at least. The case for the topological entropy is less clear for me, although things behave nicely in the cases I know and which have a physical interest).</p>\n\n<p>Given a continuous potential $\\varphi:X \\to \\mathbb{R}$, one can define the <a href=\"http://www.scholarpedia.org/article/Pressure_And_Equilibrium_States\">topological pressure</a> $P(\\varphi, f)$ by mimicking the definition of the topological entropy (other definitions include the following equation, and some extensions for complex potentials). Then one can get another variational principle:</p>\n\n<p>$$P (\\varphi, f) = \\sup_{\\{\\mu \\ \\mathrm{inv.}\\}} \\left\\{ \\int_X \\varphi \\ d \\mu + h_\\mu (f) \\right\\}.$$</p>\n\n<p>The RHS in the variational principle above is the supremum of $\\int_X \\varphi \\ d \\mu + h_\\mu (f)$, which is, up to a change of sign (1), what is called in physics the free energy of the system. And we try to maximize it, as in physics (modulo the change of sign).</p>\n\n<p>So it would seem logical if, as we have measure-theoretic and topological entropy, we would have measure-theoretic and topological free energy. And I can't find why one would like to call \"pressure\" what is the maximum of the free energy. I looked at some old works by David Ruelle, but couldn't find how this term was coined, and soon ran into the \"not on the Internet nor in the library\" wall. It may have something to do with lattices gases, but I emphasize the \"may\".</p>\n\n<p>So my question is: why is this thing called pressure? </p>\n\n<ol>\n<li>The first clue is that the entropy has a positive, and not negative, sign. The second is that we try to maximize the quantity, while in physics one tries to minimize it. Other clues include the fact that, in non-compact cases, a good condition is to have $\\lim_\\infty \\varphi = - \\infty$, again in opposition with physics.</li>\n</ol>\n\n<p><strong>Edit</strong>: I have asked three people which are familiar with the subject, but none gave me a good answer (actually, I got somewhat conflicting answer). I am starting a bounty to draw some attention, but this might be better suited to MathOverflow...</p>\n", "pids": ["53e9bc27b7602d9704893182"], "flag": 0}
{"question": "Dividing an equilateral triangle into N equal (possibly non-connected) parts", "body": "<p>It’s easy to divide an equilateral triangle into <span class=\"math-container\">$n^2$</span>, <span class=\"math-container\">$2n^2$</span>, <span class=\"math-container\">$3n^2$</span> or <span class=\"math-container\">$6n^2$</span> equal triangles.</p>\n<p>But can you divide an equilateral triangle into 5 congruent parts? Recently M. Patrakeev <a href=\"https://www.jstor.org/stable/10.4169/amer.math.monthly.124.6.547\" rel=\"nofollow noreferrer\">found</a> an awesome way to do it — see the picture below (note that the parts are non-connected — but indeed are congruent, not merely having the same area). So an equilateral triangle can also be divided into <span class=\"math-container\">$5n^2$</span> and <span class=\"math-container\">$10n^2$</span> congruent parts.</p>\n<blockquote>\n<p><strong>Question.</strong> Are there any other ways to divide an equilateral triangle into congruent parts? (For example, can it be divided into 7 congruent parts?) Or in the opposite direction: can you prove that an equilateral triangle can’t be divided into <span class=\"math-container\">$N$</span> congruent parts for some <span class=\"math-container\">$N$</span>?</p>\n</blockquote>\n<p>                                            <a src=\"https://i.stack.imgur.com/6j9W7.png\" width=\"300\"></p>\n<p>(Naturally, I’ve tried to find something in the spirit of the example above for some time — but to no avail. Maybe someone can find an example using computer search?..)</p>\n<p>I’d prefer to use finite unions of polygons as ‘parts’ and different parts are allowed to have common boundary points. But if you have an example with more general ‘parts’ — that also would be interesting.</p>\n", "pids": ["5ce2d09eced107d4c639b478"], "flag": 0}
{"question": "Trying to visualize the hierarchy of mathematical spaces", "body": "<p>I was inspired by <a href=\"https://commons.wikimedia.org/wiki/File:Mathematical_implication_diagram-alt-large-print.svg\" rel=\"noreferrer\">this</a> flowchart of mathematical sets and wanted to try and visualize it, since I internalize math best in that way. This is what I've come up with so far:</p>\n\n<p><a href=\"https://i.stack.imgur.com/g7CYc.jpg\" rel=\"noreferrer\"><strong>Version 1 (old diagram)</strong></a></p>\n\n<p><strong>Version 2:</strong>\n<a href=\"https://i.stack.imgur.com/o3WPh.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/o3WPh.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>Is there anything that I'm missing, or that is incorrectly marked? For example, where exactly should I insert a box for Fréchet Spaces? And, is it safe to say that Normed Vector Spaces are a <em>proper</em> subset of the intersection between Locally Convex Spaces and Metric Spaces (or is it the entire intersection?)</p>\n\n<p><strong>Edit:</strong>\nThank you, everyone, for your input. Obviously no single diagram is going to encapsulate the entirety of functional analysis, geometry, and topology (not to mention the myriad of algebraic structures I've ignored, as some of you have pointed out.) As someone who does a lot of analysis, I would often find myself going back to Wikipedia or my textbooks to re-read the definitions of the various spaces and sets I am working with. I just wanted something that could help me keep a lot of these ideas straight in my head; and was pretty and useful to glance at. I think I've settled on my final version (for now.) In summary, here is a quick bullet list of the labeled components of the diagram:</p>\n\n<ul>\n<li><strong>Topological Spaces</strong>: sets with a notion of what is \"open\" and \"closed\".</li>\n<li><strong>Vector Spaces</strong>: sets with operations of \"addition\" and \"(scalar) multiplication\".</li>\n<li><strong>Topological Vector Spaces</strong>: \"addition\" and \"multiplication\" are <em>continuous</em> in the topology.</li>\n<li><strong>Metric Spaces</strong>: sets that come with a way to measure the \"distance\" between two points, called a <em>metric</em>; the topology is generated by this metric.</li>\n<li><strong>Locally Convex Spaces</strong>: sets where the topology is generated by translations of \"balls\" (<em>balanced</em>, <em>absorbent</em>, <em>convex</em> sets); do not necessarily have a notion of \"distance\".</li>\n<li><strong>Normed Vector Spaces</strong>: sets where the topology is generated by a norm, which in some sense is the measure of a vector's \"length\". A norm can always generate a metric (measure the \"length\" of the difference of two vectors), and every normed space is also locally convex.</li>\n<li><strong>Fréchet Spaces</strong>: a set where the topology is generated by a translation-invariant metric; this metric <em>doesn't</em> necessarily have to come from a norm. All Fréchet spaces are <em>complete</em> metric spaces (meaning that if elements of a sequence get arbitrarily \"close\", then the sequence must converge to an element already in the space.)</li>\n<li><strong>Banach Spaces</strong>: a set that is a complete metric space, where the metric is defined in terms of a norm.</li>\n<li><strong>Inner Product Spaces</strong>: sets with a way to measure \"angles\" between vectors, called an <em>inner product</em>. An inner product can always generate a norm, but the space may or may not be complete with respect to this norm.</li>\n<li><strong>Hilbert Spaces</strong>: an inner product space that is <em>complete</em> with respect to this induced norm. Any inner product space that is incomplete (called a \"pre-Hilbert Space\") can be completed to a Hilbert space.</li>\n<li><strong>Manifold</strong>: a set with a topology that locally \"looks like\" Euclidean space. Any manifold can be turned into a metric space.</li>\n</ul>\n", "pids": ["5cf48a1eda56291d5827f8c8"], "flag": 0}
{"question": "How many ways are there to eat a chocolate bar?", "body": "<p>I'm teaching an intro programming course and came up with a recursion problem for my students to solve that's inspired by the game <a href=\"https://en.wikipedia.org/wiki/Chomp\" rel=\"noreferrer\">Chomp</a>. Here's the problem statement:</p>\n\n<blockquote>\n  <p>You have a chocolate bar that’s subdivided into individual squares.\n  You decide to eat the bar according to the following rule: <strong><em>if you\n  choose to eat one of the chocolate squares, you have to also eat every\n  square below and/or to the right of that square.</em></strong></p>\n  \n  <p>For example, here’s one of the many ways you could eat a 3 × 5\n  chocolate bar while obeying the rule. The star at each step indicates\n  the square chosen out of the chocolate bar, and the gray squares\n  indicate which squares must also be eaten in order to comply with the\n  above rule.</p>\n  \n  <p><a src=\"https://i.stack.imgur.com/5gjUe.png\" alt=\"enter image description here\"></p>\n  \n  <p>The particular choice of the starred square at each step was\n  completely arbitrary, but once a starred square is picked the choice\n  of grayed-out squares is forced. You have to eat the starred square,\n  plus each square that’s to the right of that square, below that\n  square, or both. The above route is only one way to eat the chocolate\n  bar. Here’s another:</p>\n  \n  <p><a src=\"https://i.stack.imgur.com/8pp1M.png\" alt=\"enter image description here\"></p>\n  \n  <p>As before, there’s no particular pattern to how the starred squares\n  were chosen, but once we know which square is starred the choice of\n  gray squares is forced.</p>\n  \n  <p>Now, given an <span class=\"math-container\">$m \\times n$</span> candy bar, determine the number of different ways you can eat the candy bar while obeying the above rule.</p>\n</blockquote>\n\n<p>When I gave this to my students, I asked them to solve it by writing a recursive function that explores all the different routes by which the chocolate bar could be eaten. But as I was writing this problem, I started wondering - is there a closed-form solution?</p>\n\n<p>I used my own solution to this problem to compute the number of different sequences that exist for different values of <span class=\"math-container\">$m$</span> and <span class=\"math-container\">$n$</span>, and here's what I found:</p>\n\n<p><span class=\"math-container\">$$\\left(\\begin{matrix}\n1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1\\\\\n1 &amp; 1 &amp; 2 &amp; 4 &amp; 8 &amp; 16 &amp; 32\\\\\n1 &amp; 2 &amp; 10 &amp; 58 &amp; 370 &amp; 2514 &amp; 17850\\\\\n1 &amp; 4 &amp; 58 &amp; 1232 &amp; 33096 &amp; 1036972 &amp; 36191226\\\\\n1 &amp; 8 &amp; 370 &amp; 33096 &amp; 4418360 &amp; 768194656 &amp; 161014977260\\\\\n1 &amp; 16 &amp; 2514 &amp; 1036972 &amp; 768194656 &amp; 840254670736 &amp; 1213757769879808\\\\\n1 &amp; 32 &amp; 17850 &amp; 36191226 &amp; 161014977260 &amp; 1213757769879808 &amp; 13367266491668337972\n\\end{matrix}\\right)$$</span></p>\n\n<p>Some of these rows show nice patterns. The second row looks like it's all the powers of two, and that makes sense because if you have a <span class=\"math-container\">$1 \\times n$</span> chocolate bar then any subsequence of the squares that includes the first square, taken in sorted order, is a way to eat the candy bar. The third row shows up as <a href=\"http://oeis.org/A086871\" rel=\"noreferrer\">A086871</a> on the OEIS, but none of the rows after that appear to be known sequences. The diagonal sequence also isn't on the OEIS,</p>\n\n<p>I believe that this problem is equivalent to a different one:</p>\n\n<blockquote>\n  <p>Consider the partial order defined as the Cartesian product of the less-than relation over the sets <span class=\"math-container\">$[m] = \\{0, 1, 2, ..., m - 1\\}$</span> and <span class=\"math-container\">$[n]$</span>. How many distinct sequences of elements of this partial order exist so that no term in the sequence is dominated by any previous element and the final element is the maximum element of the order?</p>\n</blockquote>\n\n<p>I'm completely at a loss for how to determine the answer to that question.</p>\n\n<p>Is there a nice closed-form solution to this problem?</p>\n", "pids": ["5c89158f4895d9cbc6ae547a"], "flag": 0}
{"question": "Applications of the wreath product?", "body": "<p>We recently went through the wreath product in my group theory class, but the definition still seems a bit unmotivated to me. The two reasons I can see for it are 1) it allows us to construct new groups, and 2) we can use it to reconstruct imprimitive group actions. Are there any applications of the wreath product outside of pure group theory?</p>\n", "pids": ["5c8f1e604895d9cbc62b2122", "5f2fcbe79fced0a24bf90f83"], "flag": 0}
{"question": "Should I understand a theorem&#39;s proof before using the theorem?", "body": "<p>I find myself embarrassed when using results in books. </p>\n\n<p>For example, there are so many results in Sobolev spaces that I think I would not be able to understand all of them. </p>\n\n<p>Yes, I could try to understand some of them but I often find I need more, and one theorem relies on another before it, so it takes time to trace back. </p>\n\n<p>What is your experience / what do you suggest?</p>\n\n<p><strong>Edit:</strong> Sometimes, I am worried that if very few users of a theorem really verify the proof, like software that is poorly-tested, there might be some bugs inside.</p>\n", "pids": ["5e75e8b393d709897c2bd886"], "flag": 0}
{"question": "What is a Manifold?", "body": "<p>Now we always encounter definition of a <a href=\"http://en.wikipedia.org/wiki/Manifold\">manifold</a> from a mathematical point of view where it is a topological space along with a family of open sets that covers it and the same old symphony. My question is from your own expertise and from what you have learned and taught to day, how can we get a deeper understanding to what's a Manifold? Maybe from a more physics-point of view?</p>\n", "pids": ["58d82fd2d649053542fd75d8"], "flag": 0}
{"question": "Is there active research in Galois Theory?", "body": "<p>I recently decided to introduce myself to the field of Modern Algebra - in particular, Galois theory - and I found it absolutely beautiful! Thus I would really like to study something in Galois theory, which leads me to ask - do people still develop Galois theory? What else is there to learn in the subject?</p>\n<p>I am inspired by questions like these:\n<a href=\"https://math.stackexchange.com/questions/181220/what-kind-of-work-do-modern-day-algebraists-do\">What kind of work do modern day algebraists do?</a> and <a href=\"https://math.stackexchange.com/questions/94620/what-do-modern-day-analysts-actually-do/154967\">What do modern-day analysts actually do?</a> and would love to learn your opinions, stories, etc!</p>\n<p>Thanks in advance!</p>\n", "pids": ["53e9af12b7602d970394a253", "5c756cc2f56def97984c06d9", "56d9099adabfae2eee0dd40a", "5c75754ef56def97989db736", "5c7566d7f56def9798112ef2"], "flag": 0}
{"question": "Painting the plane, and finding points one unit apart", "body": "<p>An old (rather easy) contest problem reads as follows:</p>\n\n<blockquote>\n  <p>Each point in a plane is painted one of two colors. Prove that there exist two points exactly one unit apart that are the same color.</p>\n</blockquote>\n\n<p>This proof can be easily written by constructing an equilateral triangle of side length $1$ unit and asserting that it is impossible for the colors of all three vertices to be pairwise unequal.</p>\n\n<p>However, I was curious about the trickier problem</p>\n\n<blockquote>\n  <p>Each point in a plane is painted one of <strong>three</strong> colors. Do there exist two points exactly one unit apart that are the same color?</p>\n</blockquote>\n\n<p>...now, if this happened in $3$-space, I could construct a tetrahedron... but I can't do this in $2$-space. Does this not work with three colors, or is the proof just more complicated? If it doesn't work, how can I construct a counterexample?</p>\n", "pids": ["5c7574bbf56def979897a366"], "flag": 0}
{"question": "Proofs that the degree of an irrep divides the order of a group", "body": "<p>It is a theorem in basic representation theory that the degree of an irreducible representation on $G$ over $\\mathbb{C}$ divides the order of $G$.  The usual proof of this fact involves <em>algebraic integers</em> (see for example Fulton &amp; Harris' <em>Representation Theory</em>, Serre's <em>Linear representations of finite groups</em>, or Simon's <em>Representations of finite and compact groups</em>).  However I find this proof somewhat unsatisfying precisely because it uses algebraic integers, which don't show up much elsewhere in basic representation theory, and it is not at all evident why algebraic integers should be used.  I feel that there has to be another proof of this theorem that uses techniques of group theory and representation theory, but the only other proof I know is one by <a href=\"http://arxiv.org/abs/1102.4353\">Kopp and Wiltshire-Gordon</a>, but that proof seems to use even more complicated ideas if not machinery!</p>\n\n<p>What are some other proofs of this theorem?  </p>\n", "pids": ["53e9a9beb7602d970331c907"], "flag": 0}
{"question": "Prove $_2F_1\\left(\\frac13,\\frac13;\\frac56;-27\\right)\\stackrel{\\color{#808080}?}=\\frac47$", "body": "<p>I discovered the following conjecture numerically, but have not been able to prove it yet:\n$$_2F_1\\left(\\frac13,\\frac13;\\frac56;-27\\right)\\stackrel{\\color{#808080}?}=\\frac47.\\tag1$$\nThe equality holds with at least $10000$ decimal digits of precision. It can be written in equivalent forms in terms of definite integrals:\n$${\\large\\int}_0^1\\frac{dx}{\\sqrt{1-x}\\ \\sqrt[3]{x^2+(3x)^3}}\\stackrel{\\color{#808080}?}=\\frac{\\sqrt[3]4\\,\\sqrt3}{7\\pi}\\Gamma^3\\!\\!\\left(\\tfrac13\\right),\\tag2$$\nor\n$${\\large\\int}_0^\\pi\\frac{d\\phi}{\\sqrt[3]{\\sin\\phi}\\,\\sqrt[3]{55+12\\sqrt{21}\\cos\\phi}}\\stackrel{\\color{#808080}?}=\\frac{\\sqrt[3]4\\,\\sqrt3}{7\\pi}\\Gamma^3\\!\\!\\left(\\tfrac13\\right).\\tag3$$</p>\n\n\n\n<p><em>Update:</em> A several more equivalent forms:\n$$_2F_1\\left(\\frac13,\\frac12;\\frac56;\\frac{27}{28}\\right)\\stackrel{\\color{#808080}?}=\\frac{2^{\\small8/3}}{7^{\\small2/3}}\\tag4$$\n$$\\int_0^\\infty\\frac{dx}{\\sqrt[3]{55+\\cosh x}}\\stackrel{\\color{#808080}?}=\\frac{\\sqrt[3]2\\,\\sqrt3}{7\\pi}\\Gamma^3\\!\\!\\left(\\tfrac13\\right)\\tag5$$\n$$C_{\\small-1/3}^{\\small(1/3)}(55)\\stackrel{\\color{#808080}?}=\\frac{3}{7\\pi^2}\\Gamma^3\\!\\!\\left(\\tfrac13\\right)\\tag6$$\n$$P_{\\small-1/2}^{\\small1/6}(55)\\stackrel{\\color{#808080}?}=\\frac{\\sqrt2\\,\\sqrt[4]3\\,e^{\\small-\\pi\\,i/12}}{7^{\\small13/12}\\,\\pi^{\\small3/2}}\\Gamma^2\\!\\!\\left(\\tfrac13\\right)\\tag7$$\nwhere $C_n^{(\\lambda)}(x)$ is the <a href=\"http://mathworld.wolfram.com/GegenbauerPolynomial.html\">Gegenbauer polynomial</a> and $P_l^m(x)$ is the <a href=\"http://mathworld.wolfram.com/LegendreFunctionoftheFirstKind.html\">Legendre function of the first kind</a>.</p>\n\n\n\n<ul>\n<li>Please suggest ideas how to prove this conjecture.</li>\n<li>What are other points where the function $_2F_1\\left(\\frac13,\\frac13;\\frac56;z\\right)$ takes simple special values?</li>\n</ul>\n", "pids": ["53e9bac2b7602d97046f00d5"], "flag": 0}
{"question": "Elementary proof of the fact that any orientable 3-manifold is parallelizable", "body": "<p>A parallelizable manifold $M$ is a smooth manifold such that there exist smooth vector fields $V_1,...,V_n$ where $n$ is the dimension of $M$, such that at any point $p\\in M$, the tangent vectors $V_1(p),...,V_n(p)$ provide a basis for the tangent space at $p$. Equivalently, a manifold is parallelizable if its tangent bundle is trivial.</p>\n\n<p>There is a theorem that states that any compact orientable 3-manifold is parallelizable, and \nthere is a proof of this result which uses $spin^c$ structures and the Steifel-Whitney class.</p>\n\n<p>I am wondering whether there exists a more elementary, perhaps more straightforward proof. Otherwise, I would be grateful for some intuition on why this is true.\nAlso, it the theorem still true without the compactness assumption? If so, is there a relatively simple proof in that case?</p>\n", "pids": ["5c7575a9f56def9798a1817e"], "flag": 0}
{"question": "Sum of Square roots formula.", "body": "<p>I would like to know if there is formula to calculate sum of series of square roots $\\sqrt{1} + \\sqrt{2}+\\dotsb+ \\sqrt{n}$ like the one for the series $1 + 2 +\\ldots+ n = \\frac{n(n+1)}{2}$.</p>\n\n<p>Thanks in advance.</p>\n", "pids": ["56d86eb1dabfae2eeee2e13c"], "flag": 0}
{"question": "Find the closed form of $\\sum_{n=1}^{\\infty} \\frac{H_{ n}}{2^nn^4}$", "body": "<p>One of the possible ways of computing the series is to obtain the generating function, but<br>\nthis might be a tedious, hard work, pretty hard to obtain. What would you propose then? </p>\n\n<p>$$\\sum_{n=1}^{\\infty}  \\frac{H_{\nn}}{2^nn^4}$$</p>\n", "pids": ["61d65e0b5244ab9dcbf1610b"], "flag": 0}
{"question": "When is $2^n \\pm 1$ a perfect power", "body": "<p>Is there an easy way of showing that $2^n \\pm 1$ is never a perfect power, except for $2^3 + 1 = 3^2 $?</p>\n\n<p>I know that  <a href=\"http://en.wikipedia.org/wiki/Catalan%27s_conjecture\">Catalan's conjecture (or Mihăilescu's theorem)</a> gives the result directly, but I'm hopefully for a more elementary method.</p>\n\n\n\n<p>I can show that it is never a square, except for $2^3 + 1$.</p>\n\n<p>Proof: Cases $n=1, 2, 3$ are easily dealt with. Henceforth, let $n\\geq4$.</p>\n\n<p>$2^n -1 \\equiv 3 \\pmod{4}$ hence is never a square.   </p>\n\n<p>If $2^n +1 =x^2$, then $2^n = (x-1)(x+1)$ and both of these are powers of 2. Thus we must have $(x-1) = 2, (x+1) = 4$. This gives the solution of $2^3 + 1 = 3^2$.</p>\n\n\n\n<p>Let's now do an odd prime.</p>\n\n<p>Say $2^n +1 = x^p$. Then $2^n = x^p - 1 = (x-1)(x^{p-1}+x^{p-2} + \\ldots +1)$, so both terms are powers of 2. We have $ x = 2^m+1$ is odd. But the other term is the sum of $p$ odd numbers, hence is odd. Since this is clearly greater than 1, we get a contradiction.</p>\n\n<p>Say $2^n -1 = x^p$. Then $2^n = x^p + 1 = (x+1)(x^{p-1} - x^{p-2} + \\ldots -x +1 )$, so both terms are powers of 2. We have $x = 2^m -1$ is odd. But the other term is the sum of $p$ odd numbers, hence is odd. Since $x^p + 1 \\neq x+1$ except for $p=1$, this means that the term is greater than 1. Hence we get a contradiction.</p>\n", "pids": ["5c756ddaf56def979856ef7c"], "flag": 0}
{"question": "How is Category Theory used to study differential equations?", "body": "<p>I know that one can use Category Theory to formulate polynomial equations by modeling solutions as limits. For example, the sphere is the equalizer of the functions\n\\begin{equation}\n  s,t:\\mathbb{R}^3\\rightarrow\\mathbb{R},\\qquad s(x,y,z):=x^2+y^2+z^2,~t(x,y,z)=1.\n  \\label{equalizer}\n\\end{equation}\nOne could then find out more about the solution set by mapping the equalizer diagram into other categories. More generally, solution sets of polynomial equations (and more generally, <a href=\"https://en.wikipedia.org/wiki/Algebraic_variety\" rel=\"noreferrer\">algebraic varieties</a>) are a central study object of algebraic geometry.</p>\n\n<p>As differential equations are central to all areas of physics, I assume that there have been made a lot of attempts to generalise these ideas to solution sets of these. However, I do not yet have a lot of knowledge about algebraic geometry, topos theory or synthetic differential geometry. Thus I would be grateful if someone could explain roughly where and how Category Theory is used to study differential equations. </p>\n\n<p>Can Category Theory really <strong>help to solve</strong> differential equations (for example by mapping diagrams of equations to other categories, similarly to how problems of topology are often solved by mapping topological spaces to algebraic ones in algebraic topology) or can it \"only\" provide schemes for generalising differential equations to other spaces/categories?</p>\n\n<p>I am particularly interested in names of areas I have to look into if I want to understand this better. Also literature recommendation would be very welcome. \n<br><br><br>\n<strong>EDIT</strong>: I found a book by Vinogradov called <a href=\"http://books.google.dk/books?id=XIve9AEZgZIC\" rel=\"noreferrer\">Cohomological Analysis of Partial Differential Equations and Secondary Calculus</a> where \"the main result [...] is Secondary Calculus on diffieties\". </p>\n\n<p>However, the material is very deep and thus I am still not completely able to say whether these \"new geometrical objects which are analogs of algebraic varieties\" can be used to help solving PDEs or if they serve to structure the theory of PDEs or result in other applications I am not aware of. Thus further information would be very appreciated!</p>\n", "pids": ["53e9ac54b7602d9703623dd3", "5c756bfbf56def979843ed10"], "flag": 0}
{"question": "What is that thing that keeps showing in papers on different fields?", "body": "<p>A few months ago, when I was studying strategies for the evaluation of functional programs, I found that the optimal algorithm uses something called Interaction Combinators, <a href=\"https://i.stack.imgur.com/eD36T.jpg\" rel=\"nofollow noreferrer\">a graph system based on a few nodes and rewrite rules</a>. </p>\n\n<p><a src=\"https://i.imgur.com/lZHc4Em.png\" alt=\"**Image**\"></p>\n\n<p>I've implemented and got some <a href=\"https://stackoverflow.com/questions/31707614/why-are-%CE%BB-calculus-optimal-evaluators-able-to-compute-big-modular-exponentiation\">surprising results</a> with it. I tried learning more, only to realize there are very few papers and almost nobody talking about it. Another day, by sheer luck, I stumble with <a href=\"http://arxiv.org/pdf/1403.8046.pdf\" rel=\"nofollow noreferrer\">this paper</a> about chemical computers that would be \"the future of computation\". Midway through my read, I see this:</p>\n\n<p><a src=\"https://i.imgur.com/kCG1I7V.png\" alt=\"**Image**\"></p>\n\n<p>The similarity to Interaction Nets in striking. The nodes, the rules, the principal ports - on its core, the system is mostly the same. I tried looking at references to find more about \"it\", but didn't find anything very relevant, so I gave up. Another day, by sheer luck once again, I sumble with <a href=\"http://graphicallinearalgebra.net/2015/05/19/paths-and-matrices-part-1/\" rel=\"nofollow noreferrer\">this blog post</a> about some kind of graphical linear algebra that \"can divide by zero\". Midway through the read, I see this:</p>\n\n<p><a src=\"https://graphicallinearalgebra.files.wordpress.com/2015/05/cheat3.gif\" alt=\"**Image**\"></p>\n\n<p>Once again, the same \"thing\" can be seen. There are some minor differences but, on its core, it is the same. <strong>What is that thing in common with those systems?</strong> How is it called, what is its importance, where is it studied and, most importantly, why it keeps showing in completely different fields?</p>\n", "pids": ["5c6107a5da56297340b114ba"], "flag": 0}
{"question": "Do nonconstructive proofs of isomorphism exist?", "body": "<p>I'm interested in proofs of claims of the form &quot;Finite objects <span class=\"math-container\">$A$</span> and <span class=\"math-container\">$B$</span> are isomorphic&quot; which are nonconstructive, in the sense that the proof doesn't exhibit the actual isomorphism at hand.</p>\n<p>A stronger (and more precisely specified) requirement would be a case in which it's computationally easy to write a proof, but computationally hard to extract the isomorphism given the proof, e.g. a class of graphs for which one can easily generate triples <span class=\"math-container\">$(G,H,P)$</span> with <span class=\"math-container\">$P$</span> a proof that <span class=\"math-container\">$G$</span> and <span class=\"math-container\">$H$</span> are isomorphic but for which there's no (known) efficient algorithm to take in <span class=\"math-container\">$(G,H,P)$</span> and return a permutation of the vertices exhibiting the isomorphism.</p>\n<p>Some examples of things that would fit the bill, were they to exist:</p>\n<ul>\n<li><p>(give a nonconstructive proof that) all objects of type <span class=\"math-container\">$X$</span> are uniquely specified by their values on five specific measurements; observe that <span class=\"math-container\">$A$</span> and <span class=\"math-container\">$B$</span> align on all such measurements.</p>\n</li>\n<li><p>The easy-to-compute function of graphs <span class=\"math-container\">$f(G,H)$</span> turns out to be equal to the product, over all relabelings of <span class=\"math-container\">$G$</span>, of the number of edges in the symmetric differences between the edge sets of <span class=\"math-container\">$H$</span> and the relabeled copy of <span class=\"math-container\">$G$</span>. (This occurs because of some cute algebraic cancellation or something, like how one can compute determinants in time <span class=\"math-container\">$O(n^3)$</span>.) Now we observe that <span class=\"math-container\">$f(G,H) = 0$</span> via direct computation, and conclude that a relabeling with no difference at all to <span class=\"math-container\">$H$</span> must exist.</p>\n</li>\n<li><p>Groups <span class=\"math-container\">$G$</span> and <span class=\"math-container\">$H$</span> of order <span class=\"math-container\">$n$</span>, specified by their multiplication tables, can be easily shown to embed as subgroups of a larger group <span class=\"math-container\">$K$</span>, which we can classify and more easily prove things about. But the existence of two non-isomorphic subgroups of order <span class=\"math-container\">$n$</span> in <span class=\"math-container\">$K$</span> would imply something about its Sylow subgroups that we know to be false.</p>\n</li>\n</ul>\n<p>Are there good examples of this phenomenon? Reasons to think it doesn't happen? I would also be interested in any pointers to literature on related topics here.</p>\n", "pids": ["5cede10dda562983788ed7f6", "5cede109da562983788e97d9"], "flag": 0}
{"question": "Why should I care about fields of positive characteristic?", "body": "<p>This is what I know about why someone might care about fields of positive characteristic:</p>\n\n<ol>\n<li>they are useful for number theory</li>\n<li>in algebraic geometry, a theory of \"geometry\" can be developed over them, and it's fun to see how this geometry works out</li>\n</ol>\n\n<p>Some people might read this and think, \"What more could you need?\" But I've never been able to make myself care about number theory, so (1) doesn't help me. (2) is nice for what it is, but I'm hoping there's something more. My understanding of (2) is that this is only geometry in a rather abstract sense and, for instance, there's no generally useful way to directly visually represent these fields or varieties over them the way we can over the reals or complex numbers. (Drawing a curve in R^2 and saying it's the curve over some other field may be helpful for some purposes, but it's not what I'm after here.)</p>\n\n<p>Is there anything else? The ideal (surely impossible) answer for me would be \"Yes, such fields are very good models for these common and easy to understand physical systems: A, B, C. Also, we can visualize them and varieties over them quite easily by method D. Finally, here's a bunch of surprising and helpful applications to 500 other areas of mathematics.\"</p>\n\n<p>UPDATE: to answer Qiaochu's comment about what I do care about.</p>\n\n<p>Let's say I care about:</p>\n\n<p>algebraic &amp; geometric topology</p>\n\n<p>differential geometry &amp; topology</p>\n\n<p>applications to physics</p>\n\n<p>and I certainly care about algebraic geometry over C</p>\n\n<p>(this is to say I understand the motivations behind these subjects and the general idea, not necessarily that I know them in depth)</p>\n", "pids": ["53e9abfdb7602d97035bc324", "53e9abfdb7602d97035bc324"], "flag": 0}
{"question": "Does the equation $x^4+y^4+1 = z^2$ have a non-trivial solution?", "body": "<p>The background of this question is this: Fermat proved that the equation,\n$$x^4+y^4 = z^2$$</p>\n\n<p>has no solution in the positive integers. If we consider the near-miss,\n$$x^4+y^4-1 = z^2$$</p>\n\n<p>then this has plenty (in fact, an infinity, as it can be solved by a Pell equation). But J. Cullen, by exhaustive search, found that the other near-miss,\n$$x^4+y^4+1 = z^2$$</p>\n\n<p>has none with $0 &lt; x,y &lt; 10^6$.</p>\n\n<p>Does the third equation really have none at all, or are the solutions just enormous?</p>\n", "pids": ["62294ec35aee126c0f0920a0", "56d83e82dabfae2eee74f571"], "flag": 0}
{"question": "What is this mathematical equation from Fringe?", "body": "<p>The following mathematical equation was shown during the television show <em><a href=\"https://en.wikipedia.org/wiki/Fringe_%28TV_series%29\" rel=\"nofollow noreferrer\">Fringe</a></em> which aired on Friday, April 22nd. Any idea what it is?</p>\n\n<p><a src=\"https://i.stack.imgur.com/g7P66.png\" alt=\"Fringe formula\"></p>\n\n<p>(edit by J.M.: for reference, this was <a href=\"https://en.wikipedia.org/wiki/List_of_Fringe_characters#Sam_Weiss\" rel=\"nofollow noreferrer\">Sam Weiss</a> scribbling formulae in his notebook.)</p>\n", "pids": ["56d92db4dabfae2eeee71129"], "flag": 0}
{"question": "Proof of recursive formula for &quot;fusible numbers&quot;", "body": "<p>The set of fusible numbers is a fantastic set of rational numbers defined by a simple rule. The story is well told <a href=\"http://www.mathpuzzle.com/fusible.pdf\">here</a> but I'll repeat the definitions. It's the formula on slide 17 that I'm trying to understand. </p>\n\n<p>Define $\\displaystyle a \\oplus b = \\frac{a+b+1}{2}$. A number is <strong><em>fusible</em></strong> if it is $0$ or if it can be written as $a \\oplus b$ where $a, b$ are fusible and $|a-b|&lt;1$. Let $F$ be the set of fusible numbers. More formally, $F$ is the intersection of all sets of real numbers that are closed under $\\oplus$ applied to arguments at a distance at most 1. </p>\n\n<p>The set $F$ is a well-ordered set of non-negative rational numbers. The proof that it's well-ordered isn't included in the PDF file I linked to, but it's not hard to show this. (It wouldn't be true if we hadn't insisted on the condition $|a-b|&lt;1$, by the way.)</p>\n\n<p>Amazingly, the order type of $F$ is $\\varepsilon_0$. It's also true that $F$ is closed under ordinary addition; this isn't hard to prove either but I don't know if it plays a part in what follows.</p>\n\n<p>Because $F$ is well-ordered, we may define $f(x)$ to be the least fusible number greater than $x$, for any real $x$. Further, set $m(x) = f(x)-x$. We obviously have $m(x) = -x$ for $x&lt;0$, while for $x \\geq 0$, it is posited that\n$$m(x) = \\frac{1}{2}m(x-m(x-1))$$ \nThe question is: <strong>why is this last formula true?</strong></p>\n\n<p>I'm able to show one of the necessary inequalities, namely that $\\displaystyle m(x) \\leq \\frac{1}{2}m(x-m(x-1))$: <br>\nGiven $x$, observe that \n$$(x-1+t) \\oplus (x-t+u) = x + u/2$$ \nTake $t = m(x-1)$, which guarantees that ($x-1+t$) is indeed fusible. Now set $u = m(x-t)$ which makes ($x-t+u$) fusible as well, and the distance between those two fusible numbers can't be greater than $1$. It follows that ($x+u/2$) is fusible, and so $m(x)$ is at most $u/2$ for that particular $u$, which is indeed $m(x-m(x-1))$. </p>\n\n<p>The question, then, is: </p>\n\n<p><em>How can we prove that no other choice of $t$ yields an even smaller value for $m(x)$?</em> </p>\n\n<p>It's not hard to show that there's no loss of generality in focusing on $x-1+t$ and $x-t+m(x-t)$, but greedily minimizing $t$ by setting $t=m(x-1)$ is not in any obvious way guaranteed to yield the minimum value for $m(x)$, as far as I can see. </p>\n\n<p>What am I missing?</p>\n", "pids": ["56d86cf0dabfae2eeed5a1b3", "5e885d0791e011213a31bad1"], "flag": 0}
{"question": "Notation for repeated application of function", "body": "<p>If I have the function $f(x)$ and I want to apply it $n$ times, what is the notation to use?</p>\n\n<p>For example, would $f(f(x))$ be $f_2(x)$, $f^2(x)$, or anything less cumbersome than $f(f(x))$? This is important especially since I am trying to couple this with a limit toward infinity.</p>\n", "pids": ["56d882b9dabfae2eee753788", "56d85b77dabfae2eee52602c"], "flag": 0}
{"question": "Why is it important to study combinatorics?", "body": "<p>I was having a discussion with my friend Sayan Mukherjee about why we need to study combinatorics which admittedly, is not our favorite subject because we see very less motivation for it (I am not saying that there does not exist motivation for studying it, it's just that I have not found it).</p>\n\n<p>Here are some of the \"uses\" of combinatorics that we could come up with:</p>\n\n<ol>\n<li><p>Counting - the number of ways in which we can perform a finite sequence of operations and how objects can be arranged or selected. For example,the number of ways in which we can select <span class=\"math-container\">$k$</span> odd and even elements from the set  <span class=\"math-container\">$S=\\{1,2,\\dots, 2n\\}$</span> so that at most 3 odd elements consecutive elements could occur in the section.</p></li>\n<li><p>Drawing bijections- The classic <a href=\"http://en.wikipedia.org/wiki/Stars_and_bars_%28combinatorics%29\" rel=\"noreferrer\">Stars and bars problem</a> provides us key ideas to count the number of integral solutions to equations of the form <span class=\"math-container\">$x_1+x_2+\\dots x_n=k$</span>.</p></li>\n<li><p>The <a href=\"http://en.wikipedia.org/wiki/Seven_Bridges_of_K%C3%B6nigsberg\" rel=\"noreferrer\">Seven Bridges of Königsberg</a> which captivated me as a child.</p></li>\n</ol>\n\n<p>I have refrained from mentioning recursions and generating functions as I see them more as tools.</p>\n\n<p>But I am looking for more motivation; counting, as described in problems seems to be tip of the iceberg and I will appreciate more examples where combinatorics and graph theory can be powerful tools. Can we please have a list of uses of combinatorics? I am not looking for applications to industry, just pure math.</p>\n\n<p>It is  not essential that the answers be pitched at high-school level; additional info will certainly be fun to revisit!</p>\n", "pids": ["56d9232ddabfae2eeeaa6381"], "flag": 0}
{"question": "Integral ${\\large\\int}_0^\\infty\\frac{dx}{\\sqrt[4]{7+\\cosh x}}$", "body": "<p>How to prove the following conjectured identity?\n$$\\int_0^\\infty\\frac{dx}{\\sqrt[4]{7+\\cosh x}}\\stackrel{\\color{#a0a0a0}?}=\\frac{\\sqrt[4]6}{3\\sqrt\\pi}\\Gamma^2\\big(\\tfrac14\\big)\\tag1$$\nIt holds numerically with precision of at least $1000$ decimal digits.</p>\n\n<p>Are there any other integers under the radical except $7$ and $1$ that result in a nice closed form?</p>\n", "pids": ["53e9b641b7602d970419e03b"], "flag": 0}
{"question": "Integral $\\int_0^\\infty\\frac{1}{x\\,\\sqrt{2}+\\sqrt{2\\,x^2+1}}\\cdot\\frac{\\log x}{\\sqrt{x^2+1}}\\mathrm dx$", "body": "<p>I need your assistance with evaluating the integral\n$$\\int_0^\\infty\\frac{1}{x\\,\\sqrt{2}+\\sqrt{2\\,x^2+1}}\\cdot\\frac{\\log x}{\\sqrt{x^2+1}}dx$$</p>\n\n<p>I tried manual integration by parts, but it seemed to only complicate the integrand more. I also tried to evaluate it with a CAS, but it was not able to handle it.</p>\n", "pids": ["53e9a122b7602d9702a1195d"], "flag": 0}
{"question": "A closed form for $\\int_0^\\infty\\frac{\\ln(x+4)}{\\sqrt{x\\,(x+3)\\,(x+4)}}dx$", "body": "<p>I need to a evaluate the following integral\n$$I=\\int_0^\\infty\\frac{\\ln(x+4)}{\\sqrt{x\\,(x+3)\\,(x+4)}}dx.$$</p>\n\n<p>Both <em>Mathematica</em>  and <em>Maple</em> failed to evaluate it in a closed form, and lookups of the approximate numeric value $4.555919963334436...$ in <a href=\"http://isc.carma.newcastle.edu.au\"><em>ISC+</em></a> and <a href=\"http://www.wolframalpha.com\"><em>WolframAlpha</em></a> did not return plausible closed form candidates either. Does anybody by any chance have an idea if a closed form exists for this integral, and what it could be?</p>\n", "pids": ["53e9a122b7602d9702a1195d"], "flag": 0}
{"question": "Can some proof that $\\det(A) \\ne 0$ be checked faster than matrix multiplication?", "body": "<p>We can compute a determinant of an $n \\times n$ matrix in $O(n^3)$ operations in several ways, for example by LU decomposition. It's also known (see, e.g., <a href=\"https://en.wikipedia.org/wiki/Determinant#Calculation\" rel=\"noreferrer\">Wikipedia</a>) that if we can multiply two $n \\times n$ matrices in $M(n)$ steps, then we can compute the determinant in $O(M(n))$ steps as well.</p>\n\n<p>However (and this is the motivating observation here), as in <a href=\"https://math.stackexchange.com/q/2665825\">this question</a>, if $\\det(A) = 0$, then I can find a vector $\\mathbf x$ such that $A \\mathbf x = \\mathbf 0$, and tell you: \"$A$ is a singular matrix. Here is a vector $\\mathbf x$ such that $A \\mathbf x = \\mathbf 0$\". I might have done lots of work to find $\\mathbf x$, but you can check my work in only $O(n^2)$ steps by computing $A \\mathbf x$: faster than you could compute $\\det(A)$ without help.</p>\n\n<p>Is it possible, in a similar way, for me to take a matrix $A$ with $\\det(A) \\ne 0$, and write a proof of this fact which you can also check faster than computing $\\det(A)$? (A perfect solution would check the proof in $O(n^2)$ steps; this is best possible, since we need that many steps to even read $A$.)</p>\n\n\n\n<p>Observations:</p>\n\n<ul>\n<li><p>A probabilistic argument exists based on <a href=\"https://en.wikipedia.org/wiki/Freivalds%27_algorithm\" rel=\"noreferrer\">Freivalds's algorithm</a>: I give you $A^{-1}$, and leave you to check that $AA^{-1} = I$. As far as we know, this still needs $O(M(n))$ time to do deterministically, but a probabilistic algorithm can take $O(n^2)$ steps to achieve a one-sided error rate of $\\frac12$: if $A^{-1}$ is correct, it will always say \"yes\", and if $A^{-1}$ is wrong, it will say \"no\" with probability at most $\\frac12$. As a result, you can take $O(n^2\\log n)$ steps to achieve  one-sided error rate of $n^{-k}$ for any $k$.</p></li>\n<li><p>More generally, we could ask for a proof that $\\det(A) = x$ for any specific nonzero value of $x$. This was the original question, but there's no hope of solving that for general $x$ if we can't even solve the $\\det(A) \\ne 0$ case. (After all, a proof that $\\det(A)$ has a <em>specific</em> nonzero value $x$ is in particular a proof that $\\det(A)$ has <em>some</em> nonzero value.)</p></li>\n</ul>\n", "pids": ["53e9af81b7602d97039c70ef"], "flag": 0}
{"question": "Is a map that preserves lines and fixes the origin necessarily linear?", "body": "<p>Let $V$ and $W$ be vector spaces over a field $\\mathbb{F}$ with $\\text{dim }V \\ge 2$. A <strong>line</strong> is a set of the form $\\{ \\mathbf{u} + t\\mathbf{v} : t \\in \\mathbb{F} \\}$. A map $f: V \\to W$ <strong>preserves lines</strong> if the image of every line in $V$ is a line in $W$. A map <strong>fixes the origin</strong> if $f(0) = 0$.</p>\n\n<p>Is a function $f: V\\to W$ that preserves lines and fixes the origin necessarily linear?</p>\n", "pids": ["53e99f4fb7602d970281dbc7"], "flag": 0}
{"question": "An interesting observation on the roots of certain polynomials", "body": "<p>Consider the following polynomial:\n<span class=\"math-container\">$$\\sum_{k=1}^{n}\\text{prime}(k)x^{k-1}$$</span>\nwhere <span class=\"math-container\">$n\\in\\mathbb{N}$</span> and <span class=\"math-container\">$\\text{prime}(n)$</span> is the <span class=\"math-container\">$n$</span>th prime. The first few polynomials are:<br />\n<span class=\"math-container\">\\begin{align}\nn=1&amp;:\\quad 2\\\\\nn=2&amp;:\\quad 2+3x\\\\\nn=3&amp;:\\quad 2+3x+5x^2\\\\\nn=4&amp;:\\quad 2+3x+5x^2+7x^3\n\\end{align}</span>\nConsider the number of real roots of these polynomials. The first few number of real roots of these polynomials form the sequence <span class=\"math-container\">$0,1,0,1,0,1,0,1,0,1,0,1,0,1,...$</span>. This alternating zeros and <span class=\"math-container\">$1$</span>'s pattern holds for all primes less than <span class=\"math-container\">$1000$</span> (verified by @Quimey) I have two questions:</p>\n<ul>\n<li>Does this pattern always hold? Said in another way, is the number of real roots of the polynomial <span class=\"math-container\">$\\sum_{k=1}^{n}\\text{prime}(k)x^{k-1}$</span> always equal to <span class=\"math-container\">$(1 + (-1)^{n})/2$</span>?</li>\n<li>Is yes, how can we prove it?</li>\n</ul>\n<p><em>Note:</em> Sorry if I missed something &quot;trivial&quot;, I don't have much experience in mathematics.</p>\n", "pids": ["60ee3f8991e01102f8efa5c3"], "flag": 0}
{"question": "How can I generate &quot;random&quot; curves?", "body": "<p>In game programming (my profession) it is often necessary to generate all kinds of random things, including random curves (for example, to make a procedural island or for an agent to follow some path). </p>\n\n<p>For one dimensional things, we usually use some random generator that generates say floats (which are really rational numbers) in some range and that is good enough as an approximation for most purposes. (Even though we cannot generate actual real numbers within a range uniformly, we can get a good sense of it with the rationals that we DO generate.)</p>\n\n<p>When it comes to 2D things, though, things are very murky. For example, suppose I want to generate curves uniformly between two points (say, all curves bounded in a box, and say, additional requirements such as that the curves are differentiable).</p>\n\n<p>The way we usually do it is to generate random parameters for some specific type of curve - say a Bezier curve, but this is not (AFAI can see) uniform in the original requirements - i.e. some curves that fit the bill will be more likely than others.</p>\n\n<p>Is this even a sensible question to ask?</p>\n\n<p>And if so, is there a way to generate curves (to a decent approximation) so that they are uniform within the parameters? (bounded and smooth)?</p>\n\n<p>It \"feels\" like there are too many curves; it is strictly true with real numbers too... but there we have that rationals can be close enough for practical purposes; but with 2D things it seems less clear that any possible real curve is \"close enough\" to a \"rational curve\".</p>\n\n<p>So I guess the main question is... if we have a set of \"all curves\", whether we can find a way to generate another set of approximations so that each \"real\" curve is close enough to our approximation.</p>\n\n<p><em>Or:</em> is there a mapping from \"approximations to reals\" to \"approximations of continuous, differentiable, bounded curves between two points\".... (that preserves uniformity, at least intuitively)?</p>\n\n<p><em>Or:</em> is there a notion of distribution of (bounded differential) curves? (And way to pick items from it).</p>\n\n<p><strong>Edit:</strong> I am more interested in the theoretical possibilities. I know LOTS of ways to generate curves... I am particular interested in generating curves without some kind of bias, and whether this even makes sense to want.</p>\n\n<p><strong>Edit:</strong> @pjs36 pointed out the curve may be arbitrary long. I don't mind additional restrictions to prevent pathological curves. Restrictions like \"not longer than $x$\", or not self-crossing.</p>\n", "pids": ["5c61080ada56297340b25516", "5c756844f56def97981e264d"], "flag": 0}
{"question": "Making Change for a Dollar (and other number partitioning problems)", "body": "<p>I was trying to solve a problem similar to the &quot;how many ways are there to make change for a dollar&quot; problem.  I ran across a <a href=\"http://www.maa.org/features/mathchat/mathchat_4_19_01.html\" rel=\"nofollow noreferrer\">site</a> that said I could use a generating function similar to the one quoted below:</p>\n<blockquote>\n<p>The answer to our problem (<span class=\"math-container\">$293$</span>) is the\ncoefficient of <span class=\"math-container\">$x^{100}$</span> in the reciprocal\nof the following:</p>\n<p><span class=\"math-container\">$(1-x)(1-x^5)(1-x^{10})(1-x^{25})(1-x^{50})(1-x^{100})$</span></p>\n</blockquote>\n<p>But I must be missing something, as I can't figure out how they get from that to <span class=\"math-container\">$293$</span>. Any help on this would be appreciated.</p>\n", "pids": ["56d86f3edabfae2eeee7189e"], "flag": 0}
{"question": "Do professional software developers write an average of 10 lines of code per day?", "body": "<p>In the 1975 software project management book, <em><a href=\"https://en.wikipedia.org/wiki/The_Mythical_Man-Month\" rel=\"noreferrer\">The Mythical Man Month: Essays on Software Engineering</a></em>, Fred Brooks states that, no matter the programming language chosen, a professional developer will write an average 10 lines of code (LoC) per day.</p>\n\n<blockquote>\n  <p>Productivities in [the] range of 600-800 debugged instructions per man-year were experienced by control program groups. Productivities in the [range of] 2000-3000 debugged instructions per man-year were achieved by [OS/360] language translator groups.  These include planning done by the group, coding component test, system test, and some support activities.</p>\n  \n  <p>-<a href=\"https://archive.org/stream/mythicalmanmonth00fred#page/92/mode/2up\" rel=\"noreferrer\">Page 93</a> of \"<em>The Mythical Man Month</em>\" (1975)</p>\n</blockquote>\n\n<p>The book quotes other numbers too for other projects, saying e.g. that an O/S is more complicated and therefore slower to write than other types of software.  However, a 2000 statements/year figure is virtually identical to the often-claimed 10 LoC/day.  Further, it is on the nearly same page as the other part of the claim, which is that LoC/day seems independent of the programming language being used.</p>\n\n<blockquote>\n  <p>Productivity [in LoC] seems constant [across languages] in terms of elementary statements [so it's better to use a higher-level language if you can], a conclusion that is reasonable in terms of the thought a statement requires and the errors it may include.<sup>11</sup></p>\n  \n  <p>-<a href=\"https://archive.org/stream/mythicalmanmonth00fred#page/94/mode/2up\" rel=\"noreferrer\">Page 94</a> of \"<em>The Mythical Man Month</em>\" (1975)</p>\n</blockquote>\n\n<p>This claim is still being made today (in 2006, at least). From <a href=\"http://www.codinghorror.com/blog/2006/07/diseconomies-of-scale-and-lines-of-code.html\" rel=\"noreferrer\">Jeff Atwood's blog, <em>Coding Horror</em></a>:</p>\n\n<blockquote>\n<pre><code>Project Size         Lines of code (per year)     COCOMO average\n    10,000 LOC           2,000 - 25,000               3,200\n   100,000 LOC           1,000 - 20,000               2,600\n 1,000,000 LOC             700 - 10,000               2,000\n10,000,000 LOC             300 -  5,000               1,600\n</code></pre>\n</blockquote>\n\n<p>The COCOMO averages divided across 250 work days per year results in 6.4 to 12.8 LoC/day, encompassing the 10 LoC/day claim from the 1975 book.</p>\n\n<p>Is it true that professional programmers produce code at around 10 LoC/day?</p>\n", "pids": ["53e99c0bb7602d97024ba858", "5390958a20f70186a0def938"], "flag": 1}
{"question": "sum of noncentral Chi-square random variables", "body": "<p>I need to find the distribution of the random variable \n$$Y=\\sum_{i=1}^{n}(X_i)^2$$\nwhere $X_i\\sim{\\cal{N}}(\\mu_i,\\sigma^2_i)$ and all $X_i$s are independent. I know that it is possible to first find the product of all moment generating functions for $X_i$s, and then transform back to obtain $Y$'s distribution. However, I wonder whether there is a general form for $Y$ like the Gaussian case: we know the sum of independent Gaussian is still a Gaussian, and thus we only need to know the summed mean and summed variance. </p>\n\n<p>How about all $\\sigma^2_i=\\sigma^2$? Will this condition make a general solution?</p>\n", "pids": ["56d906b8dabfae2eeefb151d"], "flag": 1}
{"question": "Is there (or can there be) a general algorithm to solve Rubik&#39;s cubes of any dimension?", "body": "<p>I love solving Rubik's cube (the usual 3D one). But, a lecture by Matt Parker at the Royal Institute (<a href=\"https://www.youtube.com/watch?v=1wAaI_6b9JE\" rel=\"noreferrer\">YouTube Link</a>) led me to an app that can simulate a four dimensional rubik's cube. But unfortunately it was so complex, that I soon got bored as I failed to solve it.</p>\n<p>The website to the 4D cube : <a href=\"http://superliminal.com/cube/cube.htm\" rel=\"noreferrer\">http://superliminal.com/cube/cube.htm</a></p>\n<p><a href=\"https://i.stack.imgur.com/wYAWA.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/wYAWA.png\" alt=\"4d cube\" /></a></p>\n<p>Following which today, I also found an app that can simulate a 5D cube!!</p>\n<p>The website to the 5D cube: <a href=\"http://www.gravitation3d.com/magiccube5d/\" rel=\"noreferrer\">http://www.gravitation3d.com/magiccube5d/</a></p>\n<p><a href=\"https://i.stack.imgur.com/khYXm.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/khYXm.png\" alt=\"5d cube\" /></a></p>\n<p>So, my two questions are :</p>\n<ol>\n<li><strong>Is there a general (non brute-force) algorithm that can be used to solve a well-scrambled cube of any dimension (even though it may not be very efficient, but yet is not a simple search over all the available space of move sequences) ? [Point modified after reading @RavenclawPrefect's answer :D ]</strong></li>\n<li><strong>Mathematically, what is common in all these cubes, and &quot;hypercubes&quot;?</strong></li>\n</ol>\n<blockquote>\n<p><strong>NOTE:</strong> By dimensions I mean physical dimension and not the number of rows of pieces on a face of the cube. So a four-dimension cube is a cube in x,y,z,<span class=\"math-container\">$\\delta$</span> dimensions where <span class=\"math-container\">$\\hat x,\\hat y,\\hat z,\\hat \\delta$</span> are mutually orthogonal unit vectors in the respective dimensions.<br>\nFor example, here is how the aforementioned 4D cube moves:\n<a href=\"https://miro.medium.com/max/2552/1*ga32DoV_Hc6e8t6PC1hFHw.gif\" rel=\"noreferrer\">https://miro.medium.com/max/2552/1*ga32DoV_Hc6e8t6PC1hFHw.gif</a></p>\n</blockquote>\n<hr />\n<p>Addendum:<br>\n<em>List of resources that may help finding an answer to this question:</em></p>\n<ul>\n<li><a href=\"https://math.stackexchange.com/questions/1096592/solving-rubiks-cube-and-other-permutation-puzzles\">Solving Rubik&#39;s cube and other permutation puzzles</a></li>\n</ul>\n", "pids": ["53e9b403b7602d9703ef7fe8"], "flag": 0}
{"question": "A continued fraction involving prime numbers", "body": "<p>What is the limit of the <a href=\"http://en.wikipedia.org/wiki/Continued_fraction#Infinite_continued_fractions\">continued fraction</a>\n$$\\cfrac{1}{2+\\cfrac{1}{3+\\cfrac{1}{5+\\cfrac{1}{7+\\cfrac{1}{11+\\cfrac{1}{13+\\cdots}}}}}}\\ ?$$</p>\n\n<p>Is the limit algebraic, or expressible in terms of e or $\\pi$? What is the fastest way to approximate the limit?</p>\n", "pids": ["53e9a308b7602d9702c11e27"], "flag": 0}
{"question": "Do we still need to do feature selection while using Regularization algorithms?", "body": "<p>I have one question with respect to need to use feature selection methods (Random forests feature importance value or Univariate feature selection methods etc) before running a statistical learning algorithm. </p>\n\n<p>We know to avoid overfitting we can introduce regularization penalty on the weight vectors. </p>\n\n<p>So if I want to do linear regression, then I could introduce the L2 or L1 or even Elastic net regularization parameters. To get sparse solutions, L1 penalty helps in feature selection. </p>\n\n<p>Then is it still required to do feature selection before Running L1 regularizationn regression such as Lasso?. Technically Lasso is helping me reduce the features by L1 penalty then why is the feature selection needed before running the algo? </p>\n\n<p>I read a research article saying that doing Anova then SVM gives better performance than using SVM alone. Now question is: SVM inherently does regularization using L2 norm. In order to maximise the margin, it is minimising the weight vector norm. So it is doing regularization in it's objective function. Then technically algorithms such as SVM should not be bothered about feature selection methods?. But the report still says doing Univariate Feature selection before normal SVM is more powerful. </p>\n\n<p>Anyone with thoughts? </p>\n", "pids": ["53e9b550b7602d9704087cc6"], "flag": 1}
{"question": "Two Representations of the Prime Counting Function", "body": "<blockquote>\n<p>The bounty  for the best work out of <a href=\"https://math.stackexchange.com/a/291201/19341\">Greg's answer</a>, especially the\n&quot;<strong>solving for <span class=\"math-container\">$\\pi^*(x;q,a)$</span> in terms of all <span class=\"math-container\">$\\Pi^*$</span> functions (tedious but possible)</strong>&quot;\npart is over. Since Raymond's contributions might be very helpful to recall the necessary math, upvoting his answers is highly appreciated...</p>\n<p>I posted my attempt of a workout <a href=\"https://math.stackexchange.com/a/409667/19341\">here</a>. Comments welcome...</p>\n</blockquote>\n<hr />\n<p><em>Original question:</em></p>\n<p>I have two representations of <span class=\"math-container\">$\\pi(x)$</span>:</p>\n<ol>\n<li>\n<blockquote>\n<p>The Prime Counting Function <span class=\"math-container\">$\\pi(x)$</span> is given\n<span class=\"math-container\">$$\n\\pi(x) = \\operatorname{R}(x^1) - \\sum_{\\rho}\\operatorname{R}(x^{\\rho}) \\tag{1}\n$$</span>\nwith <span class=\"math-container\">$    \\operatorname{R}(z) = \\sum_{n=1}^{\\infty} \\frac{ \\mu (n)}{n} \\operatorname{li}(z^{1/n})$</span> and <span class=\"math-container\">$\\rho$</span> running over <strong>all</strong> the zeros of <span class=\"math-container\">$\\zeta$</span> function.</p>\n</blockquote>\n</li>\n<li>\n<blockquote>\n<p>This formula, while\nwidely believed to be correct, has not yet been proved.\n<span class=\"math-container\">$$\n\\pi(x) \\approx \\int\\limits_2^x{\\frac{dt}{\\ln t}} - \\frac{\\sqrt x}{\\ln x}\\left( 1 + 2\\sum_{\\gamma} \\ \\ \\frac{\\sin(\\gamma\\ln x)}{\\gamma}\\right) \\tag{2}, \n$$</span>\nwith <span class=\"math-container\">$\\gamma=\\text{Im}({\\rho})$</span> being imaginary part of the roots  of the <span class=\"math-container\">$\\zeta$</span> function.</p>\n</blockquote>\n</li>\n</ol>\n<p>Now I have two questions:</p>\n<ol start=\"2\">\n<li>Does the truth of <span class=\"math-container\">$(2)$</span> depend on Riemann's Hypothesis or is it &quot;just&quot; what <a href=\"http://en.wikipedia.org/wiki/Prime-counting_function#Formulas_for_prime-counting_functions\" rel=\"noreferrer\">Wikipedia</a> says, that <em>The amplitude of the &quot;noisy&quot; part is heuristically about <span class=\"math-container\">$\\sqrt x/\\ln x$</span></em>?</li>\n<li>How to show the equivalence between <span class=\"math-container\">$(1)$</span> and <span class=\"math-container\">$(2)$</span>? The integral logarithm is easily found in both representations, but how do the <span class=\"math-container\">$\\rho$</span>-parts fit together? How do I get <span class=\"math-container\">$\\sin$</span>s from <span class=\"math-container\">$\\text{li}(z^{1/n})$</span>s? Does this invoke Gram's series:\n<span class=\"math-container\">$$\n    \\operatorname{R}(z) = \\sum_{n=1}^{\\infty} \\frac{ \\mu (n)}{n} \\operatorname{li}(z^{1/n}) = 1 + \\sum_{k=1}^\\infty \\frac{(\\ln z)^k}{k! k \\zeta(k+1)} ?\n$$</span>\nWe can rewrite <span class=\"math-container\">$\\displaystyle \\frac{\\sin(\\gamma\\ln x)}{\\gamma}=\\frac{x^{i\\gamma}-x^{-i\\gamma}}{i\\gamma}$</span> and I remember that I've seen a similar expression at <a href=\"http://en.wikipedia.org/wiki/Prime-counting_function#Formulas_for_prime-counting_functions\" rel=\"noreferrer\">Wikipedia</a>:\n<span class=\"math-container\">$$\n    \\psi_0(x) = x - \\sum_\\rho \\frac{x^\\rho}{\\rho} - \\ln 2\\pi - \\frac12 \\ln(1-x^{-2}) ,\n$$</span>\nBut could this help, if at all? (<span class=\"math-container\">$\\psi_0(x)$</span> is the normalization of the Chebyshev function, see <a href=\"http://en.wikipedia.org/wiki/Explicit_formula#Riemann.27s_explicit_formula\" rel=\"noreferrer\">here</a>)</li>\n</ol>\n", "pids": ["628d15ba5aee126c0f305964"], "flag": 0}
{"question": "Evaluating $\\int^1_0 \\frac{\\log(1+x)\\log(1-x) \\log(x)}{x}\\, \\mathrm dx$", "body": "<p>In this <a href=\"http://integralsandseries.prophpbb.com/topic119.html\">thread</a> </p>\n\n<p>a friend posted the following integral </p>\n\n<p>$$I=\\int^1_0 \\frac{\\log(1+x)\\log(1-x) \\log(x)}{x}\\, \\mathrm dx$$</p>\n\n<p>The best we could do is expressing it in terms of Euler sums </p>\n\n<p>$$I=-\\frac{\\zeta^2(2)}{2}+ \\sum_{n\\geq 1}\\frac{(-1)^{n-1}}{n^2} H_{n}^{(2)}+\\sum_{n\\geq 1}\\frac{(-1)^{n-1}}{n^3}H_{n}$$</p>\n\n<p>I am wondering if the approach I followed made the integral complicated ?\nWhat approach would you follow to solve the integral?, can we find a better solution ?</p>\n", "pids": ["53e99784b7602d9701f3e166"], "flag": 0}
{"question": "Closed form for $\\int_0^\\infty\\left(\\int_0^1\\frac1{\\sqrt{1-y^2}\\sqrt{1+x^2\\,y^2}}\\mathrm dy\\right)^3\\mathrm dx.$", "body": "<p>I need to find a closed form for these nested definite integrals:\n$$I=\\int_0^\\infty\\left(\\int_0^1\\frac1{\\sqrt{1-y^2}\\sqrt{1+x^2\\,y^2}}\\mathrm dy\\right)^3\\mathrm dx.$$\nThe inner integral can be represented using the <a href=\"http://mathworld.wolfram.com/HypergeometricFunction.html\">hypergeometric function $_2F_1$</a> or the <a href=\"http://mathworld.wolfram.com/CompleteEllipticIntegraloftheFirstKind.html\">complete elliptic integral of the 1st kind $K$</a> with an imaginary argument:\n$$\\int_0^1\\frac1{\\sqrt{1-y^2}\\sqrt{1+x^2\\,y^2}}\\mathrm dy=\\frac\\pi2   {_2F_1}\\left(\\frac12,\\frac12;1;-x^2\\right)=K(x\\,\\sqrt{-1}).$$\nMy conjecture is the integral $I$ has a closed-form representation:$$I\\stackrel{?}{=}\\frac{3\\,\\Gamma (\\frac14)^8}{1280\\,\\pi^2}=7.09022700484626946098980237...,$$\nbut I was neither able to find a proof of it, nor disprove the equality using numerical integration. Could you please help me with resolving this question?</p>\n", "pids": ["56d81ec1dabfae2eeead01d3", "53e9ab25b7602d97034b1003"], "flag": 0}
{"question": "Are there arbitrarily large gaps between consecutive primes?", "body": "<p>I made a program to find out the number of primes within a certain range, for example between $1$ and $10000$ I found $1229$ primes, I then increased my range to $20000$ and then I found $2262$ primes, after doing it for $1$ to $30000$, I found $3245$ primes.</p>\n\n<p>Now a curious thing to notice is that each time, The probability of finding a prime in between $2$ multiples of $10000$ is decreasing, i.e it was $$\\frac{2262-1229}{10000}=0.1033$$ between $10000$ and $20000$, and $$\\frac{3245-2262}{10000}=0.0983$$ between $20000$ and $30000$, </p>\n\n<p>So from this can we infer that there will exist two numbers separated by a gap of $10000$ such that no number in between them is prime? If so how to determine the first two numbers with which this happens? Also I took $10000$ just as a reference here, what about if the gap between them in general is $x$, can we do something for this in generality?</p>\n\n<p>Thanks!</p>\n", "pids": ["5c6108edda56297340b5817f"], "flag": 0}
{"question": "Hexagons are best for tiling 2D space in terms of perimeter vs area. What&#39;s best for 3D space?", "body": "<p>If you think of the bee-hive problem, you want to make 2D cells that divide the plane of honey into chunks of area while expending the least perimeter (since the perimeter of the cells is what takes up resources/effort). The solution ends up being the hexagonal tiling.</p>\n<p>What is the analogous &quot;tiling&quot; for 3D space that's optimal in a similar sense? (more volume, less surface area)</p>\n<p>And if possible, I'd like to know the general solution for <span class=\"math-container\">$n$</span>-D space.</p>\n<p>To make the problem statement clear: assume that each &quot;cell&quot; has a volume of at most 1. With what polyhedron should you divide the cells to minimize the ratio of surface area to volume? For example, if you tile everything with hypercubes, the ratio would be <span class=\"math-container\">$2n$</span>, which probably isn't optimal.</p>\n", "pids": ["5c757095f56def97987064b7"], "flag": 0}
{"question": "Integer matrices with integer inverses", "body": "<p>If all entries of an invertible matrix <span class=\"math-container\">$A$</span> are rational, then all the entries of <span class=\"math-container\">$A^{-1}$</span> are also rational. Now suppose that all entries of an invertible matrix <span class=\"math-container\">$A$</span> are integers. Then it's not necessary that all the entries of <span class=\"math-container\">$A^{-1}$</span> are integers. My question is:</p>\n<blockquote>\n<p>What are all the invertible integer matrices such that their inverses are also integer matrices?</p>\n</blockquote>\n", "pids": ["53e99beab7602d9702495e22"], "flag": 0}
{"question": "Do beef farmed pastures net remove carbon emissions?", "body": "<p>This viral image claims that an example beef farm with 130 cattle removes many tons of Carbon from the atmosphere every year. However it does not provide any sources.</p>\n\n<p>This image has been shared many times - e.g. [<a href=\"https://twitter.com/williecarroll37/status/1051009497504915457\" rel=\"noreferrer\">1</a>], [<a href=\"https://www.facebook.com/custompathorlacher/posts/the-growing-dividefor-some-time-now-i-believe-most-americans-have-observed-a-gro/1056699091195760/\" rel=\"noreferrer\">2</a>], [<a href=\"https://thefarmingforum.co.uk/index.php?threads/countryside-seeds-ltd.41646/page-8#post-2670022\" rel=\"noreferrer\">3</a>], [<a href=\"https://twitter.com/HertsFarmer/status/749858622092509186\" rel=\"noreferrer\">4</a>] - some of these date back to July 2016.</p>\n\n<p>Is anything in this info-graphic factual? Do the pastures required for cattle farming reduce the amount of carbon emitted to the point where it is a net reduction of carbon?</p>\n\n<blockquote>\n  <p><a href=\"https://i.stack.imgur.com/B08ZC.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/B08ZC.jpg\" alt=\"Farm Carbon output from beef: 80 tones of Carbon is produced by 50 mother cows  80 young calves + 32 tons of carbonm is produced by tractor/equipment processing/distribution - 500 tons of Carbon is removed by 150 acres of Pasture. Total output 112 tons of Carbon - Total Sequestration 500 tons of carbnon. This farm removes 388 tons of Carbon from the atmosphere annually.\"></a></p>\n</blockquote>\n", "pids": ["5c7a7e004895d9cbc6eba682", "5ce2d101ced107d4c63df4f5"], "flag": 1}
{"question": "Russian scientist injects himself with 3.5 million-year-old bacteria, says he is now stronger and hasn&#39;t gotten ill in 2 years", "body": "<p>I have found several articles regarding a Russian scientist, Anatoli Brouchkov:</p>\n\n<ol>\n<li><blockquote>\n  <p>Anatoli Brouchkov is a soft-spoken guy with silver hair, and when he lets out a reserved chuckle, his eyes light up like he was belly laughing. If you met him on the street, you'd never guess that he once <a href=\"http://fusion.net/story/207499/russian-researcher-infects-himself-with-ancient-bacteria-in-pursuit-of-immortality/\" rel=\"noreferrer\">injected himself</a> with a 3.5 million-year-old strain of bacteria, just to see what would happen.</p>\n  \n  <p>When I spoke with him at VICE's Toronto office in October, the permafrost scientist—also known as a geocryologist, currently stationed at Moscow State University—told me that he's feeling just fine. In fact, he says he's feeling healthier and less tired than ever. His <a href=\"http://www.telegraph.co.uk/news/health/11901105/Russian-scientist-says-he-is-stronger-and-healthier-after-injecting-himself-with-eternal-life-bacteria.html\" rel=\"noreferrer\">most famous claim</a> is that he hasn't had the flu in two years, which he coyly says may or may not have anything to do with the ancient bacteria he injected into his body.</p>\n  \n  <p>-<a href=\"https://motherboard.vice.com/en_us/article/yp3gg7/meet-the-scientist-who-injected-himself-with-35-million-year-old-bacteria\" rel=\"noreferrer\">\"Meet the Scientist Who Injected Himself with 3.5 Million-Year-Old Bacteria\"</a>, Motherboard (2015-12-09)</p>\n</blockquote></li>\n<li><p><a href=\"https://www.vice.com/en_uk/article/nn94ng/russian-scientist-injects-himself-with-35-million-year-old-bacteria-reckons-he-might-live-forever-now-909\" rel=\"noreferrer\">\"Russian Scientist Injects Himself with 3.5-Million-Year-Old Bacteria, Reckons He Might Now Live Forever\"</a>, Vice (2015-10-01)</p></li>\n<li><p><a href=\"http://www.dailymail.co.uk/sciencetech/article-3255253/Has-secret-eternal-life-Russian-scientist-says-stronger-healthier-injecting-3-5-MILLION-year-old-bacteria.html\" rel=\"noreferrer\">\"Has the secret to eternal life been found? Russian scientist says he is stronger and healthier after injecting himself with 3.5 MILLION year old bacteria \"</a>, DailyMail (2015-09-30)</p></li>\n</ol>\n\n<p>I am not skeptical about whether this happened, I am skeptical about whether this had (or could potentially have) any of the positive health benefits that the Russian scientist claims.</p>\n\n<p>Is there any scientific evidence to support any of this?  Or even a scientific theory on how 3+ million year old bacteria could boost our own immune system?</p>\n", "pids": ["53e9ba7db7602d970469f177"], "flag": 1}
{"question": "Is phosphine evidence of life on Venus?", "body": "<p><a href=\"https://www.syfy.com/syfywire/so-astronomers-may-have-found-evidence-of-life-on-venus\" rel=\"noreferrer\">This news article came out about evidence tied to the possibility of life on Venus</a>. The crux of the evidence is the detection of phosphine. The claim is that we only know of two ways to make this compound. Artificially with chemistry, or by anaerobic bacteria.</p>\n<blockquote>\n<p>Recently, phosphine has been examined the same way* and found to be a good biomarker for the same reasons. On Earth, phosphine (PH<sub>3</sub>) is only made by humans artificially, or by anaerobic bacteria, generally in rotting corpses. Finding it in an alien atmosphere at relatively high levels would be a decent indicator (though not proof) of biological processes.</p>\n</blockquote>\n<p>While Dr. Plait does a good job of putting adequate skepticism in his article, more &quot;popular&quot; media outlets may not be as cautious, or leave the caveats until much later in their article (<a href=\"https://people.com/human-interest/potential-sign-of-life-found-venus/\" rel=\"noreferrer\">such as this People Magazine article that doesn't mention any caveats until much later in the article which many people may not read</a>). <a href=\"https://www.popularmechanics.com/space/solar-system/a34012688/scientists-find-signs-of-life-in-venus-clouds/\" rel=\"noreferrer\">Even Popular Mechanics seems to be less cautions than other outlets</a>. The CNN headline outright says &quot;<a href=\"https://www.cnn.com/2020/09/14/world/venus-phosphine-gas-clouds-scn/index.html?utm_content=2020-09-14T16%3A17%3A02&amp;utm_source=fbCNN&amp;utm_medium=social&amp;utm_term=link&amp;fbclid=IwAR289Cyq4nacfdOyQM0YiWowogk6eol0mU9GB4Q1AlMG7IA_7HMbD-o2mMw\" rel=\"noreferrer\">signifies life has been detected</a>&quot; in the headline.</p>\n<p>So, are the two methods of producing this chemical overstated? Or is this actually some compelling evidence?</p>\n", "pids": ["621953d85aee126c0fffda1b"], "flag": 1}
{"question": "Interpreting the difference between lognormal and power law distribution (network degree distribution)", "body": "<p>As part of the network analysis, I plotted a Complementary Cumulative Distribution Function (CCDF) of network degrees. What I found was that, unlike conventional network distributions (e.g. WWW), the distribution is best fitted by a lognormal distribution. I did try to fit it against a power law and using Clauset et al's Matlab scripts, I found that the tail of the curve follows a power law with a cut-off.</p>\n<p><a src=\"https://i.stack.imgur.com/TM2je.jpg\" alt=\"enter image description here\" /></p>\n<p>Dotted line represents power law fit.\nPurple line represents log-normal fit.\nGreen line represents exponential fit.</p>\n<p>What I'm struggling to understand is what this all mean? I've read this paper by Newman which slightly touches on this topic:\n<a href=\"http://arxiv.org/abs/cond-mat/0412004\" rel=\"nofollow noreferrer\">http://arxiv.org/abs/cond-mat/0412004</a></p>\n<p>Below is my wild guess:</p>\n<p>If the degree distribution follows a power law distribution, I understand that it means there is linear preferential attachment in the distribution of links and network degree (rich gets richer effect or Yules process).</p>\n<p>Am I right in saying that with the lognormal distribution I'm witnessing, there is sublinear preferential attachment at the beginning of the curve and becomes more linear towards the tail where it can be fitted by a power law?</p>\n<p>Also, since a log-normal distribution occurs when the logarithm of the random variable (say X) is normally distributed, does this mean that in a log-normal distribution, there are more small values of X and less large values of X than a random variable that follows a power law distribution would have?</p>\n<p>More importantly, with regards to network degree distribution, does a log-normal preferential attachment still suggest a scale-free network? My instinct tells me that since the tail of the curve can be fitted by a power law, the network can still be concluded as exhibiting scale-free characteristics.</p>\n", "pids": ["53e9a554b7602d9702e77abe"], "flag": 1}
{"question": "How to prove $\\int_0^\\infty J_\\nu(x)^3dx\\stackrel?=\\frac{\\Gamma(1/6)\\ \\Gamma(1/6+\\nu/2)}{2^{5/3}\\ 3^{1/2}\\ \\pi^{3/2}\\ \\Gamma(5/6+\\nu/2)}$?", "body": "<p>I am interested in finding a general formula for the following integral:\n$$\\int_0^\\infty J_\\nu(x)^3dx,\\tag1$$\nwhere $J_\\nu(x)$ is the <a href=\"http://mathworld.wolfram.com/BesselFunctionoftheFirstKind.html\" rel=\"noreferrer\">Bessel function of the first kind</a>:\n$$J_\\nu(x)=\\sum _{n=0}^\\infty\\frac{(-1)^n}{\\Gamma(n+1)\\Gamma(n+\\nu+1)}\\left(\\frac x2\\right)^{2n+\\nu}.\\tag2$$\n<a href=\"http://www.wolfram.com/mathematica\" rel=\"noreferrer\"><em>Mathematica</em></a> gives the following result:\n$$\\int_0^\\infty J_\\nu(x)^3dx=\\frac1{\\pi\\,\\nu}{_3F_2}\\left(\\frac12,\\frac12-\\nu,\\frac12+\\nu;1-\\frac\\nu2,1+\\frac\\nu2;\\frac14\\right)+\\frac{\\Gamma\\left(-\\frac\\nu2\\right)\\Gamma\\left(\\frac{1+3\\nu}2\\right)\\cos\\frac{\\pi\\,\\nu}2}{2^{\\nu+1}\\ \\pi^{3/2}\\ \\Gamma(\\nu+1)}{_3F_2}\\left(\\frac{1-\\nu}2,\\frac{1+\\nu}2,\\frac{1+3\\nu}2;1+\\frac\\nu2,1+\\nu;\\frac14\\right),\\tag3$$\nwhich can be significantly simplified for odd and half-integer values of $\\nu$. The results at those points allow to conjecture another, simpler general formula:\n$$\\int_0^\\infty J_\\nu(x)^3dx\\stackrel?=\\frac{\\Gamma\\left(\\frac16\\right)\\ \\Gamma\\left(\\frac16+\\frac\\nu2\\right)}{2^{5/3}\\ 3^{1/2}\\ \\pi^{3/2}\\ \\Gamma\\left(\\frac56+\\frac\\nu2\\right)},\\tag4$$\nwhich agrees with $(3)$ to a very high precision for many different values of $\\nu$. It also has an advantage that it is defined for all $\\nu&gt;-\\frac13$ whereas $(3)$ is undefined at every even $\\nu$ and requires calculating a limit at those points.</p>\n\n<p>Is it possible to prove the formula $(4)$?\n\n<em>Mathematica</em> is able to evaluate $(1)$ for even values of $\\nu$ in terms of the <a href=\"http://mathworld.wolfram.com/MeijerG-Function.html\" rel=\"noreferrer\">Meijer G-function</a>. Plugging those expressions into $(4)$ we get another form of the conjecture:\n$$G_{3,3}^{2,1}\\left(\\frac14\\left|\\begin{array}{c}2a,1,2-2a\\\\\\frac12,1-a,a\\\\\\end{array}\n\\right.\\right)\\stackrel?=\\frac{\\Gamma\\left(\\frac16\\right)\\ \\Gamma\\left(\\frac23-a\\right)}{2^{5/3}\\ 3^{1/2}\\ \\pi\\ \\Gamma\\left(\\frac43-a\\right)}.\\tag5$$\nIncidentally, the case $a=\\frac12$ would positively resolve my <a href=\"https://math.stackexchange.com/questions/398674/closed-form-for-int-1-infty-int-01-frac-mathrm-dy-mathrm-dx-sqrtx2-1\">another question</a>.</p>\n", "pids": ["53e9a5dbb7602d9702f033bc", "5c755156f56def97985bb1f6"], "flag": 0}
{"question": "Can we prove AM-GM Inequality using these integrals?", "body": "<p>I came across these two results recently:</p>\n<p><span class=\"math-container\">$$ \\int_a^b \\sqrt{\\left(1-\\dfrac{a}{x}\\right)\\left(\\dfrac{b}{x}-1\\right)} \\: dx = \\pi\\left(\\dfrac{a+b}{2} - \\sqrt{ab}\\right)$$</span></p>\n<p><span class=\"math-container\">$$ \\int_a^c \\sqrt[3]{\\left| \\left(1-\\dfrac{a}{x}\\right)\\left(1-\\dfrac{b}{x}\\right)\\left(1-\\dfrac{c}{x}\\right)\\right|} \\: dx = \\dfrac{2\\pi}{\\sqrt{3}}\\left(\\dfrac{a+b+c}{3} - \\sqrt[3]{abc}\\right)$$</span>\nfor <span class=\"math-container\">$0&lt;a\\leq b\\leq c$</span>.</p>\n<p>I haven't tried to solve the first one yet, but I have an idea of how to approach it, namely using the substitution <span class=\"math-container\">$x=a\\cos^2\\theta+b\\sin^2\\theta$</span>. I have no idea how to approach the second one, however.</p>\n<p>I think that the most interesting thing about the results above is that it seems like there is a proof for the AM-GM inequality hidden within. Clearly both integrands are positive and so the AM-GM falls out for the 2 and 3 variable case. All that is required is to prove the results.</p>\n<p>My question is twofold:</p>\n<ol>\n<li>How would the second integral be computed? Is there an approach using elementary techniques?</li>\n<li>Can this be generalised to prove the AM-GM inequality for <span class=\"math-container\">$n$</span>-variables?</li>\n</ol>\n", "pids": ["58437744ac44360f10834d66", "5a260c5d17c44a4ba8a2a447", "5cd07b00ced107d4c6d4300c", "5c8676084895d9cbc66153ba", "5a260c5d17c44a4ba8a2a414", "5c757224f56def97987e466b", "5c3bcb31df5b8c0b3cc29061", "5488e9fb45ce471f90910c41", "56d8d05edabfae2eee9ee926"], "flag": 0}
{"question": "What specific algebraic properties are broken at each Cayley-Dickson stage beyond octonions?", "body": "<p>I'm starting to come around to an understanding of hypercomplex numbers, and I'm particularly fascinated by the fact that certain algebraic properties are broken as we move through each of the $2^n$ dimensions. I think I understand the first $n&lt;4$ instances:</p>\n\n<ul>\n<li>As we move from $\\mathbb{R}$ to $\\mathbb{C}$ we lose ordering</li>\n<li>From $\\mathbb{C}$ to $\\mathbb{H}$ we lose the commutative property</li>\n<li>From $\\mathbb{H}$ to $\\mathbb{O}$ we lose the associative property (in the form of $(xy)z \\neq x(yz)$, but apparently it's still alternative and $(xx)y = x(xy)$. Is that right?)</li>\n<li>The move from $\\mathbb{O}$ to $\\mathbb{S}$ is where I start to get fuzzy. From what I've read, the alternative property is broken now, such that even $(xx)y \\neq x(xy)$ but that also zero divisors come into play, thus making sedenion algebra non-division.</li>\n</ul>\n\n<p>My first major question is: Does the loss of the alternative property cause the emergence of zero divisors (or vice versa) or are these unrelated breakages?</p>\n\n<p>My bigger question is: What specific algebraic properties break as we move into 32 dimensions, then into 64, 128, 256? I've \"read\" the de Marrais/Smith paper where they coin the terms pathions, chingons, routons and voudons. At my low level, any initial \"reading\" of such a paper is mostly just intent skimming, but I'm fairly certain they don't address my question and are focused on the nature and patterns of zero divisors in these higher dimensions. If the breakages are too complicated to simply explicate in an answer here, I'm happy to do the work and read journal articles that might help me understand, but I'd appreciate a pointer to specific papers that, given enough study, will actually address the point of my specific interest--something I can't necessarily tell with an initial glance, and might need a proper mathematician to point me in the right direction.</p>\n\n<p>Thank you!</p>\n\n<p>UPDATE: If the consensus is that this is a repeat, then ok, but I don't see how the answers to the other question about <em>why</em> algebraic properties break answers my questions about <em>what</em> algebraic properties break. Actually, the response marked as an answer in that other question doesn't actually answer that question either. It provides a helpful description of how to construct a multiplication table for higher dimension Cayley-Dickson structures, but explicitly doesn't answer the question as to why the properties break. </p>\n\n<p>The Baez article many people suggest in responses to all hyper-complex number questions like mine is truly excellent, but is mostly restricted to octonions, and, in the few mentions it makes of higher dimension Cayley-Dickson algebras, does not refer to what properties are broken. </p>\n\n<p>Perhaps the question isn't answerable, but in any case it hasn't been answered in this forum. </p>\n\n<p>UPDATE 2: I should add that the sub question in this post about whether the loss of the alternative property specifically leads to the presence of zero divisors in sedenion algebra is definitely unique to my question. However, perhaps I should pose that as a separate question? Sorry, I'm not sure about that aspect of forum etiquette here. </p>\n", "pids": ["53e9afe8b7602d9703a3c85c"], "flag": 0}
{"question": "How to explain dropout regularization in simple terms?", "body": "<p>If you have a half page to explain <em>dropout</em>, how would you proceed? Which is the rationale behind this technique?</p>\n", "pids": ["599c7f09601a182cd28e5de6", "573696006e3b12023e513cb6"], "flag": 1}
{"question": "Group Theory via Category Theory", "body": "<p>I have previously done a course on group theory and now I am doing a <em>reading course</em> on category theory. So as an interesting exercise I have been asked to write an exposition of group theory for someone who already knows category theory but doesn't know any group theory. I have been given the liberty to decide how I build the theory. I already have a vague idea of what is to be done.</p>\n\n<ol>\n<li>However, I would like to hear ideas about what <em>should</em> be done. So I solicit advice on things I should emphasize, the ways I can exploit the given familiarity with category theory for a more economic presentation and/or a exposition through \"the path of least resistance\". And please feel free to also mention any tips or precautions.</li>\n<li>Please refer me to material along this line.</li>\n</ol>\n\n<p>Thanks!</p>\n", "pids": ["53e9bc54b7602d97048d0505"], "flag": 0}
{"question": "Hidden Markov Model vs Recurrent Neural Network", "body": "<p>Which sequential input problems are best suited for each?  Does input dimensionality determine which is a better match?  Are problems which require \"longer memory\" better suited for an LSTM RNN, while problems with cyclical input patterns (stock market, weather) more easily solved by an HMM?</p>\n\n<p>It seems like there is a lot of overlap; Im curious what subtle differences exist between the two.</p>\n", "pids": ["573698016e3b12023e6da477"], "flag": 1}
{"question": "Dropout makes performance worse", "body": "<p>I am playing with <a href=\"https://en.wikipedia.org/wiki/Dropout_(neural_networks)\" rel=\"noreferrer\">dropout</a> since all state of the art results in machine learning seem to be using it (for example, see <a href=\"https://arxiv.org/abs/1707.05589\" rel=\"noreferrer\">here</a>). I am familiar with all the guidelines (train longer, increase capacity of the model, use higher learning rates), but still cannot see it working. I've tried several different examples: <a href=\"https://github.com/fchollet/keras/blob/master/examples/imdb_cnn.py\" rel=\"noreferrer\">CNN for IMDB</a>, <a href=\"https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\" rel=\"noreferrer\">CNN for MNIST</a>, MLP for MNIST, <a href=\"https://groups.google.com/forum/#!topic/keras-users/Q2pSRCvTfSw\" rel=\"noreferrer\">MLP for IRIS</a>, and turning off dropout makes all my results better even though the default configurations have dropout (taken from the <a href=\"https://github.com/fchollet/keras/tree/master/examples\" rel=\"noreferrer\">Keras examples</a>). For example, I am attaching my results for one of the models trained on the IRIS dataset. The configuration without dropout has clearly the best performance. <a href=\"https://i.stack.imgur.com/jm8KL.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/jm8KL.png\" alt=\"Effect of dropout on MLP\"></a></p>\n\n<p>What am I missing?</p>\n\n<p>The code for the IRIS example is <a href=\"https://codeshare.io/5Z8xed\" rel=\"noreferrer\">here</a>.</p>\n", "pids": ["573696ce6e3b12023e5ce95a"], "flag": 1}
{"question": "What can we say of a group all of whose proper subgroups are abelian?", "body": "<p>Let $G$ be a group (not necessarily finite). Can we say something about its structure if we suppose that all of its proper subgroups are abelian? Is there a difference between the finite case and the infinite case?</p>\n\n<p>To put it in another way, is the class of such groups wild or do we control it? Naturally, abelian groups are part of it, but I am interested in the nonabelian case.</p>\n\n<p>This question may sound quite open but I think it should be interesting to investigate it.</p>\n", "pids": ["56d92b5adabfae2eeeda5dfe"], "flag": 0}
{"question": "Why isn&#39;t Akaike information criterion used more in machine learning?", "body": "<p>I just ran into \"Akaike information criterion\", and I noticed this large amount of literature on model selection (also things like BIC seem to exist).</p>\n\n<p>Why don't contemporary machine learning methods take advantage of these BIC and AIC model selection criteria?</p>\n", "pids": ["53e9a3fbb7602d9702d13c06"], "flag": 1}
{"question": "Taylor&#39;s Theorem with Peano&#39;s Form of Remainder", "body": "<p>The following form of Taylor's Theorem with minimal hypotheses is not widely popular and goes by the name of <em>Taylor's Theorem with Peano's Form of Remainder</em>:</p>\n\n<blockquote>\n  <p><strong>Taylor's Theorem with Peano's Form of Remainder</strong>: <em>If $f$ is a function such that its $n^{\\text{th}}$ derivative at $a$ (i.e. $f^{(n)}(a)$) exists then $$f(a + h) = f(a) + hf'(a) + \\frac{h^{2}}{2!}f''(a) + \\cdots + \\frac{h^{n}}{n!}f^{(n)}(a) + o(h^{n})$$ where $o(h^{n})$ represents a function $g(h)$ with $g(h)/h^{n} \\to 0$ as $h \\to 0$.</em></p>\n</blockquote>\n\n<p>One of the proofs (search \"Proof of Taylor's Theorem\" in <a href=\"http://paramanands.blogspot.com/2013/11/teach-yourself-limits-in-8-hours-part-4.html\" rel=\"noreferrer\">this blog post</a>) of this theorem uses repeated application of L'Hospital's Rule. And it appears that <a href=\"https://math.stackexchange.com/questions/1809060/proof-of-the-second-symmetric-derivative/1809079#comment3697164_1809079\">proofs of the above theorem  apart from the one via L'Hospital's Rule are not well known</a>. I have asked this question to get other proofs of this theorem which do not rely on L'Hospital's Rule and instead use simpler ideas.</p>\n\n<p>BTW I am also posting one proof of my own as a community wiki.</p>\n", "pids": ["53e998e9b7602d9702126b4f"], "flag": 0}
{"question": "Why is the roll of a die considered random?", "body": "<p>I've been reading articles on pseudo-randomness in computing when generating a random value. They all state that the generated numbers are pseudo-random because we know all the factors that influence the outcome, and that the roll of a die is considered truly random. But I'm wondering why. Don't we know all the physical forces that influence the die when it's being rolled? Or is there too many of them?</p>\n", "pids": ["56d81dbddabfae2eeea64f0e"], "flag": 0}
{"question": "Do ibuprofen or paracetamol cause hearing loss?", "body": "<p>This <a href=\"https://www.express.co.uk/life-style/health/743792/Ibuprofen-paracetamol-painkillers-hearing-loss-deaf-deafness\" rel=\"noreferrer\">2016 Express article</a> gives a rather disturbing warning that two common pain killers might cause the risk of hearing loss.</p>\n<blockquote>\n<p>PARACETAMOL or ibuprofen could cause long-term deafness, experts have revealed. Scientists have revealed the effects could caused by (sic) taking the painkillers for as frequently as (sic) two days a week for six years.</p>\n<p>Compared to women who have taken them for less than a year, women who regularly the two (sic) to treat chronic pain increased the risk of hearing loss by more than a sixth, the study revealed.</p>\n</blockquote>\n<p>(<a href=\"https://en.wikipedia.org/wiki/Paracetamol#Naming\" rel=\"noreferrer\">Paracetamol</a> is also commonly called acetaminophen or APAP, and under the brand names of Panadol or Tylenol.)</p>\n<p>If true, this sounds like a serious concern, but the article is poorly written and doesn't make it clear if it is from combining the two drugs or also applies to them when taken separately, whether it applies to both men and women, or women alone. It doesn't link to the report. It has also been a few years, so there should have been time for post-production peer review, and perhaps other studies.</p>\n<p>What is the real story? What demographics have been tested? What dosages of which drugs were involved? Is it more than merely correlation?</p>\n", "pids": ["55a46cde65ce31bc877a46dc", "5c136a49da56295a08a4afe0"], "flag": 1}
{"question": "Undergrad-level combinatorics texts easier than Stanley&#39;s Enumerative Combinatorics?", "body": "<p>I am an undergrad, math major, and I had basic combinatorics class before (undergrad level.) Currently reading Stanley's Enumerative Combinatorics with other math folks. We have found this book somewhat challenging~ Do you have any suggestions on other books to read? or books to help going thru Enumerative combinatorics?</p>\n", "pids": ["53e99ff0b7602d97028d12a6"], "flag": 0}
{"question": "Which simple puzzles have fooled professional mathematicians?", "body": "<p>Although I'm not a professional mathematician by training, I felt I should have easily been able to answer straight away the following puzzle:</p>\n<blockquote>\n<p>Three men go to a shop to buy a TV and the only one they can afford is £30 so they all chip in £10. Just as they are leaving, the manager comes back and tells  the assisitant that the TV was only £25. The assistant thinks quickly and decides  to make a quick profit, realising that he can give them all £1 back and keep £2.</p>\n<p>So the question is this: If he gives them all £1 back which means that they all  paid £9 each and he kept £2, wheres the missing £1?</p>\n<p>3 x £9 = £27 + £2 = £29...??</p>\n</blockquote>\n<p>Well, it took me over an hour of thinking before I finally knew what the correct answer to this puzzle was and, I'm embarrassed.</p>\n<p>It reminds me of the embarrassement some professional mathematicians must have felt in not being able to give the correct answer to the famous Monty Hall problem answered by Marilyn Vos Savant:</p>\n<p><a href=\"http://www.marilynvossavant.com/articles/gameshow.html\" rel=\"noreferrer\">http://www.marilynvossavant.com/articles/gameshow.html</a></p>\n<blockquote>\n<p>Suppose you're on a game show, and you're given the choice of three doors. Behind one door is a car, behind the others, goats. You pick a door, say #1, and the host, who knows what's behind the doors, opens another door, say #3, which has a goat. He says to you, &quot;Do you want to pick door #2?&quot; Is it to your advantage to switch your choice of doors?</p>\n<p>Yes; you should switch.</p>\n</blockquote>\n<p>It's also mentioned in the book: The Man Who Only loved Numbers, that Paul Erdos was not convinced the first time either when presented by his friend with the solution to the Monty Hall problem.</p>\n<p>So what other simple puzzles are there which the general public can understand yet can fool professional mathematicians?</p>\n", "pids": ["53e99a62b7602d97022cdf14"], "flag": 0}
{"question": "When can we find holomorphic bijections between annuli?", "body": "<p>I'm self-studying some complex analysis, and apparently holomorphic bijections between two annuli exist precisely when the ratios of the radii are the same. More exactly, if $A_{\\sigma,\\rho}=\\{z\\in\\mathbb{C}:\\sigma&lt|z|&lt\\rho\\}$, then there is a holomorphic bijection between $A_{\\sigma,\\rho}$ and $A_{\\sigma',\\rho'}$ iff $\\rho/\\sigma=\\rho'/\\sigma'$.</p>\n\n<p>Is there a reference where this fact is proven? Or can a proof be included here if it's not overly involved? Thanks.</p>\n", "pids": ["56d8b06adabfae2eeedc80e9"], "flag": 0}
{"question": "Do Integrals over Fractals Exist?", "body": "<p>Given, for example, a line integral like \n$$\r\n\\int_\\gamma f \\; ds\r\n$$\nwith $f$ not further defined, yet.</p>\n\n<ul>\n<li>What happens, if the contour $\\gamma$ happens to be a fractal curve?</li>\n</ul>\n\n<p>Since all fractal curves (to my knowledge) are not differentiable and have an infinite length, we should run into some trouble. Further questions of interest are:</p>\n\n<ul>\n<li>What happens if the integral is taken over a Julia Set?</li>\n<li>What happens in the case of a space-filling curve? Do we get a surface integral then?</li>\n</ul>\n\n<p>I'd be glad, if anybody could wrap her/his <a href=\"http://en.wikipedia.org/wiki/List_of_fractals_by_Hausdorff_dimension#Random_and_natural_fractals\">2.79-Hausdorff-dimensional brain surface</a> around it!</p>\n", "pids": ["53e9ba76b7602d9704699f7c"], "flag": 0}
{"question": "Quasi-coherent sheaves, schemes, and the Gabriel-Rosenberg theorem", "body": "<p>In the context of commutative rings, a ring is completely determined by its category of modules. That is, two commutative rings $R$ and $S$ are isomorphic if and only if the category of $R$-modules is equivalent to the category of $S$-modules. In particular, we have the following result about affine schemes: </p>\n\n<blockquote>\n  <p>If $X=(X,\\mathcal O_X)$ is a scheme, let $QCoh(X)$ denote the category of quasi-coherent $\\mathcal O_X$-modules on $X$. Then, two affine schemes $X$ and $Y$ are isomorphic if and only if $QCoh(X)$ is equivalent to $QCoh(Y)$.</p>\n</blockquote>\n\n<p>(This follows from the fact that if $X=Spec(R)$ for a commutative ring $R$, then $QCoh(X)$ is equivalent to the category of $R$-modules.) My question is the following:</p>\n\n<blockquote>\n  <p>For a general scheme $X$, to what extent does $QCoh(X)$ determine $X$?</p>\n</blockquote>\n\n<p><strong>Added:</strong> As t.b. noted below in the comments, the <a href=\"http://ncatlab.org/nlab/show/Gabriel-Rosenberg+theorem\">Gabriel-Rosenberg reconstruction theorem</a> answers the question, at least in the quasi-compact, quasi-connected case, which is the first case proven by Gabriel. But the nLab page is not very clear about the further generalizations. In particular, I would like to know in how much generality it holds, and the uses of the quasi-compactness  hypothesis.</p>\n", "pids": ["56d8824adabfae2eee71b8c8"], "flag": 0}
{"question": "Does the artificial sweetener aspartame cause cancer?", "body": "<p>I've often heard that the artificial sweetener <a href=\"http://www.weightlossresources.co.uk/diet/healthy_eating/aspartame.htm\" rel=\"noreferrer\">aspartame</a> causes cancer.</p>\n\n<p>Is it true?</p>\n", "pids": ["53e9b3bcb7602d9703ea167c"], "flag": 1}
{"question": "What&#39;s the Clifford algebra?", "body": "<p>I'm reading a book on Clifford algebra for physicists. I don't quite understand it conceptually even if I can do most algebraic manipulations. Can some-one teach me what the Clifford algebra really is? (Keep in mind that I don't know abstract algebra, nothing except some group theory.) \nDoes it make sense to write the sum of a scalar and a bivector in the Clifford product? Both are very different things.</p>\n", "pids": ["53e9aa73b7602d97033e75d4"], "flag": 0}
{"question": "Simple &quot;real life&quot; NP-hard problems?", "body": "<p>There are many proofs lying around that games like Lemmings or Sudoku or Tetris are NP-hard (generalized version of those games, of course). The proofs, as I recall, are not difficult but not simple either.</p>\n\n<p>I wish to give my students a question in their homework assignment which tackles some known game or something similar, so I'm interested in examples to such problem for which the proof of hardness is not hard (at least, the student can solve it with some direction).</p>\n", "pids": ["53e99fbcb7602d970289302e"], "flag": 0}
{"question": "Ambiguous Curve: can you follow the bicycle?", "body": "<p>Let $\\alpha:[0,1]\\to \\mathbb R^2$ be a smooth closed curve parameterized by the arc length. We will think of $\\alpha$ like a back track of the wheel of a bicycle. If we suppose that the distance between the two wheels is $1$ then we can describe the front track by </p>\n\n<p>$$\\tau(t)=\\alpha(t)+\\alpha'(t)\\;.$$</p>\n\n<p>Suppose we know the two (back and front) trace of a bicycle. Can you determine the orientation of the curves? For example if $\\alpha$ was a circle the answer is no. </p>\n\n<p>More precisely the question is:</p>\n\n<p>Is there a smooth closed curve parameterized by the arc length $\\alpha$ such that   </p>\n\n<p>$$\\tau([0,1])=\\gamma([0,1])$$  </p>\n\n<p>where $\\gamma(t)=\\alpha(1-t)-\\alpha'(1-t)$?</p>\n\n<p>If trace of $\\alpha$ is a circle we have  $\\tau([0,1])=\\gamma([0,1])$. Is there another?</p>\n", "pids": ["53e9ab82b7602d9703529237", "53e9b1a3b7602d9703c2f774"], "flag": 0}
{"question": "Conjecture: Every analytic function on the closed disk is conformally a polynomial.", "body": "<p>Here is my conjecture, any proof, counter-example, or intuitions?</p>\n\n<p>If $f$ is analytic on $\\text{cl}(\\mathbb{D})$ (that is, analytic on some open set containing $\\text{cl}(\\mathbb{D})$), then there is some injective analytic function $\\phi:\\mathbb{D}\\to\\mathbb{C}$ and polynomial $p$ such that $f=p\\circ\\phi$ on $\\mathbb{D}$.</p>\n\n<p>PS: I would then say that $f$ and $p$ are conformally equivalent.  Is there a better term for this relationship?</p>\n\n<p>Note: $\\text{cl}(\\mathbb{D})$ could be replaced by any simply connected compact set.  If we wanted to replace \"simply connected\" with \"finitely connected\", then we would have to replace \"polynomial\" with \"rational function\".</p>\n", "pids": ["56d8bbebdabfae2eee36188b", "56d89500dabfae2eee076234"], "flag": 0}
{"question": "Smallest graph with automorphism group the quaternion $8$-group, $Q_8$", "body": "<p>Frucht's Theorem states that for any finite group <span class=\"math-container\">$G$</span> there is a finite (undirected) graph <span class=\"math-container\">$\\Gamma$</span> for which the automorphism group <span class=\"math-container\">$\\text{Aut}(\\Gamma)$</span> of <span class=\"math-container\">$\\Gamma$</span> is isomorphic to <span class=\"math-container\">$G$</span>, and for many small groups <span class=\"math-container\">$G$</span> it is not hard to construct a small graph <span class=\"math-container\">$\\Gamma$</span> whose automorphism group <span class=\"math-container\">$\\text{Aut}(\\Gamma)$</span> is isomorphic to <span class=\"math-container\">$G$</span>.</p>\n\n<p>For example, <span class=\"math-container\">$\\Bbb Z_1$</span>, <span class=\"math-container\">$\\Bbb Z_2$</span>, and <span class=\"math-container\">$S_3$</span> are the automorphism groups of the complete graphs <span class=\"math-container\">$K_1, K_2$</span>, <span class=\"math-container\">$K_3$</span>, respectively, <span class=\"math-container\">$\\Bbb Z_2 \\times \\Bbb Z_2$</span> is the automorphism group of</p>\n\n<p><a src=\"https://i.stack.imgur.com/GmlqT.png\" alt=\"enter image description here\">,</p>\n\n<p><span class=\"math-container\">$\\Bbb Z_3$</span> is the automorphism group of the <span class=\"math-container\">$9$</span>-vertex graph </p>\n\n<p><a src=\"https://i.stack.imgur.com/e9Hyo.png\" alt=\"enter image description here\">,</p>\n\n<p><span class=\"math-container\">$\\Bbb Z_4$</span> and <span class=\"math-container\">$\\Bbb Z_5$</span> are respectively the automorphism groups of the <span class=\"math-container\">$12$</span>- and <span class=\"math-container\">$15$</span>-vertex analogues of that graph given (informally) by replacing the central triangle with a square or pentagon, <span class=\"math-container\">$\\Bbb Z_6$</span> is the automorphism group of the <span class=\"math-container\">$12$</span>-vertex graph</p>\n\n<p><a src=\"https://i.stack.imgur.com/btqXP.png\" alt=\"enter image description here\"> ,</p>\n\n<p>and <span class=\"math-container\">$\\Bbb Z_7$</span>, <span class=\"math-container\">$\\Bbb Z_8$</span>, and <span class=\"math-container\">$\\Bbb Z_9$</span> are the respectively the automorphism groups of the <span class=\"math-container\">$14$</span>-, <span class=\"math-container\">$16$</span>-, and <span class=\"math-container\">$18$</span>-vertex analogues of that graph given by replacing the hexagons with heptagons, octagons, and nonagons.</p>\n\n<p>This accounts for all groups of order <span class=\"math-container\">$&lt; 10$</span> (in fact, except for the example for <span class=\"math-container\">$\\Bbb Z_4$</span>, these examples are all minimal w.r.t. vertex count, at least among connected graphs) except <span class=\"math-container\">$\\Bbb Z_2 \\times \\Bbb Z_2 \\times \\Bbb Z_2$</span>, <span class=\"math-container\">$\\Bbb Z_3 \\times \\Bbb Z_3$</span>, and the quaternion <span class=\"math-container\">$8$</span>-group, <span class=\"math-container\">$Q_8$</span>. One can modify without much fuss the above examples to produce graphs with automorphism groups the abelian groups in this list, but it is not so clear (to me) to see how to construct a reasonably small graph with automorphism group <span class=\"math-container\">$Q_8$</span>:</p>\n\n<blockquote>\n  <p>What is the minimal number of vertices of a graph <span class=\"math-container\">$\\Gamma$</span> for which <span class=\"math-container\">$\\text{Aut}(\\Gamma) \\cong Q_8$</span>? What is an example of such a graph that achieves this minimum? Among such graphs, which has (have) the minimal number of edges?</p>\n</blockquote>\n\n<p>We can given an upper bound for the vertex count: A theorem of Babai says for all groups <span class=\"math-container\">$G \\not\\cong \\Bbb Z_3, \\Bbb Z_4, \\Bbb Z_5$</span> there is a graph <span class=\"math-container\">$\\Gamma$</span> with <span class=\"math-container\">$\\text{Aut}(\\Gamma) \\cong G$</span> such that the action of <span class=\"math-container\">$\\text{Aut}(G)$</span> has only two orbits, and so in particular has vertex count <span class=\"math-container\">$V(\\Gamma)$</span> no larger than <span class=\"math-container\">$2|G|$</span>; thus, there is a graph <span class=\"math-container\">$\\Gamma$</span> with <span class=\"math-container\">$\\text{Aut}(\\Gamma) \\cong Q_8$</span> and <span class=\"math-container\">$V(\\Gamma) \\leq 16$</span>. (I expect that <span class=\"math-container\">$16$</span> is also the minimum achievable.)</p>\n\n<p>One can attempt to solve this by exploiting a constructive proof of Frucht's Theorem: Roughly, one starts with a Cayley graph of <span class=\"math-container\">$G$</span> (which is directed and colored according to generator), which has automorphism group (of directed, colored graphs) <span class=\"math-container\">$G$</span>. Then, one replaces each edge with a suitable (undirected) graph, choosing a different replacement graph for each generator, to avoid introducing new symmetries.</p>\n\n<p>It is not clear, however, that this approach can produce a graph with <span class=\"math-container\">$\\leq 16$</span> vertices and automorphism group <span class=\"math-container\">$Q_8$</span>. The simplest Cayley graph of <span class=\"math-container\">$Q_8$</span> is</p>\n\n<p><a src=\"https://i.stack.imgur.com/sKYYu.png\" alt=\"enter image description here\">,</p>\n\n<p>but this already has <span class=\"math-container\">$16$</span> edges, and it's hard to see how one could suitably replace them without added more than <span class=\"math-container\">$8$</span> new vertices in total.</p>\n\n<p><a href=\"https://math.stackexchange.com/a/1168168/155629\">This answer</a>, by the way, gives a graph with <span class=\"math-container\">$32$</span> vertices with automorphism group <span class=\"math-container\">$Q_8$</span> (acting with <span class=\"math-container\">$4$</span> orbits on the graph):</p>\n\n<p><a src=\"https://i.stack.imgur.com/nxlIS.png\" alt=\"enter image description here\">.</p>\n\n<p>Incidentally, one <em>can</em> use the above approach to improve upon this result, i.e., construct a graph <span class=\"math-container\">$\\Gamma$</span> with <span class=\"math-container\">$&lt; 32$</span> vertices and automorphism group <span class=\"math-container\">$Q_8$</span>: Let <span class=\"math-container\">$S(p, q)$</span> denote the graph with three vertices <span class=\"math-container\">$a, b, c$</span>, <span class=\"math-container\">$p$</span> edges between <span class=\"math-container\">$a$</span> and <span class=\"math-container\">$b$</span>, and <span class=\"math-container\">$q$</span> edges between <span class=\"math-container\">$b$</span> and <span class=\"math-container\">$c$</span>. Then, we can replace the red arrows in the above Cayley graph with <span class=\"math-container\">$S(p, q)$</span> (appropriately oriented) and the green arrows with <span class=\"math-container\">$S(p', q')$</span>, where <span class=\"math-container\">$p, q, p', q'$</span> are chosen to avoid introducing new automorphisms. Each replacement adds one vertex, so the resulting graph has <span class=\"math-container\">$24$</span> vertices. (This graph is, however, not simple, and so is less than entirely satisfying.)</p>\n\n<blockquote>\n  <p>Babai, L., \"On the minimum order of graphs with given group.\" <em>Canad. Math.\n  Bull.</em>, <strong>17</strong>, pp. 467–470, 1974.</p>\n  \n  <p>Frucht, R., \"Herstellung von Graphen mit vorgegebener abstrakter Gruppe.\" <em>Compositio Mathematica</em> (in German) <strong>6</strong>, pp. 239–250, 1939.</p>\n</blockquote>\n", "pids": ["5ac1828717c44a1fda9169b8"], "flag": 0}
{"question": "Questions on a self-made theorem about polynomials", "body": "<p>I recently came up with this theorem:</p>\n<blockquote>\n<p>For any complex polynomial <span class=\"math-container\">$P$</span> degree <span class=\"math-container\">$n$</span>:</p>\n<p><span class=\"math-container\">$$ \\sum\\limits_{k=0}^{n+1}(-1)^k\\binom{n+1}{k}P(a+kb) = 0\\quad \\forall a,b \\in\\mathbb{C}$$</span></p>\n</blockquote>\n<p>Basically, if <span class=\"math-container\">$P$</span> is quadratic, <span class=\"math-container\">$P(a) - 3P(a+b) + 3P(a+2b) - P(a+3b) = 0$</span> (inputs of <span class=\"math-container\">$P$</span> are consecutive terms of any arithmetic sequence). This can be generalized to any other degrees.</p>\n<ul>\n<li>Has this been discovered? If yes, what's the formal name for this phenomenon?</li>\n<li>Is it significant/Are there important consequences of this being true?</li>\n<li>Can this be generalized to non-polynomials?</li>\n</ul>\n", "pids": ["53e9b316b7602d9703dde7a1"], "flag": 0}
{"question": "Martingale theory: Collection of examples and counterexamples", "body": "<p>The aim of this question is to collect interesting examples and counterexamples in martingale theory. There is a huge variety of such (counter)examples available here on StackExchange but I always have a hard time when I try to locate a specific example/question. I believe that it would be a benefit to make this knowledge easier to access. For this reason I would like to create a (big) list with references to related threads.</p>\n\n<p>Martingale theory is a broad topic, and therefore I suggest to focus on time-discrete martingales <span class=\"math-container\">$(M_n)_{n \\in \\mathbb{N}}$</span>. I am well aware that this is still a quite broad field. To make this list a helpful tool (e.g. for answering questions) please make sure to give a short but concise description of each (counter)example which you list in your answer.</p>\n\n<p>Related literature:</p>\n\n<ul>\n<li>Jordan M. Stoyanov: Counterexamples in Probability, Dover.</li>\n<li>Joseph P. Romano, Andrew F. Siegel: Counterexamples in probability and statistics, CRC Press.</li>\n</ul>\n", "pids": ["56d87146dabfae2eeef6c1b1"], "flag": 0}
{"question": "Iteratively replacing $3$ chocolates in a box of $10$", "body": "<blockquote>\n  <p>In the fridge there is a box containing 10 expensive high quality Belgian chocolates, which my mum keeps for visitors. Every day, when mum leaves home for work, I secretly pick 3 chocolates at random, I eat them and replace them with ordinary cheap ones, that have exactly the same wrapping. On the next day I do the same, obviously risking to eat also some of the cheap ones. How many days on average will it take for the full replacement of the expensive chocolates with cheap ones?</p>\n</blockquote>\n\n<p>I would say <span class=\"math-container\">$10/3$</span> but this is very simplistic. \nAlso, the total number of ways to pick 3 chocolates out of 10 is \n<span class=\"math-container\">$\\binom {10} 3=\\frac {10!}{3!7!} = 120$</span>\nwhich means that after 120 days I will have replaced all chocolates but I don't think it is correct.</p>\n\n<p>Any help?</p>\n", "pids": ["61efe8d65244ab9dcb096f84"], "flag": 0}
{"question": "Why is a general formula for Kostka numbers &quot;unlikely&quot; to exist?", "body": "<p>In reference to Stanley's Enumerative Combinatorics Vol. 2: right after he has defined Kostka numbers (section 7.10), he mentions that it is unlikely that a general formula for $K_{\\lambda\\mu}$ exists, where $K_{\\lambda\\mu}$ is the number of semistandard Young tableaux of shape $\\lambda$ and type $\\mu$ with $\\lambda\\vdash n$ and $\\mu$ a weak composition of $n$. Why? In particular, is this an expression of something rigorous, and if so, what?</p>\n", "pids": ["53e9a051b7602d97029375b7"], "flag": 0}
{"question": "Do people with flu shots shed the influenza virus more than those who aren&#39;t vaccinated?", "body": "<p><a href=\"https://www.collective-evolution.com/2018/04/11/the-flu-vaccine-one-of-several-reasons-why-its-useless-potentially-dangerous/\" rel=\"noreferrer\">This 2018 <em>Collective Evolution</em> article</a> claims:</p>\n<blockquote>\n<p>Once recent study, however, did bother to look at the question of whether the vaccine prevents transmission. Published on January 18, 2018, in the journal of the Proceedings of the National Academy of Sciences of the United States of America, PNAS, the study’s authors screened volunteers with confirmed cases of influenza and took breath samples. And among their findings was “an association between repeated vaccination and increased viral aerosol generation” [...]</p>\n<p>In fact, <strong>subjects who had received the influenza vaccine in both the current and the previous season were found to shed over six times more aerosolized virus</strong> than those who did not get a flu shot during either season.</p>\n</blockquote>\n<p>Do people who receive flu shots shed the virus more than people who don't?</p>\n", "pids": ["5c0f7b9ada562944ac7b5066", "55a3d00c65ce5cd7b3b89db6"], "flag": 1}
{"question": "What is the difference between topological and metric spaces?", "body": "<p>What is the difference between a topological and a metric space?</p>\n", "pids": ["56d8f6cbdabfae2eee9898c0"], "flag": 0}
{"question": "The $5n+1$ Problem", "body": "<p>The Collatz Conjecture is a famous conjecture in mathematics that has lasted for over 70 years. It goes as follows:</p>\n\n<p>Define $f(n)$ to be as a function on the natural numbers by:</p>\n\n<p>$f(n) = n/2$ if $n$ is even and\n$f(n) = 3n+1$ if $n$ is odd</p>\n\n<p>The conjecture is that for all $n \\in \\mathbb{N}$, $n$ eventually converges under iteration by $f$ to $1$.</p>\n\n<p>I was wondering if the \"5n+1\" problem has been solved. This problem is the same as the Collatz problem except that in the above one replaces $3n+1$ with $5n+1$.</p>\n", "pids": ["53e9a272b7602d9702b75f2a"], "flag": 0}
{"question": "Is this photo showing a woman standing in the nude before teenagers real?", "body": "<p>There's a photo going around Twitter and the right-wing blogosphere of a woman standing in the nude at an art exhibition attended by a bunch of teenagers.</p>\n\n<p>I do not want to embed this photo, as it includes nudity..</p>\n\n<p>Here is where I saw it: </p>\n\n<p><a href=\"https://www.citizenfreepress.com/breaking/insane-photo-what-the-hell-are-they-teaching-our-kids/\" rel=\"noreferrer\">Kane: \"Insane Photo — What are they teaching our kids!\"\nposted on CitizenFreePress on July 28, 2019 12:31 am</a>\n (archived here: <a href=\"http://archive.is/Yd8pS\" rel=\"noreferrer\">http://archive.is/Yd8pS</a>)</p>\n\n<p>Where is this photo from, and is it real or photoshopped?</p>\n", "pids": ["55a4d5e065ceb7cb02d98abd"], "flag": 1}
{"question": "On limits, schemes and Spec functor", "body": "<p>I have several related questions:</p>\n<p>Do there exist colimits in the category of schemes? If not, do there exist just direct limits? Do there exist limits? If not, do there exist just inverse limits? With more generality and summarizing, with which generality there exist limits and colimits in Schemes?</p>\n<p>Then, if I have a colimit of rings, its Spec is a limit in the category of affine schemes. Is it so in the category of all schemes? If not, with which generality, that is, what kinds of colimits does Spec transform to limits?</p>\n<p>And does Spec transform limits into colimits? If not, whith which generality, that is, what kinds of limits does Spec transform to colimits?</p>\n", "pids": ["56d84f2fdabfae2eeef58d5c"], "flag": 0}
{"question": "what happens when a model is having more parameters than training samples", "body": "<p>In a simple neural network, say, for example, the number of parameters is kept small compared to number of samples available for training and this perhaps forces the model to learn the patterns in the data. Right?</p>\n\n<p>My question is that what repercussions could we have in a scenario where the number of parameters in a model are more than the number of training instances available ?</p>\n\n<p>Can such a model lead to over-fit? What effect can those extra parameters bring about in the model performance?</p>\n\n<p>Kindly shed some light on this. I believe that it is only the data representation (number of hidden layers, number of neurons in each layer etc.) that governs the number of parameters in the model. Is my understanding correct ?</p>\n", "pids": ["5a260c8417c44a4ba8a315cc", "58d82fced649053542fd6ec6"], "flag": 1}
{"question": "Bayesian thinking about overfitting", "body": "<p>I've devoted much time to development of <a href=\"http://fharrell.com/doc/rms.pdf\" rel=\"noreferrer\">methods</a> and <a href=\"http://biostat.mc.vanderbilt.edu/Rrms\" rel=\"noreferrer\">software</a> for validating predictive models in the traditional frequentist statistical domain.  In putting more Bayesian ideas into practice and teaching I see some key differences to embrace.  First, Bayesian predictive modeling asks the analyst to think hard about prior distributions that may be customized to the candidate features, and these priors will pull the model towards them (i.e., achieve shrinkage/penalization/regularization with different amounts of penalization for different predictive features).  Second, the \"real\" Bayesian way does not result in a single model but one gets an entire posterior distribution for a prediction.</p>\n\n<p>With those Bayesian features in mind, what does overfitting mean?  Should we assess it?  If so, how?  How do we know when a Bayesian model is reliable for field use?  Or is that a moot point since the posterior will carry along all of the caution-giving uncertainties when we use the model we developed for prediction?</p>\n\n<p>How would the thinking change if we forced the Bayesian model to be distilled to a single number, e.g., posterior mean/mode/median risk?</p>\n\n<p>I see some related thinking <a href=\"https://stats.stackexchange.com/questions/82664\">here</a>.  A parallel discussion may be found <a href=\"http://discourse.mc-stan.org/t/discuss-overfitting-model-validation-in-bayesian-context/4078/2\" rel=\"noreferrer\">here</a>.</p>\n\n<p><strong>Follow-up question</strong>: : If we are fully Bayesian and spend some time thinking about the priors before seeing the data, and we fit a model where the data likelihood was appropriately specified, are we compelled to be satisfied with our model with regard to overfitting?  Or do we need to do what we do in the frequentist world where a randomly chosen subject may be predicted well on the average, but if we choose a subject who has a very low prediction or one having a very high predicted value there will be regression to the mean?</p>\n", "pids": ["56d85339dabfae2eee143f1e"], "flag": 1}
{"question": "Reference request: compact objects in R-Mod are precisely the finitely-presented modules?", "body": "<p>Let $R$ be a ring. According to <a href=\"https://mathoverflow.net/questions/59282/sums-compact-objects-f-g-objects-in-categories-of-modules\">this MO question</a>, the modules $M \\in R\\text{-Mod}$ such that $\\text{Hom}(M, -)$ preserves all filtered colimits (the <a href=\"http://ncatlab.org/nlab/show/compact+object\" rel=\"noreferrer\">compact objects</a>) are precisely the finitely-presented modules. Where can I find a proof of this?</p>\n", "pids": ["56d86564dabfae2eee9c6da8"], "flag": 0}
{"question": "Concrete examples of 2-categories", "body": "<p>I've been reading some of John Baez's work on 2-categories (eg <a href=\"http://math.ucr.edu/home/baez/week89.html\">here</a>) and have been trying to visualize some of the constructions he gives.</p>\n\n<p>I'm interested in coming up with 'concrete' examples of 2-categories. As an example of what I <em>don't</em> mean, I know that the category <strong>Cat</strong> forms a 2-category, where the objects are small categories, the morphisms are functors and the 2-morphisms are natural transformations. But this is too abstract for me - given that categorical constructs are what I'm having trouble understanding, it doesn't help me much to give an example from category theory!</p>\n\n<p>One thought I had is that you might be able to view a group as a 2-category. Taking the perspective that a group is a category with one object where the morphisms are the symmetries of the object, you should then be able to construct a 2-category by saying that the 2-morphisms are the inner automorphisms of the group. An interesting question is then what the compositional structure of the 2-morphisms is.</p>\n\n<p>To be really concrete, consider the group $D_3$. Here the object is an equilateral triangle, and there are six morphisms $e$, $r$, $r^2$, $m$, $mr$ and $mr^2$ where $e$ is the identity, $r$ is rotation by $2\\pi/3$ and $m$ is reflection in one of the axes of symmetry, and the others are the obvious compositions of these.</p>\n\n<p>Then the 2-morphisms are the functions $\\phi_g$ given by $\\phi_g(h)=ghg^{-1}$. For this example, the 2-morphisms have the structure of the underlying group $D_3$, but clearly this isn't always the case (e.g. for any abelian group the 2-morphisms have the structure of the trivial group). I haven't worked through many of the details, but it seems like there might be the grain of an interesting line of thought here.</p>\n\n<p>So my questions are:</p>\n\n<ol>\n<li><p>Is viewing groups as 2-categories an interesting thing to do, i.e. does it give you any new perspectives that make previously esoteric facts about groups 'obvious', or at least special cases of results in 2-categories?</p></li>\n<li><p>What other 'concrete' examples of 2-categories are there?</p></li>\n</ol>\n", "pids": ["5d9edb9f47c8f7664602136e"], "flag": 0}
{"question": "A new formula for Apery&#39;s constant and other zeta(s)?", "body": "<p>I recently found these Plouffe-like formulas using Mathematica's <em>LatticeReduce</em>. Has anybody seen/can prove these are indeed true? </p>\n\n<p>$$\\begin{aligned}\\frac{3}{2}\\,\\zeta(3) &amp;= \\frac{\\pi^3}{24}\\sqrt{2}-2\\sum_{k=1}^\\infty \\frac{1}{k^3(e^{\\pi k\\sqrt{2}}-1)}-\\sum_{k=1}^\\infty\\frac{1}{k^3(e^{2\\pi k\\sqrt{2}}-1)}\\\\\n\\frac{3}{2}\\,\\zeta(5) &amp;= \\frac{\\pi^5}{270}\\sqrt{2}-4\\sum_{k=1}^\\infty \\frac{1}{k^5(e^{\\pi k\\sqrt{2}}-1)}+\\sum_{k=1}^\\infty \\frac{1}{k^5(e^{2\\pi k\\sqrt{2}}-1)}\\\\\n\\frac{9}{2}\\,\\zeta(7) &amp;= \\frac{41\\pi^7}{37800}\\sqrt{2}-8\\sum_{k=1}^\\infty\\frac{1}{k^7(e^{\\pi k\\sqrt{2}}-1)}-\\sum_{k=1}^\\infty\\frac{1}{k^7(e^{2\\pi k\\sqrt{2}}-1)} \\end{aligned}$$</p>\n\n<p>And so on for other $\\zeta(2n+1)$.  The background for these are in my <a href=\"http://tpiezas.wordpress.com/2012/06/11/a-new-formula-for-aperys-constant/\">blog</a>.</p>\n", "pids": ["53e9aee4b7602d970390ddbb"], "flag": 0}
{"question": "What are some theorems that currently only have computer-assisted proofs?", "body": "<p>What are some theorems that currently only have computer-assisted proofs? For example, there's the four colour theorem.</p>\n\n<p>I am very curious about this and would like to generate a list.</p>\n", "pids": ["555041da45ce0a409eb3e15a", "53e9b0a0b7602d9703b0d2ae"], "flag": 0}
{"question": "Is it a good idea to use CNN to classify 1D signal?", "body": "<p>I am working on the sleep stage classification. I read some research articles about this topic many of them used SVM or ensemble method. Is it a good idea to use convolutional neural network to classify one-dimensional EEG signal?<br>\nI am new to this kind of work. Pardon me if I ask anything wrong? </p>\n", "pids": ["599c7987601a182cd2648373", "58d82fcbd649053542fd63ad", "595f860a0cf221598a2386c9"], "flag": 1}
{"question": "Given two basis sets for a finite Hilbert space, does an unbiased vector exist?", "body": "<p>Let $\\{A_n\\}$ and $\\{B_n\\}$ be two bases for an $N$-dimensional <a href=\"http://en.wikipedia.org/wiki/Hilbert_space\">Hilbert space</a>. Does there exist a <a href=\"http://en.wikipedia.org/wiki/Unit_vector\">unit vector</a> $V$ such that:  </p>\n\n<p>$$(V\\cdot A_j)\\;(A_j\\cdot V) = (V\\cdot B_j)\\;(B_j\\cdot V) = 1/N\\;\\;\\; \\ \\text{for all} \\ 1\\le j\\le N?$$</p>\n\n\n\n<p><strong>Notes and application:</strong><br>\nThat the $\\{A_n\\}$ and $\\{B_n\\}$ are <a href=\"http://en.wikipedia.org/wiki/Basis_%28linear_algebra%29\">bases</a> means that<br>\n$$(A_j\\cdot A_k) =\\left\\{\\begin{array}{cl}\r\n1&amp;\\;\\text{if }j=k,\\\\\r\n0&amp;\\;\\text{otherwise}.\\end{array}\\right.$$  </p>\n\n<p>In the physics notation, one might write $V\\cdot A_j = \\langle V\\,|\\,A_j\\rangle$. In quantum mechanics, $P_{jk} = |\\langle A_j|B_k\\rangle|^2$ is the \"transition probability\" between the states $A_j$ and $B_k$. \"Unbiased\" means that there is no preference in the transition probabilities. A subject much studied in <a href=\"http://en.wikipedia.org/wiki/Quantum_information\">quantum information theory</a> is <a href=\"http://en.wikipedia.org/wiki/Mutually_unbiased_bases\">\"mutually unbiased bases\" or MUBs</a>. Two mutually unbiased bases satisfy<br>\n$|\\langle A_j|B_k\\rangle|^2 = 1/N\\;\\;$ for all $j,k$.  </p>\n\n<p>If it is true that the vector $V$ always exists, then one can multiply the rows and columns of any unitary matrix by complex phases so as to obtain <a href=\"http://brannenworks.com/Gravity/qioumm_view.pdf\">a unitary matrix where each row and column individually sums to one</a>.</p>\n\n\n\n<p>If true, then $U(n)$ can be written as follows:<br>\n$$U(n) = \\exp(i\\alpha)\r\n\\begin{pmatrix}1&amp;0&amp;0&amp;0...\\\\0&amp;e^{i\\beta_1}&amp;0&amp;0...\\\\0&amp;0&amp;e^{i\\beta_2}&amp;0...\\end{pmatrix}\r\nM\r\n\\begin{pmatrix}1&amp;0&amp;0&amp;0...\\\\0&amp;e^{i\\gamma_1}&amp;0&amp;0...\\\\0&amp;0&amp;e^{i\\gamma_2}&amp;0...\\end{pmatrix}$$\nwhere the Greek letters give complex phases and where $M$ is a \"magic\" unitary matrix, that is, $M$ has all rows and columns individually sum to 1.</p>\n\n<p>And $M$ can be written as $M=\\exp(im)$ where $m$ is Hermitian and has all rows and columns sum to 0. What's significant about this is that the $m$ form a Lie algebra. Thus unitary matrices can be thought of as complex phases, plus a Lie algebra. This is a new decomposition of unitary matrices.</p>\n\n<p>Since $m$ is Hermitian and has all rows and columns sum to 0, it is equivalent to an $(n-1)\\times(n-1)$ Hermitian matrix with no restriction on the row and column sums. And this shows that $U(n)$ is equivalent to complex phases added to an object (the $M$ matrices) that is equivalent to $U(n-1)$. This gives a recursive definition of unitary matrices entirely in terms of complex phases.</p>\n", "pids": ["5c61073eda56297340af7783", "53e9a335b7602d9702c3c544", "53e9b0d8b7602d9703b54791", "53e99d7ab7602d97026385bc", "56d844aedabfae2eeea49cb3", "61c8764e5244ab9dcbe52fa4"], "flag": 0}
{"question": "Does the Levi-Civita connection determine the metric?", "body": "<p>Can I reconstruct a Riemannian metric out of its Levi-Civita connection?\nIn other words: Given two Riemannian metrics $g$ and $h$ on a manifold $M$ with the same Levi-Civita connection, can I conclude that $g=h$ up to scalars?</p>\n\n<p>If not, what can I say about the relationship between $g$ and $h$? How rigid is the Levi-Civita-Connection?</p>\n", "pids": ["53e9bde2b7602d9704a9333a"], "flag": 0}
{"question": "When is a metric space Euclidean, without referring to $\\mathbb R^n$?", "body": "<p>Normally, the Euclidean space is introduced as $\\mathbb R^n$. However, I've now been thinking about how one might define the $n$-dimensional Euclidean space only from the properties of the metric. I've come up with the following conjecture:</p>\n\n<blockquote>\n  <p>A metric space $(M,d)$ is an $n$-dimensional Euclidean space iff it has the following properties:</p>\n  \n  <p><strong>Line segment (L):</strong> For any two points $A,B\\in M$ and any number $\\lambda\\in [0,1]$, there exists exactly one point $C\\in M$ so that $d(A,C)=\\lambda\\,d(A,B)$ and $d(C,B)=(1-\\lambda)\\,d(A,B)$.</p>\n  \n  <p><strong>Uniqueness of extension (U):</strong> If for any points $A,B,C,D\\in M$ with $A\\ne B$ we have $d(A,C)=d(A,B)+d(B,C)=d(A,D)=d(A,B)+d(B,D)$ then $C=D$.</p>\n  \n  <p><strong>Homogeneity (H):</strong> For any four points $A,B,C,D\\in M$ with $d(A,B)=d(C,D)$ there exists an isometry $\\phi$ of $M$ so that $\\phi(A)=C$ and $\\phi(B)=D$.</p>\n  \n  <p><strong>Scale invariance (S):</strong> For any $\\lambda&gt;0$ there exists a function $s\\colon M\\to M$ so that for any two points $A,B\\in M$ we have $d(s(A),s(B)) = \\lambda\\,d(A,B)$.</p>\n  \n  <p><strong>Dimension (D):</strong> The maximal number of different points $P_1,\\ldots,P_k$ so that each pair of them has the same distance is $n+1$.</p>\n</blockquote>\n\n<p>Now my question: Is this correct? That is, do those conditions already guarantee that the metric space is an $n$-dimensional Euclidean space? If not, what would be an example of a metric space which is not Euclidean, but fulfils all the conditions above?</p>\n\n<p>What I already found (unless I've done an error, in that case, please correct):</p>\n\n<p>It is easy to see that it contains a full line for each pair of points: Given the points $A$ and $B$, the condition (L) already gives the points in between $A$ and $B$. Now for any $r&gt;0$, (S) tells us that there exist two points $C,D$ so that $d(C,D) = (r+1)\\,d(A,B)$. Then (L) guarantees the existence of a point $E$ with $d(C,E)=1$ and $d(E,D)=r$. And (H) guarantees us an isometry $\\phi(C)=A$ and $\\phi(E)=B$. Then the line segment from $A$ to $\\phi(D)$ extends the line segment in the direction of $B$. (U) guarantees us that this extension is unique.</p>\n\n<p>If we define a straight line $l$ as a set of points so that for any three points $A, B, C\\in l$ the largest of their distances is the sum of the other two distances, then from we also get immediately that two lines can intersect at most in one point (because if they have two points in common, then (L) guarantees that all points in between are also common, and I just showed that the extension is also unique).</p>\n\n<p>I can also use the law of cosines to define the angle $\\phi = \\angle ABC$ as $\\cos\\phi = \\frac{d(A,C)^2-d(A,B)^2-d(B,C)^2}{2\\,d(A,B)\\,d(B,C)}$ (of course the law of the cosine <em>assumes</em> Euclidean geometry, but since I'm <em>defining</em> the angle, this just means that if the space is not Euclidean, the angle I just defined is not the usual angle). It is obvious that this angle is independent of scaling (because a common factor just cancels out).</p>\n\n<p>I also think that with the definition of the angle above, I should get that the sum of angles in the triangle is always $\\pi$ (because I can just map the three points individually on three points with the same distance onto a known Euclidean plane, and there I know that the angles add up to $\\pi$).</p>\n\n<p>However is that already sufficient to show that it is an Euclidean space? Or could there be some strange metric space where all this is true without it being an Euclidean space?</p>\n", "pids": ["573696766e3b12023e5823a5"], "flag": 0}
{"question": "Where to start learning about topological data analysis?", "body": "<p>I was wondering if anyone could help me out with finding a nice introductory text for topological data analysis (I'm speaking as somebody who has two semesters of experience with topology, and much less experience with data analysis.) Are there any self-contained elementary resources on the subject? And if not, is there a sort of road map for the subject (i.e. a generally-agreed-upon sequence of topics that I should study)?</p>\n\n<p>I saw a nice overview here: <a href=\"http://www.cs.dartmouth.edu/~afra/papers/ams12/tda.pdf\" rel=\"noreferrer\">http://www.cs.dartmouth.edu/~afra/papers/ams12/tda.pdf</a>, and that piqued my interest in the topic. Thanks in advance for the help!</p>\n", "pids": ["5c75758df56def9798a04f6c"], "flag": 0}
{"question": "How do you calculate the decimal expansion of an irrational number?", "body": "<p>Just curious, how do you calculate an irrational number? Take $\\pi$ for example. Computers have calculated $\\pi$ to the millionth digit and beyond. What formula/method do they use to figure this out? How does it compare to other irrational numbers such as $\\varphi$ or $e$?</p>\n", "pids": ["53e9b04eb7602d9703ab1718", "53e9b83fb7602d97043fd81d"], "flag": 0}
{"question": "Examples of theorems that are true conceptually, but false computationally", "body": "<p>I am currently reading <a href=\"https://leanprover.github.io/theorem_proving_in_lean/axioms_and_computation.html\" rel=\"noreferrer\">Theorem Proving in Lean</a>, a document dealing with how to use <a href=\"https://leanprover.github.io\" rel=\"noreferrer\">Lean</a> (an open source theorem prover and programming language). My question stems from chapter 11.</p>\n\n<p>The particular section of the chapter that I'm interested in discusses the history and philosophical context of an initially \"essentially computational\" style of mathematics, until the 19th century, when a \"more \"conceptual\"\" understanding of mathematics was required.</p>\n\n<p>The following quote is taken from the second paragraph of section 11.1 of the linked document.</p>\n\n<blockquote>\n  <p>The goal was to obtain a powerful “conceptual” understanding without getting bogged down in computational details, but this had the effect of admitting mathematical theorems that are simply <em>false</em> on a direct computational reading.</p>\n</blockquote>\n\n<p>This is by no means essential to the understanding of the contents of the document itself, but I'm curious to ask what examples of theorems are false in a \"direct computational reading\".</p>\n\n<p>In other words, <strong>are there any examples of theorems that are true conceptually, but false computationally?</strong></p>\n", "pids": ["53e9b95bb7602d970454b736"], "flag": 0}
{"question": "Why is it considered that $(\\mathrm d x)^2=0$?", "body": "<p>Why is it okay to consider that $(\\mathrm d x)^n=0$ for any n greater than $1$?\nI can understand that $\\mathrm d x$ is infinitesimally small ( but greater than $0$ ) and hence its square or cube should be approximately equal to $0$ not exactly $0$ . </p>\n\n<p>But if this is so then how can we expect the results obtained from calculus to be <strong>exact</strong> and <strong>not just approximate</strong> ( like the slope or area under a curve )? </p>\n\n<p>I have also noticed some anomalies, like <strong>$\\sqrt{ (\\mathrm d x)^2 + (\\mathrm d y)^2 }$ is $0$ but $\\mathrm d x\\sqrt{1+ (\\mathrm d y/\\mathrm d x)^2 }$ is not $0$ when these two things are apparently the same</strong> . Moreover we can  claim that </p>\n\n<p>$$(\\mathrm d x)^2=(\\mathrm d x)^3=(\\mathrm d x)^4 = \\cdots = 0$$</p>\n\n<p>which is quite hard to believe.</p>\n\n<p>Can you help me figure out the logic behind these things ?</p>\n", "pids": ["5b67c927ab2dfb7a202aa69a"], "flag": 0}
{"question": "What are some real-world uses of Octonions?", "body": "<blockquote>\n  <p>... octonions are the crazy old uncle nobody lets out of the attic: they are nonassociative.</p>\n</blockquote>\n\n<p>Comes from a a quote by John Baez. Clearly, the sucessor to quaterions from the Cayley-Dickson process is a numerical beast, but has anybody found any real-world uses for them? For example, quaterions have a nice connection to computer graphics through the connection to SO(4), and that alone makes them worth studying. What can be done with a nonassociative algebra like the octonions?</p>\n\n<p>Note: simply mentioning that they</p>\n\n<blockquote>\n  <p>have applications in fields such as string theory, special relativity, and quantum logic.</p>\n</blockquote>\n\n<p>is not what I'm looking for (I can read wikipedia too). A specific example, especially one that is geared to someone who is <strong>not</strong> a mathematician by trade would be nice!</p>\n", "pids": ["53e9a3abb7602d9702cbe312", "53e9acaeb7602d970368ea72", "53e9b6eeb7602d9704281435", "5ff7deccd4150a363cc58e66"], "flag": 0}
{"question": "Squares in arithmetic progression", "body": "<p>It is easy to find 3 squares (of integers) in arithmetic progression. For example, $1^2,5^2,7^2$.</p>\n\n<p>I've been told Fermat proved that there are no progressions of length 4 in the squares. Do you know of a proof of this result? </p>\n\n<p>(Additionally, are there similar results for cubes, 4th powers, etc? If so, what would be a good reference for this type of material?)</p>\n\n\n\n<p><strong>Edit, March 30, 2012:</strong> The following <a href=\"https://mathoverflow.net/questions/92707/squares-in-an-arithmetic-progession\">question</a> in MO is related and may be useful to people interested in the question I posted here.</p>\n", "pids": ["53e9a7ddb7602d970311e30c"], "flag": 0}
{"question": "closed-form expression for roots of a polynomial", "body": "<p>It is often said colloquially that the roots of a general polynomial of degree $5$ or higher have \"no closed-form formula,\" but the Abel-Ruffini theorem only proves nonexistence of <em>algebraic</em> closed-form formulas. And I remember reading somewhere that the roots of quintic equations can be expressed in terms of the hypergeometric function.</p>\n\n<p>What is known, beyond Abel-Ruffini, about closed-form formulas for roots of polynomials? Does there exist a formula if we allow the use of additional special functions?</p>\n", "pids": ["53e9b196b7602d9703c22edb", "53e9a5efb7602d9702f18338"], "flag": 0}
{"question": "How do bumblebees and hornets avoid the negative effects of inbreeding?", "body": "<p>I just learned that all hornets and bumblebees except for the queen die at the end of the year and the queen starts a new nest in spring. </p>\n\n<p>But that means the next generation of queens have only brothers to breed with.</p>\n\n<p>Should this lead to severe inbreeding, which over a couple of years would cause serious problems for survival?</p>\n", "pids": ["53e9b429b7602d9703f24a89"], "flag": 1}
{"question": "Does a small cup of coffee result in a 45% reduced blood flow to the brain?", "body": "<p>The <em>Humans are Free</em> article <em><a href=\"http://humansarefree.com/2017/08/13-little-known-facts-about-coffee.html\" rel=\"noreferrer\">The Coffee Deception: 13 Little Known Facts About Coffee</a></em> makes the claim that caffeine from a cup of coffee reduces blood flow to the brain.  </p>\n\n<blockquote>\n  <p><strong>2.</strong> MRI images taken before and after 1 cup of coffee showed a decrease in blood flow to the brain by 45%. When the blood flow reduction was measured exactly, it was actually 52% less blood flow to the brain, after just one small cup of coffee.<br>\n  (Source given: Caffeine's Effects on the Human Brain, abcnews, <a href=\"http://abcn.ws/2ipmLj7\" rel=\"noreferrer\">http://abcn.ws/2ipmLj7</a>) </p>\n</blockquote>\n\n<p>Is there any truth to this claim?</p>\n", "pids": ["55a5270965ceb7cb02e2aae5", "5c757508f56def97989ae4c6", "59828b4b0cf2cf55b9dbdbce", "53e99bdcb7602d9702483115", "53e99a0fb7602d97022627ea", "5c756ea8f56def97985f2439", "63087bdc90e50fcafdfb4002"], "flag": 1}
{"question": "Applications of model theory to analysis", "body": "<p>Some of the more organic theories considered in model theory (other than set theory, which, from what I've seen, seems to be quite distinct from \"mainstream\" model theory) are those which arise from algebraic structures (theories of abstract groups, rings, fields) and real and complex analysis (theories of expansions of real and complex fields, and sometimes both).</p>\n\n<p>While relationships with algebra seem quite apparent, I wonder what are some interesting results in real and complex analysis that have nice model-theoretical proofs (or better yet, only model-theoretical proofs are known!)? </p>\n\n<p>Of course, there's nonstandard analysis, but I hope to see some different examples. That said, I wouldn't mind seeing a particularly interesting application of nonstandard analysis. :)</p>\n\n<p>I hope the question is at least a little interesting. I have only the very basic knowledge of model theory of that type (and the same applies to nonstandard analysis), so it may seem a little naive, but I got curious, hence the question.</p>\n", "pids": ["5c61078bda56297340b0b1f5"], "flag": 0}
{"question": "Examples of Diophantine equations with a large finite number of solutions", "body": "<p>I wonder, if there are examples of <a href=\"http://en.wikipedia.org/wiki/Diophantine_equation\">Diophantine equations</a> (or systems of such equations) with integer coefficients fitting on a few lines that have been proven to have a finite, but really huge number of solutions? </p>\n\n<p>Are there ones with so large number of solutions that we cannot write any explicit upper bound for this number using <a href=\"http://en.wikipedia.org/wiki/Conway_chained_arrow_notation\">Conway chained arrow notation</a>?</p>\n\n<p><em>Update:</em> I am also interested in equations with few solutions but where a value in a solution is very large itself.</p>\n", "pids": ["56d83e82dabfae2eee74f571", "56d883a2dabfae2eee7bd1c2", "5a260c0217c44a4ba8a1ccf5"], "flag": 0}
{"question": "Suspension of a product - tricky homotopy equivalence", "body": "<p>Let $(X,x_0), (Y,y_0)$ be well-pointed spaces (inclusion of the basepoints is a cofibration). Show the following homotopy equivalence\n$$\n\\Sigma (X\\times Y) \\simeq \\Sigma X \\lor \\Sigma Y \\lor \\Sigma (X\\land Y),\n$$\nwhere $\\Sigma$ means a <a href=\"http://en.wikipedia.org/wiki/Suspension_%28topology%29\">suspension</a> (or reduced suspension if one prefers since it doesn't matter for well-pointed spaces) and $\\land$ is a <a href=\"http://en.wikipedia.org/wiki/Smash_product\">smash product</a>.</p>\n\n<p>Assuming we are using reduced suspension, it is quite clear that $\\Sigma X \\lor \\Sigma Y$ is a subspace of the lhs, but I don't know how to somehow pull it outside and get $\\Sigma (X\\land Y)$.</p>\n\n<p><strong>Edit:</strong> I know the homotopy equivalence can be deduced from general theorems on \"homotopy functors\" (I hope that's how they are called in English) from chapter 7.7 in Spanier. But I was told there is an explicit proof and that's the one I'm looking for.</p>\n", "pids": ["5def90423a55ac809f181412"], "flag": 0}
{"question": "Why do new rules cause students to forget and misapply older rules?", "body": "<p>I teach at a community college. I have taught everything from arithmetic to linear algebra. I have also taught at 4-year schools, but at present, I'm devoting my energies to the problem of helping remedial algebra students to succeed. </p>\n\n<p>I have noticed a pattern in my remedial classes. It's disturbing. You see, my students first learn the concept of \"combining alike terms\" example:</p>\n\n<p>$3x^2y - 5x^2y = -2x^2y$ </p>\n\n<p>I present this topic in a number of ways including manipulatives and concrete examples.  We then apply this concept in a variety of contexts including systems of linear equations, and in word problems. Basically, it <em>appears</em> that they are getting quite good at working with variables.</p>\n\n<p>But, later when we study exponent rules such as:</p>\n\n<p>$x^ax^b=x^{a+b}$</p>\n\n<p>$(x^a)^b=x^{ab}$</p>\n\n<p>$x^{-a}=\\frac{1}{x^a}$, for $x \\neq 0$</p>\n\n<p>etc.</p>\n\n<p>these new rules seem to displace and muddy the older rules in the minds of the students. A week ago they would have considered:</p>\n\n<p>$2x + 5x = 7x$</p>\n\n<p>to be \"easy\" and every single student (even the weakest) had mastered this type of problem (signed numbers and fractions could be another matter...but still) Yet, after teaching the exponent rules I notice students doing things like this:</p>\n\n<p>$2x + 5x = 7x^2$</p>\n\n<p>to me this indicates a fundamental disconnect in terms of how mathematics works, I know they are aware of the older \"rules\" but it is as if they expect each problem to have different set of rules. This has happened all three times that I have taught this course, despite my effort to teach it in a different way each time. </p>\n\n<p>I find that this type of error is much more common in remedial classes. Why is that? I have also taught elementary school algebra and I simply never saw mistakes like this.  Not, at least, with the frequency I'm finding them now, even among responsible students who are clearly intelligent people as evidenced by their work in other subjects and pursuits, students who are putting in large amounts of time studying, who take notes etc. And these erors are hard to fix, explanations don't seem help much. </p>\n\n<p>What is going on here? Is there a name for this? </p>\n\n<p>I honestly wonder what it is I've taught them in the past two months if each new concept displaces and corrupts the old concepts.</p>\n\n<p>Eventually the students <em>will</em> master the new rules but I get the feeling many of them are working much harder than they should be to do so. It's like they are doing something that's more like memorizing a complex gymnastics routine than mathematics. Others become very frustrated, to them it must seeming like I'm just making up random stuff as I go along to vex them. </p>\n\n<p>But <em>I</em> know mathematics makes sense. That's why I love it.\nHow can I help them to see this?</p>\n", "pids": ["53e99a6db7602d97022da070"], "flag": 0}
{"question": "Where does the term &quot;integral domain&quot; come from?", "body": "<p>Self-explanatory title really! A student today asked me why they were called integral domains -- and I realised that the word \"integral\" seems to be being used in a way totally unlike any other way I hear it used in mathematics. The student suggested that \"integral\" was used because the integers were an example -- but I didn't buy this because by that logic they could have been called \"rational domains\" or \"real domains\".</p>\n\n<p>Any ideas anyone?</p>\n", "pids": ["56d8795fdabfae2eee2fd4bc"], "flag": 0}
{"question": "How many nodes in the smallest $k$-dense graph?", "body": "<p>Let's call a directed graph <strong><span class=\"math-container\">$k$</span>-dense</strong> if:</p>\n\n<ul>\n<li>Each node has exactly two children (outgoing neighbors);</li>\n<li>Each two nodes have at least three different children (besides themselves);</li>\n<li>Each three nodes have at least four different children (besides themselves);</li>\n<li>...</li>\n<li>Each <span class=\"math-container\">$k$</span> nodes have at least <span class=\"math-container\">$k+1$</span> different children (besides themselves);</li>\n</ul>\n\n<blockquote>\n  <p>What is the smallest number of nodes required for a <span class=\"math-container\">$k$</span>-dense graph?</p>\n</blockquote>\n\n<p>Here are some special cases.</p>\n\n<p>For <span class=\"math-container\">$k=1$</span>, the smallest number of nodes is <span class=\"math-container\">$3$</span>:</p>\n\n<pre><code>1-&gt;[2,3],   2-&gt;[3,1],   3-&gt;[1,2]\n</code></pre>\n\n<p>For <span class=\"math-container\">$k=2$</span>, the smallest number of nodes is <span class=\"math-container\">$7$</span>. To see this we can build the graph greedily based on the following constraint: a node's child must be different than its parent(s) and is sibling(s). Why? Because a node and its parent together must have three children besides themselves.</p>\n\n<ul>\n<li><span class=\"math-container\">$1$</span> has two children: call them <span class=\"math-container\">$2$</span> and <span class=\"math-container\">$3$</span>.</li>\n<li><span class=\"math-container\">$2$</span> must have two children different than its parent (<span class=\"math-container\">$1$</span>) and sibling (<span class=\"math-container\">$3$</span>): call them <span class=\"math-container\">$4$</span> and <span class=\"math-container\">$5$</span>.</li>\n<li><span class=\"math-container\">$3$</span> must have two children different than its parent (<span class=\"math-container\">$1$</span>) and sibling (<span class=\"math-container\">$2$</span>). The first can be <span class=\"math-container\">$4$</span>. Now, <span class=\"math-container\">$3$</span> and <span class=\"math-container\">$2$</span> together have only two children besides themselves (<span class=\"math-container\">$4$</span> and <span class=\"math-container\">$5$</span>), so <span class=\"math-container\">$3$</span> must have another different child - call it <span class=\"math-container\">$6$</span>.</li>\n<li><span class=\"math-container\">$4$</span> must have two children different than its parents (<span class=\"math-container\">$2$</span> and <span class=\"math-container\">$3$</span>) and siblings (<span class=\"math-container\">$5$</span> and <span class=\"math-container\">$6$</span>). The first can be <span class=\"math-container\">$1$</span> and the second must be new - call it <span class=\"math-container\">$7$</span>. </li>\n<li><span class=\"math-container\">$5$</span> must have two children different than its parent (<span class=\"math-container\">$2$</span>) and siblings (<span class=\"math-container\">$4$</span>). The first can be <span class=\"math-container\">$1$</span>. The second cannot be one of <span class=\"math-container\">$1$</span>'s children (<span class=\"math-container\">$2$</span> and <span class=\"math-container\">$3$</span>) or siblings (<span class=\"math-container\">$7$</span>) so it must be <span class=\"math-container\">$6$</span>.</li>\n<li><span class=\"math-container\">$6$</span> must have two children different than its parents (<span class=\"math-container\">$3$</span> and <span class=\"math-container\">$5$</span>) and siblings (<span class=\"math-container\">$4$</span> and <span class=\"math-container\">$1$</span>). These must be <span class=\"math-container\">$2$</span> and <span class=\"math-container\">$7$</span>.</li>\n<li><span class=\"math-container\">$7$</span> must have two children different than its parents (<span class=\"math-container\">$4$</span> and <span class=\"math-container\">$6$</span>) and siblings (<span class=\"math-container\">$2$</span> and <span class=\"math-container\">$1$</span>). These must be <span class=\"math-container\">$3$</span> and <span class=\"math-container\">$5$</span>.</li>\n</ul>\n\n<p>All in all, we have the following <span class=\"math-container\">$2$</span>-dense graph with <span class=\"math-container\">$n=7$</span> nodes:</p>\n\n<pre><code>1-&gt;[2,3]  2-&gt;[4,5]  3-&gt;[4,6]  4-&gt;[1,7]  5-&gt;[1,6]  6-&gt;[2,7]  7-&gt;[3,5]\n</code></pre>\n\n<p>For <span class=\"math-container\">$k=3$</span>, I used a similar greedy algorithm (with more constraints) to construct the following graph:</p>\n\n<pre><code> 1-&gt;[2,3]    2-&gt;[4,5]    3-&gt;[6,7]    4-&gt;[6,8]     5-&gt;[7,9]\n 6-&gt;[10,11]  7-&gt;[12,13]  8-&gt;[1,9]    9-&gt;[10,14]  10-&gt;[2,12]  \n11-&gt;[1,13]  12-&gt;[8,15]  13-&gt;[4,14]  14-&gt;[3,15]   15-&gt;[5,11]\n</code></pre>\n\n<p>I used a computer program to check all possibilities with at most <span class=\"math-container\">$14$</span> nodes, and found none, so (assuming my program is correct) <span class=\"math-container\">$n=15$</span> is the minimum number required for <span class=\"math-container\">$k=3$</span>.</p>\n\n<p>This hints that the minimum number of nodes in a <span class=\"math-container\">$k$</span>-dense graph should be: <span class=\"math-container\">$2^{k+1}-1$</span>. Is this true?</p>\n\n<p><strong>What is the smallest number of nodes required for general <span class=\"math-container\">$k$</span>?</strong></p>\n\n<p>UPDATE 1: I have just learned about <a href=\"https://en.wikipedia.org/wiki/Expander_graph#Vertex_expansion\" rel=\"noreferrer\">vertex expansion</a>. It seems closely related but I am still not sure how exactly. </p>\n", "pids": ["53e9b5edb7602d970413d48c"], "flag": 0}
{"question": "Implementing Ornstein–Uhlenbeck in Matlab", "body": "<p>I am reading <a href=\"http://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process\">this</a> article on Wikipedia, where three sample paths of different OU-processes are plotted. I would like to do the same to learn how this works, but I face troubles implementing it in Matlab.</p>\n\n<p>I think I have to discretize this equation somehow:\n$ x_t  = x_0 e^{-\\theta t} + \\mu(1-e^{-\\theta t}) + \\int_0^t \\sigma e^{\\theta (s)}\\, \\mathrm{d}W_s. \\, $,\nbut especially the integral equation confuses me a lot.</p>\n\n<p>I also think I will  have to use $W_t = W_t-W_0 \\sim N(0,t)$ somehow, but don't know how yet...</p>\n\n<p>Can someone please help me out?\nI am new to stochastic calculus, so please help me understand step by step.</p>\n", "pids": ["53e9b337b7602d9703e081a1"], "flag": 1}
{"question": "Right adjoints preserve limits", "body": "<p>In Awodey's book I read a slick proof that right adjoints preserve limits. If $F:\\mathcal{C}\\to \\mathcal{D}$ and $G:\\mathcal{D}\\to \\mathcal{C}$ is a pair of functors such that $(F,G)$ is an adjunction, then if $D:I\\to \\mathcal{D}$ is a diagram that has a limit, we have, for every $A\\in \\mathcal{C}$,</p>\n\n<p>$\\begin{align*} \\hom_\\mathcal{C} (A, G(\\varprojlim D)) &amp;\\simeq \\hom_{\\mathcal{D}} (F(A),\\varprojlim D)\\\\ &amp; \\simeq \\varprojlim \\hom_{\\mathcal{D}}(F(A),D)\\\\&amp; \\simeq \\varprojlim \\hom_{\\mathcal{C}}(A,GD) \\\\&amp; \\simeq \\hom_{\\mathcal{C}}(A,\\varprojlim GD)\\end{align*}$</p>\n\n<p>because representables preserve limits. Whence, by Yoneda lemma, $G(\\varprojlim D)\\simeq \\varprojlim GD$.</p>\n\n<p>This is very slick, but I can't really see why the proof is finished. Yes, we proved that the two objects are isomorphic, but a limit is not just an object... Don't we need to prove that the isomorphism also respects the natural maps? That is,</p>\n\n<p>if $\\varphi:G(\\varprojlim D)\\to \\varprojlim GD$ is the isomorphism, and $\\alpha_i: \\varprojlim D \\to D_i$, $\\beta_i:\\varprojlim GD \\to GD_i$ are the canonical maps for all $i\\in I$, do we have that $\\beta_i\\varphi=G(\\alpha_i)$?</p>\n\n<p>I don't see how this follows from Awodey's proof. How can we deduce it?</p>\n", "pids": ["56d89901dabfae2eee27435f"], "flag": 0}
{"question": "Is the Euler phi function bounded below?", "body": "<p>I am working on a question for my number theory class that asks:</p>\n\n<blockquote>\n  <p>Prove that for every integer $n \\geq 1$, $\\phi(n) \\geq \\frac{\\sqrt{n}}{\\sqrt{2}}$.</p>\n</blockquote>\n\n<p>However, I was searching around Google, and on various websites I have found people explaining that the phi function has a defined upper bound, but no lower bound. Am I reading these sites incorrectly, or am I missing something in the problem itself?</p>\n", "pids": ["53e99bfeb7602d97024a9f93"], "flag": 0}
{"question": "Motivation for/history of Jacobi&#39;s triple product identity", "body": "<p>I'm taking a short number theory course this summer. The first topic we covered was <a href=\"https://en.wikipedia.org/wiki/Jacobi_triple_product\">Jacobi's triple product identity</a>. I still have no sense of why this is important, how it arises, how it might have been discovered, etc. The proof we studied is a bit on the clever side for my taste, giving me no sense of how said proof might have been discovered. Can anyone help?</p>\n", "pids": ["5c610996da56297340b82442"], "flag": 0}
{"question": "Conjectured closed form for $\\int_0^1x^{2\\,q-1}\\,K(x)^2dx$ where $K(x)$ is the complete elliptic integral of the 1ˢᵗ kind", "body": "<p>I am interested in a general closed-form formula for integrals of the following form:\n$$\\mathcal{J}_q=\\int_0^1x^{2\\,q-1}\\,K(x)^2dx,\\tag0$$\nwhere $K(x)$ is the <a href=\"http://mathworld.wolfram.com/CompleteEllipticIntegraloftheFirstKind.html\">complete elliptic integral of the 1ˢᵗ kind</a>:\n$$K(x)={_2F_1}\\left(\\frac12,\\frac12;\\ 1;\\ x^2\\right)\\frac\\pi2\\\\=\\int_0^{\\pi/2}\\frac{d\\phi}{\\sqrt{1-x^2\\sin^2\\phi}}=\\int_0^1\\frac{dz}{\\sqrt{1-x^2z^2\\vphantom{|^2}}\\sqrt{1-z^2\\vphantom{|^2}}}.\\tag1$$\nI could not find a suitable integral in <a href=\"http://dlmf.nist.gov/19\">DLMF</a> or <a href=\"http://books.google.com/books?id=aBgFYxKHUjsC&amp;modulus&amp;pg=PA631\">Gradshteyn—Ryzhik</a> or <a href=\"http://books.google.com/books?id=2t2cNs00aTgC\">Prudnikov</a> tables of integrals. <a href=\"http://www.wolfram.com/mathematica\"><em>Mathematica</em></a> was not able to evaluate it either, even when the parameter $q$ was fixed to an integer (<em>Note</em>: In <em>Mathematica</em> you would write <a href=\"http://reference.wolfram.com/mathematica/ref/EllipticK.html\"><code>EllipticK[x^2]</code></a> for $K(x)$ because of a different convention for the modulus parameter).</p>\n\n<p><strong>But</strong>, numerical integration and lookups in <a href=\"http://www.wolframalpha.com\"><em>WolframAlpha</em></a> and <a href=\"http://isc.carma.newcastle.edu.au\"><em>ISC+</em></a> suggest that there are closed forms for (at least some) postitive integer values of the parameter $q$. For example,</p>\n\n<p>$$\\mathcal{J}_1\\stackrel?=\\frac{7\\,\\zeta(3)}4,\\ \\mathcal{J}_2\\stackrel?=\\frac{7\\,\\zeta(3)}8+\\frac14,\\\\\\mathcal{J}_3\\stackrel?=\\frac{77\\,\\zeta(3)}{128}+\\frac{17}{64},\\ \\mathcal{J}_4\\stackrel?=\\frac{119\\,\\zeta(3)}{256}+\\frac{881}{3456},\\tag2$$\nwhere $\\zeta(3)$ is the <a href=\"http://mathworld.wolfram.com/AperysConstant.html\">Apéry constant</a>.\nIt looks that the general formula for postitive integer values of $q$ is\n$$\\mathcal{J}_q\\stackrel?=a_q\\,\\zeta(3)+b_q,\\tag3$$\nwhere $a_q,\\,b_q$ are some rational coefficients. I tried to find general formulae for these coefficients, and actually discovered plausible candidates for both. </p>\n\n<p>Conjecturally, $a_q$ can be expressed in terms of a <a href=\"http://mathworld.wolfram.com/GeneralizedHypergeometricFunction.html\">generalized hypergeometric function</a>:\n$$a_q\\stackrel?=\\frac{7\\,\\pi}4\\cdot\\frac{{_4F_3}\\left(\\begin{array}{c}\\frac12,\\,\\frac12,\\,1-q,\\,1-q\\\\1,\\,\\frac32-q,\\,\\frac32-q\\end{array}\\middle|\\ 1\\right)}{\\Gamma\\left(\\frac32-q\\right)^2\\ \\Gamma(q)^2}.\\tag4$$\nSomewhat suprisingly, this scarish expression seems to evaluate only to rationals for all $q\\in\\mathbb{Z}^+$. </p>\n\n<p>For $b_q$ I found only a conjectural recurrence relation:\n$$b_1\\stackrel?=0,\\ b_2\\stackrel?=\\frac14,\\ b_q\\stackrel?=\\frac{2 \\,(2\\,q-3)\\,\\left(2\\,q^2-6\\,q+5\\right)\\cdot b_{q-1}-4\\,(q-2)^3\\cdot b_{q-2}+1}{4\\,(q-1)^3},\\tag5$$\nbut I could not find a general term formula for it.</p>\n\n<blockquote>\n  <ul>\n  <li>Can we prove that the closed forms shown in $(2)$ are correct?</li>\n  <li>Can we prove that the formula $(3)$ holds for all $q\\in\\mathbb{Z}^+$ with some rational coefficients $a_q,\\,b_q$?</li>\n  <li>Are my conjectured formulae for these coefficients $(4),\\,(5)$ correct?</li>\n  <li>Can the formula $(4)$ be expanded in terms of simpler functions?</li>\n  <li>Is there a general term formula for $(5)$?</li>\n  <li>Can we find (or at least conjecture) a general closed-form formula for $\\mathcal{J}_q$ where $q$ is not necessarily an integer?</li>\n  </ul>\n</blockquote>\n", "pids": ["53e9ab25b7602d97034b1003"], "flag": 0}
{"question": "Is &quot;Linear Algebra Done Right 3rd edition&quot; good for a beginner?", "body": "<p>Amazon book reviews say it takes unorthodox approach and is for a second exposure to linear algebra. I didn't have a first exposure to linear algebra.</p>\n\n<p>Is this book going to be bad for me, then?\nOr, should I read another linear algebra book after reading it? I want to avoid reading two linear algebra books because reading such a textbook consumes a lot of time.</p>\n", "pids": ["6037657ed3485cfff1d92f4a"], "flag": 0}
{"question": "When the product of dice rolls yields a square", "body": "<p><strong>Succinct Question:</strong></p>\n<p>Suppose you roll a fair six-sided die <span class=\"math-container\">$n$</span> times.</p>\n<p>What is the probability that the product of the rolls is a square?</p>\n<p><strong>Context:</strong></p>\n<p>I used this as one question in a course for elementary school teachers when <span class=\"math-container\">$n=2$</span>, and thought the generalization might be a good follow-up question for secondary school math teachers. But I encountered quite a bit of difficulty in tackling it, and I am wondering if there is a neater solution than what I have already seen, and to what deeper phemonena it connects.</p>\n<p><strong>Known:</strong></p>\n<p>Since the six sides of a die are <span class=\"math-container\">$1, 2, 3, 2^2, 5,$</span> and <span class=\"math-container\">$2\\cdot3$</span>, the product of the rolls is always of the form <span class=\"math-container\">$2^{A}3^{B}5^{C}$</span>, and the question is now transformed into the probability that <span class=\"math-container\">$A, B, C$</span> are all even. The actual &quot;probability&quot; component is mostly for ease of phrasing; its only contribution is a <span class=\"math-container\">$6^n$</span> in the denominator, and my true question is of a more combinatorial nature: namely,</p>\n<blockquote>\n<p>In how many ways can the product of <span class=\"math-container\">$n$</span> rolls yield a square?</p>\n</blockquote>\n<p>One approach that I have seen involves first creating an <span class=\"math-container\">$8 \\times 8$</span> matrix corresponding to the eight cases around the parity of <span class=\"math-container\">$A, B, C$</span>; one can then take the dot product of each roll with this matrix, and hope to spot a pattern. In this way, one may <em>discover</em> the formula:</p>\n<p><span class=\"math-container\">$$\\frac{6^n + 4^n + 3\\cdot2^n}{8}$$</span></p>\n<p>and the &quot;probability&quot; version is simply this formula with another <span class=\"math-container\">$6^n$</span> multiplied in the denominator.</p>\n<p>As for <strong>proving</strong> this: Some guesswork around linear combinations of the numerator yields a formula for each of the eight cases concerning <span class=\"math-container\">$A,B,C$</span> parity, and one can then prove all eight of them by induction. And so I &quot;know&quot; the answer in the sense that I have all eight of the formulae (and the particular one listed above is correct) but they were not found in a particularly organized fashion.</p>\n<blockquote>\n<p><strong>My Actual Question:</strong></p>\n<p>What is a systematic way to deduce the formula, given above, for the number of ways the product of <span class=\"math-container\">$n$</span> rolls yields a square, and to what deeper phenomena does this connect?</p>\n</blockquote>\n", "pids": ["53e9a9a9b7602d9703303772"], "flag": 0}
{"question": "AIC or p-value: which one to choose for model selection?", "body": "<p>I'm brand new to this R thing but am unsure which model to select.</p>\n\n<ol>\n<li><p>I did a <em>stepwise forward regression</em> selecting each variable based on the lowest AIC. I came up with 3 models that I'm unsure which is the \"best\".</p>\n\n<pre><code>Model 1: Var1 (p=0.03) AIC=14.978\nModel 2: Var1 (p=0.09) + Var2 (p=0.199) AIC = 12.543\nModel 3: Var1 (p=0.04) + Var2 (p=0.04) + Var3 (p=0.06) AIC= -17.09\n</code></pre>\n\n<p>I'm inclined to go with Model #3 because it has the lowest AIC (I heard negative is ok) and the p-values are still rather low. </p>\n\n<p>I've ran 8 variables as predictors of Hatchling Mass and found that these three variables are the best predictors.</p></li>\n<li><p>My next forward stepwise I choose Model 2 because even though the AIC was slightly larger the p values were all smaller. Do you agree this is the best?</p>\n\n<pre><code>Model 1: Var1 (p=0.321) + Var2 (p=0.162) + Var3 (p=0.163) + Var4 (p=0.222)  AIC = 25.63\nModel 2: Var1 (p=0.131) + Var2 (p=0.009) + Var3 (p=0.0056)                  AIC = 26.518\nModel 3: Var1 (p=0.258) + Var2 (p=0.0254)                                   AIC = 36.905\n</code></pre></li>\n</ol>\n\n<p>thanks!</p>\n", "pids": ["56d8d7aedabfae2eeed7a650"], "flag": 1}
{"question": "Testing significance of peaks in spectral density", "body": "<p>We sometimes use spectral density plot to analyze periodicity in time series. Normally we analyze the plot by visual inspection and then try to draw a conclusion about the periodicity. But have the statisticians developed any test to check whether any spikes in the plot are statistically different from white noise? Have the R-experts developed any package for spectral density analysis and for doing that kind of test?</p>\n", "pids": ["5f0e8cc89fced0a24baf78d5"], "flag": 1}
{"question": "Bruteforcing a keypad lock", "body": "<p>A particular lock at my university has a keypad with the digits 1-5 on it. When pressed in the correct permutation of those five digits, the lock will open.</p>\n\n<p>Obviously, since there are only 120 permutations, we can bruteforce the lock in 600 presses. But we can do better! The sequence <code>1234512</code> actually tests three distinct sequences with only seven presses - <code>12345</code>, <code>23451</code>, and <code>34512</code>.</p>\n\n<p>What's the fastest strategy to bruteforce this lock?</p>\n\n<p>(and for bonus points, other locks with more numbers, longer passcodes, etc.)</p>\n\n<p>(I've taken a few stabs at this problem with no progress to speak of - particularly, De Bruijn sequences are not directly relevant here)</p>\n", "pids": ["5550417745ce0a409eb3b8eb"], "flag": 0}
{"question": "Clustering quality measure", "body": "<p>I have a clustering algorithm (not k-means) with input parameter $k$ (number of clusters). After performing clustering I'd like to get some quantitative measure of quality of this clustering. \nThe clustering algorithm has one important property. For $k=2$ if I feed $N$ data points without any significant distinction among them to this algorithm as a result I will get one cluster containing $N-1$ data points and one cluster with $1$ data point. Obviously this is not what I want. So I want to calculate this quality measure to estimate reasonability of this clustering. Ideally I will be able to compare this measures for different $k$. So I will run clustering in the range of $k$ and choose the one with the best quality.\nHow do I calculate such quality measure?</p>\n\n<p>UPDATE:</p>\n\n<p>Here's an example when $(N-1, 1)$ is a bad clustering. Let's say there are 3 points on a plane forming equilateral triangle. Splitting these points into 2 clusters is obviously worse than splitting them into 1 or 3 clusters.</p>\n", "pids": ["53e9a17fb7602d9702a71d29"], "flag": 1}
{"question": "Addressing model uncertainty", "body": "<p>I was wondering how the Bayesians in the CrossValidated community view the problem of <strong>model uncertainty</strong> and how they prefer to deal with it? I will try to pose my question in two parts:</p>\n\n<ol>\n<li><p>How important (in your experience / opinion) is dealing with model uncertainty? I haven't found any papers dealing with this issue in the machine learning community, so I'm just wondering why.</p></li>\n<li><p>What are the common approaches for handling model uncertainty (bonus points if you provide references)? I've heard of Bayesian model averaging, though I am not familiar with the specific techniques / limitations of this approach. What are some others and why do you prefer one over another?</p></li>\n</ol>\n", "pids": ["56d84dc8dabfae2eeeeb1424"], "flag": 1}
{"question": "What are the interesting applications of hyperbolic geometry?", "body": "<p>I am aware that, historically, hyperbolic geometry was useful in showing that there can be consistent geometries that satisfy the first 4 axioms of Euclid's elements but not the fifth, the infamous parallel lines postulate, putting an end to centuries of unsuccesfull attempts to deduce the last axiom from the first ones.</p>\n\n<p>It seems to be, apart from this fact, of genuine interest since it was part of the usual curriculum of all mathematicians at the begining of the century and also because there are so many books on the subject.</p>\n\n<p>However, I have not found mention of applications of hyperbolic geometry to other branches of mathematics in the few books I have sampled. Do you know any or where I could find them? </p>\n", "pids": ["619bb7251c45e57ce9500f31", "53e999eeb7602d97022362fa", "56d87adddabfae2eee3a49a6"], "flag": 0}
{"question": "Expected rank of a random binary matrix?", "body": "<p>Recently a friend stumbled across this question:</p>\n\n<blockquote>\n  <p>Let $M$ be a random $n \\times n$ matrix with entries in $\\{0,1\\}$ (both zero and one has probability $p = q = \\frac{1}{2}$). What is its expected rank?</p>\n</blockquote>\n\n<p>My intuition is that it would be something of order $\\frac{n}{\\log n}$, similarly to <a href=\"http://en.wikipedia.org/wiki/Coupon_collector%27s_problem\">coupon collector's problem</a>, but I could not produce anything more specific. Unfortunately my linear algebra skills are, to put it mildly, rusty. Is this a know problem? If the exact calculation is hard, are there any simple arguments regarding the order when $n$ tends to infinity?</p>\n\n<p>I would greatly appreciate any hints, proofs, references, or any other help.</p>\n\n<p><strong>Edit:</strong> The original question was phrased in terms of field $\\mathbb{F}_2$, however, the approach for $\\mathbb{R}$ would be great as well, that is I would consider it a full answer (especially if simpler).</p>\n", "pids": ["53e9a17fb7602d9702a6feb2"], "flag": 0}
{"question": "What is so wrong with thinking of real numbers as infinite decimals?", "body": "<p><a href=\"https://www.dpmms.cam.ac.uk/~wtg10/\" rel=\"noreferrer\">Timothy Gowers</a> asks <a href=\"https://www.dpmms.cam.ac.uk/~wtg10/decimals.html\" rel=\"noreferrer\">What is so wrong with thinking of real numbers as infinite decimals?</a></p>\n\n<blockquote>\n  <p>One of the early objectives of almost any university mathematics course is to teach people to stop thinking of the real numbers as infinite decimals and to regard them instead as elements of the unique complete ordered field, which can be shown to exist by means of Dedekind cuts, or Cauchy sequences of rationals.  I would like to argue here that there is <em>nothing</em> wrong with thinking of them as infinite decimals: indeed, many of the traditional arguments of analysis become more intuitive when one does, even if they are less neat. Neatness is of course a great advantage, and I do not wish to suggest that universities should change the way they teach the real numbers. However, it is good to see how the conventional treatment is connected to, and grows out of, more `naive' ideas.</p>\n</blockquote>\n\n<p>and gives a short construction of the real numbers as infinite decimals, then using that to demonstrate the existence of square roots, and the intermediate value theorem.</p>\n\n<p>What are other reasons for or against thinking of real numbers as infinite decimals?</p>\n", "pids": ["5d1b2f673a55ac071793c7a6", "56d87516dabfae2eee123b92"], "flag": 0}
{"question": "What is the architecture of a stacked convolutional autoencoder?", "body": "<p>So I am trying to do pretraining on images of humans using convolutional nets. I read the papers (<a href=\"http://people.idsia.ch/~ciresan/data/icann2011.pdf\" rel=\"noreferrer\">Paper1</a> and <a href=\"http://ai.stanford.edu/~ang/papers/nips10-TiledConvolutionalNeuralNetworks.pdf\" rel=\"noreferrer\">Paper2</a>) and this <a href=\"https://stackoverflow.com/questions/24752655/unsupervised-pre-training-for-convolutional-neural-network-in-theano\">stackoverflow link</a>, but I am not sure I am understand the structure of the nets (it is not well defined in the papers).</p>\n\n<p>Questions:</p>\n\n<ul>\n<li><p>I can have my input followed by a noise layer followed by a conv layer, followed by a pooling layer - there after - do I de-pool before I give my output (which is same a my input image)? </p>\n\n<p>Say I have several (135,240) images. If I use 32, (12,21) kernels, followed by (2,2) pooling, I will end up with 32 (62, 110) feature maps. Now do I de-pool to get 32 (124, 220) feature maps and then flatten them? before giving my (135,240) output layer?</p></li>\n<li><p>If I have multiple such conv-pool layers, should I train them one by one - like in stacked denoised autoencoders? Or - can I have something like input-conv-pool-conv-pool-conv-pool-output(output being same as input)? In that case, how is the pooling, depooling supposed to be managed? Should I only de-pool in the last pool layer before output? And again - what should be the resize factor of that de-pooling? Is the intention to bring the feature maps back to the shape of the input?</p></li>\n<li><p>Should I be introducing noise layers after every conv-pool-depool layer?</p></li>\n<li><p>And then when fine tuning - am I supposed to just remove the de-pooling layers and leave the rest the same. Or should I remove both the noise layers and de-pooling layers </p></li>\n<li><p>Can any one point me to a url / paper which has detailed the architecture of such a stacked convolutional auto encoder to do pre training on images?</p></li>\n</ul>\n", "pids": ["58d82fc8d649053542fd5cc9"], "flag": 1}
{"question": "Why do we need a Jordan normal form?", "body": "<p>My professor said that the main idea of finding a Jordan normal form is to find the closest 'diagonal' matrix that is similar to a given matrix that does not have  a similar matrix that is diagonal.\nI know that using a diagonal matrix is good for computations and simplifying powers of matrices. \nBut what is the potential of finding a matrix with Jordan form? what is this 'almost diagonal' matrix gives me?\nWe learnt how to find it, without knowing what is the main idea behind it and what are the applications used with it, so I can't really understand it.</p>\n", "pids": ["53e9b7f5b7602d97043a63d1"], "flag": 0}
{"question": "Dealing with 0,1 values in a beta regression", "body": "<p>I have some data in [0,1] which I would like to analyze with a beta regression.\nOf course something needs to be done to accommodate the 0,1 values.  I dislike\nmodifying data to fit a model.  also I don't believe that  zero and 1 inflation\nis a good idea because I believe in this case one should  consider the 0's\nto be very small positive values  (but I don't want to say exactly what\nvalue is appropriate.  A reasonable choice I believe would be to pick small values\nlike  .001 and .999  and to fit the model using the cumulative dist for the beta.\nSo for observations y_i the log likelihood LL_iwould be</p>\n\n<pre><code> if  y_i &lt; .001   LL+=log(cumd_beta(.001))\n else if y_i&gt;.999  LL+=log(1.0-cum_beta(.999))\n else LL+=log(beta_density(y_i))\n</code></pre>\n\n<p>What I like about this model is that if the beta regression model is valid\nthis model is also valid, but it removes a bit of the sensitivity to the\nextreme values. However this seems to be such a natural approach that\nI wonder why I don't find any obvious references in the literature.\nSo my question is instead of modifying the data, why not modify the model.\nModifying the data biases the results (based on the assumption that the original model is valid), whereas modifying the model by binnning the extreme values does not bias the results.</p>\n\n<p>Maybe there is a problem I am overlooking?</p>\n", "pids": ["53e9ba85b7602d97046aa71d", "53e9ba85b7602d97046aa71d"], "flag": 1}
{"question": "Rules for selecting convolutional neural network hyperparameters", "body": "<p>Are there any good papers that cover some methodical ways of picking the dimensions for filters, pooling the units, and determining the number of convolutional layers?</p>\n", "pids": ["5736960e6e3b12023e520c34"], "flag": 1}
{"question": "Trigonometric/polynomial equations and the algebraic nature of trig functions", "body": "<p>Prove or disprove that an equation involving one trig function (either $\\sin,\\cos,\\tan$, etc) with an argument of the form $ax+b$ for non-zero rational $a,b$  and a polynomial with non-zero rational coefficients and a constant term not equal to $\\pm1$ or zero is not solvable in closed form.  For example,</p>\n\n<p>$$\\sin(x)=2-x-x^2$$</p>\n\n<p>It has solutions near $x=0.752$ and $x=-2.242$</p>\n\n<p>My reasoning for why there is no closed form solution is because</p>\n\n<ol>\n<li><p>If $x$ is a rational multiple of $\\pi$, the LHS is algebraic, while the RHS is transcendental.</p></li>\n<li><p>If $x$ is of the form $x=\\arcsin(u)\\ne\\frac ab\\pi$ and $u$ is algebraic, then  the LHS is algebraic but the RHS... is not algebraic?  See <a href=\"https://mathoverflow.net/questions/36272/when-is-arctan-a-rational-multiple-of-pi\">When is ArcTan a rational multiple of pi?</a> for some information.</p></li>\n<li><p>If $x$ is none of the above, I don't think there exists a closed form solution since $\\sin(x)$ cannot be calculated in closed form and neither can $2-x-x^2$.</p></li>\n</ol>\n\n<p>Can someone prove this general idea?</p>\n\n<p>If it is solvable, then under what conditions?</p>\n\n\n\n<p>Attempting to reduce the amount of questions that ask for closed form solutions in these scenarios, like</p>\n\n<p><a href=\"https://math.stackexchange.com/questions/2081249/nonlinear-algebraic-equation-with-trigonometric-function\">Nonlinear algebraic equation with trigonometric function</a></p>\n\n<p><a href=\"https://math.stackexchange.com/questions/1939607/how-to-solve-x-sinx-b\">How to solve $x+\\sin(x)=b$</a></p>\n\n<p><a href=\"https://math.stackexchange.com/questions/2005604/solving-an-equation\">Solving an equation</a></p>\n\n<p>etc.</p>\n\n\n\n<p>To clarify, closed form in this context is a solution in terms of <a href=\"https://en.wikipedia.org/wiki/Mathematical_constant#Table_of_selected_mathematical_constants\" rel=\"noreferrer\">well-known constants</a> and a finite combination of <a href=\"https://en.wikipedia.org/wiki/List_of_mathematical_functions\" rel=\"noreferrer\">well-known functions</a>.</p>\n", "pids": ["5c757363f56def9798895169", "56d855bbdabfae2eee269a35"], "flag": 0}
{"question": "Prove that $\\int_0^1 \\frac{{\\rm{Li}}_2(x)\\ln(1-x)\\ln^2(x)}{x} \\,dx=-\\frac{\\zeta(6)}{3}$", "body": "<p>I have spent my holiday on Sunday to crack several integral &amp; series problems and I am having trouble to prove the following integral</p>\n\n<blockquote>\n  <p>\\begin{equation}\n\\int_0^1 \\frac{{\\rm{Li}}_2(x)\\ln(1-x)\\ln^2(x)}{x} \\,dx=-\\frac{\\zeta(6)}{3}\n\\end{equation}</p>\n</blockquote>\n\n<p>Using integration by parts, $u=\\ln^2(x)$ and $dv=\\displaystyle\\frac{{\\rm{Li}}_2(x)\\ln(1-x)}{x} \\,dx$, I manage to obtain that the integral is equivalent to\n\\begin{equation}\n\\int_0^1 \\frac{{\\rm{Li}}_2^2(x)\\ln(x)}{x} \\,dx\n\\end{equation}\nwhere ${\\rm{Li}}_2^2(x)={\\rm{Li}}_2(x)^2$, square of dilogarithm of $x$.</p>\n\n<p>Could anyone here please help me to prove the above integral preferably with elementary ways (<strong>high school methods/ not residue method</strong>)? Any help would be greatly appreciated. Thank you.</p>\n", "pids": ["53e9ae63b7602d970388087e", "53e9b350b7602d9703e2ace2"], "flag": 0}
{"question": "Why is skip-gram better for infrequent words than CBOW?", "body": "<p>I wonder why skip-gram is better for infrequent words than CBOW in word2vec. I have read the claim on <a href=\"https://code.google.com/p/word2vec/\">https://code.google.com/p/word2vec/</a>.</p>\n", "pids": ["58437722ac44360f1082f450"], "flag": 1}
{"question": "Why do we care about differential forms? (Confused over construction)", "body": "<p>So it's said that differential forms provide a coordinate free approach to multivariable calculus. Well, in short I just don't get this, despite reading from many sources. I shall explain how it all looks to me. </p>\n\n<p>Let's just stick to $\\mathbb{R}^2$ for the sake of simplicity (maybe this is the down fall..). Picking some point $P=(x,y)\\in\\mathbb{R}^2$, we could ask about the directional derivative of some function $f:\\mathbb{R}^2\\rightarrow \\mathbb{R}$, in direction $v=a\\vec{i}+b\\vec{j}$.  This will be $$(\\nabla \\cdot v)|_P(f)=a\\dfrac{\\partial f}{\\partial x}|_P+b\\dfrac{\\partial f}{\\partial y}|_P =\\underbrace{ (a\\dfrac{\\partial }{\\partial x}|_P+b\\dfrac{\\partial }{\\partial y}|_P)}_\\text{$w_P$ }(f)$$ Where we can think of $w_P$ as an element of the tangent space at $P$. Now this in itself is a little weird; why have differential operators as a basis for something geometrical like a tangent space to a manifold? In any case, we apply these vectors to a function defined on our manifold, and we get the value we wanted out. </p>\n\n<p>So who cares about differential forms? We just did all this without them. We could've done this by calculating $\\mathrm{d}f$, in some basis $\\mathrm{d}x, \\mathrm{d}y$ (which is quite confusing), and then calculating $\\mathrm{d}f(w_P)$, but what do we gain in doing it this way? </p>\n\n<p>I mentioned I think the $\\mathrm{d}x$'s are confusing. Well, $\\mathrm{d}x$ is just the function $\\mathrm{d}x(\\frac{\\partial}{\\partial x})=1$ and 0 for any other differential operator -  why write this as $\\mathrm{d}x$, which had always previously been used to mean an infinitesimal increase in x? </p>\n\n<p>Now I can understand caring about the dual of the tangent space. We are combining a vector in the tangent space with something and we're getting a scalar out of it - this something should then probably belong to the dual space. But if we're thinking of just the vector, then the function $f$ on the manifold needs to be encoded by the 1-form, right? Well, we can have 1-forms which aren't derivatives of any function on the manifold - what should it mean to combine such forms with tangent vectors?</p>\n\n<p>And lastly, if we're writing all our forms in terms of $\\mathrm{d}x$'s etc., where the $x$'s are exactly the coordinates of the manifold, then how exactly have we escaped dependence on coordinates? We're still essentially calculating with respect to a given coordinate system as in usual multivariable calculus!</p>\n", "pids": ["53e99fe9b7602d97028cb4ff"], "flag": 0}
{"question": "Do $3/8$ (37.5%) of Quadratics Have No $x$-Intercepts?", "body": "<p>I randomly had a thought about what proportion of quadratics don't have real <span class=\"math-container\">$x$</span>-intercepts. Initially I thought 33%, because 0,1,2 intercepts, then I thought that the proportion of 1 intercepts is infinitesimal. So I then thought 50%, as graphically half the quadratics would be above the <span class=\"math-container\">$x$</span>-axis, the other half below.</p>\n\n<p>If you put it into a list of (max,min) and (above,below):\nMinimum + Above = no <span class=\"math-container\">$x$</span>-intercepts</p>\n\n<p>Minimum + Below = 2 <span class=\"math-container\">$x$</span>-intercepts</p>\n\n<p>Maximum + Above = 2 <span class=\"math-container\">$x$</span>-intercepts</p>\n\n<p>Maximum + Below = no <span class=\"math-container\">$x$</span>-intercepts.</p>\n\n<p>Hence 50% right?</p>\n\n<p>Well I simulated it using code. I randomised a, b and c, and output the discriminant. If it is less than 0, add 1 to a variable. Do this about 100000 times. Now divide the variable by 100000. I get numbers like <span class=\"math-container\">$(37.5\\pm0.2)$</span>%.</p>\n\n<p>I hypothesise that it averages <span class=\"math-container\">$3/8$</span>.</p>\n\n<p>Why?</p>\n\n<p>There may be a fallacy to my approach of finding the 'proportion'. Fundamentally, it is the probability of getting a quadratic with no <span class=\"math-container\">$x$</span>-intercepts. However, I am not sure.</p>\n\n<p><strong>EDIT: The range was from <span class=\"math-container\">$(-n,n)$</span>, where <span class=\"math-container\">$n$</span> was 100000, or even higher.</strong></p>\n", "pids": ["53e9a749b7602d97030814a9"], "flag": 0}
{"question": "Is the fundamental group of every subset of $\\mathbb{R}^2$ torsion-free?", "body": "<p>It seems that the fundamental group of any subset of $\\mathbb{R}^2$ will not have an element of finite order.\nThough the $3$-dimensional version is an open problem I couldn't immediately see why it is true in the $2$-dimensional case.\nPlease shed some light on this.</p>\n", "pids": ["53e9a9a9b7602d9703307174"], "flag": 0}
{"question": "Using regularization when doing statistical inference", "body": "<p>I know about the benefits of regularization when building predictive models (bias vs. variance, preventing overfitting).  But, I'm wondering if it is a good idea to also do regularization (lasso, ridge, elastic net) when the main purpose of the regression model is inference on the coefficients (seeing which predictors are statistically significant).  I'd love to hear people's thoughts as well as links to any academic journals or non-academic articles addressing this.</p>\n", "pids": ["5c756eb3f56def97985f90a6"], "flag": 1}
{"question": "A Category Theoretical view of the Kalman Filter", "body": "<p><strong>Some basic background</strong></p>\n\n<p>The Kalman filter is a (linear) state estimation algorithm that presumes that there is some sort of uncertainty (optimally Gaussian) in the state observations of the dynamical system. The Kalman filter has been extended to nonlinear systems, constrained for cases where direct state observation is impossible, etc. As one should know, the algorithm essentially performs a prediction step based on prior state knowledge, compares that prediction to measurements, and updates the knowledge of the state based on a state covariance estimate that is also updated at every step.</p>\n\n<p>In short, we have a state-space vector usually represented by a vector in $\\mathbb{R}^n$. This vector is operated on by a plant matrix, added to a control term (which is operated on by a control matrix), operated on by a covariance matrix, etc. There are usually not intrinsic constraints on the state-space vector beyond those which may be embedded in the description of the dynamical system.</p>\n\n<p><strong>My question</strong></p>\n\n<p>Can we describe the Kalman filter using the language of category theory? In other words, can we generalize the algebra of what is happening with the Kalman filter for a dynamical system to develop Kalman-like estimators for other processes with vector-like components derived from some known (or partially known) model?</p>\n\n<p><strong>A motivating example</strong></p>\n\n<p>A repeated matrix game involves two or more players choosing strategies according to some payoff function -- which is a function of the game's state space and each player's action -- typically with some notion of equilibrium (e.g. Nash equilibrium). A repeated game with a finite action space implies that strategies are discrete probability distributions representable by a vector in $\\mathbb{R}^N$ such that every element of the strategy vector is non-negative and the vector sums to unity.</p>\n\n<p>This is a more restrictive case than a general dynamical system because we have constraints on the vector representation of the strategy. But, given input (i.e. actions taken), output (state measurement of the game's state space), and a payoff structure, it might make sense to attempt a Kalman-like estimator for the strategy vector in the game.</p>\n\n<p>The challenge, of course, is developing a compatible notion of covariance. It's not clear what covariance would mean in relation to probability distributions, since we don't treat the quantity $P(\\textrm{action} = \\textrm{index})$ as random variable. But if we had a category theoretical view of the Kalman filter, could we derive a similar structure based on its algebraic properties in such a way that we can guarantee that our estimate of the opponent's strategy vector converges in some way?</p>\n\n<p><strong>Does what I'm asking even make sense?</strong></p>\n", "pids": ["5b67b49517c44aac1c864d95", "53e9a2acb7602d9702bb0f1b", "56d856badabfae2eee2e2ff0", "53e9994cb7602d970218b0b3", "53e9a71fb7602d9703053c34", "56d86bb8dabfae2eeecc2405", "55503e7545ce0a409eb298e0"], "flag": 0}
{"question": "Is there a Stokes theorem for covariant derivatives?", "body": "<p>A $V$-valued differential $n$-form $\\omega$ on a manifold $M$ is a section of the bundle $\\Lambda^n (T^*M) \\otimes V$. (That is, the restriction $\\omega_p$ to any tangent space $T_p M$ for $p \\in M$ is a completely antisymmetric map $\\omega_p : T_p M \\times T_p M \\times \\cdots \\times T_p M \\to V$.) $V$ is a vector space here.</p>\n\n<p>One can define a flat covariant derivative $\\mathrm{d}\\colon \\Lambda^n (T^*M) \\to \\Lambda^{n+1} (T^*M)$ which is just the exterior derivative. It fulfills Stokes' theorem.</p>\n\n<p>Assume now an algebra structure on $V$, and a representation $\\rho$ of $V$ on a vector space $W$.\nFor a chosen $V$-valued differential 1-form $\\omega$, there is also a covariant derivative (like a principal connection) that acts on all $W$-valued differential forms $\\phi$ by the formula $\\mathrm{d}_\\omega \\phi := \\mathrm{d} \\phi + \\omega \\wedge_\\rho \\phi$. The product $\\wedge_\\rho$ is the composition of $\\wedge$, which multiplies a $V$-valued $n$-form and a $W$-valued $m$-form to a $V \\otimes W$-valued $(n+m)$-form, and $\\rho$.</p>\n\n<p>Is there a generalisation for Stokes' theorem for $\\mathrm{d}_\\omega$? Maybe something like $\\int_M \\mathrm{d}_\\omega \\phi = \\int_{\\partial M}  \\phi$ up to terms proportional to the curvature of $\\mathrm{d}_\\omega$?</p>\n", "pids": ["53e99ccab7602d970257cecf"], "flag": 0}
{"question": "One Sample, Different Methylation Values", "body": "<p>I'm hoping that somebody here can explain this unusual result that I'm getting with some pyrosequencing data. I have bisulphite converted a few samples a couple of times over the years for different projects. Recently I was collecting some of this disparate data together and I noticed that when the same pyrosequencing assay was used on these samples, those that were converted later had decreased methylation at the CpG sites of interest compared to the initial bisulphite converted samples. The original conversion was in 2010 and the repeat conversions were in 2014/2015. The assays are the same and it's difficult to blame this on PCR amplifying one clone over another since I've done technical replicates on each aliquot. Even the 2010 converted sample has the same result in 2015 that it did in 2010 but this is different from the 2015 converted sample. </p>\n\n<p>We are using the same kit (Qiagen) for bisulphite conversion and haven't made a major change to our procedure (we follow the Qiagen protocol without modification). Has anybody noticed this phenomenon before? Is it possible that stored DNA would experience methylation changes? It seems more likely that the issue is technical but I'm having trouble figuring out exactly what that technical issue is.</p>\n", "pids": ["55a65d3a65ce054aad65447c"], "flag": 1}
{"question": "State of art streaming learning", "body": "<p>I have been working with large data sets lately and found a lot of papers of streaming methods. To name a few:</p>\n\n<ul>\n<li>Follow-the-Regularized-Leader and Mirror Descent:\nEquivalence Theorems and L1 Regularization\n(<a href=\"http://jmlr.org/proceedings/papers/v15/mcmahan11b/mcmahan11b.pdf\" rel=\"noreferrer\">http://jmlr.org/proceedings/papers/v15/mcmahan11b/mcmahan11b.pdf</a>)</li>\n<li>Streamed Learning: One-Pass SVMs (<a href=\"http://www.umiacs.umd.edu/~hal/docs/daume09onepass.pdf\" rel=\"noreferrer\">http://www.umiacs.umd.edu/~hal/docs/daume09onepass.pdf</a>)</li>\n<li>Pegasos: Primal Estimated sub-GrAdient SOlver for SVM <a href=\"http://ttic.uchicago.edu/~nati/Publications/PegasosMPB.pdf\" rel=\"noreferrer\">http://ttic.uchicago.edu/~nati/Publications/PegasosMPB.pdf</a></li>\n<li>or here : <a href=\"https://stats.stackexchange.com/questions/26041/can-svm-do-stream-learning-one-example-at-a-time\">Can SVM do stream learning one example at a time?</a></li>\n<li>Streaming Random Forests (<a href=\"http://research.cs.queensu.ca/home/cords2/ideas07.pdf\" rel=\"noreferrer\">http://research.cs.queensu.ca/home/cords2/ideas07.pdf</a>)</li>\n</ul>\n\n<p>However, I have been unable to find any documentation regarding how they compare to each other. Every article I read seem to run experiments on different data set.</p>\n\n<p>I know about sofia-ml, vowpal wabbit, but they seem to implement very few methods, compared to the huge amount of existing methods! </p>\n\n<p>Are the less common algorithms not performant enough? Is there any paper trying to review as many methods as possible?</p>\n", "pids": ["5a9cb66717c44a376ffb8ca4", "53e99d6cb7602d9702629031", "599c7aad601a182cd26d40ad"], "flag": 1}
{"question": "Should dimensionality reduction for visualization be considered a &quot;closed&quot; problem, solved by t-SNE?", "body": "<p>I've been reading a lot about <a href=\"https://lvdmaaten.github.io/tsne/\" rel=\"noreferrer\">$t$-sne</a> algorithm for dimensionality reduction. I'm very impressed with the performance on \"classic\" datasets, like MNIST, where it achieves a clear separation of the digits (<a href=\"http://jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf\" rel=\"noreferrer\">see original article</a>):</p>\n\n<p><a href=\"https://i.stack.imgur.com/k8Pdp.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/k8Pdp.png\" alt=\"t-SNE MNIST\"></a></p>\n\n<p>I've also used it to visualize the features learnt by a neural network I'm training and I was very pleased with the results. </p>\n\n<p>So, as I understand it:</p>\n\n<p><strong>$t$-sne has good results on most datasets, and has a pretty efficient implementation - $O(n \\log n)$  with the Barnes-Hut approximation method. Then, could we potentially say that the \"dimensionality reduction\" problem, at least for the purpose of creating good 2D/3D visualizations, is now a \"closed\" problem?</strong></p>\n\n<p>I'm aware that this is a pretty bold statement. I'm interested in understanding what the potential \"pitfalls\" of this method are.  That is, are there any cases in which we know that it is <em>not</em> useful? Moreover, what are the \"open\" problems in this field?</p>\n", "pids": ["5ac1829d17c44a1fda917e2e", "573696036e3b12023e516e6e", "5a73cbcc17c44a0b3035f4b5"], "flag": 1}
{"question": "For which categories we can solve $\\text{Aut}(X) \\cong G$ for every group $G$?", "body": "<p>It is usually said that groups can (or should) be thought of as \"symmetries of things\". The reason is that the \"things\" which we study in mathematics usually form a category and for every object $X$ of a (locally small) category $\\mathcal{C}$, the set of automorphisms (symmetries) of $X$, denoted by $\\text{Aut}_{\\mathcal{C}}(X)$, forms a group.</p>\n\n<p>My question is: Which categories that occur naturally in mathematics admit all kinds of symmetries? More precisely, for which categories we can solve the equation (of course up to isomorphism) $$\\text{Aut}_{\\mathcal{C}}(X) = G$$ for every group $G$?</p>\n\n<p>I will write what I could find myself about this, which also hopefully illustrates what kind of answers that would interest me:</p>\n\n<p><li> Negative for $\\mathsf{Set}$: Infinite sets have infinite symmetry groups and for finite sets we get $S_n$'s. So if we let $G$ to be any finite group which is not isomorphic to some $S_n$, the equation has no solution.</p>\n\n<p><li>Negative for $\\mathsf{Grp}$: \n<a href=\"https://math.stackexchange.com/questions/40098/cyclic-automorphism-group\">No group can have its automorphism group a cyclic group of odd order.</a> </li></p>\n\n<p><li>Positive for $\\mathsf{Grph}$ (category of graphs): \n<a href=\"http://en.wikipedia.org/wiki/Frucht&#39;s_theorem\" rel=\"noreferrer\">Frucht's theorem</a> settles this for finite groups. Also according to the wikipedia page, the general situation was solved independently by de Groot and Sabidussi. </p>\n\n<p><li>An obvious necessary condition is that $\\mathcal{C}$ should be a large category.</li></p>\n\n<p><li> <a href=\"http://www.math.uiuc.edu/documenta/vol-06/16.pdf\" rel=\"noreferrer\">This paper</a> shows that the equation can be solved if $\\mathcal{C}$ is the category of Riemann surfaces with holomorphic mappings and $G$ is countable.</p>\n\n<p><li>If we take $\\mathcal{C}$ to be the category of fields with zero characteristic, I guess the equation relates to the inverse Galois problem. Edit: This may be much easier than the inverse Galois problem, as Martin Brandenburg commented.</li></p>\n", "pids": ["56d8a6b8dabfae2eee919a5a"], "flag": 0}
{"question": "Why is cisplatin a very potent antineoplastic for testicular cancer, but not necessarily for other cancers?", "body": "<p>Cisplatin (structure below) is a platinum-based chemotherapeutic agent which is very effective in the treatment of some cancers. Its introduction was responsible for improving the cure rate for testicular cancer from 10% to 85% according to the <a href=\"https://en.wikipedia.org/wiki/Cisplatin\" rel=\"nofollow noreferrer\">wikipedia page on cisplatin</a>.</p>\n\n<p>However, it is not very effective for other types of cancers; interestingly, ovarian cancer does not respond well to it <a href=\"http://www.nature.com/onc/journal/v22/n47/full/1206933a.html\" rel=\"nofollow noreferrer\">(Siddick, 2003)</a>.</p>\n\n<p>Does someone know why cisplatin is so specific to testicular cancer? I haven't found any sources explaining this. </p>\n\n<p><a src=\"https://i.stack.imgur.com/44CYx.png\" alt=\"Cisplatin chemical structure\"></p>\n", "pids": ["53e9a7d5b7602d9703114bb6"], "flag": 1}
{"question": "How are smell and taste in fish differentiated?", "body": "<p>The senses of <em>taste</em> and <em>smell</em> in different fish classes are described as two distinct senses; smell is mediated by the nasal openings, and taste by epithelial taste buds.</p>\n\n<p>They are both forms of chemoreception and therefore it is not clear to me what intrinsically defines them as two distinct senses. The more so because reception of chemical substances is mediated by water.</p>\n\n<p>What defines them as different senses? Is it only the difference of receptors that defines them as two distinct senses, or are there other reasons to differentiate them?</p>\n", "pids": ["55a4c5d765ceb7cb02d807a4"], "flag": 1}
{"question": "Why is it so important to have principled and mathematical theories for Machine Learning?", "body": "<p>I've been wondering, why is it so important to have principled/theoretical machine learning? From a personal perspective as a human, I can understand why principled Machine Learning would be important: </p>\n\n<ul>\n<li>humans like understanding what they are doing, we find beauty and satisfaction to understanding.</li>\n<li>from a theory point of view, mathematics is fun</li>\n<li>when there are principles that guide design of things, there is less time spent on random guessing, weird trial and error. If we understood, say, how neural nets really worked, maybe we could spend much better time designing them rather than the massive amounts of trial and error that goes into it right now.</li>\n<li>more recently, if the principles are clear and theory is clear too, then there should be (hopefully) more transparency to the system. This is good because if we understand what the system is working, then AI risks that lots of people hype about pretty much goes away immediately.</li>\n<li>principles seem to be a concise way to summarize the important structures the world might have and when to use a tool rather than another.</li>\n</ul>\n\n<p>However, are these reasons strong enough really to justify an intense theoretical study of machine learning? One of the biggest criticism of theory is that because its so hard to do, they usually end up studying some very restricted case or the assumptions that have to be brought essentially make the results useless. I think I heard this once at a talk at MIT by the creator of Tor. That some of the criticism of Tor he has heard is the theoretical argument but essentially, people are never able to prove things about the real scenarios of real life because they are so complicated. </p>\n\n<p>In this new era with so much computing power and data, we can test our models with real data sets and test sets. We can see if things work by using empiricism. If we can get instead achieve AGI or systems that work with engineering and empiricism, is it still worth pursuing principled and theoretical justification for machine learning, especially when the quantitate bounds are so difficult to achieve, but intuitions and qualitative answers are so much easier to achieve with a data driven approach? This approach was not available in classical statistics, which is why I think theory was so important in those times, because mathematics was the only way we could be sure things were correct or that they actually worked the way we thought they did.</p>\n\n<p>I've personally always loved and thought theory and a principled approach was important. But with the power of just being able to try things out with real data and computing power has made me wonder if the high effort (and potentially low rewards) of theoretical pursue is still worth it. </p>\n\n<p>Is theoretical and principled pursue of machine learning really that important?</p>\n", "pids": ["57a4e91aac44365e35c9798f", "53e9a93eb7602d97032928b5"], "flag": 1}
{"question": "Does G&#246;del&#39;s Incompleteness Theorem really say anything about the limitations of theoretical physics?", "body": "<p>Stephen Hawking believes that Gödel's Incompleteness Theorem makes the search for a 'Theory of Everything' impossible. He reasons that because there exist mathematical results that cannot be proven, there exist physical results that cannot be proven as well. Exactly how valid is his reasoning? How can he apply a mathematical theorem to an empirical science?</p>\n", "pids": ["53e99b36b7602d97023d2f23"], "flag": 0}
{"question": "Mating types in fungi (and somatogamy)", "body": "<p>I would have some related questions about the mating types of fungi.</p>\n\n<ol>\n<li><p>Does a single spore generate a mycelium possessing only one mating type? If it does not in general, do Ascomycota and Basidiomycota possess only one mating type per individual mycelium?</p></li>\n<li><p>Are homothallism and heterothallism properties of the individual mycelium or of the species? The definitions that I find in my book and on line confuse me. I understand that <em>homothallism</em> is the property of a mycelium (possessing only one mating type or can it possess many mating types in a similar way to hermaphrodite animals? cfr. question 1) that can mate with itself (if it can possess many mating types and it can mate with itself only by using gametes of different mating types, is it still homothallic?) and <em>heterothallism</em> is the property of a mycelium that is not homothallic, but I am not sure I understand, because I read of <em>homothallic</em> and <em>heterothallic species</em> too: is a homothallic species a species where at least some individual is homothallic, where all individuals are homothallic or something else?</p></li>\n<li><p>I am sure that mating type is a property characterising at least gametes, but is it a property of indiviual cells too? As an example, I know that it is necessary, among many species of fungi, for two gametes to belong to two different mating types in order to produce a zygote. Some fungi, as it is the rule among Basidiomycota, reproduce by somatogamy, i.e. the nuclei generating the zygote are from somatic cells, other than gametes. In such cases, are there species where it is necessary for the somatic cells of a homothallic mycelium to belong to a different type than the type with which they are undergoing plasmogamy? Thank you very much for any answer!</p></li>\n</ol>\n", "pids": ["53e99a5cb7602d97022c5565"], "flag": 1}
{"question": "What are some interesting and well-written applied statistics papers?", "body": "<p>What are some good papers describing <em>applications</em> of statistics that would be fun and informative to read? Just to be clear, I'm not really looking for papers describing new statistical methods (e.g., a paper on least angle regression), but rather papers describing how to solve real-world problems.</p>\n\n<p>For example, one paper that would fit what I'm looking is the climate paper from the <a href=\"https://stats.meta.stackexchange.com/questions/685/second-cross-validated-journal-club\">second Cross-Validated Journal Club</a>. I'm kind of looking for more statistics-ish papers, rather than machine learning papers, but I guess it's kind of a fuzzy distinction (I'd classify the Netflix Prize papers as a bit borderline, and a paper on sentiment analysis as something I'm <em>not</em> looking for).</p>\n\n<p>I'm asking because most of the applications of statistics I've seen are either the little snippets you seen in textbooks, or things related to my own work, so I'd like to branch out a bit.</p>\n", "pids": ["53e99d51b7602d9702607bf5", "53e9b90bb7602d97044f2040"], "flag": 1}
{"question": "Family of definite integrals involving Dedekind eta function of a complex argument, $\\int_0^{\\infty} \\eta^k(ix)dx$", "body": "<p>The Dedekind eta function is denoted by $\\eta(\\tau)$, and is defined on the upper half-plane ($\\Im \\tau &gt;0$). Put $\\tau = i x$ where $x$ is \na positive real number. The function has the following representations: \n$$\\eta(ix)= e^{-\\pi x/12} \\prod_{n=1}^{\\infty} (1-e^{-2\\pi x n})\n\\\\=\\frac{2}{\\sqrt{3}}\\sum_{n=0}^{\\infty} \\cos\\left(\\frac{\\pi}{6}(2n+1)\\right)e^{-\\pi x/12 \\, (2n+1)^2}=\\sum_{n \\in \\mathbb{Z}} (-1)^n e^{-\\pi x/12 \\,(6n+1)^2}.\\tag{1}$$\nIt is not difficult to observe that when $x&gt;0$, $\\eta(i x)$ is a real number, and goes to $0$ when $x$ goes to infinity.</p>\n\n<p>It also satisfies the functional equation $$\\eta\\left(\\frac{i}{x}\\right)=\\sqrt{x}\\,\\eta(i x)\\tag{2}$$\nMoreover, the Jacobi triple product identity implies that \n$$\\eta^3(ix)=\\sum_{n=0}^{\\infty} (-1)^n (2n+1) e^{-\\pi x(n+\\frac12)^2}\\\\=\\frac12\\vartheta_1'(e^{-\\pi x})=\\frac12 \\vartheta_2(e^{-\\pi x})\\vartheta_3(e^{-\\pi x})\\vartheta_4(e^{-\\pi x})\\tag{3}$$\nWhere $\\vartheta_k$ are the Jacobi theta functions.</p>\n\n<p>Now define\n$$\\large I(k)=\\int_0^{\\infty} \\eta^k(ix)dx.\\tag{4}$$\nIn his paper <em>Some Integrals of the Dedekind Eta-function</em> (2008) (<a href=\"http://arxiv.org/abs/0812.1992\" rel=\"noreferrer\">arxiv link</a>), Glasser shows\nthat $\\displaystyle I(1)=\\frac{2 \\pi}{\\sqrt{3}},I(3)=1$ (these follow directly from the above series represantations), and also gives the Laplace transform $$\\int_0^{\\infty} e^{-x y} \\eta^3(i x)dx=\\operatorname{sech}\\sqrt{\\pi y}\\tag{5}$$\nfrom which I can deduce (by setting $y=\\pi(n+1/2)^2$, multiplying by $(-1)^n(2n+1)$ and summing) that \n$$I(6)=\\int_0^{\\infty} \\eta^6(ix)dx=\\sum_{n=0}^{\\infty} \\frac{(-1)^n (2n+1)}{\\cosh\\left(\\pi (n+\\frac12)\\right)}\n\\\\=\\frac12 \\vartheta_2^2(e^{-\\pi})\\vartheta_4^2(e^{-\\pi})=\\frac{\\pi}{4 \\Gamma\\left(\\frac34\\right)^4}.\\tag{6}$$\nBy the way, note that the closed form for $I(1)$ is <a href=\"https://math.stackexchange.com/questions/1541601/closed-form-of-the-integral-large-int-0-infty-e-x-prod-n-1-infty-left\">this question</a>  of @VladimirReshetnikov in disguise.</p>\n\n<p>A numerical computation suggests that we also have<br>\n$$I(4)\\stackrel?=\\frac{2^{2/3} \\pi}{3 \\Gamma\\left(\\frac23\\right)^3}.\\tag{7}$$</p>\n\n<p>$$I(8)\\stackrel?=\\frac23 \\left(\\frac{2^{2/3} \\pi}{3 \\Gamma\\left(\\frac23\\right)^3}\\right)^3.\\tag{8}$$</p>\n\n<p>Using the same procedure I did to evaluate $I(6)$ on another Laplace transform given by Glasser, \n$$\\int_0^{\\infty} e^{-x y} \\eta(i x)dx=\\sqrt{\\frac{\\pi}{y}} \\frac{\\sinh 2\\sqrt{\\pi y/3}}{\\cosh\\sqrt{3 \\pi y}},\\tag{9}$$\nI obtain $$I(4)=\\int_0^{\\infty} \\eta^4(ix)dx=2 \\sum_{n=0}^{\\infty} (-1)^n \\frac{\\sinh\\frac{\\pi}{\\sqrt{3}}(2n+1)}{\\cosh\\frac{\\sqrt{3}\\pi}{2}(2n+1)}\\tag{10}$$\nbut I could not evaluate this sum in terms of elliptic functions as I did with $I(6)$. The formula for $I(8)$ is even more intriguing, as I cannot even see a reasonable route to <em>start</em> proving it.</p>\n\n<blockquote>\n  <p><strong>Q1:</strong> Can we find a closed form expression for $I(n)$, at least for small integer $n$? </p>\n  \n  <p><strong>Q2:</strong> What is the closed form of $I(12)$?\n  Note that we have $$I(12)=\\int_0^{\\infty} \\eta^{12}(ix)dx=\\frac1{16} \\int_0^{\\infty}\\vartheta_2^4(e^{-\\pi x})\\vartheta_3^4(e^{-\\pi x})\\vartheta_4^4(e^{-\\pi x})dx=0.07552061383997469\\dots$$\n  Based on the other results so far, I believe the closed form may involve the Gamma function.</p>\n  \n  <p><strong>Bonus Q:</strong> What would be a way to prove the conjectural closed form for $I(4)$ or $I(8)$? </p>\n</blockquote>\n\n<p>This is interesting to me because <a href=\"https://math.stackexchange.com/questions/1760270/closed-form-of-an-integral-involving-a-jacobi-theta-function-int-0-infty\">as can be seen in this post,</a> a closed form for $I(12)$ may be used to find the closed form\nof the integral $\\int_0^{\\infty} \\vartheta_4^{12}(e^{-\\pi x})/(1+x^2) dx$.</p>\n\n<p>Another interesting aplication of these integrals is giving closed forms for beautiful <a href=\"http://mathworld.wolfram.com/LatticeSum.html\" rel=\"noreferrer\">lattice sums</a>. </p>\n\n<p>For instance, by expanding $\\eta$ into its series representation, equation $(7)$ can be rewritten\n$$\\sum_{(a,b,c,d)\\in \\mathbb{Z}^4} \\dfrac{(-1)^{a+b+c+d}}{(6a+1)^2+(6b+1)^2+(6c+1)^2+(6d+1)^2} = \\frac{\\pi^2}{18 \\sqrt[3]{2}\\,\\Gamma\\left(\\frac23\\right)^3},\\tag{11}$$\nwhich I deem visually pleasing. Similarly, equation $(6)$ can be rewritten \n$$\\sum_{(a,b,c)\\in \\mathbb{Z}^3} (-1)^{a+b+c} \\operatorname{sech}\\left(\\frac{\\pi}{2\\sqrt{3}} \\sqrt{(6a+1)^2+(6b+1)^2+(6c+1)^2}\\right) = \\frac{\\pi}{4 \\Gamma\\left(\\frac34\\right)^4}.\\tag{12}$$</p>\n\n<p><strong>UPDATE.</strong> </p>\n\n<p><strong>Paramanand Singh</strong> was able to prove the closed form for $I(4)$.</p>\n\n<p>Using the substitution suggested by him, we obtain new representations for $I(8)$ and $I(12)$: \n$$I(8) = \\frac{2^{1/3}}{\\pi^3} \\int_0^1 x^{1/3}\\,(1-x^2)^{-1/3}\\,K(x)^2 \\,dx \\stackrel?= \\frac23 \\left(\\frac{2^{2/3} \\pi}{3 \\Gamma\\left(\\frac23\\right)^3}\\right)^3 \\tag{13}$$\n$$I(12) = \\frac{2}{\\pi^5} \\int_0^1 x\\,K(x)^4\\,dx = \\quad ? \\tag{14}$$\nHere $K$ is the complete elliptic integral of the first kind.</p>\n\n<p>Furthermore, in view of the definitions of <a href=\"http://mathworld.wolfram.com/TauFunction.html\" rel=\"noreferrer\">Ramanujan's tau function</a> and the <a href=\"http://mathworld.wolfram.com/TauDirichletSeries.html\" rel=\"noreferrer\">Tau Dirichlet series</a>, it follows that \n$$I(24) = \\int_0^{\\infty} x^{10} \\eta^{24}(i x) dx = \\frac{10!}{(2\\pi)^{11}} \\sum_{n=1}^{\\infty} \\frac{\\tau(n)}{n^{11}}. \\tag{15}$$\nI am not sure about that one.</p>\n\n<p><strong>ONE MORE UPDATE</strong></p>\n\n<p>With some educated guesses and Mathematica's 'RootApproximant', I have finally found a possible closed form for $I(2)$ !!!\n$$I(2)=\\int_0^{\\infty}  \\eta^2(i x) dx \\stackrel?= \\log\\left(1+ \\sqrt{3}+\\sqrt{3+2 \\sqrt{3}}\\right) \\tag{16}$$\nThis one holds for at least 100 digits. This is surprising to me, as it's quite different from the other ones so far. This also gives me hope that a closed form for $I(5),I(7)$ etc. exists.</p>\n", "pids": ["5c41ea1fdf5b8c0b3cd40256"], "flag": 0}
{"question": "Is austerity in the UK responsible for &quot;120,000&quot; extra deaths?", "body": "<p>The UK government has been implementing tight constraints on public spending to attempt to recover from the 2008 financial crash and bailout. But this austerity is controversial.</p>\n<p>A <a href=\"http://www.independent.co.uk/news/health/tory-austerity-deaths-study-report-people-die-social-care-government-policy-a8057306.html\" rel=\"noreferrer\">recent report in The Independent</a> claims the following (I've bolded the key elements of the claim):</p>\n<blockquote>\n<p>The Conservatives have been accused of “economic murder” for austerity policies which <strong>a new study suggests have caused 120,000 deaths.</strong></p>\n<p>The paper found that there were 45,000 more deaths in the first four years of Tory-led efficiencies than would have been expected if funding had stayed at pre-election levels.</p>\n</blockquote>\n<p>The claim continues:</p>\n<blockquote>\n<p>&quot;We have found that spending constraints since 2010, especially public expenditure on social care, may have produced a substantial mortality gap in England.”</p>\n<p>The papers’ senior author and a researcher at UCL, Dr Ben Maruthappu, said that while the paper “can’t prove cause and effect” it shows an association.</p>\n<p>And he added this trend is seen elsewhere. “When you look at Portugal and other countries that have gone through austerity measures, they have found that <strong>health care provision gets worse and health care outcomes get worse</strong>...”</p>\n</blockquote>\n<p>So it isn't just a claim about the situation in the UK.</p>\n<p>Can we confidently claim that austerity has caused 120,000 deaths in the UK and can also be shown to harm mortality in other countries?</p>\n", "pids": ["56d90b3bdabfae2eee186600"], "flag": 1}
{"question": "Is a woman more likely than a man to be seriously injured in a car crash of similar severity?", "body": "<p><a href=\"https://www.theguardian.com/lifeandstyle/2019/feb/23/truth-world-built-for-men-car-crashes\" rel=\"noreferrer\">This article</a> makes a number of interesting points about the potential dangers faced by women in a world &quot;designed for men&quot;, but I want to ask specifically about this claim:</p>\n<blockquote>\n<p>But when a woman is involved in a car crash, she is 47% more likely to\nbe seriously injured, and 71% more likely to be moderately injured,\neven when researchers control for factors such as height, weight,\nseatbelt usage, and crash intensity. She is also 17% more likely to\ndie. And it’s all to do with how the car is designed – and for whom.</p>\n</blockquote>\n<p>The links in this paragraph are either dead or go to similar articles with dead links.</p>\n<p>Is the statistic credible and does it mean that car design is to blame?</p>\n", "pids": ["61b1ddd95244ab9dcb858268"], "flag": 1}
{"question": "How true is this slide on deep learning claiming that all improvements from 1980s are only due to much more data and much faster computers?", "body": "<p>I was listening to a talk and saw this slide:</p>\n\n<p><a src=\"https://i.stack.imgur.com/qg54F.jpg\" alt=\"enter image description here\"></p>\n\n<p>How true is it?</p>\n", "pids": ["53e9986eb7602d97020a7ef9"], "flag": 1}
{"question": "is the group of rational numbers the fundamental group of some space?", "body": "<p>Which path connected space has fundamental group isomorphic to the group of rationals? More generally, is every group the fundamental group of a space?</p>\n", "pids": ["53e99ff0b7602d97028cfee5"], "flag": 0}
{"question": "KKT versus unconstrained formulation of lasso regression", "body": "<p>L1 penalized regression (aka lasso) is presented in two formulations.  Let the two objective functions be\n$$\nQ_1 = \\frac{1}{2}||Y - X\\beta||_2^2 \\\\\nQ_2 =\\frac{1}{2}||Y - X\\beta||_2^2 + \\lambda ||\\beta||_1.\n$$\nThen the two different formulations are \n$$\n\\text{argmin}_\\beta \\; Q_1\n$$\nsubject to\n$$\n||\\beta||_1 \\leq t,\n$$\nand, equivalently\n$$\n\\text{argmin}_\\beta \\; Q_2.\n$$\nUsing the Karush-Kuhn-Tucker (KKT) conditions, it's easy to see how the stationarity condition for the first formulation is equivalent to taking the gradient of the second formulation and setting it equal to 0.  What I can not find, nor figure out, is how the complementary slackness condition for the first formulation, $\\lambda\\left(||\\beta||_1 - t\\right) = 0$, is guaranteed to be fulfilled by the solution to the second formulation.</p>\n", "pids": ["5d9edc4947c8f7664603acd0"], "flag": 1}
{"question": "Name of this famous question?", "body": "<p>I think that this question is well known but I cannot remember its name, and now I am interested in it and wanted to look it up, but cannot find anything just based on a description. If anyone knows the name or can find it (or anything similar), that would be very helpful. The question is as follows:</p>\n\n<blockquote>\n  <p>You have a rigid rod of unit length, and some curve in 3d space, which\n  is linear for all but a finite portion of its length. We say the rod\n  is \"on the curve\" if each of its endpoints are on the curve. Call the\n  \"ends of the curve\" the 2 linear portions that are infinite. Prove or\n  disprove that for all possible such curves, we can move the rod from\n  one end of the curve to the other while staying on the curve the whole\n  time.</p>\n</blockquote>\n", "pids": ["53e9adbdb7602d97037bfa9a"], "flag": 0}
{"question": "Integral $\\int_0^1\\frac{\\log(1-x)}{\\sqrt{x-x^3}}dx$", "body": "<p>I have a trouble with this integral\n$$I=\\int_0^1\\frac{\\log(1-x)}{\\sqrt{x-x^3}}dx.$$\nCould you suggest how to evaluate it?</p>\n", "pids": ["53e9a122b7602d9702a1195d"], "flag": 0}
{"question": "Applications of Pseudodifferential Operators", "body": "<p>I am very interested in just about anything that has to do with PDE's, and inevitably pseudodifferential operators comes up. Its obvious that such a novel way of looking at PDE's would be important, but I cant find anything in the literature thus far that explains where they could be applied, in a mathematical physics sense.</p>\n\n<p>So basically, I'm wondering if there are any physical, or numerical analysis type applications of pseudodifferential operators.</p>\n", "pids": ["53e9b137b7602d9703bb76d9"], "flag": 0}
{"question": "In machine learning, why are superscripts used instead of subscripts?", "body": "<p>I'm taking <a href=\"https://www.coursera.org/learn/machine-learning\">Andrew Ng's course on Machine Learning through Coursera</a>. For equations, superscripts are used instead of subscripts. For example, in the following equation $x^{(i)}$ is used instead of $x_i$:</p>\n\n<p>$J(\\theta_0, \\theta_1) = \\frac{1}{2m} \\sum\\limits_{i=1}^{m}{(h_\\theta(x^{(i)}) - y^{(i)})^2}$</p>\n\n<p>Apparently, this is common practice. My question is why use superscripts instead of subscripts? Superscripts are already used for exponentiation. Granted I seem to be able to disambiguate between the superscript and exponentiation use cases by paying attention to whether or not parentheses are present, but it still seems confusing.</p>\n", "pids": ["573696006e3b12023e514077"], "flag": 1}
{"question": "In neural nets, why use gradient methods rather than other metaheuristics?", "body": "<p>In training deep and shallow neural networks, why are gradient methods (e.g. gradient descent, Nesterov, Newton-Raphson) commonly used, as opposed to other metaheuristics?</p>\n\n<p>By metaheuristics I mean methods such as simulated annealing, ant colony optimization, etc., which were developed to avoid getting stuck in a local minima.</p>\n", "pids": ["5550413145ce0a409eb392b5"], "flag": 1}
{"question": "Such thing as a weighted correlation?", "body": "<p>I have some interesting data on the most popular musical artists streamed divided by location into about 200 congressional districts. I want to see if it's possible to poll a person on his or her musical preferences and determine whether he or she \"listens like a Democrat\" or \"listens like a Republican.\" (Naturally this is light hearted, but there's real entropy in the data!)</p>\n\n<p>I have data on about 100 artists, plus the average percentage votes for Republicans and Democrats in each district over the past three election cycles. So I ran a correlation on each artist to see which ones were most disproportionately listened-to as a function of vote share for Democrats. Those correlations run from about -0.3 to 0.3 for any given artist, with plenty in the middle that have little or no predictive power. </p>\n\n<p>I have two questions: First, the overall number of streams per district varies widely. Right now, I'm correlating percentage of all streams per district belonging to, say, Beyonce, against the percentage of votes cast for Democrats. But total streams in one district might be in the millions, while another is in the low 100,000s. Do I need to weight the correlation somehow to account for this?</p>\n\n<p>Second, I'm curious how to combine these correlations into a composite guess as to the user's politics. Let's say I take the 20 artists with the highest absolute correlative values (positive and negative), ten in each direction, and poll a user on how much he or she likes each artist. So I have up or down votes on each artist plus the correlation to the politics for all 20 values. Is there a standard way to combine these correlations into a single estimate? (I'm thinking something like the NYTimes' famous <a href=\"http://www.nytimes.com/interactive/2013/12/20/sunday-review/dialect-quiz-map.html?_r=0\" rel=\"noreferrer\">dialect quiz</a>, where it combined the regional probabilities for 25 questions into a heat map. But in this case, I just need a single value on how Democratic or Republican one's taste in music is.</p>\n\n<p>Thank you!</p>\n", "pids": ["6229edf95aee126c0f2cfa7e"], "flag": 1}
{"question": "How to integrate $ \\int \\frac{x}{\\sqrt{x^4+10x^2-96x-71}}dx$?", "body": "<p>I read about <span class=\"math-container\">$ \\int \\dfrac{x}{\\sqrt{x^4+10x^2-96x-71}}dx$</span> <a href=\"https://en.wikipedia.org/wiki/Risch_algorithm#Problem_examples\" rel=\"nofollow noreferrer\">on the Wikipedia Risch algorithm page</a>. They gave an answer but I don't understand how they got it.</p>\n", "pids": ["5c75718af56def9798786f33"], "flag": 0}
{"question": "Stouffer&#39;s Z-score method: what if we sum $z^2$ instead of $z$?", "body": "<p>I am performing $N$ independent statistical tests with the same null hypothesis, and would like to combine the results into one $p$-value. It seems that there are two \"accepted\" methods: <a href=\"https://en.wikipedia.org/wiki/Fishers_method\">Fisher's method and Stouffer's method</a>.</p>\n\n<p>My question is about Stouffer's method. For each separate test I obtain a z-score $z_i$. Under a null hypothesis, each of them is distributed with a standard normal distribution, so the sum $\\Sigma z_i$ follows a normal distribution with variance $N$. Therefore Stouffer's method suggests to compute $\\Sigma z_i / \\sqrt{N}$, which should be normally distributed with unit variance, and then use this as a joint z-score.</p>\n\n<p>This is reasonable, but here is another approach that I came up with and that also sounds reasonable to me. As each of $z_i$ comes from a standard normal distribution, the sum of squares $S=\\Sigma z^2_i$ should come from a chi-squared distribution with $N$ degrees of freedom. So one can compute $S$ and convert it to a $p$-value using cumulative chi-squared distribution function with $N$ degrees of freedom ($p=1−X_N(S)$, where $X_N$ is the CDF).</p>\n\n<p>However, nowhere can I find this approach even mentioned. Is it ever used? Does it have a name? What would be advantages/disadvantages compared to Stouffer's method? Or is there a flaw in my reasoning?</p>\n", "pids": ["5c1360c4da56295a08971ba6", "53e9b90bb7602d97044f3ac5"], "flag": 1}
{"question": "Why does the boundary of the Mandelbrot set contain a cardioid?", "body": "<p>In a <a href=\"https://math.stackexchange.com/questions/1340973/can-a-fractal-be-a-manifold-if-so-will-its-boundary-if-exists-be-strictly-on#comment2726214_1340978\">comment</a> to a previous answer it has been mentioned that the boundary of the Mandelbrot set contains the cardioid\n$$\nc = e^{it} \\, \\frac{2 - e^{it}}{4}\n$$\nbut how can we prove this?</p>\n", "pids": ["53e9ac33b7602d97035f998b"], "flag": 0}
{"question": "Probability and measure theory", "body": "<p>I'd like to have a correct general understanding of the importance of measure theory in probability theory. For now, it seems like mathematicians work with the notion of probability measure and prove theorems, because it automacially makes the theorem true, no matter if we work with discrete and continuous probability distribution.</p>\n\n<p>So for example, expected value - we can prove the Law of large numbers using its general definition (measure theoretic) $\\operatorname{E} [X]  = \\int_\\Omega X \\, \\mathrm{d}P$, and then derive the formula for discrete and continuous cases (discrete and continuous random variables), without having to prove it separately for each case (we have one proof instead of two). One could say that the Law of large numbers justifies the definition of expected value, by the way.</p>\n\n<p>Is it right to say that probability using the general notion of probability measure saves work of mathematicians? What are the other advantages?</p>\n\n<p>Please correct me if I'm wrong, but I hope you get the idea of what sort of information I expect - it's the importance and role of measure theory in probability and answer to the question: <strong>are there theorems in probability that do not hold for general probability measure, but are true only for either discrete or continuous probability distribution?</strong> If we can prove that no such theorems can exist, we can simply forget about the distinction between discrete and continuous distributions.</p>\n\n<p>If someone could come up with a clear, concise summary, I'd be grateful. I'm not an expert, so please take that into account.</p>\n", "pids": ["53e9a45cb7602d9702d7b15e"], "flag": 0}
{"question": "Unusual pattern in the distribution of primes of form $4n\\pm1, 6n\\pm 1$ [Chebyshev&#39;s bias]", "body": "<p>I have recently noticed an unusual pattern in the distribution of odd primes.</p>\n\n<p>Each one of the following sets contains approximately half of all odd primes:</p>\n\n<ul>\n<li>$A_n=\\{4k+1: 0\\leq k\\leq n\\}=\\{1,5,9,13,\\dots,4n+1\\}$</li>\n<li>$B_n=\\{4k+3: 0\\leq k\\leq n\\}=\\{3,7,11,15,\\dots,4n+3\\}$</li>\n<li>$C_n=\\{6k+1: 0\\leq k\\leq n\\}=\\{1,7,13,19,\\dots,6n+1\\}$</li>\n<li>$D_n=\\{6k+5: 0\\leq k\\leq n\\}=\\{5,11,17,23,\\dots,6n+5\\}$</li>\n</ul>\n\n<p>More precisely:</p>\n\n<ul>\n<li>Let $P(S)$ denote the number of odd primes in the set $S$</li>\n<li>Let $\\pi(x)$ denote the number of odd primes smaller than $x$</li>\n</ul>\n\n<p>Then for every sufficiently large value of $n$:</p>\n\n<ul>\n<li>${P(A_n)}\\approx{P(B_n)}\\approx\\frac12\\pi(4n+4)$</li>\n<li>${P(C_n)}\\approx{P(D_n)}\\approx\\frac12\\pi(6n+6)$</li>\n</ul>\n\n<p>Now, all of this is pretty easy to observe (though probably not so easy to prove).</p>\n\n<p>The following facts are subsequently obvious for every sufficiently large $n$ as well:</p>\n\n<ul>\n<li>${P(A_n)}\\leq{P(B_n)}\\implies{P(A_n)}\\leq\\frac12\\pi(4n+4)\\leq{P(B_n)}$</li>\n<li>${P(A_n)}\\geq{P(B_n)}\\implies{P(A_n)}\\geq\\frac12\\pi(4n+4)\\geq{P(B_n)}$</li>\n<li>${P(C_n)}\\leq{P(D_n)}\\implies{P(C_n)}\\leq\\frac12\\pi(6n+6)\\leq{P(D_n)}$</li>\n<li>${P(C_n)}\\geq{P(D_n)}\\implies{P(C_n)}\\geq\\frac12\\pi(6n+6)\\geq{P(D_n)}$</li>\n</ul>\n\n<p>This is because $A_n$ and $B_n$ as well as $C_n$ and $D_n$ are \"complementary\" to each other:</p>\n\n<ul>\n<li>The set ${A_n}\\cap{B_n}$ is empty, and the set ${A_n}\\cup{B_n}$ contains all odd primes smaller than $4n+4$</li>\n<li>The set ${C_n}\\cap{D_n}$ is empty, and the set ${C_n}\\cup{D_n}$ contains all odd primes smaller than $6n+6$</li>\n</ul>\n\n\n\n<p>Nevertheless, for almost every value of $n$:</p>\n\n<ul>\n<li>${P(A_n)}\\leq{P(B_n)}$</li>\n<li>${P(C_n)}\\leq{P(D_n)}$</li>\n</ul>\n\n<p>The graphs and table below provide some empirical evidence:</p>\n\n<p><a src=\"https://i.stack.imgur.com/89wFi.png\" alt=\"enter image description here\">\n<a src=\"https://i.stack.imgur.com/G62UJ.png\" alt=\"enter image description here\">\n<a src=\"https://i.stack.imgur.com/6gmuT.png\" alt=\"enter image description here\"></p>\n\n<pre><code> range     | odd primes | cases where either P(A)&gt;P(B) or P(C)&gt;P(D)\n-----------|------------|-------------------------------------------\n 10000     | 1228       | 0\n 100000    | 9591       | 1\n 1000000   | 78497      | 239\n 10000000  | 664578     | 239\n 100000000 | 5761454    | 1940\n</code></pre>\n\n\n\n<p>I would expect primes to be equally distributed between $A_n$ and $B_n$ and between $C_n$ and $D_n$.</p>\n\n<p>In other words, I would expect:</p>\n\n<ul>\n<li>[Number of primes of the form $4k+1$] $\\approx$ [Number of primes of the form $4k+3$]</li>\n<li>[Number of primes of the form $6k+1$] $\\approx$ [Number of primes of the form $6k+5$]</li>\n</ul>\n\n<p>But since the empirical evidence above suggests otherwise, my questions are:</p>\n\n<ol>\n<li>Is this indeed the case, or do they become equally distributed on a larger range?</li>\n<li>If this is indeed the case, what research has been conducted attempting to explain it?</li>\n</ol>\n\n<p>Thanks</p>\n", "pids": ["628d15ba5aee126c0f305964"], "flag": 0}
{"question": "A closed form for $\\int_{0}^{\\pi/2} x^3 \\ln^3(2 \\cos x)\\:\\mathrm{d}x$", "body": "<p>We already know that </p>\n\n<blockquote>\n  <p>\\begin{align} \n\\displaystyle &amp; \\int_{0}^{\\pi/2} x \\ln(2 \\cos x)\\:\\mathrm{d}x  = -\\frac{7}{16} \\zeta(3), \n\\\\\\\\ &amp;  \\int_{0}^{\\pi/2} x^2 \\ln^2(2 \\cos x)\\:\\mathrm{d}x  = \\frac{11 \\pi}{16} \\zeta(4).  \\end{align} </p>\n</blockquote>\n\n<p>Does the following integral admit a closed form?</p>\n\n<blockquote>\n  <p>\\begin{align} \\displaystyle &amp;  \\int_{0}^{\\pi/2} x^3 \\ln^3(2 \\cos x)\\:\\mathrm{d}x  \\end{align} </p>\n</blockquote>\n", "pids": ["53e9a208b7602d9702b0aba9", "5c61066eda56297340abd2d3"], "flag": 0}
{"question": "Does iterating $n \\to 2n+1$ always eventually produce a prime number?", "body": "<p>Is it the case that for every non-negative integer $n$, iterating $n \\to 2n+1$ eventually produces a prime number? (This is the same as asking whether for every positive integer $n$, there is a non-negative integer $k$ such that $2^k n  - 1$ is prime.) If this is not settled by proof, is there some heuristic argument either way?</p>\n", "pids": ["5f0e91539fced0a24b14ab96"], "flag": 0}
{"question": "What are the best books to study Neural Networks from a purely mathematical perspective?", "body": "<p>I am looking for a book that goes through the mathematical aspects of neural networks, from simple forward passage of multilayer perceptron in matrix form or differentiation of activation functions, to back propagation in CNN or RNN (to mention some of the topics).</p>\n\n<p>Do you know any book that goes in depth into this theory? I've had a look at a couple (such as Pattern Recognition and Machine Learning by Bishop) but still have not found a rigorous one (with exercises would be a plus). Do you have any suggestions? </p>\n", "pids": ["5a4aef9e17c44a2190f7a3ae"], "flag": 0}
{"question": "Opinions about Oversampling in general, and the SMOTE algorithm in particular", "body": "<p>What is your opinion about oversampling in classification in general, and the SMOTE algorithm in particular? Why would we not just apply a cost/penalty to adjust for imbalance in class data and any unbalanced cost of errors? For my purposes, accuracy of prediction to a future set of experimental units is the ultimate measure.</p>\n\n<p>For reference, the SMOTE paper: <a href=\"http://www.jair.org/papers/paper953.html\" rel=\"noreferrer\">http://www.jair.org/papers/paper953.html</a></p>\n", "pids": ["6124dd7091e0114cbe7a8c1c"], "flag": 1}
{"question": "Origins of the modern definition of topology", "body": "<p>The modern definition of topology is 'a family of subsets of a set $X$ containing the empty set and $X$, closed under unions and finite intersections'.</p>\n\n<p>In <em>Grundzüge der Mengenlehre (1914)</em> Hausdorff presented his set of four axioms for topological space that has undoubtedly influenced the modern definition, since they both emphasize the notion of open set. But who introduced the modern definition for the first time?</p>\n\n<blockquote>\n  <p>Hausdorff's axioms or Umgebungsaxiome (page 213 in <em>Grundzüge der\n  Mengenlehre</em>):</p>\n  \n  <p>(A) Jedem Punkt $x$ entspricht mindestens eine Umgebung $U_x$; jede\n  Umgebung  $U_x$ enthält den Punkt $x$.</p>\n  \n  <p>(B) Sind $U_x$, $V_x$ zwei Umgebungen desselben Punktes $x$, so gibt\n  es eine Umgebung $W_x$, die Teilmenge von beiden ist.</p>\n  \n  <p>(C) Liegt der Punkt $y$ in $U_x$, so gibt es eine Umgebung $U_y$, die\n  Teilmenge von $U_x$ ist.</p>\n  \n  <p>(D) Für zwei verschiedene Punkte $x$, $y$ gibt es zwei Umgebungen\n  $U_x$, $U_y$ ohne gemeinsame Punkt.</p>\n</blockquote>\n", "pids": ["53e9b39db7602d9703e827aa"], "flag": 0}
{"question": "How does `predict.randomForest` estimate class probabilities?", "body": "<p><strong>How does <code>randomForest</code> package estimate class probabilities when I use <code>predict(model, data, type = \"prob\")</code>?</strong></p>\n\n<p>I was using <code>ranger</code> for training random forests using the <code>probability = T</code> argument to predict probabilities. <code>ranger</code> says in documentation that it:</p>\n\n<blockquote>\n  <p>Grow a probability forest as in Malley et al. (2012).</p>\n</blockquote>\n\n<p>I simulated some data and tried both packages and obtained very different results (see code below)</p>\n\n<p><a href=\"https://i.stack.imgur.com/KY48O.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/KY48O.png\" alt=\"enter image description here\"></a></p>\n\n<p>So I know that it uses a different technique (then ranger) to estimate probabilities. But which one?</p>\n\n<pre><code>simulate_data &lt;- function(n){\n  X &lt;- data.frame(matrix(runif(n*10), ncol = 10))\n  Y &lt;- data.frame(Y = rbinom(n, size = 1, prob = apply(X, 1, sum) %&gt;%\n                               pnorm(mean = 5)\n                             ) %&gt;% \n                    as.factor()\n\n  ) \n  dplyr::bind_cols(X, Y)\n}\n\ntreino &lt;- simulate_data(10000)\nteste &lt;- simulate_data(10000)\n\nlibrary(ranger)\nmodelo_ranger &lt;- ranger(Y ~., data = treino, \n                                num.trees = 100, \n                                mtry = floor(sqrt(10)), \n                                write.forest = T, \n                                min.node.size = 100, \n                                probability = T\n                                )\n\nmodelo_randomForest &lt;- randomForest(Y ~., data = treino,\n                                    ntree = 100, \n                                    mtry = floor(sqrt(10)),\n                                    nodesize = 100\n                                    )\n\npred_ranger &lt;- predict(modelo_ranger, teste)$predictions[,1]\npred_randomForest &lt;- predict(modelo_randomForest, teste, type = \"prob\")[,2]\nprob_real &lt;- apply(teste[,1:10], 1, sum) %&gt;% pnorm(mean = 5)\n\ndata.frame(prob_real, pred_ranger, pred_randomForest) %&gt;%\n  tidyr::gather(pacote, prob, -prob_real) %&gt;%\n  ggplot(aes(x = prob, y = prob_real)) + geom_point(size = 0.1) + facet_wrap(~pacote)\n</code></pre>\n", "pids": ["5e5e183d93d709897cde78c0"], "flag": 1}
{"question": "What does a bottleneck layer mean in neural networks?", "body": "<p>I was reading the <a href=\"http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/1A_089.pdf\" rel=\"noreferrer\">FaceNet</a> paper and in the 3rd paragraph of the introduction it says:</p>\n\n<blockquote>\n  <p>Previous face recognition approaches based on deep networks\n  use a classification layer trained over a set of\n  known face identities and then take an intermediate bottleneck\n  layer as a representation used to generalize recognition\n  beyond the set of identities used in training.</p>\n</blockquote>\n\n<p>I was wondering what they mean by an intermediate bottleneck layer?</p>\n", "pids": ["573696026e3b12023e515eec"], "flag": 1}
{"question": "Meaning of &quot;efface&quot; in &quot;effaceable functor&quot; and &quot;injective effacement&quot;", "body": "<p>I'm reading Grothendieck's T&#x14d;hoku paper, and I was curious about the reasoning behind the terms \"effaceable functor\" and \"injective effacement\". I know that in English, to efface something means to erase it, but I'm not sure if there's another meaning in either conversational or mathematical French. </p>\n\n<p>Given an abelian category $C$ and an additive category $D$, an <em>effaceable functor</em> $F:C\\rightarrow D$ is an additive functor such that for all $A\\in\\text{Ob}(C)$, there exists some monomorphism $u:A\\rightarrow M$ such that $F(u)=0$. I'm guessing that the \"effacing\" going on here is the functor $F$ killing the map $u$.</p>\n\n<p>What I'm less sure about is the reasoning behind \"injective effacement\". Given an abelian category $C$ and $A\\in\\text{Ob}(C)$, an <em>injective effacement</em> of $A$ is a monomorphism $f:A\\rightarrow M$ such that for any monomorphism $g:B\\rightarrow C$, and any map $h:B\\rightarrow A$, there is a map $t:C\\rightarrow M$ such that the diagram commutes:\n$$\r\n\\newcommand{\\ra}[1]{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\xrightarrow{\\quad#1\\quad}\\!\\!\\!\\!\\!\\!\\!\\!}\r\n\\newcommand{\\da}[1]{\\left\\downarrow{\\scriptstyle#1}\\vphantom{\\displaystyle\\int_0^1}\\right.}\r\n%\r\n\\begin{array}{lll}\r\nB &amp; \\ra{g} &amp; C  \\\\\r\n\\da{h} &amp; &amp; \\da{t} \\\\\r\nA &amp; \\ra{f} &amp; M \\\\\r\n\\end{array}\r\n$$</p>\n\n<p>Grothendieck points out that $\\text{id}_M:M\\rightarrow M$ is an injective effacement of $M$ if and only if $M$ is an injective object of $C$, and that any monomorphism of $A$ to an injective object $M$ is an injective effacement of $A$. I don't really see what we're erasing here; my guess is that an injective effacement $f:A\\rightarrow M$ is somehow \"erasing\" the cohomology of $A$, but this is only a vague sense. </p>\n", "pids": ["623949ac6d2bdbb473c3b130"], "flag": 0}
{"question": "Why are optimization algorithms defined in terms of other optimization problems?", "body": "<p>I am doing some research on optimization techniques for machine learning, but I am surprised to find large numbers of optimization algorithms are defined in terms of other optimization problems. I illustrate some examples in the following.</p>\n\n<p>For example <a href=\"https://arxiv.org/pdf/1511.05133v1.pdf\">https://arxiv.org/pdf/1511.05133v1.pdf</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/khWHr.png\"><a src=\"https://i.stack.imgur.com/khWHr.png\" alt=\"enter image description here\"></a></p>\n\n<p>Everything looks nice and good but then there is this $\\text{argmin}_x$ in the $z^{k+1}$ update....so what is the algorithm that solves for the $\\text{argmin}$? We don't know, and it doesn't say. So magically we are to solve another optimization problem which is find the minimizing vector so that the inner product is at minimum - how can this be done?</p>\n\n<p>Take another example:<a href=\"https://arxiv.org/pdf/1609.05713v1.pdf\">https://arxiv.org/pdf/1609.05713v1.pdf</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/TJyoX.png\"><a src=\"https://i.stack.imgur.com/TJyoX.png\" alt=\"enter image description here\"></a></p>\n\n<p>Everything looks nice and good until you hit that proximal operator in the middle of the algorithm, and what is the definition of that operator?</p>\n\n<p>Boom:<a href=\"https://i.stack.imgur.com/u7aW8.png\"><a src=\"https://i.stack.imgur.com/u7aW8.png\" alt=\"enter image description here\"></a></p>\n\n<p>Now pray tell, how do we solve this $\\text{argmin}_x$ in the proximal operator? It doesn't say. In any case, that optimization problem looks hard (NP HARD) depending on what $f$ is.</p>\n\n<p>Can someone please enlighten me as to:</p>\n\n<ol>\n<li>Why are so many optimization algorithms defined in terms of other optimization problems? </li>\n</ol>\n\n<p>(Wouldn't this be some sort of chicken and egg problem: to solve problem 1, you need to solve problem 2, using method of solving problem 3, which relies on solving problem ....)</p>\n\n<ol start=\"2\">\n<li><p>How do you solve these optimization problems that are embedded in these algorithms? For example, $x^{k+1} = \\text{argmin}_x \\text{really complicated loss function}$, how to find the minimizer on the right hand side?</p></li>\n<li><p>Ultimately, I am puzzled as to how these algorithms can be numerically implemented. I recognize that adding and multiplying vectors are easy operations in python, but what about $\\text{argmin}_x$, is there some function (script) that magically gives you the minimizer to a function?</p></li>\n</ol>\n\n<p>(Bounty: can anyone reference a paper for which the authors make clear the algorithm for the sub-problem embedded in the high level optimization algorithm?)</p>\n", "pids": ["56d895dbdabfae2eee0e3d05"], "flag": 1}
{"question": "Are deep learning models parametric? Or non-parametric?", "body": "<p>I don't think there can be one answer to all the deep learning models. WHich of the deep learning models are parametric and which are non-parametric and why?</p>\n", "pids": ["5a4aef9e17c44a2190f7a881"], "flag": 1}
{"question": "Mathematical concepts named after mathematicians that have become acceptable to spell in lowercase form (e.g. abelian)?", "body": "<p>I would like to collect a list of mathematical concepts that have been named after mathematicians, which are now used in lowercase form (such as \"abelian\").  This question is partly motivated by my former supervisor, who joked (something like):</p>\n\n<blockquote>\n  <p>You know you've made it as a mathematician when they start using your name in lowercase.</p>\n</blockquote>\n\n<p>This is a <em>community wiki</em>, please:</p>\n\n<ol>\n<li>One mathematician per answer.  Please update already-existing answers if that mathematician already exists.</li>\n<li>Please give a brief description of the concept and the person (ideally with links to wikipedia).</li>\n<li>This is not about whether or not you agree with the capitalisation.</li>\n</ol>\n\n<p>Expect your answer to be edited otherwise.</p>\n", "pids": ["56d8177ddabfae2eee7b2497"], "flag": 0}
{"question": "Indefinite double integral", "body": "<p>In calculus we've been introduced first with indefinite integral, then with the definite one. Then we've been introduced with the concept of double (definite) integral and multiple (definite) integral. Is there a concept of double (or multiple) indefinite integral? If the answer is yes, how is its definition, and why we don't learn that? If the answer is no, why it is so?</p>\n", "pids": ["53e99fe9b7602d97028cb4ff"], "flag": 0}
{"question": "Prove ${\\large\\int}_0^\\infty\\left({_2F_1}\\left(\\frac16,\\frac12;\\frac13;-x\\right)\\right)^{12}dx\\stackrel{\\color{#808080}?}=\\frac{80663}{153090}$", "body": "<p>I discovered the following conjectured identity numerically (it holds with at least $1000$ digits of precision). How can I prove it?\n$${\\large\\int}_0^\\infty\\left({_2F_1}\\left(\\frac16,\\frac12;\\frac13;-x\\right)\\right)^{12}dx\\stackrel{\\color{#808080}?}=\\frac{80663}{153090}$$</p>\n\n\n\n<p><em>Update:</em> It looks like this hypergeometric function assumes algebraic values at algebraic points (it's only a guess because I have only approximations to those algebraic numbers). Looking at those values, I was able to further conjecture that the hypergeometric function for $x&lt;0$ is actually the following elementary function:</p>\n\n<p>$$\n{_2F_1}\\left(\\frac16,\\frac12;\\frac13;x\\right)\\stackrel{\\color{#808080}?}=\n\\\\\n\\frac1{\\sqrt[4]2\\sqrt3}\\cdot\\sqrt{\\frac{\\alpha}{1-x}+\\frac{1}{\\alpha}\n\\sqrt{\\frac{4\\left(\\alpha\\sqrt{2}+2\\right)+x\\left(\\sqrt[3]{4\\beta}-2\\left(\\alpha\\sqrt{2}+4\\right)\\right)+2\\sqrt[3]{2\\beta^2}}{1-x}}}~,\n$$</p>\n\n<p>where</p>\n\n<p>$$\\alpha=\\sqrt{2-2x+\\sqrt[3]{2\\beta^2}}~,\\qquad\\beta=x(x-1)~.$$</p>\n", "pids": ["53e9abc4b7602d97035781e3"], "flag": 0}
{"question": "Why is logistic regression particularly prone to overfitting in high dimensions?", "body": "<p>Why does <em>&quot;the <strong>asymptotic nature</strong> of logistic regression&quot;</em> make it particularly prone to <strong>overfitting</strong>  in <strong>high dimensions</strong>?  (<a href=\"https://developers.google.com/machine-learning/crash-course/logistic-regression/model-training\" rel=\"noreferrer\">source</a>):</p>\n<p><a href=\"https://i.stack.imgur.com/u1cZu.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/u1cZu.png\" alt=\"enter image description here\" /></a></p>\n<p>I understand the <strong>LogLoss</strong> (<a href=\"https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_error_function_and_logistic_regression\" rel=\"noreferrer\">cross entropy</a>) grows quickly as <span class=\"math-container\">$y$</span> (true probability) approaches <span class=\"math-container\">$1-y'$</span> (predicted probability):</p>\n<p><a src=\"https://i.stack.imgur.com/wuPLc.png\" width=\"400\"></p>\n<p>but <strong>why</strong> does that imply that <em>&quot;the <strong>asymptotic nature</strong> of logistic regression would keep driving the loss towards 0 in <strong>high dimensions</strong> without regularization&quot;</em>?</p>\n<p>In my mind, just because the loss can grow quickly (if we get very <em>close</em> to the wrong and full opposite answer), it doesn't mean that it would thus try to fully interpolate the data.  If anything the optimizer would <strong>avoid</strong> entering the asymptotic part (fast growing part) of the loss as aggressively as it can.</p>\n", "pids": ["5a260c8117c44a4ba8a308fe", "5d06e48dda562926acc50bdf"], "flag": 1}
{"question": "Could someone explain rough path theory? More specifically, what is the higher ordered &quot;area process&quot; and what information is it giving us?", "body": "<p><a href=\"http://www.hairer.org/notes/RoughPaths.pdf\">http://www.hairer.org/notes/RoughPaths.pdf</a> here is a textbook, but I am completely lost at the definition. It is defined on page 13, chapter 2. A rough path is defined as an ordered pair, $(X,\\mathbb{X})$ where $X$ is a continuous process and $\\mathbb{X}$ is a higher ordered area process which defines certain integrals that satisfy \"Chen's Relation\". What is this area process and what does it have to do with the original continuous function? What are these integrals (which he emphasizes are defined by the area process, not the other way around)? So could the area process be anything satisfying Chen's relations? </p>\n", "pids": ["53e9b41ab7602d9703f1041d"], "flag": 0}
{"question": "What are good references to self study persistent homology?", "body": "<p>I am a graduate student in mathematics interested in persistent homology. Can anyone recommend good books or resources to self study persistent homology?</p>\n\n<p>I am taking a course in Algebraic Topology, studying the book by Hatcher.</p>\n", "pids": ["5bdc31b817c44a1f58a0bd36"], "flag": 0}
{"question": "Is COVID-19 more dangerous than typical annual coronavirus variants?", "body": "<p>I have heard many people claim in private that COVID-19 is not worse than flu and that the reaction is overblown.</p>\n\n<p>As a poster-child example of this, I want to analyze the claims made by the German pulmonologist <a href=\"https://en.wikipedia.org/wiki/Wolfgang_Wodarg\" rel=\"noreferrer\">Dr. Wolfgang Wodarg</a> in <a href=\"https://www.youtube.com/watch?v=p_AyuhbnPOI\" rel=\"noreferrer\">this video</a>. </p>\n\n<p>There are other places (<a href=\"https://www.wodarg.com/\" rel=\"noreferrer\">Wodarg's personal website</a>, <a href=\"https://www.youtube.com/watch?v=va-3zS9q1yo\" rel=\"noreferrer\">interview</a>, <a href=\"http://zeitung.shz.de/flensburgertageblatt/2332/article/1094358/29/1/render/?token=d21c25e0d9812d4a58df107989b641a2&amp;fbclid=IwAR1GlUwIaK4STuQGUzUy-TS4A55SpkEoCuTVaQdepM5lRUXY1Ou2nYHx9S8\" rel=\"noreferrer\">online newspaper</a>) where he repeats and refines his claims but they don't come with English subtitles so I want to focus on the first video.</p>\n\n<p>The overarching claim is that there is no evidence that we are seeing unusual deaths due to COVID-19. It is just that we started measuring things we did not do before, and haven't compared them to a baseline of illness and mortality, and have blown the data we have out of proportion. However, this can be broken down into more easily verifiable subclaims:</p>\n\n<ol>\n<li>the lab in China identified a novel corona virus in a small sample\nof pneumonia patients (&lt;50) of whom there are always plenty in Wuhan\n(with 11 million people) and put it into \"the virus database\" (whatever that is)</li>\n<li>the German virologist <a href=\"https://en.wikipedia.org/wiki/Christian_Drosten\" rel=\"noreferrer\">Christian Drosten</a> developed\na test for this virus which was \"rushed to market\" in China without\nproper validation so we don't actually know if it tests what it\nshould</li>\n<li>we don't know the baseline for coronaviruses in pneumonia related deaths so we can't establish whether COVID-19 actually increased the\nrates: From the cited Glasgow study we would expect around 5-15% of flu season deaths to test positive for a coronavirus in an average flu season in Germany. That would be 3000 deaths which is more than 100x more than the reported COVID-19 death toll in Germany so far</li>\n<li>just because someone tests positive for SARS-CoV-2 and died of pneumonia does not mean that they died because of SARS-CoV-2.</li>\n</ol>\n\n<p>Are these claims true?</p>\n", "pids": ["5e8f09719e795ec180f47782", "5d528a6b10066d67516b134c", "53e99827b7602d9702047e50", "5e32aaabdf1a9c0c41e99bee"], "flag": 1}
{"question": "Are there infinitely many primes of the form [X]? We probably don&#39;t know.", "body": "<h2>Are there infinitely many primes of the form <em>[expression]?</em></h2>\n<h2>(We probably don't know. Sorry.)</h2>\n<p>This question appears pretty often, with any number of various expressions. The sad reality is that the answer, more likely than not, is that <em>we don't know.</em> What we <em>don't</em> know about the prime numbers vastly outnumbers what we do know. Related questions regarding gaps between primes are common as well. For instance:</p>\n<hr />\n<ul>\n<li><strong>Common unanswerable questions posted to M.SE</strong>\n<ul>\n<li>Are there infinitely many primes of the form <span class=\"math-container\">$n^2+1$</span> ? Or any other order-2 or higher polynomial. We <em>think</em> there probably are, but it's unproven, and going to be hard to prove.</li>\n<li>Are there infinitely many primes of the form <span class=\"math-container\">$2^k + a$</span> ? Or any other exponential expression.</li>\n<li>Are there infinitely many prime gaps of the form [<em>expression</em>]?</li>\n<li>Does [<em>this formula</em>] generate all the prime numbers? (Though this is often &quot;No.&quot;)</li>\n</ul>\n</li>\n</ul>\n<p><strong>Note</strong>: There are other questions that ask &quot;What do we know about primes of the form [<em>expression</em>]?&quot; This is a very different question, and can generate good discussion! They're also rarer.</p>\n<hr />\n<p>I felt we could use an article that could be pointed to, edited, referenced, and the like, for questions of this type. Hopefully the community will find this useful.</p>\n<p>This post will organize some answers--both positive and negative--to the question for various expressions, and provide informative links and proofs where proofs are available. Please edit in more information if you think it's useful! Note that the questions and answers here are not intended to deal with error terms, sieve bounds, asymptotics, etc. We're just keeping it nice and simple. Even the Prime Number Theorem is outside the scope here.</p>\n<hr />\n<p>Terminology used below:</p>\n<ul>\n<li>The gap function, <span class=\"math-container\">$g(p)$</span>, is the difference between two consecutive primes. That is, <span class=\"math-container\">$g(p_i) = p_{i+1} - p_i$</span>.</li>\n<li>The prime-counting function, <span class=\"math-container\">$\\pi(x)$</span>, counts the number of primes equal to or less than <span class=\"math-container\">$x$</span>.</li>\n<li>&quot;ATIM&quot;: &quot;Are There Infinitely Many&quot;</li>\n</ul>\n", "pids": ["56d8a232dabfae2eee6dc9e5"], "flag": 0}
{"question": "Why are $p$-adic numbers ubiquitous in modern number theory?", "body": "<p>I'm currently at a stage where I think I'm quite comfortable with the appearance of local non-archimedean fields in the maths I encounter, having seen a fair bit of technology built upon their structure and applications to connected areas, yet I somehow still feel like I have an unsatisfying understanding of why their introduction is absolutely crucial to study algebraic number theory and arithmetic geometry, especially since all these applications are hugely advanced compared to the point at which <span class=\"math-container\">$p$</span>-adic numbers are usually introduced in a student's career I think. If I want to motivate their definition, I sort of naturally go through the following implications in my head:</p>\n<ol>\n<li>to study a problem over the ring of integers <span class=\"math-container\">$\\mathbb{Z}$</span> (or more generally, the ring of integers of a number field) the strategy is to <em>localise</em> the problem at a prime <span class=\"math-container\">$p$</span>, as to focus around it and worry about the problem '<em>one point at a time</em>', so-to-speak;</li>\n<li>we (literally, now) localise at the prime <span class=\"math-container\">$p$</span>, just as one would do with the ring of regular functions on a variety, and replace <span class=\"math-container\">$\\mathbb{Z}$</span> with the ring <span class=\"math-container\">$\\mathbb{Z}_{(p)} := \\{ \\frac{x}{y} \\in \\mathbb{Q} \\mid p\\nmid y \\}$</span> ;</li>\n<li>we can then complete at the maximal ideal <span class=\"math-container\">$(p) \\subseteq \\mathbb{Z}_{(p)}$</span> to obtain the <span class=\"math-container\">$p$</span>-adic integers <span class=\"math-container\">$\\mathbb{Z}_p$</span>, with the benefit that now there's access to approximation techniques such as Hensel's lemma, and the newly obtained ring has pretty much all the same algebraic properties as <span class=\"math-container\">$\\mathbb{Z}_{(p)}$</span> because of its identical valuation theory.</li>\n</ol>\n<p>It's this last step which still confuses me... even though I can appreciate the utility of approximation techniques, it still feels extremely arbitrary why it turns out to be so inevitable with all the theory that builds upon this measly little step. Somehow, every time I've seen the study of formal neighbourhoods in algebraic geometry it always feels like it's a tool to tackle a problem, and not the main object of study, whereas in my head the <span class=\"math-container\">$p$</span>-adic numbers have turned out to be the main character in many areas of mathematics, which sort-of goes against this intuition of mine I find.</p>\n<p>Since this intuition really doesn't come from any of my teachers and I'm not quite sure it makes much sense, I wanted to ask if it's an apt way to think about the use of non-archimedean fields in mathematics; I'd also be very interested in learning about their role in the history of algebraic number theory since I'm not quite sure I can properly place their use and introduction on a timeline in a coherent way with all of the theory I have in mind.</p>\n<p>I apologise if my question is very hand-wavy, and I'd be super grateful for any sort of insight :) Thank you very much for your time!!</p>\n", "pids": ["53e9b32bb7602d9703dfc6c7"], "flag": 0}
{"question": "Can all groups be thought of as the symmetries of a geometrical object?", "body": "<p>It is often said that we can think of groups as the symmetries of some mathematical object. Usual examples involve geometrical objects, for instance we can think of <span class=\"math-container\">$\\mathbb{S}_3$</span> as the collection of all reflections and rotation symmetries of an equilateral triangle, similarly we can think of <span class=\"math-container\">$D_8$</span> as the symmetry group of a square.</p>\n\n<p>Cayley's Theorem along with the fact that the symmetry group of a regular <span class=\"math-container\">$n$</span>-simplex is isomorphic to <span class=\"math-container\">$\\mathbb{S}_{n+1}$</span> allows us to think of any finite group as a subset of the symmetry group of some geometrical object. Which brings me to the following questions:</p>\n\n<ol>\n<li><p>Can every finite group be represented as the collection of all symmetries of a geometrical object? That is, are all finite groups isomorphic to some Symmetry group?</p></li>\n<li><p>Can such a result (the representation of groups as distance-preserving transformations of some geometrical object) be extended to infinite groups? If so, how?</p></li>\n</ol>\n\n<p>Thanks in advance (:</p>\n", "pids": ["56d830d1dabfae2eee214990"], "flag": 0}
{"question": "What are the differences between a fiber bundle and a sheaf?", "body": "<p>They are similar. Both contain a projection map and one can define sections, moreover the fiber of the fiber bundle is just like the stalk of the sheaf.</p>\n\n<p>But what are the differences between them?</p>\n\n<p>Maybe a sheaf is more abstract and can break down, while a fibre bundle is more geometric and must keep itself continuous. Any other differences?  </p>\n", "pids": ["53e9aa95b7602d970340dc27"], "flag": 0}
{"question": "Evaluate definite interval of normal distribution", "body": "<p>I know that an easy to handle formula for the CDF of a normal distribution is somewhat missing, due to the complicated error function in it.</p>\n\n<p>However, I wonder if there is a a nice formula for $N(c_{-} \\leq x &lt; c_{+}| \\mu, \\sigma^2)$. Or what the \"state of the art\" approximation for this problem might be.</p>\n", "pids": ["557f14d46fee0fe990caea12", "53e9bb80b7602d97047c84e9", "55a38cbb65ce5cd7b3ae3964", "53e99d81b7602d970263e03c"], "flag": 1}
{"question": "Are many allergies caused by too much hygiene?", "body": "<p>One hears it once in a while that many allergies are due to people overly concerned with hygiene. The rationale is that growing up in a near-sterile environment will leave your immune system confused so that you then develop allergies.</p>\n\n<p>Is this actually true?</p>\n", "pids": ["55a40918c91b587b096abac0", "55a52948612c6b12ab057e31"], "flag": 1}
{"question": "Should One Hot Encoding or Dummy Variables Be Used With Ridge Regression?", "body": "<p>For a regression problem in which the predictor is a single categorical variable with <span class=\"math-container\">$q$</span> categories, Ridge regression can be considered the Best Linear Unbiased Predictor (BLUP) for the mixed model</p>\n<p><span class=\"math-container\">$$ \\mathbf{y} = \\mathbf{X} \\beta +\\mathbf{Zu}+ \\boldsymbol{\\epsilon} $$</span></p>\n<p>In this case, <span class=\"math-container\">$\\mathbf{X}$</span> is just a columns of 1s and <span class=\"math-container\">$\\beta$</span> is the intercept. <span class=\"math-container\">$\\mathbf{Z}$</span> is the design matrix that encodes the <span class=\"math-container\">$q$</span> random effects. In this situation, Ridge regression is the BLUP estimator if we set the ridge parameter to <span class=\"math-container\">$\\lambda = \\sigma_{\\epsilon}^2 / \\sigma^2$</span>. Here, <span class=\"math-container\">$\\sigma_{\\epsilon}$</span> is the variance of <span class=\"math-container\">$\\boldsymbol{\\epsilon}$</span>, and <span class=\"math-container\">$\\sigma$</span> is the variance of <span class=\"math-container\">$\\mathbf{u}$</span> (here, the random effects are assumed to be isotropic). I've been told this is equivalent to fitting a Ridge model in which the feature matrix is a one hot encoding (that is, all <span class=\"math-container\">$q$</span> categories appear as columns) of the categories.</p>\n<p>Some convincing arguments are made, which I will summarize here in python code. They are themselves summaries from a paper called <a href=\"https://projecteuclid.org/journals/statistical-science/volume-6/issue-1/That-BLUP-is-a-Good-Thing--The-Estimation-of/10.1214/ss/1177011926.full\" rel=\"noreferrer\"><em>That BLUP is a good thing The Estimation of Random Effects.</em></a>. Here, 3 groups are simulated.  4 Ridge models are fit: 3 in which each group takes turns being the reference group, and one in which all groups appear in the feature matrix.  Shown below is a plot of the predictions</p>\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport pandas as pd \nimport sklearn as sk\nfrom sklearn.linear_model import LinearRegression, Ridge\nimport seaborn as sb \nimport matplotlib.pyplot as plt\n\nD=pd.DataFrame({'group':[1,1,1,1,1,2,2,2,2,2,3,3,3,3,3],'y':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]})\n\n# Now let's dummy code the group in four different ways \nX = pd.get_dummies(D['group'],drop_first=False).values # Full dummy code with a dummy variable for each group \nX1 = X[:,1:3]   # Drop the first group \nX2 = X[:,[0,2]] # Drop the second group \nX3 = X[:,:2]    # Drop the last group \n\n# Now let's use the different dummy coding schemes for Ridge regression, using a Ridge coefficient of 1\n# First the first one: \nR1 = Ridge(alpha = 1)\nR1.fit(X1,D['y'])\nypred_R1=R1.predict(Xpred1)\nypred_R1\n&gt;&gt;&gt; array([ 4.875     ,  7.47916667, 11.64583333])\n\n# Then dropping the middle group  \nR2 = Ridge(alpha = 1)\nR2.fit(X2,D['y'])\nypred_R2=R2.predict(Xpred2)\nypred_R2\n&gt;&gt;&gt; array([ 3.83333333,  8.        , 12.16666667])\n\n# And finally dropping the third group\nR3 = Ridge(alpha = 1)\nR3.fit(X3,D['y'])\nypred_R3=R3.predict(Xpred3)\nypred_R3\n&gt;&gt;&gt;array([ 4.35416667,  8.52083333, 11.125     ])\n\n# Now we have 3 regressors, instead of two. To achieve a similar amount of shrinkage, we need to \n# therefor increase our Ridge coefficient a bit.   \nR = Ridge(alpha = 3, fit_intercept = True)\nR.fit(X,D['y'])\nypred_R=R.predict(Xpred)\nypred_R\n&gt;&gt;&gt;array([ 4.875,  8.   , 11.125])\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/gQEYZ.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/gQEYZ.png\" alt=\"enter image description here\" /></a></p>\n<p>It turns out, that making one group the reference group makes implicit assumptions about the covariance of the <span class=\"math-container\">$\\mathbf{u}$</span>.  Here is a plot of the covariance structure when we drop one of the variables to use as a reference</p>\n<p><a href=\"https://i.stack.imgur.com/bA0fB.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/bA0fB.png\" alt=\"enter image description here\" /></a></p>\n<p>Compare this to the true covariance structure assumed by the model with all 3 predictors in the feature matrix</p>\n<p><a href=\"https://i.stack.imgur.com/ZvpxE.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/ZvpxE.png\" alt=\"enter image description here\" /></a></p>\n<h2>Question</h2>\n<p>I've never before seen the recommendation to keep all categories in a Ridge regression.  Indeed, if we are cross validating over the penalty, the resulting covariance structure does not seem worth the instability induced by the collinearity.</p>\n<p>Does a ridge model in which all categories appear as binary indicators perform better (i.e. lower loss) than a ridge model which absorbs a category into the intercept term? If so, why? Some (not very rigorous) experiments seem to hint that the answer is &quot;no&quot;, but I'm interested in hearing the perspectives of other data scientists and statisticians.</p>\n<p>Additionally, if the goal is prediction then what are the general consequences of imposing the wrong covariance structure on the data by making one group a reference category?</p>\n<p>Should we include all categories when fitting a ridge model?</p>\n", "pids": ["55a660dd612ca6eebaae461c"], "flag": 1}
{"question": "What are some good open problems about countable ordinals?", "body": "<p>After reading some books about ordinals I had an impressions that area below $\\omega_1$ is thoroughly studied and there is not much new research can be done in it. I hope my impression was wrong. Recently I stumbled upon the sequences <a href=\"http://oeis.org/A005348\">A005348</a> and <a href=\"http://oeis.org/A199812\">A199812</a> in OEIS and was surprised by unexpected connection between ordinals and combinatorics.</p>\n\n<p>So now I am looking for interesting open problems related to countable ordinals, possible having connection to combinatorics or other fields of mathematics. Could you please point me to some resources that can help me, or formulate some problems here?</p>\n", "pids": ["53e9adc7b7602d97037cf1d4"], "flag": 0}
{"question": "Find an expression for the $n$-th derivative of $f(x)=e^{x^2}$", "body": "<p>I need to find an expression for $n$th derivative of $f(x) = e^{x^2}$. Really need help.</p>\n", "pids": ["628d15985aee126c0f2fff09", "5f4e37be9e795ea3f185b65e", "5c756eb5f56def97985fa2d8", "5550405445ce0a409eb3383a"], "flag": 0}
{"question": "Defining the derivative without limits", "body": "<p>These days, the standard way to present differential calculus is by introducing the Cauchy-Weierstrass definition of the limit. One then defines the derivative as a limit, proves results like the Leibniz and chain rules, and uses this machinery to differentiate some simple functions such as polynomials. The purpose of my question is to see what creative alternatives people can describe to this approach. The nature of the question is that there is not going to be a single best answer. I have several methods that I've collected which I'll put in as answers to my own question.</p>\n\n<p>It's not reasonable to expect answers to include an entire introductory textbook treatment of differentiation, nor would anyone want to read answers that were that lengthy. A sketch is fine. Lack of rigor is fine. Well known notation and terminology can be assumed. It would be nice to develop things to the point where one can differentiate a polynomial, since that would help to illustrate how your method works and demonstrate that it's usable. For this purpose, it suffices to prove that if $n&gt;0$ is an integer, the derivative of $x^n$ equals $0$ at $0$ and equals $n$ at $1$; the result at other nonzero values of $x$ follows by scaling. Doing this for $n=2$ is fine if the generalization to $n&gt;2$ is obvious.</p>\n", "pids": ["53e9b403b7602d9703ef2117"], "flag": 1}
{"question": "Can a GAN be used for data augmentation?", "body": "<p>Can a generative adversarial network (GAN) be used for data augmentation (i.e. to generate synthetic examples that are added to a dataset)? Would it have any impact on the performance of a model trained on the augmented dataset?</p>\n", "pids": ["5a4aef9e17c44a2190f7a8fa", "5c8d7f0b4895d9cbc663f02a", "5a9cb66717c44a376ffb88a8", "5b67b49517c44aac1c8653a7", "58d82fced649053542fd7453", "5db9296d47c8f766461f63e7", "5c2c7a9217c44a4e7cf31a03"], "flag": 1}
{"question": "Number of ways to partition a rectangle into n sub-rectangles", "body": "<p>How many ways can a rectangle be partitioned by either vertical or horizontal lines into <code>n</code> sub-rectangles? At first I thought it would be:</p>\n\n<pre><code>      f(n) = 4f(n-1) - 2f(n-2)  \nwhere f(0) = 1  \n  and f(1) = 1 \n</code></pre>\n\n<p>but the recurrence relation only counts the cases in which at least one side (either top, bottom, left or right of the original rectangle) is not split into sub-rectangles. There are many other partitions that don't belong to those simple cases like</p>\n\n<p>[EDIT ImageShack has removed the picture. One of the cases is the sixth partition when n = 4 in the picture in the accepted answer below.]</p>\n\n<p>Any other related problem suggestions are welcome. Also it is nice to know how to traverse this partition efficiently.</p>\n", "pids": ["56d90e1fdabfae2eee2a30c0", "5ce3a6c1ced107d4c6517b95"], "flag": 0}
{"question": "How many ways are there to pile $n$ &quot;$1\\times 2$ rectangles&quot; under some conditions?", "body": "<p>A friend of mine taught me the following question. He said he created the question by himself and conjectured the answer, but couldn't prove it. Though I've tried to solve the question, I've been facing difficulty.</p>\n<p>The question is about piling rectangles. (The following is an example when we pile thirteen <span class=\"math-container\">$1\\times 2$</span> rectangles.)</p>\n<p><span class=\"math-container\">$\\qquad\\qquad\\qquad\\qquad$</span><a href=\"https://i.stack.imgur.com/Hdycw.gif\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/Hdycw.gif\" alt=\"enter image description here\" /></a></p>\n<blockquote>\n<p><strong>Question</strong> : For a positive integer <span class=\"math-container\">$n$</span>, how many ways are there to pile <span class=\"math-container\">$n$</span> <span class=\"math-container\">$1\\times 2$</span> rectangles (&quot;<span class=\"math-container\">$1$</span> row and <span class=\"math-container\">$2$</span> columns&quot; only) under the following conditions?</p>\n<ul>\n<li><p>The rectangles at the bottom are next to each other.</p>\n</li>\n<li><p>A rectangle not at the bottom and another rectangle right below it &quot;overlap&quot; only half.</p>\n</li>\n</ul>\n</blockquote>\n<p>Let <span class=\"math-container\">$f(n)$</span> be the number of such ways. Then, interestingly, we have\n<span class=\"math-container\">$$f(1)=1,\\quad f(2)=3,\\quad f(3)=9,\\quad f(4)=27,\\quad f(5)=81,\\cdots$$</span></p>\n<p>We have <span class=\"math-container\">$f(3)=9$</span> because</p>\n<p><span class=\"math-container\">$\\qquad\\qquad$</span><a href=\"https://i.stack.imgur.com/cjyIg.gif\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/cjyIg.gif\" alt=\"enter image description here\" /></a></p>\n<p>So, it seems that we can have <span class=\"math-container\">$f(n)=3^{n-1}$</span>. However, I have not been able to prove that.</p>\n<p>I've tried to use induction. However, I have not been able to find a way to use the induction hypothesis. Since the answer seems very simple, there should be something that I'm missing. Can anyone help?</p>\n", "pids": ["53e9aa5cb7602d97033cb2ef"], "flag": 0}
{"question": "Why are period integrals na&#239;ve periods?", "body": "<p>Apologies for the long question.</p>\n\n<p>I recall the definition of a <em>(naïve) period</em> according to Kontsevitch and Zagier <a href=\"http://www.maths.ed.ac.uk/~aar/papers/kontzagi.pdf\">[KS]</a>:</p>\n\n<blockquote>\n  <p>A (naïve) period is a complex number whose real and imaginary parts are absolutely convergent integrals of rational functions with rational coefficients on domains of $\\mathbb R^d$ bounded by polynomial inequalities with rational coefficients.</p>\n</blockquote>\n\n<p>For example, </p>\n\n<p>$$\\pi = \\iint_{x^2+y^2 \\leq 1} dx dy$$</p>\n\n<p>is a period, whereas $e$ is conjecturally not a period. As [KS] point out, the following definition is equivalent:</p>\n\n<blockquote>\n  <p>A period is a complex number which is an absolutely convergent integral of an algebraic function defined over $\\mathbb Q$, on a domains of $\\mathbb R^d$ bounded by polynomial inequalities with real algebraic coefficients.</p>\n</blockquote>\n\n<p>To illustrate, remark that for $\\lambda&gt;1 \\in \\mathbb Q$,</p>\n\n<p>$$2\\int_0^1 \\frac{dx}{\\sqrt{x(x-1)(x-\\lambda)}}$$</p>\n\n<p>is a period according to the second definition, but not obviously to the first one. But it can be rewritten as</p>\n\n<p>$$\\iint_{0 \\leq x \\leq 1, y^2 \\leq x(x-1)(x-\\lambda)} dx dy,$$</p>\n\n<p>and so it is a period also according to the first definition. </p>\n\n<p>Kontsevitch and Zagier point out that the periods of algebraic varieties in the classical sense are naïve periods. Let $X/\\mathbb Q$ be a smooth projective variety over $\\mathbb Q$ of dimension $d$, and $\\omega \\in H^0(X, \\Omega^d_{X/\\mathbb Q})$ a global algebraic differential form of top degree on $X$. Being of top degree, the form $\\omega$ is automatically closed, and gives rise to a de Rham cohomology class $[\\omega] \\in H^d_{dR}(X/\\mathbb C)$ in the middle cohomology of the variety $X(\\mathbb C)$, which has real dimension $2d$. Now let $D$ be a divisor on $X$ with normal crossings, and let $[\\sigma] \\in H_d(X(\\mathbb C), D(\\mathbb C), \\mathbb Q)$ be a homology class relative to $D$, represented by a $d$-chain whose boundary lies on $D$. Then the integral</p>\n\n<p>$$\\int_\\sigma \\omega|_{\\sigma}$$</p>\n\n<p>depends only on the relative homology class of $\\sigma$ and on the cohomology class of $\\omega$. </p>\n\n<blockquote>\n  <p><em>Claim</em>: the integral $\\int_\\sigma \\omega|_{\\sigma}$ is a period.</p>\n</blockquote>\n\n<p>Kontsevitch and Zagier seem to treat this as an obvious fact. It seems to me like a fairly difficult theorem. Am I overlooking a simple proof?</p>\n\n<p>To illustrate, let $X$ is the elliptic curve $y^2z=x(x-z)(x-\\lambda z)$,  $\\omega = dx/y$ is the invariant differential on $X$, and $D$ is the empty divisor,  then the periods of $\\omega$ in this sense are precisely the linear combinations of the classical period integrals</p>\n\n<p>$$2\\int_0^1 \\frac{dx}{\\sqrt{x(x-1)(x-\\lambda)}}, 2\\int_\\lambda^\\infty \\frac{dx}{\\sqrt{x(x-1)(x-\\lambda)}},$$</p>\n\n<p>which shows that the statement is true as both of these integrals are naïve periods. In order to get these integral formulas, we treat $X$ as a degree $2$ ramified covering of $\\mathbb P^1$ via $(x,y) \\mapsto x$; then $y$ becomes a multi-valued function on $\\mathbb A^1$ with branch points at $\\lambda = 0,1,\\lambda, \\infty$. The first homology of $X(\\mathbb C)$ is generated by two cycles whose image in $\\mathbb P^1(\\mathbb C)$ circle the branch cuts $[0,1]$ and $[\\lambda, \\infty] \\subseteq \\mathbb P^1(\\mathbb R)$ clockwise.  Thus it suffices to see that the integrals of $\\omega$ along these cycles are periods. Consider a $1$-cycle $\\sigma$ which circles the branch cut $[0,1]$ clockwise on the branch of $y$ which is positive for real $x$ large enough. This cycle is homologous to the cycle which goes from $0$ to $1$ along the positive branch of $y$, then goes back to $1$ along the negative branch. Thus </p>\n\n<p>$$\\int_\\sigma \\omega = \\int_0^1 \\frac{dx}{\\sqrt{x(x-1)(x-\\lambda)}} - \\int_0^1 \\frac{dx}{-\\sqrt{x(x-1)(x-\\lambda)}} = 2 \\int_0^1 \\frac{dx}{\\sqrt{x(x-1)(x-\\lambda)}}.$$</p>\n\n<p>Very good. But what about a variety of dimension $d&gt;1$? I am happy with supposing that the divisor $D$ is empty, so that $[\\sigma]$ is the homology class of a $d$-cycle. Here is how I thought one might prove that the integral $\\int_\\sigma \\omega$ is a period. Let $U$ be an affine open subvariety of $X$ such that $U(\\mathbb C)$ contains the image of the $d$-cycle $\\sigma$. By the Noether normalization lemma, there is a finite map $U \\to \\mathbb A^d$, and an open $V\\subseteq \\mathbb A^d$ such that the restriction $U' \\to V$ is finite étale of some degree $n$. Let us suppose still that $U'(\\mathbb C)$ contains the image of $\\sigma$.  Locally in the complex topology of $V(\\mathbb C)$, the morphism $U' \\to V$ has $n$ sections along which we can pull back the differential $\\omega$, to get a multivalued differential $\\omega$ on $V$. Let  $\\sigma'$ denote the $d$-cycle on $V(\\mathbb C)$ obtained by composing $\\sigma$ with $U'(\\mathbb C) \\to V(\\mathbb C)$; the integral</p>\n\n<p>$$\\int_{\\sigma'}\\omega$$</p>\n\n<p>has $n$ possible values, depending on the branch of $\\omega$ which is chosen (and then analytically continued along $\\sigma'$). </p>\n\n<p>It should therefore be proven that the integrals $\\int_{\\sigma'} \\omega$ are periods. The problem is that the cycle $\\sigma$ is only differentiable. For instance, in the example above, if we re-parametrize the integral</p>\n\n<p>$$\\int_0^1 \\frac{dx}{\\sqrt{x(x-1)(x-\\lambda)}}$$</p>\n\n<p>by a diffeomorphism $t \\mapsto x(t)$ of the interval, preserving the boundary, then we get</p>\n\n<p>$$\\int_0^1 \\frac{x'(t) dt }{\\sqrt{x(t)(x(t)-1)(x(t)-\\lambda)}}$$</p>\n\n<p>which is not recognizable as a period anymore. Hence, it appears crucial that the homology class of a path $\\sigma$ circling the branch cut $[0,1]$ can be represented also by a path which is <em>piecewise-linear</em>, namely the path which goes from $0$ to $1$ in constant time on the top sheet and goes back to $0$ in constant time on the bottom sheet. </p>\n\n<p>It appears to me that the statement that $\\int_{\\sigma'} \\omega$ is a period depends on the fact that any $d$-cycle $\\sigma$ on $V(\\mathbb C) \\subseteq \\mathbb A^d(\\mathbb C)$ is homologous to one which is piecewise-linear, or even piecewise-polynomial, with algebraic coefficients. It seems to me that this is true, although it is probably a fairly difficult theorem of algebraic topology.</p>\n\n<p>Is my way of approaching this problem correct, or am I overlooking something much simpler? </p>\n\n<p>Thank you for reading, and for your ideas.</p>\n", "pids": ["5f0e63029fced0a24bf2e19a"], "flag": 0}
{"question": "How prove this sum $\\sum_{n=1}^{\\infty}\\binom{2n}{n}\\frac{(-1)^{n-1}H_{n+1}}{4^n(n+1)}$", "body": "<p>show that</p>\n\n<p>$$\\sum_{n=1}^{\\infty}\\binom{2n}{n}\\dfrac{(-1)^{n-1}H_{n+1}}{4^n(n+1)}=5+4\\sqrt{2}\\left(\\log{\\dfrac{2\\sqrt{2}}{1+\\sqrt{2}}}-1\\right)$$</p>\n\n<p>where $H_{n}=1+\\dfrac{1}{2}+\\dfrac{1}{3}+\\cdots+\\dfrac{1}{n}$</p>\n\n<p>My try: we let\n$$s(x)=\\sum_{n=1}^{\\infty}\\binom{2n}{n}\\dfrac{(-1)^{n-1}H_{n+1}}{(n+1)}x^{n+1}$$\nthen\n$$s'(x)=\\sum_{n=1}^{\\infty}(-1)^{n-1}\\binom{2n}{n}H_{n+1}x^n$$\nthen I can't.Thank you</p>\n", "pids": ["53e9a751b7602d9703088257"], "flag": 0}
{"question": "Any ideas on how I can prove this expression?", "body": "<p>I don't have a lot of places to turn because i am still in high school. So please bear with me as i had to create some notation. </p>\n\n<p>In order to understand my notation you must observe this <a href=\"http://en.wikipedia.org/wiki/Bell_polynomials#Convolution_identity\">identity for bell polynomials</a></p>\n\n<p>$a = (f'(x),f''(x),\\cdots)$ and $b = (g'(x),g''(x),\\cdots)$\n$$\nB_{n,k}(f'(x),f''(x),\\cdots,f^{(n-k+1)}(x))_{(f \\rightarrow g)^c} = \\frac{(a^{(k-c)_\\diamond} \\diamond b^{c_\\diamond})_n}{(k-c)!c!}\n$$</p>\n\n<p>Also note that $d_n= \\frac{d^n}{dx^n}[f(x)\\ln(g(x))]$</p>\n\n<p>I must prove that</p>\n\n<p>$$\n\\sum_{k=1}^{n}\\ln^k(g(x)) B_{n,k}(f'(x),f''(x),\\cdots,f^{(n-k+1)}(x))\n$$</p>\n\n<p>$$\n=\\sum_{k=1}^n[ B_{n,k}(d_1,d_2,\\cdots,d_{n-k+1})- \\sum_{m=0}^{n-k}\\sum_{j=0}^{m} {m \\choose j} \\frac{\\ln^{m-j}(g(x))}{g(x)^k} \\frac{d^j}{d(f(x))^j}[(f(x))_k] B_{n,m+k}(f'(x),\\cdots,f^{(n-m-k+1)}(x))_{(f \\rightarrow g)^k}]\n$$</p>\n\n<p>Where $(f(x))_k$ is the Pochhammer symbol for falling factorial</p>\n\n<p>I have been trying to prove this for quite a while. Any advice on doing so would be amazing. Perhaps this can be put into a determinant or something of the sort, But I am not sure about that double summation. If you have advice PLEASE do so through a comment.</p>\n", "pids": ["53e9a9a9b7602d9703303772", "56d8c482dabfae2eee424473", "53e9a9a9b7602d9703303772", "56d8c482dabfae2eee424473", "53e9ac54b7602d9703624283", "56d869f3dabfae2eeebec770"], "flag": 0}
{"question": "Explain in layperson&#39;s terms why predictive models aren&#39;t causally interpretable", "body": "<p>Imagine that you are asked to infer some causal effect -- a change in an outcome <span class=\"math-container\">$y$</span> in response to some variable <span class=\"math-container\">$x$</span>.  But, the person asking for this directs you to use a predictive model to do so.  Here's the setup:</p>\n<ul>\n<li><span class=\"math-container\">$x$</span> is confounded inasmuch as there is some unobserved <span class=\"math-container\">$u$</span> that is causally linked to both <span class=\"math-container\">$y$</span> and <span class=\"math-container\">$x$</span>.  We have a classical omitted variables bias.</li>\n<li>We have high dimensional covariates <span class=\"math-container\">$\\mathbf{Z}$</span> that are not independent of <span class=\"math-container\">$y$</span> or <span class=\"math-container\">$x$</span> and/or <span class=\"math-container\">$u$</span></li>\n<li>You are asked to train a suite of predictive models -- neural networks, boosted trees, whatever -- denoted <span class=\"math-container\">$g_i([x, \\mathbf{Z}]) + \\epsilon$</span> where <span class=\"math-container\">$i$</span> indexes different models, and then select among them model <span class=\"math-container\">$i$</span> that minimizes some metric of predictive skill.  RMSE, for instance.</li>\n<li>Based on the chosen model, you are asked to report\n<span class=\"math-container\">$$\n\\frac{\\partial \\hat{y}}{\\partial x} = \\frac{\\partial \\hat{g}_i([x, \\mathbf{Z}])}{\\partial x}\n$$</span></li>\n<li>You know that\n<span class=\"math-container\">$$\nE\\left[\\frac{\\partial \\hat{y}}{\\partial x}\\right] \\neq \\frac{\\partial y}{\\partial x}\n$$</span>\nin the population, because the error term includes the omitted variable, so therefore\n<span class=\"math-container\">$$\n\\frac{\\partial \\epsilon}{\\partial x} \\neq 0 \\text{  in the population, despite the fact that } \\frac{\\partial \\hat\\epsilon}{\\partial x} = 0\n$$</span>\nin any reasonable model <span class=\"math-container\">$g$</span>.</li>\n</ul>\n<p>On top of omitted variables bias, there may be bias from regularization too!</p>\n<ul>\n<li>Further assume that you have some causal model -- say an instrumental variables regression, utilizing some suitable instrument <span class=\"math-container\">$w$</span> for <span class=\"math-container\">$x$</span>.  It's one of the models in your suite of models, but its predictive skill in terms of cross-validated RMSE is worse than the  others.</li>\n</ul>\n<p>The best model is the one that produces the consistent causal estimate, right?  But:</p>\n<p><strong>How would you explain this to someone in layperson's terms?</strong></p>\n<p>The person asking for analysis doesn't understand causal inference, and needs to be educated.  However, they don't understand math and have little attention span.  How can you effectively convey the basic point that causal methods are required, and predictive methods are inappropriate?  <strong>No math, lots of stories, pithy sentences.</strong></p>\n", "pids": ["56d90278dabfae2eeee099a1"], "flag": 1}
{"question": "Do Fibonacci numbers form a complete residue system in every modulus?", "body": "<p>I want to show that:\n$$\\forall x,m\\ \\exists n:x\\equiv_mF_n$$</p>\n\n<p>I assume that one can prove this by the pigeonhole principle, but I couldn't manage to find a series of $m+1$ numbers that each want to occupy a different number.</p>\n", "pids": ["56d8b70cdabfae2eee10c583"], "flag": 0}
{"question": "Can we divide $\\mathbb{R}^2$ into two path connected parts such that each part is not simply-connected?", "body": "<blockquote>\n  <p>Can we divide <span class=\"math-container\">$\\mathbb{R}^2$</span> into two connected parts such that each part is not simply-connected?</p>\n</blockquote>\n\n<p><strong>My attempt</strong></p>\n\n<p>Put <span class=\"math-container\">$A= \\{ (0,0) \\} $</span> and <span class=\"math-container\">$B$</span> is the punctured plane.</p>\n\n<p>Since that <span class=\"math-container\">$S^1$</span> is a deformation retract of the punctured plane, <span class=\"math-container\">$B$</span> is not simply-connected. Thus we can find a division of <span class=\"math-container\">$\\mathbb{R}^2$</span> such that one part is simply-connected but the other is not.</p>\n\n<p>But how to deal with the problem above which requires that each part is not simply-connected? </p>\n\n<p>It seems to be related to contractible and holes. But I don't know how to convert these ideas into precise mathematical language.</p>\n\n<p>Any hints? Thanks in advance!</p>\n\n<p><strong>Added:</strong></p>\n\n<p>As pointed out in the comment, the counterexample exists.</p>\n\n<p>Now I want to ask another question</p>\n\n<blockquote>\n  <p>Can we divide <span class=\"math-container\">$\\mathbb{R}^2$</span> into two path connected parts such that each part is not simply connected?</p>\n</blockquote>\n", "pids": ["53e9a9a9b7602d9703307174"], "flag": 0}
{"question": "Is there Geometric Interpretation of Spinors?", "body": "<p>Usually in Physics we define a spinor to be an element of the $\\left(\\frac{1}{2},0\\right)$ representation space of the Lorentz group. Essentially this boils down to the 'n-tuple of numbers that transforms like a spinor' definition that physicists tend to use for vectors, covectors, and tensors.</p>\n\n<p>However, vectors, covectors, and tensors also have geometric definitions that are much nicer than, and also equivalent to, the 'n-tuple of numbers' definition. For example, a vector can be thought of as an equivalence class of curves tangent at a point, or the directional derivative at a point. A covector can be thought of as a differential 1-form or as an equivalence class of functions with equal gradient at a point. Tensors are then tensor products of these spaces.</p>\n\n<p>I was wondering if there is a similar definition of spinors based in differential geometry rather than just the representation theory of the Lorentz group. If so, are these specific to certain manifolds (complex, Lorentzian, etc), or are they general to all manifolds?</p>\n", "pids": ["53e99f6ab7602d970283d8f1", "5c6109acda56297340b880b4"], "flag": 0}
{"question": "What is an example of a non standard model of Peano Arithmetic?", "body": "<p>According to <a href=\"https://johncarlosbaez.wordpress.com/2016/04/02/computing-the-uncomputable/\">here</a>, there is the \"standard\" model of Peano Arithmetic. This is defined as $0,1,2,...$ in the usual sense. What would be an example of a <em>nonstandard</em> model of Peano Arithmetic? What would a <em>nonstandard</em> amount of time be like?</p>\n", "pids": ["56d903d0dabfae2eeee94d60"], "flag": 0}
{"question": "Accessible proof of Carleson&#39;s $L^2$ theorem", "body": "<p><a href=\"http://en.wikipedia.org/wiki/Lennart_Carleson\">Lennart Carleson</a> proved Luzin's conjecture that <a href=\"http://en.wikipedia.org/wiki/Carleson%27s_theorem\">the Fourier series of each $f\\in L^2(0,2\\pi)$ converges almost everywhere</a>. Also, <a href=\"http://en.wikipedia.org/wiki/Richard_Allen_Hunt\">Richard Hunt</a> extended the result to <a href=\"http://en.wikipedia.org/wiki/Carleson%27s_theorem#CITEREFHunt1968\">$L^p$ ($p>1$)</a>.</p>\n\n<p>Some time ago I tried to read Carleson's paper, but I would say it is fairly hard to assimilate. </p>\n\n<ol>\n<li><p>Is there an easier proof? Can someone point out of the core or give an outline?</p></li>\n<li><p>What did Hunt do? Can someone give an outline of that proof?</p></li>\n</ol>\n", "pids": ["5f0e25c39fced0a24b2adce1"], "flag": 0}
{"question": "Understanding the properties and use of the Laplacian matrix (and its norm)", "body": "<p>I am reading the wikipedia article on the Laplacian matrix:</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Laplacian_matrix\" rel=\"nofollow noreferrer\">https://en.wikipedia.org/wiki/Laplacian_matrix</a></p>\n<p>I don't understand what is the particular use of it; having the diagonals as the degree and why the negative adjacency elements off the diagonal? What use would this have?</p>\n<p>Then on reading about its norm, first of all what does a norm really mean? And what is the norm for the Laplacian matrix delivering? This norm does not result in a matrix whose terms cancel out or sum to one. Or that the determinant is equal to any consistent value. Any insight?</p>\n<p>Best,</p>\n", "pids": ["61c91b095244ab9dcb96cbc4"], "flag": 0}
{"question": "Pornography and the male libido", "body": "<p>Does watching pornography reduce or otherwise affect the desire of men to have actual sex?</p>\n\n<p>This claim has been made by numerous people, including Naomi Wolf in <a href=\"http://nymag.com/nymetro/news/trends/n_9437/\">The Porn Myth</a>.</p>\n\n<p>The broader claim is often that pornography is addictive for men, an arms race where real women can't compete with the physical features of the women of pornography, nor the apparently endless sexual appetites of these on-screen women for increasingly male-dominant/female-submissive relations. If I can use a quote from Naomi Wolf's article:</p>\n\n<blockquote>\n  <p>“For the first time in human history, the images’ power and allure have supplanted that of real naked women. Today, real naked women are just bad porn.”</p>\n</blockquote>\n\n<p>What evidence is there of the actual effect of pornography on men?</p>\n", "pids": ["53e9aa16b7602d97033850ab", "53e9a44fb7602d9702d6b153"], "flag": 1}
{"question": "Weak-to-weak continuous operator which is not norm-continuous", "body": "<p>Can one give a \"relatively easy\" example of a linear mapping $T\\colon X\\to X$ ($X$ a Banach space) which is </p>\n\n<p>a) weak-to-weak continuous</p>\n\n<p>b) weak*-to-weak* continuous ($X=Y^*$)</p>\n\n<p>but not norm-to-norm continuous (not bounded). This needs some choice I guess.</p>\n", "pids": ["53e9b7d3b7602d9704383da0"], "flag": 0}
{"question": "Reference for Ergodic Theory", "body": "<p>I am looking for a good introductory book on ergodic theory. Can someone recommend  some introductory texts on that? </p>\n", "pids": ["5c757d17f56def9798aa62b0"], "flag": 1}
{"question": "Alternative set theories", "body": "<p>This is a (soft!) question for students of set theory and their teachers. </p>\n\n<p>OK: ZFC is the canonical set theory we all know and love. <em>But what other, alternative set theories, should a serious student encounter (at least to the extent of knowing that the theory exists, and about why it is thought interesting)?</em></p>\n\n<p>Suggestions might be <strong>SP</strong> (Scott-Potter), <strong>NBG</strong>, <strong>NF</strong>, <strong>ZFA</strong>, <strong>IST</strong>, <strong>ETCS</strong> (for a few sentences of explanation, see <a href=\"http://www.logicmatters.net/2013/03/tyl-14-alternative-set-theories/\">http://www.logicmatters.net/2013/03/tyl-14-alternative-set-theories/</a></p>\n\n<p>But what would be on your list of alternative set theories would be it good for advanced students to hear about, if only briefly?</p>\n", "pids": ["5d455bc93a55ac886c5efe2c", "55503f3245ce0a409eb2cc10"], "flag": 0}
{"question": "Can a prime in a Dedekind domain be contained in the union of the other prime ideals?", "body": "<p>Suppose $R$ is a Dedekind domain with a infinite number of prime ideals.  Let $P$ be one of the nonzero prime ideals, and let $U$ be the union of all the other prime ideals <em>except</em> $P$.  Is it possible for $P\\subset U$?</p>\n\n<p>As a remark, if there were only finitely many prime ideals in $R$, the above situation would not be possible by the \"<a href=\"http://commalg.wiki-site.com/index.php/Prime_avoidance_lemma\" rel=\"noreferrer\">Prime Avoidance Lemma</a>\", since $P$ would have to then be contained in one of the other prime ideals, leading to a contradiction.</p>\n\n<p>The discussion at the top of pg. 70 in Neukirch's \"Algebraic Number Theory\" motivates this question.</p>\n\n<p>Many thanks,</p>\n\n<p>John</p>\n", "pids": ["5e4d083f3a55ac8cfd770cad"], "flag": 1}
{"question": "How to calculate a confidence interval for Spearman&#39;s rank correlation?", "body": "<p><a href=\"http://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient#Determining_significance\">Wikipedia</a> has a Fisher transform of the Spearman rank correlation to an approximate z-score.  Perhaps that z-score is the difference from null hypothesis (rank correlation 0)?</p>\n\n<p><a href=\"http://www.statsdirect.com/help/nonparametric_methods/spear.htm\">This page</a> has the following example:</p>\n\n<pre><code>4, 10, 3, 1, 9, 2, 6, 7, 8, 5\n5, 8, 6, 2, 10, 3, 9, 4, 7, 1\nrank correlation 0.684848\n\"95% CI for rho (Fisher's z transformed)= 0.097085 to 0.918443\"\n</code></pre>\n\n<p>How do they use the Fisher transform to get the 95% confidence interval?</p>\n", "pids": ["56acc2b50cf29345bf3380ee", "53e9b337b7602d9703e083f9"], "flag": 1}
{"question": "If $G \\oplus H$ is isomorphic to a proper subgroup of itself, then must the same be true of one of $G$ and $H$?", "body": "<blockquote>\n<p>Let <span class=\"math-container\">$G$</span> and <span class=\"math-container\">$H$</span> are groups. If <span class=\"math-container\">$G \\oplus H$</span> is isomorphic to a proper subgroup of itself, then must the same be true of one of <span class=\"math-container\">$G$</span> and <span class=\"math-container\">$H$</span>?</p>\n</blockquote>\n<p>I found some examples of <span class=\"math-container\">$G$</span> such that <span class=\"math-container\">$G$</span> has no proper subgroup isomorphic to <span class=\"math-container\">$G$</span>.</p>\n<p>For example, <span class=\"math-container\">$\\mathbb{Q}$</span> and <span class=\"math-container\">$\\mathbb{Q}\\oplus \\mathbb{Q}$</span> has no proper  subgroup isomorphic to each mother group.</p>\n<p>(The reason: If <span class=\"math-container\">$f:\\mathbb{Q}\\oplus \\mathbb{Q}\\rightarrow\\mathbb{Q}\\oplus \\mathbb{Q}$</span> is injective group homomorphism, then <span class=\"math-container\">$f$</span> is also <span class=\"math-container\">$\\mathbb{Q}$</span>-module homomorphism, so <span class=\"math-container\">$f$</span> is <span class=\"math-container\">$\\mathbb{Q}$</span>-linear map. So, injectivity of <span class=\"math-container\">$f$</span> implies surjectivity of <span class=\"math-container\">$f$</span>. This means <span class=\"math-container\">$\\mathbb{Q}\\oplus \\mathbb{Q}$</span> has no isomorphic subgroup.)</p>\n<p>I think there is counter-example of this claim but I can't choose one..</p>\n<p>How to prove or take counter-example?</p>\n", "pids": ["53e9af75b7602d97039b9070"], "flag": 0}
{"question": "How to compute the topological space of fibered product of schemes?", "body": "<p>I know that the topological space of fibered product of schemes is generally distinct to the usual Cartesian product of toplogical spaces of schemes. Then how can we compute the top. sp. of fibered product of sch. explicitly? Is there any systematic procedure that I can do?</p>\n\n<p>Actually this question arises from when I read the Hartshorne's Algebraic Geometry. In section 4 on Chapter2, the example says that the affine line with doubled origin(I may denote it by <strong>X</strong>) is not separated over the field <strong><em>k</em></strong>. In the explanation of the book, I can see that the top. sp. of the fibered product of two <strong>X</strong> . However, I cannot understand how to compute it. (If you want the exact statement, see the p.96 of Hartshorne)</p>\n", "pids": ["56d84f2fdabfae2eeef58d5c"], "flag": 0}
{"question": "The main attacks on the Riemann Hypothesis?", "body": "<p><a href=\"http://en.wikipedia.org/wiki/Riemann_hypothesis#Attempts_to_prove_the_Riemann_hypothesis\">Attempts to prove the Riemann Hypothesis</a></p>\n\n<p>So I'm compiling a list of all the attacks and current approaches to Riemann Hypothesis. Can anyone provide me sources (or give their thoughts on possible proofs of it) on promising attacks on Riemann Hypothesis?</p>\n\n<p>My current understanding is that the field of one element is the most popular approach to RH.</p>\n\n<p>It would be good if someone started a Polymath project with the aim of proving RH. Surely, if everyone discussing possible ways to prove RH, it would be proven in about a year or so or at least people would have made a bit more progress towards the proof or disproof.</p>\n", "pids": ["5f0de4c39fced0a24bd0d0ba", "5c80f459e1cd8e544cae1ebd"], "flag": 0}
{"question": "What are some applications of Mathematics to the medical field?", "body": "<p>This semester I'm charged with finding a senior capstone project for next year. I've given it a lot of thought and can't seem to find any interesting ideas that are appropriate for my level of mathematics:</p>\n<p>I am a junior with A's in:</p>\n<ul>\n<li>ODEs/PDEs</li>\n<li>Linear Algebra</li>\n<li>Topology</li>\n<li>Organic Chemistry 1/2</li>\n<li>Cellular Biology</li>\n<li>Introduction to Biochemistry</li>\n</ul>\n<p>and am currently enrolled in Combinatorics and Complex Variables. I've approached several of my professors and asked for some project ideas but they've not given me anything at all. I'm not asking for you to give me a project to do without me having to do anything. I just want to get a feel for what some applications are to some of the more interesting fields, like Combinatorics and something that is somewhat related to all this, Chaos Theory.</p>\n", "pids": ["5c0f8575da562944ac90ca63"], "flag": 1}
{"question": "What is a zeta function?", "body": "<p>In my readings, I've come across a wide variety of objects called zeta functions. For example, the Ihara zeta function, Igusa local zeta function, Hasse-Weil zeta function, etc. My question is simple: What makes something a zeta function? There are a couple things that the zeta functions I've seen have in common. For example: they're usually defined as some sort of infinite sum, have an Euler product and a functional equation. Also, rationality of certain zeta functions seems to be an important idea. Is there any way to understand this from a \"big picture\" point of view? </p>\n", "pids": ["53e9b2f9b7602d9703db897b"], "flag": 0}
{"question": "Looking for a clear definition of the geometric product", "body": "<p><strong>In brief:</strong> I'm looking for a clearly-worded definition<sup>1</sup> of the geometric product of two <em>arbitrary multivectors</em> in <span class=\"math-container\">$\\mathbb{G}^n$</span>.</p>\n<hr />\n<p>I'm having a hard time getting my bearings in the world of &quot;geometric algebra&quot;, even though I'm using as my guide an introductory undergraduate-level<sup>2</sup> book (<em>Linear and  geometric algebra</em> by Macdonald).</p>\n<p>Among the general problems that I'm running into is that most definitions and theorems that I find (either in this book, <em>or online</em>) seem to apply to <em>some</em> multivectors (e.g. to <span class=\"math-container\">$k$</span>-vectors, or to blades), not all.  Sometimes it is not clear to me whether a definition or result refers to all multivectors in <span class=\"math-container\">$\\mathbb{G}^n$</span> or only to a distinguished subset (e.g. blades), since these definitions/theorems are expressed in terms the word &quot;vector&quot;.  This leads to the pervading doubt as to whether this word &quot;vector&quot; is being meant as synonymous with &quot;multivector&quot;—i.e. an object in the so-called &quot;<em><strong>vector</strong></em> space <span class=\"math-container\">$\\mathbb{G}^n\\;$</span>&quot;)—, or with &quot;<span class=\"math-container\">$1$</span>-vector&quot;, or with &quot;<span class=\"math-container\">$k$</span>-vector&quot;, or something else entirely.</p>\n<p>(Hence the specification &quot;clearly-worded&quot; in my question above.  A more accurate specification would have been &quot;unambiguously-worded&quot;, but it would have been puzzling on first encounter.)</p>\n<p>Case in point is the definition of the geometric product in <span class=\"math-container\">$\\mathbb{G}^n$</span>.  Macdonald gives a very partial definition of this product for &quot;vectors&quot; (and only in <span class=\"math-container\">$\\mathbb{G}^3$</span>)<sup>3</sup>, but far as I can tell Macdonald <em>never defines this product in general, even though he uses it freely throughout much of the book!</em>  I find this astonishing, to put it mildly.  But, <em>please correct me if I'm wrong.</em></p>\n<hr />\n<p><sub><sup>1</sup>In his <a href=\"https://math.stackexchange.com/a/446895/13675\">answer below</a> Alan Macdonald writes &quot;I do not think it possible to give a quick definition of the general geometric product.&quot;  In light of this remark, I want to stress that succinctness is not among the requirements in my specifications what I'm looking for.\n</sub></p>\n<p><sub><sup>2</sup>The original version of this post incorrectly described this book as being written for &quot;high-school students&quot;, but the author pointed out this error in his <a href=\"https://math.stackexchange.com/a/446895/13675\">answer below</a>.  I apologize for the (now-amended) inaccuracy.</sub></p>\n<p><sub><sup>3</sup> On p. 82, Macdonald gives a definition for the geometric product of two <span class=\"math-container\">$1$</span>-vectors in <span class=\"math-container\">$\\mathbb{G}^3$</span>, and later explicitly states: &quot;We have defined the geometric product of two vectors, but not for example, the geometric product of a vector and a bivector.  This will be taken up in the next chapter, where we will learn to take the geometric product of any two multivectors.&quot;  As far as I can tell, however, the &quot;next chapter&quot;, which is called simply <span class=\"math-container\">$\\mathbb{G}^n$</span>, never fulfills this promise.  Or at least, it never gives a definition for the geometric product of any two multivectors in <span class=\"math-container\">$\\mathbb{G}^n$</span>.</sub></p>\n", "pids": ["53e9bd50b7602d97049e4c2b"], "flag": 0}
{"question": "Prove that $\\sum\\limits_{k=0}^{n-1}\\dfrac{1}{\\cos^2\\frac{\\pi k}{n}}=n^2$ for odd $n$", "body": "<p>In old popular science magazine for school students I've seen problem</p>\n\n<blockquote>\n  <p>Prove that $\\quad $\n  $\\dfrac{1}{\\cos^2 20^\\circ} + \n\\dfrac{1}{\\cos^2 40^\\circ} + \n\\dfrac{1}{\\cos^2 60^\\circ} + \n\\dfrac{1}{\\cos^2 80^\\circ} = 40. $</p>\n</blockquote>\n\n<p>How to prove more general identity:</p>\n\n<p>$$\n\\begin{array}{|c|}\n\\hline \\\\\n\\sum\\limits_{k=0}^{n-1}\\dfrac{1}{\\cos^2\\frac{\\pi k}{n}}=n^2 \\\\\n\\hline\n\\end{array}\n,  \\qquad \\mbox{ where } \\ n \\ \\mbox{ is odd.}$$</p>\n", "pids": ["53e9b381b7602d9703e643db"], "flag": 0}
{"question": "Universally measurable sets of $\\mathbb{R}^2$", "body": "<p>$$\\text{Is }{{\\cal B}(\\mathbb{R}^2})^u={{\\cal B}(\\mathbb{R}})^u\\times {{\\cal B}(\\mathbb{R}})^u\\,?\\tag1$$</p>\n\n<p>Is the $\\sigma$-algebra of <a href=\"http://en.wikipedia.org/wiki/Universally_measurable_set\">universally measurable sets</a> on $\\mathbb{R}^2$ equal to the \nproduct $\\sigma$-algebra of two copies of the universally measurable sets on $\\mathbb{R}$? It is not hard\nto see that (1) is true with $\\supseteq$ instead of $=$,\nand I would be astonished if (1) were true, but I'm not sure. </p>\n\n<p>Has anyone encountered this problem, or know a reference that might help?  </p>\n", "pids": ["53e9ab14b7602d970349c9d7", "622833285aee126c0fb61b54"], "flag": 0}
{"question": "What are the most important factors influencing a person’s gut microbes?", "body": "<blockquote>\n  <p><strong>You are your bacteria! The probiotics and the antibiotics...</strong></p>\n</blockquote>\n\n<p>There has been on going discussions about how our gut bacteria is important for a healthy lifestyle. </p>\n\n<blockquote>\n  <p><strong>Figure 1:</strong> Schematic diagram illustrating potential or known mechanisms\n  whereby probiotic bacteria might impact on the microbiota. These\n  mechanisms include (1) competition for dietary ingredients as growth\n  substrates, (2) bioconversion of, for example, sugars into\n  fermentation products with inhibitory properties, (3) production of\n  growth substrates, for example, EPS or vitamins, for other bacteria,\n  (4) direct antagonism by bacteriocins, (5) competitive exclusion for\n  binding sites, (6) improved barrier function, (7) reduction of\n  inflammation, thus altering intestinal properties for colonization and\n  persistence within, and (8) stimulation of innate immune response (by\n  unknown mechanisms). IEC: epithelial cells, DC: dendritic cells,\n  T:T-cells. For further details, see main text.</p>\n</blockquote>\n\n<p><a src=\"https://i.stack.imgur.com/DGl2X.jpg\" alt=\"enter image description here\"></p>\n\n<p>Also, an online search provides numerous articles about diet aspect that alters our gut bacteria. </p>\n\n<p>e.g.</p>\n\n<p><code>1.</code><a href=\"http://www.livescience.com/41869-gut-bacteria-change-diet.html\" rel=\"noreferrer\">A New Diet Quickly Alters Gut Bacteria-<em>(not sure about the credibility and relevance to humans as the study is on mice)</em></a></p>\n\n<p><code>2.</code><a href=\"http://www.medicaldaily.com/artificial-sweeteners-change-how-our-gut-bacteria-work-paving-way-diabetes-and-obesity-303562\" rel=\"noreferrer\">Artificial Sweeteners Change How Our Gut Bacteria Work, Paving The Way To Diabetes And Obesity</a></p>\n\n<p><code>3.</code><a href=\"http://newsroom.ucla.edu/releases/changing-gut-bacteria-through-245617\" rel=\"noreferrer\">Changing gut bacteria through diet affects brain function</a></p>\n\n<p>As far as the GIT is concerned, health, lifestyle, eating habits and the environment a person is living may be at large influence and affect one's gut microbes.</p>\n\n<p>Are there day to day encounters, in-depth examples and references that can prove the <strong>factors</strong> which influence our gut microbes the most?</p>\n", "pids": ["55a6cfb565ce054aad76c168"], "flag": 1}
{"question": "Closed form for $ S(m) = \\sum_{n=1}^\\infty \\frac{2^n \\cdot n^m}{\\binom{2n}n} $ for integer $m$?", "body": "<p>What is the (simple) closed form for $\\large \\displaystyle S(m) = \\sum_{n=1}^\\infty \\dfrac{2^n \\cdot n^m}{\\binom{2n}n} $ for integer $m$?</p>\n\n<p>Notation: $ \\dbinom{2n}n $ denotes the central binomial coefficient, $ \\dfrac{(2n)!}{(n!)^2} $.</p>\n\n\n\n<p>We have the following examples (all verified by WolframAlpha) for $ m\\geq 0$:</p>\n\n<p>$$\\begin{eqnarray} \nS(0) &amp;=&amp;\\sum_{n=1}^\\infty \\dfrac{2^n }{\\binom{2n}n} = 2+ \\dfrac{\\pi}2 \\\\\nS(1) &amp;=&amp;\\sum_{n=1}^\\infty \\dfrac{2^n \\cdot n }{\\binom{2n}n} = 3+ \\pi \\\\\nS(2) &amp;=&amp;\\sum_{n=1}^\\infty \\dfrac{2^n \\cdot n^2 }{\\binom{2n}n} = 11+ \\dfrac{7\\pi}2 \\\\\nS(3) &amp;=&amp;\\sum_{n=1}^\\infty \\dfrac{2^n \\cdot n^3 }{\\binom{2n}n} = 55+ \\dfrac{35\\pi}2 \\\\\nS(4) &amp;=&amp;\\sum_{n=1}^\\infty \\dfrac{2^n \\cdot n^4 }{\\binom{2n}n} = 355 + 113\\pi \\approx \\underline{709.9999}698 \\ldots , \\quad \\text{So close to an integer? Coincidence?} \\\\\nS(5) &amp;=&amp;\\sum_{n=1}^\\infty \\dfrac{2^n \\cdot n^5 }{\\binom{2n}n} = 2807+ \\dfrac{1787\\pi}2 \\\\\nS(6) &amp;=&amp;\\sum_{n=1}^\\infty \\dfrac{2^n \\cdot n^6 }{\\binom{2n}n} = 26259+ \\dfrac{16717\\pi}2 \\\\\nS(7) &amp;=&amp;\\sum_{n=1}^\\infty \\dfrac{2^n \\cdot n^7 }{\\binom{2n}n} = 283623+ 90280\\pi \\\\\n\\end{eqnarray} $$ </p>\n\n<p>And for $ m&lt;0 $ as well (all verified by WolframAlpha as well):</p>\n\n<p>$$\\begin{eqnarray} \nS(-1) &amp;=&amp;\\sum_{n=1}^\\infty \\dfrac{2^n \\frac 1 n}{\\binom{2n}n} = \\dfrac{\\pi}2 \\\\\nS(-2) &amp;=&amp;\\sum_{n=1}^\\infty \\dfrac{2^n \\frac 1 {n^2} }{\\binom{2n}n} = \\dfrac{\\pi^2 }8 \\\\\nS(-3) &amp;=&amp;\\sum_{n=1}^\\infty \\dfrac{2^n \\frac 1 {n^3} }{\\binom{2n}n} = \\pi G - \\dfrac{35\\zeta(3)}{16} + \\dfrac18 \\pi^2 \\ln2, \\quad  G \\text{ denotes Catalan's constant} \\\\\n\\end{eqnarray} $$ </p>\n\n<p><strong>So a natural question arise</strong>: Is there a closed form for $S(m) $ for all integers $ m$?</p>\n\n\n\n<p>For what it's worth, I couldn't get the (simple) closed form (using WolframAlpha alone) of $S(-4), S(-5), S(-6), \\ldots $ and $ S(8), S(9) , \\ldots $ without expressing it in terms of hypergeometric functions.</p>\n\n<p>My question is: <strong>Is there a closed form of $S(m) $ for all integers $m$ without using hypergeometric functions? And how do I compute all of these values?</strong></p>\n\n<p>Note that I don't consider hypergeometric functions to be a \"legitimate\" function because it defeats the purpose of this question.</p>\n\n\n\n<p><strong>My motivation</strong>: I was trying to solve this <a href=\"https://math.stackexchange.com/questions/1771881/show-that-sum-n-0-infty-frac2n5n55n45n35n2-9n92n12n2\">question</a> and I decided to use the hint suggested by Mandrathrax, that is to use <a href=\"http://www.wolframalpha.com/input/?i=partial+fractions,+(5x%5E5%2B+5x%5E4+%2B+5x%5E3+%2B+5x%5E2+-9x%2B9)%2F((2x%2B1)(2x%2B2)(2x%2B3))\" rel=\"noreferrer\">partial fractions</a> to get </p>\n\n<p>$$ \\dfrac{5n^5+5n^4+5n^3+5n^2-9n+9}{(2n+1)(2n+2)(2n+3)} = \\dfrac{5n^2}8 - \\dfrac{5n}8 - \\dfrac9{n+1} + \\dfrac{457}{64(2n+1)} + \\dfrac{135}{64(2n+3)} + \\dfrac{85}{32} $$</p>\n\n<p>So if I can prove the values of $ S(0), S(1), S(2) $ (which I failed to do so), then I'm pretty sure I'm halfway done with my solution.</p>\n\n<p>Why do I still want to solve that question when it already has 21 upvotes? Because I think there's a simpler solution and I personally don't like to use polylogarithms. </p>\n\n\n\n<p><strong>My feeble attempt (with help from my friends Aareyan and Julian) to solve my own question</strong>: The Taylor series of $ (\\arcsin x)^2  $ is $ \\displaystyle \\dfrac12 \\sum_{n=1}^\\infty \\dfrac1{n^2 \\binom{2n}n} (2x)^n $. Differentiating with respect to $ x $ then multiply by $ x $ (repeatedly) gives some resemblance of $S(m)$, but these series only holds true for $|x| &lt; 1$ and not $x=1$ itself. Now I'm stucked.</p>\n\n\n\n<p><strong>EDIT1</strong> (14 May 2016, 1101 GMT): Twice the coefficients of $\\pi$ for $S(m)$ with $m\\geq0$ appears to follow this <a href=\"http://oeis.org/A014307\" rel=\"noreferrer\">OEIS sequence, A014307</a>.</p>\n\n<p><strong>EDIT2</strong> (14 May 2016, 1109 GMT): The constant for $S(m)$ with $m\\geq1$ appears to follow this <a href=\"http://oeis.org/A180875\" rel=\"noreferrer\">OEIS sequence, A180875</a>.</p>\n", "pids": ["53e99a85b7602d97022f8be9", "56d8997ddabfae2eee2b0f5f", "53e99f19b7602d97027e6a27", "53e9a49db7602d9702dbf598", "53e9a91ab7602d970326b291"], "flag": 0}
{"question": "Number of vectors so that no two subset sums are equal", "body": "<p>Consider all $10$-tuple vectors each element of which is either $1$ or $0$. It is very easy to select a set $v_1,\\dots,v_{10}= S$ of $10$ such vectors so that no two distinct subsets of vectors $S_1 \\subset S$ and $S_2 \\subset S$  have the same sum. Here $\\sum_{v \\in S_i} v$ assumes simple element-wise addition over $\\mathbb{R}$.  For example, if we take the vectors that are the columns of the identity matrix as $S$ this will do.   </p>\n\n<p>What is the maximum number of vectors one can choose that have this property?  Is there a counting argument that solves this?</p>\n\n\n\n<p>A small clarification. The sum of two vectors in this problem is another vector.</p>\n\n\n\n<p><strong>Current records:</strong></p>\n\n<ul>\n<li>Lower bound: $19$. First given by Brendan McKay over at MO.</li>\n<li>Upper bound: $30$. First given by Brendan McKay over at MO.</li>\n</ul>\n\n\n\n<p>Cross-posted to <a href=\"https://mathoverflow.net/questions/157634/number-of-vectors-so-that-no-two-subset-sums-are-equal\">https://mathoverflow.net/questions/157634/number-of-vectors-so-that-no-two-subset-sums-are-equal</a></p>\n", "pids": ["53e9aa67b7602d97033dc55b"], "flag": 0}
{"question": "What is a moduli space for a differential geometer?", "body": "<p>A moduli space is a set that parametrizes objects with a fixed property and that is endowed with a particular structure. This should be an intuitive and general definition of what a moduli space is.</p>\n\n<p>Now, in the contest of algebraic geometry, we refer to a moduli space as a scheme that (co)represents a particular functor, i.e.\n\\begin{equation}\n\\mathcal{M}:\\,\\{\\mathfrak{schemes}\\}^{\\circ}\\longrightarrow\\{\\mathfrak{sets}\\}\n\\end{equation}\nthat is called the $moduli \\,functor$. The question if it is (co)representable is called the $moduli \\;problem$.</p>\n\n<p>My question is, how does a differential geometer image a moduli space? That is, I thought that he thinks it in the same above way (replacing the category of schemes with a more suitable category), but it turns out that it is not so.</p>\n\n<p>thank you!</p>\n\n<p>EDIT: I have seen some people still look at this post, so maybe it is worth to add something. First of all,  the geometry of a $C^{\\infty}$-manifold is much less rigid than that one of an algebraic variety. This reflects, for example, on the fact that in general we can find a lot automorphisms of the objects we are interested in. In particular, most of the cases (and probably 'all' the cases) we have no hope to get a fine moduli space: this justify the fact that, in differential geometry, one usually talks about moduli space without specify if it is fine or not. </p>\n\n<p>Secondly, regarding my description of the moduli problem. I have recently looked at the theory of $C^{\\infty}$-schemes (see <a href=\"http://arxiv.org/pdf/1104.4951v2.pdf\" rel=\"noreferrer\">http://arxiv.org/pdf/1104.4951v2.pdf</a>). This is a generalization of the concept of a $C^{\\infty}$-manifold in the same way as a scheme is a generalization of an algebraic variety. An interesting aspect of this theory is, for example, that a $C^{\\infty}$-manifold is always an affine $C^{\\infty}$-scheme. Replacing the category of $C^{\\infty}$-schemes in the moduli functor defined above, we can think at a moduli space of $C^{\\infty}$-objects in the classical algebraic way. Moreover, this leads in a natural way to a theory of derived differential geometry.</p>\n\n<p>Finally, I feel quite confident with this. Neverthless, this theory is modelled on the algebraic analogue and it is very recent. Even if my interests are principally on algebraic geometry, I had asked this question because I was wondering how mathematicians from different areas of mathematics approach to the problem of studying moduli spaces (the basic aim was to better understand the mathematical feeling behind these objects). And since moduli spaces in differential geometry were studied before (or at least without) the theory of $C^{\\infty}$-schemes, my primary question is still not anwered. </p>\n", "pids": ["56d866d6dabfae2eeea6e38d"], "flag": 0}
{"question": "What is the essential difference between ordinary differential equations and partial differential equations?", "body": "<p>Please forgive my stupidity. </p>\n\n<p>So many years after my undergraduate study and so many years after dealing with various concrete ODEs and PDEs, I still cannot tell the <strong>essential</strong> difference between them. </p>\n\n<p>What specific belongs to PDEs but not to ODEs? What conclusion for ODEs cannot be generalized to PDEs? </p>\n\n<p>At the moment, my understanding is simply that PDEs have more than one variables. </p>\n", "pids": ["5c757cc0f56def9798a6f7e2"], "flag": 0}
{"question": "Every point of a grid is colored in blue, red or green. How to prove there is a monochromatic rectangle?", "body": "<p>I have a $3$-coloring of $\\mathbb{Z}\\times\\mathbb{Z}$, i.e. a function $f:\\mathbb{Z}\\times\\mathbb{Z}\\to\\{\\color{red}{\\text{red}},\\color{green}{\\text{green}},\\color{blue}{\\text{blue}}\\}$.</p>\n\n<p>I have to prove that there is a monochromatic rectangle with its sides being parallel to the axis, i.e. to prove that for some choice of $a,b,c,d\\in\\mathbb{Z}$ with $a\\neq b$ and $c\\neq d$, all the points $(a,c),(a,d),(b,c),(b,d)\\,$ have the same color.</p>\n\n<p>I tried to work by contradiction, without achieving much.</p>\n\n<p>Additionally, can we prove some upper bound on $|a-b|$ and $|c-d|$?</p>\n", "pids": ["53e9abc4b7602d9703572d64"], "flag": 0}
{"question": "What is the meaning of infinitesimal?", "body": "<p>I have read that an infinitesimal is very small, it is unthinkably small but I am not quite comfortable with with its applications. My first question is that is an infinitesimal a stationary value? It cannot be a stationary value because if so then a smaller value on real number line exist, so it must be a moving value. Moving value towards $0$ so in most places we use its magnitude equal to zero but at the same time we also know that infinitesimal is not equal so in all those places were we use value of infinitesimal equal to $0$ we are making an infinitesimal error and are not $100\\%$ accurate, maybe $99.9999\\dots\\%$ accurate, but no $100\\%$! So please explain infinitesimal and its applications and methodology in context to the above paragraph or elsewise intuitively please.</p>\n", "pids": ["5f0e75089fced0a24b8bb614"], "flag": 0}
{"question": "Evaluate $\\int_{0}^{\\pi }\\theta ^{3}\\log^{3}\\left ( 2\\sin\\frac{\\theta }{2} \\right )\\mathrm{d}\\theta $", "body": "<p>Evaluate</p>\n\n<blockquote>\n  <p><span class=\"math-container\">$$\\int_{0}^{\\pi }\\theta ^{3}\\log^{3}\\left ( 2\\sin\\frac{\\theta }{2} \\right )\\,\\mathrm{d}\\theta $$</span></p>\n</blockquote>\n\n<p>Several days ago,I found this interesting integral from a paper about generalized log-sine integrals,but I can't remember the title of it. The answer of the integral is</p>\n\n<blockquote>\n  <p><span class=\"math-container\">\\begin{align*}\n-\\mathrm{Ls}_{7}^{\\left ( 3 \\right )}\\left ( \\pi  \\right)&amp;=\\frac{9}{35}\\log^72+\\frac{4}{5}\\pi ^{2} \\log^52+9\\zeta \\left ( 3 \\right )\\log^42-\\frac{31}{30}\\pi ^{4}\\log^32\\\\\n&amp;-\\left [ 72\\mathrm{Li}_5\\left ( \\frac{1}{2} \\right )-\\frac{9}{8}\\zeta \\left ( 5 \\right )-\\frac{51}{4}\\pi ^{2}\\zeta \\left ( 3 \\right ) \\right ]\\log^22\\\\\n&amp;+\\left [ 72\\mathrm{Li}_{5,1}\\left ( \\frac{1}{2} \\right )-216\\mathrm{Li}_6\\left ( \\frac{1}{2} \\right )+36\\pi ^{2}\\mathrm{Li}_4\\left ( \\frac{1}{2} \\right ) \\right ]\\log2+72\\mathrm{Li}_{6,1}\\left ( \\frac{1}{2} \\right )\\\\\n&amp;-216\\mathrm{Li}_7\\left ( \\frac{1}{2} \\right )+36\\pi ^{2}\\mathrm{Li}_5\\left ( \\frac{1}{2} \\right )-\\frac{1161}{32}\\zeta \\left ( 7 \\right )-\\frac{375}{32}\\pi ^{2}\\zeta \\left ( 5 \\right )+\\frac{1}{10}\\pi ^{4}\\zeta \\left ( 3 \\right )\n\\end{align*}</span>\n  where \n  <span class=\"math-container\">$$\\mathrm{Ls}_n^{\\left ( k \\right )}\\left ( \\alpha  \\right ):=-\\int_{0}^{\\alpha }\\theta ^{k}\\log^{n-1-k}\\left | 2\\sin\\frac{\\theta }{2} \\right |\\mathrm{d}\\theta $$</span>\n  is the generalized log-sine integral and\n  <span class=\"math-container\">$$\\mathrm{Li}_{\\lambda ,1}\\left ( z \\right )=\\sum_{k=1}^{\\infty }\\frac{z^{k}}{k^{\\lambda }}\\sum_{j=1}^{k-1}\\frac{1}{j}$$</span>\n  is the multiple polylogarithm.</p>\n</blockquote>\n\n\n\n<p>I found a beautiful way to solve the integrals below\n<span class=\"math-container\">$$\\int_{0}^{\\frac{\\pi }{2}}t^{2n}\\log^{m}\\left ( 2\\cos t  \\right )\\mathrm{d}t $$</span>\nLet's consider\n<span class=\"math-container\">$$\\mathcal{I}\\left ( x,y \\right )=\\int_{0}^{\\frac{\\pi }{2}}\\cos\\left ( xt \\right )\\left ( 2\\cos t \\right )^{y}\\mathrm{d}t$$</span>\nBy using Gamma function,the integral become\n<span class=\"math-container\">$$\\mathcal{I}\\left ( x,y \\right )=\\frac{\\pi \\, \\Gamma \\left ( y+1 \\right )}{2\\Gamma \\left ( \\dfrac{x+y+2}{2} \\right )\\Gamma \\left ( \\dfrac{y-x+2}{2} \\right )}$$</span> \nThen we can get\n<span class=\"math-container\">$$\\mathcal{I}\\left ( x,y \\right )=\\frac{\\pi }{2}\\exp\\left ( \\sum_{k=2}^{\\infty }\\frac{\\left ( -1 \\right )^{k}}{k\\cdot 2^{k}}\\zeta \\left ( k \\right )\\left [ \\left ( 2y \\right )^{k}-\\left ( y-x \\right )^{k}-\\left ( x+y \\right )^{k} \\right ] \\right )$$</span>\nOn the other hand,using taylor series \n<span class=\"math-container\">$$\\mathcal{I}\\left ( x,y \\right )=\\sum_{n=0}^{\\infty }\\frac{\\left ( -1 \\right )^{n}}{\\left ( 2n \\right )!}x^{2n}\\sum_{m=0}^{\\infty }\\frac{y^{m}}{m!}\\int_{0}^{\\frac{\\pi }{2}}t^{2n}\\log^m\\left ( 2\\cos t \\right )\\mathrm{d}t$$</span>\nSo,the comparison of coefficient shows the answer.For example\n<span class=\"math-container\">$$\\int_{0}^{\\frac{\\pi }{2}}t^{2}\\log^2\\left ( 2\\cos t \\right )\\mathrm{d}t=4\\cdot \\frac{\\pi }{2}\\left [ \\frac{12}{4\\cdot 16} \\zeta \\left ( 4 \\right )+\\frac{1}{2}\\frac{8}{2^{2}\\cdot 4^{2}}\\zeta \\left ( 2 \\right )^{2}\\right ]=\\frac{11}{1440}\\pi ^{5}$$</span></p>\n\n\n\n<p>I wonder can we use the same way to prove the integral in the beginning,if not,is there another way to handle it? </p>\n", "pids": ["56d82003dabfae2eeeb5a76d"], "flag": 0}
{"question": "Why doesn&#39;t the independence of the continuum hypothesis immediately imply that ZFC is unsatisfactory?", "body": "<p>I am risking a \"possible duplicate of... \" here, in particular with respect to <a href=\"https://math.stackexchange.com/questions/2445262/doesnt-the-unprovability-of-the-continuum-hypothesis-prove-the-continuum-hypoth\">this question</a>, <a href=\"https://math.stackexchange.com/questions/189471/why-is-the-continuum-hypothesis-not-true\">this question</a>, and <a href=\"https://math.stackexchange.com/questions/499560/why-is-the-continuum-hypothesis-believed-to-be-false-by-the-majority-of-modern-s?noredirect=1&amp;lq=1\">this question</a>. Nevertheless here goes.</p>\n\n<p>I am going to keep this question as simple as possible:</p>\n\n<p>First note two facts:</p>\n\n<ol>\n<li><p>It has been proven that CH is independent of ZFC.</p></li>\n<li><p>ZFC is intended as a foundational system of mathematics.</p></li>\n</ol>\n\n<p>Secondly: the independence of CH from ZFC has (if I understand it correctly) led many people to state that <strong>\"CH is neither true nor false\"</strong>. </p>\n\n<p><strong>My response is:</strong> It seems to me that the independence of CH from ZFC cannot be \"blamed\" on CH, but should be ZFC's responsibility, for the simple reason that <strong>CH never had any pretention of being in any way related to the ZFC</strong> axioms, while the <strong>ZFC axioms claim to be a foundation of mathematics.</strong> </p>\n\n<p>Therefore if ZFC and CH are independent, this says absolutely nothing about the truth-status of CH, and merely implies that ZFC is inadequate. ZFC is merely one possible axiomatizations that some smart people came up with a long time ago, so why don't we take ZFC with a grain of salt. <strong>Why do people disagree with my argument, and instead claim that the independence of ZFC and CH implies that CH is \"neither true nor false\"?</strong></p>\n", "pids": ["53e9ad63b7602d970374856a"], "flag": 0}
{"question": "What is the value of $\\left(\\frac{1}{2}\\right)^{\\left(\\frac{1}{3}\\right)^{\\left(\\frac{1}{4}\\right)^{\\unicode{x22F0}}}}$?", "body": "<h4>Motivation</h4>\n<p>I have been thinking about this thing for quite a while now. I have tried many ways but couldn't really figure it out.</p>\n<p>I am pretty sure that this kind of expressions don't really have a closed form, so I am asking for other representation for example maybe in terms of an infinite sum or product or something.</p>\n<h4>Creating A New Notation</h4>\n<p>Just like there is a notation for a sum <span class=\"math-container\">$\\textstyle\\displaystyle{\\sum_{n=a}^{b}s_n=s_a+\\cdots+s_b}$</span> and also for a product <span class=\"math-container\">$\\textstyle\\displaystyle{\\prod_{n=a}^{b}s_n=s_a\\cdots s_b}$</span>, I was quite surprised that there wasn't  any notation for exponentiation.</p>\n<p>I would agree that there wouldn't be any use for this notation but still, why would no mathematician ever would create such a notation just for the sake of curiosity. That is why I would request readers to give me any references if there are any. I haven't found any, so I am creating my own. Let <span class=\"math-container\">$$\\boxed{\\textstyle\\displaystyle{{\\huge\\varepsilon\\normalsize}_{k=a}^{b}s_k=s_a^{\\unicode{x22F0}^{s_b}}}}$$</span> where <span class=\"math-container\">$b&gt;a$</span>. If <span class=\"math-container\">$a&gt;b$</span> then <span class=\"math-container\">$\\textstyle\\displaystyle{{\\huge\\varepsilon\\normalsize}_{k=a}^{b}s_k=1}$</span> and <span class=\"math-container\">$\\textstyle\\displaystyle{{\\huge\\varepsilon\\normalsize}_{k=a}^{b}x=^{b-a+1}x}$</span>. Obviously <span class=\"math-container\">$a,b\\in\\mathbb{Z}$</span>.</p>\n<p>Unlike product and sum, exponentiation isn't commutative so we have to be careful when using the notation. Maybe we can modify it a little bit to include the ordering.</p>\n<p>By the way we are defining <span class=\"math-container\">$\\textstyle\\displaystyle{{\\huge\\varepsilon\\normalsize}_{k=a}^{\\infty}s_k:= \\lim_{n\\rightarrow\\infty}\\left({\\huge\\varepsilon\\normalsize}_{k=a}^{n}s_k\\right)}.$</span></p>\n<h4>Some Natural Questions</h4>\n<p>When written out in the form of this notation, some natural curious questions arrive or at least some arrived in my mind, for example <span class=\"math-container\">$\\textstyle\\displaystyle{{\\huge\\varepsilon\\normalsize}_{k=2}^{\\infty}\\frac{1}{k^s}}$</span> and <span class=\"math-container\">$\\textstyle\\displaystyle{{\\huge\\varepsilon\\normalsize}_{k=2}^{\\infty}\\frac{1}{n}}$</span>.</p>\n<h4>My Curiosity</h4>\n<p>My initial curiosity was <span class=\"math-container\">$H=\\textstyle\\displaystyle{{\\huge\\varepsilon\\normalsize}_{k=2}^{\\infty}\\frac{1}{k}=\\left(\\frac{1}{2}\\right)^{\\left(\\frac{1}{3}\\right)^{\\left(\\frac{1}{4}\\right)^{\\unicode{x22F0}}}}}$</span>.</p>\n<p>As pointed out by Tavish in the comments, this can be written as a recurrence relation given by <span class=\"math-container\">$$\\textstyle\\displaystyle{a_{n+1}=-\\frac{\\ln(a_n)}{\\ln(n)}}$$</span> where <span class=\"math-container\">$\\textstyle\\displaystyle{a_n=\\left(\\frac{1}{n}\\right)^{\\left(\\frac{1}{n+1}\\right)^{\\unicode{x22F0}}}}$</span>. Solving this will help us derive <span class=\"math-container\">$H$</span>.</p>\n<p>But as pointed out in the comments and in <a href=\"https://math.stackexchange.com/q/1458506/831748\">this question</a> (<strong>Note that this question focuses on the convergence of <span class=\"math-container\">$H$</span>, while my question focuses on something different</strong>), <span class=\"math-container\">$H$</span> doesn't really make much sense by the definition of infinite power tower above because it seems that <span class=\"math-container\">$$\\textstyle\\displaystyle{\\lim_{n\\rightarrow\\infty}\\left({\\huge\\varepsilon\\normalsize}_{k=2}^{2n}\\frac{1}{k}\\right)\\neq\\lim_{n\\rightarrow\\infty}\\left({\\huge\\varepsilon\\normalsize}_{k=2}^{2n+1}\\frac{1}{k}\\right)}.$$</span> In particular, we have</p>\n<p><span class=\"math-container\">\\begin{align}H_O&amp;=\\lim_{n\\rightarrow\\infty}\\left({\\huge\\varepsilon\\normalsize}_{k=2}^{2n+1}\\frac{1}{k}\\right)=0.6903471261\\cdots\\\\H_E&amp;=\\lim_{n\\rightarrow\\infty}\\left({\\huge\\varepsilon\\normalsize}_{k=2}^{2n}\\frac{1}{k}\\right)=0.6583655992\\cdots\\end{align}</span></p>\n<p>Let <span class=\"math-container\">$E_n=\\textstyle\\displaystyle{{\\huge\\varepsilon\\normalsize}_{k=2}^{2n}\\frac{1}{k}}$</span> and <span class=\"math-container\">$O_n=\\textstyle\\displaystyle{{\\huge\\varepsilon\\normalsize}_{k=2}^{2n+1}\\frac{1}{k}}$</span>. I tried constructing a recurrence relation for <span class=\"math-container\">$E_n$</span> and <span class=\"math-container\">$O_n$</span>, but couldn't, except <span class=\"math-container\">\\begin{align}E_{n+1}&amp;=\\left(\\log_{\\frac{1}{2n-1}}(\\cdots\\log_{\\frac{1}{2}}(E_n))\\right)^{\\left(\\frac{1}{2n+1}\\right)^{\\left(\\frac{1}{2n+2}\\right)}}\\\\O_{n+1}&amp;=\\left(\\log_{\\frac{1}{2n}}(\\cdots\\log_{\\frac{1}{2}}(O_n))\\right)^{\\left(\\frac{1}{2n+2}\\right)^{\\left(\\frac{1}{2n+3}\\right)}}\\end{align}</span> which is not really workable. If there is a way to simplify it then please do tell me or write a partial answer about it, because it would help us a lot in finding the values of <span class=\"math-container\">$H_E$</span> and <span class=\"math-container\">$H_O$</span>.</p>\n<h4>My Question</h4>\n<p>I am pretty sure that there really isn't closed form of <span class=\"math-container\">$H_E$</span> and <span class=\"math-container\">$H_O$</span>.</p>\n<p><strong>So I am asking for a different representation for those constants, maybe as a sum or an integral possibly?</strong></p>\n", "pids": ["56d8e6aadabfae2eee359a5c"], "flag": 0}
{"question": "Theorems true &quot;with probability 1&quot;?", "body": "<p>This question is inspired by <a href=\"https://math.stackexchange.com/questions/45594/theorems-which-were-shown-to-be-true-with-probability-zero-closed\">this closed question</a>, per a suggestion on meta.</p>\n\n<p>Some statements believed to be true are difficult to prove with current tools. However, there are some intuitive arguments to support them, some of them precise and some of them imprecise.</p>\n\n<p>An example of a precise argument are random oracle results in computational complexity. A typical results states that under a random oracle, the classes P, NP, coNP are all different <em>with probability 1</em>. The methods used to prove this are not believed to be strong enough to actually prove the respective conjectures, since there exist oracles under which (for example) P=NP.</p>\n\n<p>Examples of imprecise arguments abound in number theory. One can argue that there are \"probably\" only finitely many Fermat primes, and one can come up with a heuristic estimate of the density of twin primes.</p>\n\n<p>A lot of factorization algorithms are analyzed only heuristically. However, in the case of the quadratic sieve, there is also a rather more complicated argument that shows that a variant of the quadratic sieve actually performs as advertised.</p>\n\n<p>Examples of slightly different flavor are the host of results proved under the Riemann Hypothesis and its relatives. The celebrated AKS primality testing algorithm can be seen as an upgraded version of earlier algorithms whose analysis is conditional of RH; AKS provably performs as advertized.</p>\n\n<p>Do you know of any similar results? I am mostly interested in results of the following two kinds:</p>\n\n<ul>\n<li>Results stating that in some precise sense, some statement is true \"for most universes\".</li>\n<li>Non-rigorous arguments suggesting the validity of a statement which (arguably) lead to rigorous proofs.</li>\n</ul>\n\n<p>P.S. Please feel free to retag.</p>\n", "pids": ["5c610756da56297340afda29"], "flag": 0}
{"question": "Which fruit compounds affect the speed of fructose absorption?", "body": "<p>Blood fructose levels are not regulated by insulin in the human body. This means that the body absorbs <strong>pure</strong> fructose very fast, and it raises the blood fructose levels rapidly.</p>\n\n<p>Do fruits/ vegetation contain compounds, which help the digestive system to <strong>regulate the absorption of fructose</strong>? If so, what are they?</p>\n", "pids": ["55a67b7465ce054aad69293d", "53e9b945b7602d9704531f7f", "53e9b36cb7602d9703e4d374", "53e9badeb7602d970470c544", "5c1367beda56295a08a05956", "53e9a4c7b7602d9702de4c35", "55a478b465ce31bc877c028d", "55a500fd65ceb7cb02de48b4", "55a4b95e65ceb7cb02d6ec12", "55a6a2a865ce054aad6eb743", "55a5ef1c65cead59c8305f50", "55a5521f65ceb7cb02e81d23", "55a4d74e65ceb7cb02d9bca3", "53e9ac13b7602d97035d7dbc", "53e9b4d4b7602d9703ff4e78", "55a4d88265ceb7cb02d9ddd4", "55a66b1a65ce054aad6706cd", "55a535bfc91bf3b1cc51cda4"], "flag": 1}
{"question": "Do 80 to 90 percent of lifelong smokers never develop lung cancer?", "body": "<p><a href=\"https://bgr.com/science/we-may-finally-know-why-so-many-lifelong-smokers-never-get-lung-cancer/\" rel=\"noreferrer\">Joshua Hawkins of BGR.com has stated</a> that 80 to 90 percent of lifelong smokers never develop lung cancer.</p>\n<p>To quote the article:</p>\n<blockquote>\n<p>Scientists may have discovered why lifelong smokers never get lung cancer. That sentence probably seems silly, especially given that cigarettes are the number one risk factor for lung cancer. Despite tobacco products being the cause of 90 percent of deaths, lifelong smokers somehow tend to avoid getting lung cancer. […]</p>\n<p>However, based on the findings of this study, it could play a large part in why 80 to 90 percent of lifelong smokers never develop lung cancer.</p>\n</blockquote>\n<p>There doesn't seem to be any source for the claim, although a <a href=\"https://doi.org/10.1038/s41588-022-01035-w\" rel=\"noreferrer\">study in <em>Nature Genetics</em></a> was linked in the article and that is behind a paywall.</p>\n<p>As pointed out in the accepted answer to Skeptics.SE question, <a href=\"https://skeptics.stackexchange.com/q/7883/43717\">Does smoking cigarettes cause lung cancer?</a>, smoking definitely causes cancer, but do 80 to 90 percent of lifelong smokers actually never develop lung cancer?</p>\n", "pids": ["5c0f83d2da562944ac8d3a11", "6256ab215aee126c0fc1731c", "55a463ab612ca6486894d2fd", "53e9b783b7602d97043274ec"], "flag": 1}
{"question": "What is the &quot;horseshoe effect&quot; and/or the &quot;arch effect&quot; in PCA / correspondence analysis?", "body": "<p>There are many techniques in ecological statistics for exploratory data analysis of multidimensional data.  These are called 'ordination' techniques.  Many are the same or closely related to common techniques elsewhere in statistics.  Perhaps the prototypical example would be principal components analysis (PCA).  Ecologists might use PCA, and related techniques, to explore 'gradients' (I am not entirely clear what a gradient is, but I've been reading a little bit about it.)  </p>\n\n<p>On <a href=\"http://ordination.okstate.edu/eigen.htm\" rel=\"noreferrer\">this page</a>, the last item under <strong>Principal Components Analysis (PCA)</strong> reads:  </p>\n\n<blockquote>\n  <ul>\n  <li>PCA has a serious problem for vegetation data: the horseshoe effect. This is caused by the curvilinearity of species distributions along gradients. Since species response curves are typically unimodal (i.e. very strongly curvilinear), horseshoe effects are common.  </li>\n  </ul>\n</blockquote>\n\n<p>Further down the page, under <strong>Correspondence Analysis or Reciprocal Averaging (RA)</strong>, it refers to \"the arch effect\":  </p>\n\n<blockquote>\n  <ul>\n  <li>RA has a problem: the arch effect. It is also caused by nonlinearity of distributions along gradients.  </li>\n  <li>The arch is not as serious as the horseshoe effect of PCA, because the ends of the gradient are not convoluted.</li>\n  </ul>\n</blockquote>\n\n<p>Can someone explain this?  I have recently seen this phenomenon in plots that re-represent data in a lower dimensional space (viz., correspondence analysis and factor analysis).  </p>\n\n<ol>\n<li>What would a \"gradient\" correspond to more generally (i.e., in a non-ecological context)?</li>\n<li>If this happens with your data, is it a \"problem\" (\"serious problem\")?  For what?  </li>\n<li>How should one interpret output where a horseshoe / arch shows up?  </li>\n<li>Does a remedy need to be applied?  What?  Would transformations of the original data help?  What if the data are ordinal ratings?  </li>\n</ol>\n\n<p>The answers may exist in other pages on that site (e.g., for <a href=\"http://ordination.okstate.edu/PCA.htm\" rel=\"noreferrer\">PCA</a>, <a href=\"http://ordination.okstate.edu/CA.htm\" rel=\"noreferrer\">CA</a>, and <a href=\"http://ordination.okstate.edu/DCA.htm\" rel=\"noreferrer\">DCA</a>).  I have been trying to work through those.  But the discussions are couched in sufficiently unfamiliar ecological terminology and examples that it is harder to understand the issue.  </p>\n", "pids": ["53e9abebb7602d97035a9dcc", "56d822fadabfae2eeec8ebc6", "53e9a178b7602d9702a6bf62", "5e621f3d91e01160711d6039", "53e9b303b7602d9703dc613c"], "flag": 1}
{"question": "Elementary Papers at ArXiv", "body": "<p>Inspired by this <a href=\"https://mathoverflow.net/questions/2144/a-single-paper-everyone-should-read\">question</a>, at <strong>MO</strong> i am asking this question.</p>\n\n<p>Can anyone list some elementary articles at ArXiv which can be understood by High-School/Undergrad Students. I am asking this because, i would like to see some interesting papers and articles to learn something new. If the paper is very much advanced then its of no use to me since i haven't learnt enough Math. I have been searching around for past two hours and i couldn't find a single paper which i could comprehend. Article which i would like to see:-</p>\n\n<ul>\n<li><p>Interesting proofs of some Elementary number Theory results.</p></li>\n<li><p>Interesting identity involving Infinite series.</p></li>\n<li><p>Interesting articles in Basic Abstract Algebra ( concerning Groups and Rings.)</p></li>\n<li><p>Your favorite article. ( Make sure its elementary enough!)</p></li>\n</ul>\n\n<p>The best example of what type of articles i am looking for can be found in the answer given by Bill here:</p>\n\n<ul>\n<li><a href=\"https://math.stackexchange.com/questions/5763/characterizing-continuous-functions-based-on-the-graph-of-the-function\">Characterizing continuous functions based on the graph of the function</a></li>\n</ul>\n\n<p>This is an interesting article. I really enjoyed reading it since i could understand it.</p>\n", "pids": ["56d92db3dabfae2eeee70ea0", "53e9b6b0b7602d9704232fb7", "56d843f2dabfae2eee9ed964", "56d86982dabfae2eeebb59d4", "622951695aee126c0f0e0912"], "flag": 0}
{"question": "What is the difference between random variable and random sample?", "body": "<p>These two expressions confused me a lot when I was learning statistics.\nIt seems to me that they are totally different things.</p>\n\n<p>A <em>random sample</em> is to randomly take a sample from a population, whereas a <em>random variable</em> is like a function that maps the set of all possible outcomes of an experiment to a real number.</p>\n\n<p>However, say if I draw some samples $X_1$, $X_2$, $X_3$ and $X_i \\sim N(\\mu,\\sigma^2)$, where $\\mu$ and $\\sigma$ are unknown, are $X_1$, $X_2$, $X_3$ random samples or random variables?</p>\n", "pids": ["5c756db7f56def9798557af9"], "flag": 1}
{"question": "Is &quot;probabilitistic,universal, fault tolerant quantum computation&quot; possible with continuous values?", "body": "<p>It seems to be a widely held belief within the scientific community that it is possible to do \"universal, fault-tolerant\" quantum computation using optical means by following what is called  \"<a href=\"https://en.wikipedia.org/wiki/Linear_optical_quantum_computing\" rel=\"noreferrer\">linear optical quantum computing (LOQC)</a>\" pioneered by KLM (Knill, Laflamme, Milburn). However, LOQC uses only modes of light that contain either zero or one photon, not more.</p>\n\n<p>Continuous modes of light contain, by definition, much more than one photon. The paper <strong>Probabilistic Fault-Tolerant Universal Quantum Computation and Sampling Problems in Continuous Variables</strong> Douce <em>et al.</em> (2018) <a href=\"https://arxiv.org/abs/1806.06618\" rel=\"noreferrer\">[quant-ph arXiv:1806.06618v1]</a> claims \"probabilistic universal fault-tolerant\" quantum computation can also be done using continuous modes of squeezed light. The paper goes even further and claims it is possible to demonstrate quantum supremacy using continuous modes.  In fact, the paper's abstract says:</p>\n\n<blockquote>\n  <p>Furthermore, we show that this model can be adapted to yield sampling\n  problems that cannot be simulated efficiently with a classical\n  computer, unless the polynomial hierarchy collapses.</p>\n</blockquote>\n\n<p>A quantum computing startup called <a href=\"https://www.xanadu.ai/\" rel=\"noreferrer\">Xanadu</a> that has some credibility because it has written several papers with Seth Lloyd, seems to be claiming that they too will ultimately be able to do quantum computation with continuous modes of light, and perform some tasks better than a classical computer.</p>\n\n<p>And yet, what they are doing seems to me to be analog computing (is fault tolerant error correction possible for analog computing?). Also, they use squeezing and displacement operations. Such operations do not conserve energy (squeezing or displacing a mode can change its energy), so such operations seem to require exchanges of macroscopic amounts (not quantized amounts) of energy with an external environment, which probably can introduce a lot of noise into the qc. Furthermore, squeezing has only been achieved in the lab for limited small values, and a claim of universality might require arbitrary large squeezing as a resource.</p>\n\n<p>So, my question is, are these people being too optimistic or not? What kind of computing can be done realistically in the lab with continuous modes of light?</p>\n", "pids": ["5c1380a2da56292d740251af"], "flag": 1}
{"question": "What is the current state of the art in quantum sorting algorithms?", "body": "<p>As a result of an excellent answer to my question on <a href=\"https://quantumcomputing.stackexchange.com/q/1265/253\">quantum bogosort</a>, I was wondering what is the current state of the art in quantum algorithms for sorting.</p>\n\n<p>To be precise, <em>sorting</em> is here defined as the following problem: </p>\n\n<blockquote>\n  <p>Given an array <span class=\"math-container\">$A$</span> of integers (feel free to choose your representation of <span class=\"math-container\">$A$</span>, but be clear about this, I think this already is non-trivial!) of size <span class=\"math-container\">$n$</span>, we wish to transform this array into the array <span class=\"math-container\">$A_s$</span> such that the arrays 'are reshufflings of each other's and <span class=\"math-container\">$A_s$</span> is sorted, i.e. <span class=\"math-container\">$A_s[i]\\leq A_s[j]$</span> for all <span class=\"math-container\">$i\\leq j$</span>.</p>\n</blockquote>\n\n<p>What is known about this? Are there complexity bounds or conjectures for certain models? Are there <em>practical</em> algorithms? Can we <em>beat</em> classical sorting (even the <em>bucket</em> or <em>radix</em> sort <em>at their own game</em>? (i.e. in the cases where they work well?))</p>\n", "pids": ["53e9bad7b7602d9704703199", "56d830a1dabfae2eee202833"], "flag": 1}
{"question": "How does magic state distillation overhead scale compare to quantum advantages?", "body": "<p>I'm interested in the model of quantum computation by magic state injection, that is where we have access to the Clifford gates, a cheap supply of ancilla qubits in the computational basis, and a few expensive-to-distill <em>magic states</em> (usually those that implement S, T gates). I've found that the best scaling is logarithmic in the accuracy $\\varepsilon$, specifically $O(\\log^{1.6}(1/\\varepsilon)$ is what a <a href=\"https://arxiv.org/pdf/1209.2426.pdf\" rel=\"noreferrer\">2012 paper offers</a> to get the accuracy we need in the $S,T$ states. </p>\n\n<p>Is this enough to calculate most of the problems we're interested in? Are there any problems that specifically resist QCSI (Quantum Computation by State Injection) because of high overhead, but are more solvable in other models of computation?</p>\n", "pids": ["64990ccbd68f896efaf8470e", "5c8164a94895d9cbc6580775"], "flag": 1}
{"question": "Brave New Number Theory", "body": "<p>I suppose this is an extremely general question, so I apologize, and perhaps it should be deleted.  On the other hand it's an awesome question.</p>\n<p>Is it clear exactly how much (assumedly algebraic) number theory can written down diagrammatically, and if so, has there been any effort to write such problems in the category of spectra (whichever category you like) and solve problems there?  It seems that some problems may become easier to solve, if only because there are in some sense &quot;more&quot; spectra to work with than there are regular algebraic objects (i.e. we have the Eilenberg-MacLane spectrum for whatever ring or field of whatever, but we also have things that don't come from any algebraic object).</p>\n<p>I have heard about Rognes' work on Galois extensions in this sense, and that there are lots of connections to things like Morava K-theory (and the associated spectra), and plan on at least attempting to pursue such ideas.</p>\n", "pids": ["53e9b7bbb7602d9704366034"], "flag": 0}
{"question": "Why do we do matching for causal inference vs regressing on confounders?", "body": "<p>I'm new to the area of causal inference. From what I understand, one of the main concerns that causal inference tries to address is the effect of confounders!</p>\n<p>For the sake of reference, let's denote the feature that we are interested in (a.k.a treatment or exposure) by <strong>A</strong>, other features by <strong>X</strong> (Let's say some of them are confounders) and outcome by <strong>Y</strong>.</p>\n<p>I focus on the case where all our confounders are <strong>observable</strong>. I also limit to the case when we want to estimate <strong>average treatment effect</strong>.</p>\n<p>We have the below simple DAG:</p>\n<p><a href=\"https://i.stack.imgur.com/wWrey.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/wWrey.png\" alt=\"enter image description here\" /></a></p>\n<p>So there could be two cases:</p>\n<ol>\n<li>A is categorical</li>\n<li>A is continuous</li>\n</ol>\n<p>As I conceptually understand, the whole idea of matching is to marginalize the effect of treatment <strong>A</strong> on outcome <strong>Y</strong>, results in ignorability assumption to hold, which conceptually would be like replicating a randomized trial by making the distribution of covariates <strong>similiar</strong> in an observational data.</p>\n<p>I am wondering isn't it conceptually the same thing that we would have when making multiple regression on all variables? So the interpretation of each coefficient would be the <strong>marginal</strong> effect of each feature on the outcome!</p>\n<p>What is the point that I am missing? What prevents us from going for multiple regression for controlling confounder and turn into matching?</p>\n", "pids": ["60d3e0ba91e0112ca5d18614", "5eaaa1d591e011fa9e15e988"], "flag": 1}
{"question": "Level of advantage provided by annealing for traveling salesman", "body": "<p>My understanding is that there seems to be some confidence that quantum annealing will provide a speedup for problems like the traveling salesman, due to the efficiency provided by, ex, quantum tunneling. Do we know, however, around how much of a speedup is provided?</p>\n", "pids": ["53e9a570b7602d9702e98873", "58d82fced649053542fd6a6c"], "flag": 1}
{"question": "Can adiabatic quantum computing be faster than Grover&#39;s algorithm?", "body": "<p>It has been proven that adiabatic quantum computing is equivalent to \"standard\", or gate-model quantum computing. Adiabatic computing, however, shows promises for optimisation problems, where the objective is to minimise (or maximise) a function which is in some way related to the problem – that is, finding the instance that minimises (or maximises) this function immediately solves the problem.</p>\n\n<p>Now, it seems to me that Grover's algorithm can essentially do the same: by searching over the solution space, it will find one solution (possibly out of many solutions) that satisfies the oracle criterion, which in this case equates to the optimality condition, in time $O(\\sqrt N)$, where $N$ is the size of the solution space.</p>\n\n<p>This algorithm has been shown to be optimal: as Bennett et al. (1997) put it, \"the class $\\rm NP$ cannot be solved on a quantum Turing machine in time $o(2^{n/2})$\". In my understanding, this means there is no way to construct any quantum algorithm that finds a solution by searching through the space faster than $O(\\sqrt N)$, where $N$ scales with the problem size.</p>\n\n<p>So my question is: while adiabatic quantum computing is often presented as being superior when it comes to optimisation problems, can it really be faster than $O(\\sqrt N)$? If yes, this seems to contradict the optimality of Grover's algorithm, since any adiabatic algorithm can be simulated by a quantum circuit. If not, what is the point of developing adiabatic algorithms, if they are never going to be faster than something we can systematically construct with circuits? Or is there something wrong with my understanding?</p>\n", "pids": ["53e9ad33b7602d9703714c51"], "flag": 1}
{"question": "How long does quantum annealing take to find the solution to a given problem?", "body": "<p><a href=\"https://en.wikipedia.org/wiki/Quantum_annealing\" rel=\"noreferrer\">Quantum annealing</a> is an optimization protocol that, thanks to quantum tunneling, allows in given circumstances to maximize/minimize a given function more efficiently than classical optimization algorithms.</p>\n\n<p>A crucial point of quantum annealing is the adiabaticity of the algorithm, which is required for the state to stay in the ground state of the time-dependent Hamiltonian.\nThis is however also a problem, as it means that find a solution can require very long times.</p>\n\n<p>How long do these times have to be for a given Hamiltonian?\nMore precisely, given a problem Hamiltonian $\\mathcal H$ of which we want to find the ground state, are there results saying how long would it take a quantum annealer to reach the solution?</p>\n", "pids": ["5c757228f56def97987e79d8", "617771bd5244ab9dcbe7960c"], "flag": 1}
{"question": "Does a random set of points in the plane contain a large empty convex polygon?", "body": "<p>Suppose I choose <span class=\"math-container\">$n$</span> points uniformly at random from the unit square <span class=\"math-container\">$[0,1]\\times [0,1]$</span>, obtaining a set of points <span class=\"math-container\">$S=\\{p_1,\\ldots, p_n\\}\\subset [0,1]\\times [0,1]$</span>. Then <span class=\"math-container\">$S$</span> may contain subsets which span an empty convex polygon. For example, in the illustration below, we have an empty convex polygon with <span class=\"math-container\">$6$</span> corners. A polygon is &quot;empty&quot; if it contains no other point of <span class=\"math-container\">$S$</span>. Some empty convex hulls may have many corners, some fewer. I am curious about the asymptotic behaviour of this phenomenon. To this end, let</p>\n<p><span class=\"math-container\">$$ f(S)= \\max \\{|T|:T\\subseteq S\\text{ and }T\\text{ is convex and } S\\cap \\text{conv}(T)=T\\}$$</span></p>\n<p><strong>Question.</strong> How does the expectation <span class=\"math-container\">$\\mathbb E[f]$</span> grow as <span class=\"math-container\">$n\\to\\infty$</span>?</p>\n<p><strong>Conjecture.</strong> <span class=\"math-container\">$\\mathbb E[f]=\\Theta(\\sqrt{n})$</span>, due to the birthday paradox.</p>\n<p>I think this is a Ramsey Theory type question, but I am not equipped to answer it. I would be happy with either a lower bound or an upper bound, or pointers to finding them.</p>\n<p><a href=\"https://i.stack.imgur.com/SKyuj.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/SKyuj.png\" alt=\"enter image description here\" /></a></p>\n", "pids": ["53e9ac42b7602d970360ca2f"], "flag": 0}
{"question": "Marginal distribution of the diagonal of an inverse Wishart distributed matrix", "body": "<p>Suppose $X\\sim \\operatorname{InvWishart}(\\nu, \\Sigma_0)$. I'm interested in the marginal distribution of the diagonal elements $\\operatorname{diag}(X) = (x_{11}, \\dots, x_{pp})$. There are a few simple results on the distribution of submatrices of $X$ (at least some listed at Wikipedia). From this I can figure that the marginal distribution of any single element on the diagonal is inverse Gamma. But I've been unable to deduce the joint distribution. </p>\n\n<p>I thought maybe it could be derived by composition, like: </p>\n\n<p>$$p(x_{11} | x_{ii}, i\\gt 1)p(x_{22}|x_{ii}, i&gt;2)\\dots p(x_{(p-1)(p-1)}|x_{pp})p(x_{pp}),$$ </p>\n\n<p>but I never got anywhere with it and further suspect that I'm missing something simple; it seems like this \"ought\" to be known but I haven't been able to find/show it. </p>\n", "pids": ["56d8ac37dabfae2eeebca0c2"], "flag": 1}
{"question": "Alternative to Bloch sphere to represent a single qubit", "body": "<p>In order to represent the single qubit $|\\psi\\rangle$ we use an unitary vector in a $\\mathbb{C}^2$ Hilbert space whose (one of the) orthonormal base is $(|0\\rangle, |1\\rangle)$. </p>\n\n<p>We can draw $|\\psi\\rangle$ using a <a href=\"https://en.wikipedia.org/wiki/Bloch_sphere\" rel=\"noreferrer\">Bloch ball</a>. However, I found this notation quite confusing, because orthogonal vectors are spatially antiparallel (<a href=\"https://physics.stackexchange.com/questions/204090/understanding-the-bloch-sphere\">brief explanation in this Physics Stackexchange question</a>). </p>\n\n<p><a href=\"https://i.stack.imgur.com/U9pdD.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/U9pdD.png\" alt=\"Block sphere\"></a></p>\n\n<p>Do you know any different graphical representation for a single qubit?</p>\n", "pids": ["5c756d50f56def9798516077", "56d829c9dabfae2eeef4a8ee", "53e9a3e7b7602d9702cfbdcb", "5c7572f1f56def979885628f"], "flag": 1}
{"question": "How are the Tate-Shafarevich group and class group supposed to be cognates?", "body": "<blockquote>\n  <p>How can one consider the Tate-Shafarevich group and class group of a field to be analogues?</p>\n</blockquote>\n\n<p>I have heard many authors and even many expository papers saying so, class group as far as I know is the measure of failure of unique factorization of elements (in some sense) in a ring.\n On the other hand the TS-group is $Ш(E/K)=\\mathrm{Ker}(H^1(K,E)\\mapsto \\prod_{v}H^1(K_v,E))$ for a number field K. How can one compare them? I mean, how can one proceed comparing the failure of unique factorization to failure of Hasse-principle?</p>\n\n<p>Any help regarding good articles about the Hasse-principle and BSD conjectures is also appreciated.</p>\n", "pids": ["53e9b37bb7602d9703e5e294", "56d8a722dabfae2eee94fd54"], "flag": 0}
{"question": "Purpose of using Fidelity in Randomised Benchmarking", "body": "<p>Often, when comparing two density matrices, $\\rho$ and $\\sigma$ (such as when $\\rho$ is an experimental implementation of an ideal $\\sigma$), the closeness of these two states is given by the <a href=\"https://en.wikipedia.org/wiki/Fidelity_of_quantum_states\" rel=\"noreferrer\">quantum state fidelity</a> $$F = tr\\left(\\sqrt{\\sqrt{\\rho}\\sigma\\sqrt{\\rho}}\\right),$$ with infidelity defined as $1-F$.</p>\n\n<p>Similarly, when comparing how close an implementation of a gate is with an ideal version, the fidelity becomes $$F\\left( U, \\tilde U\\right) = \\int\\left[tr\\left(\\sqrt{\\sqrt{U\\left|\\psi\\rangle\\langle\\psi\\right|U^\\dagger}\\tilde U\\left|\\psi\\rangle\\langle\\psi\\right|\\tilde U^\\dagger\\sqrt{U\\left|\\psi\\rangle\\langle\\psi\\right|U^\\dagger}}\\right)\\right]^2\\,d\\psi,$$ where $d\\psi$ is the <a href=\"https://en.wikipedia.org/wiki/Haar_measure\" rel=\"noreferrer\">Haar measure</a> over pure states. Unsurprisingly, this can get relatively unpleasant to work with.</p>\n\n<p>Now, let's define a matrix $M = \\rho - \\sigma$ in the case of density matrices, or $M = U - \\tilde U$ when working with gates. Then, the Schatten norms<sup>1</sup>, such as $\\| M\\|_1 = tr\\left(\\sqrt{M^\\dagger M}\\right)$, $\\| M\\|_2^2 = tr\\left(M^\\dagger M\\right)$, or other norms, such as the <a href=\"https://arxiv.org/abs/1004.4110v1\" rel=\"noreferrer\">diamond norm</a> can be computed.</p>\n\n<p>These norms are often easier to compute<sup>2</sup> than the above Fidelity. What makes matters worse is that in <a href=\"https://arxiv.org/abs/0707.0963\" rel=\"noreferrer\">randomised benchmarking</a> calculations, <a href=\"https://arxiv.org/abs/1702.01853\" rel=\"noreferrer\">infidelity doesn't even appear to be a great measure</a>, yet is the number that's used every time that I've seen when looking at benchmarking values for quantum processors.<sup>3</sup></p>\n\n<p>So, <strong>Why is (in)fidelity the go-to value for calculating gate errors in quantum processors (using randomised benchmarking), when it doesn't seem to have a helpful meaning and other methods, such as Schatten norms, are easier to calculate on a classical computer?</strong></p>\n\n\n\n<p><sup>1 The Schatten p-norm of $M$ is $\\| M\\|_p^p = tr\\left(\\sqrt{M^\\dagger M}^p\\right)$ </sup></p>\n\n<p><sup>2 i.e. plug in a noise model on a (classical) computer and simulate</sup></p>\n\n<p><sup>3 Such as <a href=\"https://github.com/QISKit/ibmqx-backend-information/blob/master/backends/ibmqx5/README.md\" rel=\"noreferrer\">IBM's QMX5</a></sup></p>\n", "pids": ["53e9bce1b7602d9704966f79"], "flag": 1}
{"question": "Quantum states are unit vectors... with respect to which norm?", "body": "<p>The most general definition of a quantum state I found is (rephrasing the definition from <a href=\"https://en.wikipedia.org/wiki/Quantum_state#Pure_states\" rel=\"noreferrer\">Wikipedia</a>)</p>\n\n<blockquote>\n  <p>Quantum states are represented by a ray in a finite- or infinite-dimensional Hilbert space over the complex numbers.</p>\n</blockquote>\n\n<p>Moreover, we know that in order to have a useful representation we need to ensure that the vector representing the quantum state is a <em>unit vector</em>.</p>\n\n<p>But in the definition above, they don't precise the norm (or the scalar product) associated with the Hilbert space considered. At first glance I though that the norm was not really important, but I realised yesterday that the norm was <em>everywhere</em> chosen to be the Euclidian norm (2-norm).\nEven the <a href=\"https://en.wikipedia.org/wiki/Bra%E2%80%93ket_notation\" rel=\"noreferrer\">bra-ket</a> notation seems to be made specifically for the euclidian norm.</p>\n\n<p><strong>My question:</strong> Why is the Euclidian norm used everywhere? Why not using an other norm? Does the Euclidian norm has useful properties that can be used in quantum mechanics that others don't?</p>\n", "pids": ["53e9ad34b7602d97037175c9", "53e9ad34b7602d97037175c9"], "flag": 1}
{"question": "Can a quantum computer easily determine the mixing time of the Rubik&#39;s cube group?", "body": "<p>Officials in Rubik's cube tournaments have used two different ways of scrambling a cube.  Presently, they break a cube apart and reassemble the cubies in a random order $\\pi\\in G$ of the Rubik's cube group $G$.  Previously, they would apply a random sequence $g$ of Singmaster moves $\\langle U,D, F, B, L, R\\rangle$.</p>\n\n<p>However, the length $t$ of the word $g$ - the number of random moves needed in order to fully scramble the cube such that each of the $\\Vert G\\Vert=43,252,003,274,489,856,000$ permutations is roughly equally likely to occur - is presently unknown, but <a href=\"https://www.popsci.com/science/article/2010-08/gods-number-revealed-20-moves-will-solve-any-rubiks-cube-position\" rel=\"noreferrer\">must be at least</a> $20$.  This length $t$ can be called the <a href=\"https://en.wikipedia.org/wiki/Markov_chain_mixing_time\" rel=\"noreferrer\"><em>mixing time</em></a> of a random walk on the Cayley graph of the Rubik's cube group generated by the Singmaster moves $\\langle U,D, F, B, L, R\\rangle$.</p>\n\n<blockquote>\n  <p>Would a quantum computer have any advantages to determining the mixing time $t$ of the Rubik's cube group?</p>\n</blockquote>\n\n<p>I think we can have some clever sequence of Hadamard moves to create a register $\\vert A \\rangle$ as a uniform superposition over all $\\Vert G\\Vert$ such configurations; thus applying any sequence of Singmaster moves to $\\vert A \\rangle$ doesn't change $\\vert A \\rangle$.  </p>\n\n<p>If we have a guess $t'$ as to what the mixing time $t$ is, we can also create another register $\\vert B \\rangle$ as a uniform superposition of all Singmaster words of length $t'$, and conditionally apply each such word to a solved state $\\vert A'\\rangle$, to hopefully get a state $\\vert B\\rangle \\vert A\\rangle$ such that, if we measure $\\vert A \\rangle$, each of the $\\Vert G \\Vert$ configurations are equally likely to be measured.  If $t'\\lt t$, then we won't have walked along the Cayley graph of $G$ for long enough, and if we were to measure $\\vert A \\rangle$, configurations that are \"closer\" to the solved state would be more likely. Some clever Fourier-like transform on $\\vert B \\rangle$ might be able to measure how uniformly distributed $\\vert A \\rangle$ is.</p>\n\n<p>To me this feels like something a quantum computer may be good at.  For example, if $\\vert A \\rangle$ hasn't been uniformly mixed by all of the words in $\\vert B\\rangle$, then some configurations are more likely than others, e.g. $\\vert A \\rangle$ is more \"constant\"; whereas if $\\vert A \\rangle$ <em>has</em> been fully mixed by all of the walks, then $\\vert A \\rangle$ is more \"balanced\".  But my inuition about both quantum algorithms and Markov chains is not strong enough to get very far.</p>\n\n\n\n<p><strong>EDIT</strong></p>\n\n<p>Contrast this question with the quantum knot verification problem.</p>\n\n<p>In the quantum knot verification, a merchant is given a quantum coin as a state $\\vert K \\rangle$ of all knots that have a particular invariant.  In order to verify the quantum coin, she applies a Markov chain $M$ to transition $\\vert K \\rangle$ to <em>itself</em> (if it's a valid coin.)  She must apply this Markov chain and measure the result at least $t$ times, but otherwise she has no way to construct $\\vert K \\rangle$ on her own (lest she could forge the coin.)  So if she's given a valid coin, she's given a state that she <em>can't produce on her own</em>, along with a Markov chain as a matrix $M$, and she presumably knows the mixing time $t$; she's required to test that $\\vert K \\rangle$ is valid.</p>\n\n<p>In the present question, it's probably pretty <em>easy</em> to generate $\\vert RC \\rangle$ of all Rubik's cube permutations.  The quantum circuit corresponding to the Markov chain, call it $S$, of Singmaster moves, is also probably pretty easy to build.  However, the mixing time $t$ is unknown, and is the one thing to be determined.</p>\n", "pids": ["5b679156ab2dfb7a20289882"], "flag": 1}
{"question": "Do children who kill animals turn out to be violent?", "body": "<p>It is widely claimed that children who injure or kill animals as children are more likely to exhibit violent behavior as adults, committing domestic violence or murder.  A site dedicated to discussing &quot;killer kids&quot; <a href=\"http://web.archive.org/web/20110717210411/http://www.violentkids.com/violence_facts.html\" rel=\"noreferrer\">describes &quot;cruelty to animals &amp; smaller children&quot; as one of the &quot;warning signs of kids who kill&quot;</a>.</p>\n<p>The People for the Ethical Treatment of Animals (PETA), who actually cite some sources, <a href=\"http://www.peta.org/issues/Companion-Animals/animal-abuse-and-human-abuse-partners-in-crime.aspx\" rel=\"noreferrer\">states that this goes both ways</a>:</p>\n<blockquote>\n<p>Acts of cruelty to animals are not mere indications of a minor personality flaw in the abuser; they are symptomatic of a deep mental disturbance. Research in psychology and criminology shows that people who commit acts of cruelty to animals don’t stop there—many of them move on to their fellow humans. “Murderers ... very often start out by killing and torturing animals as kids,” says Robert K. Ressler, who developed profiles of serial killers for the Federal Bureau of Investigation (FBI).</p>\n<p>Studies have shown that violent and aggressive criminals are more likely to have abused animals as children than criminals who are considered non-aggressive. A survey of psychiatric patients who had repeatedly tortured dogs and cats found that all of them had high levels of aggression toward people as well. According to a New South Wales newspaper, a police study in Australia revealed that “100 percent of sexual homicide offenders examined had a history of animal cruelty.” To researchers, a fascination with cruelty to animals is a red flag in the backgrounds of serial killers and rapists. According to the FBI’s Ressler, “These are the kids who never learned it’s wrong to poke out a puppy’s eyes.”</p>\n</blockquote>\n<p>Apparently, even as adults such individuals <a href=\"http://www.americanhumane.org/interaction/support-the-bond/fact-sheets/animal-abuse-domestic-violence.html\" rel=\"noreferrer\">are still violent toward animals</a>.</p>\n<p>Is there any evidence of a correlation between childhood violence toward animals and violent behavior as an adult (or vice versa)?</p>\n", "pids": ["56d90e82dabfae2eee2c5fe9", "56d822c1dabfae2eeec763a2"], "flag": 1}
{"question": "Good online resource with tips on graphing association between two numeric variables under various conditions", "body": "<h3>Context:</h3>\n\n<p>Over the while I've acquired a set of heuristics on how to effectively plot the association between two numeric variables. I imagine most people who work with data would have a similar set of rules.</p>\n\n<p>Examples of such rules might be:</p>\n\n<ul>\n<li>If one of the variables is positively skewed, consider plotting that axis on a log scale.</li>\n<li>If there are a lot of data points (e.g., n > 1000), adopt a different strategy such as using some form of partial transparency, or sampling the data;</li>\n<li>If one of the variables takes on a limited number of discrete categories, consider using a jitter or a sunflower plot;</li>\n<li>If there are three or more variables, consider using a scatterplot matrix;</li>\n<li>Fitting some form of trend line is often useful;</li>\n<li>Adjust the size of the plotting character to the sample size (for bigger n, use a smaller plotting character);</li>\n<li>and so on.</li>\n</ul>\n\n<h3>Question:</h3>\n\n<p>I'd like to be able to refer students to a web page or site that explains these and other tricks for effectively plotting associations between two numeric variables, perhaps with examples.</p>\n\n<ul>\n<li>Are there any pages or sites on the internet that do a good job of this? </li>\n</ul>\n", "pids": ["53e9ab89b7602d9703533b7b"], "flag": 1}
{"question": "Model stability when dealing with large $p$, small $n$ problem", "body": "<p>Intro:</p>\n\n<p>I have a dataset with a classical \"large p, small n problem\". The number available samples <strong>n</strong>=150 while the number of possible predictors <strong>p</strong>=400. The outcome is a continuous variable. </p>\n\n<p>I want to find the most \"important\" descriptors, i.e., those that are best candidates for explaining the outcome and helping to build a theory. </p>\n\n<p>After research on this topic I found LASSO and Elastic Net are commonly used for the case of large p, small n. Some of my predictors are highly correlated and I want to preserve their groupings in the importance assessment, therefore, I opted for <strong>Elastic Net</strong>. I suppose that I can use absolute values of regression coefficients as a measure of importance (please correct me if I am wrong; my dataset is standardized). </p>\n\n<p><strong>Problem:</strong></p>\n\n<p>As my number of samples is small, how can I achieve a stable model?</p>\n\n<p>My current approach is to find best tuning parameters (lambda and alpha) in a grid search on 90% of the dataset with 10-fold cross-validation averaging MSE score. Then I train the model with the best tuning parameters on the whole 90% of dataset. I am able to evaluate my model using R squared on the holdout 10% of the dataset (which account to only 15 samples). </p>\n\n<p>Running repeatedly this procedure, I found a large variance in R squared assessments. As well, the number of non-zeroed predictors varies as well as their coefficients. </p>\n\n<p><strong>How can I get a more stable assessment of predictors' importance and more stable assessment of final model performance?</strong> </p>\n\n<p>Can I repeatedly run my procedure to create a number of models, and then average regression coefficients? Or should I use the number of occurrences of a predictor in the models as its importance score?</p>\n\n<p>Currently, I get around 40-50 non-zeroed predictors. Should I penalize number of predictors harder for better stability?</p>\n", "pids": ["563e04ac0cf219a1e1f6f0cf"], "flag": 1}
{"question": "Closed-form analytical solutions to Optimal Transport/Wasserstein distance", "body": "<p><a href=\"https://math.nyu.edu/faculty/tabak/publications/M107495.pdf\" rel=\"nofollow noreferrer\">Kuang and Tabak (2017)</a> mentions that:</p>\n<blockquote>\n<p>&quot;closed-form solutions of the multidimensional optimal transport problems are relatively rare, a number of numerical algorithms have been proposed.&quot;</p>\n</blockquote>\n<p>I'm wondering if there are some resources (lecture notes, papers, etc.) that collect/contain known solutions to optimal transport and/or Wasserstein distance between two distributions in dimensions greater than 1. For example, let <span class=\"math-container\">$ \\mathcal{N_1}(\\mu_1, \\Sigma_1) $</span> and <span class=\"math-container\">$ \\mathcal{N_2}(\\mu_2, \\Sigma_2) $</span> denote two Gaussian distributions with different means and covariances matrices. Then the optimal transport map between them is:</p>\n<p><span class=\"math-container\">$$ x \\longrightarrow \\mu_2 + A( x - \\mu_1 ) $$</span> where <span class=\"math-container\">$ A = \\Sigma_1^{- 1/2} (\\Sigma_1^{1/2} \\Sigma_2 \\Sigma_1^{1/2})^{1/2} \\Sigma_1^{- 1/2}$</span>. And so the Wasserstein 2 distance is</p>\n<p><span class=\"math-container\">$$ W_2 ( \\mathcal{N_1}(\\mu_1, \\Sigma_1), \\mathcal{N_2}(\\mu_2, \\Sigma_2) ) = || \\mu_1 - \\mu_2 ||^2_2 + \\mathrm{Tr}( \\Sigma_1 + \\Sigma_2 - 2( \\Sigma_1^{1/2} \\Sigma_2 \\Sigma_1^{1/2} )^{1/2} ) $$</span> where <span class=\"math-container\">$\\mathrm{Tr}$</span> is the trace operator.</p>\n<p>It will be nice to know more worked out examples of optimal transport, such as uniform distributions between different geometric objects, e.g. concentric and overlapping balls, between rectangles, etc.</p>\n", "pids": ["5eda19d991e01187f5d6dad4", "5b3d98d617c44a510f802643", "53e9bb44b7602d97047853c9", "607d520491e011bf62020967", "5d285a9a3a55ac1fc6b5215a", "5c757dd7f56def9798b299e6", "641a71fb90e50fcafd7201b2", "5d0b009d8607575390fd4860", "5cede0f7da562983788d640a"], "flag": 0}
{"question": "How are gates implemented in a continuous-variable quantum computer?", "body": "<p>I've mostly worked with superconducting quantum computers I am not really familiar with the experimental details of photonic quantum computers that use photons to create continuous-variable cluster states such as the one that the Canadian startup <a href=\"https://www.xanadu.ai\" rel=\"noreferrer\">Xanadu</a> is building. How are gate operations implemented in these types of quantum computers? And what is the universal quantum gate set in this case?</p>\n", "pids": ["5d0b00538607575390fbcb5c", "53e9ad42b7602d9703726970"], "flag": 1}
{"question": "What is the origin of the expression “Yoneda Lemma”?", "body": "<p>Thank you very much in advance for telling where the expression “Yoneda Lemma” comes from. </p>\n\n<p><strong>EDIT 1.</strong> On page -14 of</p>\n\n<p>Reprints in <em>Theory and Applications of Categories</em>, No. 3, 2003.\n<strong>Abelian Categories</strong>, by Peter J. Freyd</p>\n\n<p><a href=\"http://www.tac.mta.ca/tac/reprints/articles/3/tr3abs.html\" rel=\"noreferrer\">http://www.tac.mta.ca/tac/reprints/articles/3/tr3abs.html</a></p>\n\n<p>(direct link:  <a href=\"http://www.tac.mta.ca/tac/reprints/articles/3/tr3.pdf\" rel=\"noreferrer\">http://www.tac.mta.ca/tac/reprints/articles/3/tr3.pdf</a> )</p>\n\n<p>one reads:</p>\n\n<blockquote>\n  <p>The Yoneda lemma turns out not to be in Yoneda’s paper. When, some time after both printings of the book appeared, this was brought to my (much chagrined) attention, I brought it the attention of the person who had told me that it was the Yoneda lemma. He consulted his notes and discovered that it appeared in a lecture that MacLane gave on Yoneda’s treatment of the higher Ext functors. The name “Yoneda lemma” was not doomed to be replaced.</p>\n</blockquote>\n\n<p><strong>EDIT 2.</strong> In the entry “<a href=\"https://www.encyclopediaofmath.org/index.php/Grothendieck_functor\" rel=\"noreferrer\">Grothendieck functor</a>” of the <strong>Encyclopaedia of Mathematics</strong> [EOM], edited by Michiel Hazewinkel”, one reads</p>\n\n<blockquote>\n  <p>In the English literature, the Grothendieck functor is commonly called the Yoneda embedding or the Yoneda–Grothendieck embedding.</p>\n</blockquote>\n\n<p><strong>EDIT 3.</strong> The article</p>\n\n<p>Grothendieck, Alexander. Technique de descente et théorèmes d'existence en géométrie algébriques. II. Le théorème d'existence en théorie formelle des modules. <em>Séminaire Bourbaki</em>, 5 (1958-1960). Exposé No. 195, 22 p. Février 1960.</p>\n\n<p>quoted in the EOM entry mentioned is available <a href=\"http://www.numdam.org:80/numdam-bin/item?id=SB_1958-1960__5__369_0\" rel=\"noreferrer\">here</a>.</p>\n\n<p><strong>EDIT 4. Subquestion 1:</strong> When was the Yoneda Lemma stated in print for the first time? <strong>Subquestion 2:</strong> When did this Gare du Nord conversation mentioned by Theo Buehler occur? </p>\n\n<p>The advantage of Subquestion 1 is that it’s more likely to have a definite answer. [I think we all agree on the fact that Grothendieck’s Exposé does contain the “Yoneda Lemma”.]</p>\n\n<p><strong>EDIT 5.</strong> Tentative answer to Subquestion 1: I feel (tell me if I’m wrong) there is a consensus on the opinion that the Yoneda Lemma was stated in print for the first time in </p>\n\n<p>Grothendieck, Alexander. Technique de descente et théorèmes d'existence en géométrie algébriques. II. Le théorème d'existence en théorie formelle des modules. <em>Séminaire Bourbaki</em>, 5 (1958-1960). Exposé No. 195, 22 p. Février 1960. Available <a href=\"http://www.numdam.org:80/numdam-bin/item?id=SB_1958-1960__5__369_0\" rel=\"noreferrer\">here</a>.</p>\n\n<p>[I’m taking this opportunity to thank Theo Buehler for his generous contribution to this thread in particular, and to this site in general.]</p>\n", "pids": ["623949ac6d2bdbb473c3b130", "623949ac6d2bdbb473c3b130"], "flag": 0}
{"question": "What is the mathematical justification for the &quot;universality&quot; of the universal set of quantum gates (CNOT, H, Z, X and π/8)?", "body": "<p>In <a href=\"https://quantumcomputing.stackexchange.com/a/1281/26\">this</a> answer I mentioned that the CNOT, H, X, Z and $\\pi/8$ gates form a universal set of gates, which given in sufficient number of gates can get arbitrarily close to replicating any unitary quantum gate (I came to know about this fact from Professor Umesh Vazirani's EdX lectures). But, is there any mathematical justification for this? There should be! I tried searching for relevant papers but couldn't find much.</p>\n", "pids": ["53e9ac0bb7602d97035ca140", "64990ccbd68f896efaf8470e", "53e9b30ab7602d9703dcfe86"], "flag": 1}
{"question": "Continuous dependent variable with ordinal independent variable", "body": "<p>Given a continuous dependent variable <em>y</em> and independent variables including an ordinal variable <em>X</em><sub>1</sub>, how do I fit a linear model in <code>R</code>? Are there papers about this type of model?</p>\n", "pids": ["53e9b62eb7602d9704188ce1"], "flag": 1}
{"question": "Reference to self-study Abstract Algebra and Category Theory", "body": "<p>I'm very interested in learning abstract algebra and category theory on my own. It seems a very powerful tool in math and it seems worthwile to take a time and learn about it. I just don't know even where to begin. Can someone point out for me what are good references to self-study those topics ? I'm really beginner, the only thing connected to algebra that I'm familiar with is linear algebra.</p>\n\n<p>Thanks very much in advance.</p>\n\n<p><strong>Edit:</strong> Until now I've studied analytic geometry, single variable calculus, multivariable calculus, linear algebra, ordinary differential equations and I'm currently studying differential geometry and multilinear algebra.</p>\n", "pids": ["56d84ce1dabfae2eeee474ea"], "flag": 0}
{"question": "Simulate constrained normal on lower or upper bound in R", "body": "<p>I'd like to generate random data from a constrained normal distribution using R.</p>\n\n<p>For example I might want to simulate a variable from a normal distribution with <code>mean=3, sd= 2</code> and any values larger than 5 are resampled from the same normal distribution.</p>\n\n<p>Thus, for the general function, I could do the following.</p>\n\n<pre><code>rnorm(n=100, mean=3, sd=2)\n</code></pre>\n\n<p>I then had a few thoughts:</p>\n\n<ul>\n<li>Iterate an <code>ifelse</code> function with a loop that repeats until all values are constrained to lie within the bounds. </li>\n<li>Simulate many more values than required and takes the first <code>n</code> that satisfy the constraint.</li>\n<li>Avoid vectorised normal variable simulators and instead use a for loop with a do while inside to simulate each observation one at a time and loop where required.</li>\n</ul>\n\n<p>All of the above seem a little bit clunky.</p>\n\n<h3>Question</h3>\n\n<ul>\n<li>What is a simple way to simulate a constrained random normal variable in R  from normal with mean = 3,sd = 2 and max = 5?</li>\n<li>More generally what is a good general way of incorporating constraints into simulated variables in R? </li>\n</ul>\n", "pids": ["53e9b38eb7602d9703e6e476", "53e9b53bb7602d9704070032"], "flag": 1}
{"question": "Is quantum computing mature enough for a computer scientist with no physics background?", "body": "<p>Sligthly related to <a href=\"https://quantumcomputing.stackexchange.com/questions/1367/programming-quantum-computers-for-non-physics-majors\">this question</a>, but not the same.</p>\n\n<p>Traditional computer science requires no physics knowledge for a computer scientist to be able to research and make progress in the field. Of course, you do need to know about the underlying physical layer when your research is related to that, but in many cases you can ignore it (e.g. when designing an algorithm). Even when architectural details are important (e.g. cache layout), oftentimes it is not necessary to know all the details about them, or how they're implemented at the physical level.</p>\n\n<p>Has quantum computing reached this level of \"maturity\"? Can you design a quantum algorithm, or do actual research in the field, as a computer scientist that doesn't know anything about quantum physics? In other words, can you \"learn\" quantum computing ignoring the physical side, and is it worth it (in terms of scientific career)?</p>\n", "pids": ["53e9a366b7602d9702c743af"], "flag": 1}
{"question": "Does a complete list of open quantum software projects exist?", "body": "<p>An answer to \n<a href=\"https://quantumcomputing.stackexchange.com/questions/1478/is-there-any-source-which-tabulates-quantum-computing-algorithms-for-simulating\">Is there any source which tabulates quantum computing algorithms for simulating physical systems?</a> mentions the <a href=\"https://math.nist.gov/quantum/zoo/\" rel=\"noreferrer\">Quantum Algorithm Zoo</a>, a list of quantum algorithms. Several answers to <a href=\"https://quantumcomputing.stackexchange.com/questions/1367/programming-quantum-computers-for-non-physics-majors\">Programming quantum computers for non-physics majors</a> include links to different kinds of development kits. Likewise, <a href=\"https://quantumcomputing.stackexchange.com/questions/1474/what-programming-languages-are-available-for-quantum-computers\">What programming languages are available for quantum computers?</a> gathers a couple of good attempts at listing those.</p>\n\n<p>The present question is related to the above, and yet it's not answered by the above resources.</p>\n\n<p><strong>Does a complete list of open quantum software projects exist?</strong></p>\n\n<p>Ideal answers would be: if it exists, the link to said list, and if it doesn't, a (well-formatted) as-exhaustive-as-possible compilation of open quantum software projects.</p>\n\n<p>Related question: <a href=\"https://quantumcomputing.stackexchange.com/questions/1973/are-there-any-quantum-software-startups\">Are there any quantum software startups?</a></p>\n", "pids": ["5c1d81f03a55ac3112b95482", "5c1d81f03a55ac3112b95482"], "flag": 1}
{"question": "Are the Ricci and Scalar curvatures the only &quot;interesting&quot; tensors coming from the Riemannian curvature tensor?", "body": "<p>In studying Riemannian geometry, one learns about the Riemann curvature tensor\n$$Rm(X,Y,Z,W) = \\langle \\nabla_X\\nabla_YZ -\\nabla_Y\\nabla_XZ - \\nabla_{[X,Y]}Z, W\\rangle$$\nand its various symmetries.  From the Riemann curvature tensor, one can define the Ricci and scalar curvatures, which give us \"pieces\" of the curvature.</p>\n\n<p>I understand that both the Ricci and scalar curvatures are important ways of measuring curvature.  <strong>My question is:</strong> are these (in any sense) the \"only\" interesting tensors that come from the Riemann curvature?</p>\n\n<p>That is, I could imagine inventing other curvature tensors by performing various operations on $Rm$.  Is there a reason that doing so would be fruitless?  Why do we privilege the Ricci and Scalar curvatures?  Do they give us all the information that we might want?</p>\n\n<p>A <a href=\"https://math.stackexchange.com/questions/2549/are-there-higher-dimensional-analogues-of-sectional-curvature\">previous question</a> of mine hinted at this, though my thoughts were not quite as clear.</p>\n", "pids": ["53e99f0ab7602d97027d9eae", "53e9adffb7602d97038076b0"], "flag": 0}
{"question": "Regularization for ARIMA models", "body": "<p>I am aware of LASSO, ridge and elastic-net type of regularization in linear regression models.</p>\n<p><strong>Question:</strong></p>\n<ol>\n<li>Can this (or a similar) kind of penalized estimation be applied to ARIMA modelling (with a non-empty MA part)?</li>\n</ol>\n<p>In building ARIMA models, it seems usual to consider a pre-selected maximum lag order (<span class=\"math-container\">$p_{max}$</span>,<span class=\"math-container\">$q_{max}$</span>) and then choose some optimal order <span class=\"math-container\">$p \\leqslant p_{max}$</span> and <span class=\"math-container\">$q \\leqslant q_{max}$</span> e.g. by minimizing AIC or AICc. But could regularization be used instead?</p>\n<p>My further <strong>questions</strong> are:</p>\n<ol start=\"2\">\n<li>Could we include <em>all</em> terms up to (<span class=\"math-container\">$p_{max}$</span>,<span class=\"math-container\">$q_{max}$</span>) but penalize the size of the coefficients (potentially all the way to zero)? Would that make sense?</li>\n<li>If it would, has that been implemented in R or other software? If not, what was the trouble?</li>\n</ol>\n<p>A somewhat related post can be found <a href=\"https://stats.stackexchange.com/questions/10425/fitting-an-arimax-model-with-regularization-or-penalization-e-g-with-the-lasso?rq=1\">here</a>.</p>\n<p><sub>Keywords: ARMA, penalization, regularized, shrinkage.</sub></p>\n", "pids": ["5ce3aac9ced107d4c658eb22"], "flag": 1}
{"question": "What is the intuition behind quantum t-designs?", "body": "<p>I started reading about Randomized Benchmarking (<a href=\"https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.106.180504\" rel=\"nofollow noreferrer\">this paper</a>, <a href=\"https://arxiv.org/abs/1009.3639\" rel=\"nofollow noreferrer\">arxiv version</a>) and came across &quot;unitary 2 design.&quot;</p>\n<p>After some googling, I found that the Clifford group being a unitary 2 design is a specific case of &quot;Quantum t-design.&quot;</p>\n<p>I read the <a href=\"https://en.wikipedia.org/wiki/Quantum_t-design\" rel=\"nofollow noreferrer\">wikipedia page</a> and a few other references (<a href=\"https://www.cs.mcgill.ca/%7Eakazna/AK_UnitaryDesigns20090929.pdf\" rel=\"nofollow noreferrer\">this one for example,</a> <a href=\"https://www.cs.mcgill.ca/%7Eakazna/\" rel=\"nofollow noreferrer\">non pdf link to the website that links to the pdf</a>).</p>\n<p>I would like to have some intuitive understanding of the difference between different t designs and what makes the Clifford group a 2 design.</p>\n", "pids": ["5c0f73f7da562944ac69cf67"], "flag": 1}
{"question": "What applications does Grover&#39;s Search Algorithm have?", "body": "<p>Grover's Search algorithm is usually talked about in terms of finding a marked entry in an unsorted database. This is a natural formalism that lets it be applied directly to searching for solutions to NP problems (where a good solution is easily recognised).</p>\n\n<p>I was <a href=\"https://quantumcomputing.stackexchange.com/q/1967/1837\">interested to learn</a> about other applications of Grover's search to finding the minimum, mean and median of a set of numbers. That leaves me wondering if there are any other less-obvious applications of Grover's search (or applications of its generalisations such as amplitude amplification) which are already known? Any brief insight about how this is done would be appreciated.</p>\n", "pids": ["53e9b9e1b7602d97045d98a1", "5736953f6e3b12023e46e4c2"], "flag": 1}
{"question": "Getting started with Lie Groups", "body": "<p>I am looking for some material (e.g. references, books, notes) to get started with Lie Groups and Lie Algebra.</p>\n\n<p>My motivation is that I (eventually) want to understand the theory underpinning <a href=\"http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4608934\">papers</a> <a href=\"http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4434662\">such</a> <a href=\"http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6160733\">as</a> <a href=\"http://www.sciencedirect.com/science/article/pii/S1566253511000571\">these</a>.</p>\n\n<p>The problem is, I am at the <a href=\"http://en.wikipedia.org/wiki/There_are_known_knowns\">Rumsfeldian</a> stage where <em>I don't know what I don'\nt know.</em> The <a href=\"http://en.wikipedia.org/wiki/Lie_group\">wikipedia page</a> makes it clear that I lack several prerequisites in modern geometry.</p>\n\n<p>So, what would be a proposed study path to get to this stage?  My background is electronic engineering and am comfortable with associated topics (signal processing, estimation theory, Kalman Filtering, etc.)</p>\n", "pids": ["53e9b7f5b7602d97043a63d1"], "flag": 0}
{"question": "Tools for creating quantum circuit diagrams", "body": "<p>What tools exist for creating quantum circuit diagrams and exporting them as images? Preferably one which runs in Windows, or even better one which runs in the web browser.</p>\n", "pids": ["5c757d9bf56def9798afff03"], "flag": 1}
{"question": "About the ratio of the areas of a convex pentagon and the inner pentagon made by the five diagonals", "body": "<p>I've thought about the following question for a month, but I'm facing difficulty. </p>\n\n<p><strong>Question</strong> : Letting $S{^\\prime}$ be the area of the inner pentagon made by the five diagonals of a convex pentagon whose area is $S$, then find the max of $\\frac{S^{\\prime}}{S}$.</p>\n\n<p>$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $<a src=\"https://i.stack.imgur.com/jkXDV.gif\" alt=\"enter image description here\"></p>\n\n<p>It seems that a regular pentagon and its affine images would give the max. However, I don't have any good idea without tedious calculations. Can anyone help?</p>\n\n<p><em>Update</em> : I crossposted to <a href=\"https://mathoverflow.net/questions/143664/about-the-ratio-of-the-areas-of-a-convex-pentagon-and-the-inner-pentagon-made-by\">MO</a>.</p>\n", "pids": ["5ce2d0b0ced107d4c63a7dc6"], "flag": 0}
{"question": "A dynamical systems view of the Central Limit Theorem?", "body": "<p>(Originally <a href=\"https://math.stackexchange.com/questions/1724959/a-dynamical-systems-view-of-the-central-limit-theorem\">posted</a> on MSE.)</p>\n\n<p>I have seen many heuristic discussions of the classical central limit theorem speak of the normal distribution (or any of the stable distributions) as an \"attractor\" in the space of probability densities. For example, consider these sentences at the top of Wikipedia's <a href=\"https://en.wikipedia.org/wiki/Central_limit_theorem\" rel=\"noreferrer\">treatment</a>:</p>\n\n<blockquote>\n  <p>In more general usage, a central limit theorem is any of a set of weak-convergence theorems in probability theory. They all express the fact that a sum of many independent and identically distributed (i.i.d.) random variables, or alternatively, random variables with specific types of dependence, will tend to be distributed according to one of a small set of <em>attractor distributions</em>. When the variance of the i.i.d. variables is finite, the attractor distribution is the normal distribution.</p>\n</blockquote>\n\n<p>This dynamical systems language is very suggestive. Feller also speaks of \"attraction\" in his treatment of the CLT in his second volume (I wonder if that is the source of the language), and Yuval Flimus in <a href=\"http://www.cs.toronto.edu/~yuvalf/CLT.pdf\" rel=\"noreferrer\">this note</a> even speaks of the \"basin of attraction.\" (I don't think he really means \"the exact form of the <em>basin of attraction</em> is deducible beforehand\" but rather \"the exact form of the <em>attractor</em> is deducible beforehand\"; still, the language is there.) My question is: <strong>can these dynamical analogies be made precise?</strong> I don't know of a book in which they are -- though many books do make a point of emphasizing that the normal distribution is special for its stability under convolution (as well as its stability under the Fourier transform). This is basically telling us that the normal is important because it is a fixed point. The CLT goes further, telling us that it is not just a fixed point but an attractor.</p>\n\n<p>To make this geometric picture precise, I imagine taking the phase space to be a suitable infinite-dimensional function space (the space of probability densities) and the evolution operator to be repeated convolution with an initial condition. But I have no sense of the technicalities involved in making this picture work or whether it is worth pursuing. </p>\n\n<p>I would guess that since I can't find a treatment that does pursue this approach explicitly, there must be something wrong with my sense that it can be done or that it would be interesting. If that is the case, I would like to hear why.</p>\n\n<p><strong>EDIT</strong>: There are three similar questions throughout Math Stack Exchange and MathOverflow that readers may be interested in:</p>\n\n<ul>\n<li><a href=\"https://mathoverflow.net/questions/191791/gaussian-distributions-as-fixed-points-in-some-distribution-space\">Gaussian distributions as fixed points in Some distribution space</a> (MO)</li>\n<li><a href=\"https://mathoverflow.net/questions/182752/central-limit-theorem-via-maximal-entropy\">Central limit theorem via maximal entropy</a> (MO)</li>\n<li><a href=\"https://math.stackexchange.com/questions/813748/is-there-a-proof-for-the-central-limit-theorem-via-some-fixed-point-theorem\">Is there a proof for the central limit theorem via some fixed point theorem?</a> (MSE)</li>\n</ul>\n", "pids": ["53e99e31b7602d97026f7662"], "flag": 1}
{"question": "Representation of real numbers in quantum computers", "body": "<p>In classical binary computers, real numbers are often represented using the <a href=\"https://en.wikipedia.org/wiki/IEEE_754\" rel=\"noreferrer\">IEEE 754 standard</a>. With quantum computers you can of course do this as well - and for measurements this (or a similar standard) will probably be necessary since the result of any measurement is binary. But could real numbers be modeled more easily and / or more precisely within the qubits using different methods before the measurement happens? If so, are there any use cases where this is actually useful, seeing that (I'm assuming) any additional precision will be lost when measurements are performed?</p>\n\n<p>To be clear, I'm not (necessarily) looking for existing standards, just for ideas or suggestions on how to represent those numbers. If there's any research into it, that would be useful too of course.</p>\n", "pids": ["56d92d73dabfae2eeee5b001"], "flag": 1}
{"question": "An example where $\\frac{(2m)!(2n)!}{m!n!(m + n)!}$ is the number of ways of counting something?", "body": "<p>Prove that for all non-negative integers $m,n$, $\\frac{(2m)!(2n)!}{m!n!(m + n)!}$ is an integer.</p>\n\n<p>There is a answer given here to this question <a href=\"https://math.stackexchange.com/questions/215355/prove-that-for-all-non-negative-integers-m-n-frac2m2nmnm-n\">here.</a></p>\n\n<p>I've seen how it can be proven using recurrence equations as well. When I was trying to solve this problem I was looking to represent it as the number of ways of counting something. Can anyone give such an example, thus proving the question another and very natural way?</p>\n", "pids": ["53e99860b7602d970209c294"], "flag": 0}
{"question": "Do multi-qubit measurements make a difference in quantum circuits?", "body": "<p>Consider the <a href=\"https://quantumcomputing.stackexchange.com/a/1348/144\">unitary circuit</a> model of quantum computation. If we need to generate entanglement between the input qubits with the circuit, it must have multi-qubit gates such as CNOT, as <a href=\"https://journals.aps.org/pra/abstract/10.1103/PhysRevA.53.2046\" rel=\"noreferrer\">entanglement cannot increase under local operations and classical communication</a>. Consequently, we can say that quantum computing with multi-qubit gates is inherently different from quantum computing with just local gates. But what about measurements?</p>\n\n<p>Does including simultaneous measurements of multiple qubits make a difference in quantum computing or can we perhaps emulate this with local measurements with some overhead? <strong>EDIT:</strong> <em>by \"emulate with local measurements\", I mean have the same effect with local measurements + any unitary gates.</em></p>\n\n<p>Please notice that I am not merely asking how measuring one qubit changes the others, which has already been <a href=\"https://quantumcomputing.stackexchange.com/questions/1206/how-does-measurement-of-one-qubit-affect-the-others\">asked and answered</a>, or if such measurements are possible. I am interested to know whether including such measurements could bring something new to the table.</p>\n", "pids": ["5f0dd6ed9fced0a24b6f08d3", "5e2eb5213a55ace6202f486d", "53e9a782b7602d97030bee48", "53e9a26bb7602d9702b74bf4"], "flag": 1}
{"question": "Are there any estimates on how complexity of quantum engineering scales with size?", "body": "<p>It seems to me that an extremely relevant question for the prospects of quantum computing would be how the engineering complexity of quantum systems scales with size. Meaning, it's easier to build $n$ $1$-qubit computers than one $n$-qubit computer. In my mind, this is roughly analogous to the fact that it's easier to analytically solve $n$ $1$-body problems than one $n$-body problem, since entanglement is the primary motivating factor behind quantum computing in the first place.</p>\n\n<p>My question is the following: It seems that we should really care about how the 'difficulty' of building and controlling an $n$-body quantum system grows with $n$. Fix a gate architecture, or even an algorithm--is there a difficulty in principle arising from the fact that an $n$-qubit computer <em>is</em> a quantum many-body problem? And that mathematically speaking, our understanding of how quantum phenomena scale up into classical phenomena is quite poor? Here difficulty could be defined in any number of ways, and the question we would care about, roughly is, is controlling a $1000$-qubit machine (that is, preserving the coherence of its wavefunctions) 'merely' $100$x harder than controlling a $10$-qubit machine, or $100^2$, or $100!$ or $100^{100}$? Do we have any reasons for believing that it is more or less the former, and not the latter?</p>\n", "pids": ["5c6106b8da56297340ad6e5e"], "flag": 1}
{"question": "Obtaining gate $e^{-i\\Delta t Z}$ from elementary gates", "body": "<p>I am currently reading \"Quantum Computation and Quantum Information\" by Nielsen and Chuang. In the section about Quantum Simulation, they give an illustrative example (section 4.7.3), which I don't quite understand:</p>\n\n<blockquote>\n  <p>Suppose we have the Hamiltonian \n  <span class=\"math-container\">$$ H = Z_1 ⊗ Z_2 ⊗ \\cdots ⊗ Z_n,\\tag{4.113}$$</span>\n  which acts on an <span class=\"math-container\">$n$</span> qubit system. Despite this being an interaction involving all of the system, indeed, it can be simulated efficiently. What we desire is a simple quantum circuit which implements <span class=\"math-container\">$e^{-iH\\Delta t}$</span>, for arbitrary values of <span class=\"math-container\">$\\Delta t$</span>. A circuit doing precisely this, for <span class=\"math-container\">$n = 3$</span>, is shown in Figure 4.19. The main insight is that although the Hamiltonian involves all the qubits in the system, it does so in a <em>classical</em> manner: the phase shift applied to the system is <span class=\"math-container\">$e^{-i\\Delta t}$</span> if the <em>parity</em> of the <span class=\"math-container\">$n$</span> qubits in the computational basis is even; otherwise, the phase shift should be <span class=\"math-container\">$e^{i\\Delta t}$</span>. Thus, simple simulation of <span class=\"math-container\">$H$</span> is possible by first classically computing the parity (storing the result in an ancilla qubit), then applying the appropriate phase shift conditioned on the parity, then uncomputing the parity (to erase the ancilla).</p>\n  \n  <p><a href=\"https://i.stack.imgur.com/OwE2r.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/OwE2r.png\" alt=\"enter image description here\"></a>\n  Furthermore, extending the same procedure allows us to simulate more complicated extended Hamiltonians. Specifically, we can efficiently simulate any Hamiltonian of the form <span class=\"math-container\">$$H = \\bigotimes_{k=1}^n\\sigma_{c\\left(k\\right)}^k,$$</span> where <span class=\"math-container\">$\\sigma_{c(k)}^k$</span> is a Pauli matrix (or the identity) acting on the <span class=\"math-container\">$k$</span>th qubit, with <span class=\"math-container\">$c(k) \\in \\{0, 1, 2, 3\\}$</span> specifying one of <span class=\"math-container\">$\\{I, X, Y, Z\\}$</span>. The qubits upon which the identity operation is performed can be disregarded, and <span class=\"math-container\">$X$</span> or <span class=\"math-container\">$Y$</span> terms can be transformed by single qubit gates to <span class=\"math-container\">$Z$</span> operations. This leaves us with Hamiltonian of the form of (4.113), which is simulated as described above.</p>\n</blockquote>\n\n<p>How can we obtain gate <span class=\"math-container\">$e^{-i\\Delta t Z}$</span> from elementary gates (for example from Toffoli gates)?</p>\n", "pids": ["55a6be0665ce054aad73cb68"], "flag": 1}
{"question": "Evolution of endosymbionts?", "body": "<p>Mitochondria and plastids in eukaryotes evolved through a process of endosymbiosis. How does an event like a eukaryote engulfing a bacteria, become a part of the genome? Some of these primitive eukaryotes could have been more predisposed to more vigorous endocytosis as a result of their DNA, but how could the physical event account for evolution of organelles?</p>\n", "pids": ["53e9a8c5b7602d970321234d", "5fba38ebd4150a363c996884"], "flag": 1}
{"question": "Why isn&#39;t Dominated Convergence Theorem taught in intro analysis", "body": "<p>In a course based off a book like Rudin's Principles of Mathematical Analysis that does non-measure theoretic analysis why isn't dominated convergence taught? It would be useful since continuous functions are Lebesgue measurable. Is there not a way to prove a non-measure theoretic version of this statement? </p>\n", "pids": ["53e9a0f4b7602d97029e0c32"], "flag": 0}
{"question": "What is effect size... and why is it even useful?", "body": "<p>I have an introductory-graduate-level statistics background (assume I know mathematical statistics and probability at an undergraduate level (e.g., Wackerly et al., Ross' Probability), and have some knowledge of measure theory). </p>\n\n<p>I have recently started a job doing experimental design and statistical reporting in education statistics, and have been placed on a project where I am basically assessing accountability metrics for schools and have to analyze the data, propose changes, etc. Note that I am the only one in my department with a mathematical statistics background.</p>\n\n<p>In my position, people have strongly suggested using effect size to measure effectiveness of programs. The only time I've ever heard of effect size is from my friend, who studied psychology. My impression is that $$\\text{Effect Size} = \\dfrac{\\text{Difference of Means}}{\\text{Standard Deviation}}\\text{.}$$</p>\n\n<p><strong>What is so useful about this metric over traditional hypothesis testing, and why should I care about it?</strong> To me, it looks like nothing more than a test statistic for a two-sample $t$-test. I don't see this useful at all apart from maybe putting everything on the same scale (which is why anyone really \"normalizes\" anything), but I thought test statistics (which is what effect size seems like to me) were out of fashion, and $p$-values are preferred.</p>\n", "pids": ["56d818d3dabfae2eee851618"], "flag": 1}
{"question": "Restricted Boltzmann Machine : how is it used in machine learning?", "body": "<p><strong>Background:</strong></p>\n\n<p>Yes, Restricted Boltzmann Machine (RBM) CAN be used to initiate the weights of a neural network. Also it CAN be used in a \"layer-by-layer\" way to build a deep belief network <em>(that is, to train a $n$-th layer on the top of $(n-1)$-th layer, and then to train the $n+1$-th layer on the top of the $n$-th layer, rinse and repeat ... )</em>.</p>\n\n<p>Regarding how to use RBM, details can be found from the thread of \n<a href=\"https://stats.stackexchange.com/questions/48162/good-tutorial-for-restricted-boltzmann-machine-rbm\">Good tutorial for Restricted Boltzmann Machines (RBM)</a> where some papers and tutorials can be found.</p>\n\n<p><strong>My question would be :</strong> </p>\n\n<ul>\n<li>Is RBM really used in either industrial projects or academic projects </li>\n<li>If yes, how &amp; which projects it is being used ? </li>\n<li>Any popular library (such as tensorflow, Caffe, Theono, etc) provides RBM module ?</li>\n</ul>\n\n<p>Thanks for sharing. <strong>I wish to know whether RBM is really useful in practice.</strong></p>\n", "pids": ["53e9a532b7602d9702e536a6"], "flag": 1}
{"question": "Most wanted reproducible results in computational algebra", "body": "<p>I am interested in suggestions for major computational results obtained with the help of mathematical software but not easily verifiable using computers.</p>\n\n<p>\"Most wanted\" could refer, for example, to the following:</p>\n\n<ul>\n<li>results which are highly cited/reused in other publications/computations</li>\n<li>computational proofs of fundamental results</li>\n<li>counterexamples to central conjectures in a field</li>\n<li>checking correctness of various mathematical databases</li>\n<li>producing open source implementations of computations previously performed using another open or closed source software, or when the old code is not available at all</li>\n<li>landmark computations that one could be interested to reproduce (<em>in the same way like a chemistry reaction from a textbook could be reproduced by mixing baking soda and vinegar in your kitchen</em>).</li>\n</ul>\n\n<p>If the publication just says \"this result was produced using the system X\", it may be a long way to reproduce it. It may include a reference to exact version of the system, a link to the extra code to download, but again it may happen that that version has to be installed in some particular way to satisfy certain dependencies, the extra code is not well documented so it is unclear how to run it, some other special knowledge or non-trivial computational resources are needed, etc.</p>\n\n<p>On the other side, having these results easier reproducible could be crucial for science. Hypothetically, one could e.g. download a virtual machine and re-run the whole experiment, or use the newest version of the system to check whether the experiment still runs with the same outcome.</p>\n\n<p>I hope that making such a list of suggested experiments to reproduce will be useful to those interested in checking them twice ;-). For example, one could submit their findings to a journal like <a href=\"http://rescience.github.io/\">ReScience</a> which \"targets computational research and encourages the explicit replication of already published research, promoting new and open-source implementations in order to ensure that the original research is reproducible\".</p>\n\n<p><em>Remark: suggestions on computational verification of previously obtained theoretical results and pointers to existing reproducible experiments are also welcome.</em></p>\n", "pids": ["5d9edc4347c8f7664603951c"], "flag": 0}
{"question": "Do characteristic polynomials exhaust all monic polynomials?", "body": "<p>Let $A$ be an $n\\times n$ matrix, then $\\mathrm{char}_A(x):=\\det(xI-A)$ is a monic polynomial of degree $n$. It is called the characteristic polynomial of $A$. My question is the converse:</p>\n\n<blockquote>\n  <p>Let $p(x)$ be a monic polynomial of degree $n$. Can we always find an $n\\times n$ matrix such that $p(x)=\\mathrm{char}_A(x)$?</p>\n</blockquote>\n", "pids": ["53e9a5fdb7602d9702f27c3c", "62d4f5f15aee126c0f7b6d62", "53e99e13b7602d97026d53f7", "53e9b937b7602d97045213b2"], "flag": 0}
{"question": "Can an RNA vaccine change your DNA permanently?", "body": "<p>I was sent this recent <a href=\"https://www.youtube.com/watch?v=ksEVaO806Oo\" rel=\"noreferrer\"><em>Food For Thought</em> YouTube video</a>.</p>\n<p>It contains a number of wild claims about vaccinations.</p>\n<p>In particular, it contains snippets of edited, unsourced footage of <a href=\"https://en.wikipedia.org/wiki/Bill_Gates\" rel=\"noreferrer\">Bill Gates</a> saying:</p>\n<blockquote>\n<p>one final way that's new and is promising is called the RNA vaccine. With RNA and DNA instead of putting that shape in, you put instructions in the code to make that shape.</p>\n</blockquote>\n<p>The text description states:</p>\n<blockquote>\n<p>Bill Gates caught on video admitting vaccine will CHANGE our DNA FOREVER.</p>\n</blockquote>\n<p>Whether or not the Bill Gates was accurately quoted in context, <strong>can an RNA vaccine permanently change the recipients DNA?</strong></p>\n", "pids": ["5ce2cbcdced107d4c62a5aef", "60b9a6a1e4510cd7c8ff7976", "610a6d045244ab9dcbe22896", "600fe74ed4150a363c21f5d8", "5c757dfef56def9798b43e6b"], "flag": 1}
{"question": "Is the seven-dimensional cross product unique?", "body": "<p>I'm confused about how many different 7D cross products there are. I'm defining a 7D cross product to be any bilinear map <span class=\"math-container\">$V \\times V \\to V$</span> (where <span class=\"math-container\">$V$</span> is the inner product space <span class=\"math-container\">$\\mathbb{R}^7$</span> endowed with the Euclidean inner product) such that for all <span class=\"math-container\">$a, b \\in V$</span>:</p>\n\n<ol>\n<li><span class=\"math-container\">$(a \\times b) \\cdot a = (a \\times b) \\cdot b = 0$</span> and</li>\n<li><span class=\"math-container\">$|a \\times b|^2 = |a|^2 |b|^2 - (a \\cdot b)^2$</span>.</li>\n</ol>\n\n<p>(I know that other definitions are sometimes used in the literature.)</p>\n\n<p><a href=\"https://pdfs.semanticscholar.org/1f6b/ff1e992f60eb87b35c3ceed04272fb5cc298.pdf\" rel=\"noreferrer\">Massey 1983</a> (PDF) provides a construction that they claim characterizes the 7D cross product \"uniquely up to isomorphism\", but I don't understand what they mean by \"up to isomorphism.\"</p>\n\n<p>On the other hand, the <a href=\"https://en.wikipedia.org/wiki/Seven-dimensional_cross_product\" rel=\"noreferrer\">Wikipedia page on the 7D cross product</a> claims that there are 480 different multiplication tables for the 7D cross product. But are these actually distinct functions on the abstract (coordinate-free) vector space, or just the same function written with respect to different choices of ordered basis?</p>\n\n<p>The Wikipedia page also claims that \"the\" cross product (does their use of the word \"the\" imply that it's unique, or do they really mean \"a\" cross product?) is only invariant under the 14-dimensional subgroup <span class=\"math-container\">$G_2$</span> of the 21-dimensional group <span class=\"math-container\">$SO(7)$</span>. I don't have a great intuitive understanding of how to think about this result. But since the defining properties of the cross product are clearly <span class=\"math-container\">$SO(7)$</span>-invariant, the result seems to indicate to me that there is actually a continuous family of 7D cross products isomorphic to the homogeneous space <span class=\"math-container\">$SO(7)/G_2$</span>. If that's correct, then the space of 7D cross products actually forms a 7-dimensional manifold, and so there are an uncountably infinite number of distinct 7D cross products.</p>\n\n<p>So how many different 7D cross products are there? One? 480? An uncountably infinite number? How should I think about this?</p>\n\n<p>(My guess is that the answer is \"an uncountably infinite number\", and that (a) there's some subtlety hidden in Massey's phrase \"up to isomorphism\" which makes the answer greater than one, and (b) the 480 multiplication tables mentioned on Wikipedia are actually just the restriction of the full manifold of cross products to those whose basis vectors are permutations of each other.)</p>\n", "pids": ["53e9ba70b7602d970468f878"], "flag": 0}
{"question": "Building a quantum computer in simulation", "body": "<p>If one wants to start building a quantum computer from scratch inside simulations (like how people get to build a classical computer from scratch in the <a href=\"http://nand2tetris.org/\" rel=\"noreferrer\">Nand2Tetris course</a>), is it possible? </p>\n\n<p>If yes, what would be some possible approaches?</p>\n\n<p>Also, what will be the limits of such a simulated machine, given a specific amount of classical computing power? For instance, if we were to pick your average desktop/laptop, what will be the limit? If we take a supercomputer (like Titan) then what would be the limit?</p>\n", "pids": ["5f03046adfae54360a4630c6", "5550415545ce0a409eb3a5f1", "5c757390f56def97988b032a", "599c7971601a182cd263dd8a", "5c8a198b4895d9cbc6158ce3"], "flag": 1}
{"question": "Can Machine Learning or Deep Learning algorithms be utilised to &quot;improve&quot; the sampling process of a MCMC technique?", "body": "<p>Based on the little knowledge that I have on MCMC (Markov chain Monte Carlo) methods, I understand that sampling is a crucial part of the aforementioned technique. The most commonly used sampling methods are Hamiltonian and Metropolis. </p>\n\n<p>Is there a way to utilise machine learning or even deep learning to construct a more efficient MCMC sampler?</p>\n", "pids": ["59ae3be32bbe271c4c71b3cd", "5736986b6e3b12023e7300eb", "5c756a0cf56def97982fd9f8"], "flag": 1}
{"question": "A Measure Theoretic Formulation of Bayes&#39; Theorem", "body": "<p>I am trying to find a measure theoretic formulation of Bayes' theorem, when used in statistical inference, Bayes' theorem is usually defined as:</p>\n\n<p><span class=\"math-container\">$$p\\left(\\theta|x\\right) = \\frac{p\\left(x|\\theta\\right) \\cdot p\\left(\\theta\\right)}{p\\left(x\\right)}$$</span></p>\n\n<p>where:</p>\n\n<ul>\n<li><span class=\"math-container\">$p\\left(\\theta|x\\right)$</span>: the <em>posterior density</em> of the parameter.\n<br></li>\n<li><span class=\"math-container\">$p\\left(x|\\theta\\right)$</span>: the <em>statistical model</em> (or <em>likelihood</em>).\n<br></li>\n<li><span class=\"math-container\">$p\\left(\\theta\\right)$</span>: the <em>prior density</em> of the parameter.\n<br></li>\n<li><span class=\"math-container\">$p\\left(x\\right)$</span>: the <em>evidence</em>.</li>\n</ul>\n\n<p>Now how would we define Bayes' theorem in a measure theoretic way?\n<br>\nSo, I started by defining a probability space: </p>\n\n<p><span class=\"math-container\">$$\\left(\\Theta, \\mathcal{F}_\\Theta, \\mathbb{P}_\\Theta\\right)$$</span> </p>\n\n<p>such that <span class=\"math-container\">$\\theta \\in \\Theta$</span>.\n<br>\nI then defined another probability space:</p>\n\n<p><span class=\"math-container\">$$\\left(X, \\mathcal{F}_X, \\mathbb{P}_X\\right)$$</span></p>\n\n<p>such that <span class=\"math-container\">$x \\in X$</span>.\n<br>\nFrom here now on I don't know what to do, the joint probability space would be:</p>\n\n<p><span class=\"math-container\">$$\\left(\\Theta \\times X, \\mathcal{F}_\\Theta \\otimes \\mathcal{F}_X, ?\\right)$$</span></p>\n\n<p>but I don't know what the measure should be.\n<br>\nBayes' theorem should be written as follow:</p>\n\n<p><span class=\"math-container\">$$? = \\frac{? \\cdot \\mathbb{P}_\\Theta}{\\mathbb{P}_X}$$</span></p>\n\n<p>where:</p>\n\n<p><span class=\"math-container\">$$\\mathbb{P}_X = \\int_{\\theta \\in \\Theta} ? \\space \\mathrm{d}\\mathbb{P}_\\Theta$$</span></p>\n\n<p>but as you can see I don't know the other measures and in which probability space they reside.\n<br>\nI stumbled upon this <a href=\"https://www.physicsforums.com/threads/how-to-prove-bayes-rule-for-probability-measures.522058/\" rel=\"noreferrer\">thread</a> but it was of little help and I don't know how was the following measure-theoretic generalization of Bayes' rule reached:</p>\n\n<p><span class=\"math-container\">$${P_{\\Theta |y}}(A) = \\int\\limits_{x \\in A} {\\frac{{\\mathrm d{P_{\\Omega |x}}}}{{\\mathrm d{P_\\Omega }}}(y)\\mathrm d{P_\\Theta }}$$</span></p>\n\n<p>I'm self-studying measure theoretic probability and lack guidance so excuse my ignorance.</p>\n", "pids": ["5ce2c835ced107d4c6225f94"], "flag": 1}
{"question": "Violation of the Quantum Hamming bound", "body": "<p>The quantum Hamming bound for a non-degenerate $[[N,k,d]]$ quantum error correction code is defined as: </p>\n\n<p>\\begin{equation}\n2^{N-k}\\geq\\sum_{n=0}^{\\lfloor d/2\\rfloor}3^n\\begin{pmatrix}N \\\\ n\\end{pmatrix}.\n\\end{equation}\nHowever, there is no proof stating that degenerate codes should obey such bound. I wonder if there exists any example of a degenerate code violating the quantum Hamming bound, or if there have been some advances in proving similar bounds for degenerate codes.</p>\n", "pids": ["53e999d8b7602d970221f2c5", "53e9a1a1b7602d9702a97876"], "flag": 1}
{"question": "What problems have been frequently computationally verified for large values?", "body": "<p>Although any theorem (or true conjecture) can be computationally checked, many long-standing open problems have been computational verified for very large values. For example, the Collatz Conjecture and Fermat's Last Theorem (before it was proven) were computationally verified by large scale computation programs. Not only have these calculations been carried out, but there is a lengthy history of improving the bound for which these calculations have been carried out until.</p>\n\n<p>What are other problems (not necessarily from number theory) have been similarly verified for values up to some large bound, and how high have they been checked? Specifically I’m interested in cases where is an <strong>established history of computationally verifying the problem</strong> up to larger and larger bounds.</p>\n\n<p>I’m interested both in the current cutting edge and the <strong>history of the computation</strong>.</p>\n", "pids": ["5c7559ddf56def979880b506"], "flag": 0}
{"question": "Have all numbers with &quot;sufficiently many zeros&quot; been proven transcendental?", "body": "<p>Any number less than 1 can be expressed in base g as $\\sum _{k=1}^\\infty {\\frac {D_k}{g^k}}$, where $D_k$ is the value of the $k^{th}$ digit. If we were interested in only the non-zero digits of this number, we could equivalently express it as $\\sum _{k=1}^\\infty {\\frac {C_k}{g^{Z(k)}}}$, where $Z(k)$ is the position of the $k^{th}$ non-zero digit base $g$ and $C_k$ is the value of that digit (i.e. $C_k = D_{Z(k)}$).</p>\n\n<p>Now, consider all the numbers of this form $(\\sum _{k=1}^\\infty {\\frac {C_k}{g^{Z(k)}}})$ where the function $Z(k)$ eventually dominates any polynomial. Is there a proof that any number of this form is transcendental?</p>\n\n<p>So far, I have found a paper demonstrating this result for the case $g=2$; it can be found <a href=\"http://www.escholarship.org/uc/item/44t5s388?display=all\">here</a>.</p>\n", "pids": ["53e99aa6b7602d970231f786"], "flag": 0}
{"question": "Does machine learning really need data-efficient algorithms?", "body": "<p>Deep learning methods are often said to be very data-inefficient, requiring 100-1000 examples per class, where a human needs 1-2 to reach comparable classification accuracy.</p>\n<p>However, modern datasets are huge (or can be made huge), which begs the question of whether we really need data-efficient algorithms. Are there application areas where a data-efficient machine learning algorithm would be very useful, despite making trade-offs elsewhere, <em>e.g.</em> training or inference efficiency? Would an ML algorithm that is, say, 100x more data-efficient, while being 1000x slower, be useful?</p>\n<p>People who work on data-efficient algorithms often bring up robotics for &quot;motivation&quot;. But even for robotics, large datasets can be collected, as is done in this data-collection factory at Google:</p>\n<p><a href=\"https://i.stack.imgur.com/frkuJ.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/frkuJ.jpg\" alt=\"enter image description here\" /></a></p>\n<p>Basically, my concern is that while data-efficient algorithms exist (<em>e.g.</em> ILP, graphical models) and could be further improved, their practical applicability is squeezed between common tasks, where huge datasets exist, and rare ones, that may not be worth automating (leave something for humans!).</p>\n", "pids": ["6062eeec91e0118c891f194c", "607837a991e011f5ecc9dcda"], "flag": 1}
{"question": "Homology and Graph Theory", "body": "<p>What is the relationship between homology and graph theory? Can we form simplicial complexes from a graph $G$ and compute their homology groups? Are there any practical results in looking at the homology of simplicial complexes formed from a graph?</p>\n", "pids": ["53e9adfeb7602d97038058d6", "53e9b1d7b7602d9703c6ba06"], "flag": 0}
{"question": "Twirling Quantum Channels: Pauli and Clifford Twirling", "body": "<p>I am currently working through some papers related with approximations of more general quantum channels such as amplitude and phase damping channels to Pauli channels. The reason to do so is so that the Gottesman-Knill theorem is fulfilled and efficient Monte Carlo simulations can be performed for Quantum Error Correction codes.</p>\n\n<p>In such reading, I reach to some papers that use the so-called Twirling in order to justify this channel approximation, but I have not found much literature specifically talking about the topic, as I have found the information to be scattered and not so well distinguished. My principal doubt is the difference between Pauli and Clifford twirls, and if both of them can be applied to the same channel without losing too much on the approximation. For example:</p>\n\n<ul>\n<li><p>In <a href=\"https://arxiv.org/abs/1210.5799\" rel=\"noreferrer\">Surface code with decoherence: An analysis of three superconducting architectures</a> the authors justify the use of Pauli twirling in order to approximate the combined amplitude and phase damping channel to an asymmetric Pauli channel, relating their parameters.</p></li>\n<li><p>In <a href=\"https://arxiv.org/abs/0707.0685\" rel=\"noreferrer\">Symmetrized Characterization of Noisy Quantum Processes</a> the authors use the Clifford twirl to symmetrize channels such as the asymmetric Pauli channel to the depolarizing channel.</p></li>\n</ul>\n\n<p>I am wondering if someone can give me some insight about this topic, or provide specific literature about the topic of Twirling in Quantum Information Theory. Also ideas or references to the use of those techniques as approximations for error correction is interesting for me and welcome.</p>\n", "pids": ["5ce2d0c1ced107d4c63b36e7", "5c6106bcda56297340ad816f", "5b679156ab2dfb7a20289882", "58437718ac44360f1082dd89", "56d84034dabfae2eee821a04", "53e99dc5b7602d9702686997"], "flag": 1}
{"question": "Can spectrum &quot;specify&quot; an operator?", "body": "<p>Given a bounded operator $A$ on a Banach space $X$, one may find the spectrum $\\sigma(A)\\subset{\\bf C}$. </p>\n\n<p>Here are my <strong>questions</strong>:</p>\n\n<blockquote>\n  <ul>\n  <li>Given some set in the complex plane, say, $S\\subset{\\bf C}$, can one find an operator $A$ such that $\\sigma(A)=S$? </li>\n  <li>Is there a \"big picture\" for this kind of questions?</li>\n  </ul>\n</blockquote>\n", "pids": ["53e9a855b7602d97031a29ca"], "flag": 0}
{"question": "Quantum circuits explain algorithms, why didn&#39;t classical circuits?", "body": "<p>When explaining a <em>quantum</em> algorithm, many revert to 'circuit-speak' by drawing a diagram of how qubits split off into transformations and measurements, however, rarely if not never would someone explaining a <em>classical</em> math algorithm revert to its representation in binary circuits. I would understand that this is because transforms and such don't exist in the binary world, but:</p>\n\n<p>Doesn't this unnecessary focus on the computational details relating to <em>computing</em>-computing, rather than the mathematical/statistical/optimization problem that the circuitry merely only underlies, detract from the main problem/application at hand? Is the classical mindset just that intuitive and aligned to general human thought, that quantum circuits, on the other hand, will remain to be a standard explanation strategy?</p>\n", "pids": ["5fd6e28c98b36632c84b9751", "5c757057f56def97986e2e9b", "62708f615aee126c0fa691fb", "5c757178f56def979878101a"], "flag": 1}
{"question": "Compactness of a bounded operator $T\\colon c_0 \\to \\ell^1$", "body": "<p>Pitt Theorem says that any bounded linear operator $T\\colon \\ell^r \\to \\ell^p$, $1 \\leq p &lt; r &lt; \\infty$, or $T\\colon c_0 \\to \\ell^p$ is compact.</p>\n\n<p>I know how to prove this in case $\\ell^r \\to \\ell^p$, and $c_0 \\to \\ell^p$, where $p &gt; 1$. Main idea in the first case is that $\\ell^r$ is reflexive and hence closed ball $B_{\\ell^r}$ is weakly compact. In the second case we could just use Schauder Theorem ($T$ is compact if and only if $T^*$ is compact).</p>\n\n<p>The only case left is $T\\colon c_0 \\to \\ell^1$. I have tried something like this:</p>\n\n<p>By Schauder Theorem we need to prove that $T^*\\colon \\ell^\\infty \\to \\ell^1$ is compact. By Banach-Alaoglu Theorem we know that $B_{\\ell^\\infty}$ is compact in the $weak^{*}$ topology on $\\ell^\\infty$. Moreover, we know, since $\\ell^1$ is separable, that $B_{\\ell^\\infty}$ is metrizable. Hence, it is enough to prove that if $(x_n)$ is a $weak{}^{*}$ convergent (say, to $x$) sequence in $B_{\\ell^\\infty}$ then $(Tx_n)$ converges (to $Tx$, I think). Since Schur Theorem (weak and norm convergence is the same in $\\ell^1$) we only need to show that $(Tx_n)$ converges weakly in $\\ell^1$.</p>\n\n<p>And here I stuck. Could you give me any ideas or references? In every book I have looked so far this particular case was omitted.</p>\n\n\n\n<p><strong>Edit (4.4.2011):</strong> I found in Diestel's <em>Sequences and series in Banach spaces</em> (chap. VII, Exercise 2(ii)) something like this:</p>\n\n<p>A bounded operator $T: c_0 \\to X$ is compact if and only if every subseries of $\\sum_{n=1}^\\infty Te_n$ is convergent, where $(e_n)$ is canonical basis for $c_0$.</p>\n\n<p>I know how to prove this, but how we can show that operators $T: c_0 \\to \\ell^1$ possess the subseries property?</p>\n", "pids": ["53e9b360b7602d9703e3f4d9"], "flag": 0}
{"question": "What is a Bacon-Shor code and what is its significance?", "body": "<p>I'm at the AQC conference at NASA and everybody seems to suddenly be talking about the <a href=\"http://qserver.usc.edu/qec11/slides/Brooks_QEC11.pdf\" rel=\"noreferrer\">Bacon-Shor</a> code but there is no Wikipedia page and the pdf that I gave a link to does not really explain what it is and how it works.</p>\n\n<p>How does it compare to the <a href=\"https://quantumcomputing.stackexchange.com/questions/1845/intuition-for-shor-code-failure-probability\">Shor code</a> ?</p>\n", "pids": ["53e9b8f5b7602d97044d95bb", "56d90073dabfae2eeed3d798", "53e99a6eb7602d97022dff2f", "56d90073dabfae2eeed3d798", "56d829c0dabfae2eeef46bc2", "53e9a0fbb7602d97029e467f", "53e99c7cb7602d970252fb2d", "5c75732cf56def979887590a"], "flag": 1}
{"question": "How does approximating gates via universal gates scale with the length of the computation?", "body": "<p>I understand that there is a <a href=\"https://arxiv.org/abs/quant-ph/0505030\" rel=\"noreferrer\">constructive proof</a> that arbitrary gates can be approximated by a finite universal gate set, which is the <a href=\"https://en.wikipedia.org/wiki/Solovay%E2%80%93Kitaev_theorem\" rel=\"noreferrer\">Solovay–Kitaev Theorem</a>.<br>\nHowever, the approximation introduces an error, which would spread and accumulate in a long computation. This would presumably scale badly with the length of the calculation? Possibly one might apply the approximation algorithm to the complete circuit as a whole, not to a single gate. But how does this scale with the length of the computation (i.e. how does the approximation scale with the dimension of the gates)? How does the gate approximation relate to gate synthesis? Because I could imagine that this affects the final length of the computation?<br>\nEven more disturbing to me: What happens if the length of the calculation is not known at the time when the gate sequence is compiled?</p>\n", "pids": ["53e99bd5b7602d970247d17a"], "flag": 1}
{"question": "Is the common Computer Science usage of &#39;ignoring constants&#39; useful when comparing classical computing with quantum computing?", "body": "<p>Daniel Sank mentioned in <a href=\"https://quantumcomputing.stackexchange.com/questions/171/is-there-proof-that-the-d-wave-one-is-a-quantum-computer-and-is-effective/172?noredirect=1#comment426_172\">a comment</a>, responding to (my) opinion that the <em>constant</em> speed-up of $10^8$ on a problem admitting a polynomial time algorithm is meager, that </p>\n\n<blockquote>\n  <p>Complexity theory is way too obsessed with infinite size scaling limits. What matters in real life is how fast you get the answer to your problem. </p>\n</blockquote>\n\n<p>In Computer Science, it is common to ignore constants in algorithms, and all in all, this has turned out to work rather well. (I mean, there <em>are</em> good and <em>practical</em> algorithms. I hope you will grant me (theoretical) algorithms researchers have had a rather large hand in this!)</p>\n\n<p>But, I do understand that this is a slightly different situation as now we are:</p>\n\n<ol>\n<li>Not comparing two algorithms running on the same computer, but two (slightly) different algorithms on two <em>very different</em> computers.</li>\n<li>We now are working with <em>quantum</em> computers, for which perhaps traditional perfomance measurements may be insufficient.</li>\n</ol>\n\n<p>In particular, the methods of algorithm analysis are merely <em>methods</em>. I think radically new computing methods calls for a critical review of our current performance evaluation methods!</p>\n\n<p>So, my question is:</p>\n\n<p>When comparing the performance of algorithms on a quantum computer versus algorithms on a classical computer, is the practice of 'ignoring' constants a good practice?</p>\n", "pids": ["5c757228f56def97987e79d8", "5ce2d064ced107d4c637353d"], "flag": 1}
{"question": "Probability formula for a multivariate-bernoulli distribution", "body": "<p>I need a formula for the probability of an event in a n-variate Bernoulli distribution $X\\in\\{0,1\\}^n$ with given $P(X_i=1)=p_i$ probabilities for a single element and for pairs of elements $P(X_i=1 \\wedge X_j=1)=p_{ij}$. Equivalently I could give mean and covariance of $X$. </p>\n\n<p>I already learned that there exist many $\\{0,1\\}^n$ distributions having the properties just as there are many distributions having a given mean and covariance. I am looking for a canonical one on $\\{0,1\\}^n$, just as the Gaussian is a canonical distribution for $R^n$ and a given mean and covariance.</p>\n", "pids": ["53e99b8db7602d9702434236"], "flag": 1}
{"question": "Simplification of expressions containing radicals", "body": "<p>As an example, consider the polynomial $f(x) = x^3 + x - 2 = (x - 1)(x^2 + x + 2)$ which clearly has a root $x = 1$.\nBut we can also find the roots using Cardano's method, which leads to</p>\n\n<p>$$x = \\sqrt[3]{\\sqrt{28/27} + 1} - \\sqrt[3]{\\sqrt{28/27} - 1}$$</p>\n\n<p>and two other roots.</p>\n\n<p>It's easy to check numerically that this expression is really equal to $1$, but is there a way to derive it algebraically which isn't equivalent to showing that this expression satisfies $f(x) = 0$?</p>\n", "pids": ["53e9a4d6b7602d9702df48cd", "53e998f6b7602d9702136d43"], "flag": 0}
{"question": "Does quantum computing threaten blockchain?", "body": "<p>As per Wikipedia, <a href=\"https://en.wikipedia.org/wiki/Blockchain\" rel=\"noreferrer\"><em>blockchains</em></a> are a way to maintain \"a continuously growing list of records, called blocks, which are linked and secured using cryptography [... and] inherently resistant to modification of the data.\"</p>\n\n<p>Blockchains are in current practical use, for example in the cryptocurrency <a href=\"https://en.wikipedia.org/wiki/Cryptocurrency\" rel=\"noreferrer\">bitcoin</a>. These implementations must make use of some particular approach to cryptography, which will involve assumptions intended to underwrite their security.</p>\n\n<p>Are the current implementations of blockchain resistant to attacks using quantum computation?</p>\n", "pids": ["5b076eb4da5629516ce730ae", "5b1643ba8fbcbf6e5a9bc4cd"], "flag": 1}
{"question": "Are vaccinated children significantly less healthy than the unvaccinated, as recent study claims?", "body": "<p>In their 2020 <a href=\"https://pubmed.ncbi.nlm.nih.gov/33266457/\" rel=\"noreferrer\">study</a> termed &quot;Relative Incidence of Office Visits and Cumulative Rates of Billed Diagnoses Along the Axis of Vaccination&quot; <a href=\"https://www.mdpi.com/1660-4601/17/22/8674/pdf\" rel=\"noreferrer\">[full text]</a>, appearing in the <em>International Journal of Environmental Research and Public Health</em>, <a href=\"https://www.longdom.org/editor/james-lyons-weiler-9274\" rel=\"noreferrer\">Lyons-Weiler et al.</a> analyze a dataset spanning ten years of pediatric practice.</p>\n<p><strong>Study Synopsis</strong></p>\n<p>In a nutshell, this dataset contains a total of 21.777 actual patients and includes vaccination history, office visits, and billed diagnosis.</p>\n<p>First, the authors pool vaccinated and non-vaccinated patients. Second, the authors perform statistical analysis on the distribution of (a) office visits and (b) billed diagnosis among both groups.</p>\n<p>Findings seem to indicate a drastic enrichment (&gt;95% CI) of various diagnosed diseases within the vaccinated group, compared to the non-vaccinated one (see image below).</p>\n<p>Based on those results, the study concludes:</p>\n<blockquote>\n<p>We can conclude that the unvaccinated children in this practice are\nnot, overall, less healthy than the vaccinated and that indeed the\nvaccinated children appear to be significantly less healthy than the\nunvaccinated</p>\n</blockquote>\n<p><strong>Thoughts</strong></p>\n<p>On the one hand, the authors include at least some statistical evaluations on the robustness of their results.</p>\n<p>On the other hand, the article is lacking any hypothesis why similar effects can't be found with the same methods on other datasets.</p>\n<p>Furthermore, many of their &quot;disease&quot; criteria are not actual diseases but a loose group of symptoms generally associated with a vague disease-like term that lacks proper definition, such as &quot;behavioral issues&quot;.</p>\n<p>In summary, those results seem credible at first sight, but also highly counter-intuitive.</p>\n<p><strong>Therefore, I am highly skeptical.</strong></p>\n<p><strong>Questions</strong></p>\n<ol>\n<li><strong>Are vaccinated people significantly more susceptible to a wide range of diseases?</strong></li>\n<li><strong>Is the approach of this study following good scientific practice?</strong></li>\n<li><strong>Which follow-up analysis are adequate to verify/falsify their hypothesis?</strong></li>\n<li><strong>Are there any studies that directly support/contradict those findings on a larger dataset?</strong></li>\n</ol>\n<p><a href=\"https://i.stack.imgur.com/DOXzX.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/DOXzX.png\" alt=\"enter image description here\" /></a></p>\n", "pids": ["5ce2d06cced107d4c6378fda"], "flag": 1}
{"question": "What are the practical uses of Neural ODEs?", "body": "<p>\"Neural Ordinary Differential Equations\", by Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt and David Duvenaud, was awarded the <a href=\"https://nips.cc/Conferences/2018/Awards\" rel=\"noreferrer\">best-paper award in NeurIPS in 2018</a></p>\n\n<p>There, authors propose the NeuralODE, which is a method that fuses concepts of Differential Equations and Neural Networks. Borrowing from previous literature and contributing newer developments, NeuralODEs can, for example, use Differential Equation Solvers in their forward pass and still maintain a computable backward pass.</p>\n\n<p>Two examples in the paper really caught the attention in the media I think, which were on Flow-based generative modelling and the pseudo-equivalence between the ResNet skip-connection depth and the NeuralODE number of function evaluations (see more here: <a href=\"https://stats.stackexchange.com/questions/441779/what-is-the-continuous-depth-concept-in-neural-ode-paper-by-david-duvenaud\">What is the continuous depth concept in Neural ODE paper by David Duvenaud?</a>).</p>\n\n<p>So, for brevity's sake, two questions need to be made pertaining to the way they are to be actually used (which I'm surprised we did not have in CV yet):</p>\n\n<ul>\n<li><p>Is there something NeuralODEs do that \"conventional\" Neural Networks cannot? Continuous time computations? \"Infinite\" \"depth\" computation?</p></li>\n<li><p>Is there something \"conventional\" Neural Networks do that NeuralODEs cannot do? </p></li>\n</ul>\n", "pids": ["5d25bcd73a55ac8369528eb5", "5de799809e795e77580692fb", "5d06e492da562926acc556fd", "59ae3be32bbe271c4c71b791", "5bdc31b817c44a1f58a0bcb4", "5cede0fdda562983788dd567", "5e1456e93a55acd652ef3258"], "flag": 1}
{"question": "Scalability of ion trap quantum computers", "body": "<p>My understanding is that the magnetic fields needed to hold the ions in place in ion trap quantum computers are very complex, and for that reason, currently, only 1-D computers are possible, therefore reducing the ease of communication between qubits. There does seem to be a proposition for a 2-d system using a Paul trap <a href=\"https://arxiv.org/pdf/1408.6659.pdf\" rel=\"noreferrer\">in this preprint</a> but I can't seem to find if this has actually been tested.</p>\n\n<p>Does the scalability of ion trap quantum computers depend upon this alone (whether or not the ions can be arranged in configurations other than a straight line) or are other factors entailed? If the former, what progress has been made? If the latter, what are the other factors?</p>\n", "pids": ["55a4ad2165ceb7cb02d5d04a"], "flag": 1}
{"question": "What is Fourier Analysis on Groups and does it have &quot;applications&quot; to physics?", "body": "<p>I am trying to be as specific as possible, but I am extremely unclear about this topic (Fourier Analysis on Groups). </p>\n\n<p>In Reed-Simon Vol II (Fourier Analysis, Self-Adjointness) there is some discussion about semigroups (those that are holomorphic, hypercontractive, $L^p$-contractive, strongly continuous). There is also mention of pseudo-differential operators in the noncommutative case. Furthermore, I know that infinte-dimensional group representations are very valuable in physics as well, but is that even related to the the group representations that arise in \"Fourier Analysis on Groups\"? </p>\n\n<p>I know I am asking an extremely superficial question, but I don't know anything about Fourier Analysis on Groups and I am trying to understand what it is about. </p>\n", "pids": ["53e9b815b7602d97043c7b86"], "flag": 0}
{"question": "Texas sharpshooter fallacy in exploratory data analysis", "body": "<p>I was reading <a href=\"http://www.nature.com/news/how-scientists-fool-themselves-and-how-they-can-stop-1.18517\">this</a> article in Nature in which some fallacies are explained in the context of data analysis. I noticed that the Texas sharpshooter fallacy was particularly difficult to avoid:</p>\n\n<blockquote>\n  <p>A cognitive trap that awaits during data analysis is illustrated by\n  the fable of the Texas sharpshooter: an inept marksman who fires a\n  random pattern of bullets at the side of a barn, draws a target around\n  the biggest clump of bullet holes, and points proudly at his success.</p>\n  \n  <p>His bullseye is obviously laughable — but the fallacy is not so\n  obvious to gamblers who believe in a 'hot hand' when they have a\n  streak of wins, or to people who see supernatural significance when a\n  lottery draw comes up as all odd numbers.</p>\n  \n  <p><strong>Nor is it always obvious to researchers. “You just get some\n  encouragement from the data and then think, well, this is the path to\n  go down,” says Pashler. “You don't realize you had 27 different\n  options and you picked the one that gave you the most agreeable or\n  interesting results, and now you're engaged in something that's not at\n  all an unbiased representation of the data.</strong>”</p>\n</blockquote>\n\n<p>I think that kind of exploration work is commonplace and often, hypotheses are constructed based on that part of the analysis. There is a whole approach (<a href=\"https://en.wikipedia.org/wiki/Exploratory_data_analysis\">EDA</a>) dedicated to this process:</p>\n\n<blockquote>\n  <p>Exploratory data analysis was promoted by John Tukey to encourage\n  statisticians to explore the data, and possibly formulate hypotheses\n  that could lead to new data collection and experiments</p>\n</blockquote>\n\n<p>It looks like any exploratory process performed without having a hypothesis beforehand is prone to generate spurious hypotheses. </p>\n\n<p>Notice that the description of EDA above actually talks about <code>new data collection and experiments</code>. I understand that after new data have been collected, then a confirmatory data analysis (CDA) is appropriate. However, I don't think this distinction is made very clearly, and although a separation of EDA and CDA would be ideal, surely there are some circumstances in which this is not feasible. I would go as far as to say that following this separation strictly is uncommon and most practitioners don't subscribe to the EDA paradigm at all. </p>\n\n<p>So my question is: Does EDA (or any informal process of exploring data) make it more likely to fall for the Texas sharpshooter fallacy?</p>\n", "pids": ["5ce2d09cced107d4c639983d"], "flag": 1}
{"question": "What is a tight lower bound on the coupon collector time?", "body": "<p>In the classic <a href=\"http://en.wikipedia.org/wiki/Coupon_collector%27s_problem\">Coupon Collector's problem</a>, it is well known that the time $T$ necessary to complete a set of $n$ randomly-picked coupons satisfies $E[T] \\sim n \\ln n $,$Var(T) \\sim n^2$, and $\\Pr(T &gt; n \\ln n + cn) &lt; e^{-c}$. </p>\n\n<p>This upper bound is better than the one given by the Chebyshev inequality, which would be roughly  $1/c^2$.</p>\n\n<p>My question is: is there a corresponding better-than-Chebyshev <em>lower bound</em> for $T$? (e.g., something like $\\Pr(T &lt; n \\ln n - cn) &lt; e^{-c}$ ) ?</p>\n", "pids": ["5a9cb66717c44a376ffb8b06"], "flag": 1}
{"question": "How to permute (reshuffle) an n-bit input?", "body": "<p>I am interested in a quantum algorithm that gets as input an n-bit sequence and that produces as output a reshuffled (permuted) version of this n-bit sequence.</p>\n\n<p>E.g. if the input is 0,0,1,1 (so n=4 in this case) then the possible answers are:</p>\n\n<ul>\n<li>0,0,1,1</li>\n<li>0,1,0,1</li>\n<li>0,1,1,0</li>\n<li>1,0,0,1</li>\n<li>1,0,1,0</li>\n<li>1,1,0,0</li>\n</ul>\n\n<p>Note that only one output should be generated which is randomly chosen among all possible valid outputs. </p>\n\n<p>How can this best be implemented in a <strong>quantum algorithm</strong> ?</p>\n\n<p>A solution for this is already proposed as part of one of the answers for <a href=\"https://quantumcomputing.stackexchange.com/questions/2209/how-to-create-a-quantum-algorithm-that-produces-2-n-bit-sequences-with-equal-num\">How to create a quantum algorithm that produces 2 n-bit sequences with equal number of 1-bits?</a>.  But the problem with this solution is that this requires about $\\binom{n}2$ help qubits which becomes rapidly huge if n is big.</p>\n\n<p>Note:</p>\n\n<ul>\n<li>Please, do not provide a classical algorithm without any explanation of how the steps of the classical algorithm can be mapped to a universal quantum computer.</li>\n<li>for me there are 2 good ways to interpret <em>\"randomly chosen among all possible good outputs\"</em>:  (1) each possible good output has equal chance of being chosen. (2) every possible good output has a chance > 0 of being chosen.</li>\n</ul>\n", "pids": ["55a69d4e65ce054aad6dde4e", "5c75726af56def979880eb00"], "flag": 1}
{"question": "In regression analysis what&#39;s the difference between data-generation process and model?", "body": "<p>In regression analysis what's the difference between 'data-generation process' and 'model'? </p>\n", "pids": ["56d873e0dabfae2eee096199"], "flag": 1}
{"question": "k-means implementation with custom distance matrix in input", "body": "<p>Can anyone point me out a k-means implementation (it would be better if in matlab) that can take the distance matrix in input?\nThe standard matlab implementation needs the observation matrix in input and it is not possible to custom change the similarity measure.   </p>\n", "pids": ["53e9af61b7602d97039a2fd8"], "flag": 1}
{"question": "Fitting t-distribution in R: scaling parameter", "body": "<p>How do I fit the parameters of a t-distribution, i.e. the parameters corresponding to the 'mean' and 'standard deviation' of a normal distribution. I assume they are called 'mean' and 'scaling/degrees of freedom' for a t-distribution?</p>\n\n<p>The following code often results in 'optimization failed' errors.</p>\n\n<pre><code>library(MASS)\nfitdistr(x, \"t\")\n</code></pre>\n\n<p>Do I have to scale x first or convert into probabilities? How best to do that?   </p>\n", "pids": ["5fe1d35e91e0119a161eddf7"], "flag": 1}
{"question": "Why did a famous mathematician say that algebraic topology was dead?", "body": "<p>I found Novikov said that algebraic topology was dead in the early 1970's in this <a href=\"http://celebratio.org/cm/2/bgroup/4/\">article</a>.</p>\n\n<blockquote>\n  <p>Segal had been one of Atiyah's first students, working on equivariant K-theory, and \n  then other equivariant generalized cohomology theories. He was a collaborator on the second of the Annals papers on the index theorem. Well known as an algebraic topologist, he arrived in Moscow in the early 1970s to give some lectures and met S. Novikov, who told him, “So you are a topologist? Here we think that algebraic topology is dead.”</p>\n</blockquote>\n\n<p>I wonder what he meant by it.\nAny thoughts?</p>\n\n<p><strong>Note</strong> I heard that Thom also said so, but I could find only <a href=\"http://ja.wikipedia.org/wiki/%E3%83%AB%E3%83%8D%E3%83%BB%E3%83%88%E3%83%A0\">Japanese Wikipedia article</a> saying he said so, which does not give a reference for that assertion.</p>\n", "pids": ["5c7846604895d9cbc68dfa45"], "flag": 0}
{"question": "Is this what &quot;happiness looks like&quot;?", "body": "<p>This gif has been widely distributed on imgur/reddit/twitter/media and it is meant to represent</p>\n\n<blockquote>\n  <p>Molecules of the protein myosin drag a ball of endorphins along an active filament into the inner part of the brain's parietal cortex, which produces feelings of happiness.</p>\n</blockquote>\n\n<p><a href=\"https://i.stack.imgur.com/QZBMz.gif\"><a src=\"https://i.stack.imgur.com/QZBMz.gif\" alt=\"Video in the claim\"></a></p>\n\n<p>However, I have some doubts.</p>\n\n<p>For example, on imgur there are people that claim it isn't so:</p>\n\n<blockquote>\n  <p>That's kinesin transporting a vesicle along a microtubule. I hope OP's not one of my students ...</p>\n</blockquote>\n\n<p>And the video looks uncannily similar, but not identical, to this Harvard BioVisions <a href=\"http://multimedia.mcb.harvard.edu/anim_innerlife.html\">\"Inner life of the cell\" video</a> (about halfway through) where it represents inner cell activity unrelated to endorphin or the brain.</p>\n\n<p><a href=\"https://i.stack.imgur.com/SN74N.png\"><a src=\"https://i.stack.imgur.com/SN74Nm.png\" alt=\"Harvard video\"></a></p>\n\n<p>Was this video meant to represent a ball of endorphins being transported into the brain cortex or is it a different biology video which has been misrepresented?</p>\n", "pids": ["53e99de2b7602d97026a4e7f"], "flag": 1}
{"question": "What are some well known improvements over textbook MCMC algorithms that people use for bayesian inference?", "body": "<p>When I'm coding a Monte Carlo simulation for some problem, and the model is simple enough, I use a very basic textbook Gibbs sampling. When it's not possible to use Gibbs sampling, I code the textbook Metropolis-Hastings I've learned years ago. The only thought I give to it is choosing the jumping distribution or its parameters.</p>\n\n<p>I know there are hundreds and hundreds of specialized methods that improve over those textbook options, but I usually never think about using/learning them. It usually feels like it's too much effort to improve a little bit what is already working very well. </p>\n\n<p>But recently I've been thinking if maybe there aren't new general methods that can improve over what I've been doing. It's been many decades since those methods were discovered. Maybe I'm <em>really</em> outdated!</p>\n\n<p><strong>Are there any well known alternatives to Metropolis-Hastings that are:</strong></p>\n\n<ul>\n<li><strong>reasonably easy to implement,</strong> </li>\n<li><strong>as universally appliable as MH,</strong> </li>\n<li><strong>and always improves over MH's results in some sense (computational performance, accuracy, etc...)?</strong></li>\n</ul>\n\n<p>I know about some very specialized improvements for very specialized models, but are there some general stuff everybody uses that I don't know? </p>\n", "pids": ["56d8b1e3dabfae2eeee83835"], "flag": 1}
{"question": "What is Recurrent Reinforcement Learning", "body": "<p>I recently came across the word of \"Recurrent Reinforcement Learning\". I understand what \"Recurrent Neural Network\" is and what \"Reinforcement Learning\" is, but couldn't find much information about what a \"Recurrent Reinforcement Learning\" is. </p>\n\n<p>Can someone explain to me what is a \"Recurrent Reinforcement learning\" and what is the difference between \"Recurrent Reinforcement learning\" and normal \"Reinforcement learning\" like Q-Learning algorithm. </p>\n", "pids": ["573696106e3b12023e522918"], "flag": 1}
{"question": "Grover&#39;s algorithm: a real life example?", "body": "<p>I'm fairly confused about how Grover's algorithm could be used in practice and I'd like to ask help on clarification through an example.</p>\n\n<p>Let's assume an $N=8$ element database that contains colors Red, Orange, Yellow, Green, Cyan, Blue, Indigo and Violet, and not necessarily in this order. My goal is to find Red in the database.</p>\n\n<p>The input for Grover's algorithm is $n = \\log_2(N=8) = 3$ qubits, where the 3 qubits encode the indices of the dataset. My confusion comes here (might be confused about the premises so rather say confusion strikes here) that, as I understand, the oracle actually searches for one of the indices of the dataset (represented by the superposition of the 3 qubits), and furthermore, the oracle is \"hardcoded\" for which index it should look for.</p>\n\n<p>My questions are:</p>\n\n<ul>\n<li>What do I get wrong here?</li>\n<li>If the oracle is really looking for one of the indices of the database, that would mean we know already which index we are looking for, so why searching?</li>\n<li>Given the above conditions with the colors, could someone point it out if it is possible with Grover's to look for Red in an unstructured dataset? </li>\n</ul>\n\n<p>There are implementations for Grover's algorithm with an oracle for $n=3$ searching for |111>, e.g. (or see an R implementation of the same oracle below): \n<a href=\"https://i.stack.imgur.com/eF896.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/eF896.png\" alt=\"Oracle for 111\"></a>\n<a href=\"https://quantumcomputing.stackexchange.com/a/2205\">https://quantumcomputing.stackexchange.com/a/2205</a></p>\n\n<p>Again, my confusion is, given I do not know the position of $N$ elements in a dataset, the algorithm requires me to search for a string that encodes the position of $N$ elements. How do I know which position I should look for when the dataset is unstructured?</p>\n\n<p>R code:</p>\n\n<pre><code> #START\n a = TensorProd(TensorProd(Hadamard(I2),Hadamard(I2)),Hadamard(I2))\n # 1st CNOT\n a1= CNOT3_12(a)\n # 2nd composite\n # I x I x T1Gate\n b = TensorProd(TensorProd(I2,I2),T1Gate(I2)) \n b1 = DotProduct(b,a1)\n c = CNOT3_02(b1)\n # 3rd composite\n # I x I x TGate\n d = TensorProd(TensorProd(I2,I2),TGate(I2))\n d1 = DotProduct(d,c)\n e = CNOT3_12(d1)\n # 4th composite\n # I x I x T1Gate\n f = TensorProd(TensorProd(I2,I2),T1Gate(I2))\n f1 = DotProduct(f,e)\n g = CNOT3_02(f1)\n #5th composite\n # I x T x T\n h = TensorProd(TensorProd(I2,TGate(I2)),TGate(I2))\n h1 = DotProduct(h,g)\n i = CNOT3_01(h1)\n #6th composite\n j = TensorProd(TensorProd(I2,T1Gate(I2)),I2)\n j1 = DotProduct(j,i)\n k = CNOT3_01(j1)\n #7th composite\n l = TensorProd(TensorProd(TGate(I2),I2),I2)\n l1 = DotProduct(l,k)\n #8th composite\n n = TensorProd(TensorProd(Hadamard(I2),Hadamard(I2)),Hadamard(I2))\n n1 = DotProduct(n,l1)\n n2 = TensorProd(TensorProd(PauliX(I2),PauliX(I2)),PauliX(I2))\n a = DotProduct(n2,n1)\n #repeat the same from 2st not gate\n a1= CNOT3_12(a)\n # 2nd composite\n # I x I x T1Gate\n b = TensorProd(TensorProd(I2,I2),T1Gate(I2))\n b1 = DotProduct(b,a1)\n c = CNOT3_02(b1)\n # 3rd composite\n # I x I x TGate\n d = TensorProd(TensorProd(I2,I2),TGate(I2))\n d1 = DotProduct(d,c)\n e = CNOT3_12(d1)\n # 4th composite\n # I x I x T1Gate\n f = TensorProd(TensorProd(I2,I2),T1Gate(I2))\n f1 = DotProduct(f,e)\n g = CNOT3_02(f1)\n #5th composite\n # I x T x T\n h = TensorProd(TensorProd(I2,TGate(I2)),TGate(I2))\n h1 = DotProduct(h,g)\n i = CNOT3_01(h1)\n #6th composite\n j = TensorProd(TensorProd(I2,T1Gate(I2)),I2)\n j1 = DotProduct(j,i)\n k = CNOT3_01(j1)\n #7th composite\n l = TensorProd(TensorProd(TGate(I2),I2),I2)\n l1 = DotProduct(l,k)\n #8th composite\n n = TensorProd(TensorProd(PauliX(I2),PauliX(I2)),PauliX(I2))\n n1 = DotProduct(n,l1)\n n2 = TensorProd(TensorProd(Hadamard(I2),Hadamard(I2)),Hadamard(I2))\n n3 = DotProduct(n2,n1)\n result=measurement(n3)\n plotMeasurement(result)\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/zJBT3.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/zJBT3.png\" alt=\"Image2\"></a></p>\n", "pids": ["5f0eb63d9fced0a24bf622f3", "5e5e18b293d709897ce287cc", "63c0cc6490e50fcafd2a8dee"], "flag": 1}
{"question": "A Geometric Proof of $\\zeta(2)=\\frac{\\pi^2}6$? (and other integer inputs for the Zeta)", "body": "<p>Is there a known geometric proof for this famous problem? $$\\zeta(2)=\\sum_{n=1}^\\infty n^{-2}=\\frac16\\pi^2$$</p>\n\n<p>Moreover we can consider possibilities of geometric proofs of the following identity for positive even inputs of the Zeta function:\n$$ \\zeta(2n)=(-1)^{n+1} \\frac{B_{2n}(2\\pi)^{2n}}{2(2n)!}$$\nand negative inputs:\n$$ \\zeta(-n)=-\\frac{B_{n+1}}{n+1}$$</p>\n", "pids": ["622951695aee126c0f0e0912", "53e9ba05b7602d9704605861"], "flag": 0}
{"question": "Can we prove the existence of $A\\cup B$ without the union axiom?", "body": "<p>If <span class=\"math-container\">$A$</span> and <span class=\"math-container\">$B$</span> are sets, then <span class=\"math-container\">$A\\cup B$</span> is defined as follows:\n<span class=\"math-container\">$$A\\cup B:=\\{x: x\\in A \\, \\, \\,\\text{ or } \\, \\, \\, x\\in B\\}.$$</span></p>\n<p>In ZFC, <span class=\"math-container\">$A\\cup B$</span> exists because <span class=\"math-container\">$\\bigcup\\{A, B\\}$</span> exists by union axiom, and it is known that axiom of union is independent of rest of ZFC.</p>\n<p>If there is a set such that <span class=\"math-container\">$A\\subseteq C$</span> and <span class=\"math-container\">$B\\subseteq C$</span>, then we can define <span class=\"math-container\">$A\\cup B$</span> using the <span class=\"math-container\">$C$</span> and separation axiom. But can I prove the existence of <span class=\"math-container\">$C$</span> in ZF-Union? Thanks for any help.</p>\n", "pids": ["5c8a29594895d9cbc61db16e"], "flag": 0}
{"question": "What algorithm does ward.D in hclust() implement if it is not Ward&#39;s criterion?", "body": "<blockquote>\n  <p>The one used by option \"ward.D\" (equivalent to the only Ward option\n  \"ward\" in R versions &lt;= 3.0.3) does not implement Ward's (1963)\n  clustering criterion, whereas option \"ward.D2\" implements that\n  criterion (Murtagh and Legendre 2014).</p>\n</blockquote>\n\n<p>(<a href=\"http://stat.ethz.ch/R-manual/R-patched/library/stats/html/hclust.html\" rel=\"noreferrer\">http://stat.ethz.ch/R-manual/R-patched/library/stats/html/hclust.html</a>)</p>\n\n<p>Apparently ward.D does not implement Ward's criterion properly. Nonetheless it seems to do a good job regarding the clusterings it produces. What does method=\"ward.D\" implement if it is not Ward's criterion?</p>\n\n<p><strong>References</strong></p>\n\n<p>Murtagh, F., &amp; Legendre, P. (2014). Ward’s hierarchical agglomerative clustering method: which algorithms implement Ward’s criterion?. <em>Journal of Classification</em>, <strong>31</strong>(3), 274-295.</p>\n", "pids": ["53e9a525b7602d9702e48adf"], "flag": 1}
{"question": "Is there a good (preferably comprehensive) list of which conjectures imply the Riemann Hypothesis?", "body": "<p>I wanted to prepare a presentation for the students I tutor on the <a href=\"http://en.wikipedia.org/wiki/Clay_Millennium_Problems#Problems\" rel=\"nofollow\">Clay Millennium problems</a>. </p>\n\n<p>This is directed at the <a href=\"http://en.wikipedia.org/wiki/Clay_Millennium_Problems#The_Riemann_hypothesis\" rel=\"nofollow\">Riemann Hypothesis</a> and the Generalized Riemann Hypothesis.</p>\n\n<p>The <a href=\"http://en.wikipedia.org/wiki/Riemann_hypothesis#Consequences_of_the_Riemann_hypothesis\" rel=\"nofollow\">Wikipedia article</a> is good at showing how many conjectures be come true if RH or GRH is proven to be true:</p>\n\n<ul>\n<li>$GRH \\implies Conjecture\\;X$.</li>\n</ul>\n\n<p>What am looking for is list of possible solution paths where; if <em>something</em> is true then the GRH (or the RH) is true or <em>something</em> is equivalent to GRH (or the RH):</p>\n\n<ul>\n<li><p>$Conjecture\\;X \\;\\implies GRH$.</p></li>\n<li><p>$Conjecture\\;X \\iff GRH$.</p></li>\n</ul>\n\n<p>The Wikipedia article is a good reference for the first bullet point, but not for the last two.</p>\n\n<p>I am looking for references to fill out a list regarding the last two bullet points for my presentation.</p>\n", "pids": ["53e9b8a8b7602d970448027f"], "flag": 0}
{"question": "Can a group have a subset that is stable under all automorphisms, but not under inverse?", "body": "<p>The title really says it all. For any group $G$ the map $g\\mapsto g^{-1}$ gives a (canonical) isomorphism from $G$ to the opposite group $G^\\mathrm{op}$; this marks a difference with for instance non-commutative rings where the two might not be isomorphic. As a consequence there is for instance no fundamental difference between studying left and right group actions, even for a fixed group$~G$.</p>\n\n<p>So while groups cannot be in any manner \"naturally left-handed\", whatever that might be construed to mean, there is still the potential possibility of being able to point to some \"chiral\" subset of the group, a subset that might have some relation to the group without being in the same relation to the opposite group. It is quite evident that notions such as normaliser or centraliser applied to some (set of) elements will never yield such subset; indeed anything that is a subgroup will not do because it is closed under inverse.</p>\n\n<p>Which brought me to my question:</p>\n\n<blockquote>\n  <p>Can a group $G$ have a subset closed under the action of $\\operatorname{Aut}(G)$, but not under the map $g\\mapsto g^{-1}$?</p>\n</blockquote>\n\n<p>Since one has in particular the inner automorphisms, one need only consider unions of conjugacy classes.</p>\n\n<p>I can see no reason why this should be impossible, but it is also hard to construct an example.</p>\n\n<ul>\n<li>For Abelian groups $g\\mapsto g^{-1}$ <em>is</em> an automorphism, so no luck here</li>\n<li>On the other hand most symmetric groups have trivial outer automorphism groups; however here every $g$ is conjugate to $g^{-1}$, no luck either</li>\n<li>In alternating groups a conjugacy class of $S_n$ might fall apart, an an element might not be conjugate to its inverse; the two conjugacy classes would still however be related by an outer automorphism (coming from $S_n$)</li>\n<li>In $GL(n,K)$ most elements are not conjugate to their inverse; however there is an obvious out automorphism of transpose-inverse, and every invertible matrix <em>is</em> similar to its transpose (due to the theory of f.g. modules over a PID, leading to classification of similarity by invariant factors).</li>\n<li>Most \"natural\" subgroups of $GL(n,K)$ would suffer from the same \"outer automorphism\" phenomenon as alternating groups do, so they do not look promising.</li>\n</ul>\n\n<p>That's where I am now; I unfortunately do not know a lot of examples where I know enough to easily see whether I can find such subsets. Maybe a good candidate is the general linear group over a skew field (division ring), since the result of similarity to one's transpose does not hold there, as far as I know. But I don't know enough about automorphisms of these groups to known whether they are good candidates.</p>\n", "pids": ["5d9edc6147c8f7664603d9b4"], "flag": 0}
{"question": "Root finding for stochastic function", "body": "<p>Suppose we have a function $f(x)$ that we can only observe through some noise.  We can not compute $f(x)$ directly, only $f(x) + \\eta$ where $\\eta$ is some random noise.  (In practice: I compute $f(x)$ using some Monte Carlo method.)</p>\n\n<p>What methods are available for finding roots of $f$, i.e. computing $x$ so that $f(x) = 0$?</p>\n\n<p>I am looking for methods which minimize the number of evaluations needed for $f(x)+\\eta$, as this is computationally expensive.</p>\n\n<p>I am particularly interested in methods that generalize to multiple dimensions (i.e. solve $f(x,y) = 0, g(x,y) = 0$).</p>\n\n<p>I'm also interested in methods that can make use of some information about the variance of $\\eta$, as an estimate of this may be available when computing $f(x)$ using MCMC.</p>\n", "pids": ["5e7230f693d709897cf90566"], "flag": 1}
{"question": "Are there any versions of t-SNE for streaming data?", "body": "<p>My understanding of <a href=\"http://lvdmaaten.github.io/tsne/\" rel=\"noreferrer\">t-SNE</a> and the Barnes-Hut approximation is that all data points are required so that all force interactions can be calculated at the same time and each point can be adjusted in the 2d (or lower dimensional) map.</p>\n\n<p>Are there any versions of t-sne that can efficiently deal with streaming data? So if my observations are arriving one at a time, it will find the best location on the 2d map to place the new observation, or continuously update all points on the 2d map to account for ht new observation.</p>\n\n<p>Would this even make sense or does it go against the setup of t-sne.</p>\n", "pids": ["573696046e3b12023e517636"], "flag": 1}
{"question": "Is entanglement necessary for quantum computation?", "body": "<p>Entanglement is often discussed as being one of the essential components that makes quantum different from classical. But is entanglement really necessary to achieve a speed-up in quantum computation?</p>\n", "pids": ["53e9aa56b7602d97033c559d", "5f0dcf909fced0a24bb5b1d5"], "flag": 1}
{"question": "How to recode categorical variable into numerical variable when using SVM or Neural Network", "body": "<p>To use SVM or Neural Network it needs to transform (encode) categorical variables into numeric variables, the normal method in this case is to use 0-1 binary values with the k-th categorical value transformed to be (0,0,...,1,0,...0) (1 is on the k-th position). Is there other methods to do this, especially when there are a large number of categorical values(e.g.10000) such that the 0-1 representation will introduce a large number of additional dimensions(input units) in Neural Network which seems not quite desired or expected? </p>\n\n<p>I am asking about general strategies.</p>\n", "pids": ["57a4e91aac44365e35c97b81"], "flag": 1}
{"question": "How to compactly represent multiple qubit states?", "body": "<p>Since access to quantum devices capable of quantum computing is still extremely limited, it is of interest to <a href=\"https://quantumcomputing.stackexchange.com/questions/163/building-a-quantum-computer-in-simulation\">simulate quantum computations on a classical computer</a>. Representing the state of $n$ qubits as a vector takes $2^n$ elements, which greatly restricts the number of qubits one can consider in such simulations.</p>\n\n<p>Can one use a representation<sup>1</sup> that is more compact, in the sense that it uses less memory and/or computational power than the simple vector representation? How does it work?</p>\n\n<p>While easy to implement, it is clear that the vector representation is wasteful for states that exhibit sparsity and/or redundancy in their vector representation. For a concrete example, consider the 3-qubit state $(1/\\sqrt{3}, 1/\\sqrt{3},0,0,0,-1/\\sqrt{3}, 0,0)^T$. It has $2^3$ elements but they only assume $3$ possible values, with most of the elements being $0$. Of course, to be useful in simulating a quantum computation we would also need to consider how to represent gates and the action of gates on qubits, and including something about these would be welcome, but I would be happy to hear just about qubits too.</p>\n\n<p><sub>\n1. Notice that I am asking about the representations, not software, libraries or articles that might utilize/present such representations. If you present and explain a representation you are very welcome to mention where it is already used though. \n</sub></p>\n", "pids": ["5c7571aef56def9798798f76", "53e99f34b7602d9702801239", "5c757057f56def97986e2e9b", "5a9cb65d17c44a376ffb8586", "5f0e34bc9fced0a24b92adf8", "589d20ee0cf2b64293405379", "57a4e921ac44365e35c9918c", "53e9b275b7602d9703d18260", "555040c545ce0a409eb3661c", "5c75734ff56def9798889f4b", "5aed14c317c44a44381574c0"], "flag": 1}
{"question": "Why are particular combinations of algebraic properties &quot;richer&quot; than others?", "body": "<p>Pedagogically, when students are exposed to algebraic structures it seems standard for the major emphasis, if not all the emphasis, to be on groups, rings, R-modules, and categories. These are rich structures with interesting properties, but in the big picture, I have wondered <strong>why some defining properties make for a rich structure, while other properties gives less interesting structures</strong>, or nothing worth teaching at all.</p>\n\n<p>As a motivating example, a set (or class, whatever) that is closed under some operation seems necessary to talk about anything meaningful; however, why is the particular combination of </p>\n\n<ol>\n<li>Having inverse elements</li>\n<li>Having an identity element</li>\n<li>Associativity</li>\n</ol>\n\n<p>more rich (a group) than simply replacing associativity with commutativity (a structure I don't even know a name for)? I have also wondered why associativity is much more prevalent than commutativity. As another motivating example, <strong>we teach much about groups and rings but why not loops, monoids, semilattices, and near-rings?</strong> What makes the former set either richer in structure or more pedagogically sound to teach?</p>\n\n<p>Even in category theory I can ask what makes the specific combination of defining properties of a category so great. —why associativity and not commutativity? —why categories and not semi categories? I wonder why its particular combination of defining properties is more \"powerful\", deep, and pervasive than another combination of properties.</p>\n", "pids": ["5c610741da56297340af8360", "56d8c403dabfae2eee3e5075"], "flag": 0}
{"question": "What is F1 Optimal Threshold? How to calculate it?", "body": "<p>I've used h2o.glm() function in R which gives a contingency table in the result along with other statistics. The contingency table is headed \"<strong>Cross Tab based on F1 Optimal Threshold</strong>\"</p>\n\n<p><a href=\"https://en.wikipedia.org/wiki/F1_score\" rel=\"noreferrer\">Wikipedia</a> defines F1 Score or F Score as the harmonic mean of precision and recall. But aren't Precision and Recall found only when the result of predicted values of a logistic regression(for example) is transformed to binary using a cutoff.</p>\n\n<p>Now by cutoff I remember, what is the connection between F1 Score and Optimal Threshold. How is optimal threshold calculated? How is F1 optimal threshold calculated?</p>\n\n<p>Sorry if I've missed something, I'm new to stats here.</p>\n", "pids": ["5c75697bf56def97982a087a"], "flag": 1}
{"question": "How would a quantum computer be used to solve Partial Differential Equations?", "body": "<p>Say you have a PDE you want to solve.</p>\n\n<p>What kind of quantum algorithms would you use to solve it?\nHow do we input our problem on a quantum computer?\nWhat will be the output and in what form?</p>\n\n<p>I know that quantum algorithms for solving linear systems (often named HHL but actually this is a bad name as other versions are not from the HHL authors) were listed before but maybe other methods are out there.\nAlso as it is considered as a subroutine, the output is quantum and then unless you want statistics from it or use it as an input of another quantum algorithm, it is limiting.</p>\n", "pids": ["5ce2d0deced107d4c63c709e"], "flag": 1}
{"question": "State of the art gate speeds and decoherence times", "body": "<p>I am interested in the state of the art gate speeds and decoherence times for the qubit types I know are being pursued by companies presently:</p>\n\n<ul>\n<li>superconducting qubits,</li>\n<li>ion trap qubits,</li>\n<li>photonic qubits.</li>\n</ul>\n\n<p>Where can I find these, and is there a place where these are updated regularly?</p>\n\n<p>There have been various published tables depicting these times for various types of qubits over the years (including the famous Los Alamos National Lab QC Roadmap), but the numbers always change while the published papers don't.</p>\n\n<p>I needed these numbers to answer <a href=\"https://quantumcomputing.stackexchange.com/a/4099/2293\">this question</a> because I wanted to compare the 1ps decoherence time in the FMO to state-of-the-art decoherence times and gate times in popular candidates for QCs, so I went searching for some reasonable values for roughly this time period, but I don't anymore know where to look. </p>\n\n<p> \nThe longest coherence time ever measured was given in this answer, but no gate times were given: <a href=\"https://quantumcomputing.stackexchange.com/questions/1687/what-is-the-longest-time-a-qubit-has-survived-with-0-9999-fidelity/1985#1985\">What is the longest time a qubit has survived with 0.9999 fidelity?</a></p>\n\n<p>James Wootton talked about the advantages and disadvantages of the above three qubit types, but not the gate/decoherence times, in this answer: <a href=\"https://quantumcomputing.stackexchange.com/questions/1226/what-is-the-leading-edge-technology-for-creating-a-quantum-computer-with-the-few/1234#1234\">What is the leading edge technology for creating a quantum computer with the fewest errors?</a></p>\n", "pids": ["58d82fcbd649053542fd64cd"], "flag": 1}
{"question": "Why is &quot;h&quot; used for entropy?", "body": "<p>Why is the letter \"h\" (or \"H\") used to denote entropy in information theory, ergodic theory, and physics (and possibly other places)?</p>\n\n<p><strong>Edit:</strong> I'm looking for an explanation of the original use of \"H\". As Ilmari Karonen points out, Shannon got \"H\" from <a href=\"http://en.wikipedia.org/wiki/H-theorem\">Boltzmann's H-theorem</a>. So (assuming Boltzmann actually used \"H\"), the original use is at least as early as that.</p>\n", "pids": ["5fdd683a197a5ecbc089104e"], "flag": 1}
{"question": "Are men smarter than women?", "body": "<p>I recently stumbled across the following article:\n<a href=\"http://www.dailymail.co.uk/debate/article-1274952/Men-ARE-brainy-women-says-scientist-Professor-Richard-Lynn.html\">Sorry, men ARE more brainy than women (and more stupid too!) It's a simple scientific fact, says one of Britain's top dons</a>, in which the author claims:</p>\n\n<p><code>1.</code> That men are on average smarter than women:</p>\n\n<blockquote>\n  <p>one of the main reasons why there are not more female science\n  professors or chief executives or Cabinet ministers is that, on\n  average, men are more intelligent than women.</p>\n  \n  <p>Boys and girls may start out with the same IQ but by 16 or so boys are\n  starting to inch ahead. The ever-growing success of girls at GCSE,\n  A-level and now at university would seem to refute this - but the\n  blame lies with our exam system, with its emphasis on coursework,\n  which rewards diligence more than it does intelligence.</p>\n  \n  <p>The undeniable, easily measurable fact remains that, <strong>by the time both\n  sexes reach 21, men, on average, score five IQ points higher than\n  women</strong>.</p>\n</blockquote>\n\n<p><code>2.</code> That very-high-IQ men are much more common-place than very-high-IQ women:</p>\n\n<blockquote>\n  <p>For not only is the average man more intelligent than the average\n  woman but also a clear and rather startling imbalance emerges between\n  the sexes at the high levels of intelligence that the most demanding\n  jobs require. </p>\n  \n  <p>For instance, <strong>at the near-genius level (an IQ of 145), brilliant men\n  outnumber brilliant women by 8 to one</strong>. That's statistics, not sexism.</p>\n  \n  <p>In this context, Professor Greenfield's indignation that only one in\n  ten science professors is female doesn't seem all that bad. It also\n  goes some way to explaining why, in almost 110 years of Nobel Prize\n  history, only two women have ever won the Prize for physics, only four\n  have won the Prize for chemistry and why no women at all have ever won\n  the coveted Fields Medal for mathematics in eight decades of trying.</p>\n</blockquote>\n\n<p>This perplexed me, as I thought women and men were intellectually on par with each other.  Is the article right or wrong: about the relative average intelligences of adults, and the ratios of exceptional intelligences?</p>\n\n\n\n<p>The article makes other claims as well, related to personality, for example:</p>\n\n<blockquote>\n  <p>Consequently, ambitious, high-achieving men typically work harder, compete more aggressively and become totally immersed in their careers, while even the most high-achieving women will often admit to finding themselves distracted by their genetically preconditioned aptitude for nurture and support.</p>\n</blockquote>\n\n<p>To keep this question focussed, please ignore such claims about personality, and about what may cause gender imbalance in the job markets, and focus only on the claims about \"intelligence\" as made above.</p>\n", "pids": ["53e9a7d6b7602d9703115f8c", "53e9b365b7602d9703e44536", "5c75664ef56def97980b45cf"], "flag": 1}
{"question": "Overfitting: No silver bullet?", "body": "<p>My understanding is that even when following proper cross validation and model selection procedures, overfitting <strong>will</strong> happen if one searches for a model <strong>hard enough</strong>, unless one imposes restrictions on model complexity, period. Moreover, often times people try to learn penalties on model complexity from the data which undermines the protection they can provide.</p>\n\n<p>My question is: How much truth is there to the statement above?</p>\n\n<p>I often hear ML practicioners say: \"<em>At my company/lab, we always try every model available (e.g. from libraries like <a href=\"http://caret.r-forge.r-project.org/\" rel=\"nofollow noreferrer\">caret</a> or <a href=\"http://scikit-learn.org/\" rel=\"nofollow noreferrer\">scikit-learn</a>) to see which one works best</em>\". I often argue that this approach can easily overfit <strong>even</strong> if they are serious about cross-validation and keep hold-out sets in any way they want. Moreover the harder they search, the more likely they may overfit. In other words, <a href=\"https://stats.stackexchange.com/questions/63968/optimization-the-root-of-all-evil-in-statistics\">over-optimization is a real problem</a> and there are no heuristics that can help you systematically fight against it. Am I wrong to think this way?</p>\n", "pids": ["6136d84a5244ab9dcb6aa8bf"], "flag": 1}
{"question": "Proportion of explained variance in a mixed-effects model", "body": "<p>I do not know if this has been asked before, but I do not found anything about it. My question is if anyone can provide a good reference to learn how to obtain the proportion of variance explained by each one of the fixed and random factors in a mixed-effects model.</p>\n", "pids": ["53e9bb5ab7602d970479c500", "53e9af6eb7602d97039b27c8", "53e9bcc5b7602d970494861f"], "flag": 1}
{"question": "How is the Grover-Algorithm applied to a database?", "body": "<h3>Question</h3>\n\n<p>I want to use the Grover-Algorithm to search an unsorted database for an element <span class=\"math-container\">$x$</span>. Now the question arises, how do I initialize index and value of the database with the qubits?</p>\n\n<h3>Example</h3>\n\n<ul>\n<li>Let's say I have <span class=\"math-container\">$4$</span> qubits. Thus, <span class=\"math-container\">$2 ^ 4 = 16$</span> classical values can be mapped.</li>\n<li>My unsorted database <span class=\"math-container\">$d$</span> has the following elements: <span class=\"math-container\">$d [\\text{Value}] = [3,2,0,1]$</span>.</li>\n<li>I want to search for <span class=\"math-container\">$x = 2_d = 10_b = |10\\rangle$</span>.</li>\n<li>My approach: index the database <span class=\"math-container\">$d$</span> with <span class=\"math-container\">$d [(\\text{Index, Value})] = [(0,3), (1,2), (2,0), (3,1)]$</span>. Registers <span class=\"math-container\">$0$</span> and <span class=\"math-container\">$1$</span> for the index and registers <span class=\"math-container\">$2$</span> and <span class=\"math-container\">$3$</span> for the value. Then apply the Grover-Algorithm only to registers <span class=\"math-container\">$2$</span> and <span class=\"math-container\">$3 (\\text{Value})$</span>. Can this be realized? Is there another approach?</li>\n</ul>\n\n<h3>What I already implemented (<a href=\"https://github.com/soultanis/Grover-Algorithmus-Qiskit\" rel=\"noreferrer\">on GitHub</a>)</h3>\n\n<p>The \"Grover-Algorithm with 2-, 3-, 4-Qubits\", but what it does is simple: the bits are initialized with <span class=\"math-container\">$|0\\rangle$</span>, the oracle will mark my solution <span class=\"math-container\">$x$</span> (which is just a number like <span class=\"math-container\">$2_d = 10_b$</span>), the Grover part will increase the probability of the selected element <span class=\"math-container\">$x$</span> and decrease all other probabilities and then the qubits are read out by being mapped to the classical bits. We let this process run several times in succession and thus obtain a probability distribution, where the highest probability has our sought element <span class=\"math-container\">$x$</span>. </p>\n\n<p>The output is always the same as the one marked in the oracle. How can I generate more information from the output, that I do not know at the time when I constructed the oracle?</p>\n", "pids": ["5c8a6c82e1cd8e7f300e3ccd", "56d8ab21dabfae2eeeb3d00f"], "flag": 1}
{"question": "How many two-qubit gates are required to implement a general N-qubit unitary?", "body": "<p>Is there a known formula or a scaling behaviour for how many two-qubit gates are required to construct a general N-qubit unitary?</p>\n\n<p>I suppose there are several cases to consider:</p>\n\n<ul>\n<li>Exact representation of the gates</li>\n<li>Approximate decompositions to a given accuracy</li>\n<li>Any subclass of unitaries that have more efficient decompositions</li>\n<li>With vs without ancillary qubits.</li>\n</ul>\n\n<p><strong>edit:</strong> As a starting point, I know an optimal decomposition of a general two-qubit gate (into CNOT and single-qubit) and I consider single-qubit operations as \"free\" (they can be absorbed into the two-qubit gates, and for practical implementations they have lower error rates).</p>\n\n<p><strong>edit:</strong> In Nielsen and Chuang they say that there always exists an <span class=\"math-container\">$n\\times n$</span> unitary that requires n-1 2-qubit gates. Are n-1 gates sufficient for a general <span class=\"math-container\">$n\\times n$</span> unitary?</p>\n", "pids": ["53e9ac0bb7602d97035ca140"], "flag": 1}
{"question": "Tensorflow Cross Entropy for Regression?", "body": "<p>Does cross-entropy cost make sense in the context of regression? (as opposed to classification) If so, could you give a toy example through tensorflow and if not, why not? <br><br>\nI was reading about cross entropy in\n<a href=\"http://neuralnetworksanddeeplearning.com/chap3.html\" rel=\"nofollow noreferrer\">Neural Networks and Deep Learning</a> by Michael Nielsen and it seems like something that could naturally be used for regression as well as classification, but I don't understand how you'd apply it efficiently in tensorflow since the loss functions take logits (which I don't really understand either) and they're listed under Classification <a href=\"https://www.tensorflow.org/versions/r0.9/api_docs/python/nn.html\" rel=\"nofollow noreferrer\">here</a></p>\n", "pids": ["5c8c26524895d9cbc6cd4114", "58437725ac44360f1082fa5e"], "flag": 1}
{"question": "How to predict outcome with only positive cases as training?", "body": "<p>For the sake of simplicity, let's say I'm working on the classic example of spam/not-spam emails.</p>\n\n<p>I have a set of 20000 emails. Of these, I know that 2000 are spam but I don't have any example of not-spam emails. I'd like to predict whether the remaining 18000 are spam or not. Ideally, the outcome I'm looking for is a probability (or a p-value) that the email is spam.</p>\n\n<p><strong>What algorithm(s) can I use to make a sensible prediction in this situation?</strong></p>\n\n<p>At the moment, I'm thinking of a distance-based method that would tell me how similar my email is to a known spam email. What options do I have?</p>\n\n<p>More generally, can I use a supervised learning method, or do I necessarily need to have negative cases in my training set to do that? Am I limited to unsupervised learning approaches? What about semi-supervised methods?</p>\n", "pids": ["53e99d3eb7602d97025f507b", "5550415945ce0a409eb3a7f3", "53e99d3eb7602d97025f507b"], "flag": 1}
{"question": "Does vegetarian sweat smell better?", "body": "<p>I've read this article online in a Belgian newspaper (in Dutch): <a href=\"https://www.hln.be/wetenschap-planeet/medisch/weet-wat-je-zweet-deze-7-dingen-wist-je-nog-niet-over-zweten~ab789904/\" rel=\"noreferrer\">Weet wat je zweet: deze 7 dingen wist je nog niet over zweten — HLN</a>.</p>\n\n<p>Number 4 is saying that vegetarian sweat smells better then non vegetarian sweat. </p>\n\n<p>I've done some research and found this article:\n<a href=\"https://www.psychologytoday.com/intl/blog/animals-and-us/201701/do-vegetarians-smell-sexier\" rel=\"noreferrer\">Do Vegetarians Smell Sexier?\n — Psychology Today</a>.</p>\n\n<p>That article refers to 2 studies. One study found that:</p>\n\n<blockquote>\n  <p>As you can see in this graph, women rated the body odors of the men to be sexier, more pleasant, and less intense after they had given up meat for two weeks. The experiment worked. Who knew? </p>\n</blockquote>\n\n<p>And the other:</p>\n\n<blockquote>\n  <p>But in contrast to results of the Czech study, the Australian women rated the body odors of frequent meat eaters to be more pleasant than men who ate a lot of vegetables. No one knows why the two groups of researchers obtained opposite results when in comes to how meat-eating affects body odor. </p>\n</blockquote>\n\n<p>So do vegetarians and their sweat smell better?</p>\n", "pids": ["55a52733612c6b12ab051463"], "flag": 1}
{"question": "Is it possible to &quot;boost your immune system&quot;?", "body": "<p>I often hear claims that some activities, nutrients, ... <em>\"boost\"</em> your immune system. My understanding of the immune system is that it is a finely tuned machine with enormous destructive power. If unconditionally activated it is at least as dangerous, if not more, than the diseases it protects us from. The best evidence for that is the large variety of autoimmune diseases.</p>\n\n<p>So I'm wondering if there is evidence that some activities, food or substances really <em>\"boost\"</em> the immune system? And I'm also wondering whether boosting the immune system would be a good idea in the first place, considering the destructive potential of it?</p>\n", "pids": ["53e9aa02b7602d9703370ed5"], "flag": 1}
{"question": "What is the origin of the autoencoder neural networks?", "body": "<p>I searched on Google, Wikipedia, Google scholar, and more, but I could not find the origin of Autoencoders. Perhaps it's one of those concepts that evolved very gradually, and it's impossible to trace back a clear starting point, but still I would like to find some kind of summary of the main steps of their development.</p>\n\n<p>The <a href=\"http://www.deeplearningbook.org/contents/autoencoders.html\" rel=\"noreferrer\">chapter about autoencoders</a> in Ian Goodfellow, Yoshua Bengio and Aaron Courville's Deep Learning book says:</p>\n\n<blockquote>\n  <p>The idea of autoencoders has been part of the historical landscape of\n  neuralnetworks for decades (LeCun, 1987; Bourlard and Kamp, 1988;\n  Hinton and Zemel,1994). Traditionally, autoencoders were used for\n  dimensionality reduction or feature learning.</p>\n</blockquote>\n\n<p>This <a href=\"http://www.uoguelph.ca/~gwtaylor/cifar/pascal.vincent/pascal_vincent_part_2.pdf\" rel=\"noreferrer\">presentation</a> by Pascal Vincent says:</p>\n\n<blockquote>\n  <p>Denoising using classical autoencoders was actually introduced much\n  earlier (LeCun, 1987; Gallinari et al., 1987), as an alternative to\n  Hopfield networks (Hopfield, 1982).</p>\n</blockquote>\n\n<p>This seems to imply that \"classical autoencoders\" existed before that: LeCun and Gallinari used them but did not invent them. I see no trace of \"classical autoencoders\" earlier than 1987.</p>\n\n<p>Any ideas?</p>\n", "pids": ["53e9b068b7602d9703acf032"], "flag": 1}
{"question": "Prove the integral evaluates to $\\frac{K}{\\pi}$", "body": "<p>Yesterday I received the following integral that might require some tedious steps to do</p>\n\n<p>$$\\int_0^{\\infty}{\\small\\left[ \\frac{x}{\\log^2\\left(e^{\\large x^2}-1\\right)}- \\frac{x}{\\sqrt{e^{\\large x^2}-1}\\log^2\\left(e^{\\large x^2}-1\\right)}-\\frac{x}{\\sqrt{e^{\\large x^2}-1}\\log\\left(\\left(e^{\\large x^2}-1\\right)^2\\right)}\\right] \\ dx}=\\frac{K}{\\pi}$$</p>\n\n<p>where $K$ is the Catalan's constant</p>\n\n<p>What to do? Well, one can let $x^2\\mapsto x$, $e^{x}-1\\mapsto x$ and then we get an integral where we can add<br>\na parameter of the type $x^s$, and then I have an integral $I(s)$ that I differentiate twice with respect<br>\nto $s$, and then integrate over $[0,\\infty)$. Of course, the last step is to integrate twice with respect to $s$, but this is not the work I love. My feeling is that there is a pretty easy way to prove the integral result that I don't see yet,  but maybe you see it and share it with me.  </p>\n", "pids": ["56d81ec1dabfae2eeead0235"], "flag": 0}
{"question": "Is the flu more deadly than COVID-19 for children?", "body": "<p>Dr. Jay Bhattacharya was quoted in this recent <a href=\"https://fee.org/articles/harvard-researchers-nearly-half-of-young-adults-showing-signs-of-depression-amid-pandemic\" rel=\"noreferrer\">Foundation for Economic Education</a> article:</p>\n<blockquote>\n<p>In a debate last week with pro-lockdown Harvard epidemiologist, Marc\nLipsitch, Dr. Bhattacharya acknowledged that COVID-19 “is an\nabsolutely deadly disease for people who are older and for people who\nhave certain chronic conditions.” He explained that there is a 95\npercent COVID-19 survival rate for people 70 and older, while for\npeople who are under 70, there is currently a 99.95 percent survival\nrate.</p>\n<p>Dr. Bhattacharya said: “<strong>For children the flu is\nworse.</strong> We’ve had more flu deaths of children this year than Covid\ndeaths.”</p>\n</blockquote>\n<p>Dr. Bhattacharya who made the claim is also an important signee of <a href=\"https://gbdeclaration.org/\" rel=\"noreferrer\">the Great Barrington Declaration</a>, which argues for focused protection, and which also states on the website that (without proof):</p>\n<blockquote>\n<p>Fortunately, our understanding of the virus is growing. We know that\nvulnerability to death from COVID-19 is more than a thousand-fold\nhigher in the old and infirm than the young. <strong>Indeed, for children,\nCOVID-19 is less dangerous than many other harms, including influenza.</strong></p>\n</blockquote>\n<p>I know that Covid is hitting the older people disproportionately hard, but is it true that it hit less hard on children than flu?</p>\n", "pids": ["5f0744809e795e1a9f4abf42", "5e54f1bf93d709897c723940"], "flag": 1}
{"question": "Minimum number of layers in a deep neural network", "body": "<p>At what point do we start classifying multi layered neural networks as deep neural networks or to put it in another way 'What is the minimum number of layers in a deep neural network?'</p>\n", "pids": ["573696026e3b12023e515eec", "5550415645ce0a409eb3a69e"], "flag": 1}
{"question": "The sum of independent lognormal random variables appears lognormal?", "body": "<p>I'm trying to understand why the sum of two (or more) lognormal random variables approaches a lognormal distribution as you increase the number of observations. I've looked online and not found any results concerning this.</p>\n\n<p>Clearly if $X$ and $Y$ are independent lognormal variables, then by properties of exponents and gaussian random variables, $X \\times Y$ is also lognormal. However, there is no reason to suggest that $X+Y$ is also lognormal.</p>\n\n<p>HOWEVER</p>\n\n<p>If you generate two independent lognormal random variables $X$ and $Y$, and let $Z=X+Y$, and repeat this process many many times, the distribution of $Z$ appears lognormal. It even appears to get closer to a lognormal distribution as you increase the number of observations.</p>\n\n<p>For example: After generating 1 million pairs, the distribution of the <strong>natural log of Z</strong> is given in the histogram below. This very clearly resembles a normal distribution, suggesting $Z$ is indeed lognormal.</p>\n\n<p><a href=\"https://i.stack.imgur.com/m5ycJ.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/m5ycJ.png\" alt=\"enter image description here\"></a></p>\n\n<p>Does anyone have any insight or references to texts that may be of use in understanding this?</p>\n", "pids": ["53e9a80cb7602d9703151047"], "flag": 1}
{"question": "Will deep learning neural networks run on quantum computers?", "body": "<p>Deep Learning (multiple layers of artificial neural networks used in supervised and unsupervised machine learning tasks) is an incredibly powerful tool for many of the most difficult machine learning tasks: image recognition, video recognition, speech recognition, etc.  Given that it is currently one of the most powerful machine learning algorithms, and Quantum Computing is generally regarded as a game changer for certain very difficult computation tasks, I'm wondering if there has been any movement on combining the two.  </p>\n\n<ul>\n<li>Could a deep learning algorithm run on a quantum computer?  </li>\n<li>Does it make sense to try?   </li>\n<li>Are there other quantum algorithms that would make deep learning irrelevant?</li>\n</ul>\n", "pids": ["5c8cd9cb4895d9cbc625f859", "5c8bb3d14895d9cbc6a4a78a", "5c7573b1f56def97988c6215", "5a260c8617c44a4ba8a31f5d", "5a260c8617c44a4ba8a324cc", "62c2a9565aee126c0fcf082c", "5c757420f56def9798910c14", "5c757cd7f56def9798a7da25", "5c757488f56def979895723e"], "flag": 1}
{"question": "What is the opposite of measurement, in a quantum circuit?", "body": "<p>My understanding is that at the level of quantum mechanics, almost all operations are reversible in time. Most gates in a quantum circuit clearly obey this rule; they can be reversed by applying some other gate. But a measurement gate seems to be one-directional. Is there some physical process that performs the opposite of what a measurement gate does?</p>\n", "pids": ["53e99b0ab7602d970239bbdc"], "flag": 1}
{"question": "Why are non-Clifford gates more complex than Clifford gates?", "body": "<p>There are two groups of quantum gates - Clifford gates and non-Clifford gates.</p>\n\n<p>Representatives of Clifford gates are Pauli matrices <span class=\"math-container\">$I$</span>, <span class=\"math-container\">$X$</span>, <span class=\"math-container\">$Y$</span> and <span class=\"math-container\">$Z$</span>, Hadamard gate <span class=\"math-container\">$H$</span>, <span class=\"math-container\">$S$</span> gate and <span class=\"math-container\">$CNOT$</span> gate. Non-Clifford gate is for example <span class=\"math-container\">$T$</span> gate and Toffoli gate (because its implementation comprise <span class=\"math-container\">$T$</span> gates).</p>\n\n<p>While Clifford gates can be simulated on classical computer efficiently (i.e. in polynomial time), non-Clifford gates cannot. Moreover (if my understanding is correct), non-Clifford gates increase time consumption of a quantum algorithm far more than Clifford gates.</p>\n\n<p><strong>My questions are these:</strong></p>\n\n<ol>\n<li>Am I right that non-Clifford gates increase time consumption (or complexity of quantum algorithm)?</li>\n<li>Why non-Clifford gates cannot be simulated efficiently? <em>This is confusing for me, because <span class=\"math-container\">$S$</span> and <span class=\"math-container\">$T$</span> gates are both rotations with only different angle.</em></li>\n</ol>\n", "pids": ["5fd6e28c98b36632c84b9751", "5ce2d064ced107d4c637353d"], "flag": 1}
{"question": "Are there spaces &quot;smaller&quot; than $c_0$ whose dual is $\\ell^1$?", "body": "<p>It is well known that both the sequence spaces $c$ and $c_0$ have duals which are isometrically isomorphic to $\\ell^1$. Now, $c_0$ is a subspace of $c$. My question - is there an even smaller subspace of $c$ whose dual is isometrically isomorphic to $\\ell^1$? More generally, is there a characterization of preduals of $\\ell^1$? References are most welcome.</p>\n", "pids": ["56d8768fdabfae2eee1c8c29", "5c61092dda56297340b6738e", "53e9ab73b7602d97035189c9"], "flag": 0}
{"question": "Multivariate gaussian integral over positive reals", "body": "<p>The multivariate gaussian integral over the whole <span class=\"math-container\">$\\mathbf{R}^n$</span> has closed form solution</p>\n\n<p><span class=\"math-container\">$$P = \\int_{\\mathbf{x} \\in \\mathbf{R}^n} \\exp \\left(-\\frac12 \\mathbf{x}^T \\mathbf{A} \\mathbf{x}\\right)\\,d\\mathbf{x} = \\sqrt{\\frac{(2\\pi)^n}{\\det \\mathbf{A}}}$$</span></p>\n\n<p>where <span class=\"math-container\">$\\mathbf{A}$</span> is a symmetric positive-definite covariance matrix.</p>\n\n<p>However, I need to solve the integral for positive reals <span class=\"math-container\">$\\{\\mathbf{x} \\in \\mathbf{R}^n :\\, \\mathbf{x}_i \\geq 0\\ \\forall i\\}$</span> only and in at least 6 dimensions:</p>\n\n<p><span class=\"math-container\">$$P = \\int_{\\{\\mathbf{x} \\in \\mathbf{R}^n :\\, \\mathbf{x}_i \\geq 0\\ \\forall i\\}} \\exp \\left(-\\frac12 \\mathbf{x}^T \\mathbf{A} \\mathbf{x}\\right)\\,d\\mathbf{x}$$</span></p>\n\n<p>For diagonal <span class=\"math-container\">$\\mathbf{A}$</span> with zero covariance, <a href=\"http://www.dtic.mil/dtic/tr/fulltext/u2/401722.pdf\" rel=\"noreferrer\">a solution has been published</a>.\nFor non-diagonal covariance, my approach so far is to apply affine coordinate transforms to rotate and rescale the gaussian ellipsoid into the unit sphere (<a href=\"https://math.stackexchange.com/a/581081/159759\">see here</a>).</p>\n\n<p>In two dimensions, the solution to the integral then reduces to comparing the area enclosed by the transformed positive coordinate axes (blue) to the area of the unit circle:</p>\n\n<p><a src=\"https://i.stack.imgur.com/Cg8tV.png\" alt=\"Affine transformations do not change volume ratios\"></p>\n\n<p>In three dimensions, the solution is given by the ration of the surface area of an enclosed spherical polygon to the surface area of the unit sphere.</p>\n\n<p>In four dimensions, this approach becomes quite <a href=\"https://mathoverflow.net/questions/7470/is-there-a-neat-formula-for-the-volume-of-a-tetrahedron-on-the-surface-of-s3\">complicated</a>, and I don't know how to use the usual spherical excess formulas for higher dimensions.</p>\n\n<p>Any ideas or alternative approaches? Is there a multivariate error function? Any treatment on the multivariate half normal distribution?</p>\n\n\n\n<p>Addition (2018-12-03):</p>\n\n<p>Thank you Przemo for your solution to the problem for <span class=\"math-container\">$n=2, 3$</span>. While I had no trouble following your derivation in 2D, I'm stuck with the derivation of your intermediate step for <span class=\"math-container\">$n=3$</span>. I mainly tried two approaches:</p>\n\n<ul>\n<li><p>Completing the square in one variable, say <span class=\"math-container\">$x$</span>, leaves me with\n<span class=\"math-container\">$$\\int_{\\mathbb{R}_+^2} \\mathrm{d}y\\mathrm{d}z \\exp\\left(-\\frac{1}{2} \\frac{\\mathrm{det}\\,A_3}{\\mathrm{det}\\,A_2}z^2\\right) \\exp\\left(-\\frac{1}{2} \\frac{\\mathrm{det}\\, A_2}{a}(y-m z)^2\\right) \\left[1 - \\mathrm{erf}\\left(\\frac{a_{12}y+a_{13}z}{\\sqrt{2a}}\\right) \\right] $$</span>\nwhere <span class=\"math-container\">$A_2=\\begin{pmatrix} a &amp; a_{12}\\\\ &amp; b\\end{pmatrix}$</span>, <span class=\"math-container\">$A_3$</span> as you defined it, and <span class=\"math-container\">$m$</span> is a function of the coefficients of the matrices. However, I do not know how to proceed from there: expanding the error function to do the integral in y, say, is a nightmare due to the constant term in z; I also did not find a way to do a coordinate transform à la <span class=\"math-container\">$s=a_{12}y+a_{13}z$</span> or something similar.</p></li>\n<li><p>Indeed, your intermediate solution looks more like you were able to complete the square in two of the variables independently; but what happened to the cross-term? I cannot find a factorisation of the exponent that would allow me to complete two integrals over the half-line with only one variable left in the error function yielded by the integral. </p></li>\n</ul>\n\n<p>Any help / hint would be greatly appreciated! Thank you in advance.</p>\n", "pids": ["5c755383f56def9798619314", "539099ec20f70186a0e1ce4d"], "flag": 0}
{"question": "Why are the sex chromosomes called X and Y?", "body": "<p>Is there a specific reason that the letter Y is used as the symbol for the male chromosome and X is used for the female chromosome?</p>\n", "pids": ["642e9dc490e50fcafd536ea9"], "flag": 1}
{"question": "Status of Google&#39;s quantum supremacy claim 2022", "body": "<p>More than a year ago a couple of scientists made a splash by <a href=\"https://arxiv.org/abs/2103.03074\" rel=\"noreferrer\">presenting a classical algorithm</a> that took less than a week to simulate Sycamore's circuits on a small GPU cluster. Also, their simulations produced exact results and not estimates.</p>\n<p>This was a big runtime cut from Google's claim of 10000 years on a supercomputer to ~5 days on a small GPU cluster. The runtime can be cut further if a more computational resources are used.</p>\n<p>As far as I know, the paper was submitted to Phys Rev journal\nand uploaded on Arxiv more than a year ago. However, I can't find the published version.</p>\n<p>Does anyone know the status of the paper? Also, if the proposed algorithm turns out to be correct, does it mean we can scratch Google's claim of quantum supremacy until they repeat the experiment with more qubits, higher circuit depth and some sort of solid verification that produced results are indeed correct and not just noise?</p>\n", "pids": ["63969ba790e50fcafdcf1a38"], "flag": 1}
{"question": "Open/publicly available textbooks worth their salt", "body": "<p>I've been reading a bit about \"open textbooks\", i.e. textbooks made available for easy, online access. These can be nice for those without access to a great library, or who might not be willing to drop the big bucks on a math textbook. In a similar vein, many classic textbooks are available online (legitimately) for free; for example, one can find Oxtoby's <em>Measure and Category</em> in its entirety on Rice's website (I presume that Rice checked that this was kosher before they put it up).</p>\n\n<p>My issue with the open textbooks is that they tend to be very introductory. You have your typical high school maths, e.g. pre-calculus, calculus, and then some introductory texts to abstract algebra, analysis, etc. But if you're interested in anything more, then you're stuck looking for an $80 book, which is typically where they tend to be (from my understanding) more expensive and harder to find. That is, I can get a typical undergrad analysis book pretty easily on these open textbook sites, but if I want anything more, say, an intro to measure-theoretic analysis, then I'm stuck looking through the old routes, i.e. library or Amazon.</p>\n\n<p>My question to you: What are some of your favorite textbooks that are legitimately available for free on the Interwebz? More particularly, I'm interested in books on more specialized subjects (i.e. something beyond an intro to abstract algebra/statistics), though if you have some stellar reference for single-variable calculus or something to that effect, then I'd be glad to hear it as well.</p>\n", "pids": ["61c9bdb65244ab9dcb921f86"], "flag": 0}
{"question": "What are some applications of Chebotarev Density Theorem?", "body": "<p>Let $L/K$ be a Galois extension of number fields and let $\\mathcal{C}$ be a conjugacy class in $Gal(L/K)$. Let $\\mathbb{P}(K)$ be the set of all prime ideals in $K$ and let $\\left(\\frac{L/K}{\\mathfrak{p}} \\right)$ correspond to the associated conjugacy class of Frobenius elements living over $\\mathfrak{p}$(of course unramified) and suppose $A=\\left\\lbrace \\mathfrak{p}\\in P(K) \\mid \\left(\\frac{L/K}{\\mathfrak{p}} \\right)=\\mathcal{C} \\right\\rbrace$.</p>\n\n<p>Then the Chebotarev Density Theorem states that $\\delta(A)=\\frac{|C|}{[L:K]}$. </p>\n\n<p>This also is a generalisation of Frobenius density theorem. </p>\n\n<p>For positive integers $a,n$ such that $\\gcd(a,n)=1$ CDT for $K=\\mathbb{Q}$ and $L=\\mathbb{Q}(\\zeta_n)$ and $\\mathcal{C}=\\lbrace \\zeta_n \\to \\zeta_n^a \\rbrace$ gives Dirichlet's theorem of infinitude of primes in arithmetic progression. </p>\n\n<p>I wish to ask what other applications are of this theorem.  </p>\n", "pids": ["53e9aeb7b7602d97038dc9d4"], "flag": 0}
{"question": "Do Starship&#39;s grocery delivering robots consume only as much energy as boiling water for a cup of tea per trip?", "body": "<p><a href=\"https://www.starship.xyz/\" rel=\"noreferrer\">Starship Technologies</a> is a robotics company with a program of developing robots that will deliver takeaway meals etc. using small robots such is this:</p>\n<p><a href=\"https://i.stack.imgur.com/oV7Y6.jpg\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/oV7Y6.jpg\" alt=\"small white robots, not even knee high\" /></a></p>\n<p>One particular <a href=\"https://www.starship.xyz/press_releases/starship-and-co-op-roll-out-delivery-robots-to-bedford-and-kempston/\" rel=\"noreferrer\">press release</a> on their website makes this claim:</p>\n<blockquote>\n<p>Starship’s robots are powered by zero carbon electricity, with an <strong>average delivery</strong> for a Starship robot <strong>consuming as little energy as boiling a kettle to make just one cup of tea</strong>. Orders are made through the Starship food delivery app, which is available for download on iOS and Android, with groceries picked fresh in local Co-op stores and delivered quickly and conveniently in as little as one hour or less.</p>\n</blockquote>\n<p>I can't find any justification for this claim, which is being repeated around the media.</p>\n<p>Is the claim about energy usage true? One assumes that the 'average' delivery isn't a test run of a few metres.</p>\n", "pids": ["628d26095aee126c0f4a8c91"], "flag": 1}
{"question": "What use has quantum computing been?", "body": "<p>Most of us on this site believe that quantum computing will work. However, let's play devil's advocate. Imagine that we suddenly hit some fundamental stumbling block that prevented further development towards a universal quantum computer. Perhaps we're limited to a NISQ device (Noisy, Intermediate Scale Quantum) of 50-200 qubits, for the sake of argument. The study of (experimental) quantum computing suddenly stops and no further progress is made.</p>\n\n<p><strong>What good has already come out of the study of quantum computers?</strong></p>\n\n<p>By this, I mean realisable quantum technologies, the most obvious candidate being Quantum Key Distribution, but also technical results that feed into other fields. Rather than simply a list of items, a brief description of each would be appreciated.</p>\n", "pids": ["594879310cf2615b52d1b72f", "582336370cf206871ad317df", "60e81f815244ab9dcb104177", "5a22106f0cf2b25cfd5361e5", "5c75710bf56def9798749057", "5b67b48817c44aac1c864638", "53e99da4b7602d970265deb9", "5c04967517c44a2c7470936a", "6124d1375244ab9dcb9ad9c8"], "flag": 1}
{"question": "How should different quantum computing devices be compared?", "body": "<p>In the last years, there has been a spur of demonstrations of devices able to perform proof of principle, small-scale, non-fault-tolerant quantum computation (or Noisy Intermediate-Scale Quantum technologies, how <a href=\"https://arxiv.org/abs/1801.00862\" rel=\"noreferrer\">they have been referred to</a>).</p>\n\n<p>With this I'm mostly referring to the superconducting and ion trap devices demonstrated by groups such as Google, Microsoft, Rigetti Computing, Blatt's group (and probably others that I'm forgetting now).</p>\n\n<p>These devices, as well as the ones that will follow them, are often radically different from each other (in terms of architecture, gates that are easier/harder to implement, number of qubit, connectivity between the qubits, coherence and gate times, generation and readout capabilities, gate fidelities, to name the most obvious factors).</p>\n\n<p>On the other hand, it is very common in press releases and non-technical news to just say \"the new X device has Y more qubits than the one before, therefore it is so much more powerful\".</p>\n\n<p>Is the number of qubits really such an important factor to assess these devices? Or should we instead use different metrics? More generally, are there \"simple\" metrics that can be used to qualitatively, but meaningfully, compare different devices? </p>\n", "pids": ["5ff68ceed4150a363cd3f196", "55a67faa65ce054aad6996d8"], "flag": 1}
{"question": "Has anyone seen this combinatorial identity involving the Bernoulli and Stirling numbers?", "body": "<p>Does anyone know a nice (combinatorial?) proof and/or reference for the following identity?</p>\n\n<blockquote>\n  <p>$$\\left( \\frac{\\alpha}{1 - e^{-\\alpha}} \\right)^{n+1} \\equiv \\sum_{j=0}^n \\frac{(n-j)!}{n!} |s(n+1, n+1-j)| \\alpha^j \\bmod \\alpha^{n+1}.$$</p>\n</blockquote>\n\n<p>Here</p>\n\n<p>$$\\frac{\\alpha}{1 - e^{-\\alpha}} = \\sum_{i=0}^{\\infty} (-1)^i \\frac{B_i \\alpha^i}{i!}$$</p>\n\n<p>is one of the generating functions for the <a href=\"http://en.wikipedia.org/wiki/Bernoulli_number#Generating_function\">Bernoulli numbers</a>, and $|s(n+1, n+1-j)|$ is an unsigned <a href=\"http://en.wikipedia.org/wiki/Stirling_numbers_of_the_first_kind\">Stirling number of the first kind</a>.</p>\n\n<p><strong>Motivation</strong> (feel free to ignore): this identity comes from two different computations of the <a href=\"http://en.wikipedia.org/wiki/Todd_class\">Todd class</a> of $\\mathbb{CP}^n$. One uses the <a href=\"http://en.wikipedia.org/wiki/Euler_sequence\">Euler sequence</a>. The other involves computing the holomorphic Euler characteristic $\\chi(\\mathcal{O}(k))$ of the line bundles $\\mathcal{O}(k)$ using that the higher cohomology of $\\mathcal{O}(k)$ vanishes for $k$ large enough and that for $k \\ge 0$, $H^0(\\mathcal{O}(k))$ is the dimension of the space of homogeneous polynomials of degree $k$ in $n+1$ variables, which is ${k+n \\choose n}$, then working out what the Todd class must be using <a href=\"http://en.wikipedia.org/wiki/Hirzebruch%E2%80%93Riemann%E2%80%93Roch_theorem\">Hirzebruch-Riemann-Roch</a>. This is a bit indirect to say the least, and I have no idea how to convert it into combinatorics. </p>\n", "pids": ["5f378ac49fced0a24b24d054"], "flag": 0}
{"question": "Quotient of $S^3\\times S^3$ by an action of $S^1$", "body": "<p>Consider the action of $S^1$ on the product of 3-spheres $S^3\\times S^3$ defined by:</p>\n\n<p>$$e^{it}.(z_1, z_2)=(e^{2it}z_1, e^{3it}z_2)$$</p>\n\n<p>where $z_1, z_2\\in S^3$. Here we understant $e^{2it}z_1$ as the multiplication by $e^{2it}$ in each component of $z_1$ when we look at $S^3$ as a subspace of $\\mathbb{C}^2$ (more precisely, $S^3=\\{(a,b)\\in \\mathbb{C}^2: |a|^2+|b|^2=1\\}$).</p>\n\n<p>So my question is what is (topologically, for instance) the quotient of $S^3\\times S^3$ by this action? I'm convinced that this should give $S^3\\times S^2$ because this action is in some sense a \"twisted\" <a href=\"https://en.wikipedia.org/wiki/Hopf_fibration\" rel=\"noreferrer\">Hopf fibration</a>, but I've not been able to show this (at least in an explicit way).</p>\n", "pids": ["56d8f6bfdabfae2eee98494b"], "flag": 0}
{"question": "How can it be trapped in a saddle point?", "body": "<p>I am currently a bit puzzled by how mini-batch gradient descent can be trapped in a saddle point. </p>\n\n<p>The solution might be too trivial that I don't get it.</p>\n\n<p>You get an new sample every epoch, and it computes a new error based on a new batch, so the cost function is only static for each batch, which means that the gradient also should change for each mini batch.. but according to <a href=\"http://sebastianruder.com/optimizing-gradient-descent/index.html#stochasticgradientdescent\" rel=\"noreferrer\">this</a> should  a vanilla implementation have issues with saddle points?</p>\n\n<blockquote>\n  <p>Another key challenge of minimizing highly non-convex error functions\n  common for neural networks is avoiding getting trapped in their\n  numerous suboptimal local minima. Dauphin et al. [19] argue that the\n  difficulty arises in fact not from local minima but from saddle\n  points, i.e. points where one dimension slopes up and another slopes\n  down. These saddle points are usually surrounded by a plateau of the\n  same error, which makes it notoriously hard for SGD to escape, as the\n  gradient is close to zero in all dimensions.</p>\n</blockquote>\n\n<p>I would mean that especially SGD would have clear advantage against saddle points, as it fluctuates towards its convergence... The fluctuations and the random sampling , and cost function being different for each epoch should be enough reasons for not becoming trapped in one.  </p>\n\n<p>For full batch gradient decent does it make sense that it can be trapped in  saddle point, as the error function is constant. </p>\n\n<p>I am a bit confused on the two other parts. </p>\n", "pids": ["555048ef45ce0a409eb72b92", "5736960c6e3b12023e51ee32"], "flag": 1}
{"question": "How power-efficient are quantum computers?", "body": "<p>Quantum algorithms scale faster than classical ones (at least for <a href=\"https://en.wikipedia.org/wiki/BQP\" rel=\"nofollow noreferrer\">certain problem clases</a>), meaning quantum computers would require a much smaller number of logical operations for inputs above a given size.</p>\n<p>However, it is not so commonly discussed how quantum computers compare to regular computers (a normal PC today) in terms of power consumption per logical operation. (Has this not been talked about much, because the main focus of quantum computers is how fast they can compute data?)</p>\n<p>Can someone explain why quantum computing would be more or less power-efficient than classical computing, per logical operation?</p>\n", "pids": ["5c75710bf56def9798749057"], "flag": 1}
{"question": "Prove the inequality $\\frac{b+c}{a(y+z)}+\\frac{c+a}{b(z+x)}+\\frac{a+b}{c(x+y)}\\geq \\frac{3(a+b+c)}{ax+by+cz}$", "body": "<blockquote>\n  <p>Suppose that <span class=\"math-container\">$a,b,c,x,y,z$</span> are all positive real numbers. Show that\n  <span class=\"math-container\">$$\\frac{b+c}{a(y+z)}+\\frac{c+a}{b(z+x)}+\\frac{a+b}{c(x+y)}\\geq \\frac{3(a+b+c)}{ax+by+cz}$$</span></p>\n</blockquote>\n\n<p>Below are what I've done, which may be misleading.</p>\n\n<ol>\n<li>I've tried to analyze <strong>when the equality holds</strong>：</li>\n</ol>\n\n<p>1.1 Under the condition that <span class=\"math-container\">$a=b=c$</span>, it reduces to\n<span class=\"math-container\">$$\\frac{2}{y+z}+\\frac{2}{z+x}+\\frac{2}{x+y}\\geq \\frac{9}{x+y+z}$$</span>\n1.2 Under the condition that <span class=\"math-container\">$x=y=z$</span>, it reduces to\n<span class=\"math-container\">$$\\frac{b+c}{2a}+\\frac{c+a}{2b}+\\frac{a+b}{2c}\\geq 3$$</span>\nBoth are easy to verify. However, <span class=\"math-container\">$ax+by+cz$</span> is not easy to deal with. Is there any famous inequality that I can use here? </p>\n\n<p>1.3 Under the condition that <span class=\"math-container\">$(x,y,z)$</span> and <span class=\"math-container\">$(a,b,c)$</span> are in proportion, i.e. <span class=\"math-container\">$x=at, y=bt, z=ct$</span> for some <span class=\"math-container\">$t&gt;0$</span>, the inequality reduces to\n<span class=\"math-container\">$$\\frac{1}{a}+\\frac{1}{b}+\\frac{1}{c}\\geq \\frac{3(a+b+c)}{a^2+b^2+c^2}$$</span>\nwhich can be proved by using <em>Newton's inequality</em>:\n<span class=\"math-container\">$$(ab+bc+ca)^2 \\geq 3abc(a+b+c)$$</span></p>\n\n<ol start=\"2\">\n<li><p>I’ve also tried to construct a function\n<span class=\"math-container\">$$f(x,y,z)=\\frac{b+c}{a(y+z)}+\\frac{c+a}{b(z+x)}+\\frac{a+b}{c(x+y)}- \\frac{3(a+b+c)}{ax+by+cz}$$</span> \nand analyze its global minimum. But the first-order condition is complicated\n<span class=\"math-container\">$$\\frac{3(a+b+c)}{(ax+by+cz)^2}=\\frac{c+a}{ab(z+x)^2}+\\frac{a+b}{ca(x+y)^2}$$</span>\n<span class=\"math-container\">$$\\frac{3(a+b+c)}{(ax+by+cz)^2}=\\frac{b+c}{ab(y+z)^2}+\\frac{a+b}{bc(x+y)^2}$$</span>\n<span class=\"math-container\">$$\\frac{3(a+b+c)}{(ax+by+cz)^2}=\\frac{b+c}{ca(y+z)^2}+\\frac{c+a}{bc(z+x)^2}$$</span>\nMaybe some convexity can be used here?</p></li>\n<li><p>Substitution has been considered. Let\n<span class=\"math-container\">$$u=\\frac{a}{a+b+c},v=\\frac{b}{a+b+c}, w=\\frac{c}{a+b+c}$$</span>\nThen <span class=\"math-container\">$u,v,w&gt;0$</span> and <span class=\"math-container\">$u+v+w=1$</span>, which are just weights we assign to <span class=\"math-container\">$x,y,z$</span>. The inequality becomes\n<span class=\"math-container\">$$\\frac{1}{u(y+z)}+\\frac{1}{v(z+x)}+\\frac{1}{w(x+y)}-\\frac{3}{ux+vy+wz}\\geq \\frac{1}{y+z}+\\frac{1}{z+x}+\\frac{1}{x+y}$$</span>\nDefine another function in variables <span class=\"math-container\">$u,v,w$</span>\n<span class=\"math-container\">$$g(u,v,w)=\\frac{1}{u(y+z)}+\\frac{1}{v(z+x)}+\\frac{1}{w(x+y)}-\\frac{3}{ux+vy+wz}$$</span>\nand consider the constrained optimization problem:\n<span class=\"math-container\">$$\\min g(u,v,w)\\\\ \\text{s.t. } u&gt;0\\\\ v&gt;0 \\\\w&gt;0\\\\ u+v+w=1$$</span>\nThe corresponding Lagrangian function can be\n<span class=\"math-container\">$$L_{\\lambda}(u,v,w)=\\frac{1}{u(y+z)}+\\frac{1}{v(z+x)}+\\frac{1}{w(x+y)}-\\frac{3}{ux+vy+wz}+\\lambda(u+v+w-1)$$</span>\nAnd the first-order conditions give\n<span class=\"math-container\">$$\\frac{1}{u^2(y+z)}-\\frac{3x}{(ux+vy+wz)^2}=\\lambda\\Rightarrow \\frac{1}{u(y+z)}-\\frac{3ux}{(ux+vy+wz)^2}=\\lambda u\\\\ \\frac{1}{v^2(z+x)}-\\frac{3y}{(ux+vy+wz)^2}=\\lambda\\Rightarrow \\frac{1}{v(z+x)}-\\frac{3vy}{(ux+vy+wz)^2}=\\lambda v\\\\ \\frac{1}{w^2(x+y)}-\\frac{3z}{(ux+vy+wz)^2}=\\lambda\\Rightarrow \\frac{1}{w(x+y)}-\\frac{3wz}{(ux+vy+wz)^2}=\\lambda w\\\\ u+v+w=1$$</span>\nSumming up yields\n<span class=\"math-container\">$$\\lambda=\\frac{1}{u(y+z)}+\\frac{1}{v(z+x)}+\\frac{1}{w(x+y)}-\\frac{3}{ux+vy+wz}$$</span>\nNone of the methods I tried seems to work, and now I even doubt the truth of the inequality.</p></li>\n</ol>\n", "pids": ["56d8ba86dabfae2eee2b4d2d"], "flag": 0}
{"question": "Why is “or” (in logic) sometimes equivalent to “and” (in natural language)?", "body": "<p>In classical propositional logic, <strong>or</strong> (aka. <em>disjunction</em>) is a Boolean function $\\vee:\\{0,1\\}^2\\longrightarrow\\{0,1\\}$ defined as $\\vee:=\\{ (00,0), (01,1), (10,1),(11,1) \\}$, and <strong>and</strong> (aka. <em>conjunction</em>) is a Boolean function $\\wedge: \\{0,1\\}^2\\longrightarrow\\{0,1\\}$ defined as $\\{(00,0),(01,0),(10,0),(11,1)\\}$.</p>\n\n<p>There's also <a href=\"https://en.wikipedia.org/wiki/Rule_of_inference\" rel=\"noreferrer\">rules of inference</a> for these functions, such as $\\vee$-introduction, $\\wedge$-introduction, $\\vee$-elimination, and $\\wedge$-elimination, as well as other machinery from logic.</p>\n\n\n\n<p>So, <strong>or</strong> and <strong>and</strong> are not the same object. But when using them in math reasoning, sometimes the 2 can be used interchangeably.</p>\n\n<p><strong>Example.</strong> Let $X$ be a topological space, let $A\\subseteq X$, let $\\text{Lim }A$ be the set of <a href=\"https://en.wikipedia.org/wiki/Limit_point\" rel=\"noreferrer\">limit points</a> of $A$. The <em>closure</em> of $A$ is defined as $A\\cup\\text{Lim }A$. But the set $A\\cup \\text{Lim }A$ is defined as the set $\\{x\\in X\\ |\\ x\\in A\\ \\vee\\ x\\in \\text{Lim }A\\}$, namely, the set of all $x\\in X$ where $x\\in A$ <strong>or</strong> $x\\in \\text{Lim }A$. Equivalently, th closure of $A$ is the set $A$ <em>and</em> its limit points.</p>\n\n<p>(This is the first example that came to mind, but hopefully you get the idea.)</p>\n\n<p>I know I'm mixing formal logic with natural (human!) language to the point of frivolity, but I'm wondering if there's a non-mundane reason for this equivalence. Perhaps <strong>or</strong> and <strong>and</strong> are \"dual\", in some sense? Or perhaps the equivalence arises just because natural language is really weird?</p>\n\n<p>(One could disregard this question by saying \"the meaning of <strong>or</strong> in logic is not the same as in natural language\" (usually natural language uses <em>exclusive-or</em>), just like the meaning of <strong>if</strong> in logic is not the same as in natural language (usually natural language uses <em>if-and-only-if</em>), but I get the feeling something else is going on.)</p>\n", "pids": ["56d92d55dabfae2eeee50957"], "flag": 0}
{"question": "Why does the monotone convergence theorem not apply on Riemann integrals?", "body": "<p>I had just learned in measure theory class about the monotone convergence theorem in this version:</p>\n\n<p>For every monotonically increasing sequence of functions <span class=\"math-container\">$f_n$</span> from measurable space <span class=\"math-container\">$X$</span> to <span class=\"math-container\">$[0, \\infty]$</span>,\n<span class=\"math-container\">$$\n\\text{if}\\quad\n\\lim_{n\\to \\infty}f_n = f,\n\\quad\\text{then}\\quad\n\\lim_{n\\to \\infty}\\int f_n \\, \\mathrm{d}\\mu = \\int f \\,\\mathrm{d}\\mu\n.\n$$</span></p>\n\n<p>I tried to find out why this theorem apply only for a Lebesgue integral, but I didn't find a counter example for Riemann integrals, so I would appreciate your help.</p>\n\n<p>(I guess that <span class=\"math-container\">$f$</span> might not be integrable in some cases, but I want a concrete example.)</p>\n", "pids": ["56d868f8dabfae2eeeb74c18"], "flag": 0}
{"question": "How well-studied is origami field theory?", "body": "<p>It's well known that angle trisection cannot be done with straightedge and compass alone, as</p>\n<blockquote>\n<p><strong>Theorem 1.</strong> If <span class=\"math-container\">$z \\in \\mathbb C$</span> is constructible with straightedge and compass from <span class=\"math-container\">$\\mathbb Q$</span>, then <span class=\"math-container\">$$\\mathbb Q (z) : \\mathbb Q = 2^n.$$</span></p>\n<p>But the minimal polynomial of <span class=\"math-container\">$\\cos 20 ^{\\circ}$</span> is <span class=\"math-container\">$8 x ^ { 3 } - 6 x - 1$</span>, so <span class=\"math-container\">$$\\mathbb Q (\\cos 20 ^{\\circ}) : \\mathbb Q = 3,$$</span></p>\n<p>That proves we cannot trisect <span class=\"math-container\">$ 60 ^{\\circ}$</span>.</p>\n</blockquote>\n<p>However, it's doable with origami, as <a href=\"https://math.stackexchange.com/questions/1176613/huzita-axiom-6-computing-the-origami-trisection-of-an-angle\">Huzita Axiom 6 - Computing the Origami Trisection of an Angle</a> shows. My question is:</p>\n<blockquote>\n<p>Exactly what field extensions can be obtained by considering origami constructible number? Is this as well-studied as straightedge and compass, i.e. do we have a similar theorem as <strong>Theorem 1</strong>?</p>\n</blockquote>\n", "pids": ["616ce5a25244ab9dcbacfd8c"], "flag": 0}
{"question": "Are bees disappearing and why?", "body": "<p>According to the web site of the film <a href=\"http://vanishingbees.co.uk/\">Vanishing of the Bees</a>:</p>\n\n<blockquote>\n  <p>Bees are dying in their billions. In the UK, around one fifth of honeybee hives were lost in the winter of 2008/2009.</p>\n</blockquote>\n\n<p>Is there evidence of bees disappearing and what are scientific theories on this subject?</p>\n", "pids": ["5cc0f600ced107d4c65376a6"], "flag": 1}
{"question": "How deep is the connection between the softmax function in ML and the Boltzmann distribution in thermodynamics?", "body": "<p>The softmax function, commonly used in neural networks to convert real numbers into probabilities, is the same function as the Boltzmann distribution, the probability distribution over energies for en ensemble of particles in thermal equilibrium at a given temperature T in thermodynamics.</p>\n\n<p>I can see some clear heuristical reasons why this is practical:</p>\n\n<ul>\n<li>No matter if input values are negative, softmax outputs positive values that sum to one.</li>\n<li>It's always differentiable, which is handy for backpropagation.</li>\n<li>It has a 'temperature' parameter controlling how lenient the network should be toward small values (when T is very large, all outcomes are equally likely, when very small, only the value with the largest input is selected).</li>\n</ul>\n\n<p>Is the Boltzmann function only used as softmax for practical reasons, or is there a deeper connection to thermodynamics/statistical physics?</p>\n", "pids": ["5e5e18a893d709897ce24867"], "flag": 1}
{"question": "Why do error correction protocols only work when the error rates are already significantly low to begin with?", "body": "<p><a href=\"https://en.wikipedia.org/wiki/Quantum_error_correction\" rel=\"nofollow noreferrer\">Quantum error correction</a> is a fundamental aspect of quantum computation, without which large-scale quantum computations are practically unfeasible.</p>\n\n<p>One aspect of fault-tolerant quantum computing that is often mentioned is that each error-correction protocol has associated an <em>error rate threshold</em>.\nBasically, for a given computation to be protectable against errors via a given protocol, the error rate of the gates must be below a certain threshold.</p>\n\n<p>In other words, if the error rates of single gates are not low enough, then it is not possible to apply error-correction protocols to make the computation more reliable.</p>\n\n<p>Why is this? Why is it not possible to reduce error rates that are not already very low to begin with?</p>\n", "pids": ["53e9b775b7602d970431d63a", "5ff68d23d4150a363cd48a18"], "flag": 1}
{"question": "What is the essential difference between a neural network and nonlinear regression?", "body": "<p>Artificial neural networks are often (demeneangly) called \"glorified regressions\". The main difference between ANNs and multiple / multivariate linear regression is of course, that the ANN models nonlinear relationships. </p>\n\n<p>So what is the difference between an ANN and a multiple / multivariate nonlinear regression model? </p>\n\n<p>The only thing I can think of, is the graph-like structure of the neural network, that allows for an efficient parameter learning procedure (backpropagation), and other advantages (flexible stackering of layers in deep networks allowing for feature learning, etc).</p>\n\n<p>Can they be effectively called 'glorified nonlinear regressions'? Or is there more to it?</p>\n\n<p>EDIT: Found a good discussion on this here <a href=\"https://www.quora.com/Is-Machine-Learning-just-glorified-curve-fitting\" rel=\"noreferrer\">https://www.quora.com/Is-Machine-Learning-just-glorified-curve-fitting</a> \nwhere essentially it is agreed that the differences are mostly nuiances, but the approach being similar. </p>\n\n<p>I understand that in that case, the answer is more of a subjective nature, and this question is not appropiate for stackexchange.</p>\n", "pids": ["58d82fcbd649053542fd67d7", "599c796d601a182cd263c833", "5aed14e217c44a443815999c", "5b1643ba8fbcbf6e5a9bc894", "5b3d98cc17c44a510f801b91"], "flag": 1}
{"question": "What is the difference between a qudit system with d=4 and a two-qubit system?", "body": "<p>I understand that a qudit is a quantum $d$-state system. If $d=4$, is this exactly the same as a two-qubit system, which also presents $4$ quantum states? The Hilbert space is the same, right? Are there any theoretical or practical differences?</p>\n", "pids": ["53e9b1f8b7602d9703c8df94"], "flag": 1}
{"question": "Can mountains on Earth grow higher than 49,000 feet (15,000 m)?", "body": "<p>I just saw this picture in <a href=\"http://www.learnsomethingeveryday.co.uk/2011/08/20\" rel=\"noreferrer\">Learn Something Every Day</a> and thought of you. Some of the sites I've found reason it with gravity but doesn't explain very well.</p>\n\n<p><a src=\"https://i.stack.imgur.com/tfUTZ.jpg\" width=\"320\" height=\"208\"></p>\n", "pids": ["53e9a824b7602d970316c9c1"], "flag": 1}
{"question": "Why can we cover $\\mathbb R^N$ with open balls of radius $r$ such that each point is in at most $N + 1$ balls?", "body": "<blockquote>\n<p>If <span class=\"math-container\">$N \\geq 3$</span>, why can we cover <span class=\"math-container\">$\\mathbb R^N$</span> with open balls of a fixed radius <span class=\"math-container\">$r$</span> such that each point is in at most <span class=\"math-container\">$N + 1$</span> balls?</p>\n</blockquote>\n<p>This is a claim in a proof of Lions' Vanishing Lemma, as presented in Willem's <em>Minimax Theorems</em> (Lemma 1.21). Probably very simple but I am not able to write a proper proof.</p>\n", "pids": ["56d86e1edabfae2eeedeb0db", "53e999f5b7602d970223e88c"], "flag": 0}
{"question": "Can linear maps between infinite-dimensional spaces be represented as matrices?", "body": "<p>Any linear map between two finite-dimensional vector spaces can be represented as a matrix under the bases of the two spaces. </p>\n\n<p>But if one or all of the vector spaces is infinite dimensional, is the linear map still represented as a matrix under their bases?</p>\n\n<p>If there is matrix of infinite dimension, what is it used for if not used as a representation of a linear map between vector spaces?</p>\n\n<p>Thanks and regards!</p>\n", "pids": ["53e99af2b7602d970237ef24"], "flag": 0}
{"question": "Is this graph a planar graph or not?", "body": "<p>I've been trying to find out if this graph is planar or not for a while and have really been coming up short when it comes to creating a planar drawing of the graph. My intuition is telling me that it's non-planar, but I cannot find any subgraph of the graph homeomorphic to K3, 3 (by Kuratowski's Theorem). Any help would be greatly appreciated. The graph can be seen below:<a href=\"https://i.stack.imgur.com/YMfmb.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/YMfmb.png\" alt=\"enter image description here\"></a></p>\n", "pids": ["53e99800b7602d970200d0b4"], "flag": 0}
{"question": "When did MCMC become commonplace?", "body": "<p>Does anyone know around what year MCMC became commonplace (i.e., a popular method for Bayesian inference)? A link to the number of published MCMC (journal) articles over time would be especially helpful.</p>\n", "pids": ["5f0eb2159fced0a24b9f1b8e"], "flag": 1}
{"question": "An example where the likelihood principle *really* matters?", "body": "<p>Is there an example where two different defensible tests with proportional likelihoods would lead one to <strong>markedly</strong> different (and equally defensible) inferences, for instance, where the p-values are order of magnitudes far apart, but the power to alternatives is similar? </p>\n\n<p>All the examples I see are very silly, comparing a binomial with a negative binomial, where the p-value of the first is 7% and of the second 3%, which are \"different\" only insofar one is making binary decisions on arbitrary thresholds of significance such as 5% (which, by the way, is a pretty low standard for inference) and do not even bother to look at power. If I change the threshold for 1%, for instance, both lead to the same conclusion. </p>\n\n<p>I've never seen an example where it would lead to markedly different and <em>defensible</em> inferences. Is there such an example?</p>\n\n<p>I'm asking because I've seen so much ink spent on this topic, as if the Likelihood Principle is something fundamental in the foundations of statistical inference. But if the best example one has are silly examples like the one above, the principle seems completely inconsequential. </p>\n\n<p>Thus, I'm looking for a very compelling example, where if one does not follow the LP the weight of evidence would be overwhelmingly pointing in one direction given one test, but, in a different test with proportional likelihood, the weight of evidence would be overwhelmingly pointing in an opposite direction, and both conclusions look sensible.</p>\n\n<p>Ideally, one could demonstrate we can have arbitrarily far apart, yet sensible, answers, such as tests with <span class=\"math-container\">$p =0.1$</span> versus <span class=\"math-container\">$p= 10^{-10}$</span> with proportional likelihoods and equivalent power to detect the same alternative.</p>\n\n<p><strong>PS:</strong> Bruce's answer does not address the question at all.</p>\n", "pids": ["55a6426e65ce054aad61ed22"], "flag": 1}
{"question": "Jones Polynomial", "body": "<p>There are many fairly standard quantum algorithms that can all be understood within a very similar framework, from Deutsch's algorithm Simon's problem, Grover's search, Shor's algorithm and so on.</p>\n\n<p>One algorithm that seems to be completely different is the algorithm for evaluating the <a href=\"https://arxiv.org/abs/quant-ph/0511096\" rel=\"noreferrer\">Jones Polynomial</a>. Moreover, it seems like this is a crucial algorithm to understand in the sense that it is a <a href=\"https://arxiv.org/abs/quant-ph/0001108\" rel=\"noreferrer\">BQP-complete</a> problem: it exhibits the full power of a quantum computer. Also, for a variant of the problem, it's <a href=\"https://arxiv.org/abs/0707.2831\" rel=\"noreferrer\">DQC-1 complete</a>, i.e. it exhibits the full power of <a href=\"https://arxiv.org/abs/quant-ph/9802037\" rel=\"noreferrer\">one clean qubit</a>.</p>\n\n<p>The <a href=\"https://arxiv.org/abs/quant-ph/0511096\" rel=\"noreferrer\">Jones Polynomial algorithm</a> paper presents the algorithm in a very different way to the other quantum algorithms. Is there a more similar/familiar way that I can understand the algorithm (specifically, the unitary $U$ in the DQC-1 variant, or just the whole circuit in the BQP-complete variant)?</p>\n", "pids": ["5f0ea6ec9fced0a24bbd27df", "64990ccbd68f896efaf8470e"], "flag": 1}
{"question": "&quot;Casual&quot; mathematical facts with practical consequences", "body": "<p>Some mathematical facts -be them approximations or not- can be described as coincidences, without any deeper meaning in themselves, but leading to relevant practical consequences. I was thinking in these two examples:</p>\n\n<ul>\n<li>$2^{10} = 1024 \\approx 1000 = 10^3$ </li>\n</ul>\n\n<p>This \"casual\" approximate equation is practically relevant and potentially dangerous (I don't know what he was thinking, that guy who invented mathematics and gave us 10 fingers!). First some engineers created the <a href=\"http://en.wikipedia.org/wiki/Decibel\">decibel</a> and started assuming 'a 3db change means a factor of 2' - harmless enough. But then came digital computers and the convention-confusion <a href=\"http://en.wikipedia.org/wiki/Kilobyte\">KB=1024 bytes</a> started.</p>\n\n<ul>\n<li>$\\displaystyle 2^{7/12} = 1.498307\\ldots \\approx 3/2$</li>\n</ul>\n\n<p>Related to the tempered system used in music since -approx- Bach, this can be seen as a fortunate or unfortunate fact. If it were an exact equation, musical tuning <a href=\"http://en.wikipedia.org/wiki/Equal_temperament#Twelve-tone_equal_temperament\">would be simpler</a> and 'pure'; because it's not, the intervals we usually hear are 'impure'. On the other hand, if the approximation were just a little worse, the equal temperament would we intolerable, and to transpose music in most instruments would be a mess. </p>\n\n<p>Can you think of more examples?</p>\n", "pids": ["5c77fd6f4895d9cbc66f6d35"], "flag": 0}
{"question": "Do 1.4 million Chinese people die each year because of air pollution?", "body": "<p>This claim is made in <a href=\"http://www.lemonde.fr/climat/article/2015/12/18/nouvelle-alerte-maximale-a-la-pollution-de-l-air-a-pekin_4834430_1652612.html\">an article</a> published on december 18th on the online version of the French newspaper <em>Le Monde</em>.</p>\n\n<blockquote>\n  <p>Des études scientifiques ont estimé que près de 1,4 million de Chinois meurent chaque année, directement ou indirectement, de la pollution de l’air.</p>\n</blockquote>\n\n<p>Which translates to</p>\n\n<blockquote>\n  <p>Some scientific studies estimated that almost 1.4 million Chinese\n  people die each year, directly or indirectly, from air pollution.</p>\n</blockquote>\n\n<p>This claim is made without referring to any source. It sounds like a huge number to me, so I'd like to know if this is true.</p>\n", "pids": ["56d8188ddabfae2eee82f655", "56d8188ddabfae2eee82f655"], "flag": 1}
{"question": "What condition need to be imposed on Havel-Hakimi theorem to check for connected graph?", "body": "<blockquote>\n  <p><strong>Havel-Hakimi Theorem</strong>:\n  A sequence s: $d_1, d_2, \\ldots, d_n$ of non-negative integers\n      with $\\Delta = d_1 \\geq d_2 \\geq \\ldots \\geq d_n$ and $\\Delta \\geq 1$, is graphical if and only if the \n      sequence\n          $$s_1: d_2 - 1, d_3 - 1, \\ldots d_{\\Delta + 1} - 1, d_{\\Delta + 2}, \\ldots, d_n$$\n          is graphical.<br>\n  Havel-Hakimi theorem provides an algorithm for determining whether a given finite sequence of non-negative\n      integers is graphical. If, upon repeated application of Theorem 1, we arrive at a sequence, where every term of\n      which 0, then the original sequence is graphical. On the other hand, if we arrive a sequence containing a negative\n      integer, then the given sequence is not graphical. </p>\n</blockquote>\n\n<p>I tried several sequences and realized, the sequence is not graphical if it fails Havel-Hakimi's theorem. However, it doesn't always work for <em>connected graph</em>. For instance, the sequence:\n$$ 3, 3, 1, 1, 1, 1, 1, 1$$\ncan be processed by Havel-Hakimi's algorithm as follows:</p>\n\n<pre><code>3, 3, 1, 1, 1, 1, 1, 1\n2, 0, 0, 1, 1, 1, 1\n2, 1, 1, 1, 1, 0, 0\n0, 0, 1, 1, 0, 0\n1, 1, 0, 0, 0, 0\n0, 0, 0, 0, 0\n</code></pre>\n\n<p>But it can't be graphed as a connected component. On the other hand, the sequence:\n$$5, 4, 3, 2, 2, 2, 2, 2$$\nalso satisfies the Havel-Hakimi's algorithm, but can be graphed as follows:</p>\n\n<p><a src=\"https://i.stack.imgur.com/QJggY.png\" alt=\"enter image description here\"></p>\n\n<p>So my question is, what other conditions need to be added so that Havel-Hakimi's algorithm work for connected graph? Thank you.</p>\n", "pids": ["62283edd5aee126c0fe05b41"], "flag": 0}
{"question": "Why is LogLoss preferred over other proper scoring rules?", "body": "<p>It seems anytime people care about estimating probabilities accurately they choose LogLoss as the evaluation metric. But there are many other evaluation metrics which will prefer accurate estimation of probabilities (and not only ranking or performance at some cut-off). Including RMSE (on the continuous model score vs 0/1 actual). \nObviously LogLoss penalizes over confidence very heavily, Why is this desirable? When is it not? </p>\n", "pids": ["53e9b52db7602d9704060707", "55503f8945ce0a409eb2eabc", "53e9a2fab7602d9702c02bf1"], "flag": 1}
{"question": "Solving a peculiar system of equations", "body": "<p>I have the following system of equations where the $m$'s are known but $a, b, c, x, y, z$ are unknown. How does one go about solving this system? All the usual linear algebra tricks I know don't apply and I don't want to do it through tedious substitutions.</p>\n\n<p>\\begin{aligned}\na + b + c &amp;= m_0 \\\\\nax + by + cz &amp;= m_1 \\\\\nax^2 + by^2 + cz^2 &amp;= m_2 \\\\\nax^3 + by^3 + cz^3 &amp;= m_3 \\\\\nax^4 + by^4 + cz^4 &amp;= m_4 \\\\\nax^5 + by^5 + cz^5  &amp;= m_5\n\\end{aligned}</p>\n", "pids": ["5fe1e7197767f8fc9d682bb4"], "flag": 0}
{"question": "Tensors, what should I learn before?", "body": "<p>Here I will be just posting a simple questions. I know about vectors but now I want to know about tensors. In a physics class I was told that scalars are tensors of rank 0 and vectors are tensors of rank 1. Now what will be a tensor of rank <span class=\"math-container\">$2,3\\ldots$</span>? This is quite tempting.\nSo my question is: What are the prerequisites I need to learn profoundly before taking up an introductory course on \"Tensors\"?</p>\n", "pids": ["53e9ace1b7602d97036be162"], "flag": 0}
{"question": "How does random forest generate the random forest", "body": "<p>I am not an expert of random forest but I clearly understand that the key issue with random forest is the (random) tree generation. Can you explain me how the trees are generated? (i.e. What is the used distribution for tree generation?)</p>\n\n<p>Thanks in advance ! </p>\n", "pids": ["5ff7562bd4150a363c6b1faf"], "flag": 1}
{"question": "3 other extensions of the Secretary Problem", "body": "<p>In the classical <a href=\"https://en.wikipedia.org/wiki/Secretary_problem\" rel=\"nofollow noreferrer\">secretary problem</a> (also known as Marriage, Sultan's Dowry, Gogol problems),</p>\n<ol>\n<li><p>There are <span class=\"math-container\">$n$</span> candidates ordered from the best to the worst (no ties).  We know <span class=\"math-container\">$n$</span>.</p>\n</li>\n<li><p>The candidates arrive sequentially in random order (uniform distribution).</p>\n</li>\n<li><p>We can only determine the relative ranks as they arrive (and can not know the absolute ranks).</p>\n</li>\n<li><p>We can either accept or reject a candidate. When a candidate is rejected she cannot be recalled.</p>\n</li>\n</ol>\n<p>We want to choose the very best candidate and have to find the optimal strategy and its probability of success.</p>\n<p>There are a lot of extensions of this problem (for example: <span class=\"math-container\">$n$</span> is not known, not uniform distribution for <span class=\"math-container\">$k$</span> less than <span class=\"math-container\">$n$</span>,\nto select the <span class=\"math-container\">$k$</span> best candidates, etc.). Mike gave us very useful information about an extension (to select the <span class=\"math-container\">$2,4,k$</span> best) in his\nanswer to the &quot;<a href=\"https://math.stackexchange.com/questions/30601/generalization-of-the-sultans-dowry-problem\">Generalization of the Sultan's dowry problem</a>&quot;.</p>\n<p>In these 3 new extensions (with 1,2,3,4 as in the Classical Secretary problem) , we have to to find the optimal strategy and its probability of success if:</p>\n<p>Problem 1: We want to choose the very best OR the worst (only one selection).</p>\n<p>Problem 2: We want to choose the median candidate (only one selection).</p>\n<p>Problem 3: We want to choose the very best AND the worst  (two selections).</p>\n", "pids": ["5c755496f56def979865c55c"], "flag": 0}
{"question": "What kind of real-world problems (excluding cryptography) can be solved efficiently by a quantum algorithm?", "body": "<p>This question is very similar as <a href=\"https://quantumcomputing.stackexchange.com/questions/1584/is-there-any-general-statement-about-what-kinds-of-problems-can-be-solved-more-e\">Is there any general statement about what kinds of problems can be solved more efficiently using a quantum computer?</a></p>\n\n<p>But the answers provided to that questions mainly looked at it from a  <em>theoretical/mathematical</em> point of view.</p>\n\n<p>For this question, I am more interested in the <em>practical/engineering</em> point of view.  So I would like to understand what kind of problems can be more efficiently solved by a quantum algorithm than you would currently be able to do with a classical algorithm.  So I am really assuming that you do not have all knowledge about all possible classical algorithms that could optimally solve the same problem!</p>\n\n<p>I am aware that the <a href=\"https://math.nist.gov/quantum/zoo/\" rel=\"nofollow noreferrer\">quantum zoo</a> expresses a whole collection of problems for which there exists a quantum algorithm that runs more efficiently than a classical algorithm but I fail to link these algorithms to <em>real-world problems</em>.</p>\n\n<p>I understand that Shor's factoring algorithm is very important in the world of cryptography but I have deliberately excluded cryptography from the scope of this question as the world of cryptography is a very specific world which deserves his own questions.</p>\n\n<p>In efficient quantum algorithms, I mean that there must at least be one step in the algorithm that must be translated to a quantum circuit on a n-qubit quantum computer.  So basically this quantum circuit is creating a <span class=\"math-container\">$2^n$</span> x <span class=\"math-container\">$2^n$</span> matrix and its execution will give one of the <span class=\"math-container\">$2^n$</span> possibilities with a certain possibility (so different runs might give different results - where the likely hood of each of the <span class=\"math-container\">$2^n$</span> possibilities is determined by the constructed <span class=\"math-container\">$2^n$</span> x <span class=\"math-container\">$2^n$</span> Hermitian matrix.)</p>\n\n<p>So I think to answer my question there must be some aspect/characteristic of the real world problem that can be mapped to a <span class=\"math-container\">$2^n \\times 2^n$</span> Hermitian matrix.\nSo what kind of aspects/characteristics of a real-world problem can be mapped to such a matrix?</p>\n\n<p>With <em>real-world problem</em> I mean an actual problem that might be solved by a quantum algorithm, I don't mean a domain where there might be a potential use of the quantum algorithm.</p>\n", "pids": ["5f0e728e9fced0a24b52baa4", "60de5c3891e0110ac15e4407", "5c75752ff56def97989c7f3a"], "flag": 1}
{"question": "Continuous $f\\colon [0,1]\\to \\mathbb{R}$ all of whose nonempty fibers are countably infinite?", "body": "<p>I have been told it is possible to construct a continuous function $f\\colon [0,1]\\to \\mathbb{R}$ such that $f^{-1}(x)$ is either empty or has cardinality $\\aleph_0$ for every $x\\in \\mathbb{R}$. I've thought about this for a while but can't seem to cook up an example. Does anyone know such a construction?</p>\n", "pids": ["53e9b89bb7602d9704473add"], "flag": 0}
{"question": "Permutations with restriction", "body": "<p>We have $n$ types of objects, and the number of objects of type $i$ is $a_i$, $1\\leq i\\leq n$. </p>\n\n<p>What is the number of permutation of the $\\sum_{i=1}^n a_i$ objects, if no two objects of the same type are next to each other?</p>\n\n<p>A simple example: If we have the objects $\\{a,a,a,b,b,c,c\\}$, then we allow $abcabac$ but not $aaabbcc$.</p>\n", "pids": ["53e9ac8eb7602d970366437f"], "flag": 0}
{"question": "History of Modern Mathematics Available on the Internet", "body": "<p>I have been meaning to ask this question for some time, and have been spurred to do so by Georges Elencwajg's fantastic answer to <a href=\"https://math.stackexchange.com/questions/147561/sheaves-and-complex-analysis/147676#147676\">this</a> question and the link contained therein.</p>\n<p>In my free time I enjoy reading historical accounts of &quot;recent&quot; mathematics (where, to me, recent means within the last 100 years). A few favorites of mine being Alexander Soifer's <a href=\"https://rads.stackoverflow.com/amzn/click/com/0387746404\" rel=\"noreferrer\" rel=\"nofollow noreferrer\">The Mathematical Coloring Book</a>, Allyn Jackson's two part mini-biography of Alexander Grothendieck (<a href=\"http://www.ams.org/notices/200409/fea-grothendieck-part1.pdf\" rel=\"noreferrer\">Part I</a> and <a href=\"http://www.ams.org/notices/200410/fea-grothendieck-part2.pdf\" rel=\"noreferrer\">Part II</a>) and Charles Weibel's <a href=\"http://www.math.uiuc.edu/K-theory/0245/survey.pdf\" rel=\"noreferrer\">History of Homological Algebra</a>.</p>\n<p>My question is then:</p>\n<blockquote>\n<p>What freely available resources (i.e. papers, theses, articles) are there concerning the history of &quot;recent&quot; mathematics on the internet?</p>\n</blockquote>\n<p>I would like to treat this question in a manner similar to my <a href=\"https://math.stackexchange.com/questions/144165/free-graph-theory-resources\">question</a> about graph theory resources, namely as a list of links to the relevant materials along with a short description. Perhaps one person (I would do this if necessary) could collect all the suggestions and links into one answer which could be used a repository for such materials.</p>\n<p>Any suggestions I receive in the comments will listed below.</p>\n<p>Suggestions in the Comments:</p>\n<ul>\n<li><p>[Gregory H. Moore, The emergence of open sets, closed sets, and limit points in analysis and topology]</p>\n<p><a href=\"http://mcs.cankaya.edu.tr/%7Ekenan/Moore2008.pdf\" rel=\"noreferrer\">http://mcs.cankaya.edu.tr/~kenan/Moore2008.pdf</a></p>\n</li>\n</ul>\n", "pids": ["53e99ab3b7602d9702330433"], "flag": 0}
{"question": "How is the general solution for algebraic equations of degree five formulated?", "body": "<p>In a book on neural networks I found the statement:</p>\n\n<blockquote>\n  <p>The general solution for algebraic equations of degree five, for example, cannot be formulated using only algebraic functions, yet this can be done if a <strong>more general class of functions</strong> is allowed as computational primitives.</p>\n</blockquote>\n\n<p>What are the \"more general class of functions\"?</p>\n", "pids": ["56d903a3dabfae2eeee812f7"], "flag": 0}
{"question": "Combining two confidence intervals/point estimates", "body": "<p>Suppose one has two independent samples from the same population, and different methods were used on the two samples to derive point estimate and confidence intervals. In trivial cases a sensible person would just pool the two samples and use one method to do the analysis, but let's suppose for the moment that different method has to be used due to limitation of one of the sample such as missing data. These two separate analyses would generate independent, equally valid estimates for the population attribute of interest. Intuitively I think there should be a way to properly combine these two estimates, both in terms of point estimate and confidence interval, resulting in a better estimation procedure. My question is what should be the best way to do it? I can imagine a weighted mean of some sort according to the information/sample size in each sample, but what about the confidence intervals? </p>\n", "pids": ["53e9986eb7602d97020a7046"], "flag": 1}
{"question": "A nice introduction to forcing", "body": "<p>I want to get acquainted with forcing, along with a few friends, and I'm looking for a text to introduce the basic notions (pardon the pun :) ).</p>\n\n<p>The point is to study a text (or texts, if they can be reasonably seamed together) together for about one week, several hours a day, each of us (three) preparing a part on his own so as to explain it to the others (and so understand it better himself).</p>\n\n<p>Again, I'm not looking for something necessarily in-depth, just enough to understand the basics at a decent, but not overly exerting pace (after all, it's still summer vacation for us :) ).</p>\n\n<p>It is important to mention that all of us are somewhat familiar with the basics of descriptive set theory and model theory (but not axiomatic set theory per se), so ideally I would like a source that would somehow capitalize on that familiarity.</p>\n\n<p>Any suggestions?</p>\n", "pids": ["53e9a0dfb7602d97029cb37b"], "flag": 0}
{"question": "How to prove/disprove universality for a set of gates?", "body": "<p>A universal set of gates are able to mimic the operation of any other gate type, given enough gates. For example, a universal set of quantum gates are the Hadamard (&nbsp;<span class=\"math-container\">$H$</span>&nbsp;), the <span class=\"math-container\">$\\pi/8$</span> phase shift (&nbsp;<span class=\"math-container\">$T$</span>&nbsp;), and the <span class=\"math-container\">$\\mathrm{CNOT}$</span> gate. How would one disprove or prove universality of a set of gates such as <span class=\"math-container\">$\\{H,T\\}$</span>, <span class=\"math-container\">$\\{\\mathrm{CNOT},T\\}$</span>, or <span class=\"math-container\">$\\{\\mathrm{CNOT}, H\\}$</span>?</p>\n", "pids": ["5c7569fbf56def97982f2e4d", "53e9ae55b7602d970386c92f"], "flag": 1}
{"question": "Can vectors be inverted?", "body": "<p>I wish to enquire if it is possible to solve the below for $C$.</p>\n\n<p>$$B^{-1}(x-\\mu) = xc $$</p>\n\n<p>Here obviously $B$ is an invertible matrix and both $c$ and $\\mu$ are column vectors.\nWould the solution be $$x^{-1}B^{-1}(x-\\mu) = c $$ is it possible to invert vectors ?</p>\n\n<p>How about if it was the other way</p>\n\n<p>$$B^{-1}(x-\\mu) = cx $$</p>\n\n<p>Is there any other way to do this ?\nThanks in advance. </p>\n", "pids": ["5c757147f56def979876d4a2"], "flag": 0}
{"question": "When can you use data-based criteria to specify a regression model?", "body": "<p>I've heard that when many regression model specifications (say, in OLS) are considered as possibilities for a dataset, this causes multiple comparison problems and the p-values and confidence intervals are no longer reliable. One extreme example of this is stepwise regression.</p>\n\n<p>When can I use the data itself to help specify the model, and when is this not a valid approach? Do you always need to have a subject-matter-based theory to form  the model?</p>\n", "pids": ["5f0de2f49fced0a24b9fea79"], "flag": 1}
{"question": "Estimating R-squared and statistical significance from penalized regression model", "body": "<p>I am using the R package <em>penalized</em> to obtain shrunken estimates of coefficients for a dataset where I have lots of predictors and little knowledge of which ones are important. After I've picked tuning parameters L1 and L2 and I'm satisfied with my coefficients, is there a statistically sound way to summarize the model fit with something like R-squared?</p>\n<p>Furthermore, I'm interested in testing the overall significance of the model (i.e. does R²=0, or do all the =0).</p>\n<p>I've read through the answers on a similar question asked <a href=\"https://stats.stackexchange.com/questions/2121/how-can-i-estimate-coefficient-standard-errors-when-using-ridge-regression\">here</a>, but it didn't quite answer my question. There's an excellent tutorial on the R package that I'm using <a href=\"http://cran.r-project.org/web/packages/penalized/vignettes/penalized.pdf\" rel=\"noreferrer\">here</a>, and the author Jelle Goeman had the following note at the end of the tutorial regarding confidence intervals from penalized regression models:</p>\n<blockquote>\n<p>It is a very natural question to ask for standard errors of regression coefficients or other estimated quantities. In principle such standard errors can easily be calculated, e.g. using the bootstrap.</p>\n<p>Still, this package deliberately does not provide them. The reason for this is that standard errors are not very meaningful for strongly biased estimates such as arise from penalized estimation methods. Penalized estimation is a procedure that reduces the variance of estimators by introducing substantial bias. The bias of each estimator is therefore a major component of its mean squared error, whereas its variance may contribute only a small part.</p>\n<p>Unfortunately, in most applications of penalized regression it is impossible to obtain a sufficiently precise estimate of the bias. Any bootstrap-based cal- culations can only give an assessment of the variance of the estimates. Reliable estimates of the bias are only available if reliable unbiased estimates are available, which is typically not the case in situations in which penalized estimates are used.</p>\n<p>Reporting a standard error of a penalized estimate therefore tells only part of the story. It can give a mistaken impression of great precision, completely ignoring the inaccuracy caused by the bias. It is certainly a mistake to make confidence statements that are only based on an assessment of the variance of the estimates, such as bootstrap-based confidence intervals do.</p>\n</blockquote>\n", "pids": ["56d90276dabfae2eeee08651"], "flag": 1}
{"question": "Why at all consider sampling without replacement in a practical application?", "body": "<p>Sampling with replacement has two advantages over sampling without replacement as I see it:</p>\n\n<p>1) You don't need to worry about the finite population correction.</p>\n\n<p>2) There is a chance that elements from the population are drawn multiple times - then you can recycle the measurements and save time.</p>\n\n<p>Of course from an academic POV one has to investigate both methods. But from a practical POV I don't see why one would consider sampling without replacement given the advantages of with replacement.</p>\n\n<p>But I am a beginner in statistics so there might be plenty of good reasons why without replacement might be the superior choice - at least for specific use cases. Please, unconfuse me!</p>\n", "pids": ["5c756b2df56def97983b5f00"], "flag": 1}
{"question": "When is an accumulation point not the limit of some sequence in a topological space?", "body": "<p>In a general topological space $(X,\\tau)$ we define an accumulation point $x_0$ of a set $A$ to be a point such that any open neighbourhood about $x_0$ intersects $A$.</p>\n\n<p>Now it is certainly true that if a sequence $x_n\\in A$ tends to some limit $x \\in X$, $x$ must be an accumulation point of $A$ since $x_n$ lies in any open neighbourhood of $x$ for all $n$ sufficiently large, and so lies in the intersection of this open neighbourhood and $A$. </p>\n\n<p><strong>What I would like to know is:</strong> Are there any (preferably elementary) examples of a topological space with a subset $A$ that has an accumulation point which is not the limit of any sequence in $A$. I would also appreciate information on any conditions on a space which imply that any accumulation point of $A$ is the limit of some sequence in $A$.</p>\n\n<p>For example, if $X$ is first countable (e.g. any metric space) then it is easy to show that any accumulation point of $A$ must be the limit of some sequence of points in $A$. Intuitively this is because for a given point $x$, we can find a nested sequence of open sets that \"get smaller\" and can eventually be contained in any open neighbourhood of $x$, so these nested open sets \"contract around $x$, allowing us to find such a sequence.</p>\n", "pids": ["56d86028dabfae2eee75d7da"], "flag": 0}
{"question": "How to interpret a QQ-plot of p-values", "body": "<p>I am doing GWAS SNP association studies on diseases by using a software called plink (<a href=\"http://pngu.mgh.harvard.edu/~purcell/plink/download.shtml\">http://pngu.mgh.harvard.edu/~purcell/plink/download.shtml</a>).</p>\n\n<p>With association results I get p-values for all the SNPs that was analyzed. Now, I use a QQ-plot of those p-values to show if a very low p-value differs from the expected distribution of p-values (a uniform distribution). If a p-value deviates from the expected distribution one \"may\" call that p-value for statistic significant.</p>\n\n<p>As you can see in the QQ-plot, at the top tail end, the last 4 points are somewhat hard to interpret. Two of the last points in the grey suggests that those p-values are in the expected distribution of p-values, whilst the other two are not.</p>\n\n<p>Now, how to interpret this, the last two points have <em>lower</em> p-values but are not \"significant\" according to the QQ-plot, whilst the other two points with <em>higher</em> p-values are \"significant\"? How can this be true?</p>\n\n<p><a src=\"https://i.stack.imgur.com/zwSwt.png\" alt=\"enter image description here\"></p>\n", "pids": ["56d8af41dabfae2eeed48269"], "flag": 1}
{"question": "What would be an example of a really simple model with an intractable likelihood?", "body": "<p><a href=\"http://en.wikipedia.org/wiki/Approximate_Bayesian_computation\" rel=\"noreferrer\">Approximate Bayesian computation</a> is a really cool technique for fitting basically any stochastic model, intended for models where the likelihood is intractable (say, you can sample from the model if you fix the parameters but you cannot <em>numerically, algorithmically or analytically</em> calculate the likelihood). When introducing approximate Bayesian computation (ABC) to an audience it is nice to use some example model that is really simple but still somewhat interesting <strong>and</strong> that has an intractable likelihood.</p>\n\n<p><strong>What would be a good example of a really simple model that still has an intractable likelihood?</strong></p>\n", "pids": ["56d8d7aedabfae2eeed7a5f6"], "flag": 1}
{"question": "Can the factorial function be written as a sum?", "body": "<p>I know of the sum of the natural logarithms of the factors of n! , but would like to know if any others exist.</p>\n", "pids": ["53e997fcb7602d970200996c"], "flag": 0}
{"question": "Integral results in difference of means $\\pi(\\frac{a+b}{2} - \\sqrt{ab})$", "body": "<p><span class=\"math-container\">$$\\int_a^b \\left\\{ \\left(1-\\frac{a}{r}\\right)\\left(\\frac{b}{r}-1\\right)\\right\\}^{1/2}dr = \\pi\\left(\\frac{a+b}{2} - \\sqrt{ab}\\right)$$</span></p>\n<p>What an interesting integral! What strikes me is that the result involves the difference of the arithmetic and geometric mean. <strong>Is there an innate geometric explanation that corresponds to this result? And can we generalize this integral to, say, the mean of three or more items?</strong></p>\n<hr />\n<p>Some background on where I saw it and how to solve it. This arises in calculating the action variable <span class=\"math-container\">$I$</span> for the Kepler problem (Hamiltonian <span class=\"math-container\">$H=\\frac{p_r^2}{2m}+\\frac{p_\\phi^2}{2mr}-\\frac{k}{r}$</span>). The <span class=\"math-container\">$a,b$</span> are the minimal and maximal <span class=\"math-container\">$r$</span> from the origin set at the focus of an ellipse (i.e. the perihelion/aphelion). <a href=\"http://www.damtp.cam.ac.uk/user/tong/dynamics.html\" rel=\"noreferrer\">See David Tong's Classical Dynamics notes <span class=\"math-container\">$\\S$</span>4.5.4.</a></p>\n<p>I was able to solve the integral by using the third Euler substitution, letting</p>\n<p><span class=\"math-container\">$$\\left\\{ \\left(1-\\frac{a}{r}\\right)\\left(\\frac{b}{r}-1\\right)\\right\\}^{1/2}=\\frac{1}{r}\\sqrt{-(r-a)(r-b)}=\\frac{1}{r}(r-a)t$$</span></p>\n<p>giving <span class=\"math-container\">$r=\\frac{b+at^2}{1+t^2}$</span> and</p>\n<p><span class=\"math-container\">$$2(b-a)\\left\\{\\int_{t(r_2)=0}^{t(r_1)=\\infty}\\frac{t^2}{(1+t^2)^2}dt - \\int_{t(r_2)=0}^{t(r_1)=\\infty}\\frac{\\frac{a}{b}t^2}{(1+t^2)(1+\\frac{a}{b}t^2)}dt\\right\\}$$</span>\n<span class=\"math-container\">$$=\\pi\\left(\\frac{b-a}{2}\\right) + \\pi\\left(a-\\sqrt{ab}\\right)=\\pi\\left(\\frac{a+b}{2} - \\sqrt{ab}\\right).$$</span></p>\n", "pids": ["58437744ac44360f10834d66", "5a260c5d17c44a4ba8a2a447", "5cd07b00ced107d4c6d4300c", "5c8676084895d9cbc66153ba", "5a260c5d17c44a4ba8a2a414", "5c757224f56def97987e466b", "5c3bcb31df5b8c0b3cc29061", "5488e9fb45ce471f90910c41", "56d8d05edabfae2eee9ee926"], "flag": 0}
{"question": "Proving $\\sum_{k=0}^{2m}(-1)^k{\\binom{2m}{k}}^3=(-1)^m\\binom{2m}{m}\\binom{3m}{m}$ (Dixon&#39;s identity)", "body": "<p>I found the following formula in a book without any proof:</p>\n\n<p>$$\\sum_{k=0}^{2m}(-1)^k{\\binom{2m}{k}}^3=(-1)^m\\binom{2m}{m}\\binom{3m}{m}.$$</p>\n\n<p>I don't know how to prove this at all. Could you show me how to prove this? Or If you have any helpful information, please teach me. I need your help.</p>\n\n<p><em>Update</em> : I <a href=\"https://mathoverflow.net/questions/143334/proving-sum-k-02m-1k-binom2mk3-1m-binom2mm-binom3mm\">crossposted to MO</a>.</p>\n", "pids": ["53e9a2acb7602d9702bb20ba"], "flag": 0}
{"question": "Gradient descent on non-convex function works. How?", "body": "<p>For Netflix Prize competition on recommendations one method used a stochastic gradient descent, popularized by <a href=\"http://sifter.org/~simon/journal/20061211.html\" rel=\"nofollow noreferrer\">Simon Funk</a> who used it to solve an SVD approximately. The math is better explained <a href=\"http://www.cs.bme.hu/nagyadat/Recommender_systems_handbook.pdf\" rel=\"nofollow noreferrer\">here</a> on pg 152. A rating is predicted by </p>\n\n<p><span class=\"math-container\">$$\n\\hat{r}_{ui} = \\mu + b_i + b_u + q_i^Tp_u\n$$</span></p>\n\n<p>Regularized square error is</p>\n\n<p><span class=\"math-container\">$$\n\\min_{b*,q*,p*} \\sum_{u,i} (r_{ui} - \\mu - b_i - b_u - q_i^Tp_u)^2 + \n\\lambda_4 (b_i^2 + b_u^2 + ||q_i||^2 + ||p_u||^2)\n$$</span></p>\n\n<p>If partial derivatives are taken according to each variable, and through a constant for the update rule we have equations such as</p>\n\n<p><span class=\"math-container\">$$\nb_u \\leftarrow b_u + \\gamma (e_{ui} - \\lambda_4 \\cdot b_u)\n$$</span></p>\n\n<p>[The rest is skipped]. My question is this, paper <a href=\"http://www2.research.att.com/~volinsky/papers/ieeecomputer.pdf\" rel=\"nofollow noreferrer\">here</a> (<a href=\"http://web.archive.org/web/20150318161041/http://www2.research.att.com/~volinsky/papers/ieeecomputer.pdf\" rel=\"nofollow noreferrer\">Wayback Machein</a>) states square error function above non-convex because of <span class=\"math-container\">$q_i^Tp_u$</span> and both variables here are unknown which, of course, is correct. Then how do we guarantee stochastic gradient descent scheme described in all papers will find a global minimum? I read somewhere SGD can be used to solve non-convex functions, I'd like to hear about some details on how. SGD SVD method described in the links works well in practice. </p>\n\n<p>Also, alternating least squares can be applied to solve the SVD problem described above according to IEEE Koren paper. This method alternates between holding one or the other variable constant thereby creating convex problems in the process. I wonder if SGD, while it goes through dimensions, data points one-by-one also, in a way, creates convex sub-problems as it proceeds. </p>\n\n<p>Maybe the answer is simply this <a href=\"http://www.cs.nyu.edu/~yann/talks/lecun-20071207-nonconvex.pdf\" rel=\"nofollow noreferrer\">presentation</a> by LeCun, stochastic gradient on non-convex functions have no theoretical guarantees, but this doesn't mean we should not use them. \"When Empirical Evidence suggests a fact for which we don't have \ntheoretical guarantees, it just means the theory is inadequate\". </p>\n", "pids": ["5ead65439fced0a24bb87ec9"], "flag": 0}
{"question": "Is there an example that a theorem in number theory is useful in another field in mathematics?", "body": "<p>I know there are two advanced approaches to number theory. That is, algebraic number theory and analytic number theory. I have heard that algebraic geometry, which generally seems completely different from number theory, is now known to be a very strong tool to attack number theory.</p>\n\n<p>But what about converse?</p>\n\n<p>Is there any other fields in mathematics in which number theory makes them easier? Is there any theorem in number theory which is helpful to other fields in mathematics?</p>\n", "pids": ["53e9a660b7602d9702f92b3b"], "flag": 0}
{"question": "Calculate variance explained by each predictor in multiple regression using R", "body": "<p>I have run a multiple regression in which the model as a whole is significant and explains about 13% of the variance. However, I need to find the amount of variance explained by each significant predictor. How can I do this using R?</p>\n\n<p>Here's some sample data and code:</p>\n\n<pre><code>D = data.frame(\n    dv = c( 0.75, 1.00, 1.00, 0.75, 0.50, 0.75, 1.00, 1.00, 0.75, 0.50 ),\n    iv1 = c( 0.75, 1.00, 1.00, 0.75, 0.75, 1.00, 0.50, 0.50, 0.75, 0.25 ),\n    iv2 = c( 0.882, 0.867, 0.900, 0.333, 0.875, 0.500, 0.882, 0.875, 0.778, 0.867 ),\n    iv3 = c( 1.000, 0.067, 1.000, 0.933, 0.875, 0.500, 0.588, 0.875, 1.000, 0.467 ),\n    iv4 = c( 0.889, 1.000, 0.905, 0.938, 0.833, 0.882, 0.444, 0.588, 0.895, 0.812 ),\n    iv5 = c( 18, 16, 21, 16, 18, 17, 18, 17, 19, 16 ) )\nfit = lm( dv ~ iv1 + iv2 + iv3 + iv4 + iv5, data=D )\nsummary( fit )\n</code></pre>\n\n<p>Here's the output with my actual data:</p>\n\n<pre><code>Call: lm(formula = posttestScore ~ pretestScore + probCategorySame + \n    probDataRelated + practiceAccuracy + practiceNumTrials, data = D)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.6881 -0.1185  0.0516  0.1359  0.3690 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)\n (Intercept)        0.77364    0.10603    7.30  8.5e-13 ***\n iv1                0.29267    0.03091    9.47  &lt; 2e-16 ***\n iv2                0.06354    0.02456    2.59   0.0099 **\n iv3                0.00553    0.02637    0.21   0.8340\n iv4               -0.02642    0.06505   -0.41   0.6847\n iv5               -0.00941    0.00501   -1.88   0.0607 .  \n--- Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.18 on 665 degrees of freedom\n Multiple R-squared:  0.13,      Adjusted R-squared:  0.123\n F-statistic: 19.8 on 5 and 665 DF,  p-value: &lt;2e-16\n</code></pre>\n\n<p>This question has been answered <a href=\"https://stats.stackexchange.com/questions/60872/how-to-split-r-squared-between-predictor-variables-in-multiple-regression\">here</a>, but the accepted answer only addresses uncorrelated predictors, and while there is an additional response that addresses correlated predictors, it only provides a general hint, not a specific solution. I would like to know what to do if my predictors are correlated.</p>\n", "pids": ["53e9bc10b7602d97048738d5"], "flag": 1}
{"question": "Mathematical Notation and its importance", "body": "<p>You can see how mathematical notation evolved during the last centuries <a href=\"http://www.prandiano.com.br/html/fr_arq.htm\">here</a>.</p>\n\n<p>I think everyone here knows that a bad notation can change an otherwise elementar problem into a difficult problem. Just try to do basic arithmetics with roman numbers, for example.</p>\n\n<p>As a computer programmer I know that in some situations programming language notation plays a critical rule because some algorithms are better expressed in a particular language than in other languages even considering they all have the same basis: Lambda Calculus, Turing machines, etc</p>\n\n<p>The linguists has their so-called <a href=\"http://en.wikipedia.org/wiki/Sapir%E2%80%93Whorf_hypothesis\">Sapir–Whorf hypothesis</a> which \"...holds that the structure of a language affects the ways in which its respective speakers conceptualize their world, i.e. their world view, or otherwise influences their cognitive processes.\"</p>\n\n<p>Then, I ask: is there any field in Math that studies Math's notation and its influence for good or for bad in Math itself?</p>\n\n<p>Modifying the fragment on the paragraph above:\nis it possible that the notation, the symbols and the language used in Math affects the ways in which Mathematicians conceptualize their world and influences their cognitive processes?</p>\n", "pids": ["53e9b331b7602d9703e05742"], "flag": 0}
{"question": "The Gaussian moat problem and its extension to other rings in $\\mathbb{C}$, $\\mathbb{H}$ and $\\mathbb{O}$", "body": "<p>One of my favourite open problems in number theory, an area in which I enjoy only as a hobbyist, is the Gaussian moat problem, namely </p>\n\n<p>\"Is it possible to walk to infinity in $\\mathbb{C}$, taking steps of bounded length, using the Gaussian primes as stepping stones?\"</p>\n\n<p>We can easily show that one cannot accomplish walking to infinity using steps of bounded length on the real line using primes in $\\mathbb{R}$. For an arbitrary natural number $k$, consider the $k-1$ consecutive numbers </p>\n\n<p>$$\nk! + 2, k! + 3, \\ldots k! + k,\n$$\nall of which are composite. This is another way of saying there are arbitrarily large gaps in the primes. </p>\n\n<p>For the Gaussian primes, there is computational proof that a moat of length $\\sqrt{26}$ exists, so one cannot walk to infinity using steps of length $5$. Erdos is said to have conjectured that it is impossible to complete the walk. Percolation theory also suggests that the walk is impossible, though to my understanding this heuristic assumes the primes are completely independent in some way. </p>\n\n<p>Eisenstein integers are numbers of the form $a+b\\omega$, with $a$, $b \\in \\mathbb{R}$, where $\\omega = \\mathrm{e}^{\\mathrm{i}\\pi/3}$. My first and main question is -</p>\n\n<blockquote>\n  <p><strong>What is the current lower bound for step size in the analogous problem for Eisenstein primes?</strong></p>\n</blockquote>\n\n<p>Quaternions with all integer components are called Lipshitz integers. So let us call primes over this ring Lipshitz primes. A Lipshitz integer is only a Lipshitz prime if its norm is a prime. Is anything known about the moat problem over $\\mathbb{H}$? One might think that given the extra dimensions or degrees of freedom walking to infinity should be easier, however I'm not sure how rare Lipshitz primes are. </p>\n\n<p><a href=\"https://mathoverflow.net/q/30765/43361\">Responses to this post</a> point out that factorisation over octonions is not unique, so it is difficult to come up with a concept of primes over $\\mathbb{O}$.</p>\n", "pids": ["56d84312dabfae2eee980330"], "flag": 0}
{"question": "Elastic/ridge/lasso analysis, what then?", "body": "<p>I'm getting really interested in the elastic net procedure for predictor shrinkage/selection. It seems very powerful.</p>\n\n<p>But from the scientific point of view I don't know well what to do once I got the coefficients. What question am I answering? These are the variables that most influence that outcome and these are the coefficients which give the best variance/bias ratio during validation? </p>\n\n<p>This is of course a very descriptive/predictive approach compared to the classical p value/confidence intervals approach. Inferential estimation is being studied now by Tibshirani &amp; Co. but is still experimental.</p>\n\n<p>Some people are using the variables chosen by elastic net to perform classical inferential analysis, but that would eliminate the limitation in variance brought by the technique.</p>\n\n<p>Another problem is that since lambda and alpha parameters for elastic net are chosen by cross validation they are subject to random variability. So every time you run (eg.) cv.glmnet() you will select a slightly different subset of predictors with always different coefficients.</p>\n\n<p>I though about solving this considering the right lambda and alpha as random variables and re run the cross validation step n times to get a distribution of these parameters.\nThis way for every predictor I would have the number of occurrences and for every coefficients I would have distribution of results. \nThis should give me more generalizable results with ranges statistics (like sd of the coefficients).\nIt would also be interesting to see whether the lambda and the alpha picked this way approximate to some distribution asymptotically, since that would open up the way for some inference test (but I'm not a statistician so I should not speak about things I don't fully understand).</p>\n\n<p>So finally my question is: Once you get the predictors and the coefficients from an elastic net with cross validation based alpha and lambda, which and how should you present these results? How should you discuss them? what did we learn? Which hypothesis/generalization are we confuting?</p>\n", "pids": ["5d9edbbd47c8f76646025bb4", "56d8b38adabfae2eeef595c2", "56d88e06dabfae2eeecfc25a", "55839133e4b046969cdab95e", "5c756999f56def97982b3acc"], "flag": 1}
{"question": "How few training examples is too few when training a neural network?", "body": "<p>I'm a beginner trying to put together my first project. I had a song classification project in mind, but since I would be manually labeling, I could only reasonably put together about 1000 songs, or 60 hours of music. </p>\n\n<p>I would be classifying with several classes, so it's possible that one class would have as few as 50-100 songs in the training set- this seems like too few! Is there a general rule of thumb for how much data is needed to train a neural network to give it a shot at working?</p>\n\n<p>Edit: I was thinking of using a vanilla LSTM. The input features will have dimension 39, output dimension 6, my first attempt for hidden layer dimension would be 100. </p>\n", "pids": ["57a4e918ac44365e35c974f0"], "flag": 1}
{"question": "What are the theoretical guarantees of bagging", "body": "<p>I've (approximately) heard that:</p>\n\n<blockquote>\n  <p>bagging is a technique to reduce the variance of an predictor/estimator/learning algorithm.</p>\n</blockquote>\n\n<p>However, I have never seen a formal mathematical proof of this statement. Does anyone know why this is mathematically true? It just seems to be such a widely accepted/known fact, that I'd expect a direct reference to this. I'd be surprised if there is non. Also, does anyone know what effect this has on the bias?</p>\n\n<p>Are there any other theoretical guarantees of approaches bagging that anyone knows and thinks is important and wants to share it?</p>\n", "pids": ["53e99d3eb7602d97025f507b"], "flag": 1}
{"question": "Challenge: Demonstrate a Contradiction in Leibniz&#39; differential notation", "body": "<p>I want to know if the Leibniz differential notation actually leads to contradictions - I am starting to think it does not.</p>\n\n<p>And just to eliminate the most commonly showcased 'difficulty':</p>\n\n<p>For the level curve $f(x,y)=0$ in the plane we have $$\\frac{dy}{dx}=-\\frac{\\dfrac{\\partial f}{\\partial x}}{\\dfrac{\\partial f}{\\partial y}}$$ If we were to \"cancel\" the differentials we would incorrectly derive $\\frac{dy}{dx}=-\\frac{dy}{dx}$. Why does this not work? Simple: The \"$\\partial f$\" in the numerator is a response to the change in $x$, whereas the \"$\\partial f$\" in the denominator is a response to the change in $y$. They are different numbers, and so cannot be cancelled. </p>\n\n<p>Related: consult the <a href=\"https://math.stackexchange.com/questions/726950/how-is-it-that-treating-leibniz-notation-as-a-fraction-is-fundamentally-incorrec\">answer to this previous question.</a></p>\n\n\n\n<p><em>The other part has been moved to a new post <a href=\"https://math.stackexchange.com/questions/783681/the-meaning-of-differentials-in-integration\">here</a>.</em></p>\n", "pids": ["56d82a23dabfae2eeef6f94a", "56d82a23dabfae2eeef6f94a"], "flag": 0}
{"question": "Why is LASSO not finding my perfect predictor pair at high dimensionality?", "body": "<p>I'm running a small experiment with LASSO regression in R to test if it is able to find a perfect predictor pair. The pair is defined like this: f1 + f2 = outcome</p>\n\n<p>The outcome here is a predetermined vector called 'age'. F1 and f2 are created by taking half of the age vector and setting the rest of the values to 0, for example: age = [1,2,3,4,5,6], f1 = [1,2,3,0,0,0] and f2 = [0,0,0,4,5,6].\nI combine this predictor pair with an increasing amount of randomly created variables by sampling from a normal distribution N(1,1).</p>\n\n<p>What I see is when I hit 2^16 variables, LASSO is not finding my pair anymore. See the results below.</p>\n\n<p><a href=\"https://i.stack.imgur.com/eZhk9.png\"><a src=\"https://i.stack.imgur.com/eZhk9.png\" alt=\"Number of features per fold per data size\"></a><a href=\"https://i.stack.imgur.com/2Nt5P.png\"><a src=\"https://i.stack.imgur.com/2Nt5P.png\" alt=\"Coefficients of the perfect pair\"></a></p>\n\n<p>Why is this happening? You can reproduce the results with the script below. I've noticed that when I pick a different age vector, e.g: [1:193] then LASSO does find the pair at high dimensionality (>2^16).</p>\n\n<p>The Script:</p>\n\n<pre><code>## Setup ##\nlibrary(glmnet)\nlibrary(doParallel)\nlibrary(caret)\n\nmae &lt;- function(errors){MAE &lt;- mean(abs(errors));return(MAE)}\nseed = 1\nn_start &lt;- 2 #start at 2^n features\nn_end &lt;- 16 #finish with 2^n features\ncl &lt;- makeCluster(3)\nregisterDoParallel(cores=cl)\n\n#storage of data\nfeatures &lt;- list()\ncoefs &lt;- list()\nL &lt;- list() \nP &lt;- list() \nC &lt;- list() \nRSS &lt;- list() \n\n## MAIN ##\nfor (j in n_start:n_end){\n  set.seed(seed)\n  age &lt;- c(55,31,49,47,68,69,53,42,58,67,60,58,32,52,63,31,51,53,37,48,31,58,36,42,61,49,51,45,61,57,52,60,62,41,28,45,39,47,70,33,37,38,32,24,66,54,59,63,53,42,25,56,70,67,44,33,50,55,60,50,29,51,49,69,70,36,53,56,32,43,39,43,20,62,46,65,62,65,43,40,64,61,54,68,55,37,59,54,54,26,68,51,45,34,52,57,51,66,22,64,47,45,31,47,38,31,37,58,66,66,54,56,27,40,59,63,64,27,57,32,63,32,67,38,45,53,38,50,46,59,29,41,33,40,33,69,42,55,36,44,33,61,43,46,67,47,69,65,56,34,68,20,64,41,20,65,52,60,39,50,67,49,65,52,56,48,57,38,48,48,62,48,70,55,66,58,42,62,60,69,37,50,44,61,28,64,36,68,57,59,63,46,36)\n  beta2 &lt;- as.data.frame(cbind(age,replicate(2^(j),rnorm(length(age),1,1))));colnames(beta2)[1] &lt;-'age'\n\n  f1 &lt;- c(age[1:96],rep(0,97)) \n  f2 &lt;- c(rep(0,96),age[97:193])\n  beta2 &lt;- as.data.frame(cbind(beta2,f1,f2))\n\n  #storage variables\n  L[[j]] &lt;- vector()\n  P[[j]] &lt;- vector()\n  C[[j]] &lt;- list()\n  RSS[[j]] &lt;- vector()\n\n  #### DCV LASSO ####\n  set.seed(seed) #make folds same over 10 iterations\n  for (i in 1:10){\n\n    print(paste(j,i))\n    index &lt;- createFolds(age,k=10)\n    t.train &lt;- beta2[-index[[i]],];row.names(t.train) &lt;- NULL\n    t.test &lt;- beta2[index[[i]],];row.names(t.test) &lt;- NULL\n\n    L[[j]][i] &lt;- cv.glmnet(x=as.matrix(t.train[,-1]),y=as.matrix(t.train[,1]),parallel = T,alpha=1)$lambda.min #,lambda=seq(0,10,0.1)\n    model &lt;- glmnet(x=as.matrix(t.train[,-1]),y=as.matrix(t.train[,1]),lambda=L[[j]][i],alpha=1)\n    C[[j]][[i]] &lt;- coef(model)[,1][coef(model)[,1] != 0]\n    pred &lt;- predict(model,as.matrix(t.test[,-1]))\n    RSS[[j]][i] &lt;- sum((pred - t.test$age)^2)\n    P[[j]][i] &lt;- mae(t.test$age - pred)\n    gc()\n  }\n}\n\n##############\n## PLOTTING ##\n##############\n\n#calculate plots features\nbeta_sum = unlist(lapply(unlist(C,recursive = F),function(x){sum(abs(x[-1]))}))\npenalty = unlist(L) * beta_sum\nRSS = unlist(RSS)\npair_coefs &lt;- unlist(lapply(unlist(C,recursive = F),function(x){\n  if('f1' %in% names(x)){f1 = x['f1']}else{f1=0;names(f1)='f1'}\n  if('f2' %in% names(x)){f2 = x['f2']}else{f2=0;names(f2)='f2'}\n  return(c(f1,f2))}));pair_coefs &lt;- split(pair_coefs,c('f1','f2'))\ninout &lt;- lapply(unlist(C,recursive = F),function(x){c('f1','f2') %in% names(x)})\ncolors &lt;- unlist(lapply(inout,function(x){if (x[1]*x[2]){'green'}else{'red'}}))\nfeatlength &lt;- unlist(lapply(unlist(C,recursive = F),function(x){length(x)-1}))\n\n#diagnostics\nplot(rep(n_start:n_end,each=10),pair_coefs$f1,col='red',xaxt = \"n\",xlab='n/o randomly generated features (log2)',main='Pair Coefficients',ylim=c(0,1),ylab='pair coefficients');axis(1, at=n_start:n_end);points(rep(n_start:n_end,each=10),pair_coefs$f2,col='blue');axis(1, at=n_start:n_end, labels=(n_start:n_end));legend('bottomleft',fill=c('red','blue'),legend = c('f1','f2'),inset=.02)\nplot(rep(n_start:n_end,each=10),RSS+penalty,col=colors,xaxt = \"n\",xlab='n/o randomly generated features (log2)',main='RSS+penalty');axis(1, at=n_start:n_end, labels=(n_start:n_end));legend('topleft',fill=c('green','red'),legend = c('Pair Selected','Pair not Selected'),inset=.02)\nplot(rep(n_start:n_end,each=10),penalty,col=colors,xaxt = \"n\",xlab='n/o randomly generated features (log2)',main='Penalty');axis(1, at=n_start:n_end, labels=(n_start:n_end));legend('topleft',fill=c('green','red'),legend = c('Pair Selected','Pair not Selected'),inset=.02)\nplot(rep(n_start:n_end,each=10),RSS,col=colors,xaxt = \"n\",xlab='n/o randomly generated features (log2)',main='RSS');axis(1, at=n_start:n_end, labels=(n_start:n_end));legend('topleft',fill=c('green','red'),legend = c('Pair Selected','Pair not Selected'),inset=.02)\nplot(rep(n_start:n_end,each=10),unlist(L),col=colors,xaxt = \"n\",xlab='n/o randomly generated features (log2)',main='Lambdas',ylab=expression(paste(lambda)));axis(1, at=n_start:n_end, labels=(n_start:n_end));legend('topleft',fill=c('green','red'),legend = c('Pair Selected','Pair not Selected'),inset=.02)\nplot(rep(n_start:n_end,each=10),featlength,ylab='n/o features per fold',col=colors,xaxt = \"n\",xlab='n/o randomly generated features (log2)',main='Features per Fold');axis(1, at=n_start:n_end, labels=(n_start:n_end));legend('topleft',fill=c('green','red'),legend = c('Pair Selected','Pair not Selected'),inset=.02)\nplot(penalty,RSS,col=colors,main='Penalty vs. RSS')\n</code></pre>\n", "pids": ["5d9edc3b47c8f76646037c61"], "flag": 1}
{"question": "Why does Q-learning overestimate action values?", "body": "<p>I'm having difficulty finding any explanation as to why standard Q-learning tends to overestimate q-values (which is addressed by using double Q-learning). The only sources I have found don't really explain exactly why this overestimation occurs.</p>\n\n<p>For example, the Wikipedia article on Q-learning says:</p>\n\n<blockquote>\n  <p>Because the maximum approximated action value is used in the Q-learning update, in noisy environments Q-learning can sometimes overestimate the actions values, slowing the learning.</p>\n</blockquote>\n\n<p>What does this mean? I understand Q-learning, but not the above. Why does the use of the maximum q-value cause overestimation?</p>\n\n<p>Thanks!</p>\n", "pids": ["53e9bb7ab7602d97047bb048"], "flag": 1}
{"question": "Avoid overfitting in regression: alternatives to regularization", "body": "<p>Regularization in regression (linear, logistic...) is the most popular way to reduce over-fitting.</p>\n\n<p>When the goal is prediction accuracy (not explaining), are there any good alternatives to regularization, especially suited for big data-sets (mi/billions of observations and millions of features)?</p>\n", "pids": ["56d83b97dabfae2eee6291d1"], "flag": 1}
{"question": "Data Augmentation strategies for Time Series Forecasting", "body": "<p>I'm considering two strategies to do \"data augmentation\" on time-series forecasting.</p>\n\n<p>First, a little bit of background. A predictor <span class=\"math-container\">$P$</span> to forecast the next step of a time-series <span class=\"math-container\">$\\lbrace A_i\\rbrace$</span> is a function that typically depends on two things, the time-series past states, but also the predictor's past states:</p>\n\n<p><span class=\"math-container\">$$P(\\lbrace A_{i\\leq t-1}\\rbrace,P_{S_{t-1}})$$</span></p>\n\n<p>If we want to adjust/train our system to obtain a good <span class=\"math-container\">$P$</span>, then we'll need enough data. Sometimes available data won't be enough, so we consider doing data augmentation.</p>\n\n<p><strong>First approach</strong></p>\n\n<p>Suppose we have the time-series <span class=\"math-container\">$\\lbrace A_i \\rbrace$</span>, with <span class=\"math-container\">$1 \\leq i \\leq n$</span>. And suppose also that we have <span class=\"math-container\">$\\epsilon$</span> that meets the following condition: <span class=\"math-container\">$0&lt;\\epsilon &lt; |A_{i+1} - A_i| \\forall i \\in \\lbrace 1, \\ldots,n\\rbrace$</span>.</p>\n\n<p>We can construct a new time series <span class=\"math-container\">$\\lbrace B_i = A_i+r_i\\rbrace$</span>, where <span class=\"math-container\">$r_i$</span> is a realization of the distribution <span class=\"math-container\">$N(0,\\frac{\\epsilon}{2}) $</span>.</p>\n\n<p>Then, instead of minimizing the loss function only over <span class=\"math-container\">$\\lbrace A_i \\rbrace$</span>, we do that also over <span class=\"math-container\">$\\lbrace B_i \\rbrace$</span>. So, if the optimization process takes <span class=\"math-container\">$m$</span> steps, we have to \"initialize\" the predictor <span class=\"math-container\">$2m$</span> times, and we'll compute approximately <span class=\"math-container\">$2m(n-1)$</span> predictor internal states.</p>\n\n<p><strong>Second approach</strong></p>\n\n<p>We compute <span class=\"math-container\">$\\lbrace B_i \\rbrace$</span> as before, but we don't update the predictor's internal state using <span class=\"math-container\">$\\lbrace B_i \\rbrace$</span>, but <span class=\"math-container\">$\\lbrace A_i \\rbrace$</span>. We only use the two series together at the time of computing the loss function, so we'll compute approximately <span class=\"math-container\">$m(n-1)$</span> predictor internal states.</p>\n\n<p>Of course, there is less computational work here (although the algorithm is a little bit uglier), but it does not matter for now.</p>\n\n<p><strong>The doubt</strong></p>\n\n<p>The problem is: from a statistical point of view, which is the the \"best\" option? And why?</p>\n\n<p>My intuition tells me that the first one is better, because it helps to \"regularize\" the weights related with the internal state, while the second one only helps to regularize the weights related with the observed time-series' past.</p>\n\n\n\n<p><strong>Extra:</strong></p>\n\n<ul>\n<li>Any other ideas to do data augmentation for time series forecasting?</li>\n<li>How to weight the synthetic data in the training set?</li>\n</ul>\n", "pids": ["58d82fc8d649053542fd5a35"], "flag": 1}
{"question": "Is every self-homeomorphism homotopic to a diffeomorphism?", "body": "<p>Given a smooth manifold $M$, is every homeomorphism $M \\to M$ homotopic to a diffeomorphism? </p>\n\n<p>Hirsch's \"Differential Topology\" has a proof that every $C^1$ diffeomorphism of smooth manifolds is homotopic to a $C^\\infty$ one, but as far as I can tell, says nothing about the case of $C^0$ automorphisms.</p>\n\n<p>If false in general, is the above claim true in dimensions at most $3$? (If somehow false because of exotic smooth structures - is it true for topological manifolds supporting only one smooth structure?)</p>\n", "pids": ["56d81916dabfae2eee86e522"], "flag": 0}
{"question": "Infinite prisoners with hats -- is choice really needed?", "body": "<p>The problem is <a href=\"https://en.wikipedia.org/wiki/Prisoners_and_hats_puzzle#Countably_Infinite-Hat_Variant_without_Hearing\" rel=\"nofollow noreferrer\">this</a> (recently asked about <a href=\"https://math.stackexchange.com/questions/1032928/prisoners-problem\">here</a>):</p>\n\n<blockquote>\n  <p>A countably infinite number of prisoners, each with an unknown and randomly assigned red or blue hat line up single file line. Each prisoner faces away from the beginning of the line, and each prisoner can see all the hats in front of him, and none of the hats behind. Starting from the beginning of the line, each prisoner must correctly identify the color of his hat or he is killed on the spot. The prisoners have a chance to meet and confer beforehand, but once in line, no prisoner can hear what the other prisoners say. The question is, is there a way to ensure that only finitely many prisoners are killed?</p>\n</blockquote>\n\n<p>The standard solution depends on the Axiom of Choice, as discussed in <a href=\"https://math.stackexchange.com/questions/340725/why-does-the-infinite-prisoners-and-hats-puzzle-require-the-axiom-of-choice\">this previous question</a>.</p>\n\n<p>However, the previous question only explains that <em>that</em> particular strategy requires the Axiom of Choice. It still seems at least conceivable that there could be a completely different strategy that works and doesn't need Choice.</p>\n\n<p><strong>Thus:</strong> Is it known to be consistent with ZF that there is no strategy for the prisoners?</p>\n\n<p>(Bonus question: If \"yes\", then is this also true in the variant where the prisoners can hear the answers of lower-numbered prisoners?)</p>\n", "pids": ["62b3e7b45aee126c0ff5bde9", "53e9b03db7602d9703a9da48"], "flag": 0}
{"question": "Number of ways to connect sets of $k$ dots in a perfect $n$-gon", "body": "<p>Let <span class=\"math-container\">$Q(n,k)$</span> be the number of ways in which we can connect sets of <span class=\"math-container\">$k$</span> vertices in a given perfect <span class=\"math-container\">$n$</span>-gon such that no two lines intersect at the <strong>interior</strong> of the <span class=\"math-container\">$n$</span>-gon and no vertex remains isolated.</p>\n<p>Intersection of the lines <strong>outside</strong> the <span class=\"math-container\">$n$</span>-gon is acceptable. Obviously, <span class=\"math-container\">$k|n$</span>, and <span class=\"math-container\">$n$</span> <em>can't</em> be prime because otherwise there will be dots left unconnected. The <span class=\"math-container\">$n$</span>-gon itself is an acceptable solution to a connection of <span class=\"math-container\">$n$</span> vertices, and in the case of <span class=\"math-container\">$k&gt;2$</span>, these aren't lines, but a set of connected lines, a sort of a network formed by connected planar graphs with straight edges with <span class=\"math-container\">$k$</span> vertices, which are required to be vertices of the <span class=\"math-container\">$n$</span>-gon itself.</p>\n<p>There must always be <span class=\"math-container\">$S =\\frac nk$</span> sets of lines. For <span class=\"math-container\">$k=2$</span>, there are exactly <span class=\"math-container\">$\\frac nk$</span> lines, and for <span class=\"math-container\">$k&gt;2$</span>, there are exactly <span class=\"math-container\">$\\frac nk$</span>, not lines but sets of such connected planar graphs.</p>\n<p>Take for example <span class=\"math-container\">$Q(6,2)$</span>. We have a perfect hexagon. By brute-forcing with pencil and paper, I found that there are 5 ways to connect sets of 2 vertices (dots) such that no two lines intersect inside the hexagon. Hence, <span class=\"math-container\">$Q(6,2) = 5$</span>.</p>\n<p>The following image depicts the case of <span class=\"math-container\">$Q(6,2)$</span>:</p>\n<p><a src=\"https://i.stack.imgur.com/kemWb.png\" alt=\"Q(6,2)\" /></p>\n<p>I know for sure that an elegant solution exists for <span class=\"math-container\">$k=2$</span>, but I can't figure it out. For generality I ask about any amount of <span class=\"math-container\">$k$</span> dots.</p>\n<p>It's also extremely important to note we're not dividing the <span class=\"math-container\">$n$</span>-gon into <span class=\"math-container\">$k$</span>-gons, but connecting paths between <span class=\"math-container\">$k$</span> nodes/vertices/dots.</p>\n<h3>Now let's move one step further:</h3>\n<p>Let <span class=\"math-container\">$U(n,k)$</span> be the number of <strong>unique</strong> ways to connect sets of <span class=\"math-container\">$k$</span> dots in a perfect <span class=\"math-container\">$n$</span>-gon, such that no two lines intersect, and <strong>rotational symmetry</strong> is neglected, i.e, every possible arrangement is unique and can't be formed by rotating or flipping another arrangement in any way. <span class=\"math-container\">$U(6,2)=2$</span>.\nNote that <span class=\"math-container\">$U(6,2)=2$</span> because the arrangements of the first line in the image are not unique, and can be formed by rotating one another. The same happens for the second line of arrangements. This results in only 1 unique arrangement for each line. Hence <span class=\"math-container\">$U(6,2)=2$</span>.</p>\n<p>I'm pretty clueless about both functions <span class=\"math-container\">$U$</span> and <span class=\"math-container\">$Q$</span>, and I couldn't derive an algorithm or formula to any of them. Hence I'm posting this here.</p>\n<p>I'm pretty sure there's a pure combinatorial approach to this problem, perhaps involving Polya's Enumeration Theorem (PET). Is there an elegant solution to these functions? Can they even be solved for <span class=\"math-container\">$k&gt;2$</span>?</p>\n<p>Any light shed on any of the functions will be very much appreciable, as I haven't been successful in deriving a formula for any of them.</p>\n<h3>EDIT - Temporary Solutions + Relevant questions AND progress</h3>\n<p><span class=\"math-container\">$$Q(n,2) = C_{n \\over 2}\\quad\\text{where}\\quad C_n = \\frac{1}{n+1} {2n\\choose n}$$</span>\nAnd <span class=\"math-container\">$C_n$</span> denotes the <span class=\"math-container\">$n$</span>'th <strong>Catalan</strong> number.</p>\n<p>Now let us denote <span class=\"math-container\">$W(n) = U(n,2)$</span>. Can you find a formula for <span class=\"math-container\">$W(n)$</span>? Perhaps a connection between <span class=\"math-container\">$Q(n,2)$</span> and <span class=\"math-container\">$W(n)$</span>?</p>\n<p><strong>Another EDIT: (2)</strong></p>\n<p><span class=\"math-container\">$$Q(k,k) = k\\cdot 2^{k-3}$$</span></p>\n<p><strong>EDIT 3</strong></p>\n<p>It seems like in general, <span class=\"math-container\">$Q(n,3)$</span> is given here:\n<a href=\"https://oeis.org/search?q=3%2C27%2C324&amp;sort=&amp;language=english&amp;go=Search\" rel=\"nofollow noreferrer\">https://oeis.org/search?q=3%2C27%2C324&amp;sort=&amp;language=english&amp;go=Search</a></p>\n<p>Perhaps generalization to higher powers will result in the general <span class=\"math-container\">$Q(n,k)$</span> function..</p>\n<p><strong>EDIT 4</strong></p>\n<p>Here is a small table of values for <span class=\"math-container\">$Q(n,k)$</span>, which seems to be correct, provided by <strong>fabian</strong>'s algorithm:\n(Table is in the form <span class=\"math-container\">$Q(x\\cdot k,k)$</span>)</p>\n<p><span class=\"math-container\">$$\n\\begin{array}{c|rrrrr}\n{_k\\,\\backslash\\, ^n} &amp; k &amp; 2k &amp; 3k &amp; 4k &amp; 5k \\\\\n\\hline\n2 &amp; 1  &amp; 2     &amp; 5       &amp; 14         &amp; 42\\\\\n3 &amp; 3  &amp; 27    &amp; 324     &amp; 4455       &amp; 66339\\\\\n4 &amp; 8  &amp; 256   &amp; 11264   &amp; 573440     &amp; 31752192\\\\\n5 &amp; 20 &amp; 2000  &amp; 280000  &amp; 45600000   &amp; 8096000000\\\\\n6 &amp; 48 &amp; 13824 &amp; 5640192 &amp; 2686058496 &amp; 1396580548608\\\\\n\\end{array}\n$$</span></p>\n<p><strong>EDIT 5 - <span class=\"math-container\">$Q(n,k)$</span> <em>SOLVED</em></strong></p>\n<p>As beautifully found and explained by <strong>@CuddlyCuttlefish</strong> in his answer, the formula for <span class=\"math-container\">$Q(n,k)$</span> is as follows:\n<span class=\"math-container\">$$Q(n,k) = \\frac{(n)_{\\frac{n}{k}-1}}{\\left(\\frac{n}{k}\\right)!}\\cdot (k\\cdot 2^{k-3})^{\\frac{n}{k}} \\quad\\text{where}\\quad (n)_j = n(n-1)...(n-(j-1))$$</span></p>\n<p>And <span class=\"math-container\">$(n)_j$</span> is the <strong>falling factorial</strong>, defined as above.</p>\n<h2>Now moving to <span class=\"math-container\">$U(n,k)$</span></h2>\n<p>Now it only remains to find a formula or an algorithm for <span class=\"math-container\">$U(n,k)$</span>.\nPersonally I think it has to do with <strong>Polya's Enumeration Theorem</strong> and <strong>Burnside's lemma</strong>, combined with the <strong>cycle-index of the symmetric group</strong>, <span class=\"math-container\">$Z(S_n)$</span>. I've touched upon something related to that, and thus I think it's related. I'm not 100% sure but my instincts tell me it's related.</p>\n<p><strong>EDIT 6</strong></p>\n<p>In order to make it clear, I'm hereby adding a picture to describe the case of <span class=\"math-container\">$U(6,3)$</span> and by that to clarify better what <span class=\"math-container\">$U(n,k)$</span> means.</p>\n<p><a src=\"https://i.stack.imgur.com/O5HVR.png\" alt=\"enter image description here\" /></p>\n<p><span class=\"math-container\">$U(6,3)=4$</span>, as shown in the picture above (@<strong>Marko Riedel</strong> has pointed out an additional arrangement which I had previously missed). There are four <strong>unique</strong> arrangements to connect sets of 3 vertices such that <strong>no vertice remains isolated, no lines intersect at the interior of the hexagon, and each arrangement is unique and can't be formed by rotating or flipping any other arrangement.</strong></p>\n<p>There are two unique <strong>path-types</strong>, one that is introduced by connecting 3 adjacent vertices (<span class=\"math-container\">$p_1$</span>), and another that connects 2 vertices with a little <strong>&quot;jump&quot;,</strong> and the third vertice is then adjacent (<span class=\"math-container\">$p_2$</span>).</p>\n<p>Hope it makes things a bit clearer..</p>\n<p><strong>EDIT 7</strong></p>\n<p>As provided by @<strong>Marko Riedel's</strong> algorithm, <span class=\"math-container\">$U(n,3)$</span> sequence starts as follows:</p>\n<p><span class=\"math-container\">$$1, 4, 22, 201, 2244, 29096, 404064, 5915838,\\ldots$$</span></p>\n<p>Computation was very rough, and calculation times were long. That's about as efficient as it gets, as of now. Producing more values just consumes either too much memory, time or both. Refer to <strong>Marko Riedel's</strong> answers for more sequences and further explanations. Also if anybody can verify the above it would be great.</p>\n", "pids": ["53e9bbeab7602d9704841234"], "flag": 1}
{"question": "Without the Axiom of Choice, does every infinite field contain a countably infinite subfield?", "body": "<p>Earlier today I <a href=\"https://math.stackexchange.com/questions/1517718/does-every-infinite-field-contain-a-countably-infinite-subfield\">asked whether every infinite field contains a countably infinite subfield.</a> That question quickly received several positive answers, but the question of whether those answers use the Axiom of Choice has spawned off an interesting discussion in its own right. Thus I'd like to pose that question separately:</p>\n\n<blockquote>\n  <p>Without using the Axiom of Choice, can it be shown that every infinite field contains a countably infinite subfield?</p>\n</blockquote>\n\n<p>Note that <a href=\"https://math.stackexchange.com/questions/1396676/is-axiom-of-choice-necessary-for-proving-that-every-infinite-set-has-a-countably\">the corresponding question for sets has a negative answer,</a> but since fields have so much more structure than sets, it is not <em>a priori</em> unreasonable to me that there might exist an AC-less resolution for fields.</p>\n\n\n\n<p><strong>EDIT:</strong> For the purposes of this question, an infinite set is one that is not bijective with $\\{1, \\dots, n\\}$ for any $n \\in \\Bbb N$. Thanks to @MartinSleziak for bringing this issue up in chat.</p>\n", "pids": ["53e99813b7602d970202d11f"], "flag": 0}
{"question": "Is CEO the &quot;profession&quot; with the most psychopaths?", "body": "<p>An <a href=\"http://time.com/32647/which-professions-have-the-most-psychopaths-the-fewest/\" rel=\"nofollow noreferrer\">opinion article in <em>Time</em></a> has this subheading:</p>\n\n<blockquote>\n  <p>CEO is the profession with the most psychopaths.</p>\n</blockquote>\n\n<p>This may have been added by a <a href=\"https://en.wikipedia.org/wiki/Headline\" rel=\"nofollow noreferrer\">headline</a> editor though, because the article body doesn't flesh out the fact that well, besides this (ordered?) list</p>\n\n<p><a href=\"https://i.stack.imgur.com/mM1T7.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/mM1T7.png\" alt=\"Via The Wisdom of Psychopaths: What Saints, Spies, and Serial Killers Can Teach Us About Success: + Psychopathy: 1. CEO 2. Lawyer 3. Media (TV/Radio) 4. Salesperson 5. Surgeon 6. Journalist 7. Police Officer 8. Clergyperson 9. Chef 10. Civil Servant // - Psychopathy: 1. Care Aide 2. Nurse 3. Therapist 4. Craftsperson 5. Beautician/Stylist 6. Charity Worker 7. Teacher 8. Creative Artist 9. Doctor 10. Accountant\"></a></p>\n\n<p>It's not impossible that the book cited may have made that claim too though (I didn't check.) </p>\n\n<p>Is there high quality empirical evidence to back up this claim that CEOs have the most (or at least a large number) of psychopaths compared to other occupations? </p>\n\n<p>(I do note that <em>Time</em> marked the article as opinion, perhaps to distance itself from the claims therein. Nevertheless, the claim in question is stated as a bare fact therein.)</p>\n", "pids": ["5c756684f56def97980d9866", "56d9249fdabfae2eeeb34e66", "56d9249edabfae2eeeb349a7", "56d82521dabfae2eeed77d55", "55a46feb65ce31bc877a9ed1", "53e99946b7602d9702186bf8", "55a6827065ce054aad6a0a3a", "55a3f6402401c6de3b7befc7", "55a682dd65ce054aad6a24c4"], "flag": 1}
{"question": "What does &quot;variational&quot; mean?", "body": "<p>Does the use of \"variational\" always refer to optimization via variational inference?</p>\n\n<p>Examples:</p>\n\n<ul>\n<li>\"Variational auto-encoder\"</li>\n<li>\"Variational Bayesian methods\"</li>\n<li>\"Variational renormalization group\"</li>\n</ul>\n", "pids": ["5a260c8617c44a4ba8a31cb3"], "flag": 1}
{"question": "What *is* an Artificial Neural Network?", "body": "<p>As we delve into <a href=\"https://en.wikipedia.org/wiki/Artificial_neural_network\" rel=\"noreferrer\">Neural Networks</a> literature, we get to identify other methods with neuromorphic topologies (\"Neural-Network\"-like architectures). And I'm not talking about the <a href=\"https://en.wikipedia.org/wiki/Universal_approximation_theorem\" rel=\"noreferrer\">Universal Approximation Theorem</a>. Examples are given below.</p>\n\n<p>Then, it makes me wonder: what is the definition of an artificial Neural Network? Its topology appears to cover everything.</p>\n\n\n\n<h2>Examples:</h2>\n\n<p>One of the first identifications we make is between PCA and a linear Autoencoder with tied-weights in the encoder and decoder and thresholded activations in the bottleneck layer.</p>\n\n<p>Also, a common identification is done between linear models (logistic regression in special) and a Neural Network with no hidden layer and a single output layer. This identification opens several doors.</p>\n\n<p><a href=\"https://www.quora.com/How-are-neural-networks-related-to-Fourier-transforms\" rel=\"noreferrer\">Fourier and Taylor series? ANNs</a>. <a href=\"https://en.wikipedia.org/wiki/Support_vector_machine\" rel=\"noreferrer\">SVM</a>? ANN. Gaussian Process? ANN (with single hidden layer with infinite hidden units).</p>\n\n<p>And so, just as easily, we can incorporate arbitrary regularized versions with specialized loss functions of these algorithms into a Neural Network framework.</p>\n\n<p>But the more we dig, the more similarities appear. I just stumbled into <a href=\"https://arxiv.org/abs/1806.06988\" rel=\"noreferrer\">Deep Neural Decision Trees</a>, which makes the identification of a specific ANN architecture with decision trees, allowing these to be learned by ANN methods (such as Gradient Descent backpropagation). From this we can construct Random Forests and Gradient Boosted Decision Trees from solely Neural Network topologies.</p>\n\n<p>If everything can be expressed as an Artificial Neural Network, what defines an Artificial Neural Network?</p>\n", "pids": ["53e9b068b7602d9703acf032"], "flag": 1}
{"question": "What is the opposite category of $\\operatorname{Top}$?", "body": "<p>My question is rather imprecise and open to modification. I am not entirely sure what I am looking for but the question seemed interesting enough to ask: </p>\n\n<p>The opposite category of rings is the category of affine schemes. This is usually thought of as the category of spaces. Can we run the construction backwards for categories usually thought of as containing spaces?</p>\n\n<p>For instance, does $\\operatorname{Top}^{\\operatorname{op}}$ have a nice description as some \"algebraic\" category?</p>\n\n<p>Note that it does not seem easy to describe the opposite category of all schemes. Therefore, the above question might be asking too much. Perhaps the following is a more tractable (or not) question:</p>\n\n<p>Can we find an \"algebraic\" category $C$ such that we can embed $C^{\\operatorname{op}}$ in $\\operatorname{Top}$ such that every topological space can be covered by objects in $C^{\\operatorname{op}}$? Perhaps one would like to replace this criterion of being covered by objects by a more robust notion in general.</p>\n\n<p>One can repeat the question for other categories of spaces like:</p>\n\n<ul>\n<li>Category of manifolds (perhaps closer to schemes than general topological spaces)</li>\n<li>Compactly generated spaces</li>\n<li>Simplicial Sets</li>\n</ul>\n\n<p>and so on. A perhaps interesting example is the category of finite sets, it's opposite category is the category of finite Boolean algebras.</p>\n", "pids": ["60d40ae191e0112ca5d1882e"], "flag": 0}
{"question": "Why is best subset selection not favored in comparison to lasso?", "body": "<p>I'm reading about best subset selection in the Elements of statistical learning book. \nIf I have 3 predictors $x_1,x_2,x_3$, I create $2^3=8$ subsets:</p>\n\n<ol>\n<li>Subset with no predictors</li>\n<li>subset with predictor $x_1$</li>\n<li>subset with predictor $x_2$</li>\n<li>subset with predictor $x_3$</li>\n<li>subset with predictors $x_1,x_2$</li>\n<li>subset with predictors $x_1,x_3$</li>\n<li>subset with predictors $x_2,x_3$</li>\n<li>subset with predictors $x_1,x_2,x_3$</li>\n</ol>\n\n<p>Then I test all these models on the test data to choose the best one.</p>\n\n<blockquote>\n  <p>Now my question is why is best subset selection not favored in\n  comparison to e.g. lasso?</p>\n</blockquote>\n\n<p>If I compare the thresholding functions of best subset and lasso, I see that the best subset sets some of the coefficients to zero, like lasso.\nBut, the other coefficient (non-zero ones) will still have the ols values, they will be unbiasd. Whereas, in lasso some of the coefficients will be zero and the others (non-zero ones) will have some bias. \nThe figure below shows it better: \n<a href=\"https://i.stack.imgur.com/tGah6.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/tGah6.png\" alt=\"enter image description here\"></a></p>\n\n<p>From the picture the part of the red line in the best subset case is laying onto the gray one. The other part is laying in the x-axis where some of the coefficients are zero. The gray line defines the unbiased solutions. In lasso, some bias is introduced by $\\lambda$. From this figure I see that best subset is better than lasso! What are the disadvantages of using best subset? </p>\n", "pids": ["5c610930da56297340b67c3a", "5c75705cf56def97986e5d98", "57e0987c0cf2ca636f027cfa"], "flag": 1}
{"question": "Encoding of categorical variables with high cardinality", "body": "<p>For <strong>unsupervised anomaly detection / fraud analytics</strong> on credit card data (where I don't have labeled fraudulent cases), there are a lot of variables to consider. The data is of mixed type with continuous/numerical variables (e.g. USD amount spent) as well as <strong>categorical variables</strong> (e.g. account number).</p>\n\n<p>What is the most suitable way of including categorical variables that have a very large number of unique classes? My thoughts so far:</p>\n\n<ul>\n<li><strong>Label Encoding</strong> (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\" rel=\"noreferrer\">scikit-learn</a>): i.e. mapping integers to classes. While it returns a nice single encoded feature column, it imposes a false sense of ordinal relationship (e.g. 135 > 72).</li>\n<li><strong>One Hot / Dummy Encoding</strong> (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\" rel=\"noreferrer\">scikit-learn</a>): i.e. expanding the categorical feature into lots of dummy columns taking values in {0,1}. This is infeasible for categorical features having e.g. >10,000 unique values. I understand that models will struggle with the sparse and large data.</li>\n</ul>\n\n<p>What <strong>other (more advanced?)</strong> suitable methods are there to include large categorical feature columns? Is it possible to still use One Hot Encoding with some tricks? I read about bin counting (<a href=\"https://blogs.technet.microsoft.com/machinelearning/2015/02/17/big-learning-made-easy-with-counts/\" rel=\"noreferrer\">Microsoft blog</a>) though I haven't found any applications related to intrusion detection / fraud analytics.</p>\n\n<p>P.S.: In my view, this problem seems very similar to encoding an IP-address feature column when dealing with unsupervised intrusion detection.</p>\n", "pids": ["60b5921e91e011f95a64971c"], "flag": 1}
{"question": "Can an instrumental variable equation be written as a directed acyclic graph (DAG)?", "body": "<p>Directed acyclic graphs (DAGs) are efficient visual representations of qualitative causal assumptions in statistical models, but can they be used to present a regular instrumental variable equation (or other equations)? If so, how? If not, why?</p>\n", "pids": ["5d3044533a55ac92aa14c740", "53e99800b7602d9702010925"], "flag": 1}
{"question": "RNN vs Kalman filter : learning the underlying dynamics?", "body": "<p>Being recently interested in Kalman filters and Recurrent neural networks, it appears to me that the two are closely related, yet I can't find relevant enough litterature :</p>\n\n<p>In a Kalman filter, the set of equations is :\n<span class=\"math-container\">$$x_{k} = Ax_{k-1} + Bu_{k} + w_{k-1}$$</span>\n<span class=\"math-container\">$$ z_k  = Hx_k + v_k$$</span></p>\n\n<p>with <span class=\"math-container\">$x$</span> the state and <span class=\"math-container\">$z$</span> the measurement.</p>\n\n<p>In an Elman RNN (from <a href=\"https://en.wikipedia.org/wiki/Recurrent_neural_network\" rel=\"noreferrer\">here</a>), the relation between the layers is:\n<span class=\"math-container\">$$h_{k} = \\sigma_h (Uh_{k-1} + Wx_{k} + b)$$</span>\n<span class=\"math-container\">$$ y_k  = \\sigma_y (Vh_k + c)$$</span></p>\n\n<p>with <span class=\"math-container\">$x$</span> the input layer, <span class=\"math-container\">$h$</span> the hidden layer and <span class=\"math-container\">$y$</span> the output layer and <span class=\"math-container\">$\\sigma$</span> are the activation functions for the layers.  </p>\n\n<p>It's clear that the two set of equations are the same, modulo the activations. The analogy here seems to be the following. The output layer corresponds to the measured state, the hidden layer is the true state, driven by a process <span class=\"math-container\">$x$</span> which is the input layer. </p>\n\n<ul>\n<li><p>First question : is the analogy viable ? And how can we interpret the activations ?</p></li>\n<li><p>Second question : in a Kalman filter the <span class=\"math-container\">$A$</span> matrix is that of the underlying dynamics of the state <span class=\"math-container\">$x$</span>. Since training a RNN allows to learn the <span class=\"math-container\">$W$</span> matrices, are RNN able to learn the dynamics of the underlying state ? Ie once my RNN is trained, can I look at the coefficients of my network to guess the dynamics behind my data ?</p></li>\n</ul>\n\n<p>(I'm going to try to do the experiment on artificially generated data, to see if this works, and will update as soon as it's done)</p>\n\n<p>EDIT : I wish I had access to <a href=\"https://ieeexplore.ieee.org/document/227334\" rel=\"noreferrer\">this paper</a></p>\n", "pids": ["60f928515244ab9dcb5694bd"], "flag": 1}
{"question": "Three questions about the article &quot;Ditch p-values. Use Bootstrap confidence intervals instead&quot;", "body": "<p>I am not a statistician by training and I was asked by students to explain them an article called <a href=\"https://www.r-bloggers.com/2021/11/ditch-p-values-use-bootstrap-confidence-intervals-instead/?fbclid=IwAR0EydDLDH3dL5XMyayZ2LQRzWMSQe9jYTpqOelX4lgo15pyGXjr8sozAIk\" rel=\"noreferrer\">&quot;Ditch p-values. Use Bootstrap confidence intervals instead&quot;</a> . The author seems a prominent academic, however, I am confused about some of the material there. Please, ignore this post if it seems too long for you. I cut it to just 3 questions, I will infer other answers based on these.</p>\n<blockquote>\n<p>Let’s take a simplified but revealing example: we want to determine Robert’s citizenship. Null hypothesis: H0, Robert is a US citizen. Alternative hypothesis: H1, he is not. Our data: we know that Robert is a US senator. There are 100 senators out of 330 million US citizens, so under the null hypothesis, the probability of our data (i.e., the p-value) is 100 / 300,000,000 ≈ 0.000000303. Per the rules of statistical significance, we can safely conclude that our null hypothesis is rejected and Robert is not a US citizen.</p>\n</blockquote>\n<p>Am I right that this is not a p-value (which is the probability to see this or more extreme value of a test statistic)? Is it a correct procedure for a statistical testing? I have a gut feeling that it is a wrong situation to apply hypothesis testing, but I can not formally answer why.</p>\n<blockquote>\n<p>P-values were invented at a time when all calculations had to be done by hand, and so they rely on simplifying statistical assumption. Broadly speaking, they assume that the phenomenon you’re observing obeys some regular statistical distribution</p>\n</blockquote>\n<p>It seems to be wrong, but the question is: can we say that non-parametric tests also rely on some regular statistical distributions? Not only they have assumptions, but also, technically, their statistics also follow some distributions.</p>\n<blockquote>\n<p>Let’s say that a business decision-maker is pondering two possible actions, A and B. Based on observed data, the probability of zero or negative benefits is:</p>\n<p>0.08 for action A</p>\n<p>0.001 for action B</p>\n<p>Should the decision-maker pick action B based on these numbers? What if I told you that the corresponding 90%\nconfidence intervals are:</p>\n<p>[-0.5m; 99.5m] for action A [0.1m; 0.2m] for action B Action B may\nhave a lower probability of leading to a zero or negative outcome, but\nits expected value for the business is much lower, unless the business\nis incredibly risk-averse.</p>\n</blockquote>\n<p>Can we, based on confidence intervals, say, what is an expected value? Is in this situation a clear decision? I always thought that confidence intervals are not necessarily symmetric, but I started to doubt here.</p>\n", "pids": ["5eba73be91e01108d77cf7ac", "619b54c51c45e57ce9b07ff5"], "flag": 1}
{"question": "Blind quantum computing — generic structure variable selection", "body": "<h2>Background</h2>\n\n<p>Recently I came upon a research article entitled <a href=\"https://arxiv.org/pdf/1110.1381.pdf\" rel=\"noreferrer\">Experimental Demonstration of Blind Quantum Computing</a>. Within this research article, the scientists claimed that - through the proper choice of a generic structure - a data engineer can hide the information about how the data was calculated.</p>\n\n<h2>Question</h2>\n\n<p>If a scientist were to use a BQC <em>(Blind Quantum Computation)</em> protocol to calculate private measurements, what types of variables would they have to use to formulate a generic structure for the blind quantum state?</p>\n\n<h2>Thoughts</h2>\n\n<p>I would like to understand what types of variables could go into the generic structure in order to help keep the data calculations hidden from the server. If you select certain known generic variables, I do not understand why the selection of other known generic variables would prevent the data calculations from being hidden.</p>\n", "pids": ["55a90cd7240153a85d6fbd11", "53e9a26bb7602d9702b74bf4"], "flag": 1}
{"question": "Do Hausdorff spaces that aren&#39;t completely regular appear in practice?", "body": "<p>Completely regular spaces include all metrizable spaces, topological vector spaces, and topological groups in general. In fact, they are exactly the <a href=\"https://en.wikipedia.org/wiki/Uniformizable_space\" rel=\"noreferrer\">uniformizable spaces</a>.\nComplete regularity is hereditary, ie. a subspace of a completely regular space is also completely regular, and it's preserved by arbitrary products. The completely regular spaces are in fact a reflective subcategory of $\\mathrm{Top}$, as can be seen from another characterization: they are exactly the spaces for which the real functions determine the topology, ie. the topology is the initial topology for the set of real continuous functions.\nFinally, every subspace of a compact Hausdorff space is completely regular, and conversely, every ($T_0$) completely regular space embeds universally into a compact Hausdorff space via the Stone-Čech compactification.</p>\n\n<p>There are of course many natural examples of topologies that aren't completely regular. The two that I know of are Zariski topology, which is $T_1$, but not Hausdorff, and <a href=\"https://en.wikipedia.org/wiki/Alexandrov_topology\" rel=\"noreferrer\">Alexandrov topology</a>, which is a natural topology on a poset that can't even be $T_1$ in an interesting way.</p>\n\n<p>What I haven't seen before are examples of Hausdorff topologies that aren't completely regular, and weren't constructed specifically for the purpose of being a counterexample. Considering how widely topology is applied (and how little I know of it) I'm assuming there are some, and I'd be interested in hearing how often they appear. </p>\n\n<p>The strengthening of this question to normal spaces seems to have elementary and satisfactory answers: the topology of pointwise convergence on $\\mathbb R$ isn't normal (witnessing the fact that normal spaces aren't closed under products).</p>\n", "pids": ["56d89480dabfae2eee034645", "5c77d71a4895d9cbc6591d34"], "flag": 0}
{"question": "Why is Functional Data Analysis (FDA) not as popular?", "body": "<p>I am interested in FDA (data perceived as functions), as someone from a pure mathematics background and I think it can help provide solutions to some major challenges in data analysis (also data science), compared to the ordinary perspective in which data is perceived, as vectors. However, I have not found so much literature about it on the web. Could someone help me understand why this is so? Also, where can I get some good reads in FDA?</p>\n", "pids": ["5de0d637df1a9c0c415ba2ee"], "flag": 1}
{"question": "Why does the Akaike Information Criterion (AIC) sometimes favor an overfitted model?", "body": "<p>As an exercise to develop practical experience working with <a href=\"https://en.wikipedia.org/wiki/Model_selection#Criteria\" rel=\"nofollow noreferrer\">model selection criteria</a>, I computed fits of the highway mpg vs. engine displacement data from the tidyverse <a href=\"https://ggplot2.tidyverse.org/reference/mpg.html\" rel=\"nofollow noreferrer\">mpg example data set</a> using <a href=\"https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/poly\" rel=\"nofollow noreferrer\">polynomial</a> and <a href=\"https://www.rdocumentation.org/packages/splines/versions/3.6.2/topics/bs\" rel=\"nofollow noreferrer\">B-spline</a> models of increasing parametric complexity ranging from 3 to 19 degrees of freedom (note that the <code>degree</code> or <code>df</code> number in either model family counts the number of additional fitted coefficients <em>besides</em> the intercept).</p>\n<p>The results of the fitting procedure are shown in the plot below.  The blue line shows the predicted regression result across an evenly spaced set of engine displacement values along the range of the input data set, while the orange-red points show the result at the values within the original data set that were actually used to derive the fit:</p>\n<p><a href=\"https://i.stack.imgur.com/VTDe0.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/VTDe0.png\" alt=\"Fitted polynomial and B-spline models with tidyverse mpg example data\" /></a></p>\n<p>Starting at around ~11 degrees of freedom, the blue lines (which are most visible where there were no observations within the input data set) begin to exhibit classic signs of overfitting: they wiggle and gyrate wildly, varying much more widely than the input data itself, indeed in some cases extending down into the non-phyiscal region (i.e., dipping down into negative mpg, which has no physical interpretation).  Moreover, the two model classes (polynomial vs. B-spline) exhibit randomness in the locations of these dips and wiggles.  An additional plot below shows the differences between the two model families vs. increasing number of model parameters.  For simpler models with fewer parameters, the difference is uniformly small, usually &lt; 1-2 mpg across the entire range of the data set, while for models with more parameters the difference is large, and generally becomes more divergent as the number of parameters increases:</p>\n<p><a href=\"https://i.stack.imgur.com/AXTPN.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/AXTPN.png\" alt=\"Differences (polynomial - B-spline) between models with increasing numbers of parameters fitted to tidyverse mpg data set\" /></a></p>\n<p>Based upon the apparent overfitting that I can see with higher numbers of fitted model parameters, I would expect most model selection criteria to choose an optimal model as having &lt; 10 fitted coefficients.  However, I extracted the Akaike Information Criterion (AIC) values returned with each of the fitted models, and that's not actually what happens in this case.  Instead, the most complex models with the largest number of fitted parameters exhibit the smallest AIC values, and are therefore favored by AIC:</p>\n<p><a href=\"https://i.stack.imgur.com/b2Iyc.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/b2Iyc.png\" alt=\"Akaike Information Criterion (AIC) for models with increasing numbers of parameters\" /></a></p>\n<p><strong>Edit:</strong> based upon another contributor's reply, I've modified the above plot to show both AICc as well as AIC.  As expected, using AICc instead of AIC results in a correction which is indeed larger for models with a greater number of parameters, but not nearly large enough to make any difference in the final outcome:</p>\n<p><a href=\"https://i.stack.imgur.com/QjmJE.png\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/QjmJE.png\" alt=\"Akaike Information Criterion (AIC and AICc) for models with increasing numbers of parameters\" /></a></p>\n<p><strong>My question:</strong> what is happening here?  Why does AIC give a counterintuitive result, apparently favoring overfitted models?  And is there any well-established alternative criteria that might be expected to work better in this case, selecting a less complicated model that does not exhibit such obvious overfitting?</p>\n<p>For reference, the code that produces these plots is here (<strong>edit:</strong> updated to produce version 2 of the AIC vs. input degrees of freedom plot):</p>\n<pre class=\"lang-r prettyprint-override\"><code>library(tidyverse)\nlibrary(splines)\nlibrary(AICcmodavg)\n\n# ---- Part 1: Fit various models to data and plot results \n\n# Select degrees of freedom (i.e., number of coefficients, \n# not counting\n# the intercept coefficient) for polynomial or B-spline models\ndflo &lt;- 3\ndfhi &lt;- 19\ninputdf &lt;- seq(dflo,dfhi,2)\nndf &lt;- length(inputdf)\ndflist &lt;- as.list(inputdf)\nnames(dflist) &lt;- sprintf(&quot;%2d&quot;, inputdf)\n\n# Fit all of the models, and save the fit objects \n# to a nested list\n# (outer list level: model family (poly or spline),\n#  inner list level: dof)\nfitobj &lt;- list()\nfitobj<span class=\"math-container\">$poly &lt;- map(dflist, ~lm(formula=hwy~poly(displ, \n                   degree=.), data=mpg))\nfitobj$</span>bspl &lt;- map(dflist, ~lm(formula=hwy~bs(displ, df=.), \n                   data=mpg))\n\n# Make a list of data points at which to predict the \n#fitted models (grid:\n# evenly spaced 1D series of points ranging from minimum engine \n# displacement\n# in the original data set to maximum engine displacement, \n# orig: the input\n# data set itself)\nngrid &lt;- 200\ndval &lt;- list()\ndval<span class=\"math-container\">$grid &lt;- data.frame(displ=seq(min(mpg$</span>displ), max(mpg<span class=\"math-container\">$displ),  \n                              length.out=ngrid))\ndval$</span>orig &lt;- data.frame(displ=mpg$displ)\n\n# Key elements for a new list\nmtype &lt;- list(&quot;poly&quot;=&quot;poly&quot;, &quot;bspl&quot;=&quot;spline&quot;)\ndtype &lt;- list(&quot;grid&quot;=&quot;Evenly spaced grid&quot;, \n              &quot;orig&quot;=&quot;Original values&quot;)\n\n# For both models (poly and spline), and both sets of prediction points (grid\n# and original), predict all the models, and dump all of the results to a list \n# of data frames, keyed by the cross product of the 2 pairs of input keys\npred &lt;- list()\nfor(mkey in c(&quot;poly&quot;, &quot;bspl&quot;)) {\n    for(dkey in c(&quot;grid&quot;, &quot;orig&quot;)) {\n        crosskey &lt;- paste(mkey, dkey, sep=&quot;_&quot;)\n        pred[[crosskey]] &lt;- map_dfr(map(fitobj[[mkey]], \n                                        predict.lm,\n                                        newdata=dval[[dkey]],\n                                        interval=&quot;confidence&quot;),\n                                    as_tibble, .id=&quot;inputdf&quot;) %&gt;%\n                            bind_cols(displ=rep(dval[[dkey]]$displ, ndf),\n                                      modeltype=mtype[[mkey]],\n                                      prediction_points=dtype[[dkey]])\n    }\n}\n# Reorganize the list of data frames into a single giant unified data frame\ndfpred &lt;- map_dfr(pred, bind_rows) %&gt;%\n          mutate(modelspec=paste(inputdf, modeltype, sep=&quot; &quot;))\n\n# Plot all of the fitted models. Evenly spaced 1D grid \n# is shown as a blue\n# line, the original data points from the parent data set are \n# orange-red\n# dots superimposed on top of it.  Gray ribbons are confidence \n# intervals \n# produced by predict.lm in previous step above.\nplt_overview &lt;- ggplot() +\n                geom_ribbon(aes(x=displ, ymin=lwr, ymax=upr), \n                            data=dfpred,\n                            fill=&quot;grey70&quot;) +\n                geom_point(aes(x=displ, y=hwy), data=mpg, \n                size=1.5) +\n                geom_line(aes(x=displ, y=fit, \n                color=prediction_points),\n                          data=filter(dfpred, \n                          prediction_points==dtype<span class=\"math-container\">$grid),\n                      size=2) +\n            geom_point(aes(x=displ, y=fit, \n                       color=prediction_points),\n                       data=filter(dfpred, \n                       prediction_points==dtype$</span>orig),\n                           size=3) +\n                scale_color_manual(breaks=dtype, \n                values=c(&quot;blue&quot;, &quot;tomato&quot;)) +\n                xlab(&quot;Engine Displacment (liters)&quot;) +\n                ylab(&quot;Highway Miles Per Gallon (mpg)&quot;) +\n                coord_cartesian(ylim=c(0,50)) +\n                facet_wrap(~modelspec, ncol=4) +\n                theme(text=element_text(size=32),\n                      legend.position=&quot;bottom&quot;)\npng(filename=&quot;fit_overview.png&quot;, width=1200, height=1600)\nprint(plt_overview)\ndev.off()\n\n# ---- Part 2: Plot differences between poly / spline model families ----\n\n# For each input degree of freedom, calculate the difference between the\n# poly and B-spline model fits, at both the grid and original set of \n# prediction points\ndfdiff &lt;- bind_cols(filter(dfpred, modeltype==&quot;poly&quot;) %&gt;%\n                      select(inputdf, displ, fit, prediction_points) %&gt;%\n                      rename(fit_poly=fit),\n                    filter(dfpred, modeltype==&quot;spline&quot;) %&gt;%\n                      select(fit) %&gt;%\n                      rename(fit_bspl=fit)) %&gt;%\n          mutate(fit_diff=fit_poly-fit_bspl)\n\n# Plot differences between two model families\nplt_diff &lt;- ggplot(mapping=aes(x=displ, y=fit_diff, color=prediction_points)) +\n            geom_line(data=filter(dfdiff, prediction_points==dtype<span class=\"math-container\">$grid),\n                  size=2) +\n        geom_point(data=filter(dfdiff, prediction_points==dtype$</span>orig),\n                       size=3) +\n            scale_color_manual(breaks=dtype, values=c(&quot;blue&quot;, &quot;tomato&quot;)) +\n            xlab(&quot;Engine Displacment (liters)&quot;) +\n            ylab(&quot;Difference (Poly - B-Spline) of Fit Results (mpg)&quot;) +\n            coord_cartesian(ylim=c(-10,10)) +\n            facet_wrap(~inputdf, ncol=4) +\n            theme(text=element_text(size=32),\n                  legend.position=&quot;bottom&quot;)\npng(filename=&quot;fit_diff.png&quot;, width=1200, height=800)\nprint(plt_diff)\ndev.off()\n\n# ---- Part 3: Plot Akaike Information Criterion (AIC) for all models ----\n\n# Compute both AIC and AICc for both model families (polynomial and B-spline)\n# and organize the result into a single unified data frame\nsord &lt;- list(&quot;AIC&quot;=FALSE, &quot;AICc&quot;=TRUE)\naictbl &lt;- map(sord,\n              function(so) map(fitobj,\n                               function(fo) map(fo, AICc, second.ord=so) %&gt;%\n                                 unlist())) %&gt;%\n          map_dfr(function(md) map_dfr(md, enframe,\n                                       .id=&quot;mt&quot;), .id=&quot;aictype&quot;) %&gt;%\n          mutate(modeltype=unlist(mtype[mt]),\n                 inputdf=as.numeric(name)) %&gt;%\n          rename(aic=value) %&gt;%\n          select(inputdf, aic, modeltype, aictype)\n\n# Plot AIC\nplt_aic &lt;- ggplot(aictbl, aes(x=inputdf, y=aic, color=aictype)) +\n           geom_line() +\n           geom_point(size=3) +\n           xlab(&quot;Input Degrees of Freedom&quot;) +\n           ylab(&quot;Akaike Information Criterion (AIC)&quot;) +\n           labs(color=&quot;AIC Correction Type&quot;) +\n           facet_wrap(~modeltype, ncol=1) +\n           theme(text=element_text(size=32),\n                 legend.position=&quot;bottom&quot;)\npng(filename=&quot;aic_vs_inputdf.png&quot;, width=800, height=800)\nprint(plt_aic)\ndev.off()\n</code></pre>\n", "pids": ["53e99eb5b7602d97027823a4"], "flag": 1}
{"question": "How does topological quantum computing differ from other models of quantum computing?", "body": "<p>I've heard the term <a href=\"https://en.wikipedia.org/wiki/Topological_quantum_computer\" rel=\"noreferrer\">Topological Quantum Computer</a> a few times now and know that it is equivalent to quantum computers using circuits with respect to some polynomial-time reduction.</p>\n\n<p>However, it is totally unclear to me how such a quantum computer differs from others, how it works, and what its strengths are.</p>\n\n<p>In short: how is a <em>topological quantum computer</em> different than other models, such as gate-based quantum computers and what are the specific use cases for that it is better suited than other models?</p>\n", "pids": ["53e9b1f8b7602d9703c8df94", "53e9ab2cb7602d97034b9b54", "5f0c2f8a9fced0a24ba7e78c", "5c866e074895d9cbc65bd51e"], "flag": 1}
{"question": "What are some good blogs for Mathematical Statistics and Machine Learning?", "body": "<p>I am looking for  blogs that focus on the mathematical theory of Statistics and Machine Learning, ideally at a research or &quot;advanced&quot; level.</p>\n<p>The blog doesn't have to be solely about these topics but ideally most of the posts would be exposing the mathematical theory of an idea/concept/algorithm that is either directly or closely related to them. Here is an example of what I'm looking for, and I will add another one as an answer (<strong>Disclaimer : I have no affiliation with any of the authors of the blogs I link</strong>):</p>\n<ul>\n<li><a href=\"http://gregorygundersen.com/blog/\" rel=\"noreferrer\">Gregory Gundersen's blog</a> neatly presents the theory of many well-known (and some lesser-known) algorithms and results in Statistics, such as Conjugate Gradient Descent, Ordinary Least Squares, Hidden Markov Models... Some of the posts contain illustration with available source code</li>\n</ul>\n<p>Please limit your answer to less than 2-3 links and provide a short description for each blog, as above.</p>\n", "pids": ["608a7d6891e011b76ccd5513"], "flag": 1}
{"question": "How to measure in another basis", "body": "<p>I am new to qiskit and I have to simulate a quantum circuit. I read this documentation <a href=\"https://qiskit.org/textbook/ch-states/single-qubit-gates.html\" rel=\"noreferrer\">https://qiskit.org/textbook/ch-states/single-qubit-gates.html</a> where it is left as an exercise to the reader to write a function to measure in the <span class=\"math-container\">$|+i\\rangle$</span> and <span class=\"math-container\">$|-i\\rangle$</span> or the y-basis. I want to know if I've done it correctly or not.</p>\n<p>I need to measure a state in the y-basis after preparing it in an equal superposition the <span class=\"math-container\">$|0\\rangle$</span> and <span class=\"math-container\">$|1\\rangle$</span> states. To do this, I first applied the Hadamard gate which does the first part and takes the <span class=\"math-container\">$|0\\rangle$</span> state to the <span class=\"math-container\">$|+\\rangle$</span> state. Now comes the measurement part. To do this I applied an <span class=\"math-container\">$S^\\dagger$</span> and then the <span class=\"math-container\">$H$</span> gate again.</p>\n<p>Now I simply measure the state</p>\n<pre><code>def Y_measurement(qc,qubit,cbit):\n    qc.sdg(qubit)\n    qc.h(qubit)\n    qc.measure(qubit,cbit)\n    return qc\n\ncircuit = QuantumCircuit(1,1)\ncircuit.h(0)\ncircuit.barrier()\n\n\nY_measurement(circuit, 0, 0)\n\ncircuit.draw(output='mpl') \n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/xrfQn.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/xrfQn.png\" alt=\"enter image description here\" /></a></p>\n<p>Is this correct?</p>\n", "pids": ["5aed14d617c44a4438159318"], "flag": 1}
{"question": "How to tune smoothing in mgcv GAM model", "body": "<p>I am trying to figure out how to control the smoothing parameters in an <code>mgcv::gam</code> model.</p>\n<p>I have a binomial variable I am trying to model as primarily a function of x and y coordinates on a fixed grid, plus some other variables with more minor influences.  In the past I have constructed a reasonably good local regression model using package <code>locfit</code> and just the (x,y) values.</p>\n<p>However, I want to try incorporating the other variables into the model, and it looked like generalized additive models (GAM) were a good possibility.  After looking at packages gam and mgcv, both of which have a GAM function, I opted for the latter since a number of comments in mailing list threads seem to recommend it.  One downside is that it doesn't seem to support a local regression smoother like loess or locfit.</p>\n<p>To start, I just wanted to try to replicate approximately the locfit model, using just (x,y) coordinates.  I tried with both regular and tensor product smooths:</p>\n<pre class=\"lang-r prettyprint-override\"><code>my.gam.te &lt;- gam(z ~ te(x, y), \n      family=binomial(logit), data=my.data, \n      scale = -1)  \n\nmy.gam.s  &lt;- gam(z ~  s(x, y), \n      family=binomial(logit), data=my.data, \n      scale = -1)\n</code></pre>\n<p>However, plotting the predictions from the model, they are much much more smoothed compared to the locfit model.  So I've been trying to tune the model to not oversmooth as much.  I've tried adjusting the parameters sp and k, but it's not clear to me how they affect the smoothing.  In locfit, the nn parameter controls the span of the neighborhood used, with smaller values allowing for less smoothing and more &quot;wiggling&quot;, which helps to capture some areas on the grid where the probability of the binomial outcomes changes rapidly.  How would I go about setting up the gam model to enable it to behave similarly?</p>\n", "pids": ["56d8d87ddabfae2eeedcad47"], "flag": 1}
{"question": "Groups with given automorphism groups", "body": "<p>It is an easy exercise to show that all finite groups with at least three elements have at least one non-trivial automorphism; in other words, there are - up to isomorphism - only finitely many finite groups $G$ such that $Aut(G)=1$ (to be exact, just two: $1$ and $C_2$).</p>\n\n<p>Is an analogous statement true for all finite groups? I.e., given a finite group $A$, are there - again up to isomorphism - only finitely many groups $G$ with $Aut(G)\\cong A$?</p>\n\n<p>If yes, is there an upper bound on the number of such groups $G$ depending on a property of $A$ (e.g. its order)?</p>\n\n<p>And if not, which groups arise as counterexamples?</p>\n\n<p>And finally, what does the situation look like for infinite groups $G$ with a given finite automorphism group? And what if infinite automorphism groups $A$ are considered?</p>\n", "pids": ["53e99f35b7602d970280436e", "656f5f78939a5f40821548da"], "flag": 0}
{"question": "In practice how is the random effects covariance matrix calculated in a mixed effects model?", "body": "<p>Basically what I'm wondering is how different covariance structures are enforced, and how the values inside these matrices are calculated. Functions like lme() allow us to chose which structure we'd like, but I'd love to know how they are estimated.</p>\n\n<p>Consider the linear mixed effects model $Y=X\\beta+Zu+\\epsilon$.</p>\n\n<p>Where $u \\stackrel{d}{\\sim} N(0,D)$ and $\\epsilon \\stackrel{d}{\\sim} N(0,R)$.  Furthermore:</p>\n\n<p>$Var(Y|X,Z,\\beta,u)=R$</p>\n\n<p>$Var(Y|X,\\beta)=Z&#39;DZ+R=V$</p>\n\n<p>For simplicity we'll assume $R=\\sigma^2I_n$.</p>\n\n<p>Basically my question is: How exactly is $D$ estimated from the data for the various parameterizations?\nSay if we assume $D$ is diagonal (random effects are independent) or $D$ fully parameterized (case I'm more interested in at the moment) or any of the various other parameterizations? Are there simple estimators/equations for these? (That would no doubt be iteratively estimated.)</p>\n\n<p><strong>EDIT:</strong>\nFrom the book Variance Components (Searle, Casella, McCulloch 2006) I've managed to gleam the following:</p>\n\n<p>If $D=\\sigma^2_uI_q$ then then the variance components are updated and calculated as follows:</p>\n\n<p>$\\sigma_u^{2(k+1)} = \\frac{\\hat{\\textbf{u}}^T\\hat{\\textbf{u}}} {\\sigma_u^{2(k)}\\text{trace}(\\textbf{V}^{-1}\\textbf{Z}^T\\textbf{Z})}$</p>\n\n<p>$\\sigma_e^{2(k+1)} = Y&#39;(Y-X{\\hat{\\beta}}^{(k)}-{Z}\\hat{{u}}^{(k)})/n$</p>\n\n<p>Where $\\hat{\\beta}^{(k)}$ and $\\hat{{u}}^{(k)}$ are the $k$th updates respectively.</p>\n\n<p>Is there general formulas when $D$ is block diagonal or fully parameterized? I'm guessing in the fully parameterized case, a Cholesky decomposition is used to ensure positive definiteness and symmetry.</p>\n", "pids": ["53e9b267b7602d9703d09f37"], "flag": 1}
{"question": "How to do estimation, when only summary statistics are available?", "body": "<p>This is in part motivated by the following <a href=\"https://stats.stackexchange.com/questions/37569/lognormal-distribution-from-world-bank-quintiles-ppp-data\">question</a> and the discussion following it. </p>\n\n<p>Suppose the iid sample is observed, $X_i\\sim F(x,\\theta)$. The goal is to estimate $\\theta$. But original sample is not available. What we have instead are some statistics of the sample $T_1,...,T_k$. Suppose $k$ is fixed. How do we estimate $\\theta$? What would be maximum likelihood estimator in this case?</p>\n", "pids": ["56d897cfdabfae2eee1df80e"], "flag": 1}
{"question": "A &quot;countable Zorn&#39;s lemma&quot;?", "body": "<p>Is there something like a \"countable Zorn's lemma\" which is equivalent to the axiom of countable choice?</p>\n", "pids": ["56d878d1dabfae2eee2c0cf4"], "flag": 0}
{"question": "Does caffeine actually enhance cognition?", "body": "<p>I have heard, respectively:</p>\n\n<ul>\n<li>Caffeine measurably enhances cognitive function.</li>\n<li>Caffeine does not measurably enhance cognitive function in any significant way.</li>\n<li>Caffeine enhances cognitive function, but only indirectly, in that it counteracts the effects of fatigue.</li>\n<li>Caffeine enhances cognitive function, but only indirectly, in that it counteracts the effects of caffeine withdrawal.</li>\n<li>Caffeine has no physical effect on cognitive function, but has a psychological effect.</li>\n</ul>\n\n<p>What is the actual behavior of caffeine in relation to cognition?  (I'm particularly interested to know if any research addresses the claim that it only counteracts the effects of caffeine withdrawal)</p>\n", "pids": ["55a525c765ceb7cb02e27307"], "flag": 1}
{"question": "Do transcripts always start and end with exons?", "body": "<p>I realized that in all cases of \"RefSeq Genes\" annotations of hg19 I looked at spliced transcripts start (and end) with an exon. From the annotation there is no evidence of any sequence upstream or downstream of these exons that remain in the nascent RNA.</p>\n\n<p>Does this reflect the biology or is it just a consequence of the spliced read mapping? In other words: Do transcribed regions upstream of the first exon and downstream of the last exon exist in nascent RNA?</p>\n\n<p>These regions, if they exist, cannot be called introns when those are defines as 'spliced sequences between exons'. How would one call them?</p>\n", "pids": ["53e99a35b7602d9702294580"], "flag": 1}
{"question": "Sampling model for crowdsourced data?", "body": "<p>I'm working on an open health survey application, planned to be used in developing country. </p>\n\n<p>The basic idea is that survey <strong>interviews are crowdsourced</strong> - they are performed by unorganized volunteers who submit forms data of the interviews they performed by using their mobile devices, and each survey is accompanied by the GPS data of the interview location. </p>\n\n<p>Traditional surveys compiled by government agencies are usually implemented using some standard sampling model - usually a probability sampling model. This requires a lot of centralized planning that cannot be always performed. (mentioned this to put my question in the right context)</p>\n\n<p>We can say that a volunteer will implement a convenience sampling around his area. He will interview arbitrarily number of people he can reach. </p>\n\n<p>The basic problem is: <strong>How can understand and characterize the overall sampling model of this surveying system?</strong> Are there any methodologies or composed models to deal with such cases? </p>\n", "pids": ["53e9b0abb7602d9703b1bd12", "53e9b96fb7602d9704560e9a"], "flag": 1}
{"question": "Most effective use of colour in heat/contour maps", "body": "<p>It's quite common to use heat/contour maps when presenting time-frequency EEG findings. The colour scheme often chosen (and one that I like and use) is the \"jet\" colour scheme (see e.g., google image search <a href=\"https://www.google.com.au/search?hl=en&amp;safe=off&amp;client=firefox-a&amp;hs=HvS&amp;rls=org.mozilla%3aen-US%3aofficial&amp;channel=fflb&amp;q=time+frequency+EEG&amp;bav=on.2,or.r_gc.r_pw.r_qf.&amp;bpcl=36601534&amp;biw=1321&amp;bih=632&amp;um=1&amp;ie=UTF-8&amp;tbm=isch&amp;source=og&amp;sa=N&amp;tab=wi&amp;ei=QoyPUN-RMa-tiQeD4IGgBg\">time-frequency EEG</a>). I'm wondering if there are any better colour schemes for presenting these plots, and/or guidelines for the presentation of such maps.  </p>\n\n<p>e.g., from R base library</p>\n\n<pre><code>#Volcano\nx &lt;- 10*(1:nrow(volcano))\ny &lt;- 10*(1:ncol(volcano))\nimage(x, y, volcano, col = terrain.colors(100), axes = FALSE)\n\n# With Jet colours\njet.colors &lt;-  colorRampPalette(c(\"midnightblue\",\"blue\", \"cyan\",\"green1\", \"yellow\",\"orange\",\"red\", \"darkred\"), space=\"Lab\")\nimage(x, y, volcano, col = jet.colors(100), axes = FALSE)\n</code></pre>\n", "pids": ["53e9ba65b7602d97046841da"], "flag": 1}
{"question": "Mean(scores) vs Score(concatenation) in cross validation", "body": "<h3>TLDR:</h3>\n<p>My dataset is pretty small (120) samples. While doing 10-fold cross validation, should I:</p>\n<ol>\n<li><p>Collect the outputs from each test fold, concatenate them into a vector, and then compute the error on this full vector of predictions (120 samples)?</p>\n</li>\n<li><p>Or should I <strong>instead</strong> compute the error on the outputs I get <strong>on each fold</strong> (with 12 samples per fold), and then get my final error estimate as the average of the 10 fold error estimates?</p>\n</li>\n</ol>\n<p>Are there any scientific papers that argue the differences between these techniques?</p>\n<hr />\n<h3>Background: Potential Relationship to Macro/Micro scores in multi-label classification:</h3>\n<p>I think this question may be related to the difference between <strong>micro</strong> and <strong>Macro</strong> averages that are often used in a multi-label classification task (e.g. say 5 labels).</p>\n<p>In the multi-label setting, <strong>micro average scores</strong> are computed by making an <strong>aggregated</strong> contingency table of true positive, false positive, true negative, false negative for all 5 classifier predictions on 120 samples. This contingency table is then used to compute the micro precision, micro recall and micro f-measure. So when we have 120 samples and five classifiers, the micro measures are computed on 600 predictions (120 samples * 5 labels).</p>\n<p>When using the <strong>Macro</strong> variant, one computes the measures (precision, recall, etc.) <strong>independently</strong> on each label and finally, these measures are averaged.</p>\n<p>The idea behind the difference between <strong>micro</strong> vs <strong>Macro</strong> estimates may be extended to what can be done in a K-fold setting in a binary classification problem. For 10-fold we can either <strong>average</strong> over 10 values (<strong>Macro</strong> measure) or concatenate the 10 experiments and compute the <strong>micro</strong> measures.</p>\n<h3>Background - Expanded example:</h3>\n<p>The following example illustrates the question.  Let's say we have 12 test samples and we have 10 folds:</p>\n<ul>\n<li><strong>Fold 1</strong>: <strong>TP</strong> = 4, <strong>FP</strong> = 0, <strong>TN</strong> = 8 <strong>Precision</strong> = 1.0</li>\n<li><strong>Fold 2</strong>: <strong>TP</strong> = 4, <strong>FP</strong> = 0, <strong>TN</strong> = 8 <strong>Precision</strong> = 1.0</li>\n<li><strong>Fold 3</strong>: <strong>TP</strong> = 4, <strong>FP</strong> = 0, <strong>TN</strong> = 8 <strong>Precision</strong> = 1.0</li>\n<li><strong>Fold 4</strong>: <strong>TP</strong> = 0, <strong>FP</strong> = 12,  <strong>Precision</strong> = 0</li>\n<li><strong>Fold 5</strong> .. <strong>Fold 10</strong>: All have the same <strong>TP</strong> = 0, <strong>FP</strong> = 12 and <strong>Precision</strong> = 0</li>\n</ul>\n<p>where I used the following notation:</p>\n<p><strong>TP</strong> = # of True Positives,\n<strong>FP</strong> = # False Positive,\n<strong>TN</strong> = # of True Negatives</p>\n<p>The results are:</p>\n<ul>\n<li>Average precision across 10 folds = 3/10 = <strong>0.3</strong></li>\n<li>Precision on the concatenation of the predictions of the 10 folds = TP/TP+FP = 12/12+84 = <strong>0.125</strong></li>\n</ul>\n<p><strong>Note that the values 0.3 and 0.125 are very different</strong>!</p>\n", "pids": ["53e9bcb3b7602d9704932142"], "flag": 1}
{"question": "Effective Sample Size for posterior inference from MCMC sampling", "body": "<p>When obtaining MCMC samples to make inference on a particular parameter, what are good guides for the minimum number of <strong>effective samples</strong> that one should aim for?</p>\n\n<p>And, does this advice change as the model becomes more or less complex?</p>\n", "pids": ["5c610965da56297340b75359"], "flag": 1}
{"question": "What fast algorithms exist for computing truncated SVD?", "body": "<p>Possibly off topic here, but there exist several (<a href=\"https://stats.stackexchange.com/questions/66034/what-are-efficient-algorithms-to-compute-singular-value-decomposition-svd\">one</a>, <a href=\"https://stats.stackexchange.com/questions/79043/why-pca-of-data-by-means-of-svd-of-the-data\">two</a>) related questions already. </p>\n\n<p>Poking around in the literature (or a google search for Truncated SVD Algorithms) turns up a lot of papers that <em>use</em> truncated SVDs in various ways, and <em>claim</em> (frustratingly, often without citation) that there are fast algorithms for computing it, but no one seems to be pointing at what those algorithms are.</p>\n\n<p>The only thing I can find is a single <a href=\"http://arxiv.org/abs/0909.4061\" rel=\"noreferrer\">randomized algorithm</a>, used in the <a href=\"https://code.google.com/p/redsvd/wiki/English\" rel=\"noreferrer\">redSVD library</a>.</p>\n\n<p>What I'd like to see is a set of exact and inexact algorithms, suitable for understanding how the systems work (but not necessarily for actually implementing them of course!).</p>\n\n<p>Does anyone have a good reference for this sort of thing?</p>\n", "pids": ["53e9b3b2b7602d9703e999b3"], "flag": 1}
{"question": "Do two compatible tRNA codons bond together?", "body": "<p>Can two tRNA with complementary anti-codons link together?  For instance UUU with AAA. If not, why not?</p>\n", "pids": ["53e9b5a1b7602d97040e7977"], "flag": 1}
{"question": "What loss function should one use to get a high precision or high recall binary classifier?", "body": "<p>I'm trying to make a detector of objects that occur very rarely (in images), planning to use a CNN binary classifier applied in a sliding/resized window. I've constructed balanced 1:1 positive-negative training and test sets (is it a right thing to do in such case btw?), and classifier is doing fine on a test set in terms of accuracy. Now I want to control recall/precision of my classifier so, for example, it will not wrongly label too much of a majority class occurrences. </p>\n\n<p>Obvious (for me) solution is to use same logistic loss which is used now, but weight type I and type II errors differently by multiplying loss in one of the two cases on some constant, which can be tuned. Is it right?</p>\n\n<p>P.S. On a second thought this is equivalent to weighting some training samples more than the others. Just adding more of one class will achieve the same I think.</p>\n", "pids": ["5c75666df56def97980c9968", "599c7cc1601a182cd27d4507"], "flag": 1}
{"question": "Why do deep neural networks work well?", "body": "<p>The universal approximation theorem, as I understand it, states that for any continuous bounded function <span class=\"math-container\">$f: X \\rightarrow \\mathbb{R}$</span> with compact domain <span class=\"math-container\">$X$</span> and any threshold <span class=\"math-container\">$\\varepsilon$</span> there is a neural network <span class=\"math-container\">$N: X \\rightarrow \\mathbb{R}$</span> with a <strong>single</strong> hidden layer that can approximate the function to the specific threshold:</p>\n\n<p><span class=\"math-container\">$$\\forall x \\in X:\\quad \\left\\| f(x) - N(x) \\right\\| \\le \\varepsilon$$</span></p>\n\n<p>Nevertheless, there are also Taylor and Fourier series expansions.\nThough deep neural networks seem to work better in, for example, face recognition task.</p>\n\n<p>The universal approximation theorem speaks about <strong>shallow</strong> neural networks.\nAlso, it's general and doesn't say a lot about the nature of a function to approximate.\nIs there a mathematical explanation for such success of deep learning (at least, for specific tasks)?</p>\n", "pids": ["5c5ce50d17c44a400fc38e8c", "599c7b59601a182cd272b77e", "573696086e3b12023e51b69f", "5a260c8417c44a4ba8a31555", "573695fd6e3b12023e51148a", "573696026e3b12023e5163e1", "599c7959601a182cd2633bb3", "58437722ac44360f1082efb7", "5bdc31b417c44a1f58a0baa7"], "flag": 0}
{"question": "How do the number of imputations &amp; the maximum iterations affect accuracy in multiple imputation?", "body": "<p>The help page for <code>MICE</code> defines the function as:</p>\n\n<pre><code>mice(data, m = 5, method = vector(\"character\", length = ncol(data)),\n  predictorMatrix = (1 - diag(1, ncol(data))),\n  visitSequence = (1:ncol(data))[apply(is.na(data), 2, any)],\n  form = vector(\"character\", length = ncol(data)),\n  post = vector(\"character\", length = ncol(data)), defaultMethod = c(\"pmm\",\n  \"logreg\", \"polyreg\", \"polr\"), maxit = 5, diagnostics = TRUE,\n  printFlag = TRUE, seed = NA, imputationMethod = NULL,\n  defaultImputationMethod = NULL, data.init = NULL, ...)\n</code></pre>\n\n<p>Those are a <em>lot</em> of parameters. How does one decide which parameters to specify and which ones to leave as default?</p>\n\n<p>I'm especially interested in the number of multiple imputations, <code>m</code> and the maximum iterations, <code>maxit</code>. How do these parameters affect accuracy? </p>\n\n<p>In other words, when (how?) - whilst using these parameters - can I really say that a sort of convergence has been reached?</p>\n", "pids": ["53e9a63eb7602d9702f6f0cf", "55a3ec3665ce5cd7b3bd13ec"], "flag": 1}
{"question": "Applying Graph Theory to Linear Algebra (not the other way around)", "body": "<p>I know about applications of Linear Algebra to Graph Theory, I find them boring. What interests me is whether one can draw graph-like pictures of linear functions to understand them better.</p>\n\n<p>Do you know of any results like that?</p>\n\n<p>I have one particular question I would like to know the answer to:</p>\n\n<p>Let <span class=\"math-container\">$f : V \\rightarrow V$</span> be a linear function and <span class=\"math-container\">$b_1,...,b_n \\in V$</span> a basis of <span class=\"math-container\">$V$</span>. Also for every <span class=\"math-container\">$v \\in V$</span> define <span class=\"math-container\">$v_1,...,v_n$</span> so that <span class=\"math-container\">$v_1 b_1 + ... + v_n b_n = v$</span>.\nFinally let <span class=\"math-container\">$G = (B,E)$</span> be the graph with <span class=\"math-container\">$B = \\{b_1,...,b_n\\}$</span> and <span class=\"math-container\">$E = \\{ (b_i, b_j) \\text{ with weight } f(b_i)_j \\mid i,j \\in \\{1,...,n\\} \\}$</span>.\nIn words: draw a circle for every basis element and connect them so that you can see how <span class=\"math-container\">$f$</span> maps the basis elements to each other.</p>\n\n<p>Now delete all weights that are zero and assume the other weights are positive. Can we say something like: There is a cycle in <span class=\"math-container\">$G$</span> if and only if <span class=\"math-container\">$f$</span> has an eigenvector? To me that sounds like the <a href=\"https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem\" rel=\"noreferrer\">Perron–Frobenius theorem\n</a>.</p>\n\n<p>I'm also wondering if one could prove the existence of Jordan-Normal-Forms using graphs like this. (generalized eigenvectors are then maybe cycles connected by a tree)</p>\n\n<p>In general I feel like there should be a graph-theoretic perspective on the (basic) concepts I've seen in linear algebra. What do you think?</p>\n", "pids": ["53e9bcf6b7602d970497e64a"], "flag": 0}
{"question": "RNNs: When to apply BPTT and/or update weights?", "body": "<p>I am trying to understand the high-level application of RNNs to sequence labeling via (among others) Graves' 2005 paper on <a href=\"http://www.cs.toronto.edu/~graves/nn_2005.pdf\" rel=\"noreferrer\">phoneme classification.</a></p>\n\n<p>To summarize the problem:  We have a large training set consisting of (input) audio files of single sentences and (output) expert-labeled start times, stop times and labels for individual phonemes (including a few \"special\" phonemes such as silence, such that each sample in each audio file is labeled with some phoneme symbol.)</p>\n\n<p>The thrust of the paper is to apply an RNN with LSTM memory cells in the hidden layer to this problem.  (He applies several variants and several other techniques as comparison.  I am for the moment ONLY interested in the unidirectional LSTM, to keep things simple.)</p>\n\n<p>I believe I understand the architecture of the network:  An input layer corresponding to 10 ms windows of the audio files, preprocessed in ways standard to audio work; a hidden layer of LSTM cells, and an output layer with a one-hot coding of all possible 61 phone symbols.</p>\n\n<p>I believe I understand the (intricate but straightforward) equations of the forward pass and backward pass through the LSTM units.  They are just calculus and the chain rule. </p>\n\n<p>What I do not understand, after reading this paper and several similar ones several times, is <em>when exactly</em> to apply the backpropagation algorithm and <em>when exactly</em> to update the various weights in the neurons.</p>\n\n<p>Two plausible methods exist:</p>\n\n<p>1)  Frame-wise backprop and update</p>\n\n<pre><code>Load a sentence.  \nDivide into frames/timesteps.  \nFor each frame:\n- Apply forward step\n- Determine error function\n- Apply backpropagation to this frame's error\n- Update weights accordingly\nAt end of sentence, reset memory\nload another sentence and continue.\n</code></pre>\n\n<p>or,</p>\n\n<p>2)  Sentence-wise backprop and update:</p>\n\n<pre><code>Load a sentence.  \nDivide into frames/timesteps.  \nFor each frame:\n- Apply forward step\n- Determine error function\nAt end of sentence:\n- Apply backprop to average of sentence error function\n- Update weights accordingly\n- Reset memory\nLoad another sentence and continue.\n</code></pre>\n\n<p><strong>Note that this is a general question about RNN training</strong> using the Graves paper as a pointed (and personally relevant) example:  When training RNNs on sequences, is backprop applied at every timestep?  Are weights adjusted every timestep?  Or, in a loose analogy to batch training on strictly feed-forward architectures, are errors accumulated and averaged over a particular sequence before backprop and weight updates are applied?</p>\n\n<p>Or am I even more confused than I think?</p>\n", "pids": ["53e99bffb7602d97024ac0e6", "573696106e3b12023e5224ff"], "flag": 1}
{"question": "What is the VC dimension of a decision tree?", "body": "<p>What is the <a href=\"https://en.wikipedia.org/wiki/VC_dimension\">VC dimension</a> of a decision tree with k splits in two dimensions? Let us say the model is CART and the only allowed splits are parallel to the axes.</p>\n\n<p>So for one split we can <a href=\"https://en.wikipedia.org/wiki/VC_dimension#Shattering\">order 3 points in a triangle</a> and then for any labeling of the points we could get perfect prediction (i.e.: shattered points)</p>\n\n<p>But what about 2 splits, or any general k?</p>\n", "pids": ["558b55c5e4b037c0875c551b", "5f7fdd328de39f0828397d33"], "flag": 1}
{"question": "Stochastic interpretation of Einstein equations", "body": "<p>Einstein's theory of gravitation, <a href=\"http://en.wikipedia.org/wiki/General_relativity\" rel=\"nofollow noreferrer\">general relativity</a>, is a purely <a href=\"http://en.wikipedia.org/wiki/Differential_geometry\" rel=\"nofollow noreferrer\">geometric theory</a>.</p>\n\n<p>In a recent question I wanted to know what the relation of <a href=\"https://math.stackexchange.com/questions/16982/relation-of-brownian-motion-to-helmholtz-equation\">Brownian motion to the Helmholtz equation</a> is and got a very thorough <a href=\"https://math.stackexchange.com/questions/16982/relation-of-brownian-motion-to-helmholtz-equation/17053#17053\">answer</a> from <a href=\"https://math.stackexchange.com/users/1321/george-lowther\">George Lowther</a>.</p>\n\n<p>He pointed out that there is, roughly speaking, a very general relation of semi-elliptic second order differential operators of the form </p>\n\n<p>$$Af = \\frac12 a^{ij}f_{,ij} + b^i f_{,i} - cf = 0$$</p>\n\n<p>to a \"killed\" Brownian motion. (I used some <a href=\"http://mathworld.wolfram.com/EinsteinSummation.html\" rel=\"nofollow noreferrer\">summation convention</a> and $,i = \\frac{\\partial}{\\partial x^i}$.)</p>\n\n<p>Now, the <a href=\"http://en.wikipedia.org/wiki/Einstein_field_equations\" rel=\"nofollow noreferrer\">Einstein field equations</a></p>\n\n<p>$$R_{\\mu\\nu}-\\frac12 g_{\\mu\\nu}R = \\frac{8\\pi G}{c^4}T_{\\mu\\nu}$$</p>\n\n<p>are coupled hyperbolic-elliptic partial differential equations (I dropped the cosmological constant here). Can we somehow <strong>adopt</strong> the relation of a <strong>random process</strong> to this kind of equation, or</p>\n\n<blockquote>\n  <p>Is there a way to interprete the\n  Einstein equations stochastically?</p>\n</blockquote>\n", "pids": ["53e9a351b7602d9702c5bb3a"], "flag": 0}
{"question": "Connecting a $n, n$ point grid", "body": "<p>I stumbled across the problem of connecting the points on a <span class=\"math-container\">$n, n$</span> grid with a minimal amount of straight lines without lifting the pen.</p>\n<p>For <span class=\"math-container\">$n=1, n=2$</span> it is trivial. For <span class=\"math-container\">$n=3$</span> you can find the solution with a bit trial and error (I will leave this to the reader as it is a fun to do, you can do it with 4 lines). I found one possible solution for a <span class=\"math-container\">$4,4$</span> grid and animated it, it uses 6 lines and is probably optimal (will hopefully help you to understand the problem better, the path doesn't have to be closed like in the animation, open ends are allowed!):</p>\n<p><a src=\"https://i.stack.imgur.com/4D4a1.gif\" alt=\"Problem\" /></p>\n<p>Now my question is, for higher <span class=\"math-container\">$n$</span>, is there a way to get the amount of minimal lines to use and does an algorithm exist to find a actual solution? I think its quite hard to model the &quot;straight lines&quot; with graph theory.</p>\n<p>Edit:\nReading Erics excellent answer I found the following website: <a href=\"http://www.mathpuzzle.com/dots.html\" rel=\"noreferrer\">http://www.mathpuzzle.com/dots.html</a> that also gives an algorithm to connect the points in <span class=\"math-container\">$2n-2$</span> steps, solutions up to <span class=\"math-container\">$10,10$</span> and mentions:</p>\n<blockquote>\n<p>Toshi Kato conjectures: On\n<span class=\"math-container\">$(2N+1)x(2N+1)$</span> grid, <span class=\"math-container\">$N \\geq 2$</span>, Using <span class=\"math-container\">$4N$</span>\ncontinuous lines, and not lifting your\npencil from the paper, can go through\nall the dots of a <span class=\"math-container\">$(2N+1)x(2N+1)$</span> grid,\nending at the same place started. But\nmust visit at least one dot twice in\nthe route.</p>\n<p>On <span class=\"math-container\">$(2N)x(2N)$</span> grid, <span class=\"math-container\">$N \\geq 2$</span>, Using <span class=\"math-container\">$4N-2$</span>\ncontinuous lines, and not lifting your\npencil from the paper, can go through\nall the dots of a <span class=\"math-container\">$(2N)x(2N)$</span> grid,\nending at the same place started. And\ncan visit each dots just once.</p>\n</blockquote>\n<p>It seems to be an open problem to show that <span class=\"math-container\">$2n-2$</span> is optimal.</p>\n<p>Also I found the following page with a proof that in the <span class=\"math-container\">$3,3$</span> grid there cannot be <span class=\"math-container\">$2$</span> parallel lines: <a href=\"http://fahim-patel.blogspot.com/2011/01/proof.html\" rel=\"noreferrer\">http://fahim-patel.blogspot.com/2011/01/proof.html</a> I think it might be interesting for coming up with a proof that <span class=\"math-container\">$2n-2$</span> is optimal (however maybe there is no such proof, as we only saw solutions for very small <span class=\"math-container\">$n$</span>, for bigger <span class=\"math-container\">$n$</span> there might be some developments we don't know about).</p>\n", "pids": ["62d620f65aee126c0fad4b23"], "flag": 0}
{"question": "Series of logarithms $\\sum\\limits_{k=1}^\\infty \\ln(k)$ (Ramanujan summation?)", "body": "<p>I had this question earlier, so to say as a \"standalone\" problem, but now it pops up in context of an analysis with the <em>lngamma</em>-function. As well as we can convert the question of sums of like powers $Su_p(n)=1^p+2^p+3^p+\\cdots+n^p$ in terms of the Hurwitz-zeta $Su_p(n) = \\zeta(p,1)-\\zeta(p,n+1)$ (and solve using the Bernoulli-polynomials) I try to express this for sums of logarithms (and powers of logarithms) : $$ Sl_p(n) = \\ln(1)^p+\\ln(2)^p+\\cdots+\\ln(n)^p $$<br>\nI have seemingly proper coefficients for power series which allow that computations/approximations. The result is always found by the difference of $ Sl_p(n)-Sl_p(1) $ . Here the power series has zero as constant term.<br>\n\nHowever, to have the analogue to the Hurwitz-zeta I should have the constant term the \"value\" for the infinite sum $ Sl_p(\\infty) $ instead. <em>(This cancels properly if I formulate the sum of (powers of) logarithms always as that difference $ Sl_p(n)-Sl_p(1) $)</em> And also, I'd like that this agreed conceptually more to the notion:\n$$ \\begin{array} {rll} Sl_p(n)-Sl_p(1) &amp;=&amp; T_p(0)-T_p(n) \\\\\\\n &amp; =&amp;  (\\ln(1)+\\ln(2)+\\ln(3)+\\cdots) \\\\\\ \n &amp; &amp; - (\\ln(n+1)+\\ln(n+2)+\\ln(n+2)+\\cdots) \\end{array} $$<br>\nas this agrees more with the idea of the Hurwitz-zeta-difference.     </p>\n\n<p>But this requires, that $T_p(0)$ represents the (infinite) sum of the $p$'th powers of the logarithms, and the constant in the power series of $T_p(0)$ must contain just such a value. Let's talk about the first powers of the logs $p=1 $ first and denote the assumed sum as $L_1$ : $ L_1 = \\lim_{n\\to \\infty} T_1(0) $</p>\n\n\n\n<p><strong>[update 2]</strong><br>\n<em>I think, thanks to the hint of J.M., I can answer Q1 myself now; only Q2 remains somehow vague - besides a simple empirical heuristic I did still not get the formally correct approach to the constant term/integral-definition in the Ramanujan summation - but this is now only a side problem here (however it would be nice to get help also for this question).</em></p>\n\n<p><em>With the help of the knowledge about the derivatives of the zeta at zero the relevant part of the problem could now satisfyingly be solved, so I put it here in an answer to my own question, see that answer below....</em>       </p>\n\n<p>Final remark/conclusion: it is interesting, that the power series for the lngamma pops up here \"automatically\" - we need no other uniqueness criterion for the argument, that the (Eulerian) gamma-function gives \"the correct\" interpolation for the factorial problem. It is just the result of the construction of an operator for the \"indefinite summation\" (which was the comceptual goal from where the problem/question arose initially)</p>\n\n<p><em>In the following I keep the rest of the original question although the approach to the Ramanujan summation contains an error</em><br>\n<strong>[end Update 2]</strong></p>\n\n\n\n<p>I tried to give sense to that divergent series by replacing the powers of $x$ in the Mercator series for $ \\ln(1+x) $ by appropriate zetas at negative integer arguments. If I understand things correctly then this is similar to the method of Ramanujan summation, where the Bernoulli numbers are just replaced by the according zeta-values (appropriately scaled). With this I got then an approximation of $$L_1 \\approx -0.0810614667953 $$<br>\nwhich seems a rather \"random\" value...<br>\nBy searching in other online sources I got the suggestion (<a href=\"http://oeis.org/A110544\">OEIS</a>), that this is also $$ \\int_1^2 \\ln(\\Gamma(t)) \\; dt \\approx -0.08106146679532725821967026 $$ </p>\n\n<p>With this my power series for $T_1(x)$ begins like      </p>\n\n<p>$ \\qquad \\small \\begin{array} {l}\n - &amp; 0.0810614667953 \\\\\n - &amp; 0.577215664902x \\\\\n + &amp; 0.533859200973x^2 \\\\\n + &amp; 0.325578788221x^3 \\\\\n + &amp; 0.125274140308x^4 \\\\\n + &amp; 0.0337256506589x^5 \\\\\n + &amp; 0.00685935357296x^6 \\\\\n + &amp; 0.00117260810356x^7 \\\\\n + &amp; O(x^8)\n \\end{array} \n$<br>\nThe other coefficients occur also in the power series for $f(x)=\\ln(\\Gamma(\\exp(x)) $     </p>\n\n<p>Also, $L_1$ seem to satisfy the following expression: \n$$ \\exp(L_1) = {\\sqrt{(2\\pi)} \\over e} \\approx 0.9221370088957891168791517 $$ </p>\n\n<p>The questions are:\n$\\qquad$   <strong><em>Q1</em></strong>: Is that value <em>$-0.0801\\ldots$</em> a meaningful (or even correct) representation for the infinite sum of logarithms?<br>\n$\\qquad$   <strong><em>Q2</em></strong>: Did I reproduce the Ramanujan summation correctly here?</p>\n\n\n\n<p><strong>[update 1]</strong>: J.M. mentions the relation to $ y= - \\zeta'(0) \\approx 0.918938533205 $ where the representation of the derivative of zeta at 0 equals formally just the sum of logarithms. Now my $L_1$ and the $y$ are related by $L_1 = y - 1$. So I expect some error in my derivation which leads just to that unit difference...</p>\n", "pids": ["5fb791ad91e01122f29d6900"], "flag": 0}
{"question": "Non-axiomatisability and ultraproducts", "body": "<p>Let $T$ be a first-order theory over a language $L$, and let $\\mathcal{M}$ be a subclass of the class of models of $T$. As I understand it, if there is no theory $\\hat{T}$ over $L$ whose class of models is exactly $\\mathcal{M}$, frequently, the \"morally correct\" reason is that $\\mathcal{M}$ is not closed under ultraproducts. However, it is sometimes possible to obtain a simpler proof of non-axiomatisability by compactness or completeness considerations.</p>\n\n<p><strong>Example</strong>. Consider the first order theory of fields, and let $\\mathcal{M}$ be the class of fields of positive characteristic. Then $\\mathcal{M}$ is not axiomatisable in the language of fields since, for example, if we take the ultraproduct of all the finite fields $\\mathbb{F}_p$, $p$ prime, we would obtain a field of characteristic 0.</p>\n\n<p>We could also prove this directly: if $T&#39;$ is the naïve axiomatisation of fields of characteristic 0 (i.e. the one with one axiom of the form $\\underbrace{1 + \\cdots + 1}_{n\\text{ times}} \\ne 0$ for every positive $n \\in \\mathbb{N}$), and $\\hat{T}$ is any axiomatisation of $\\mathcal{M}$, then $T&#39; \\cup \\hat{T}$ is inconsistent, so there is some finite subset which is inconsistent, so there is some finite set $X$ for which $\\hat{T}$ proves that there is an $n \\in X$ such that $\\underbrace{1 + \\cdots + 1}_{n\\text{ times}} = 0$; but there are fields of positive characteristic other than those $n \\in X$ — a contradiction.</p>\n\n<p><strong>Question</strong>. Is it in fact <em>always</em> possible to translate a proof of non-axiomatisability using ultraproducts to one using compactness/completeness?</p>\n", "pids": ["53e9a1a1b7602d9702a9769c"], "flag": 0}
{"question": "Can up to 70% of scientific studies not be reproduced?", "body": "<p>I read and heard a lot about the <a href=\"http://www.reproducibilityinitiative.org/\"><em>Reproducibility Initiative</em></a> recently, <a href=\"http://blog.scienceexchange.com/2012/08/the-reproducibility-initiative/\">claiming that the data of many scientific studies cannot/was not/is not be reproduced</a>.</p>\n\n<blockquote>\n  <p>“In the last year, problems in reproducing academic research have drawn a lot of public attention, particularly in the context of translating research into medical advances. <strong>Recent studies indicate that up to 70% of research from academic labs cannot be reproduced, representing an enormous waste of money and effort</strong>,” said Dr. Elizabeth Iorns, Science Exchange’s co-founder and CEO. “In my experience as a researcher, I found that the problem lay primarily in the lack of incentives and opportunities for validation—the Reproducibility Initiative directly tackles these missing pieces.”</p>\n</blockquote>\n\n<p>Unfortunately I was not able to find those studies (where these reproduced!?) proving this statement. I want to know where these studies where carried out, medicine, biology, psychology, but couldn't find anything. I'm also somehow skeptical that science is in that bad shape, considering that studies are often used/mandatory here on skeptics.se for good answers and to get license for pharmaceutical products. 70% looks a bit too high to me.</p>\n", "pids": ["55a4a13865ceb7cb02d4b42c"], "flag": 1}
{"question": "Does circumcision reduce HIV risk?", "body": "<p>I've seen numerous claims that circumcision reduces HIV risk, both on TV and <a href=\"http://aids.about.com/od/hivprevention/a/circumcision.htm\">online</a>.</p>\n\n<p>Have there been any studies to verify if circumcision does or doesn't reduce HIV risk in a statistically-significant manner?</p>\n", "pids": ["53e9af06b7602d970393a52a"], "flag": 1}
{"question": "Do emotionally-driven tears release toxins from the body?", "body": "<p>Sometime ago I'd heard someone trained in child psychology claim that crying for emotional reasons (as opposed to getting something in your eye for example) released toxins from the brain and/or body.  More specifically, she claimed that emotionally-based tears, when collected and fed to rats in their food, resulted in a markedly increased statistical rate of disease and mortality in comparison to reflex-based tears or no tears at all.  The explanation seemed a little hand-wavy, was uncited, and I was a little bit suspicious.</p>\n\n<p>However, I have noticed for some time that emotionally-based tears taste different depending on the \"bitterness\" of the experience.  Then, I recently went through an extremely stressful time where I experienced levels of emotional stress higher than I ever have in my life.  I found to my surprise that my tears during this period, if allowed to drain down my throat, caused extreme soreness for a short period of time (mitigated by drinking liquids); whereas if I was careful not to allow them to, no soreness resulted.  A friend also experiencing extreme emotional stress found that the specific areas on her cheeks that her tears touched became visibly red and raw.  Again, her experience was that the rawness correlated with contact vs no contact in specific incidents--rather than frequency.  These responses seemed too specific to be <a href=\"http://en.wikipedia.org/wiki/Psychosomatic_medicine\">psychosomatic</a>.</p>\n\n<p>Now, \"toxins\" is very vague and it's clear that crying is an important emotional tool regardless of whether its significance is psychologically- or physiologically-based.  My sample-space is unsatisfactorily small, but has intrigued me.  Is there any scientific evidence that:</p>\n\n<ol>\n<li>Emotionally-driven tears contain\nsubstances harmful to the body, and\nif so which substances and by which\nmechanisms.</li>\n<li>Emotionally-driven tears contain\nsubstances which are in some way\nspecifically related to stress.</li>\n<li>And, if either of the above are\ntrue, is it scientifically plausible\nthat the substances in\nemotionally-driven tears are in any\nway originating in the brain?</li>\n</ol>\n\n<p>I'm especially interested any evidence which suggests there is a good reason to fully expel emotionally-driven tears from the body, and any that suggests failure to cry under emotional stress prevents the release of a substance which ought to be released for body/brain health.  Does anyone have any good research on these topics?  My apologies for the length and detail of the question.</p>\n\n<p><strong>Edit:</strong> I've also recently experienced stinging cheeks after an especially poignant (yet low tear volume) cry.  Since this is now a topic of curiousity for me it's hard to rule out a psychosomatic effect, but it was a distinct enough feeling to bump this post with an edit.  No hard sources out there, anyone?</p>\n", "pids": ["53e9979eb7602d9701f6c890"], "flag": 1}
{"question": "Does the tongue have different taste zones?", "body": "<p>I've seen quite a few of these \"tongue maps\", showing discrete borders between taste zones and often conflicting setups, like these two:</p>\n\n<p><a src=\"https://i.stack.imgur.com/O1XDh.jpg\" width=\"195\">\n<a src=\"https://i.stack.imgur.com/hdceH.gif\" width=\"250\"></p>\n\n<p>Anecdotally, I can feel all tastes all over the tongue, more or less equally well, so I don't really understand what these map are supposed to indicate. </p>\n\n<p>Does the tongue have different taste zones as shown?</p>\n", "pids": ["53e9a9e6b7602d970334a670"], "flag": 1}
{"question": "Has fluoride been classified as a neurotoxin?", "body": "<p>My Facebook feed includes a report that fluoride has recently been officially classified as a neurotoxin.</p>\n<ul>\n<li><a href=\"http://awarenessact.com/fluoride-officially-classified-as-a-neurotoxin-in-worlds-top-medical-journals\" rel=\"noreferrer\">Awareness Act, 5 April 2018</a></li>\n</ul>\n<blockquote>\n<p>A big step has been made here recently. In the most prestigious medical journal. One known as The Lancet. fluoride has been at last classified as a neurotoxin one hundred percent. This puts it in the same category as things like lead, arsenic, and mercury.</p>\n<p>This news was released by the author Stefan Smyle who actually cited a report that had been published in The Lancet Neurology, Volume 13, Issue 3 to be exact in the March of 2014 edition.</p>\n</blockquote>\n<p>I am not entirely sure what it means to be &quot;officially classified&quot;, but has such a classification been made?</p>\n<p>(Whether fluoride actually <em>is</em> a neurotoxin is a separate claim, if anyone wants to ask a separate question about it.)</p>\n", "pids": ["5c0f7c33da562944ac7cc0bd"], "flag": 1}
{"question": "So can anybody indicate whether it is worthwhile trying to understand what Mochizuki did?", "body": "<p>So I am looking at some math stuff and I start looking at the abc-conjecture. Naturally I run into the name Mochizuki and so start trying to see what he did. Well, he is starting look like another Galois. Frankly it was getting frustrating ... the lack of information. It seems like no one understands what he did. Well, if Mochizuki invented a new area of mathematics that solves big problems then wouldn't it be valuable to study his work? Why aren't a lot of people moving to understand what he did? There just seems to be a contradiction between his claims and the response by the mathematical community at large. The fact that it is 2014 with no new news indicates an issue. It would be nice if someone can resolve or explain this.</p>\n", "pids": ["56d8d2dcdabfae2eeeb2bb44", "599c77ef601a182cd258bef2"], "flag": 0}
{"question": "Comparing countable models of ZFC", "body": "<p>Let us consider the class $\\cal C$ of countable models of ZFC. For ${\\mathfrak A}=(A,{\\in}_A)$ and ${\\mathfrak B}=(B,{\\in}_B)$ in $\\cal C$ I say that ${\\mathfrak A}&lt;{\\mathfrak B}$ iff there is a injective map $i: A \\to B$ such that $x {\\in}_A y \\Leftrightarrow i(x) {\\in}_B i(y)$ (note that this is a much weaker requirement for $i$ than to be an elementary embedding). My two questions are :</p>\n\n<p>(1) Is there a simple construction of two incomparable models ${\\mathfrak A},{\\mathfrak B}$ ?\n(i.e. neither ${\\mathfrak A}&lt;{\\mathfrak B}$ nor ${\\mathfrak B}&lt;{\\mathfrak A}$).</p>\n\n<p>(2) Given two models ${\\mathfrak A},{\\mathfrak B}$ in $\\cal C$, is there always a third model ${\\mathfrak C}$ in $\\cal C$ such that ${\\mathfrak A}&lt;{\\mathfrak C}$ and ${\\mathfrak B}&lt;{\\mathfrak C}$ ?</p>\n", "pids": ["56d83ad4dabfae2eee5e3162"], "flag": 0}
{"question": "What is the longest time a qubit has survived with 0.9999 fidelity?", "body": "<p>I am pretty intrigued by the record time that a qubit has survived.</p>\n", "pids": ["55a698b465ce054aad6d1632", "55a698b465ce054aad6d1632"], "flag": 1}
{"question": "Density of halting Turing machines", "body": "<p>If we enumerate all Turing machines, $T_1$, $T_2$, $T_3,\\ldots,T_n,\\ldots$,\nWhat is \n$$\\lim_{m\\to\\infty}\\frac{\\#\\{k\\mid k\\lt m \\text{ and }T_k\\text{ halts}\\}}{m}\\quad?$$</p>\n\n<p>Or does this depend on how we enumerate them ?</p>\n", "pids": ["573696016e3b12023e515b42"], "flag": 0}
{"question": "What is the leading edge technology for creating a quantum computer with the fewest errors?", "body": "<p>Which technological path seems most promising to produce a quantum processor with a greater <a href=\"https://dal.objectstorage.open.softlayer.com/v1/AUTH_039c3bf6e6e54d76b8e66152e2f87877/community-documents/quatnum-volumehp08co1vbo0cc8fr.pdf\" rel=\"nofollow noreferrer\">quantum volume</a> (preferring fewer errors per qubit over more qubits), than <a href=\"https://en.wikipedia.org/wiki/Majorana_fermion\" rel=\"nofollow noreferrer\">Majorana fermions</a>?</p>\n\n<p>The preferred format for the answer would be similar to:</p>\n\n<p>\"Group ABC's method DEF has demonstrated better QV than using MF; as proven independently in paper G on page x, paper H on page y, and paper I on page z\".</p>\n\n<p>On <a href=\"https://www.nature.com/articles/nphys4110\" rel=\"nofollow noreferrer\">Majorana fermions</a> Landry Bretheau <a href=\"https://news.mit.edu/2017/superconductors-graphene-exotic-electronic-states-quantum-computing-0505\" rel=\"nofollow noreferrer\">says</a>:</p>\n\n<blockquote>\n  <p>These particles could be the elementary brick of topological quantum computers, with very strong protection against errors. Our work is an initial step in this direction.</p>\n</blockquote>\n\n\n\n<p>Example of an insufficient (but interesting) answer:</p>\n\n<p>In their paper \"<a href=\"https://arxiv.org/abs/1405.4052\" rel=\"nofollow noreferrer\">Robust quantum metrological schemes based on protection of quantum Fisher information</a>\", Xiao-Ming Lu, Sixia Yu, and C.H. Oh construct a family of $2t+1$ qubits metrological schemes being immune to $t$-qubit errors after the signal sensing. In comparison at least five qubits are required for correcting arbitrary 1-qubit errors in standard quantum error correction.</p>\n\n<p>[Note: This theory of robust metrological schemes preserves the quantum Fisher information instead of the quantum states themselves against noise. That results in a good effective volume <strong>if</strong> they can construct a device utilizing their techniques and show that it <strong>scales</strong>.</p>\n\n<p>While that might seem like one promising answer it's a single link (without multiple concurring sources) and there's no device built to show scalability. A low qubit device that's error free and unscalable <strong>or</strong> a device with many error-prone qubits has a low volume (and thus is \"Not An Answer\").]</p>\n\n\n\n<p>Additional references:</p>\n\n<p>Paper explaining <a href=\"https://ibm.biz/BdiaQe\" rel=\"nofollow noreferrer\">Quantum Volume</a>.</p>\n\n<p><a href=\"https://i.stack.imgur.com/ekkrL.jpg\" rel=\"nofollow noreferrer\"><a src=\"https://i.stack.imgur.com/ekkrL.jpg\" alt=\"Qubits vs. Error Rate\"></a></p>\n\n<p>After doing some research it looks like Graphene sandwiched between superconductors to produce Majorana fermions is the leading edge - is there something better? [\"better\" means currently possible,  not theoretically possible or ridiculously expensive]. The graphic illustrates that over a hundred qubits with less 0.0001 error rate is wonderful,  lesser answers are acceptable.</p>\n", "pids": ["5c756863f56def97981ed8ca", "56d89b5cdabfae2eee3983d9", "5c0f7865da562944ac73feac"], "flag": 1}
{"question": "Are there any examples of anyone applying quantum algorithms to problems in computational biology?", "body": "<p>As the title suggests, I'm searching for published examples of quantum algorithms being applied to problems in computational biology. Clearly the odds are high that practical examples don't exist (yet) – what I'm interested in is any <em>proof of concepts</em>. Some examples of computational biology problems in this context would be:</p>\n<ul>\n<li>Protein Structure Prediction (Secondary, Tertiary)</li>\n<li>Drug-Ligand Binding</li>\n<li>Multiple Sequence Alignment</li>\n<li>De-novo Assembly</li>\n<li>Machine Learning Applications</li>\n</ul>\n<p>I've found only one such reference that I think is illustrative of what I'm looking for. In this research, a D-Wave was used for transcription factor binding, however, it would be interesting to have examples outside the realm of adiabatic quantum computing.</p>\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1803.00135.pdf\" rel=\"nofollow noreferrer\">Quantum annealing versus classical machine learning applied to a simplified computational biology problem</a></li>\n</ul>\n<p>There are several in terms of quantum simulation. While they clearly aren't simulations at a scale often considered to be biologically relevant, one could imagine that this line of research is a precursor to modeling larger molecules of biological significance (among many other things).</p>\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1801.03897.pdf\" rel=\"nofollow noreferrer\">Cloud Quantum Computing of an Atomic Nucleus</a></li>\n<li><a href=\"https://journals.aps.org/prx/abstract/10.1103/PhysRevX.6.031007\" rel=\"nofollow noreferrer\">Scalable Quantum Simulation of Molecular Energies</a></li>\n</ul>\n<p>So, aside from transcription factor binding and quantum simulation, are there any other proof of concepts that exist and are relevant to biology?</p>\n<p><strong>Update I:</strong> I’ve accepted the best answer so far but I’ll be checking in to see if any more examples come up. Here's another I found, somewhat old (2010), that aimed at <a href=\"https://arxiv.org/pdf/1204.5485.pdf\" rel=\"nofollow noreferrer\">demonstrating identification of low energy protein conformations in lattice protein models</a> – also a D-Wave publication.</p>\n<p><strong>Update II:</strong> A table in <a href=\"https://arxiv.org/pdf/2112.00760.pdf\" rel=\"nofollow noreferrer\">this paper</a> covers some existing applications, most using quantum annealing hardware.</p>\n", "pids": ["5d4ac1f13a55acb184527edf"], "flag": 1}
{"question": "Properties of Haar measure", "body": "<p>Let $G$ be a locally compact group (but not discrete) and let $m$ be its left Haar measure. Is it true that $\\forall \\epsilon$ $\\exists$ $C$ such that $C$ is a compact neighborhood of the identity and the measure of $C$ is less than$\\epsilon$ ?</p>\n\n<p>I have little experience working with Haar measure (basically been told to just assume that it exists) so I'm wary of weird measure theoretic pathologies.</p>\n\n<p>Moreover, if anyone could suggest a reference, it'd be much appreciated.</p>\n", "pids": ["56d856acdabfae2eee2dbc10"], "flag": 0}
{"question": "What is the minimum integer value to make quantum factorization to be worthwhile?", "body": "<p>Let us assume that we have quantum and classical computers such that, experimentally, each elementary logical operation of mathematical factorization is equally time-costing in classical and in quantum factorization:\nWhich is the lowest integer value for which the quantum proceeding is faster than the classical one?</p>\n", "pids": ["53e9bd50b7602d97049e33b3"], "flag": 1}
{"question": "Using a fractional number of classical bits within quantum teleportation", "body": "<p>Recently, I heard that there can be transfer of <em>rational</em> classical bits (for example 1.5 cbits) from one party to another via quantum teleportation. In the <a href=\"https://courses.physics.illinois.edu/phys596/fa2011/StudentWork/team10_final.pdf\" rel=\"noreferrer\">Standard Teleportation Protocol</a>, 2 classical bits and 1 maximally entangled shared resource state is required for perfect teleportation of the unknown state. But I do not understand how $1.x$ bits can be sent over in the classical channel.</p>\n\n<ol>\n<li><p>Is that possible? If yes, could you give a brief explanation?</p></li>\n<li><p>It'd be helpful if you could point me to some papers in which perfect teleportation is possible using fractional bits (and possibly extra quantum resources).</p></li>\n</ol>\n\n<p>Some people might be wondering as to how this may be relevant to quantum computing. D. Gottesman and I.L. Chuang <a href=\"https://www.nature.com/articles/46503\" rel=\"noreferrer\">suggested</a> that quantum teleportation will play an important role as a primitive subroutine in quantum computation. G. Brassard, S.L. Braunstein and R. Cleve <a href=\"https://www.sciencedirect.com/science/article/pii/S0167278998000438\" rel=\"noreferrer\">showed</a> that quantum teleportation can be understood as quantum computation.</p>\n", "pids": ["5f0e82c39fced0a24bc96a0e"], "flag": 1}
{"question": "Banach spaces over fields other than $\\mathbb{C}$?", "body": "<p>Sorry, this is a rather vague question. I was just wondering if there is any kind of theory about normed (if possible Banach) spaces over fields other than the real or complex numbers. I'm guessing that there must probably be some kind of topology or order on the field.  More precisely, the question is if there is a conventional definition of normed space over an arbitrary field and if there has been any work done about the theory of these spaces. In particular, do any of the classical theorems (uniform boundedness, Hahn-Banach, etc) carry over?</p>\n\n<p>After seeing <a href=\"http://en.wikipedia.org/wiki/Absolute_value_%28algebra%29\">http://en.wikipedia.org/wiki/Absolute_value_%28algebra%29</a> we could of course make the following rather naive definition:</p>\n\n<p>Let $V$ be a vector space over $F$, and let $|\\cdot|_F$ be a absolute value on $F$. Then a function $N:V \\to \\mathbb{R}$ is a norm if:</p>\n\n<ol>\n<li>$N(x) = 0$ iff $x = 0$</li>\n<li>$N(x + y) \\le N(x) + N(y)$</li>\n<li>$N(cx) = |c|_F N(x)$</li>\n</ol>\n\n<p>Any ideas?</p>\n\n<p>Thanks.</p>\n", "pids": ["53e99a5db7602d97022c98df", "5f0e4cc49fced0a24bf4dbf4", "53e99a5db7602d97022c9e30"], "flag": 0}
{"question": "Decomposition of a manifold", "body": "<p>As a kind of aside to <a href=\"https://math.stackexchange.com/questions/77175/decomposing-the-sphere-as-a-product\">this</a> question, where one of the answers assumed that if $S^n=X \\times Y$ then we can assume that $X$ and $Y$ are manifolds.</p>\n\n<p>If we have a manifold $M$, such that $M$ is homeomorphic to $X \\times Y$, then must $X$ and $Y$ be manifolds? The converse ($X,Y$ manifolds implies $X \\times Y$ is a manifold) is certainly true. I'd like to think it is true, but I have seen enough strange topological behaviour to suggest this may not be true. </p>\n\n<p>For this question take 'manifold' to mean a second countable Hausdorff space that is locally homeomorphic to $\\mathbb{R}^n$, for some finite $n$.</p>\n", "pids": ["53e9b4ceb7602d9703feaae5"], "flag": 1}
{"question": "Talks using just two words, such that the same thing is never said three times in a row", "body": "<p>A bit more than 20 years ago, the following exercise was assigned to a class as the Christmas holiday exercise. I did search for a while whether it was posted here earlier, and could not find it. I guess I might as well ask it as a New Year's Eve riddle here. It was in German; I hope I can translate it in such a way that its spirit is preserved. </p>\n\n<blockquote>\n  <p>Two politicians are arguing who of the two of them is able to give the longest talk, without saying the same thing three times in a row. There is a problem, however, they both do only know 2 words, namely 'but' (B) and 'if' (I). </p>\n  \n  <p>The first one begins 'B', the second one replies 'BI' which is countered by 'BIIB'. The second politician is quite bright, he simply repeats literally the last talk given by the other one, then takes that talk again but interchanges B and I and appends the result of this operation to the first talk. His opponent realizes this strategy and proceeds in the same way. So we get talks\n  <span class=\"math-container\">$$ B, B\\, I, BI\\, IB, BIIB\\, IBBI, BIIB IBBI\\, IBBIBIIB, ...$$</span>\n  That is, the <span class=\"math-container\">$k$</span>-th talk <span class=\"math-container\">$T_k$</span> has length <span class=\"math-container\">$2^{k-1}$</span> and coincides with the first half of <span class=\"math-container\">$T_{k+1}$</span>.</p>\n  \n  <p>A mathematician comes along, who has not much to contribute, either. But he solves the controversy in a mathematician's manner. He gives a talk <span class=\"math-container\">$T$</span> of infinite length, such that the first <span class=\"math-container\">$2^{k-1}$</span> words of <span class=\"math-container\">$T$</span> agree with <span class=\"math-container\">$T_k$</span>. Afterwards (!) he leaves and leaves it to the politicians to prove that in his talk he had never said the same thing three times in a row, to be more precise, nowhere in his talk <span class=\"math-container\">$T$</span> exists a segment <span class=\"math-container\">$S$</span> of finite length which occurs three times as a sequence <span class=\"math-container\">$SSS$</span> in <span class=\"math-container\">$T$</span>.</p>\n  \n  <p>How do you prove this? :-)</p>\n</blockquote>\n", "pids": ["53e99dabb7602d970266b15b"], "flag": 0}
{"question": "Is acting with a positive map on a state not part of a larger system allowed?", "body": "<p>In the comments to a <a href=\"https://quantumcomputing.stackexchange.com/questions/2047/two-notions-of-general-quantum-operators\">question</a> I asked recently, there is a discussion between <a href=\"https://quantumcomputing.stackexchange.com/users/2293/user1271772\">user1271772</a> and myself on positive operators. </p>\n\n<p>I know that for a positive trace-preserving operator $\\Lambda$ (e.g. the partial transpose) if acting on a mixed state $\\rho$ then although $\\Lambda(\\rho)$ is a valid density matrix it mucks up the density matrix of the system it is entangled to - hence this is not a valid operator.</p>\n\n<p>This and user1271772's comments, however, got me thinking. $\\Lambda$ acting on a state which is not part of a larger system does indeed give a valid density matrix and there is no associated entangled system to muck it up.</p>\n\n<p>My question is, therefore: Is such an operation allowed (i.e. the action of a positive map on a state which is not part of a larger system). If not, why not? And if so, is it true that any positive map can be extended to a completely positive map (perhaps nontrivially)?</p>\n", "pids": ["53e9bac2b7602d97046f29e5", "56d829cadabfae2eeef4acc3"], "flag": 1}
{"question": "Does the G-Spot exist?", "body": "<p>There's a lot of talk in magazines about a woman's G-Spot. </p>\n\n<p>But does it exist? Or is it a trick to keep men searching?</p>\n", "pids": ["53e9b946b7602d9704534623"], "flag": 1}
{"question": "Are there mass graves of indigenous children in Canada?", "body": "<p>In 2021 there were reports of mass graves in Canada. For instance, <a href=\"https://edition.cnn.com/2021/06/29/world/meanwhile-in-america-june-29-intl/index.html\" rel=\"noreferrer\">CNN analysis</a> quotes Indigenous peoples</p>\n<blockquote>\n<p>that tens of thousands of their children were forcibly removed from their families for decades and sent to what some described as more like &quot;concentration camps&quot; than boarding schools. More than 750 unmarked graves were discovered at one such school.</p>\n</blockquote>\n<p>and writes:</p>\n<blockquote>\n<p>School to honour the 215 children whose remains were discovered buried near the facility, in Kamloops, British Columbia, Canada, on June 4, 2021.</p>\n</blockquote>\n<p>Today (2022) The <a href=\"https://nypost.com/2022/05/27/kamloops-mass-grave-debunked-biggest-fake-news-in-canada/\" rel=\"noreferrer\">New York Post</a> is disputing the previous claims.</p>\n<blockquote>\n<p>‘Biggest fake news story in Canada’: Kamloops mass grave debunked by academics</p>\n</blockquote>\n<blockquote>\n<p>“Not one body has been found,”</p>\n</blockquote>\n<ul>\n<li>Is there evidence of mass graves near boarding schools or in Canada?</li>\n<li>If so, is there evidence of that buried are children (of indigenous origin)?</li>\n<li>If so, is there evidence that victims are due to murder or other deliberate action? (Apart from natural causes, such as disease outbreaks.)</li>\n</ul>\n", "pids": ["53e9b12ab7602d9703bab6e6"], "flag": 1}
{"question": "Who built the first quantum computer using at least two qubits?", "body": "<p>In <a href=\"https://quantumcomputing.stackexchange.com/questions/1235/who-invented-quantum-computing\">my previous question</a> I asked who invented a quantum computer using qubits.</p>\n\n<p>As a follow-up to this question I want to ask who built the first quantum computer using at least two qubits.</p>\n\n<p>During my research I have discovered that in 1998, Jonathan A. Jones and Michele Mosca <a href=\"https://arxiv.org/abs/quant-ph/9801027\" rel=\"noreferrer\">developed a quantum computer using two qubits</a> specifically to solve <a href=\"https://en.wikipedia.org/wiki/Deutsch%E2%80%93Jozsa_algorithm\" rel=\"noreferrer\">Deutsch's problem</a>. Have there been other working quantum computers before to solve other problems or general attempts not specifically bound to one problem?</p>\n", "pids": ["53e997b5b7602d9701f96149", "558a927be4b0b32fcb379a68"], "flag": 1}
{"question": "If $1\\leq p &lt; \\infty$ then show that $L^p([0,1])$ and $\\ell_p$ are not topologically isomorphic", "body": "<p>If $1\\leq p &lt; \\infty$ then show that $L^p([0,1])$ and $\\ell_p$ are not topologically isomorphic unless $p=2$.</p>\n\n<p>Maybe I would have to use the Rademacher's functions.</p>\n", "pids": ["53e9b360b7602d9703e3f4d9"], "flag": 0}
{"question": "Did H. Lebesgue claim &quot;1 is prime&quot; in 1899? Source?", "body": "<p>John Derbyshire, in his text \"Prime obsession: Bernhard Riemann and the greatest unsolved problem in mathematics\" states that </p>\n\n<blockquote>\n  <p>The last mathematician of any importance who did [consider the number 1 to be a prime] seems to be Henri Lebesgue, in 1899.</p>\n</blockquote>\n\n<p><strong>What is the source of this claim about H. Lebesgue (claiming 1 is prime in 1899)?</strong> I do not want to discuss the primality of one here, just the simple question: did H. Lebesgue make such a claim.  In 1899 he was beginning the series of articles that became his thesis on integration, perhaps primes were used as an example... Derbyshire told me he surely <em>had</em> a source, but no longer has his notes for the text.  Many web pages repeat this claim, often citing Derbyshire, and in one case Smith's History (1921, v. 1), which does not appear to mention Lebesgue at all. </p>\n\n<p>Perhaps just an error?  V.A. Lebesgue, in his 1859 \"Exercices d'analyse num\\'erique,\" listed 1 as a prime (though in articles published both before and after this, he has 2 as the first prime).  </p>\n\n<p>In 1914 D.N. Lehmer published the well known <em>List of prime numbers from 1 to 10,006,721,</em> so surely H. Lebesgue, if he made such a claim, was not the last.  So my question is simply did H. Lebesgue make such a claim in 1899?   </p>\n", "pids": ["56d89d38dabfae2eee480ecb"], "flag": 0}
{"question": "Why should faithfully flat descent preserve so many properties?", "body": "<p>This question is based on the following proposition (EGA IV, 2.7.1)</p>\n\n<p>Let $f: X \\rightarrow Y$ be a $S$-morphism of $S$-schemes, $g: S'\\rightarrow S$ a faithfully flat and quasi-compact morphism. Denote $X \\times_S S'$ by $X'$, and denote $Y \\times_S S'$ by $Y.$ We have a natural morphism $f': X\\rightarrow Y.$ Consider the following properties of morphisms:</p>\n\n<p>(i) separated</p>\n\n<p>(ii) quasiseparated</p>\n\n<p>(iii) locally of finite type</p>\n\n<p>(iv) locally of finite presentation</p>\n\n<p>(v) finite type</p>\n\n<p>(vi) finite presentation</p>\n\n<p>(vii) proper</p>\n\n<p>(viii) isomorphism</p>\n\n<p>(ix) monomorphism</p>\n\n<p>(x) open immersion</p>\n\n<p>(xi) quasi-compact immersion</p>\n\n<p>(xii) closed immersion</p>\n\n<p>(xiii) affine</p>\n\n<p>(xiv) quasi-affine</p>\n\n<p>(xv) finite</p>\n\n<p>(xvi) quasi-finite</p>\n\n<p>(xvii) entire (I'm not sure exactly what a \"morphisme entier\" is, but some reading of the french wikipedia gave me the impression that it's an integral morphism)</p>\n\n<p>If $P$ is one of the preceding properties, then $f$ has property $P$ if and only if $f'$ has property $P.$</p>\n\n<p>My impression of the proof is that there are quite a few ingredients needed to prove this proposition, where different ingredients are needed for different properties, and it surprises me that there seems to be no \"unifying principle\" that covers all the proofs.</p>\n\n<p>What I would like is something like this theorem: Let $P$ be a property closed under composition and base change. Then, if $f:X \\rightarrow Y$ is a map of $Z$-schemes, such that the structure morphism $X \\rightarrow Z$ is in $P$ and the diagonal morphism of the structure morphism $Y \\rightarrow Z$ is in $P$, then $f$ is in $P$. I like this theorem because it explicitly states the conditions the property needs to satisfy, and the conditions are fairly loose. Then, you have essentially the same proof of this theorem for every such property $P$.</p>\n\n<p>Is there any such unification of the proofs for this result? To me, it seems like this result is some incredibly mysterious miracle. I would appreciate any intuition behind this result.</p>\n", "pids": ["53e99e4db7602d9702712255"], "flag": 0}
{"question": "Quantum algorithm for linear systems of equations (HHL09): Step 1 - Confusion regarding the usage of phase estimation algorithm", "body": "<p>I have been trying to get my head around the famous(?) paper <a href=\"https://arxiv.org/abs/0811.3171\" rel=\"noreferrer\"><strong>Quantum algorithm for linear systems of equations (Harrow, Hassidim &amp; Lloyd, 2009)</strong></a> (more popularly known as the <strong>HHL09 algorithm</strong> paper) for some time, now.</p>\n\n<p><strong>On the very first page, they say</strong>: </p>\n\n<blockquote>\n  <p>We sketch here the basic idea of our algorithm and then discuss it in\n  more detail in the next section. Given a Hermitian $N\\times N$ matrix\n  $A$, and a unit vector $\\vec{b}$, suppose we would like to find\n  $\\vec{x}$ satisfying $A\\vec{x} = \\vec{b}$. (We discuss later questions\n  of efficiency as well as how the assumptions we have made about $A$\n  and $\\vec{b}$ can be relaxed.)  First, the algorithm represents\n  $\\vec{b}$ as a quantum state $|b\\rangle = \\sum_{i=1}^{N}b_i|i\\rangle$.\n  Next, we use techniques of Hamiltonian simulation [3, 4] to apply\n  $e^{iAt}$ to $|b_i\\rangle$ for a superposition of different times $t$.\n  This ability to exponentiate $A$ translates, via the well-known\n  technique of  phase-estimation [5–7] into the ability to decompose $|b\\rangle$\n  in the eigenbasis of $A$ and to find the corresponding eigenvalues\n   $\\lambda_j$ Informally, the state of the system after\n  this stage is close to $\\sum_{j=1}^{j=N} \\beta_j\n |u_j\\rangle|\\lambda_j\\rangle$, where $u_j$ is the eigenvector basis of\n  $A$ and $|b\\rangle = \\sum_{j=1}^{j=N} \\beta_j|u_j\\rangle$.</p>\n</blockquote>\n\n<p>So far so good. As described in <a href=\"https://rads.stackoverflow.com/amzn/click/1107002176\" rel=\"noreferrer\"><strong>Nielsen &amp; Chuang</strong></a> in the chapter \"<strong>The quantum Fourier transform and its applications</strong>\", the phase estimation algorithm is used to estimate $\\varphi$ in $e^{i2\\pi \\varphi}$ which is the eigenvalue corresponding to an eigenvector $|u\\rangle$ of the unitary operator $U$. </p>\n\n<p><strong>Here's the relevant portion from Nielsen &amp; Chuang:</strong></p>\n\n<blockquote>\n  <p>The phase estimation algorithm uses two registers. The first register\n  contains $t$ qubits initially in the state $|0\\rangle$. How we choose\n   $t$ depends on two things: the number of digits of accuracy we wish to\n  have in our estimate for $\\varphi$, and with what probability we wish the\n  phase estimation procedure to be successful. The dependence of $t$ on\n  these quantities emerges naturally from the following analysis.</p>\n  \n  <p>The second register begins in the state $|u\\rangle$ and contains as\n  many qubits as is necessary to store $|u\\rangle$. Phase estimation is\n  performed in two stages. First, we apply the circuit shown in Figure\n  5.2. The circuit begins by applying a Hadamard transform to the first register, followed by application of controlled - $U$ operations on\n  the second register, with $U$ raised to successive powers of two. The\n  final state of the first register is easily seen to be:</p>\n  \n  <p>$$\\frac{1}{2^{t/2}}\\left(|0\\rangle+\\text{exp}(2\\pi i\n 2^{t-1}\\varphi)|1\\rangle)(|0\\rangle+\\text{exp}(2\\pi i\n 2^{t-2}\\varphi)|1\\rangle)...(|0\\rangle+\\text{exp}(2\\pi i\n 2^{0}\\varphi)|1\\rangle\\right)=\n \\frac{1}{2^{t/2}}\\sum_{k=0}^{2^{t}-1}\\text{exp}(2\\pi i \\varphi\n k)|k\\rangle$$</p>\n  \n  <p><a href=\"https://i.stack.imgur.com/qPhh0.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/qPhh0.png\" alt=\"enter image description here\"></a></p>\n  \n  <p>The second stage of phase estimation is to apply the inverse quantum\n  Fourier transform on the first register. This is obtained by reversing\n  the circuit for the quantum Fourier transform in the previous section\n  (Exercise 5.5) and can be done in $\\Theta (t^2)$ steps. The third and\n  final stage of phase estimation is to read out the state of the first\n  register by doing a measurement in the computational basis. We will\n  show that this provides a pretty good estimate of $\\varphi$. An\n  overall schematic of the algorithm is shown in Figure 5.3.</p>\n  \n  <p>To sharpen our intuition as to why phase estimation works, suppose $\\varphi$\n  may be expressed exactly int bits, as $\\varphi = 0.\\varphi_1 ...\n \\varphi_t$. Then the state (5.20) resulting from the first stage of\n  phase estimation may be rewritten</p>\n  \n  <p>$$\\frac{1}{2^{t/2}}(|0\\rangle + \\exp(2\\pi i\n 0.\\varphi_t|1\\rangle)(|0\\rangle + \\exp(2\\pi i 0.\\varphi_{t-1}\\varphi_t|1\\rangle)...(|0\\rangle + \\exp(2\\pi i 0.\\varphi_1...\\varphi_t|1\\rangle)$$</p>\n  \n  <p>The second stage of phase estimation is to apply the inverse quantum\n  Fourier transform. But comparing the previous equation with the\n  product form for the Fourier transform, Equation (5.4), we see that\n  the output state from the second stage is the product state\n   $|\\varphi_1 ...\\varphi_t\\rangle$. A measurement in the computational\n  basis, therefore, gives us $\\varphi$ exactly!</p>\n  \n  <p><a href=\"https://i.stack.imgur.com/9hDwn.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/9hDwn.png\" alt=\"enter image description here\"></a></p>\n  \n  <p>Summarizing, the phase estimation algorithm allows one to estimate the\n  phase $\\varphi$ of an eigenvalue of a unitary operator $U$, given the\n  corresponding eigenvector $|u\\rangle$. An essential feature at the\n  heart of this procedure is the ability of the inverse Fourier\n  transform to perform the transformation</p>\n  \n  <p>$$\\frac{1}{2^{t/2}}\\sum_{j = 0}^{2^t-1}\\exp(2\\pi i \\varphi j)|j\\rangle |u\\rangle \\to |\\tilde \\varphi \\rangle |u\\rangle$$</p>\n</blockquote>\n\n<p>Let's proceed from here. I found a nice <em>circuit diagram</em> for the <strong>HHL09 algorithm</strong> <a href=\"https://arxiv.org/abs/1612.02886v2\" rel=\"noreferrer\">here</a><sup>[$\\dagger$]</sup>:</p>\n\n<p><a href=\"https://i.stack.imgur.com/nEmvl.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/nEmvl.png\" alt=\"enter image description here\"></a></p>\n\n<h2>Step 1 (Phase Estimation):</h2>\n\n<p>In the first step of the <strong>HHL09 algorithm</strong> the same concept (of the standard Quantum Phase Estimation algorithm as described in Nielsen and Chuang) is used. However, we must keep in mind that $A$ by itself isn't a unitary operator. However, if we assume that $A$ is Hermitian then the exponential $e^{iAt}$ is unitary (no worries, there's exists a workaround in case $A$ isn't Hermitian!).  </p>\n\n<p>Here, we can write $U=e^{iAt}$. There's another subtle point involved here. We <em>do not</em> know the eigenvectors $|u_j\\rangle$ of $U$ beforehand (but we <em>do know</em> that for any unitary matrix of size $N\\times N$ there exist $N$ orthonormal eigenvectors). Moreover, we need to remind ourselves that if the eigenvalues of $A$ are $\\lambda_j$ then the eigenvalues of $e^{iAt}$ will be $e^{i \\lambda_j t}$. If we compare this with the form of eigenvalues given in Nielsen and Chuang for $U$ i.e. if  $e^{2\\pi i \\varphi} \\equiv e^{ i \\lambda_j t}$, we'd find $\\varphi = \\frac{\\lambda_j t}{2\\pi}$. In this case, we begin in the state $|b\\rangle$ (which can be written as a superposition of the eigenvectors of $U$ i.e. $\\sum_{j=1}^{j=N}\\beta_j|u_j\\rangle$) rather than any particular eigenvector $|u_j\\rangle$ of $U$, as far as the second register of qubits is concerned. If we had begun in the state $|u\\rangle \\otimes (|0\\rangle)^{\\otimes t}$ we would have ended up with $|u\\rangle \\otimes |\\tilde\\varphi\\rangle$ i.e. $|u_j\\rangle \\otimes |\\tilde{\\frac{\\lambda_j t}{2\\pi}}\\rangle$ (considering that $\\lambda_j$ is the eigenvalue associated with the eigenvector $|u_j\\rangle$ of $A$). Now, instead if we begin in the superposition of eigenvectors $\\sum_{j=1}^{j=N}\\beta_j|u_j\\rangle$ we should end up with $\\sum_{j=1}^{j=N}\\beta_j|u_j\\rangle\\otimes |\\tilde{\\frac{\\lambda_j t}{2\\pi}}\\rangle$. </p>\n\n<h2><strong>Question:</strong></h2>\n\n<p><strong>Part 1</strong>: In the <strong>HHL09 paper</strong>, they wrote about the state of the system after this Phase Estimation step is $\\sum_{j=1}^{j=N}\\beta_j|u_j\\rangle\\otimes |\\tilde\\lambda_j\\rangle$. However, from what I wrote above it seems to me that the state of the system should rather be $\\sum_{j=1}^{j=N}\\beta_j|u_j\\rangle\\otimes |\\tilde{\\frac{\\lambda_j t}{2\\pi}}\\rangle$. </p>\n\n<p><strong>What am I missing here? Where did the factor of $\\frac{t}{2\\pi}$ vanish in their algorithm?</strong></p>\n\n<p><strong>Edit:</strong> <strong>Part 2</strong> has been asked <a href=\"https://quantumcomputing.stackexchange.com/questions/2390/quantum-algorithm-for-linear-systems-of-equations-hhl09-step-1-number-of-qu\">here</a> to make the individual questions more focused.</p>\n\n\n\n<p><sup>I also have several confusions regarding Step 2 and Step 3 of the HHL09 algorithm too, but I decided to post them as separate question threads, as this one is becoming too long. I'll add the links to those question threads, on this post, once they are created.</sup></p>\n\n<p>[$\\dagger$]: <em>Homomorphic Encryption Experiments on IBM's Cloud Quantum Computing Platform</em> Huang et al. (2016)</p>\n", "pids": ["5ac1829d17c44a1fda917e53", "55a68aca65ce054aad6b1847", "5488ea7645ce471f9091987e", "56d91049dabfae2eee370d7e"], "flag": 1}
{"question": "Is it possible to assign a value to the sum of primes?", "body": "<p>It is <a href=\"http://en.wikipedia.org/wiki/1_%2B_2_%2B_3_%2B_4_%2B_%C2%B7_%C2%B7_%C2%B7\" rel=\"nofollow noreferrer\">possible</a>, by means of zeta function regularization and the Ramanujan summation method, to assign a finite value to the sum of the natural numbers (here <span class=\"math-container\">$n \\to \\infty $</span>) :</p>\n\n<p><span class=\"math-container\">$$ 1 + 2 + 3 + 4 + \\cdots + n \\; {“ \\;=\\; ”} - \\frac{1}{12} . $$</span></p>\n\n<p>Is it also possible to assign a value to the sum of primes, <span class=\"math-container\">$$ 2 + 3 + 5 + 7 + 11 + \\cdots + p_{n}  $$</span> (<span class=\"math-container\">$n \\to \\infty$</span>)\nby using any summation method for divergent series?</p>\n\n<p>This question is inspired by a <a href=\"http://www.quora.com/What-is-the-sum-of-all-primes?q=divergent+series+primes\" rel=\"nofollow noreferrer\">question on quora</a>.</p>\n\n<p>Thanks in advance, </p>\n", "pids": ["60531d4191e011547ddf5453"], "flag": 0}
{"question": "Has error correction been &quot;solved&quot;?", "body": "<p>I recently came across Dan Piponi's blog post <em><a href=\"http://blog.sigfpe.com/2006/02/end-to-coding-theory.html\">An End to Coding Theory</a></em> and it left me very confused. The relevant portion is:</p>\n\n<blockquote>\n  <p>But in the sixties Robert Gallager looked at generating random sparse syndrome matrices and found that the resulting codes, called Low Density Parity Check (LDPC) codes, were good in the sense that they allowed messages to be transmitted at rates near the optimum rate found by Shannon - the so-called Shannon limit. Unfortunately the computers of the day weren't up to the task of finding the most likely element of M from a given element of C. But now they are. We now have near-optimal error correcting codes and the design of these codes is ridiculously simply. There was no need to use exotic mathematics, random matrices are as good as almost anything else. The past forty years of coding theory has been, more or less, a useless excursion. Any further research in the area can only yield tiny improvements.</p>\n</blockquote>\n\n<p>In summary, he states that the rate of LDPC codes is very near channel capacity—so near that further improvements would not be worth the while.</p>\n\n<p>So, my question is: What does modern research in error-correcting codes entail? I noticed that Dan did not mention <em>what</em> channel the rate of LDPC codes approach the capacity of, so maybe there exist channels that LDPC codes don't work well on? What other directions does modern research in the field explore?</p>\n", "pids": ["5d64ff713a55acf547f20d1b"], "flag": 0}
{"question": "What are the possible ways to visualise large, entangled states?", "body": "<p>What are the prominent visualizations used to depict large, entangled states and in what context are they most commonly applied?</p>\n<p>What are their advantages and disadvantages?</p>\n", "pids": ["5c7574c5f56def9798980c9c", "53e99f4fb7602d9702821d9b", "53e9b3fcb7602d9703eec388", "5c756d50f56def9798516077", "53e99ffcb7602d97028df582"], "flag": 1}
{"question": "Is the &quot;Quantum Volume&quot; a fair metric for future, elaborate, high value quantum computations?", "body": "<p>A metric called the \"quantum volume\" has been proposed to somehow compare the utility of different quantum computing hardware. Roughly speaking, it measures their worth by the square of the maximum depth of quantum computations it permits but limits its value to the square of the qubits involved. This limit is justified by wanting to forestall \"gaming\" of the system by optimizing towards few qubits. One reference is <a href=\"https://arxiv.org/abs/1710.01022\" rel=\"noreferrer\">https://arxiv.org/abs/1710.01022</a>.</p>\n\n<p>I am concerned that this measure, as good as it may be for noisy near-term quantum computing devices, hides the actual quality advances for more advanced quantum computers (those with high quantum gate fidelity). The question is: Is this concern justified?</p>\n\n<p>The argument behind my concern is the assumption that potential killer applications for quantum computers, for example quantum chemical calculations, will require computations with a gate depth much larger than the (potentially modest) number of qubits required. In this case, the \"quantum volume\" would be limited to the square of the number of qubits, regardless of whether one quantum computer (with particularly high fidelity) permits an essentially unlimited depth or whether it only allows the bare minimum gate depth to achieve the limitation of the \"quantum volume\" to the square of the number of qubits. One aspect of my question is: Is this argument correct?</p>\n", "pids": ["595ce32c0cf2a2b6d11f00d3"], "flag": 1}
{"question": "Automatic compilation of quantum circuits", "body": "<p>A recent question here asked how to compile the 4-qubit gate CCCZ (controlled-controlled-controlled-Z) into simple 1-qubit and 2-qubit gates, and the only answer given so far <a href=\"https://quantumcomputing.stackexchange.com/a/4081/2293\">requires 63 gates</a>! </p>\n\n<p>The first step was to use the C$^n$U construction given by Nielsen &amp; Chuang:</p>\n\n<p><a src=\"https://i.stack.imgur.com/Wi9FAm.png\" width=\"400\" /></p>\n\n<p>With $n=3$ this means 4 CCNOT gates and 3 simple gates (1 CNOT and 2 Hadamards is enough to do the final CZ on the target qubit and the last work qubit).</p>\n\n<p><a href=\"https://dl.acm.org/citation.cfm?id=2011799\" rel=\"noreferrer\">Theorem 1 of this paper</a>, says that in general the CCNOT requires 9 one-qubit and 6 two-qubit gates (15 total):</p>\n\n<p><a href=\"https://i.stack.imgur.com/GRfPe.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/GRfPe.png\" alt=\"enter image description here\"></a></p>\n\n\n\n<p><strong><em>This means:</em></strong></p>\n\n<p>(4 CCNOTs) x (15 gates per CCNOT) + (1 CNOT) + (2 Hadamards) = <strong>63 total gates</strong>.</p>\n\n<p>In a <a href=\"https://quantumcomputing.stackexchange.com/questions/4078/how-to-construct-a-multi-qubit-controlled-z-from-elementary-gates/4081#comment4442_4081\">comment</a>, it has been suggested the 63 gates can be then further compiled using an \"automatic procedure\", for example from the theory of <a href=\"https://en.wikipedia.org/wiki/Automatic_group\" rel=\"noreferrer\">automatic groups</a>. </p>\n\n<p><strong><em>How can this \"automatic compilation\" be done, and how much would it reduce the number of 1-qubit and 2-qubit gates in this case?</em></strong></p>\n", "pids": ["53e9aeb7b7602d97038d98cb"], "flag": 1}
{"question": "Does the quantum coherence in the FMO complex have any significance to quantum computing (on a biological substrate)?", "body": "<p>The quantum effects of the FMO complex (photosynthetic light harvesting complex found in green sulfur bacteria) have been well studied as well as the quantum effects in other photosynthetic systems. One of the most common hypotheses for explaining these phenomenon (focusing on FMO complex) is Environment-Assisted Quantum Transport (ENAQT) originally described by <a href=\"https://arxiv.org/abs/0807.0929\" rel=\"nofollow noreferrer\">Rebentrost et al.</a>. This mechanism describes how certain quantum networks can \"use\" decoherence and environment effects to improve the efficiency of quantum transport. Note that the quantum effectss arise from the transport of <em>excitons</em> from one pigment (chlorophyll) in the complex to another. (There is a <a href=\"https://quantumcomputing.stackexchange.com/questions/1854/quantum-simulation-of-environment-assisted-quantum-walks-in-photosynthetic-energ\">question</a> that discusses the quantum effects of the FMO complex in a little more detail).</p>\n\n<p>Given that this mechanism allows for quantum effects to take place at room temperatures without the negative effects of decoherence, <strong>are their any applications for quantum computing?</strong> There are some examples of artificial systems that utilize ENAQT and related quantum effects. However, they present biomimetic solar cells as a potential application and do not focus on the applications in quantum computing.</p>\n\n<p>Originally, it was <a href=\"https://www.nature.com/articles/nature05678\" rel=\"nofollow noreferrer\">hypothesized</a> that the FMO complex performs a Grover's search algorithm, however, from what I understand, it has now since been showed that this is not true.</p>\n\n<p>There have been a couple studies that use chromophores and substrates not found in biology (will add references later). However, I would like to focus on <strong>systems that use a biological substrate.</strong></p>\n\n<p>Even for biological substrates there are a couple examples of <em>engineered</em> systems that use ENAQT. For example, a <a href=\"https://www.nature.com/articles/nmat4448#methods\" rel=\"nofollow noreferrer\">virus-based system</a> was developed using genetic engineering. A <a href=\"https://www.nature.com/articles/nmat5033\" rel=\"nofollow noreferrer\">DNA-based excitonic circuit</a> was also developed. However, most of these examples present photovoltaics as a main example and not quantum computing.</p>\n\n<p><a href=\"https://arxiv.org/abs/1311.4688\" rel=\"nofollow noreferrer\">Vattay and Kauffman</a> was (AFAIK) the first to study the quantum effects as quantum biological computing, and proposed a method of engineering a system similar to the FMO complex for quantum computing.</p>\n\n<blockquote>\n  <p>How could we use this mechanism to build new types of computers? In\n  the light harvesting case the task of the system is to transport the\n  exciton the fastest possible way to the reaction center whose position\n  is known. In a computational task we usually would like to find the\n  minimum of some complex function $f_n$. For the simplicity let this\n  function have only discrete values from 0 to K. If we are able to map\n  the values of this function to the electrostatic site energies of the\n  chromophores $H_{nn} = \\epsilon_0 f_n$ and we deploy reaction centers\n  near to them trapping the excitons with some rate $κ$ and can access\n  the current at each reaction center it will be proportional with the\n  probability to find the exciton on the chromophore $j_n ∼ κ\\rho_{nn}$.</p>\n</blockquote>\n\n\n\n<p>How can the quantum effects of the FMO complex be used on a biological substrate for quantum computing? Given that the quantum effects occur due to the transport of excitons on network structures, could ENAQT provide more efficient implementations of network-based algorithms (ex: shortest path, traveling salesman, etc.)?</p>\n\n\n\n<p>P.S. I will add more relevant references if needed. Also, feel free to add relevant references as well.</p>\n", "pids": ["53e9bc8fb7602d970490e418", "53e9bd64b7602d97049ff93e"], "flag": 1}
{"question": "Efficient computation of $\\sum_{k=1}^n \\left\\lfloor \\frac{n}{k}\\right\\rfloor$", "body": "<p>I realize that there is probably not a closed form, but is there an efficient way to calculate the following expression?</p>\n\n<p><span class=\"math-container\">$$\\sum_{k=1}^n \\left\\lfloor \\frac{n}{k}\\right\\rfloor$$</span></p>\n\n<p>I've noticed <span class=\"math-container\">$$\\sum_{k=1}^n \\left\\lfloor \\frac{n}{k}\\right\\rfloor = \\left\\lfloor\\frac{1}{2}\\sum_{k=1}^{\\left\\lfloor\\frac{n}{2}\\right\\rfloor} \\left\\lfloor\\frac{n}{k}\\right\\rfloor\\right\\rfloor + \\sum_{k=1,\\ odd(k)}^n \\left\\lfloor \\frac{n}{k}\\right\\rfloor$$</span></p>\n\n<p>But I can't see an easy way to let the second term enter in a recursion.</p>\n", "pids": ["56d88a03dabfae2eeeae4660", "53e9ab9eb7602d9703546c98"], "flag": 0}
{"question": "Two worlds collide: Using ML for complex survey data", "body": "<p>I am struck with seemingly easy problem, but I haven't found a suitable solution for several weeks now.</p>\n<p>I have quite a lot of poll/survey data (tens of thousands of respondents, say 50k per dataset), coming from something I hope is called complexly designed survey with weights, stratification, specific routing and so on. For each respondents, there are hundreds of variables such as demographics (age, region...) and then mostly binary (at most, categorical) variables.</p>\n<p>I come more from computer science/machine learning background and I had to learn a lot about <em>classical survey statistics</em> and methodology. Now I want to apply <em>classical machine learning</em> to those data (e.g. predicting some missing values for subset of respondents - basically classification task). But, hold and behold, I cannot find a suitable way how to do that. How should I incorporate those stratas, weights or routing (like: if question 1 answered with option 2, ask question 3, otherwise skip it)?</p>\n<p>Simply applying my models (trees, logistic regression, SVM, XGBoost...) seems dangerous (and, they fail in most cases), since they usually assume data are coming from simple random sample or iid.</p>\n<p>A lot of methods at least have weights, but it doesn't help much. Furthermore, it is unclear how I should I combine imbalanced classes and weights given by survey definition together, not talking about those stratification stuff. Furthermore, result models should be well calibrated - the predicted distribution should be very close to the original one. Good performance of prediction isn't the only criteria here. I changed the optimisation metric to take into account this as well (such as <em>distance</em> of predicted distribution from the true distribution + accuracy/MCC) and it helped in some cases, why crippling the performance in others.</p>\n<p>Is there some canonical way how to deal with this problem? It seems as a heavily underappreciated area of research for me. IMO many surveys could benefit from ML's power, but there are no sources. Like these are two worlds not interacting with each other.</p>\n<p>What I have found so far:</p>\n<ul>\n<li><a href=\"http://civilstat.com/2014/08/statistical-modeling-the-two-cultures-breiman/\" rel=\"nofollow noreferrer\">http://civilstat.com/2014/08/statistical-modeling-the-two-cultures-breiman/</a></li>\n</ul>\n<blockquote>\n<p>For instance, I still know of only one paper (Toth &amp; Eltinge, 2011) on how to do regression trees when your data come from a complex sample survey.</p>\n</blockquote>\n<ul>\n<li><a href=\"https://ccsg.isr.umich.edu/chapters/introduction-to-statistical-analysis/#nine\" rel=\"nofollow noreferrer\">https://ccsg.isr.umich.edu/chapters/introduction-to-statistical-analysis/#nine</a></li>\n</ul>\n<blockquote>\n<p>In a recent meta-analysis of 150 sampled research papers analyzing several surveys with complex sampling designs, it is found that analytic errors caused by ignorance or incorrect use of the complex sample design features were frequent.</p>\n</blockquote>\n<ul>\n<li><a href=\"https://www.fhwa.dot.gov/2015datapalooza/presentations/PolicyDev.4_Pierce.pdf\" rel=\"nofollow noreferrer\">https://www.fhwa.dot.gov/2015datapalooza/presentations/PolicyDev.4_Pierce.pdf</a></li>\n</ul>\n<p>Related CV questions, but none of them contains any usable answer how to approach this (either no answer, not what I ask for, or present misleading recommendations):</p>\n<ul>\n<li><a href=\"https://stats.stackexchange.com/questions/24251/matched-analysis-with-complex-survey-data\">Matched Analysis with Complex Survey Data</a></li>\n<li><a href=\"https://stats.stackexchange.com/questions/102812/machine-learning-with-weighted-complex-survey-data\">Machine learning with weighted / complex survey data</a></li>\n<li><a href=\"https://stats.stackexchange.com/questions/211715/cross-validation-after-lasso-in-complex-survey-data\">Cross validation after LASSO in complex survey data</a></li>\n<li><a href=\"https://stats.stackexchange.com/questions/62175/separation-in-logistic-regression-in-a-complex-survey\">Separation in logistic regression in a complex survey?</a></li>\n<li><a href=\"https://stats.stackexchange.com/questions/89204/fitting-multilevel-models-to-complex-survey-data-in-r\">Fitting multilevel models to complex survey data in R</a></li>\n</ul>\n", "pids": ["5fd8aa9a91e0119b22c1f35a", "5f0d8dda91e011047aff9984", "619bad811c45e57ce9e83739", "56d85f97dabfae2eee71a8fe"], "flag": 1}
{"question": "Prove $\\gamma_1\\left(\\frac34\\right)-\\gamma_1\\left(\\frac14\\right)=\\pi\\,\\left(\\gamma+4\\ln2+3\\ln\\pi-4\\ln\\Gamma\\left(\\frac14\\right)\\right)$", "body": "<p>Please help me to prove this identity:\n$$\\gamma_1\\left(\\frac{3}{4}\\right)-\\gamma_1\\left(\\frac{1}{4}\\right)=\\pi\\,\\left(\\gamma+4\\ln2+3\\ln\\pi-4\\ln\\Gamma\\left(\\frac{1}{4}\\right)\\right),$$\nwhere $\\gamma_n(a)$ is a <a href=\"http://mathworld.wolfram.com/StieltjesConstants.html\">generalized Stieltjes constant</a> and $\\gamma$ is the <a href=\"http://mathworld.wolfram.com/Euler-MascheroniConstant.html\">Euler-Mascheroni constant</a>.</p>\n", "pids": ["56d81ec1dabfae2eeead01cb", "53e9b181b7602d9703c0cfed"], "flag": 0}
{"question": "Approximating unitary matrices", "body": "<p>I currently have 2 unitary matrices that I want to approximate to a good precision with the fewer quantum gates possible.</p>\n\n<p>In my case the two matrices are:</p>\n\n<ul>\n<li>The square root of NOT gate (up to a global phase)\n<span class=\"math-container\">$$G = \\frac{-1}{\\sqrt{2}}\\begin{pmatrix} i &amp; 1 \\\\ 1 &amp; i \\end{pmatrix} = e^{-\\frac{3}{4}\\pi} \\sqrt{X}$$</span></li>\n<li><span class=\"math-container\">$$W = \n\\begin{pmatrix} \n1&amp;0&amp;0&amp;0\\\\\n0&amp;\\frac{1}{\\sqrt{2}}&amp;\\frac{1}{\\sqrt{2}}&amp;0\\\\\n0&amp;\\frac{1}{\\sqrt{2}}&amp;\\frac{-1}{\\sqrt{2}}&amp;0\\\\\n0&amp;0&amp;0&amp;1 \\\\\n\\end{pmatrix}$$</span></li>\n</ul>\n\n<p>My question is the following: </p>\n\n<blockquote>\n  <p>How can I approximate these specific matrices with the fewer quantum gates possible and a good precision?</p>\n</blockquote>\n\n<p>What I want to have an can afford to have it:</p>\n\n<ol>\n<li>I can afford to use several days/weeks of CPU time and a <strong>lot</strong> of RAM.</li>\n<li>I can afford to spend 1 or 2 human days searching for mathematical tricks (in last resort, that is why I ask here first). This time does not include the time I would need to implement the hypothetical algorithms used for the first point.</li>\n<li>I want the decomposition to be nearly exact. I don't have a target precision at the moment, but the 2 gates above are used extensively by my circuit and I don't want errors to accumulate too much. </li>\n<li>I want the decomposition to use the fewest quantum gates possible. This point is secondary for the moment.</li>\n<li>A good method would let me choose the trade-off I want between the number of quantum gates and the precision of the approximation. If this is not possible, an accuracy of at least <span class=\"math-container\">$10^{-6}$</span> (in terms of trace norm) is probably (as said before, I do not have estimates so I am not sure of this threshold) required.</li>\n<li>The gate set is:\n<span class=\"math-container\">$$\n\\left\\{ H, X, Y, Z, R_\\phi, S, T, R_x, R_y, R_z, \\text{CX}, \\text{SWAP}, \\text{iSWAP}, \\sqrt{\\text{SWAP}} \\right\\}\n$$</span>\nwith <span class=\"math-container\">$R_\\phi, \\text{SWAP}, \\sqrt{\\text{SWAP}}$</span> as described in <a href=\"https://en.wikipedia.org/wiki/Quantum_logic_gate\" rel=\"nofollow noreferrer\">Wikipédia</a>, <span class=\"math-container\">$R_A$</span> the rotation with respect to the axe <span class=\"math-container\">$A$</span> (<span class=\"math-container\">$A$</span> is either <span class=\"math-container\">$X$</span>, <span class=\"math-container\">$Y$</span> or <span class=\"math-container\">$Z$</span>) and \n<span class=\"math-container\">$$\\text{iSWAP} = \\begin{pmatrix}   1 &amp; 0 &amp; 0 &amp; 0  \\\\\n  0 &amp; 0 &amp; i &amp; 0  \\\\\n  0 &amp; i &amp; 0 &amp; 0  \\\\\n  0 &amp; 0 &amp; 0 &amp; 1  \\\\ \\end{pmatrix}$$</span>.</li>\n</ol>\n\n<p>The methods I know about:</p>\n\n<ol>\n<li>The Solovay-Kitaev algorithm. I have an implementation of this algorithm and already tested it on several unitary matrices. The algorithm generates sequences that are quite long and the trade-off [number of quantum gates] VS [precision of the approximation] is not enough parametrisable. Nevertheless, I will execute the algorithm on these gates and edit this question with the results I obtained.</li>\n<li>Two papers on <a href=\"https://arxiv.org/abs/1212.6253\" rel=\"nofollow noreferrer\">1-qubit gate approximation</a> and <a href=\"https://arxiv.org/abs/1212.0506\" rel=\"nofollow noreferrer\">n-qubit gate approximation</a>. I also need to test these algorithms.</li>\n</ol>\n\n<p>EDIT: edited the question to make \"square root of not\" more apparent.</p>\n", "pids": ["56d8929ddabfae2eeef4461f"], "flag": 1}
{"question": "Quantum Supremacy: How do we know that a better classical algorithm doesn&#39;t exist?", "body": "<p>According to the Wikipedia (Which quotes this paper <a href=\"https://arxiv.org/abs/1203.5813\" rel=\"noreferrer\">https://arxiv.org/abs/1203.5813</a> by Preskill) the definition of Quantum Supremacy is</p>\n\n<blockquote>\n  <p>Quantum supremacy or quantum advantage is the potential ability of\n  quantum computing devices to solve problems that classical computers\n  practically cannot.</p>\n</blockquote>\n\n<p>On that same paper, Preskill says that a more feasible approach would be to find Quantum Systems that a quantum computer can simulate in polynomic time while a classical computer can't. </p>\n\n<p>My question is: Would that situation be enough to prove Quantum Supremacy? How do we know no better classical algorithm exist? Maybe there is a efficient way of simulating that system but we don't know it yet. If this is the case, then proving quantum supremacy is more about proving rigorously that a problem is classically hard than about finding that it is quantumly easy, right?</p>\n", "pids": ["53e9a516b7602d9702e3bc4b", "5c75750af56def97989af622"], "flag": 1}
{"question": "Class group and factorizations", "body": "<p>There is a common characterization of the class group ${\\rm Cl}(R)$ as a kind of measure of how badly factorization fails to be unique. The most obvious justification for this sentiment is that the order of the class group of $R$ determines if it has unique factorization or not:</p>\n\n<p>$$h=1\\quad\\Leftrightarrow\\quad {\\rm PID}\\quad \\Rightarrow \\quad {\\rm UFD}. \\tag{$\\star$}$$</p>\n\n<p>This is very unsatisfying though because the exact size of $h$ (not even to mention all of the <em>group structure</em> that ${\\rm Cl}(R)$ has in general) is not used, and \"UFD / not UFD\" doesn't in any sense <em>measure</em> the extent to which $R$ fails to be a UFD, only <em>if</em> it does. Plus, the converse, UFD $\\Rightarrow$ PID, is specific to when $R$ is Dedekind, so this is only a partial justification.</p>\n\n<p>There are a number of answers exposing specific ideas in <a href=\"https://math.stackexchange.com/questions/178783/how-does-a-class-group-measure-the-failure-of-unique-factorization\">How does a class group measure the failure of unique factorization?</a> (which is basically my question here, but I am resurrecting it because I am not satisfied) and <a href=\"https://mathoverflow.net/questions/10934/class-number-measuring-the-failure-of-unique-factorization\">Class number measuring failure of unique factorization</a> at MO.</p>\n\n<p>PLC and BD cite Carlitz ($h=2$ iff factorization lengths are invariant), PLC notes that $h$ can yield arithmetic obstructions to certain paths like in FLT, and BD cites a theorem of Kaczorowski which goes from factorization information to an exact isomorphism class characterization of the class group (which is reverse of the desired order: going from class group to factorization information).</p>\n\n<p>Kevin has the strongest skeptical vibe among the responses in his conclusion:</p>\n\n<blockquote>\n  <p>Unfortunately, you can see we lose a lot of information in passing to the class group, and in particular it doesn't tell us anything at all about which elements are obstacles to unique factorization. The intuition, rather, is that a more complicated class group implies we're further from unique factorization.</p>\n</blockquote>\n\n<p>I am not sure how the mentioned intuition translates into concrete facts, but I do get the impression that $\\rm Cl$ doesn't have the right \"type\" of information to talk about factorizations. Rather, I think the more <em>direct</em> description for $\\rm Cl$ is as a measure of how ideals fail to act like numbers.</p>\n\n<p>Here is my own crack at \"measuring\" factorization's failure to be unique. Let $\\Gamma(R)$ be the set of all associates classes of irreducible elements. (Suppose $R$ is a factorization domain, so all elements have <em>some</em> factorization if not a unique one, and $K$ is $R$'s fraction field.) The group of principal fractional ideals is essentially $K^\\times/R^\\times$, and it is generated by irreducible elements. Thus there is a surjective map $\\Bbb Z^{\\oplus \\Gamma(R)}\\to K^\\times/R^\\times$, and the kernel is comprised of all <em>relations</em> satisfied between irreducibles under multiplication. These relations are precisely the <em>inequivalent factorizations into irreducibles</em> that occur in $R$. Our knowledge so far can be put into a diagram:</p>\n\n<p>$$\\{{\\rm relations}\\}\\to\\Bbb Z^{\\oplus \\Gamma(R)}\\to K^\\times/R^\\times\\to I(R)\\to{\\rm Cl}(R).$$</p>\n\n<p>Observe this has two subsequences which are short exact, the first ending and the second beginning with $K^\\times/R^\\times$. (Can we determine if $\\rm relations$ is infinitely generated or not?) One thing to notice is that in such a sequence $A\\to B\\to C\\to D\\to E$, the exact sequence $C\\to D\\to E$ generically is expected to have little control over the exact sequence $A\\to B\\to C$, which at face value seems like good evidence that ${\\rm Cl}(R)$ does not influence factorization very much, but in fact $(\\star)$ says $|{\\rm Cl}|=1$ implies $\\{\\rm relations\\}=0$, so this diagram does not fully capture the situation.</p>\n\n<p>So, my questions:</p>\n\n<ul>\n<li>What <em>direct</em>, <em>specific</em> relationships exist between elemental factorizations and ideal classes? (In particular, beyond Kaczorowski's theorem.)</li>\n<li>Why is it useful to think of ${\\rm Cl}(R)$ as measuring the failure of unique factorization, as opposed to being only indirectly related (i.e. by measuring the failure of ideals to act like numbers)?</li>\n<li>What properties of ${\\rm Cl}(R)$ definitively <em>don't</em> say anything specific about factorizations, and conversely what properties of factorizations are definitively <em>not</em> captured by ideal classes?</li>\n</ul>\n\n<p>Sorry if I have been rambling, or not justified posting about this again, or my questions too vague.</p>\n", "pids": ["53e9bce1b7602d97049661d5"], "flag": 0}
{"question": "How to store qubits while preserving Heisenberg&#39;s uncertainty principle?", "body": "<p>I know that qubits are represented by quantum particles (for example photons) and that their state is given by one property (for example spin).</p>\n\n<p>My question is about the <strong>quantum memory</strong>: how are the qubits stored in a quantum computer. I suppose we require a kind of black box for Heisenberg's uncertainty principle to work. If I understand this correctly this principle is relevant for the superposition of the qubit.</p>\n\n<p>How is this kind of <em>black box</em> implemented in real quantum computers?</p>\n", "pids": ["55a5488f65ceb7cb02e6e427"], "flag": 1}
{"question": "How can one define contextuality within the circuit model?", "body": "<p>It is in general believed that contextuality is one of the quantum resource that provides the quantum advantage. A context is usually defined in terms of a set of commuting observables. The quantum algorithms are usually describe employing the circuit model. I am curious how can one define contextuality in the within the circuit model?</p>\n<p>To be concrete, we may consider Peres-Mermin Square and define a circuit representing each observable at each spot. I think the above definition of contextuality require some upgrading while combining all the gates to implement quantum contextuality for Peres-Mermin square. Please share any suggestion or any reference that can be help as a starting point.</p>\n<p><a href=\"https://arxiv.org/abs/quant-ph/0406166\" rel=\"nofollow noreferrer\">Spekken (2005)</a> generalizes the above definition of contextuality. Could we apply Spekken definition for a circuit model too?</p>\n", "pids": ["5caea6fce1cd8e43f51ba40a"], "flag": 1}
{"question": "What is the difference between regular PCA and probabilistic PCA?", "body": "<p>I know regular PCA does not follow probabilistic model for observed data. So what is the basic difference between PCA and <a href=\"https://people.cs.pitt.edu/~milos/courses/cs3750-Fall2007/lectures/class17.pdf\" rel=\"noreferrer\">PPCA</a>?  In PPCA latent variable model contains for example observed variables $y$, latent (unobserved variables $x$) and a matrix $W$ that does not has to be orthonormal as in regular PCA.  One more difference that I can think of regular PCA only provide principal components, where PPCA provides the probabilistic distribution of the data.</p>\n\n<p>Could someone please through more light on the differences between PCA and PPCA?</p>\n", "pids": ["5c2348ceda562935fc1d5722"], "flag": 1}
{"question": "When was the first use of the word Entanglement?", "body": "<p>Schrödinger wrote a letter to Einstein after the 1935 EPR paper, and in that letter Schrödinger used the German word \"Verschränkung\" which translates into \"entanglement\", but when was the word first used in English?</p>\n\n<p>Schrödinger's 1935 paper written in English, called <a href=\"https://www.cambridge.org/core/journals/mathematical-proceedings-of-the-cambridge-philosophical-society/article/discussion-of-probability-relations-between-separated-systems/C1C71E1AA5BA56EBE6588AAACB9A222D\" rel=\"noreferrer\">Discussion of Probability Relations between Separated Systems</a>, says (according to Wikipedia) \"I would not call [entanglement] one but rather the characteristic trait of quantum mechanics, the one that enforces its entire departure from classical lines of thought\" which means the concept was there but it whatever word he used for it was not entanglement (hence the square brackets). Unfortunately I do not have access to the full paper.</p>\n", "pids": ["53e9b29cb7602d9703d42286"], "flag": 1}
{"question": "Ordinary generating function for $\\binom{3n}{n}$", "body": "<p>The ordinary generating function for the central binomial coefficients, that is, <span class=\"math-container\">$$\\displaystyle \\sum_{n=0}^{\\infty} \\binom{2n}{n} x^{n} = \\frac{1}{\\sqrt{1-4x}} \\, , \\quad |x| &lt; \\frac{1}{4},$$</span></p>\n<p>can be derived by using the duplication formula for the gamma function and the generalized binomial theorem.</p>\n<p>But what about the ordinary generating function for <span class=\"math-container\">$ \\displaystyle  \\binom{3n}{n}$</span>?</p>\n<p>According to Wolfram Alpha,   <span class=\"math-container\">$$ \\sum_{n=0}^{\\infty} \\binom{3n}{n} x^{n} = \\frac{2\\cos \\left(\\frac{1}{3} \\arcsin \\left(\\frac{3 \\sqrt{3x}}{2} \\right)\\right)}{\\sqrt{4-27x}} \\, , \\quad |x| &lt; \\frac{4}{27}. $$</span></p>\n<p>Any suggestions on how to prove this?</p>\n<p><strong>EDIT</strong>:</p>\n<p>Approaching this problem using the fact that <span class=\"math-container\">$$ \\text{Res} \\Big[ \\frac{(1+z)^{3n}}{z^{n+1}},0 \\Big] = \\binom{3n}{n},$$</span></p>\n<p>I get <span class=\"math-container\">$$ \\sum_{n=0}^{\\infty} \\binom{3n}{n} x^{n} = -\\frac{1}{2 \\pi i x} \\int_{C} \\frac{dz}{z^{3}+3z^{2}+3z - \\frac{z}{x}+1},$$</span></p>\n<p>where <span class=\"math-container\">$C$</span> is a circle centered at <span class=\"math-container\">$z=0$</span> such that every point on the circle satisfies <span class=\"math-container\">$ \\displaystyle\\Big|\\frac{x(1+z)^{3}}{z} \\Big| &lt; 1$</span>.</p>\n<p>Evaluating that contour integral would appear to be quite difficult.</p>\n", "pids": ["53e9aa56b7602d97033c1f37"], "flag": 0}
{"question": "Correlated Bernoulli trials, multivariate Bernoulli distribution?", "body": "<p>I'm simplifying a research question that I have at work. Imagine that I have 5 coins and let's call heads a success. These are VERY biased coins with probability of success p=0.1. Now, if the coins were independent, then getting the probability of at least 1 head or more is very simple, $1-(1-1/10)^5$. In my scenario,  my Bernoulli trials (coin tosses) are not independent. The only information I have access to are the probability of successes (each one is p=.1) and the theoretical Pearson correlations among the binary variables.</p>\n\n<p>Is there any way to calculate the probability of one success or more only with this information? I'm trying to avoid a simulation-based approach because these theoretical results will be used to guide the accuracy of a simulation study. I have been looking into the multivariate Bernoulli distribution but I don't think that I can fully specify it only with correlations and marginal probabilities of success. A friend of mine recommended constructing a Gaussian copula with bernoulli marginals (using the R package <code>copula</code>) and then using the <code>pMvdc()</code> function on a large sample to get the probability I want but I'm not exactly sure how to go about it with it. </p>\n", "pids": ["53e9a4fab7602d9702e18f0d"], "flag": 1}
{"question": "Continuous Collatz Conjecture", "body": "<p>Has anyone studied the real function \n$$ f(x) = \\frac{ 2 + 7x - ( 2 + 5x )\\cos{\\pi x}}{4}$$ (and $f(f(x))$ and $f(f(f(x)))$ and so \non) with respect to the Collatz conjecture? </p>\n\n<p>It does what Collatz does on integers, and is defined smoothly on all \nthe reals. </p>\n\n<p>I looked at $$\\frac{ \\overbrace{ f(f(\\cdots(f(x)))) }^{\\text{$n$ times}} }{x}$$ briefly, and it appears to have bounds independent of $n$. </p>\n\n<p>Of course, the function is very wiggly, so Mathematica's graph is \nprobably not $100\\%$ accurate. </p>\n", "pids": ["53e9a272b7602d9702b75f2a", "53e9b3c8b7602d9703eb4f70"], "flag": 0}
{"question": "Where exactly does entanglement appear in Shor&#39;s algorithm?", "body": "<p>One deals with the notion of superposition when studying Shor's algorithm, but how about entanglement? Where exactly does it appear in this particular circuit?</p>\n<p>I assume it is not yet present in the initial state <span class=\"math-container\">$\\left|0\\right&gt;\\left|0\\right&gt;$</span>, but how about in further process, after applying Hadamard gates, the controlled-U gates and the inverse Fourier transform?</p>\n<p>I understand that the first and second registers have to be entangled, otherwise, the final measurement on one of them wouldn't collapse the other one, which gives us the period (well, kind of, we need to use continuous fractions to infer it).</p>\n", "pids": ["53e9a4abb7602d9702dcd0b1"], "flag": 1}
{"question": "Simulating Clifford + few-T circuits", "body": "<p>I want to simulate large stabilizer circuits (H/S/CNOT/MEASURE/feedforward) with a small number of T gates mixed in. How can I do this in a way that scales exponentially only in the number of T gates? Are there existing implementations?</p>\n", "pids": ["5c0f7471da562944ac6ae3d4", "5c0f7446da562944ac6a719c"], "flag": 1}
{"question": "What&#39;s the maximum value of Kullback-Leibler (KL) divergence", "body": "<p>I am going to use KL divergence in my python code and <a href=\"https://bigdatascientistblog.wordpress.com/2017/09/11/a-simple-introduction-to-kullback-leibler-divergence-through-python-code/\" rel=\"noreferrer\">I got this tutorial</a>.</p>\n\n<p>On that tutorial, to implement KL divergence is quite simple. </p>\n\n<pre><code>kl = (model * np.log(model/actual)).sum()\n</code></pre>\n\n<p>As I understand, the probability distribution of <code>model</code> and <code>actual</code> should be &lt;= 1. </p>\n\n<p>My question is, what's the maximum bound/maximum possible value of k?. I need to know the maximum possible value of kl distance as for the maximum bound in my code.</p>\n", "pids": ["657705b8939a5f408205d1a4"], "flag": 1}
{"question": "Iconic (toy) models of neural networks", "body": "<p>My physics professors in grad school, as well as the Nobel laureate Feynman, would always present what they called toy models to illustrate basic concepts and methods in physics, such as the harmonic oscillator, pendulum, spinning top, and black box.</p>\n<p>What toy models are used to illustrate the basic concepts and methods underlying the application of neural networks? (Please provide references.)</p>\n<p>By a toy model I mean a particularly simple, minimally sized network applied to a highly constrained problem through which basic methods can be presented and one's understanding tested and enhanced through actual implementation, i.e., constructing the basic code and preferably to a certain degree doing/checking the basic math by hand or aided by a symbolic math app.</p>\n", "pids": ["5550415945ce0a409eb3a847"], "flag": 1}
{"question": "What is the actual power of Quantum Phase Estimation?", "body": "<p>I have some perplexity concerning the concept of phase estimation: by definition, given a unitary operator $U$ <em>and</em> an eigenvector $|u\\rangle$ with related eigenvalue $\\text{exp}(2\\pi i \\phi)$, the phase estimation allows to find the value of $\\phi$.\nThis would mean that I would be able to determine an eigenvalue of a certain matrix <em>given</em> that I know already one of its eigenvectors? But isn't the fact that needing an eigenvector beforehand would quite reduce the usefulness of the phase estimation itself?</p>\n", "pids": ["619715f85244ab9dcb1852ff"], "flag": 1}
{"question": "Intuitively, why is the Euler-Mascheroni constant near $\\sqrt{1/3}$?", "body": "<p>Questions that ask for \"intuitive\" reasons are admittedly subjective, but I suspect some people will find this interesting.</p>\n\n<p>Some time ago, I was struck by the coincidence that the Euler-Mascheroni constant <span class=\"math-container\">$\\gamma$</span> is close to the square root of <span class=\"math-container\">$1/3$</span>. (Their numerical values are about <span class=\"math-container\">$0.57722$</span> and <span class=\"math-container\">$0.57735$</span> respectively.)</p>\n\n<p>Is there any informal or intuitive reason for this? For example, can we find a series converging to <span class=\"math-container\">$\\gamma$</span> and a series converging to <span class=\"math-container\">$\\sqrt{1/3}$</span> whose terms are close to each other?</p>\n\n<p>An example of the kind of argument I have in mind can be found in <a href=\"http://www.math.harvard.edu/~elkies/Misc/index.html\" rel=\"nofollow noreferrer\">Noam Elkies' list of one-page papers</a>, where he gives a \"reason\" that <span class=\"math-container\">$\\pi$</span> is slightly less than <span class=\"math-container\">$\\sqrt{10}$</span>. (Essentially, take <span class=\"math-container\">$\\sum\\frac1{n^2}=\\pi^2/6$</span> as known, and then bound that series above by a telescoping series whose sum is <span class=\"math-container\">$10/6$</span>.)</p>\n\n<p>There are lots of ways to get series that converge quickly to <span class=\"math-container\">$\\sqrt{1/3}$</span>. For example, taking advantage of the fact that <span class=\"math-container\">$(4/7)^2\\approx1/3$</span>, we can write\n<span class=\"math-container\">$$\n\\sqrt{\\frac{1}{3}}=(\\frac{16}{48})^{1/2}\n=(\\frac{16}{49}\\cdot\\frac{49}{48})^{1/2}=\\frac{4}{7}(1+\\frac{1}{48})^{1/2}\n$$</span>\nwhich we can expand as a binomial series, so <span class=\"math-container\">$\\frac{4}{7}\\cdot\\frac{97}{96}$</span> is an example of a good approximation to <span class=\"math-container\">$\\sqrt{1/3}$</span>. Can we also get good approximations to <span class=\"math-container\">$\\gamma$</span> by using series that converge quickly, and can we find the \"right\" pair of series that shows \"why\" <span class=\"math-container\">$\\gamma$</span> is slightly less than <span class=\"math-container\">$\\sqrt{1/3}$</span>?</p>\n\n<p>Another type of argument <a href=\"http://en.wikipedia.org/wiki/Proof_that_22/7_exceeds_%CF%80\" rel=\"nofollow noreferrer\">that's out there</a>, showing \"why\" <span class=\"math-container\">$\\pi$</span> is slightly less than <span class=\"math-container\">$22/7$</span>, involves a particular definite integral of a \"small\" function that evaluates to <span class=\"math-container\">$\\frac{22}{7}-\\pi$</span>. So, are there any definite integrals of \"small\" functions that evaluate to <span class=\"math-container\">$\\sqrt{\\frac13}-\\gamma$</span> or <span class=\"math-container\">$\\frac13-\\gamma^2$</span>?</p>\n", "pids": ["56d877addabfae2eee24680b"], "flag": 0}
{"question": "Average norm of a N-dimensional vector given by a normal distribution", "body": "<p>I'm interested in knowing what is the expected value of the norm of a vector obtained from a gaussian distribution in function of the number of dimensions $N$ and $\\sigma$, i.e:</p>\n\n<p>$$E[\\|x\\|_2],\\quad x\\sim\\mathcal{N}(0,\\sigma I_N)$$</p>\n\n<p>I tried to search for this but didn't find anything. Can I get some help from you? </p>\n", "pids": ["53e9990db7602d970214d6e9"], "flag": 0}
{"question": "What is bits per dimension (bits/dim) exactly (in pixel CNN papers)?", "body": "<p>If it is for the lack of my effort to search, I apologize in advance but I couldn't  find a explicit definition of bits per dimension (bits/dim). </p>\n\n<p>The first mention of its definition I found was from 'Pixel Recurrent Neural Networks'. But it is still quite unclear to me so let me ask.</p>\n\n<p>Defining the 256-softmax output of a image <span class=\"math-container\">$\\boldsymbol{x}$</span> as <span class=\"math-container\">$\\boldsymbol{y} \\in \\mathbb{R}^{32 \\times 32 \\times 256}$</span>, the negative log-likelihood, to my understanding, is\n<span class=\"math-container\">$$\n- \\mathbb{E}_{\\boldsymbol{x}}  \\ln p(\\boldsymbol{y}|\\boldsymbol{x}).\n$$</span>\n(Note that we are assuming here that image is one-channeled with its size being <span class=\"math-container\">$32 \\times 32 \\times 1$</span>.)</p>\n\n<p>According to the above paper (and possibly other materials), it seems to me that the definition of bits/dim is\n<span class=\"math-container\">$$\n\\text{bit/dim} = \\dfrac{- \\mathbb{E}_{\\boldsymbol{x}}  \\log_2 p(\\boldsymbol{y}|\\boldsymbol{x})}{32\\cdot 32\\cdot 1}\n$$</span>\nbecause it says 'The total discrete log-likelihood is normalized by\nthe dimensionality of the images '.</p>\n\n<p><strong>Questions.</strong> </p>\n\n<p><strong>1) Is the above definition correct?</strong></p>\n\n<p>2) Or should I replace <span class=\"math-container\">$\\mathbb{E}_{\\boldsymbol{x}}$</span> by <span class=\"math-container\">$\\sum_{\\boldsymbol{x}}$</span>?</p>\n", "pids": ["599c7949601a182cd262c74c", "599c7949601a182cd262c74c"], "flag": 1}
{"question": "Is leave-one-out cross validation (LOOCV) known to systematically overestimate error?", "body": "<p>Let's assume that we want to build a regression model that needs to predict the temperature in a build. We start from a very simple model in which we assume that the temperature only depends on weekday.</p>\n\n<p>Now we want to use k-fold validation to check if our hypothesis is valid. Now, for each weekday we calculate mean temperature using the whole data set. However, when we do the leave-one-out validation, we take one observation and calculate the mean without this particular observation. As a result, whenever an observation goes up, the corresponding prediction (mean calculated with the remaining values) goes down. So, we have an anticorrelation between observations and predictions and it should obviously decrease the accuracy of the model.</p>\n\n<p>So, my question is: Is it a known effect and how to deal with it?</p>\n", "pids": ["53e9b2b1b7602d9703d5d0a2"], "flag": 1}
{"question": "Exercises in category theory for a non-working mathematican (undergrad)", "body": "<p>I'm trying to learn category theory pretty much on my own (with some help from a professor). My main information source is the good old <strong>Categories for the working mathematician</strong> by Mac Lane. I find the book very good and and I don't have very much trouble understanding the theory, proofs and motivations and so on. </p>\n\n<p>But many examples fly over my head as do the exercises.</p>\n\n<p>The thing is that I'm far from a working mathematician or a grad student, which the book seems to be aimed towards. I know that one have to do learn math by <em>doing</em> math and I find it almost impossible when exercises involve things I'm not yet familiar with (modules, algebras etc). I simply don't have time to learn these things just so I can solve my exercises but on the other hand I don't want to miss out on learning things just because the exercises are on a too high level for me.</p>\n\n<p>So I want to ask you for references on exercises in category theory aimed at someone with limited knowledge of abstract algebra, suitable for concepts in <strong>Categories for the working mathematician</strong> but with more basic objects but still meaningful and challenging. </p>\n\n<p>(I consider myself to have fairly good basic knowledge of \"elementary\"-style abstract algebra (monoids, groups, rings, fields, linear algebra, some galois theory, related number theory, some algebraic graph theory etc))</p>\n", "pids": ["5c757395f56def97988b35cc"], "flag": 0}
{"question": "Do magnetic water softeners work?", "body": "<p>I'm extremely skeptical of the idea of magnetic water softeners (strong magnets attached to pipes), but desperately wish it were true because I hate lugging 40# bags of salt out to my well house in the hot Texas sun. </p>\n\n<p>I'd love to see some objective research results on the subject from someone who isn't selling a magnetic water softening system.</p>\n\n<p>For the purposes of this question, \"work\" is defined as changing the properties of water treated with the system to: </p>\n\n<ol>\n<li>Substantially improve the effectiveness of soap products using the output water.  </li>\n<li>Minimize scale buildup on fixtures, in pipes, and on dishes.  </li>\n</ol>\n\n<p>The reason I'm being so specific is that I've seen some defenders of this technology that claim you get the <em>benefits</em> of soft water using their systems, but because of the way it works it doesn't show any difference on standard water hardness tests. That is, it is pseudo-soft water, but acts like soft water for all practical purposes. Just the fact that they have a miracle solution, that involves magnets, and is resilient to empirical testing makes me <em>extremely</em> skeptical.</p>\n", "pids": ["5ce2cc9cced107d4c62c1523"], "flag": 1}
{"question": "Why do we use Gaussian distributions in Variational Autoencoder?", "body": "<p>I still don't understand why we force the distribution of the hidden representation of a <strong>Variational Autoencoder (VAE)</strong> to follow <strong>a multivariate normal distribution</strong>. Why this specific distribution and not another one ? </p>\n\n<p>This is maybe linked with another question : Why is the <strong>weights distribution</strong> in a neural network following a <strong>Gaussian Distribution</strong> ? Is it just the application of the Central Limit theorem that tells you that many independent inputs will generate many independent errors, and the observed weights are the results of these multiple back-propagated signals... ?</p>\n", "pids": ["5c2348ceda562935fc1d5722", "58d82fd2d649053542fd7894", "5b1643ba8fbcbf6e5a9bc933"], "flag": 1}
{"question": "How to implement a matrix exponential in a quantum circuit?", "body": "<p>Maybe it is a naive question, but I cannot figure out how to actually exponentiate a matrix in a quantum circuit.\nAssuming to have a generic square matrix <em>A</em>, if I want to obtain its exponential, $e^{A}$, i can use the series</p>\n\n<p>$$e^{A} \\simeq I+ A+\\frac{A^2}{2!}+\\frac{A^3}{3!}+...$$</p>\n\n<p>To have its approximation. I do not get how to do the same using quantum gates then apply it for instance to perform an Hamiltonian simulation. Some help?</p>\n", "pids": ["5aed14d117c44a44381589c1", "5550453445ce0a409eb5483a", "62708f615aee126c0fa691fb"], "flag": 1}
{"question": "Estimating the entropy", "body": "<p>Given a discrete random variable $X$, I would like to estimate the entropy of $Y=f(X)$ by sampling. I can sample uniformly from $X$. The samples are just random vectors of length $n$ where the entries are $0$ or $1$.  For each sample vector $x_i$, I can then compute the function $f(x_i)$ which itself is a vector.  A naive method is to run this process for as long as time allows and then to take the collection of $f(x_i)$ vectors and compute its entropy by making a histogram of how frequently each vector has occurred.</p>\n\n<p>This however doesn't seem a good estimate. In particular, the sample space for $Y$ is exponential in $n$ and so I am very likely never to have seen any samples with low probability.  This will mean I may grossly underestimate the entropy I think.</p>\n\n<p>The size of the vectors $n$ will typically be at most $100$ and is known.</p>\n\n<blockquote>\n  <p>Is there an unbiased estimator for the entropy?</p>\n</blockquote>\n\n<p>Or alternatively, </p>\n\n<blockquote>\n  <p>Is there an estimator with lower variance?</p>\n</blockquote>\n", "pids": ["53e9a23eb7602d9702b450f7", "5c6108b6da56297340b4b4f1", "55323e2145cec66b6f9e1c70", "55323e2145cec66b6f9e1c70"], "flag": 0}
{"question": "On the invertibility of the adjacency matrix of a graph", "body": "<p>Which are the sufficient and necessary conditions for an undirected graph with no self edges (i.e. no loop of length $1$) to have an invertible adjacency matrix?</p>\n\n<p>In this case, the adjacency matrix is symmetric (i.e. $A = A^\\top$). Moreover, all the diagonal elements are $0$ and there is a $1$ in both the entries $(i,j)$ and $(j,i)$, with $i\\neq j$, if and only if vertices $i$ and $j$ are connected. </p>\n\n<p>A first necessary condition is the following: all vertices must have at least one connection, otherwise the relative row of $A$ is null. But what else?</p>\n", "pids": ["53e9a98eb7602d97032e6156", "5db926c747c8f766461b722d"], "flag": 0}
{"question": "Modern Use Cases of Restricted Boltzmann Machines (RBM&#39;s)?", "body": "<p><strong>Background:</strong> A lot of the modern research in the past ~4 years (post <a href=\"https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\" rel=\"noreferrer\">alexnet</a>) seems to have moved away from using generative pretraining for neural networks to achieve state of the art classification results. </p>\n\n<p>For example, the top results for mnist <a href=\"http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\" rel=\"noreferrer\">here</a> include only 2 papers of the top 50 seem to be using generative models, both of which are RBM's. The other 48 winning papers are about different discriminative feed forward architectures with much effort being put towards finding better/novel weight initializations and activation functions different from the sigmoid used in the RBM and in many older neural networks. </p>\n\n<p><strong>Question:</strong> Is there any modern reason to use Restricted Boltzmann Machines anymore? </p>\n\n<p>If not, is there a de facto modification one can apply to these feed forward architectures to make any of their layers generative?</p>\n\n<p><strong>Motivation:</strong> I ask because some of the models I'm seeing available, usually variants on the RBM, don't necessarily have obvious analogous discriminative counterparts to these generative layers/models, and visa versa. For example: </p>\n\n<ul>\n<li><p><a href=\"https://www.cs.toronto.edu/~gdahl/papers/mcRBMdeepPhoneRec.pdf\" rel=\"noreferrer\">mcRBM</a></p></li>\n<li><p><a href=\"http://www.icml-2011.org/papers/591_icmlpaper.pdf\" rel=\"noreferrer\">ssRBM</a></p></li>\n<li><p><a href=\"http://www.cs.toronto.edu/~rgrosse/icml09-cdbn.pdf\" rel=\"noreferrer\">CRBM</a> (although one could argue the CNN used feed forward architectures <em>is</em> the discriminative analogous architecture)</p></li>\n</ul>\n\n<p>Also, these were clearly pre alexnet as well, from 2010, 2011, and 2009 respectfully.</p>\n", "pids": ["5550410f45ce0a409eb384f8", "5c2348ceda562935fc1d5722", "5b1643ba8fbcbf6e5a9bc513"], "flag": 1}
{"question": "Are all $[[n, k, d]]$ quantum codes equivalent to additive self-orthogonal $GF(4)^n$ classical codes?", "body": "<p>Theorem 2 of [1] states:</p>\n\n<blockquote>\n  <p>Suppose $C$ is an additive self-orthogonal sub-code of $\\textrm{GF}(4)^n$, containing $2^{n-k}$ vectors, such that there are no vectors of weight $&lt;d$ in $C^\\perp/C$. Then any eigenspace of $\\phi^{-1}(C)$ is an additive quantum-error-correcting code with parameters $[[n, k, d]]$.</p>\n</blockquote>\n\n<p>where here $\\phi: \\mathbb{Z}_2^{2n} \\rightarrow \\textrm{GF}(4)^n$ is the map between the binary representation of $n$-fold Pauli operators and their associated codeword, and $C$ is <em>self-orthogonal</em> if $C \\subseteq C^\\perp$ where $C^\\perp$ is the dual of $C$.</p>\n\n<p>This tells us that each additive self-orthogonal $\\textrm{GF}(4)^n$ classical code represents a $[[n, k, d]]$ quantum code.</p>\n\n<p>My question is whether the reverse is also true, that is: <strong>is every $[[n, k, d]]$ quantum code represented by an additive self-orthogonal $\\textrm{GF}(4)^n$ classical code?</strong></p>\n\n<p>Or equivalently: <strong>Are there any $[[n, k, d]]$ quantum codes that are not represented by an additive self-orthogonal $\\textrm{GF}(4)^n$ classical code?</strong></p>\n\n<p>[1]: Calderbank, A. Robert, et al. \"Quantum error correction via codes over GF (4).\" IEEE Transactions on Information Theory 44.4 (1998): 1369-1387.</p>\n", "pids": ["57a4e91dac44365e35c984c6", "53e99a78b7602d97022e8ea5", "645dad16d68f896efad9df4e", "53e9a9c4b7602d9703325192", "53e99867b7602d97020a36bc"], "flag": 1}
{"question": "Have the Covid-19 vaccines caused more deaths than Covid-19 itself did?", "body": "<p>A popular <a href=\"https://stevekirsch.substack.com/p/now-published-in-the-peer-reviewed\" rel=\"noreferrer\">article</a> by <a href=\"https://en.wikipedia.org/wiki/Steve_Kirsch\" rel=\"noreferrer\">Steve Kirsch</a> on his substack discusses the following:</p>\n<blockquote>\n<p>A worldwide Bayesian causal Impact analysis suggests that COVID-19 gene therapy (mRNA vaccine) causes more COVID-19 cases per million and more non-Covid deaths per million than are associated with COVID-19 [43].</p>\n<p>An abundance of studies has shown that the mRNA vaccines are neither safe nor effective, but outright dangerous.</p>\n<p>[citing:] 43. Beattie, K.A. (2021) Worldwide Bayesian Causal Impact\nAnalysis of Vaccine Administration on Deaths and Cases\nAssociated with COVID-19: A BigData Analysis of 145\nCountries. Department of Political Science University of\nAlberta Alberta, Canada</p>\n</blockquote>\n<p>This excerpt is itself from a peer-reviewed study <em>COVID-19 vaccines – An Australian Review</em> by Conny Turni and Astrid Lefringhausen, which was <a href=\"https://www.opastpublishers.com/open-access-articles/covid19-vaccinesan-australian-review.pdf\" rel=\"noreferrer\">published</a> in the Journal of Clinical &amp; Experimental Immunology. Is this an accurate reading of the peer reviewed study? Furthermore, is that study an accurate analysis of facts?</p>\n", "pids": ["63903fc790e50fcafdedddf2"], "flag": 1}
{"question": "How can I prove my conjecture for the coefficients in $t(x)=\\log(1+\\exp(x)) $?", "body": "<p>I'm considering the transfer-function\n$$ t(x) = \\log(1 + \\exp(x)) $$\nand find the beginning of the power series (simply using Pari/GP) as\n$$ t(x) = \\log(2) + 1/2 x + 1/8 x^2 – 1/192 x^4 + 1/2880 x^6 - \\ldots $$\nExamining the pattern of the coefficients I find the much likely composition\n$$ t(x) = \\sum_{k=0}^\\infty {\\eta(1-k) \\over k! }x^k $$ where $ \\eta() $ is the Dirichlet eta-(or \"alternating zeta\") function.<br>\nI'm using this definition in further computations and besides the convincing simplicitiness of the pattern the results are always meaningful. However, I've no idea how I could prove this description of the coefficients.     </p>\n\n<p>Q: Does someone has a source or an idea, how to do such a proof on oneself?</p>\n", "pids": ["62abf77b5aee126c0f64f08d", "62f6055090e50fcafd06bac9", "5f4e37be9e795ea3f185b65e", "63432a0b90e50fcafdfbd8bc", "615e657b5244ab9dcbf21f6d", "628d15985aee126c0f2fff09"], "flag": 0}
{"question": "Why is the Topology of a Graph called a &quot;Topology&quot;?", "body": "<p>The topology of a graph (i.e. a network topology), as far as I can tell, doesn't actually have anything to do with open or closed sets, nor does it have any consistent, rigorous definition in practice. </p>\n\n<p>So why is it called a topology?</p>\n\n<p>Also, simplicial complexes kind of look like graphs -- is their topology related to this \"topology\"?</p>\n\n<p>Possibly related: <a href=\"https://math.stackexchange.com/questions/1118286/is-a-network-topology-a-topological-space\">Is a &quot;network topology&#39;&quot; a topological space?</a>, but here I'm asking for the etymology of the term (topology I thought was invented specifically for the mathematical field, why is the topology of a graph, which isn't necessarily related, called that? Why don't they call it the connectivity or something like that?)</p>\n", "pids": ["5c610830da56297340b2ccc0"], "flag": 0}
{"question": "Problems from the Kourovka Notebook that undergraduate students can fully appreciate", "body": "<blockquote>\n  <p><a href=\"http://arxiv.org/abs/1401.0300\"><em>The Kourovka Notebook</em></a> is a collection of open problems in Group\n  Theory. </p>\n</blockquote>\n\n<p>My question is: could you point out some (a \"big-list\" of) problems [by referencing them] presented in this book that are, in principle, accessible to undegraduate students: <em>i.e.</em>, problems that refer to (and possibly might be solved by applying) definitions, concepts, and theorems that are presented in a book like Herstein's <em>Topics in Algebra</em> (and then, by extension, in an abstract algebra course for undergraduates).</p>\n\n<p>The aim of this question is to allow undergraduate students to have a better understanding of current research in algebra by letting them see concretely open problems that can be easily related to known concepts. </p>\n", "pids": ["53e9a27ab7602d9702b7f997", "56d87fdedabfae2eee5ebb98", "53e9a27ab7602d9702b7f997", "56d87fdedabfae2eee5ebb98", "53e9a27ab7602d9702b7f997"], "flag": 0}
{"question": "Bounds for $n$-th prime", "body": "<p>In <a href=\"http://en.wikipedia.org/wiki/Prime_number_theorem\" rel=\"noreferrer\">this Wikipedia page</a> I have found that the bounds for $n$-th prime is given by, $$n(\\ln n+\\ln \\ln n)&gt;p_n&gt;n(\\ln n+\\ln \\ln n-1)$$ for all $n\\ge6$. Are there even stronger bounds for the $n$-th prime? </p>\n\n<p>If possible (of course if the answer is affirmative) in the answer (or comment) please give the link of the paper in which it first appears.</p>\n", "pids": ["53e9a76eb7602d97030a8318"], "flag": 0}
{"question": "what is the relation between quaternions and imaginary numbers?", "body": "<p>I understand the idea behind complex and imaginary numbers. I am trying to understand quaternions. </p>\n\n<p>What is the relation between imaginary (or complex) numbers, and quaternions?</p>\n", "pids": ["61164a2c5244ab9dcbd499b8"], "flag": 0}
{"question": "What are hyperreal numbers? (Clarifying an already answered question)", "body": "<p>This question already has an answer <a href=\"https://math.stackexchange.com/a/967137/404146\">here</a>. That answer is abstract. Could you help me with some not-so-abstract examples of what the answerer is talking about? For example, give examples of hyperreal numbers which are written as numbers, if that is possible. </p>\n\n<p>Another examples that I would like to understand are these statements:</p>\n\n<p>Hyperreal numbers extend the reals. As well, real numbers form a subset of the hyperreal numbers.</p>\n\n<p><strong>I've not yet studied mathematics at university level.</strong></p>\n", "pids": ["5c756cd3f56def97984cb9b3"], "flag": 0}
{"question": "What areas of math can be tackled by artificial intelligence?", "body": "<p>Artificial intelligence is nearing, with image/speech recognition, chess/go engines etc. My question is, what areas of math that are interesting to mathematicians, is likely to be the first to be able to be tackled by artificial intelligence? Is there some areas of math where some open conjectures or similar was solved by AI? Has AI been of use in math at all yet?</p>\n", "pids": ["5a73cbcc17c44a0b3035f300", "58d82fced649053542fd6d70"], "flag": 0}
{"question": "Relationship between Catalan&#39;s constant and $\\pi$", "body": "<p>How related are <span class=\"math-container\">$G$</span> (Catalan's constant) and <span class=\"math-container\">$\\pi$</span>?</p>\n\n<p>I seem to encounter <span class=\"math-container\">$G$</span> a lot when computing definite integrals involving logarithms and trig functions. </p>\n\n<p>Example:</p>\n\n<p>It is well known that \n<span class=\"math-container\">$$G=\\int_0^{\\pi/4}\\log\\cot x\\,\\mathrm{d}x$$</span>\nSo we see that \n<span class=\"math-container\">$$G=\\int_0^{\\pi/4}\\log\\sin(x+\\pi/2)\\,\\mathrm{d}x-\\int_0^{\\pi/4}\\log\\sin x\\,\\mathrm{d}x$$</span>\nSo we set out on the evaluation of \n<span class=\"math-container\">$$L(\\phi)=\\int_0^\\phi\\log\\sin x\\,\\mathrm{d}x,\\qquad \\phi\\in(0,\\pi)$$</span>\nwe recall that \n<span class=\"math-container\">$$\\sin x=x\\prod_{n\\geq1}\\frac{\\pi^2n^2-x^2}{\\pi^2n^2}$$</span>\nApplying <span class=\"math-container\">$\\log$</span> on both sides,\n<span class=\"math-container\">$$\\log\\sin x=\\log x+\\sum_{n\\geq1}\\log\\frac{\\pi^2n^2-x^2}{\\pi^2n^2}$$</span>\nintegrating both sides from <span class=\"math-container\">$0$</span> to <span class=\"math-container\">$\\phi$</span>,\n<span class=\"math-container\">$$L(\\phi)=\\phi(\\log\\phi-3)+\\sum_{n\\geq1}\\phi\\log\\frac{\\pi^2n^2-\\phi^2}{\\pi^2n^2}+\\pi n\\log\\frac{\\pi n+\\phi}{\\pi n-\\phi}$$</span>\nWith the substitution <span class=\"math-container\">$u=x+\\pi/2$</span>,\n<span class=\"math-container\">$$\n\\begin{align}\n\\int_0^\\phi \\log\\cos x\\,\\mathrm{d}x=&amp;\\int_0^{\\phi}\\log\\sin(x+\\pi/2)\\,\\mathrm{d}x\\\\\n=&amp;\\int_{\\pi/2}^{\\phi+\\pi/2}\\log\\sin x\\,\\mathrm{d}x\\\\\n=&amp;\\int_{0}^{\\phi+\\pi/2}\\log\\sin x\\,\\mathrm{d}x-\\int_{0}^{\\pi/2}\\log\\sin x\\,\\mathrm{d}x\\\\\n=&amp;L(\\phi+\\pi/2)+\\frac\\pi2\\log2\n\\end{align}\n$$</span>\nSo \n<span class=\"math-container\">$$G=L\\bigg(\\frac{3\\pi}4\\bigg)-L\\bigg(\\frac\\pi4\\bigg)+\\frac\\pi2\\log2$$</span>\nAnd after a lot of algebra,\n<span class=\"math-container\">$$G=\\frac\\pi4\\bigg(\\log\\frac{27\\pi^2}{16}+2\\log2-6\\bigg)+\\pi\\sum_{n\\geq1}\\bigg[\\frac14\\log\\frac{(16n^2-9)^3}{256n^4(16n^2-1)}+n\\log\\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\\bigg]$$</span></p>\n\n<p>So yeah I guess I found a series for <span class=\"math-container\">$G$</span> in terms of <span class=\"math-container\">$\\pi$</span>, but are there any other sort of these representations of <span class=\"math-container\">$G$</span> in terms of <span class=\"math-container\">$\\pi$</span>?</p>\n\n<p><strong>really important edit</strong></p>\n\n<p>As it turns out, the series \n<span class=\"math-container\">$$\\frac\\pi4\\bigg(\\log\\frac{27\\pi^2}{16}+2\\log2-6\\bigg)+\\pi\\sum_{n\\geq1}\\bigg[\\frac14\\log\\frac{(16n^2-9)^3}{256n^4(16n^2-1)}+n\\log\\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\\bigg]$$</span>\ndoes not converge, however it is a simple fix, and the series\n<span class=\"math-container\">$$G=\\frac\\pi4\\bigg(\\log\\frac{3\\pi\\sqrt{3}}2-1\\bigg)+\\pi\\sum_{n\\geq1}\\bigg[\\frac14\\log\\frac{(16n^2-9)^3}{256n^4(16n^2-1)}+n\\log\\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}-1\\bigg]$$</span>\n<em>does</em> converge to <span class=\"math-container\">$G$</span>. </p>\n\n<p>Quite amazingly, we can use this to find a really neat infinite product identity. Here's how. </p>\n\n<p>Using the rules of exponents and logarithms, we may see that \n<span class=\"math-container\">$$\\frac{G}\\pi+\\frac12-\\log\\bigg(3^{3/4}\\sqrt{\\frac\\pi2}\\bigg)=\\sum_{n\\geq1}\\log\\bigg[\\frac1{4en}\\bigg(\\frac{(16n^2-9)^3}{16n^2-1}\\bigg)^{1/4}\\bigg(\\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\\bigg)^n\\bigg]$$</span>\nThen using the fact that \n<span class=\"math-container\">$$\\log\\prod_{i}a_i=\\sum_{i}\\log a_i$$</span>\nWe have \n<span class=\"math-container\">$$\\frac{G}\\pi+\\frac12-\\log\\bigg(3^{3/4}\\sqrt{\\frac\\pi2}\\bigg)=\\log\\bigg[\\prod_{n\\geq1}\\frac1{4en}\\bigg(\\frac{(16n^2-9)^3}{16n^2-1}\\bigg)^{1/4}\\bigg(\\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\\bigg)^n\\bigg]$$</span>\nThen taking <span class=\"math-container\">$\\exp$</span> on both sides,\n<span class=\"math-container\">$$\\prod_{n\\geq1}\\frac1{4en}\\bigg(\\frac{(16n^2-9)^3}{16n^2-1}\\bigg)^{1/4}\\bigg(\\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\\bigg)^n=\\sqrt{\\frac{2e}{3\\pi\\sqrt{3}}}e^{G/\\pi}$$</span>\nOr perhaps more aesthetically,\n<span class=\"math-container\">$$\\prod_{n\\geq1}\\frac1{4en}\\bigg(\\frac{(16n^2-9)^3}{16n^2-1}\\bigg)^{1/4}\\bigg(\\frac{(4n+3)(4n-1)}{(4n-3)(4n+1)}\\bigg)^n=\\sqrt{\\frac{2}{3\\pi\\sqrt{3}}}\\exp\\bigg(\\frac{G}{\\pi}+\\frac12\\bigg)$$</span></p>\n", "pids": ["5ce023a0ced107d4c69e56c3"], "flag": 0}
{"question": "A Binomial Identity simplify", "body": "<p>I want to symplify\n<span class=\"math-container\">$$ \\sum_{\\ell=1}^{k} \\frac{1}{\\ell}\\sum_{m=1}^{\\min\\{\\ell,k-\\ell\\}}\\binom{\\ell}{m}\\binom{k-\\ell-1}{m-1}.\n$$</span></p>\n", "pids": ["53e9a9a9b7602d9703303772"], "flag": 0}
{"question": "What exactly is a hypothesis space in machine learning?", "body": "<p>Whilst I understand the term conceptually, I'm struggling to understand it operationally. Could anyone help me out by providing an example?</p>\n", "pids": ["53e9b421b7602d9703f17cc7"], "flag": 1}
{"question": "How many elliptic curves have complex multiplication?", "body": "<p>Let $K$ be a number field. Suppose we order elliptic curves over $K$ by naive height. What is the natural density of elliptic curves without complex multiplication?</p>\n\n<p>More generally, suppose we order $g$-dimensional abelian varieties over $K$ by Faltings height. What is the natural density of such varieties without complex multiplication?</p>\n", "pids": ["5f0e0cbf9fced0a24bd8e4c6", "5c754f94f56def9798566eb5", "56d8a73cdabfae2eee95d672", "5c610934da56297340b68c84", "53e9b395b7602d9703e77dc7"], "flag": 0}
{"question": "Advances on imperfect quantum copying", "body": "<p>It is known by the no-cloning theorem that constructing a machine that is able to clone an arbitrary quantum state is impossible. However, if the copying is assumed not to be perfect, then universal quantum cloning machines can be generated, being able to create imperfect copies of arbitrary quantum states where the original state and the copy have a certain degree of fidelity that depends on the machine. I came across the paper <a href=\"https://arxiv.org/pdf/quant-ph/9607018.pdf\" rel=\"noreferrer\">Quantum copying: Beyond the no-cloning theorem</a> by Buzek and Hillery where this kind of <em>universal quantum cloning machine</em> is presented. However, this paper is from 1996 and I am not aware if some advances in this kind of machines have been done yet.</p>\n\n<p>Consequently, I would like to know if someone does know if any advances in such kind of cloning machines have been done since then, that is, machines whose fidelity is better than the one presented in such paper, or the methods are less complex ... Additionally, it would be also interesting to obtain references about any useful application that such machines present if there is any.</p>\n", "pids": ["5c610987da56297340b7e636", "53e9a00ab7602d97028e9fcc", "5ff6894cd4150a363cc9c8d8", "53e9ae04b7602d970380ca5c", "62708f615aee126c0fa68ee3", "53e9ace9b7602d97036c691e", "6350bc6690e50fcafdeceab1"], "flag": 1}
{"question": "How many rounds would it take to get each pair on the same team at least once, not using all possible teams?", "body": "<p>I have a young group of kids (<span class=\"math-container\">$30$</span>) playing soccer and they need to be put into <span class=\"math-container\">$6$</span> teams of <span class=\"math-container\">$5$</span> players for each round of matches. All <span class=\"math-container\">$6$</span> teams play at the same time on adjoining fields.</p>\n<p>If I wanted each kid to play on a team with every other kid in the group (so they know each others names), how many team rounds would I need?</p>\n<p>Note: I'm not after the number of rounds to get through all of the combinations of unique teams.</p>\n", "pids": ["53e9ad3bb7602d9703721cbc"], "flag": 0}
{"question": "Euler-Mascheroni constant in Bessel function integral", "body": "<p>I am currently juggling some integrals. In a physics textbook, Chaikin-Lubensky <a href=\"https://www.cambridge.org/core/books/principles-of-condensed-matter-physics/70C3D677A9B5BEC4A77CBBD0A8A23E64\" rel=\"noreferrer\">[1]</a>, Chapter 6, (6.1.26), I came upon an integral that goes\n<span class=\"math-container\">\\begin{equation}\n\\int_0^{1} \\textrm{d} y\\, \\frac{1 - J_0(y)}{y} - \\int_{1}^{\\infty} \\textrm{d} y\\, \\frac{J_0(y)}{y} = -.116.\n\\end{equation}</span>\nThey give the result only as a floating point value without naming sources. The value looks suspiciously like <span class=\"math-container\">$\\gamma - \\ln(2)$</span> to me (<span class=\"math-container\">$\\gamma$</span> being the Euler-Mascheroni constant), which would solve a problem I have elsewhere. I am unfamiliar with the typical manipulations one uses on this kind of integrals and the various definitions of the Euler-Mascheroni constant. I fumbled around a bit with cosine integrals <span class=\"math-container\">$\\textrm{Ci}(y)$</span> but did not get far with it. So I am happy about suggestions.</p>\n", "pids": ["56ac87860cf2a8c8f70a99c1"], "flag": 0}
{"question": "Roadmap for learning Topological Data Analysis?", "body": "<p>I'm a math major who has recently graduated and I will be starting full time work in 'data analysis'. </p>\n\n<p>Having finished with decent marks and still being incredibly interested in mathematics, I was thinking of pursuing graduate study/research at some point in the future. I was reading up about possible areas of study for this when I came across topological data analysis, which (as I understand it) is an application of algebraic topology to data analysis.</p>\n\n<p>Given my situation, I was intrigued by the concept and I would like to do some self study so I can have a working understanding of the subject. I have only done basic undergraduate abstract algebra, analysis and point set topology, and I am currently reading Munkres' Topology (Chapter 9 onwards). How do I get from where I am now to understanding the theory behind TDA and being able to apply it?</p>\n\n<p>My knowledge on further mathematics is far from extensive and I would appreciate any advice on links/texts which I could use to learn the relevant material. </p>\n", "pids": ["599c78a4601a182cd25e0ad6", "573696056e3b12023e518c9b", "5550417645ce0a409eb3b7c5", "5550413d45ce0a409eb39976", "5c610933da56297340b68972"], "flag": 0}
{"question": "Where do we put error correction code in quantum circuit?", "body": "<p>First of all : I am a beginner in quantum computing.</p>\n\n<p>I would like to have a resource (or an answer if it is not complicated) explaining where we put the error correction codes in a quantum circuit.</p>\n\n<p>Indeed, I know we have different possible errors that can occur (bit flip, phase flip etc), and we have algorithm to correct them. But what I would like to know is if there are some strategies to where we put the error correction algorithm. Is it after each gate involved of the main algorithm ? Is there a smarter strategy used to do a single correction for a set of gates ?</p>\n\n<p>If the answer is \"complicated\" I would like to have a resource to learn all this (I find a lot of things for error correction code, but I haven't found anything about where we must do the correction).</p>\n", "pids": ["5ff68d23d4150a363cd48a18", "5c866e074895d9cbc65bd51e"], "flag": 1}
{"question": "Evaluate $\\int_0^1\\arcsin^2(\\frac{\\sqrt{-x}}{2}) (\\log^3 x) (\\frac{8}{1+x}+\\frac{1}{x}) \\, dx$", "body": "<p>Here is an interesting integral, which is equivalent to the title\n<span class=\"math-container\">$$\\tag{1}\\int_0^1 \\log ^2\\left(\\sqrt{\\frac{x}{4}+1}-\\sqrt{\\frac{x}{4}}\\right) (\\log ^3x) \\left(\\frac{8}{1+x}+\\frac{1}{x}\\right) \\, dx = \\frac{5 \\pi ^6}{1134}-\\frac{22 \\zeta (3)^2}{5}$$</span></p>\n<blockquote>\n<p>Question: how to prove <span class=\"math-container\">$(1)$</span>?</p>\n</blockquote>\n<hr />\n<p>Using power expansion of <span class=\"math-container\">$\\log^2(\\sqrt{x+1}-\\sqrt{x})$</span>, we can derive an equivalent form of <span class=\"math-container\">$(1)$</span>:\n<span class=\"math-container\">$$\\tag{2}\\sum _{n=1}^{\\infty } \\frac{1}{n^2 \\binom{2 n}{n}} \\left(8 \\sum _{j=1}^n \\frac{(-1)^j}{j^4}+\\frac{(-1)^n}{n^4}\\right)=-\\frac{22 \\zeta (3)^2}{15}-\\frac{97 \\pi ^6}{34020}$$</span></p>\n<p>Letting <span class=\"math-container\">$\\sqrt{\\frac{x}{4}+1}-\\sqrt{\\frac{x}{4}}=\\sqrt{u+1}$</span> gives\n<span class=\"math-container\">$$\\tag{3}\\int_0^{\\phi} \\log^2 (1+u) \\log^3\\left(\\frac{u^2}{1+u}\\right)  \\frac{(u+2)(9 u^2+u+1)}{u (u+1) (u^2+u+1)} du = \\frac{10 \\pi ^6}{567}-\\frac{88 \\zeta (3)^2}{5}$$</span>\nwith <span class=\"math-container\">$\\phi = (\\sqrt{5}+1)/2$</span>. But all these variations look equally difficult.</p>\n<p>Any idea is welcomed.</p>\n", "pids": ["6390045290e50fcafd838579"], "flag": 0}
{"question": "Essential papers on matrix decompositions", "body": "<p>I recently read Skillicorn's book on matrix decompositions, and was a bit disappointed, as it was targeted to an undergraduate audience. I would like to compile (for myself and others) a short bibliography of essential papers (surveys, but also breakthrough papers) on matrix decompositions. What I have in mind primarily is something on SVD/PCA (and robust/sparse variants), and NNMF, since those are by far the most used. Do you all have any recommendation/suggestion? I am holding off mine not to bias the answers. I would ask to limit each answer to 2-3 papers.</p>\n\n<p>P.S.: I refer to these two decompositions as the most used <em>in data analysis</em>. Of course QR, Cholesky, LU and polar are very important in numerical analysis. That is not the focus of my question though.</p>\n", "pids": ["53e9a8a3b7602d97031f2034", "60c18ae391e0112cf43c2046"], "flag": 1}
{"question": "Applications for Homology", "body": "<p><strong>The Question:</strong> Are there any ways that \"applied\" mathematicians can use Homology theory?  Have you seen any good applications of it to the \"real world\" either directly or indirectly?</p>\n\n<p><strong>Why do I care?</strong>  Topology has appealed to me since beginning it in undergrad where my university was more into pure math.  I'm currently in a program where the mathematics program is geared towards more applied mathematics and I am constantly asked, \"Yeah, that's cool, but what can you use it for in the real world?\"  I'd like to have some kind of a stock answer for this.</p>\n\n<p><strong>Full Disclosure.</strong> I am a first year graduate student and have worked through most of Hatcher, though I am not by any means an expert at any topic in the book.  This is also my first post on here, so if I've done something wrong just tell me and I'll try to fix it.</p>\n", "pids": ["5550412745ce0a409eb38e2b"], "flag": 0}
{"question": "Social network datasets", "body": "<p>I am looking for social network datasets (twitter, friendfeed, facebook, lastfm, etc.) for classification tasks, preferably in arff format. </p>\n\n<p>My searches via UCI and Google weren't successful so far... any suggestions?</p>\n", "pids": ["53e9b556b7602d970408d72a"], "flag": 1}
{"question": "LASSO assumptions", "body": "<p>In a LASSO regression scenario where</p>\n\n<p>$y= X \\beta + \\epsilon$,</p>\n\n<p>and the LASSO estimates are given by the following optimization problem</p>\n\n<p>$ \\min_\\beta ||y - X \\beta|| + \\tau||\\beta||_1$</p>\n\n<p>Are there any distributional assumptions regarding the $\\epsilon$? </p>\n\n<p>In an OLS scenario, one would expect that the $\\epsilon$ are independent and normally distributed.</p>\n\n<p>Does it make any sense to analyze the residuals in a LASSO regression?</p>\n\n<p>I know that the LASSO estimate can be obtained as the posterior mode under independent double-exponential priors for the $\\beta_j$. But I haven't found any standard \"assumption checking phase\".</p>\n\n<p>Thanks in advance (:</p>\n", "pids": ["53e99b0fb7602d970239f022"], "flag": 1}
{"question": "Are correlations stronger than those allowed by quantum mechanics possible?", "body": "<p>We know how a quantum correlation setup can help us with a better probability of winning games like the CHSH. But what is the upper bound that physics can allow? Is it the quantum correlation setup? Or can we exceed them in general sense to get much stronger correlations? </p>\n", "pids": ["60828e1e91e0118612e3f3d8", "56d8b2d8dabfae2eeeefefd3", "62eb39485aee126c0fb7b194"], "flag": 1}
{"question": "Arc Length of B&#233;zier Curves", "body": "<blockquote>\n  <p><strong>See also:</strong> <a href=\"https://gamedev.stackexchange.com/q/6009/3637\">answers with code on GameDev.SE</a></p>\n</blockquote>\n\n<p>How can I find out the arc length of a Bézier curve? For instance, the arc length of a linear Bézier curve is simply:</p>\n\n<p>$$s = \\sqrt{(x_1 - x_0)^2 + (y_1 - y_0)^2}$$</p>\n\n<p>But what of quadratic, cubic, or nth-degree Bézier curves?</p>\n\n<p>$$\\mathbf{B}(t) = \\sum_{i=0}^n {n\\choose i}(1-t)^{n-i}t^i\\mathbf{P}_i$$</p>\n", "pids": ["53e9b75ab7602d97042fb9ca"], "flag": 0}
{"question": "Can we grow enough crops to feed all people on Earth?", "body": "<p>Vegetarianism is heavily promoted. But let's say all people on Earth stop eating animal products. Can we grow enough crops so all people on the Earth are provided with enough healthy, nutritious food? </p>\n\n<p>The question is of course very theoretical, but without discussing future possibilities to cultivate deserts and oceans, is there enough space to grow enough crops? </p>\n", "pids": ["55a46c0465ce31bc877a3160"], "flag": 1}
{"question": "Roadmap to SPDEs", "body": "<p>I'm trying to learn about the Kushner-Stratonovich-Pardoux equations in filtering theory.</p>\n\n<p>I'm familiar with Itô calculus at the level of Øksendal's book (but struggle with much of Karatzas and Shreve, for example).</p>\n\n<p>My PDE theory is pretty weak. I know about the Fokker-Planck equations, and that's about it. My guess is that before I begin reading, I'll need to learn a significant amount of classical PDE theory. I would appreciate any recommendations for PDE textbooks that emphasize material that will be useful in the study of SPDEs. If someone could recommend a gentle introduction to SPDEs to go with it, I would be very grateful.</p>\n\n<p>Many thanks.</p>\n", "pids": ["53e9ab4fb7602d97034e11d9"], "flag": 0}
{"question": "When should I *not* permit a fixed effect to vary across levels of a random effect in a mixed effects model?", "body": "<p>Given a predicted variable (P), a random effect (R) and a fixed effect (F), one could fit two* mixed effects models (<a href=\"http://cran.r-project.org/web/packages/lme4/\" rel=\"noreferrer\">lme4</a> syntax):</p>\n<pre><code>m1 = lmer( P ~ (1|R) + F )\nm2 = lmer( P ~ (1+F|R) + F)\n</code></pre>\n<p>As I understand it, the second model is the one that permits the fixed effect to vary across levels of the random effect.</p>\n<p>In my research I typically employ mixed effects models to analyze data from experiments conducted across multiple human participants. I model participant as a random effect and experimental manipulations as fixed effects. I think it makes sense a priori to let the degree to which the fixed effects affect performance in the experiment vary across participants. However, I have trouble imagining circumstances under which I should nor permit the fixed effects to vary across levels of a random effect, so my question is:</p>\n<p>When should one <strong>not</strong> permit a fixed effect to vary across levels of a random effect?</p>\n", "pids": ["55a605b065cead59c832d077", "56d88c85dabfae2eeec329a8"], "flag": 1}
{"question": "Is there a general method of expressing optimization problem as a Hamiltonian?", "body": "<p>Let's say, that we have an optimization problem in the form:</p>\n\n<p><span class=\"math-container\">$$ \\min_x f(x) \\\\ g_i(x) \\leq 0, i = 1, ..., m \\\\ h_j(x) = 0, j = 1, ..., p,\n $$</span></p>\n\n<p>where <span class=\"math-container\">$f(x)$</span> is an objective function, <span class=\"math-container\">$g_i(x)$</span> are inequality constraints and <span class=\"math-container\">$h_j(x)$</span> are equality constraints.</p>\n\n<p>Recently I was reading about the <em><a href=\"https://en.wikipedia.org/wiki/Adiabatic_quantum_computation\" rel=\"noreferrer\">adiabatic quantum computing</a></em>. The Wikipedia says:</p>\n\n<blockquote>\n  <p>First, a (potentially complicated) Hamiltonian is found whose ground state describes the solution to the problem of interest. Next, a system with a simple Hamiltonian is prepared and initialized to the ground state. Finally, the simple Hamiltonian is adiabatically evolved to the desired complicated Hamiltonian. By the adiabatic theorem, the system remains in the ground state, so at the end the state of the system describes the solution to the problem. Adiabatic quantum computing has been shown to be polynomially equivalent to conventional quantum computing in the circuit model.</p>\n</blockquote>\n\n<p>Is there some general method of expressing the optimization problem (e.g. as presented above) in the Hamiltonian formalism used in <em>adiabatic quantum computing</em>?</p>\n", "pids": ["5c756d32f56def979850471a", "5c756be8f56def9798431776", "56d829d9dabfae2eeef522d8"], "flag": 1}
{"question": "Approximating roots of the truncated Taylor series of $\\exp$ by values of the Lambert W function", "body": "<p>If you map the nth roots of unity $z$ with the function $-W(-z/e)$ you get decent starting points for some root finding algorithm to the roots of the scaled truncated taylor series of $\\exp$. Here W is the lambertW function, $e$ is $\\exp(1)$ and 'scaled' in 'scaled truncated taylor series of exp' means the following: say if $$s_5(x) = 1+x+x^2/2+x^3/6+x^4/24+x^5/120$$ is the 'truncated taylor series of exp' of degree 5 then we will look at $s_5(5x)$ so we are looking at $s_n(nx)$  in general. </p>\n\n<p>Here is a plot <a src=\"https://i.stack.imgur.com/nixkp.jpg\" alt=\"curve\"> for the case $n=33$ (it only works for uneven $n$).\nUsing the lambert W function comes from formula (1.1) from paper 221 <a href=\"http://www.math.kent.edu/~varga/pub/\" rel=\"noreferrer\">available from here</a>. This formula is:</p>\n\n<p>$$e^{-nz}s_n(nz)=1-\\frac{\\sqrt{n}}{\\tau_n\\sqrt{2\\pi}}\\int_0^z(\\zeta e^{1-\\zeta})^n\\textrm{d}\\zeta,~~z\\in \\mathbb{C}$$</p>\n\n<p>$-W(-z/e)$ is the inverse of $ze^{1-z}$.</p>\n\n<p>How to get a better map from the roots of unity to the roots of this polynomial?\nAlternatively, is there some infinite sum representation for the roots? There isn't much difference: \"applying\" LambertW to some start values is pretty much the same as an infinite series.</p>\n\n<p>Here is an <a href=\"http://pastebin.com/iuq1dCCz\" rel=\"noreferrer\">octave script</a> for such a plot as the one above (To use lambertw(), as in the script, install the 'specfun' package for octave - or use a more number/function theory centric system than octave).</p>\n", "pids": ["53e9acb6b7602d97036961ac"], "flag": 0}
{"question": "Sampling random circuits vs Solovay-Kitaev compiler", "body": "<p>Suppose I want to obtain a gate sequence representing a particular 1 qubit unitary matrix.\nThe gate set is represented by a discrete universal set, e.g. Clifford+T gates or <span class=\"math-container\">$\\{T,H\\}$</span> gates.\nA well known approach to solve the problem is to use Solovay-Kitaev (SK) algorithm.\nI tried <a href=\"https://github.com/cryptogoth/skc-python\" rel=\"noreferrer\">this implementation</a> for SK algorithm. The resulting circuits are incredibly long (<span class=\"math-container\">$l\\sim 100-1000$</span> gates for the Fowler distance <span class=\"math-container\">$\\epsilon \\sim 0.01$</span>, tolerance error for the basic approximation <span class=\"math-container\">$\\epsilon\\sim 0.03$</span>). Moreover the basic approximation (building a KD-tree) can take quite long time (although this might be due to somewhat slow Python code).</p>\n\n<p>On the other hand I wrote a very simple script that generates random sequences of gates and selects the best performing circuits. It works very fast and results in much shorter circuits with Fowler distances <span class=\"math-container\">$\\epsilon&lt; 10^{-4}-10^{-5}$</span>. This should be more than sufficient for any realistic applications. </p>\n\n<p>So, at this point I don't quite understand, what is practical significance of Solovay-Kitaev algorithm in this case (for 1 qubit operations)? </p>\n\n<p>Of course, the theoretical scaling of SK algorithm looks pretty good. The number of gates generated by SK algorithm to approximate any 1 qubit unitary grows as <span class=\"math-container\">$l\\sim\\log^c(1/\\delta)$</span>, where <span class=\"math-container\">$\\delta$</span> is L2 approximation error. For random sampling there are no such guarantees. However on practice I'm not convinced that SK is very useful for 1 qubit case.\nNo doubts that in the case of large number of qubits random sampling will fail because of the curse of dimensionality. But it seems that SK algorithm also quickly becomes computationally unfeasible (<span class=\"math-container\">$\\#$</span> of qubits <span class=\"math-container\">$\\geq 4$</span>?). </p>\n", "pids": ["64990ccbd68f896efaf8470e"], "flag": 1}
{"question": "Why bother with Mathematics, if G&#246;del&#39;s Incompleteness Theorem is true?", "body": "<p>OK, maybe the title is exaggerated, but is it true that the rest of math is just \"good enough\", or a good approximation of absolute truth - like Newtonian physics compared to general relativity? How do we know that our \"approximation\" is the right one? Another analogy: Fundamental physics is also not  well-fundamented (where is the Higgs boson?) but most of the rest of the physics is on top of it, and it does its job well (it's a good-enough approximation).</p>\n\n<p><strong>Summary</strong>: According to the responses, math is indeed an imperfect domain, but can be seen as perfect for all practical purposes. In this case I wonder if math is indeed pure and identical across all possible universes. Maybe another universe comes up with a different set of axioms, more or less consistent than what we have now.</p>\n", "pids": ["53e9aadfb7602d9703460e90"], "flag": 0}
{"question": "Frequentism and priors", "body": "<p>Robby McKilliam says in a comment to <a href=\"https://stats.stackexchange.com/a/56/11697\">this</a> post:</p>\n\n<blockquote>\n  <p>It should be pointed out that, from the frequentists point of view, there is no reason that you can't incorporate the prior knowledge into the model. In this sense, the frequentist view is simpler, you only have a model and some data. There is no need to separate the prior information from the model</p>\n</blockquote>\n\n<p>Also, <a href=\"https://stats.stackexchange.com/a/20561/11697\">here</a>, @jbowman says that frequentists use regularization by a cost/penalty function, while bayesians can make this a prior:</p>\n\n<blockquote>\n  <p>Frequentists realized that regularization was good, and use it quite commonly these days - and Bayesian priors can be easily interpreted as regularization.</p>\n</blockquote>\n\n<p>So, my question is, can frequentists in general incorporate into their models what Bayesians specify as priors? Taking the regularization as an example, is the cost/penalty function really integrated into the model, or is this a purely artificial means of adjusting the solution (as well as making it unique)?</p>\n", "pids": ["53e99e4cb7602d9702710ed2"], "flag": 1}
{"question": "State of the art in quantum memory", "body": "<p>Presently, how much information can a quantum computer store, in how many qubits? What restrictions are there and how does it vary across realizations (efficiency of data storage, ease of reading and writing, etc)?</p>\n", "pids": ["55a6ae6665ce054aad70dbd0"], "flag": 1}
{"question": "Superposition of quantum circuits", "body": "<p>Given a quantum circuit <span class=\"math-container\">$C_1$</span> that generates a state <span class=\"math-container\">$\\vert\\psi\\rangle$</span> and another circuit <span class=\"math-container\">$C_2$</span> that generates <span class=\"math-container\">$\\vert\\phi\\rangle$</span>, is there a way to construct a circuit that outputs</p>\n<p><span class=\"math-container\">$$\\frac{1}{\\sqrt{2}}(\\vert \\psi\\rangle +\\vert\\phi\\rangle)$$</span></p>\n<p>using <span class=\"math-container\">$C_1$</span> and <span class=\"math-container\">$C_2$</span> as black boxes?</p>\n", "pids": ["5c7567f5f56def97981bfa33"], "flag": 1}
{"question": "Can a zombie apocalypse really occur?", "body": "<p>Now, before you flag this question as blatantly off-topic, I claim to have a scientific basis for this(!): not some drug or remote control, but parasitic infection.</p>\n<p>While reading about <a href=\"https://en.wikipedia.org/wiki/Behavior-altering_parasites_and_parasitoids\" rel=\"noreferrer\">behavior altering parasites and parasitoids</a>, I found this:</p>\n<blockquote>\n<p>Parasites that induce behavioral changes in their hosts often exploit the regulation of social behavior in the brain...For example, <em>Toxoplasma gondii</em> attaches to the hypothalamus rather than target a specific cellular pathway; this broad targeting leads to a widespread increase in host dopamine levels, which may in turn account for the loss of aversion to cat odor...This rise in dopamine levels induces a loss of aversion to cat odor in the rats, increasing the risk of predation by cats, <em>T. gondii</em>’s definitive host.</p>\n</blockquote>\n<p>Now, if a parasite can prevent mice from being afraid of cats, how hard would it be for another parasite to prevent humans from caring about each other's life(!)? <strong>Can a parasite develop some method by which it can alter behavior of humans in such a way that they just start killing each other for no reason? How easy/hard would it be for a parasite to do so?</strong></p>\n<p><em><strong>Note:</strong> although it is just a curiosity question about whether it is possible or not, giving some description of neural pathways which stimulate social behavior in humans and how they are regulated would be much more appreciated.</em></p>\n", "pids": ["55a4e41e65ceb7cb02db4d95"], "flag": 1}
{"question": "Is there a cure for Ebola?", "body": "<p>Wikipedia's page on <a href=\"http://en.wikipedia.org/wiki/Ebola_virus_disease\">\"Ebola Virus Disease\"</a> states:</p>\n\n<blockquote>\n  <p>No specific treatment for the virus is available.</p>\n</blockquote>\n\n<p>Wikipedia's page on <a href=\"http://simple.wikipedia.org/wiki/Ebola_virus\">\"Ebola Virus\"</a> also states:</p>\n\n<blockquote>\n  <p>There is no cure for Ebola, but if people get care quickly from\n  doctors and nurses at a hospital, more of them live.</p>\n</blockquote>\n\n<p>So how are there news articles telling us of people with Ebola who have been cured?</p>\n\n<p>We have a myriad of news articles describing people in the U.S and around the world. afflicted with Ebola that have now been cured:</p>\n\n<ul>\n<li><a href=\"http://www.cnn.com/2014/10/28/health/us-ebola/index.html?hpt=hp_t1\">Dallas nurse Amber Vinson</a>\n<ul>\n<li>Recovered</li>\n</ul></li>\n<li><a href=\"http://www.theguardian.com/world/2014/oct/24/texas-nurse-ebola-nina-pham-release-test-negative\">Dallas nurse Nina Pham</a>\n<ul>\n<li>Cured</li>\n</ul></li>\n<li><a href=\"http://www.nydailynews.com/life-style/health/experimental-ebola-treatments-primer-article-1.1986203\">Nebraskan journalist Ashoka Mukpo</a> \n<ul>\n<li>Cured</li>\n</ul></li>\n<li><a href=\"http://www.nbcnews.com/storyline/ebola-virus-outbreak/docs-declare-ebola-patients-kent-brantly-nancy-writebol-no-risk-n185626\">American missionary Nancy Writebol</a>\n<ul>\n<li>Cured/Recovered? (<em>See link above</em>)</li>\n</ul></li>\n<li><a href=\"http://time.com/3270016/ebola-survivor-kent-brantly/\">Dr. Kent Brantly</a>\n<ul>\n<li>Cured/Recovered? (<em>See link above</em>)</li>\n</ul></li>\n<li><a href=\"http://abcnews.go.com/Health/wireStory/spain-woman-free-ebola-virus-2nd-test-shows-26345120\">Spanish nurse assitant Teresa Romero</a>\n<ul>\n<li>Recovered</li>\n</ul></li>\n<li><a href=\"http://www.voanews.com/content/french-ebola-patient-recovers/2472644.html\">Unnamed French nurse</a>\n<ul>\n<li>Cured</li>\n</ul></li>\n</ul>\n\n<p>Is there really no treatment for the disease? Then how are these people surviving? How are they getting treated? I am especially confused by the wording the articles use.  Some use the word \"surviving\" to describe some people's incidents with the disease, which would imply that they had not been cured, but some articles also state they \"were cured\", which would imply there exists a cure for Ebola.</p>\n", "pids": ["55a68bd765ce054aad6b26db"], "flag": 1}
{"question": "Clustering &amp; Time Series", "body": "<p>I have a multivariate dataset that changes over time. I have extracted (and normalised) some features and used <strong>k-means</strong> to generate clusters over the entire span of the dataset.</p>\n<p>Now I want to see whether the clusters change significantly over time. So, working backwards, and thus reducing the dataset by x-months, can I see a significant reduction on certain clusters?</p>\n<p>This, I think, could fall within the realm of time series clustering. I was hoping to avoid complicating the approach, since the clusters are currently meaningful and the approach is relatively simple.</p>\n<p>Could anyone please advise me on how to go about this?</p>\n<p>My intuition is <strong>to reduce the dataset by x-months and then cluster (using k-means) the data for comparison</strong>.  However, I may be breaking the rules here, and oversimplifying a complicated problem.</p>\n", "pids": ["629587475aee126c0fe14f5c"], "flag": 1}
{"question": "Are spin-glass problems NP (-complete)?", "body": "<p>It is well known that finding ground states for spin-glass systems (Ising, XY...) is NP-hard (at least as hard as the hardest NP-problems) so that they can be efficiently used to solve other NP problems like the Traveling Salesman Problem. </p>\n<p>My question is: is the problem NP-complete? This seems to be what is claimed <a href=\"https://archive.siam.org/pdf/news/654.pdf\" rel=\"noreferrer\">here</a>. To my understanding, this would mean that apart from NP-hard, the problem is NP itself. But I don't know an obvious algorithm to check if a given solution is the true ground state in polynomial time?\nAnd actually, I think that a similar argument can be made for the traveling salesman problem.</p>\n", "pids": ["5390994d20f70186a0e1396c"], "flag": 1}
{"question": "Did &quot;fossil-fuel pollution [kill] three times as many people as COVID-19 did&quot; in 2020?", "body": "<p>Bill McKibben writes for <em>The New Yorker</em> in a March 18, 2022 article titled <a href=\"https://www.newyorker.com/news/essay/in-a-world-on-fire-stop-burning-things\" rel=\"noreferrer\">&quot;In a World on Fire, Stop Burning Things&quot;</a> (emphasis added):</p>\n<blockquote>\n<p>Our species depends on combustion; it made us human, and then it made us modern. But, having spent millennia learning to harness fire, and three centuries using it to fashion the world we know, we must spend the next years systematically eradicating it. Because, taken together, those blazes—the fires beneath the hoods of 1.4 billion vehicles and in the homes of billions more people, in giant power plants, and in the boilers of factories and the engines of airplanes [and] ships—are more destructive than the most powerful volcanoes, dwarfing Krakatoa and Tambora. <strong>The smoke and smog from those engines and appliances directly kill nine million people a year, more deaths than those caused by war and terrorism, not to mention malaria and tuberculosis, together. (In 2020, fossil-fuel pollution killed three times as many people as COVID-19 did.)</strong></p>\n</blockquote>\n<p>In 2020, did three times as many people die from fossil-fuel pollution as from COVID-19?</p>\n", "pids": ["627e281f5aee126c0f826ed8"], "flag": 1}
{"question": "Are circuits with more than 1000 gates common?", "body": "<p>I have seen circuits with 30 qubits and around 500 gates. Also circuits with 32 qubits and 6000 gates. Are circuits with more than 1000 gates common in quantum computing? Are there many quantum algorithms that require more than 1000 gates? How common are they?</p>\n", "pids": ["5d0b00a68607575390fd7781", "5fa9196491e011e83f740817", "5e3006423a55ac0524a25c26"], "flag": 1}
{"question": "State produced by spontaneous parametric down-conversion (SPDC)", "body": "<p>I'm researching SPDC's efficacy for use in an optical quantum computing model and I've been trying to figure out exactly what state the photons are in when they come out (as represented by a vector, for example), if I'm using type 1 SPDC and I'm looking at the polarization of the photons.</p>\n\n<p>Please provide any references used =)</p>\n", "pids": ["55a5d4bd65ce60f99bf6a890"], "flag": 1}
{"question": "Can quantum computers handle &#39;big&#39; data?", "body": "<p>While there are many interesting questions that a computer can solve with barely any data (such as factorization, which requires \"only\" a single integer), most real-world applications, such as <a href=\"https://en.wikipedia.org/wiki/Machine_learning\" rel=\"nofollow noreferrer\">machine learning</a> or <a href=\"https://en.wikipedia.org/wiki/Artificial_intelligence\" rel=\"nofollow noreferrer\">AI</a>, will require large amounts of data.</p>\n\n<p>Can quantum computers handle this massive stream of data, in theory or in practice? Is it a good idea to store the data in a \"quantum memory\", or is it better to store it in a \"classical memory\"? </p>\n", "pids": ["53e9b082b7602d9703aea4a8"], "flag": 1}
{"question": "Is gradient boosting appropriate for data with low event rates like 1%?", "body": "<p>I am trying gradient boosting on a dataset with event rate about 1% using Enterprise miner, but it is failing to produce any output. My question is, since it a decision tree based approach, is it even right to use gradient boosting with such low event?</p>\n", "pids": ["53e9a21db7602d9702b230a5"], "flag": 1}
{"question": "Why use a certain measure of forecast error (e.g. MAD) as opposed to another (e.g. MSE)?", "body": "<p>MAD = Mean Absolute Deviation\nMSE = Mean Squared Error</p>\n\n<p>I've seen suggestions from various places that MSE is used despite some undesirable qualities (e.g. <a href=\"http://www.stat.nus.edu.sg/~staxyc/T12.pdf\" rel=\"noreferrer\">http://www.stat.nus.edu.sg/~staxyc/T12.pdf</a>, which states on p8 \"It is commonly believed that MAD is a better criterion than MSE. However, mathematically MSE is more convenient than MAD.\")</p>\n\n<p>Is there more to it than that? Is there a paper that thoroughly analyzes the situations in which various methods of measuring forecast error are more/less appropriate? My google searches haven't revealed anything. </p>\n\n<p>A similar question to this was asked at <a href=\"https://stackoverflow.com/questions/13391376/how-to-decide-the-forecasting-method-from-the-me-mad-mse-sde\">https://stackoverflow.com/questions/13391376/how-to-decide-the-forecasting-method-from-the-me-mad-mse-sde</a>, and the user was asked to post on stats.stackexchange.com, but I don't think they ever did.</p>\n", "pids": ["619b6a401c45e57ce9ee99d3"], "flag": 1}
{"question": "Intuition behind topological spaces", "body": "<p>I'm studying topology since a few months ago and I have never caught a good intuition of the topological spaces, but now I think that I did.</p>\n<p>My intuition is the next; as many people point out the open sets capture a notion of nearness,\n(but I did never understand the exact way of this nearness intuition),the points in the open sets are near, and two points in distinct open sets are far, and then the axioms try to capture the behaviours of the opens.</p>\n<p>To find a good intuition I have worked with two examples of spaces which I named <span class=\"math-container\">$A$</span> and <span class=\"math-container\">$B$</span>;\n<span class=\"math-container\">$A=[\\{a,b,c,d,e,f\\},(\\{a,b,c,d,e,f\\},\\{\\},\\{a,b,c,e,f\\},\\{e,f\\},\\{a,b\\},\\{a,b,d,e,f\\},\\{a,b,e,f\\})]$</span>,\n<span class=\"math-container\">$B=[\\{a,b,c,d,e,f\\},(\\{a,b,c,d,e,f\\},\\{\\},\\{a,b,c,e,f\\},\\{a,b,d,e,f\\},\\{a,b,e,f\\})]$</span><br />\nand I obtained the next pictures (and here is my first question: are these  the correct spatial representaition of the spaces? <span class=\"math-container\">$A$</span> is in the right, <span class=\"math-container\">$B$</span> is the left, the black circles represent points):</p>\n<p><a href=\"https://i.stack.imgur.com/NDaGZ.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/NDaGZ.png\" alt=\"enter image description here\" /></a></p>\n<p>And then the union axiom allows to establish different degrees of nearness, specifically the opens that aren't union of other opens  have near points, and the unions have points nearer than other points that aren't. Concretely in the space <span class=\"math-container\">$A$</span>; <span class=\"math-container\">$\\{e,f\\}$</span> and <span class=\"math-container\">$\\{a,b\\}$</span> are nearer than <span class=\"math-container\">$c$</span> and <span class=\"math-container\">$d$</span>, then the unions allow to speak of a &quot;global &quot; nearness.</p>\n<p>The intersection axiom also talk about  different degrees of nearness, in the way that if we have near points and we have other near points that have common points, then than points are near, and in fact they are nearer, and so the intersection  talk of a &quot;local&quot; nearness.</p>\n<p>And finally the axiom of the necessary membership of the space itself and the empty set, guarantees the fact that &quot;there are nothing outside the space&quot; or the totality of the space and in that sense all the points are near in the space.</p>\n<p>Is this a good intuition? if not, please give me a good one.</p>\n", "pids": ["53e9ba65b7602d9704683584"], "flag": 0}
{"question": "Fast method for finding best metaparameters of SVM (that is faster than grid search)", "body": "<p>I am using SVM models to do short term forecasting of air pollutants. To train a new model I need to find appropriate metaparameters for an SVM model (I mean C, gamma and so on). </p>\n\n<p>Libsvm documentation (and many other books I have read) suggests using grid search to find these parameters - so I basically train model for each combination of these parameters from a certain set and choose the best model. </p>\n\n<p>Is there any better way to find optimal (or near optimal) metaparameters? For me it is mainly a matter of computation time - one grid search of this problem takes about two hours (after I did some optimisations). </p>\n\n<p>Pros of grid search:  </p>\n\n<ul>\n<li>It can be easily parallelized - if you have 20 CPUs it will run 20 times faster, parallelizing other methods is harder</li>\n<li>You check big parts of metaparameter space, so if there is a good solution you will find it. </li>\n</ul>\n", "pids": ["5390972920f70186a0dfa5e1"], "flag": 1}
{"question": "How can quantum decoherence be managed?", "body": "<p>I've stumbled myself upon <a href=\"https://en.wikipedia.org/wiki/Quantum_decoherence\" rel=\"noreferrer\">this article</a> on Wikipedia, which says:</p>\n<blockquote>\n<p>Decoherence can be viewed as the <strong>loss of information from a system into the environment</strong> (often modeled as a heat bath), since every system is loosely coupled with the energetic state of its surroundings.</p>\n<p><em>&lt;...&gt;</em></p>\n<p>Decoherence represents a challenge for the practical realization of quantum computers, since such machines are expected to rely heavily on the undisturbed evolution of quantum coherences. Simply put, they require that coherent states be preserved and that <strong>decoherence is managed</strong>, in order to actually perform quantum computation.</p>\n</blockquote>\n<p><sup><em>(emphasis mine)</em></sup></p>\n<p>So I am wondering how can this <code>loss of information</code> be managed? Does this mean that it should be prevented completely, or is it necessary for quantum computing to actually allow some information loss in order to compute?</p>\n", "pids": ["53e9a620b7602d9702f5159b"], "flag": 1}
{"question": "How to construct a multi-qubit controlled-Z from elementary gates?", "body": "<p>For the implementation of a certain quantum algorithm, I need to construct a multi-qubit (in this case, a three-qubit) controlled-Z gate from a set of elementary gates, as shown in the figure below.\n<a href=\"https://i.stack.imgur.com/IA6d1.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/IA6d1.png\" alt=\"Three-qubit controlled-Z gate.\"></a>\n.</p>\n\n<p>The gates that I can use are</p>\n\n<ul>\n<li>the Pauli gates $\\rm X, Y, Z$ and all their powers (i.e. all Pauli rotations up to a phase factor),</li>\n<li>${\\rm exp}(i\\theta|11\\rangle\\langle11|)$ (rotation about $|11\\rangle\\langle11|$ projector),</li>\n<li>$\\rm H$ (Hadamard),</li>\n<li>$\\rm C_X$ (single-qubit controlled-X or CNOT),</li>\n<li>$\\rm C_Z$ (single-qubit controlled-Z), and</li>\n<li>$\\rm S$ (SWAP).</li>\n</ul>\n\n<p>How can I go about building this three-qubit controlled-Z from these gates? I have read several papers on circuit decompositions, but none of them could give me a clear and concise answer.</p>\n", "pids": ["53e9a965b7602d97032bec7e", "53e9aeb7b7602d97038d98cb", "599c7965601a182cd2638ee9"], "flag": 1}
{"question": "Performing PCA with only a distance matrix", "body": "<p>I want to cluster a massive dataset for which I have only the pairwise distances. I implemented a k-medoids algorithm, but it's taking too long to run so I would like to start by reducing the dimension of my problem by applying PCA. However, the only way I know to perform this method is using the covariance matrix which I don't have in my situation.</p>\n\n<p>Is there a way to apply PCA knowing the pairwise distances only?</p>\n", "pids": ["5f0e1d6d9fced0a24b70cb05"], "flag": 1}
{"question": "Applications of Gr&#246;bner bases", "body": "<p>I would like to present an application of Gröbner bases.  The audience is a class of first year graduate students who are taking first year algebra.  </p>\n\n<p>Does anyone have suggestions on a specific application that the audience would appreciate?</p>\n", "pids": ["53e9a091b7602d970297c347", "53e9a374b7602d9702c7d6a8", "53e99e31b7602d97026f442b", "53e9bd4bb7602d97049da4b6"], "flag": 0}
{"question": "Area under the ROC curve or area under the PR curve for imbalanced data?", "body": "<p>I have some doubts about which performance measure to use, area under the ROC curve (TPR as a function of FPR) or area under the precision-recall curve (precision as a function of recall).</p>\n\n<p>My data is imbalanced, i.e., the number of negative instances is much larger than positive instances.</p>\n\n<p>I am using the output prediction of weka, a sample is:</p>\n\n<pre><code>inst#,actual,predicted,prediction\n1,2:0,2:0,0.873\n2,2:0,2:0,0.972\n3,2:0,2:0,0.97\n4,2:0,2:0,0.97\n5,2:0,2:0,0.97\n6,2:0,2:0,0.896\n7,2:0,2:0,0.973\n</code></pre>\n\n<p>And I am using pROC and ROCR r libraries.</p>\n", "pids": ["53e99d3eb7602d97025f507b"], "flag": 1}
{"question": "How to correctly assess the correlation between ordinal and a continuous variable?", "body": "<p>I'd like to estimate the correlation between:</p>\n\n<p>An ordinal variable: subjects are asked to rate their preference for 6 types of fruit on a 1-5 scale (ranging from very disgusting to very tasty) On average subjects use only 3 points of the scale.</p>\n\n<p>A continuous variable: the same subjects are asked to quickly identify these fruits, which results in an mean accuracy for the 6 fruits. </p>\n\n<p>Is Spearman rho the best method to analyze these data and/or are there other good methods I could consider?</p>\n", "pids": ["53e9aa48b7602d97033b5861"], "flag": 1}
{"question": "Do optimization techniques map to sampling techniques?", "body": "<p>From any generic sampling algorithm, one can derive an optimization algorithm.</p>\n\n<p>Indeed, to maximize an arbitrary function $f: \\textbf{x} \\rightarrow f(\\textbf{x})$, it suffices to draw samples from $g \\sim e^{f/T}$. For $T$ small enough, these samples will fall near the global maximum (or local maxima in practice) of the function $f$.</p>\n\n<p>By \"sampling\" I mean, drawing a pseudo-random sample from a distribution given a log-likelihood function known up to a constant. For instance, MCMC sampling, Gibbs sampling, Beam Sampling, etc. By \"optimization\" I mean the attempt to find parameters maximizing the value of a given function. </p>\n\n\n\n<p>Is the reverse possible?\nGiven a heuristic to find the maximum of a function or a combinatorial expression, can we extract an efficient sampling procedure? </p>\n\n<p>HMC for instance seems to take advantage of gradient information. Can we construct a sampling procedure that takes advantage of a BFGS-like approximation of the Hessian?\n(edit: apparently yes: <a href=\"http://papers.nips.cc/paper/4464-quasi-newton-methods-for-markov-chain-monte-carlo.pdf\">http://papers.nips.cc/paper/4464-quasi-newton-methods-for-markov-chain-monte-carlo.pdf</a>)\n We can use MCTS in combinatorial problems, can we translate that into a sampling procedure?</p>\n\n<p>Context:  a difficulty in sampling is often that most of the mass of the probability distribution lies within a very small region. There are interesting techniques to find such regions, but they do not directly translate into unbiased sampling procedures. </p>\n\n\n\n<p>Edit: I now have a lingering feeling that the answer to that question is somewhat equivalent to the equality of complexity classes #P and NP, making the answer a likely \"no\". It does explain why every sampling technique yields an optimization technique but not vice versa.</p>\n", "pids": ["53e9a832b7602d970317a700"], "flag": 1}
{"question": "General construction of $W_n$-state", "body": "<p>Two of the most well known entangled states are the GHZ-state <span class=\"math-container\">$|\\psi\\rangle = 1/\\sqrt{2}\\left( |0\\rangle^{\\otimes n} + |1\\rangle^{\\otimes n}\\right)$</span> and the <span class=\"math-container\">$W_n$</span>-state, with <span class=\"math-container\">$W_3 = 1/\\sqrt{3}\\left(|100\\rangle + |010\\rangle + |001\\rangle\\right)$</span>. </p>\n\n<p>Constructing the GHZ-state is simple for arbitrary <span class=\"math-container\">$n$</span>. However, implementing the <span class=\"math-container\">$W_n$</span>-state is more difficult. For <span class=\"math-container\">$n=2$</span> it is easy, and for <span class=\"math-container\">$n=4$</span> we can use</p>\n\n<pre><code>H q[0,3]\nX q[0,3]\nToffoli q[0],q[3],q[1]\nX q[0,3]\nToffoli q[0],q[3],q[2]\nCNOT q[2],q[0]\nCNOT q[2],q[3]\n</code></pre>\n\n<p>Even for <span class=\"math-container\">$n=3$</span> we have implementations, see <a href=\"https://physics.stackexchange.com/questions/311743/quantum-circuit-for-a-3-qubit-w-state\">this answer</a> for instance. However, I have not found an algorithm that, given an <span class=\"math-container\">$n$</span>, outputs the circuit for constructing the <span class=\"math-container\">$W_n$</span>-state. </p>\n\n<p>Does such an algorithm, defined by single- and two-qubit gates, exist? And if so, what is it? </p>\n", "pids": ["5c7574f8f56def97989a304f", "5c756739f56def979815725a"], "flag": 1}
{"question": "Is there any general statement about what kinds of problems can be approximated more efficiently using a quantum computer?", "body": "<p>As the name already suggests, this question is a follow-up of <a href=\"https://quantumcomputing.stackexchange.com/q/1584/1346\">this other</a>. I was delighted with the quality of the answers, but I felt it would be immensely interesting if insights regarding optimization and approximation techniques were added, but might fall off-topic, hence this question.</p>\n\n<p>From Blue's answer:</p>\n\n<blockquote>\n  <p>the rule of thumb in complexity theory is that if a quantum computer \"can help\" in terms of solving in polynomial time (with an error bound) iff the class of problem it can solve lies in BQP but not in P or BPP</p>\n</blockquote>\n\n<p>How does this apply to approximation classes? Is there any specific topological, numerical, etc property of quantum computing that can be leveraged?</p>\n\n\n\n<p>As an example of what could I be asking (but definitely not restricted to that!), take the <a href=\"https://en.wikipedia.org/wiki/Christofides_algorithm\" rel=\"nofollow noreferrer\">Christofides algorithm</a>: it exploits specific geometrical properties of the graph that it optimizes on (symmetry, triangle inequality): the salesman travels on a feasible world. But salesmen have also huge mass, and we can know their position and momentum at the same time with great precision. Maybe a quantum model could work as well for other kind of metrics with more relaxed restrictions, like the <a href=\"https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Relation_to_metrics\" rel=\"nofollow noreferrer\">K-L divergence</a>? In that case solving it would still be NP complete, but the optimization would apply for a broader topology. This example is maybe a long shot, but I hope you get what I mean. I don't really know if it makes sense at all, but the answer could also address it in that case :)</p>\n\n\n\n<p><strong>RELATED:</strong></p>\n\n<ul>\n<li><a href=\"https://quantumcomputing.stackexchange.com/q/126/1346\">Level of advantage provided by annealing for traveling salesman</a></li>\n</ul>\n", "pids": ["60de5c3891e0110ac15e4407"], "flag": 1}
{"question": "What is quantum entanglement, and what role does it play in quantum error correction?", "body": "<p>I want to understand what quantum entanglement is and what role does it play in quantum error correction. </p>\n\n<p><strong>NOTE</strong>:\nAs per the suggestions of @JamesWootton and @NielDeBeaudrap, I have asked a separate question for the classical analogy <a href=\"https://quantumcomputing.stackexchange.com/q/1554/1678\">here</a>.</p>\n", "pids": ["5d3196783a55ac8592bf99a3", "53e99a52b7602d97022b46ac"], "flag": 1}
{"question": "why boosting method is sensitive to outliers", "body": "<p>I found many articles that state that boosting methods are sensitive to outliers, but no article explaining why. </p>\n\n<p>In my experience outliers are bad for any machine learning algorithm, but why are boosting methods singled out as particularly sensitive?</p>\n\n<p>How would the following algorithms to rank in terms of sensitivity to outliers: boost-tree, random forest, neural network, SVM, and simple regression methods such as logistic regression?</p>\n", "pids": ["573696016e3b12023e515803"], "flag": 1}
{"question": "Generalized Additive Model Python Libraries", "body": "<p>I know that R has gam and mgcv libraries for generalized additive models.  But I am having difficulty finding their counterparts in the Python ecosystem (statsmodels only has prototype in the sandbox).  Is anyone aware of existing python libraries?  Who knows this might be a good project to develop/contribute to scikit-learn if not.</p>\n", "pids": ["61a888256750f82b17638ca7"], "flag": 1}
{"question": "Are true Projective Measurements possible experimentally?", "body": "<p>I have heard various talks at my institution from experimentalists (who all happened to be working on superconducting qubits) that the textbook idea of true \"Projective\" measurement is not what happens in real-life experiments. Each time I asked them to elaborate, and they say that \"weak\" measurements are what happen in reality.</p>\n\n<p>I assume that by \"projective\" measurements they mean a measurement on a quantum state like the following:</p>\n\n<p>$$P\\vert\\psi\\rangle=P(a\\vert\\uparrow\\rangle+ b\\vert\\downarrow\\rangle)=\\vert\\uparrow\\rangle \\,\\mathrm{or}\\, \\vert\\downarrow\\rangle$$</p>\n\n<p>In other words, a measurement which fully collapses the qubit.</p>\n\n<p>However, if I take the experimentalist's statement that real measurements are more like strong \"weak\"-measurements, then I run into Busch's theorem, which says roughly that you only get as much information as how strongly you measure. In other words, I can't get around not doing a full projective measurement, I need to do so to get the state information</p>\n\n<p>So, I have two main questions:</p>\n\n<ol>\n<li><p>Why is it thought that projective measurements cannot be performed experimentally? What happens instead?</p></li>\n<li><p>What is the appropriate framework to think about experimental measurement in quantum computing systems that is actually realistic? Both a qualitative and quantitative picture would be appreciated.</p></li>\n</ol>\n", "pids": ["53e9a003b7602d97028e7734"], "flag": 1}
{"question": "How is Grover&#39;s algorithm used to estimate the mean and median of a set of numbers?", "body": "<p>On the <a href=\"https://en.wikipedia.org/wiki/Grover%27s_algorithm\" rel=\"noreferrer\">Wikipedia page for Grover's algorithm</a>, it is mentioned that:</p>\n\n<p><em>\"Grover's algorithm can also be used for estimating the mean and median of a set of numbers\"</em> </p>\n\n<p>So far I only knew how it can be used to search a database. But not sure how to implement that technique to estimate the mean and median of a set of numbers. Moreover, there's no citation (as far as I noticed) on that page which explains the technique.  </p>\n", "pids": ["5f0eb63d9fced0a24bf622f3", "53e9baecb7602d970471fa83"], "flag": 1}
{"question": "In what kind of real-life situations can we use a multi-arm bandit algorithm?", "body": "<p>Multi-arm bandits work well in situation where you have choices and you are not sure which one will maximize your well being. You can use the algorithm for some real life situations. As an example, learning can be a good field: </p>\n\n<blockquote>\n  <p>If a kid is learning carpentry and he is bad at it, the algorithm will tell him/her that he/she probably should need to move on. If he/she is good at it, the algorithm will tell him/her to continue to learn that field. </p>\n</blockquote>\n\n<p>Dating is a also a good field:</p>\n\n<blockquote>\n  <p>You're a man on your putting a lot of 'effort' in pursuing a lady. However, your efforts are definitely unwelcomed. The algorithm should \"slightly\" (or strongly) nudge you to move on.</p>\n</blockquote>\n\n<p>What others real-life situation can we use the multi-arm bandit algorithm for?</p>\n\n<p><sub>PS: If the question is too broad, please leave a comment. If there is a consensus, I'll remove my question.</sub></p>\n", "pids": ["5c871f994895d9cbc6cebc7b"], "flag": 1}
{"question": "Rigorous security proof for Wiesner&#39;s quantum money", "body": "<p>In his celebrated paper \"<a href=\"https://www.researchgate.net/publication/234782642_Conjugate_Coding\" rel=\"noreferrer\">Conjugate Coding</a>\" (written around 1970), Stephen Wiesner proposed a scheme for quantum money that is unconditionally impossible to counterfeit, assuming that the issuing bank has access to a giant table of random numbers and that banknotes can be brought back to the bank for verification. In Wiesner's scheme, each banknote consists of a classical \"serial number\" $s$, together with a quantum money state $|\\psi_s\\rangle$ consisting of $n$ unentangled qubits, each one either</p>\n\n<p>$$|0\\rangle,\\ |1\\rangle,\\ |+\\rangle=(|0\\rangle+|1\\rangle)/\\sqrt{2},\\ \\text{or}\\ |-\\rangle=(|0\\rangle-|1\\rangle)/\\sqrt{2}.$$</p>\n\n<p>The bank remembers a classical description of $|\\psi_s\\rangle$ for every $s$.  And therefore, when $|\\psi_s\\rangle$ is brought back to the bank for verification, the bank can measure each qubit of $|\\psi_s\\rangle$ in the correct basis (either $\\{|0\\rangle,|1\\rangle\\}$ or $\\{|+\\rangle,|-\\rangle\\}$), and check that it gets the correct outcomes.</p>\n\n<p>On the other hand, because of the uncertainty relation (or alternatively, the No-Cloning Theorem), it's \"intuitively obvious\" that, if a counterfeiter who <i>doesn't</i> know the correct bases tries to copy $|\\psi_s\\rangle$, then the probability that <i>both</i> of the counterfeiter's output states pass the bank's verification test can be at most $c^n$, for some constant $c&lt;1$.  Furthermore, this should be true regardless of what strategy the counterfeiter uses, consistent with quantum mechanics (e.g., even if the counterfeiter uses fancy entangled measurements on $|\\psi_s\\rangle$).</p>\n\n<p>However, while writing a paper about other quantum money schemes, my coauthor and I realized that we'd never seen a rigorous proof of the above claim anywhere or an explicit upper bound on $c$: neither in Wiesner's original paper nor in any later one.</p>\n\n<p>So, <i>has</i> such a proof (with an upper bound on $c$) been published?  If not, then can one derive such a proof in a more-or-less straightforward way from (say) approximate versions of the No-Cloning Theorem, or results about the security of the BB84 quantum key distribution scheme?</p>\n\n<p>I should maybe clarify that I'm looking for more than just a reduction from the security of BB84.  Rather, I'm looking for an <i>explicit upper bound</i> on the probability of successful counterfeiting (i.e., on $c$)---and ideally, also some understanding of what the optimal counterfeiting strategy looks like.  I.e., does the optimal strategy simply measure each qubit of $|\\psi_s\\rangle$ independently, say on the basis</p>\n\n<p>$$\\{ \\cos(\\pi/8)|0\\rangle+\\sin(\\pi/8)|1\\rangle, \\sin(\\pi/8)|0\\rangle-\\cos(\\pi/8)|1\\rangle \\}?$$</p>\n\n<p>Or is there an entangled counterfeiting strategy that does better?</p>\n\n<p>Right now, the best counterfeiting strategies that I know are (a) the strategy above, and (b) the strategy that simply measures each qubit in the $\\{|0\\rangle,|1\\rangle\\}$ basis and \"hopes for the best.\"  Interestingly, <i>both</i> of these strategies turn out to achieve a success probability of $(5/8)$<sup>$n$</sup>.  So, my conjecture of the moment is that $(5/8)$<sup>$n$</sup> might be the right answer.  In any case, the fact that $5/8$ is a <i>lower</i> bound on c rules out any security argument for Wiesner's scheme that's \"too\" simple (for example, any argument to the effect that there's nothing nontrivial that a counterfeiter can do, and therefore the right answer is $c=1/2$).</p>\n", "pids": ["57a4e91aac44365e35c978bf", "56d85a22dabfae2eee481ed9"], "flag": 1}
{"question": "Testing for coefficients significance in Lasso logistic regression", "body": "<p>[A similar question was asked <a href=\"https://stats.stackexchange.com/questions/108272/repeated-multiple-regression-for-lasso-significance-testing\">here</a> with no answers]</p>\n<p>I have fit a <strong>logistic regression model with L1 regularization</strong> (Lasso logistic regression) and I would like to test the fitted coefficients for significance and get their p-values. I know Wald's tests (for instance) are an option to test the significance of individual coefficients in full regression without regularization, but with Lasso I think further problems arise which do not allow to apply the usual Wald formulas. For instance, the variance estimates neded for the test do not follow the usual expressions. The original Lasso paper:</p>\n<p><a href=\"http://statweb.stanford.edu/%7Etibs/lasso/lasso.pdf\" rel=\"nofollow noreferrer\">Regression Shrinkage and Selection via the Lasso</a></p>\n<p>suggests a bootstrap-based procedure to estimate the coefficients variance, which (again, I think) may be needed for the tests (section 2.5, last paragraph of page 272 and beginning of 273):</p>\n<blockquote>\n<p>One approach is via the bootstrap: either <span class=\"math-container\">$t$</span> can be fixed or we may optimize over <span class=\"math-container\">$t$</span> for each bootstrap sample. Fixing <span class=\"math-container\">$t$</span> is analogous to selecting the best subset (<em>of features</em>) and then using the least squares standard error for that subset</p>\n</blockquote>\n<p>What I understand is: fit a Lasso regression repeatedly to the whole dataset until we find the optimal value for the regularization parameter (this is not part of the bootstrap), and then use only the features selected by the Lasso to fit OLS regressions to subsamples of the data and apply the usual formulas to compute the variances from each of those regressions. (And then what should I do with all those variances of each coefficient to get the final variance estimate of each coefficient?)</p>\n<p>Furthermore, is it correct to use the usual significance tests (for instance Wald's test which makes use of the estimated betas and variances) with the Lasso estimates of the coefficients and the bootstrap-estimated variances? I am fairly sure it is not, but any help (use a different test, use a more straightforward approach, whaterever...) is more than welcome.</p>\n<p>According to the answers <a href=\"https://stats.stackexchange.com/questions/153889/insignificant-coefficients-in-logistic-regression-after-lasso-variable-selection\">here</a> I suspect inference and p-values just cannot be obtained. In my case, p-values are an external requirement (although the use of L1 regularization was my choice).</p>\n<p>Thanks a lot</p>\n<p><strong>EDIT</strong>\nWhat if I fit an OLS logistic regression using only the variables selected by a previous run of the Lasso logistic regression? Apparently (see <a href=\"https://stats.stackexchange.com/questions/153889/insignificant-coefficients-in-logistic-regression-after-lasso-variable-selection\">here</a>),</p>\n<blockquote>\n<p>There's no need to run the model again after doing cross-validation (you just get the coefficients from the output of cv.glmnet), and in fact if you fit the new logistic regression model without penalisation then you're defeating the purpose of using lasso</p>\n</blockquote>\n<p>But what if I do this with the sole purpose of being able to compute p-values while keeping the number of variables low? Is it a very dirty approach? :-)</p>\n", "pids": ["56d839efdabfae2eee58ed02", "5c610977da56297340b79e3d"], "flag": 1}
{"question": "simulating random samples with a given MLE", "body": "<p>This Cross Validated question asking about <a href=\"https://stats.stackexchange.com/q/243260/7224\">simulating a sample conditional on having a fixed sum</a> reminded me of a problem set to me by <a href=\"https://xianblog.wordpress.com/2012/06/18/george-casella/\" rel=\"noreferrer\">George Casella</a>. </p>\n\n<blockquote>\n  <p>Given a parametric model $f(x|\\theta)$, and an iid sample from this model,\n  $(X_1,\\ldots,X_n)$, the MLE of $\\theta$ is given by\n  $$\\hat{\\theta}(x_1,\\ldots,x_n)=\\arg\\min \\sum_{i=1}^n \\log\n  f(x_i|\\theta)$$ For a given value of $\\theta$, is there a generic way\n  to simulate an iid sample $(X_1,\\ldots,X_n)$ conditional on the value of\n  the MLE $\\hat{\\theta}(X_1,\\ldots,X_n)$?</p>\n</blockquote>\n\n<p>For instance, take a $\\mathfrak{T}_5$ distribution, with location parameter $\\mu$, which density is$$f(x|\\mu)=\\dfrac{\\Gamma(3)}{\\Gamma(1/2)\\Gamma(5/2)}\\,\\left[1+(x-\\mu)^2/5\\right]^{-3}$$If $$(X_1,\\ldots,X_n)\\stackrel{\\text{iid}}{\\sim} f(x|\\mu)$$how can we simulate $(X_1,\\ldots,X_n)$ conditional on $\\hat{\\mu}(X_1,\\ldots,X_n)=\\mu_0$? In this $\\mathfrak{T}_5$ example, the distribution of $\\hat{\\mu}(X_1,\\ldots,X_n)$ does not have a closed form expression.</p>\n", "pids": ["599c7cc1601a182cd27d4686"], "flag": 1}
{"question": "Why does (almost) every pair of Hamiltonians generate, through repeated commutation, the whole space of Hermitian matrices?", "body": "<p>In [1], the problem of simulating a Hamiltonian using repeated applications of a different set of Hamiltonians is discussed.</p>\n\n<p>In particular, let $A$ and $B$ be a pair of Hermitian operators, and let $\\mathcal L$ be the algebra generated from $A, B$ through repeated commutation $^{\\mathbf{(\\dagger)}}$.</p>\n\n<p>The author then asks (first paragraph of third page) what  is $\\mathcal L$ for an arbitrary pair of observables $A$ and $B$, and argues that $\\mathcal L$ is the space of all Hermitian matrices, unless (quoting from the paper) <em>both $e^{iA t}$ and $e^{iB t}$ lie in an $n$-dimensional unitary representation of some Lie group other than $U(n)$</em>.</p>\n\n<p>I'm not too familiar with the theory of Lie algebras, so this statement is quite cryptic for me.\nHow can this be shown more explicitly?\nEquivalently, is there a more direct way to show this fact?</p>\n\n\n\n<p>$(\\dagger)$: More explicitly, this is the vector space spanned by $A, B, i[A,B], [A,[A,B]], ...$</p>\n\n<p>[1] Lloyd 1995, <em>Almost Any Quantum Logic Gate is Universal</em>, <a href=\"https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.75.346\" rel=\"noreferrer\">Link to PRL</a>.</p>\n", "pids": ["58aba2a20cf2d213e937dfcc"], "flag": 1}
{"question": "How meaningful is the connection between MLE and cross entropy in deep learning?", "body": "<p>I understand that given a set of $m$ independent observations \n$\\mathbb{O}=\\{\\mathbf{o}^{(1)}, . . . , \\mathbf{o}^{(m)}\\}$\nthe <a href=\"http://www.deeplearningbook.org/contents/ml.html\" rel=\"noreferrer\">Maximum Likelihood Estimator</a> (or, equivalently, the MAP with flat/uniform prior) that identifies the parameters $\\mathbf{θ}$ that produce the model distribution  $p_{model}\\left(\\,\\cdot\\, ; \\mathbf{θ}\\right)$\nthat best matches those observations will be</p>\n\n<p>$$\\mathbf{θ}_{ML}(\\mathbb{O})= p_{model}\\left(\\mathbb{O}; \\mathbf{θ}\\right) = \\underset{\\mathbf{θ}}{\\arg\\max}‎‎\\prod_{i=1}^{m} p_{model}\\left(\\mathbf{o}^{(i)}; \\mathbf{θ}\\right)$$</p>\n\n<p>or, more conveniently</p>\n\n<p>$$\\mathbf{θ}_{ML}(\\mathbb{O})= \\underset{\\mathbf{θ}}{\\arg\\min}\\sum_{i=1}^{m} -\\log p_{model}\\left(\\mathbf{o}^{(i)}; \\mathbf{θ}\\right)$$</p>\n\n<p>and see the role that $\\mathbf{θ}_{ML}$ can play in defining a loss function for multi-class deep neural networks, in which $\\mathbf{θ}$ corresponds to the the network's trainable parameters (e.g., $\\mathbf{θ} = \\{\\mathbf{W}, \\mathbf{b}\\} )$ and the observations are the pairs of input activations $\\mathbf{x}$ and corresponding correct class labels $y \\in [1, k]$, $\\mathbf{o}^{(i)}$ = {$\\mathbf{x}^{(i)}, y^{(i)}$}, by taking </p>\n\n<p>$$p_{model}\\left(\\mathbf{o}^{(i)}; \\mathbf{θ}\\right) \\equiv p_{model}\\left(y^{(i)} | \\mathbf{x}^{(i)}; \\mathbf{θ}\\right)$$</p>\n\n<p><br/></p>\n\n<p>What I don't understand is how this relates to the so called \"cross entropy\" of the (vectorized) correct output, $\\mathbf{y}^{(i)}$, and the corresponding output activations of the network, $\\mathbf{a}(\\mathbf{x}^{(i)}; \\mathbf{θ})$\n$$H(\\mathbf{o}^{(i)}; \\mathbf{θ}) = -\\mathbf{y}^{(i)}\\cdot \\mathbf{log}\\,\\mathbf{a}(\\mathbf{x}^{(i)}; \\mathbf{θ})‎$$ \nthat is used in practice when measuring error/loss during training. There are several related issues:</p>\n\n<p><br/></p>\n\n<h3>Activations \"as probabilities\"</h3>\n\n<p>One of the steps in establishing the relationship between MLE and cross entropy is to use the output activations \"as if\" they are probabilities. But it's not clear to me that they are, or at least that they $all$ are.</p>\n\n<p>In calculating training error — specifically, in calling it a \"cross entropy loss\" — it is assumed that (after normalizing activations to sum to 1)</p>\n\n<p>$$p_{model}\\left(\\mathbf{o}^{(i)}; \\mathbf{θ}\\right) \\equiv a_{y^{(i)}}(\\mathbf{x}^{(i)}; \\mathbf{θ})\\tag{1}\\label{1}‎‎$$ </p>\n\n<p>or</p>\n\n<p>$$\\log p_{model}\\left(\\mathbf{o}^{(i)}; \\mathbf{θ}\\right) = \\log a_{y^{(i)}}(\\mathbf{x}^{(i)}; \\mathbf{θ})‎‎$$ </p>\n\n<p>so that we can write </p>\n\n<p>$$-\\log p_{model}\\left(\\mathbf{o}^{(i)}; \\mathbf{θ}\\right) = -\\mathbf{y}^{(i)}\\cdot \\mathbf{log}\\,\\mathbf{a}(\\mathbf{x}^{(i)}; \\mathbf{θ})‎\\tag{3}\\label{3}$$</p>\n\n<p>and thus</p>\n\n<p>$$\\mathbf{θ}_{ML}(\\mathbb{O})=\\underset{\\mathbf{θ}}{\\arg\\min}\\sum_{i=1}^{m} H(\\mathbf{o}^{(i)}; \\mathbf{θ})$$</p>\n\n<p>But while this certainly makes $a_{y^{(i)}}(\\mathbf{x}^{(i)}; \\mathbf{θ}_{ML})$ a probability (to the extent that anything is), it places no restrictions on the other activations. </p>\n\n<blockquote>\n  <p>Can the $\\mathbf{a}_{y^{(i)}}(\\mathbf{x}^{(i)}; \\mathbf{θ}_{ML})$ really be said to be PMFs in that case? Is there anything that makes the $a_{y^{(i)}}(\\mathbf{x}^{(i)}; \\mathbf{θ}_{ML})$ not in fact probabilities (and merely \"like\" them)?</p>\n</blockquote>\n\n<p><br/></p>\n\n<h3>Limitation to categorization</h3>\n\n<p>The crucial step above in equating MLE with cross-entropy relies entirely on the \"one-hot\" structure of $\\mathbf{y}^{(i)}$ that characterizes a (single-label) multi-class learning problem. Any other structure for the $\\mathbf{y}^{(i)}$ would make it impossible to get from $\\eqref{1}$ to $\\eqref{3}$.</p>\n\n<blockquote>\n  <p>Is the equation of MLE and cross-entropy minimization limited to cases where the $\\mathbf{y}^{(i)}$ are \"one-hot\"?  </p>\n</blockquote>\n\n<p><br/></p>\n\n<h3>Different training and prediction probabilities</h3>\n\n<p>During prediction, it is almost always the case that </p>\n\n<p>$$p_{model}\\left(y^{(i)} | \\mathbf{x}^{(i)}; \\mathbf{θ}\\right) \\equiv P\\left(\\underset{j\\in[1,k]}{\\arg\\max}\\,a_j(\\mathbf{x}^{(i)}; \\mathbf{θ}) = y^{(i)}\\right)\\tag{2}\\label{2}$$</p>\n\n<p>which results in correct prediction probabilities that are different from the probabilities learned during training unless it is reliably the case that</p>\n\n<p>$$a_{y^{(i)}}(\\mathbf{x}^{(i)}; \\mathbf{θ}_{ML}) = P\\left(\\underset{j\\in[1,k]}{\\arg\\max}\\,a_j(\\mathbf{x}^{(i)}; \\mathbf{θ}_{ML}) = y^{(i)}\\right)$$</p>\n\n<blockquote>\n  <p>Is this ever reliably the case? Is it likely at least approximately true? Or is there some other argument that justifies this equation of the <em>value</em> of the learned activation at the label position with the <em>probability that the maximum value</em> of learned activations occurs there?</p>\n</blockquote>\n\n<p><br/></p>\n\n<h3>Entropy and information theory</h3>\n\n<p>Even assuming that the above concerns are addressed and the activations are valid PMFs (or can <em>meaningfully</em> be treated as such), so that the role played by cross entropy in <em>computing</em> $\\mathbf{θ}_{ML}$ is unproblematic, it's not clear to me why it is helpful or meaningful to talk about the entropy of the $\\mathbf{a}(\\mathbf{x}^{(i)}; \\mathbf{θ}_{ML})$, since Shanon entropy applies to <a href=\"https://en.wikipedia.org/wiki/Variable-length_code#Uniquely_decodable_codes\" rel=\"noreferrer\">a specific kind of encoding</a>, which is not the one being used in training the network.</p>\n\n<blockquote>\n  <p>What role does information theoretic entropy play in interpreting the cost function, as opposed to simply providing a tool (in the form of cross entropy) for computing one (that corresponds to MLE)?</p>\n</blockquote>\n", "pids": ["599c797a601a182cd2641eda"], "flag": 1}
{"question": "Methods to work around the problem of missing data in machine learning", "body": "<p>Virtually any database we want to make predictions using machine learning algorithms will find missing values ​​for some of the characteristics.</p>\n\n<p>There are several approaches to address this problem, to exclude lines that have missing values ​​until they fill with the mean values ​​of the characteristics.</p>\n\n<p>I would like to use for a somewhat more robust approach, which would basically run a regression (or another method) where the dependent variable (Y) would be each of the columns that have missing values ​​but only with the rows of the table that contain all the data , and predict the missing values ​​with this method, complete the table by the table and move to the next 'column' with missing values ​​and repeat the method until everything is filled.</p>\n\n<p>But that gives me some doubts.</p>\n\n<p>Why any column start? I believe that the one with the smallest missing values ​​until the one with the most</p>\n\n<p>Is there any threshold of missing values ​​that is not worth trying to complete it? (for example, if this characteristic only has 10% of the values ​​filled would not it be more interesting to exclude it)</p>\n\n<p>Is there any kind of implementation in traditional packages or other methods that are robust to missings?</p>\n", "pids": ["55a4d173612c6b12aafaced6"], "flag": 1}
{"question": "Artificial neural networks EQUIVALENT to linear regression with polynomial features?", "body": "<p>I want to improve my understanding of neural networks and their benefits compared to other machine learning algorithms. My understanding is as below and my question is: </p>\n\n<p>Can you correct and supplement my understanding please? :)</p>\n\n<p>My understanding:</p>\n\n<p>(1) Artificial neural networks = A function, which predicts output values from input values. According to a Universal Approximation Theorem (<a href=\"https://en.wikipedia.org/wiki/Universal_approximation_theorem\" rel=\"noreferrer\">https://en.wikipedia.org/wiki/Universal_approximation_theorem</a>), you usually can have any possible (though it should behave well) prediction function, given enough neurons. </p>\n\n<p>(2) The same is true for linear regression, by taking polynomials of the input values as additional input values, since you can approximate (compare Taylor expansion) each function well by polynomials.</p>\n\n<p>(3) This means, that (in a sense, with respect to best possible outcomes), those 2 methods are equivalent. </p>\n\n<p>(4) Hence, their main difference lies in which method lends itself to better computational implementation. In other words, with which method can you find, based on training examples, faster good values for the parameters which eventually define the prediction function.</p>\n\n<p>I welcome any thoughts, comments and recommendations to other links or books to improve my thinking. </p>\n", "pids": ["5b67b4b917c44aac1c867e2f"], "flag": 1}
{"question": "Periods in history of statistics", "body": "<p>The history of many fields of science can be divided into a small number of time intervals that often begin with some important discovery.</p>\n\n<p>But I have never seen something similar in timeline of statistics.</p>\n\n<p>Obviously, there are some important dates that can be considered as starting points of a new period (Pascal+Fermat, Bayes, Pearson, Tukey,..).</p>\n\n<p>Can we at least very roughly divide history of statistics into small number of periods?\nNote that the only similar <a href=\"https://stats.stackexchange.com/questions/5115/most-famous-statisticians\">question</a> to this is related to only famous statisticians, not to periods in history.</p>\n", "pids": ["53e9b1c2b7602d9703c51335"], "flag": 1}
{"question": "Universal approximation theorem for convolutional networks", "body": "<p>The universal approximation theorem is a quite famous result for neural networks, basically stating that under some assumptions, a function can be uniformly approximated by a neural network within any accuracy.</p>\n\n<p>Is there some analogous result that applies to convolutional neural networks?</p>\n", "pids": ["5b1643ba8fbcbf6e5a9bc4d0", "5b3d98cc17c44a510f801f5e"], "flag": 1}
{"question": "Data augmentation on training set only?", "body": "<p>Is it common practice to apply data augmentation to training set only, or to both training and test sets?</p>\n", "pids": ["5c8fac7f4895d9cbc65a1e41"], "flag": 1}
{"question": "Is it &#39;fair&#39; to set a seed in a random forest regression to yield the highest accuracy?", "body": "<p>I have a random forest regression built using skl and I note that I yield different results based on setting the random seed to different values. </p>\n\n<p>If I use LOOCV to establish which seed works best, is this a valid method? </p>\n", "pids": ["6147fba55244ab9dcb1b538c", "53e9ada5b7602d97037a301f", "5e09a7cadf1a9c0c4167bc62"], "flag": 1}
{"question": "Can $\\sin(x)$ be used as activation in deep learning?", "body": "<p><span class=\"math-container\">$\\sin(x)$</span> seems to zero centered which is a desirable property for activation functions. Even the gradient won't vanish at any point. I am not sure if the oscillating nature of the function or its gradient can cause any issue during backpropagation.</p>\n", "pids": ["5a260c8617c44a4ba8a32488", "5eede0b091e0116a23aafaa5"], "flag": 1}
{"question": "Are there any theories using thermodynamics/statistical mechanics or information theory principles to modelling in ecology?", "body": "<p>So far, I've only known one: the MaxEnt theory. It uses the maximum information entropy developed by information theorist, which in turn inspired by the thermodynamics from physics, to predict the number of organism in an area. This theory is developed by John Harte. \nYou can read about this theory in <a href=\"https://www.quantamagazine.org/20140903-the-thermodynamic-theory-of-ecology/\" rel=\"noreferrer\">Quanta Magazine</a>.</p>\n\n<p>I also know the book Towards the Thermodynamics Theory for Ecological Systems, written by Jørgensen and Svirezhev.</p>\n\n<p>I find it hard to find another theory similar with the two theories above. Do you know any theories using the thermodynamics or information principles to modelling in ecology?</p>\n\n<p>I have opened a <a href=\"https://www.reddit.com/r/ecology/comments/3snb6p/are_there_any_theories_using_the_thermodynamics/\" rel=\"noreferrer\">reddit discussion</a> about this.</p>\n", "pids": ["53e999b4b7602d97021f7e96"], "flag": 1}
{"question": "When to check model assumptions", "body": "<p>Statistical methods are based on model assumptions. For example, an independent one-way ANOVA makes the following assumptions:</p>\n<ul>\n<li><p>Normally distributed residuals</p>\n</li>\n<li><p>Homogeneity of variance</p>\n</li>\n<li><p>Independence of observations</p>\n</li>\n</ul>\n<p>Whether or not these assumptions are met will influence the reliability of the independent one-way ANOVA’s results and the conclusions drawn from them (to varying degrees, depending on what assumptions are violated and how).</p>\n<p>My question is: <strong>When should we check the assumptions of our model? Is it preferable to first check model assumptions or inspect model fit? <em>How</em> might that influence the interpretations and decisions we make thereafter, and <em>why</em> might this be preferable to the other approach?</strong></p>\n<p>In the case of general linear models, we first need to fit our model, otherwise we cannot test whether the residuals are normally distributed. But immediately after that we could either choose to check model assumptions or inspect model fit.</p>\n<p>In particular I am interested in answers that speak to any of the following three approaches:</p>\n<ol>\n<li><p>The purpose of checking model assumptions is to decide whether the originally chosen test is appropriate for the data, so assumptions should be checked first. A different, more appropriate, test should be used if assumptions are violated, and conclusions should be drawn from this test. This approach is endorsed in textbooks (e.g., <a href=\"https://www.wiley.com/en-us/Statistics+for+Research%2C+3rd+Edition-p-9780471267355\" rel=\"noreferrer\">Dowdy et al., 2004</a>), and is also the one I’ve encountered in statistics courses I’ve taken.</p>\n</li>\n<li><p>The purpose of checking model assumptions is to assess the quality of the model we originally chose in light of our data, so assumptions should be checked second. Depending on the severity of violations, conclusions drawn from test results might be reigned in, or the model might be respecified. This seems to be the approach endorsed by Fisher (see <a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1111/joes.12200\" rel=\"noreferrer\">Spanos, 2017</a>).</p>\n</li>\n<li><p>Model assumptions are often violated in the real world, so there’s no need to check them. Instead we should choose better default tests that are less constrained and stick with those (e.g., Declare et al., <a href=\"https://www.rips-irsp.com/articles/10.5334/irsp.82/\" rel=\"noreferrer\">2017</a>, <a href=\"https://www.rips-irsp.com/articles/10.5334/irsp.198/\" rel=\"noreferrer\">2019</a>). This is also a popular approach, for example, see Section 4 in the Spanos, 2017 paper cited above.</p>\n</li>\n</ol>\n<p>This <a href=\"https://arxiv.org/pdf/1908.02218.pdf\" rel=\"noreferrer\">preprint</a> has some good discussion and examples comparing the performance of these approaches in different circumstances and with different tests. It concludes:</p>\n<blockquote>\n<p>“In some setups either running a less constrained test or running the model-based test without preliminary testing have been found superior to the combined procedure involving preliminary [assumption checking to guide test selection].” However, “a sober look at the results reveals that the combined procedures are almost always competitive with at least one of the unconditional tests, and often with them both. It is clear, though, that recommendations need to depend on the specific problem, the specific tests involved. Results often also depend on in what way exactly model assumptions of the model-based test are violated, which is hard to know without some kind of data dependent reasoning.”</p>\n</blockquote>\n<p>So the best performing approach depends on circumstances and the test used. However, if you were to pick one of the previously mentioned approaches as a general principle to follow when better information isn’t available, which would make the most preferable default?</p>\n<p>Please base your answers on experience or evidence.</p>\n", "pids": ["612349f35244ab9dcb60e994"], "flag": 1}
{"question": "Given a decomposition for a unitary $U$, how do you decompose the corresponding controlled unitary gate $C(U)$?", "body": "<p>Suppose we have a circuit decomposition of a unitary $U$ using some universal gate set (for example CNOT-gates and single qubit unitaries). Is there a direct way to write down the circuit of the corresponding controlled unitary $C_U$ using the same universal gate set?</p>\n\n<p>For example take $U=i Y = H X H X$, as a circuit:<br>\n<a href=\"https://i.stack.imgur.com/xGUVS.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/xGUVS.png\" alt=\"circuit for U\"></a></p>\n\n<p>We can replace the $X$ gates by $C_X$ (CNOT) gates to obtain $C_U$:<br>\n<a href=\"https://i.stack.imgur.com/UPq7u.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/UPq7u.png\" alt=\"circuit for CU\"></a></p>\n\n<p>This works because if the control qubit is in state $|0\\rangle$ the action on the target is $H^2=\\mathbb{I}$, while for $|1\\rangle$ it applies the circuit for $U$. For different $U$, in particular if it acts on several qubits, coming up with such a circuit might be cumbersome. Is there a recipe to obtain the circuit of $C_U$ given that you know how to build $U$?</p>\n", "pids": ["53e9afd3b7602d9703a237bc", "53e9ac0bb7602d97035ca140", "53e9a36db7602d9702c76acb"], "flag": 1}
{"question": "Advantage of simulating sparse Hamiltonians", "body": "<p>In @DaftWullie's answer to <a href=\"https://quantumcomputing.stackexchange.com/questions/3823/practical-implementation-of-hamiltonian-evolution\">this question</a> he showed how to represent in terms of quantum gates the matrix used as example in <a href=\"https://arxiv.org/pdf/1110.2232v2.pdf\" rel=\"noreferrer\">this article</a>. However, I believe it to be unlikely to have such well structured matrices in real life examples, therefore I was trying to look at other methods to simulate an Hamiltonian.\n I have found in several articles a reference to <a href=\"https://arxiv.org/pdf/quant-ph/0301023.pdf\" rel=\"noreferrer\">this one</a> by Aharonov and Ta-Shma in which, among other things they state that it is possible to have some advantage in simulating <em>sparse</em> hamiltonians. After reading the article, however, I haven't understood how the simulation of sparse hamiltonians could be performed. The problem is usually presented as one of graph coloring, however also looking at the <a href=\"https://www.cs.umd.edu/~amchilds/talks/ibm13.pdf\" rel=\"noreferrer\">presentation</a> that @Nelimee suggested to read to study matrix exponentiation, this all falls down the silmulation through product formula.</p>\n\n<p>To make an example, let's take a random matrix like:   </p>\n\n<p>$$\nA = \\left[\\begin{matrix}\n2 &amp;  0  &amp; 0 &amp; 0\\\\\n8  &amp;  5 &amp; 0 &amp; 6\\\\\n0 &amp; 0 &amp; 7 &amp; 0\\\\\n0 &amp; 5 &amp; 3 &amp; 4\n\\end{matrix}\\right];\n$$\n this is not hermitian, but using the suggestion from Harrow,Hassidim and Lloyd we can construct an hermitian matrix starting from it:</p>\n\n<p>$$\nC = \\left[ \\begin{matrix}\n0 &amp; A\\\\\nA^{\\dagger} &amp; 0\n\\end{matrix} \\right]\n =  \\left[\\begin{matrix}\n0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp;  0  &amp; 0 &amp; 0\\\\\n0 &amp; 0 &amp; 0 &amp; 0 &amp; 8  &amp;  5 &amp; 0 &amp; 6\\\\\n0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 7 &amp; 0\\\\\n0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 5 &amp; 3 &amp; 4\\\\\n2 &amp; 8 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\\n0 &amp; 5 &amp; 0 &amp; 5 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\\n0 &amp; 0 &amp; 7 &amp; 3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\\n0 &amp; 6 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\  \n\\end{matrix}\\right].\n$$</p>\n\n<p>Now that I have an 8x8, 2-sparse hermitian matrix:</p>\n\n<ul>\n<li>Can I simulate its evolution in other ways than the product formula method?</li>\n<li>Even if I use the product formula, how do I exploit the fact that it is sparse? Is it just because there are less non-zero entries and therefore it should be easier to find the product of basic gates?</li>\n</ul>\n", "pids": ["573698276e3b12023e6f91c9", "53e9a67cb7602d9702fad1fc"], "flag": 1}
{"question": "Data partitioning for spatial data", "body": "<p>I am constructing different configurations of a Random Forest in order to investigate the influence of well-design variables and location, on the first-year production volumes of shale oil wells, within a given area in the US. In the different model configurations, I control for location in different ways, to show how the influence of well-design variables may be biased when the spatial resolution of the models is inadequate. Here, location acts as a proxy for geological properties/reservoir quality.</p>\n\n<p>I have a dataset of ~4500 wells, with 6 variables. The response is the first-year production volume, and the predictors are three different well-design variables in addition to longitude and latitude.</p>\n\n<p>I have been researching and putting some thought into the subject of data partitioning when working with spatial data. For instance, in this chapter of \"Geocomputation with R\" by Lovelace et al. (<a href=\"https://geocompr.robinlovelace.net/spatial-cv.html\" rel=\"noreferrer\">https://geocompr.robinlovelace.net/spatial-cv.html</a>), they highlight the importance of spatial cross-validation: <em>\"Randomly splitting spatial data can lead to training points that are neighbors in space with test points. Due to spatial autocorrelation, test and training datasets would not be independent in this scenario, with the consequence that CV fails to detect possible overfitting. Spatial CV alleviates this problem and is the central theme of this chapter.\"</em></p>\n\n<p>Further, they illustrate how a spatial partitioning may differ from a random partitioning:\n<a href=\"https://i.stack.imgur.com/B31OC.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/B31OC.png\" alt=\"enter image description here\"></a></p>\n\n<p>...and show an example of how results may be positively biased if spatial data is split at random (this is the difference in AUC of a classification problem):\n<a href=\"https://i.stack.imgur.com/yNNG1.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/yNNG1.png\" alt=\"AUC under different CV-schemes\"></a></p>\n\n<p>The point is that due to spatial autocorrelation (near things are more related than distant things), you will end up with some observations in the training set that are very similar to observations in the test set if the proximity of observations is not accounted for when splitting the data. This may cause \"information leakage\" between the sets.</p>\n\n<p><strong>My question is,</strong> does this information leakage necessarily pose a problem? I figure that this and the similarity of observations is something that may just as well be representative of the problem at hand, and therefore make the performance assessment more representative of a real-life application of the model. I understand that a spatially disjoint test set yields a more representative performance assessment of your model if it should be used for predicting on a completely new and distant area. But if you want to assess a model's predictive performance with respect to a mix of near and distant locations, wouldn't a random split be more reasonable?</p>\n\n<p>Hoping for some input here, thanks!</p>\n\n<p><strong>Edit:</strong> After reaching out to the authors of the abovementioned book on Twitter, I was advised to check out the following lecture by Hanna Meyer: <a href=\"https://www.youtube.com/watch?v=mkHlmYEzsVQ\" rel=\"noreferrer\">https://www.youtube.com/watch?v=mkHlmYEzsVQ</a>. She makes a distinction between \"data reproduction\" and \"data prediction\" (at approximately 16:40 in the video). This is something that crossed my mind while initially writing this post; that I am not really applying these models for prediction, but rather using predictive models as a tool for investigating factors that influence well productivity. After watching the video, I have become more confident that this application is more like \"data reproduction\", where a random partitioning seems OK, rather than \"data prediction\".</p>\n", "pids": ["5a9cb63417c44a376ffb5dc4", "5db92b0047c8f76646219c44"], "flag": 1}
{"question": "Should the y-axis on a survival plot go from 0 to 100 even if the lines are all above 0.9?", "body": "<p>I am reviewing an article that includes a survival plot, with % survival on the y-axis and time on the x-axis. The y-axis goes from 0 to 100, but the two survival curves are both always above 90%.</p>\n<p>I can see reasons for changing the y-axis to (say) 80 to 100: It will be easier to distinguish the lines and easier to see just how they are.</p>\n<p>I can also see reasons for leaving it 0 to 100: It is clearer that the vast majority survive.</p>\n<p>I have read some similar debates about other types of plots, but not about survival plots. Is there a &quot;best practices&quot; here? Am I missing any good reasons to prefer one or the other?</p>\n", "pids": ["5dbec34c47c8f766462c32f5"], "flag": 1}
{"question": "Is there an intuition built on ansatz in VQE algorithm or is it more a trial and error approach?", "body": "<p>Variational Quantum Eigensolver is a popular algorithm in Quantum Computing. But the ansatz part is very tricky. I do not really understand if they are built on some intuition, according to hardware or something else; or if it was just a trial and error approach.</p>\n\n<p>What do you think about it?</p>\n", "pids": ["5c756be5f56def979842fdc7"], "flag": 1}
{"question": "Why is correlation only defined between two variables?", "body": "<p>I am an MBA student is taking statistics courses.</p>\n<p>Our statistics prof was teaching us about correlations in statistics. We learned about Pearson's Correlation of Coefficient which is defined as the correlation between only two variables.</p>\n<p>I am asked the prof if the correlation can be calculated between more than two variables and he said &quot;no&quot;. But I am struggling to understand why this is the case?</p>\n<p>For example: Hurricanes are correlated with Wind Speed, Hurricanes are also correlated with Temperature - Although I am not a meteorologist don't actually know if this is true (I just assumed this to show a point), we can see that in theory more than two variables can be correlated.</p>\n<p>Therefore, why do we only evaluate the correlation between two variables and not more than two variables?</p>\n", "pids": ["53e9a5e9b7602d9702f10e85", "5e621f3d91e01160711d6028"], "flag": 1}
{"question": "What&#39;s an example of building a circuit $U_f$ that implements a simple function $f$?", "body": "<p>I'd like to be able to program simple functions into simulators such as <a href=\"http://tph.tuwien.ac.at/~oemer/qcl.html\" rel=\"noreferrer\">QCL</a>.  I read that any function <span class=\"math-container\">$f$</span> can be implemented, but I don't know how to get say a unitary matrix that implements <span class=\"math-container\">$f$</span>.<br>\n<span class=\"math-container\">$\\newcommand{\\qr}[1]{|#1\\rangle}$</span>\nI think first I must figure out a function that mimics <span class=\"math-container\">$f$</span> in a reversible way.  I think that <span class=\"math-container\">$$U_f\\qr{x}\\qr{0} = \\qr{x}\\qr{0 \\oplus f(x)}$$</span> does it.  However, how do I implement this as a circuit?  Please give a simple example, if you would.</p>\n", "pids": ["599c795b601a182cd2633f80"], "flag": 1}
{"question": "Can quantum computing be profitable without quantum hardware?", "body": "<p>What are the fields/business ideas that a new business can work on within quantum computing that can be profitable if this business has no access to onboard quantum setups but can access the cloud-based quantum computing platforms? What are the problems it can work on that can be valuable to industry?</p>\n", "pids": ["573696056e3b12023e518319", "63bfb05e90e50fcafd66319e", "5b67b48817c44aac1c864638"], "flag": 1}
{"question": "Does a cointegration model exist for irregularly spaced time series?", "body": "<p>It isn't clear to me how to calculate cointegration with irregular time series (ideally using <a href=\"http://en.wikipedia.org/wiki/Johansen_test\">the Johansen test</a> with VECM).  My initial thought would be to regularize the series and interpolate missing values, although that may bias the estimation.</p>\n\n<p>Is there any literature on this subject?</p>\n", "pids": ["53e9acaeb7602d970368dfc9", "5f0e274a9fced0a24b4ba26d"], "flag": 1}
{"question": "Is Google&#39;s 72 qubit device better than D-Wave&#39;s machines, which feature more than 2000 qubits?", "body": "<p>Google recently announced the <em>Bristlecone</em> 72 qubit quantum computer.\nHowever, D-Wave already announced quantum computers featuring more than $2000$ qubits.</p>\n\n<p>Why is Google's new device newsworthy then? Is it better than D-Wave's machine in some respects? If so, how?</p>\n", "pids": ["56d86e85dabfae2eeee183cf", "55a6bc1565ce054aad735d34", "5c0f830cda562944ac8b7b85", "5550413045ce0a409eb39218", "56d8cd35dabfae2eee86320c"], "flag": 1}
{"question": "How to perform a fair coin toss experiment over phone?", "body": "<p>I was recently asked this question by my friend. Suppose the two individuals participating in a toss are not near each other, but could communicate over a telephone. How does one construct a fair coin toss experiment that is mutually agreeable to both of them? They can't agree on a function of quantities like the time or the telephone number, as these decide the winner a priori (before the experiment is conducted). </p>\n\n<p>I suggested they disconnect the call and try again; whoever manages to reach the other first is the winner. But the state machine involved here is a bit complicated to get the simple (0.5,0.5) probabilities.</p>\n\n<p>PS: They do not trust each other, so one of them can't toss a fair coin and convey its outcome to the other. Both of them throwing simultaneously also doesn't work, as the second person has the incentive to lie when they are communicating the results to each other.</p>\n", "pids": ["53e9b360b7602d9703e3d0a9"], "flag": 0}
{"question": "How to create quantum circuits from scratch", "body": "<p>I am doing self-study at the moment using primarily the book: Quantum Computing a Gentle Introduction by Eleanor Rieffel and Wolfgang Polak.</p>\n\n<p>Getting through the earlier chapters and exercises went quite well (fortunately the earlier chapters had plenty of examples), however I got stuck on the 5th chapter on quantum circuits. Although I understand the concepts the authors present, perhaps due to a lack of examples, I have trouble applying said concepts to the exercises. </p>\n\n<p>The exercises I have trouble with (and where I can't find a solution or thorough/ introductory explanation for) are the following:</p>\n\n<p><span class=\"math-container\">$\\\\$</span></p>\n\n<p><strong>Questions:</strong></p>\n\n<p>Design a circuit for creating:\n<span class=\"math-container\">$\\left| W_n \\right&gt; = \\frac{1}{\\sqrt{n}}(\\left| 0 \\dots 001 \\right&gt; + \\left| 0 \\dots 010 \\right&gt; + \\left| 0\\dots 100 \\right&gt;) + \\cdots + \\left| 1\\dots 000 \\right&gt;)$</span> from <span class=\"math-container\">$\\left| 0 \\dots 000 \\right&gt;$</span></p>\n\n<p>And design a circuit for creating \"the Hardy state\":\n<span class=\"math-container\">$\\frac{1}{\\sqrt{12}}(3\\left| 00 \\right&gt; + \\left| 01 \\right&gt; + \\left| 10 \\right&gt; + \\left| 11 \\right&gt;)$</span></p>\n\n<p><span class=\"math-container\">$\\\\$</span></p>\n\n<p>Can somebody point me in the right direction or refer me to some literature/ tutorials so I can grasp these kind of exercises better?</p>\n\n<p><span class=\"math-container\">$\\\\$</span></p>\n\n<p>Perhaps a related question:\n<a href=\"https://quantumcomputing.stackexchange.com/questions/6002/tips-and-tricks-for-constructing-circuits-to-generate-arbitrary-quantum-states\">Tips and tricks for constructing circuits to generate arbitrary quantum states</a></p>\n", "pids": ["53e9a5e9b7602d9702f163b4"], "flag": 1}
{"question": "What does &quot;bipartite&quot; mean?", "body": "<p>This is a really easy question, but my mother language is not English and I get confused quite a lot reading Preskill notes.</p>\n\n<p>What does a bipartite system mean? Is this just that it \"lives\" in a tensor product of two Hilbert spaces? Does it mean that the system is separable? I just want a clear definition of what bipartite means (without any other special conditions on it), so that I can know for sure. Thanks in advance!</p>\n", "pids": ["5ddba6863a55acfc7e1617e1"], "flag": 1}
{"question": "Is it possible to run a general implementation Shor&#39;s algorithm on a real IBM quantum computer at least for N = 15?", "body": "<p>I need to make a general implementation of Shor's algorithm that factors, at least, N = 15. I have been able to perform an implementation that works in simulators, with ProjectQ, but when running it on a real quantum computer. </p>\n\n<p>I have decided to try it using Qiskit. Currently, I'm trying to find the first implementations in Qiskit, to see if it's possible to do what I want because I already doubt it. </p>\n\n<p>I have tried, among others, whit <a href=\"https://github.com/ttlion/ShorAlgQiskit\" rel=\"noreferrer\">these implementations</a>. Also with IBM's <a href=\"https://github.com/Qiskit/qiskit-aqua/blob/master/qiskit/aqua/algorithms/single_sample/shor/shor.py\" rel=\"noreferrer\">own implementation</a>. But either they use too many qubits 4n+2, which for N = 15 would be 18 qubits, and the public quantum computer with more qubits has only 14, or they use several measurements in the same qubit, which is not supported by IBM quantum computers. Now, I just want to know if it is possible to do what I want with current computers and how. I have read many papers, but their conclusions and methods are not supported by the current publicly available quantum computers, or the maximum N that they can factor is less than 15.  </p>\n\n<p>Thank you in advance. Greetings.</p>\n", "pids": ["5ce2d20bced107d4c6494cd1"], "flag": 1}
{"question": "Is there a simple, formulaic way to construct a modular exponentiation circuit?", "body": "<p>I'm a newcomer to quantum computing and circuit construction, and I've been struggling to understand how to make a modular exponentiation circuit. From what I know, there are several papers on the matter (like Pavlidis, van Meter, Markov and Saeedi, etc.) but they are all so complicated and involve a lot of efficiency and optimization scheme that make it impossible for me to understand. When I read it in Nielsen and Chuang, specifically in Box 5.2 the author wrote them without any example, as if it is very easy to make (it probably is, but not for me).</p>\n\n<p>Anyway, I've learned about the algorithm to do modular exponentiation using binary representation (it's simple enough at least this thing), but I don't know how to make a circuit out of it. Here's the picture I believe describing the process:</p>\n\n<p><a href=\"https://i.stack.imgur.com/rtUhi.png\" rel=\"noreferrer\"><a src=\"https://i.stack.imgur.com/rtUhi.png\" alt=\"enter image description here\"></a></p>\n\n<p>So how do I build those <span class=\"math-container\">$U$</span> circuit? Can anyone, for example, tell me how do things changed when say I went from <span class=\"math-container\">$11^x (\\mod{15})$</span> to <span class=\"math-container\">$7^x (\\mod{21})$</span>? I don't care if the circuit is not gonna be optimized and contain thousands of gates, but I want to at least understand the first step before going into more advanced stuffs like optimization.</p>\n\n<p>Thank you very much!</p>\n", "pids": ["56d86816dabfae2eeeb061d5"], "flag": 1}
{"question": "Confusion related to difference of kriging and gaussian processes", "body": "<p>I am having a hard time understanding what is the difference between kriging and gaussian processes. I mean wiki says they are the same but their formulas for prediction are so different. </p>\n\n<p>I am a bit confused why they are called similar. Clarifications?</p>\n", "pids": ["5a260c8417c44a4ba8a31542"], "flag": 1}
{"question": "Where does precisely the difficulty in exponentiating a Hamiltonian $H$ in the quantum simulation problem lay?", "body": "<p>I've read in the Nielsen's, Chuang's \"Quantum Computation and Quantum Information\":</p>\n\n<blockquote>\n  <p>Classical simulation begins with the realization that in solving a simple differential equation such as <span class=\"math-container\">$dy/dt = f(y)$</span>, to first order, it is known that <span class=\"math-container\">$y(t + \\Delta t) \\approx y(t) + f (y)\\Delta t$</span>. Similarly, the quantum case is concerned with the solution of <span class=\"math-container\">$id|\\psi \\rangle/dt = H|\\psi \\rangle$</span>, which, for a time-independent <span class=\"math-container\">$H$</span>, is just <span class=\"math-container\">$$|\\psi(t)\\rangle = e^{-iHt}|\\psi(0)\\rangle.\\ \\ \\ \\ \\ \\ (4.96)$$</span>\n  Since H is usually extremely difficult to exponentiate (it may be sparse, but it is also\n  exponentially large), a good beginning is the first order solution <span class=\"math-container\">$|\\psi(t + \\Delta t)\\rangle \\approx (I − iH \\Delta t)|\\psi(t)\\rangle$</span>. This is tractable, because for many Hamiltonians <span class=\"math-container\">$H$</span> it is straightforward to compose quantum gates to efficiently approximate <span class=\"math-container\">$I − iH \\Delta t$</span>. However, such first order solutions are generally not very satisfactory.</p>\n  \n  <p>Efficient approximation of the solution to Equation (4.96), to high order, is possible for many classes of Hamiltonian. For example, in most physical systems, the Hamiltonian can be written as a sum over many local interactions. Specifically, for a system of <span class=\"math-container\">$n$</span> particles,\n  <span class=\"math-container\">$$ H = \\sum_{k=1}^L H_k,\\ \\ \\ \\ \\ \\ \\ (4.97)$$</span>\n  where each <span class=\"math-container\">$H_k$</span> acts on at most a constant c number of systems, and L is a polynomial in <span class=\"math-container\">$n$</span>. For example, the terms <span class=\"math-container\">$H_k$</span> are often just two-body interactions such as <span class=\"math-container\">$X_i X_j$</span> and one-body Hamiltonians such as <span class=\"math-container\">$X_i$</span>. [...] <strong>The important point is that although <span class=\"math-container\">$e^{−iHt}$</span> is difficult to compute, <span class=\"math-container\">$e^{−iH_kt}$</span> acts on a much smaller subsystem, and is straightforward to approximate, using quantum circuits.</strong></p>\n</blockquote>\n\n<p>This may be a silly question, but I'm stuck with this one. Does the difficulty of obtaining <span class=\"math-container\">$e^{-iHt}$</span> lies only in its size? Both <span class=\"math-container\">$e^{-iHt}$</span> and <span class=\"math-container\">$e^{-iH_kt}$</span> can be seen as matrices (of course, the first one is immensely larger than the latter one) and a Taylor series can be used to approximate both of them. This in turn boils down to just making a number of multiplications of <span class=\"math-container\">$H$</span> (with different coefficients standing by the consecutive matrices). So, it makes sense for a sparse matrix to be easier to obtain, because we just don't have to do a number of multiplications, which would at the end give 0. </p>\n\n<p>There are two things that come to my mind. First of which is a divide-and-conquer approach, where obtainment of <span class=\"math-container\">$e^{-iH_kt}$</span> is simple and all \"small\" results are combined to get a big one. In fact, I think that Trotterization is this kind of approach. The second thing is a guess, that maybe <span class=\"math-container\">$e^{-iH_kt}$</span> can be computed in some different way, than using Taylor series (it's a really wild guess)?</p>\n", "pids": ["5c7570a0f56def979870cb23", "5a73cbcc17c44a0b3035f48c"], "flag": 1}
{"question": "What is the relation between POVMs and observables (as Hermitian operators)?", "body": "<p>Let <span class=\"math-container\">$\\renewcommand{\\calH}{{\\mathcal{H}}}\\calH$</span> be a finite-dimensional Hilbert space.\nAn <em>observable</em> <span class=\"math-container\">$A$</span> is here a Hermitian operator, <span class=\"math-container\">$A\\in\\mathrm{Herm}(\\calH)$</span>.\nA <em>POVM</em> is here a collection of positive operators summing to the identity: <span class=\"math-container\">$\\{\\mu(a): a\\in\\Sigma\\}\\subset\\mathrm{Pos}(\\calH)$</span> such that <span class=\"math-container\">$\\sum_{a\\in\\Sigma} \\mu(a)=I$</span>, for some register <span class=\"math-container\">$\\Sigma$</span>.</p>\n<p>An observable <span class=\"math-container\">$A$</span> is given physical meaning via the mapping <span class=\"math-container\">$\\rho\\mapsto \\operatorname{Tr}(A\\rho)$</span> for any state <span class=\"math-container\">$\\rho$</span>, which gives us the <em>expectation value</em> of <span class=\"math-container\">$A$</span> on <span class=\"math-container\">$\\rho$</span>.\nOn the other hand, a POVM <span class=\"math-container\">$\\mu$</span> is given physical meaning interpreting <span class=\"math-container\">$\\Sigma$</span> as the set of possible <em>outcomes</em>, with the outcome <span class=\"math-container\">$a$</span> occurring with probability <span class=\"math-container\">$\\operatorname{Tr}(\\mu(a)\\rho)$</span>.</p>\n<p>A POVM is always a collection of observables, but not all collections of observables are POVMs.</p>\n<p>Intuitively, I understand the process of &quot;<em>measuring an observable <span class=\"math-container\">$A$</span></em>&quot; as tantamount to performing the (projective) POVM corresponding to the eigenvectors of <span class=\"math-container\">$A$</span>, then attaching numbers (the eigenvalues of <span class=\"math-container\">$A$</span>) to the corresponding outcomes, and obtaining the corresponding expectation value in the limit of many measurements.\nIn this sense, I would be led to say that POVMs are more &quot;fundamental&quot; than observables, in the sense that observables amount to measuring a POVM and then doing post-processing on the corresponding measurement results.</p>\n<p>On the other other hand, in several contexts observables, rather than POVMs, are given the spotlight. To name one example, we discuss the uncertainty principle in terms of observables, not in terms of POVMs.\nIn this sense, it seems like observables are generally regarded as &quot;more fundamental&quot;.</p>\n<p>In light of this, is there any general statement that can be made about the relations between observables and POVMs?\nShould they be regarded as simply incomparable ideas, or is there merit in thinking of observables as equivalent to post-processing of measurement (POVM) results? Or are there reasons to instead use observables as the primitive idea, and think of POVMs as simply special sets of observables?</p>\n<hr />\n<p><sup><em>While the title might one lead to believe this question is similar to <a href=\"https://quantumcomputing.stackexchange.com/q/15630/55\">this other one</a> I asked previously, the questions are really completely different; the apparent similarity is due to the different possible meanings of the term &quot;observable&quot; in different contexts.</em></sup></p>\n", "pids": ["5f0e7fa69fced0a24b826d14", "53e9b365b7602d9703e464a1"], "flag": 1}
{"question": "Quantum walk with binary tree", "body": "<p>I’m trying to grok quantum walks, and would like to create an example that walks a perfect binary tree to find the one and only marked leaf node. Is this possible? If so, suppose the depth of the tree is five. Would that require a circuit with five wires? Would it best be realized with a Discrete Time Quantum Walk, flipping a Hadamard Coin five times? Regardless of whether these questions are on the right track, and although I’ve read a lot of papers on the subject, I’m currently at a loss for how to implement what I’ve described. Any concrete pointers?</p>\n", "pids": ["56d83a7fdabfae2eee5c70e1", "599c7a3c601a182cd269f78a", "5c75714bf56def979876f186"], "flag": 1}
{"question": "Do women statistically have better multitasking ability than men?", "body": "<p>I hear this very often, while woman can do several things at a time. If this is true, what are the <em>qualifications</em> that make woman capable of doing several things at once?</p>\n\n<p>A quick Google search returned an obviously popular book;</p>\n\n<p><a src=\"https://i.stack.imgur.com/R7Iju.jpg\" alt=\"enter image description here\"></p>\n\n<p>However, I haven't read it and I'm not planning to. Plans may change if this gets interesting though.</p>\n\n<p>Are there any evidence that support the idea/ theory?</p>\n", "pids": ["56264b900cf2a1d82217f1d5"], "flag": 1}
{"question": "Suggestions for cost-sensitive learning in a highly imbalanced setting", "body": "<p>I have a dataset with a few million rows and ~100 columns.\nI would like to detect about 1% of the examples in the dataset, which belong to a common class. I have a minimum precision constraint, but due to very asymmetric cost I am not too keen on any particular recall (as long as I am not left with 10 positive matches!)</p>\n\n<p>What are some approaches that you would recommend in this setting? (links to papers welcome, links to implementations appreciated)</p>\n", "pids": ["623b03905aee126c0fb7fdea"], "flag": 1}
{"question": "Nutrient limitation in terrestrial and freshwater ecosystems", "body": "<p>In terms of primary production, it is often described in textbooks that nitrogen is the most limiting nutrient in terrestrial ecosystems, while phosphorus is the most limiting nutrient in freshwater ecosystems. What creates this difference?</p>\n", "pids": ["53e9a751b7602d9703087d37", "53e9b0d1b7602d9703b4c289"], "flag": 1}
{"question": "Does a plant have to have leaves to produce fruit?", "body": "<p>Is it possible that a plant can still produce fruit, even though it may not have leaves? Are there any plant species that can produce fruit without leaves?</p>\n", "pids": ["53e9b9b4b7602d97045a5672"], "flag": 1}
{"question": "Superconducting qubit researchers: Do your TLS&#39;s move?", "body": "<p>I have a superconducting system with tens of qubits, each of which can be tuned using DC flux.</p>\n\n<p>One of the main tasks for coherent manipulation of the qubits is to find good idling frequencies and operating points for entangling gates. This effort is confounded by two-level systems (TLS), which cause rapid energy relaxation, and wreak general havok on coherent manipulation.</p>\n\n<p>I spent a long time finding a good set of idling frequencies and operating points, all the while considering the locations of the TLS's, and then one day I came in the the lab and they had moved around! I had to start all over again.</p>\n\n<p>I want to learn more about how and why TLS's move, and whether it's possible to maybe control the movement. As part of my research, I want to poll the community and see what other people's experience with this problem is like.</p>\n", "pids": ["5d53dfe7a74a1962372e0a5a", "56d900ebdabfae2eeed6cfde"], "flag": 1}
{"question": "How could Majorana particles be used to improve quantum computers?", "body": "<p>This recent press release claiming that <a href=\"https://www.tue.nl/en/university/news-and-press/news/01-01-1970-improved-measurements-bring-final-proof-of-majorana-particles-closer-than-ever/\" rel=\"nofollow noreferrer\">Improved measurements bring final proof of Majorana particles closer than ever</a>, which summarizes the results of a recent paper in Nature simply entitled \"<a href=\"https://www.nature.com/articles/nature26142\" rel=\"nofollow noreferrer\">Quantized Majorana conductance</a>\" claims that </p>\n\n<blockquote>\n  <p>Thanks to their unique physical characteristics, Majorana particles are much more stable than most other qubits.</p>\n</blockquote>\n\n<p>Why would this be the case (in theory, at least). Is the approach to qubits with Majorana particles considered to be valid, or are they surrounded by skepticism?</p>\n", "pids": ["5c866e074895d9cbc65bd51e"], "flag": 1}
{"question": "Biased bootstrap: is it okay to center the CI around the observed statistic?", "body": "<p>This is similar to <a href=\"https://stats.stackexchange.com/questions/133864/bootstrap-estimate-is-outside-of-confidence-interval\">Bootstrap: estimate is outside of confidence interval</a></p>\n\n<p>I have some data that represents counts of genotypes in a population. I\nwant to estimate genetic diversity using Shannon's index and also\ngenerate a confidence interval using bootstrapping. I've noticed,\nhowever, that the estimate via bootstrapping tends to be extremely\nbiased and results in a confidence interval that lies outside of my\nobserved statistic.</p>\n\n<p>Below is an example.</p>\n\n<pre><code># Shannon's index\nH &lt;- function(x){\n  x &lt;- x/sum(x)\n  x &lt;- -x * log(x, exp(1))\n  return(sum(x, na.rm = TRUE))\n}\n# The version for bootstrapping\nH.boot &lt;- function(x, i){\n  H(tabulate(x[i]))\n}\n</code></pre>\n\n<p>Data generation</p>\n\n<pre><code>set.seed(5000)\nX &lt;- rmultinom(1, 100, prob = rep(1, 50))[, 1]\n</code></pre>\n\n<p>Calculation</p>\n\n<pre><code>H(X)\n\n## [1] 3.67948\n\nxi &lt;- rep(1:length(X), X)\nH.boot(xi)\n\n## [1] 3.67948\n\nlibrary(\"boot\")\ntypes &lt;- c(\"norm\", \"perc\", \"basic\")\n(boot.out &lt;- boot::boot(xi, statistic = H.boot, R = 1000L))\n\n## \n## CASE RESAMPLING BOOTSTRAP FOR CENSORED DATA\n## \n## \n## Call:\n## boot::boot(data = xi, statistic = H.boot, R = 1000)\n## \n## \n## Bootstrap Statistics :\n##     original     bias    std. error\n## t1*  3.67948 -0.2456241  0.06363903\n</code></pre>\n\n<p>Generating the CIs with bias-correction</p>\n\n<pre><code>boot.ci(boot.out, type = types)\n\n## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\n## Based on 1000 bootstrap replicates\n## \n## CALL : \n## boot.ci(boot.out = boot.out, type = types)\n## \n## Intervals : \n## Level      Normal              Basic              Percentile     \n## 95%   ( 3.800,  4.050 )   ( 3.810,  4.051 )   ( 3.308,  3.549 )  \n## Calculations and Intervals on Original Scale\n</code></pre>\n\n<p>Assuming that the variance of <em>t</em> can be used for the variance of <em>t0</em>.</p>\n\n<pre><code>norm.ci(t0 = boot.out$t0, var.t0 = var(boot.out$t[, 1]))[-1]\n\n## [1] 3.55475 3.80421\n</code></pre>\n\n<p>Would it be correct to report the CI centered around <em>t0</em>? Is there a\nbetter way to generate the bootstrap?</p>\n", "pids": ["53e9aa32b7602d970339f2eb"], "flag": 1}
{"question": "Can one interrogate black boxes for quantum coherence?", "body": "<p>This question is based on a scenario that is partly hypothetical and partly based on the experimental features of molecule-based quantum devices, which often present a quantum evolution and have some potential to be scalable, but are generally extremely challenging to characterize in detail (a relevant but not unique example is a series of works related to this <a href=\"http://science.sciencemag.org/content/344/6188/1135\" rel=\"noreferrer\">electrical control of nuclear spin qubits in single molecules</a>).</p>\n\n<p>The scenario: Let us say we have a variety of black boxes, each of which is are able to process information. We don't control the quantum evolution of the boxes; in the language of the quantum circuit model, we do not control the sequence of quantum gates. We know each black box is hardwired to a different algorithm, or, more realistically, to a different time-dependent Hamiltonian, including some incoherent evolution. We don't know the details of each black box. In particular, we don't know whether <strong>their quantum dynamics are coherent enough to produce a useful implementation of a quantum algorithm</strong> (let us herein call this \"<em>quantumness</em>\"; the lower bound for this would be \"it's distinguishable from a classical map\"). To work with our black boxes towards this goal, <strong>we only know how to feed them classical inputs and obtain classical outputs</strong>. Let us here distinguish between two sub-scenarios:</p>\n\n<ol>\n<li>We cannot perform entanglement ourselves: we employ product states as\ninputs, and single qubit measurements on the outputs. However, we can choose the basis of our input preparation and of our measurements (at minimum, between two orthogonal bases).</li>\n<li>As above, but we cannot choose the bases and have to worked on some fixed, \"natural\" base.</li>\n</ol>\n\n<p>The goal: to check, for a given black box, the <em>quantumness</em> of its dynamics. At least, for 2 or 3 qubits, as a proof-of-concept, and ideally also for larger input sizes.</p>\n\n<p>The question: in this scenario, is there a series of correlation tests, in the style of <a href=\"https://en.wikipedia.org/wiki/Bell&#39;s_theorem#Bell_inequalities\" rel=\"noreferrer\">Bell's inequalities</a>, which can achieve this goal?</p>\n", "pids": ["53e9b2dbb7602d9703d91ea1"], "flag": 1}
{"question": "Can ants lift 50 times their weight?", "body": "<p><a src=\"https://i.stack.imgur.com/aqFbo.jpg\" alt=\"enter image description here\"></p>\n\n<p>I've encountered this one many times over the years, mostly in those \"useless facts\" books and sites such as the one <a href=\"http://www.useless-facts.net/Insects-Spiders.html\" rel=\"noreferrer\">here</a>.  </p>\n\n<p>In fact, it's been one of those bits of trivia I seem to have unconsciously taken for granted as true, probably due to the sheer number of times I've heard it. It occurred to me though that while I've often heard the claim stated, I've never seen it proven.</p>\n\n<p><strong>Has it been scientifically proven that ants are capable of lifting 50 times their weight?</strong></p>\n\n<p>For the pedants:</p>\n\n<ol>\n<li>It doesn't matter what kind of ant</li>\n<li>We are assuming an otherwise healthy and normal ant (of any kind).</li>\n</ol>\n", "pids": ["56d81bc5dabfae2eee990d45"], "flag": 1}
{"question": "Resources for learning about multiple-target techniques?", "body": "<p>I am looking for resources (books, lecture notes, etc.) about techniques that can handle data that have multiple-targets (Ex: three dependent variable: 2 discrete and 1 continuous). </p>\n\n<p>Does anyone have any resources/knowledge on this? I know that it is possible to use neural networks for this.  </p>\n", "pids": ["56d8d87edabfae2eeedcb09e"], "flag": 1}
{"question": "What would be the simplest addition that would make the D-Wave architecture universal?", "body": "<p>The D-Wave system, as I understand it, allows us to program Ising models and to find their ground states. In this form, it is not universal for quantum computation: it can not simulate a circuit model quantum computer.</p>\n\n<p>What would be the simplest thing that could be done to make it universal? What are the reasons why such a thing has not been implemented?</p>\n", "pids": ["53e9a2c8b7602d9702bd0711", "59602f120cf2932415a54b50", "53e9a2c8b7602d9702bd0711"], "flag": 1}
{"question": "Why can&#39;t there be an error detecting code with fewer than 4 qubits?", "body": "<p>Essentially this boils down to: Is it possible to encode a single logical qubit in three physical qubits so that the resulting code has distance two?</p>\n<p>In other words, does a <span class=\"math-container\">$[\\![3,1,2]\\!]$</span> code exist?</p>\n<p>Comments:</p>\n<ul>\n<li><p>No <span class=\"math-container\">$[\\![3,1,2]\\!]$</span> stabilizer code exists. A simple argument is given for example below equation <span class=\"math-container\">$(14)$</span> in <a href=\"https://arxiv.org/abs/quant-ph/0512170\" rel=\"nofollow noreferrer\">this paper</a>. In general it shows that no <span class=\"math-container\">$[\\![2n+1,2n-1,2]\\!]$</span> stabilizer code exists.</p>\n</li>\n<li><p>No <span class=\"math-container\">$[\\![3,1,3]\\!]$</span>, <span class=\"math-container\">$[\\![3,2,2]\\!]$</span>, or <span class=\"math-container\">$[\\![2,1,2]\\!]$</span> code exists; this follows from the quantum singleton bound\n<span class=\"math-container\">$$\nn-k\\geq 2(d-1).\n$$</span></p>\n</li>\n<li><p>There is a well known <span class=\"math-container\">$[\\![4,2,2]\\!]$</span> stabilizer code with stabilizer <span class=\"math-container\">$ XXXX,ZZZZ $</span>. This is the smallest known quantum code with <span class=\"math-container\">$ d \\geq 2 $</span>.</p>\n</li>\n</ul>\n<p>This question is similar to <a href=\"https://quantumcomputing.stackexchange.com/questions/4798/why-cant-there-be-an-error-correcting-code-with-fewer-than-5-qubits/4832#4832\">Why can&#39;t there be an error correcting code with fewer than 5 qubits?</a>\nbut for <span class=\"math-container\">$ d=2 $</span> instead of <span class=\"math-container\">$ d=3 $</span>.</p>\n", "pids": ["53e9bddbb7602d9704a88a67", "5a260c8117c44a4ba8a30919", "558a96b5e4b0b32fcb37b202", "5a260c8117c44a4ba8a30919", "558a96b5e4b0b32fcb37b202"], "flag": 1}
{"question": "Good introductory material on quantum computational complexity classes", "body": "<p>I wish to learn more about computational complexity classes in the context of quantum computing. </p>\n\n<p>The medium is not so important; it could be a book, online lecture notes or the like. What matters the most are the contents. </p>\n\n<p>The material should cover the basics of quantum computational complexity classes and discuss the similarities, differences and relationships between them and perhaps also with classical computational complexity classes.</p>\n\n<p>I would prefer a rigorous treatment over an intuitive one. The author's style doesn't matter.</p>\n\n<p>As for prerequisites, I know next to nothing about the topic, so maybe more self-contained material would be better. That being said, I probably would not read a 1000 page book unless it was phenomenally good, anything in the range of 1-500 pages might work. </p>\n\n<p>As for availability, I would of course prefer material that is not behind a paywall of some sort and can be found online, but this is not a strict requirement.</p>\n\n<p>What do you recommend? </p>\n", "pids": ["5c7570a0f56def979870cb23"], "flag": 1}
{"question": "Has homeopathy ever passed a double-blind study?", "body": "<p>Has there ever been a double-blind study of homeopathy in which the null hypothesis was rejected?</p>\n\n<p>I'm not looking for a blanket validation. Just a single study where the null hypothesis (that there is no difference between homeopathy and placebo) was rejected.</p>\n", "pids": ["53e9bcb3b7602d9704934063", "53e99b63b7602d970240a783"], "flag": 1}
{"question": "Hamiltonian monte carlo", "body": "<p>Can someone explain the main idea behind Hamiltonian Monte Carlo methods and in which cases they will yield better results than Markov Chain Monte Carlo methods ?</p>\n", "pids": ["5c756bb4f56def979840eb49"], "flag": 1}
{"question": "Metropolis-Hastings integration - why isn&#39;t my strategy working?", "body": "<p>Assume I have a function $g(x)$ that I want to integrate\n$$ \\int_{-\\infty}^\\infty g(x) dx.$$\nOf course assuming $g(x)$ goes to zero at the endpoints, no blowups, nice function. One way that I've been fiddling with is to use the Metropolis-Hastings algorithm to generate a list of samples $x_1, x_2, \\dots, x_n$ from the distribution <em>proportional</em> to $g(x)$, which is missing the normalization constant \n$$N = \\int_{-\\infty}^{\\infty} g(x)dx $$ \nwhich I will call $p(x)$, and then computing some statistic $f(x)$ on these $x$'s:\n$$ \\frac{1}{n} \\sum_{i=0}^n f(x_i) \\approx \\int_{-\\infty}^\\infty f(x)p(x)dx.$$ </p>\n\n<p>Since $p(x) = g(x)/N$, I can substitute in $f(x) = U(x)/g(x)$ to cancel $g$ from the integral, resulting in an expression of the form\n$$ \\frac{1}{N}\\int_{-\\infty}^{\\infty}\\frac{U(x)}{g(x)} g(x) dx = \\frac{1}{N}\\int_{-\\infty}^\\infty U(x) dx.$$\nSo provided that $U(x)$ integrates to $1$ along that region, I should get the result $1/N$, which I could just take the reciprocal to get the answer I want. Therefore I could take the range of my sample (to most effectively use the points) $r = x_\\max - x_\\min $ and let $U(x) = 1/r$ for each sample I've drawn. That way $U(x)$ evaluates to zero outside of the region where my samples aren't, but integrates to $1$ in that region. So if I now take the expected value, I should get:\n$$E\\left [\\frac{U(x)}{g(x)}\\right ] = \\frac{1}{N} \\approx \\frac{1}{n} \\sum_{i=0}^n \\frac{U(x)}{g(x)}.  $$</p>\n\n<p>I tried testing this in R for the sample function $g(x) = e^{-x^2}$. In this case I do not use Metropolis-Hastings to generate the samples but use the actual probabilities with <code>rnorm</code> to generate samples (just to test). I do not quite get the results I am looking for. Basically the full expression of what I'd be calculating is:\n$$\\frac{1}{n(x_{\\max} - x_\\min)} \\sum_{i=0}^n \\frac{1}{ e^{-x_i^2}}. $$\nThis should in my theory evaluate to $1/\\sqrt{\\pi}$. It gets close but it certainly does not converge in the expected way, am I doing something wrong?</p>\n\n<pre><code>ys = rnorm(1000000, 0, 1/sqrt(2))\nr = max(ys) - min(ys)\nsum(sapply(ys, function(x) 1/( r * exp(-x^2))))/length(ys)\n## evaluates to 0.6019741. 1/sqrt(pi) = 0.5641896\n</code></pre>\n\n<p><strong>Edit for CliffAB</strong></p>\n\n<p>The reason I use the range is just to easily define a function that is non-zero over the region where my points are, but that integrates to $1$ on the range $[-\\infty, \\infty]$. The full specification of the function is:\n$$ U(x) = \\begin{cases} \\frac{1}{x_\\max - x_\\min} &amp; x_\\max &gt; x &gt; x_\\min \\\\ 0 &amp; \\text{otherwise.} \\end{cases} $$ \nI did not have to use $U(x)$ as this uniform density. I could have used some other density that integrated to $1$, for example the probability density \n$$ P(x) = \\frac{1}{\\sqrt{\\pi}} e^{-x^2}.$$\nHowever this would have made summing the individual samples trivial i.e.\n$$ \\frac{1}{n} \\sum_{i=0}^n \\frac{P(x)}{g(x)} = \\frac{1}{n} \\sum_{i=0}^n \\frac{e^{-x_i^2}/\\sqrt{\\pi}}{e^{-x_i^2} } = \\frac{1}{n} \\sum_{i=0}^n \\frac{1}{\\sqrt{\\pi}} = \\frac{1}{\\sqrt{\\pi}}.$$</p>\n\n<p>I could try this technique for other distributions that integrate to $1$. However, I would still like to know why it doesn't work for a uniform distribution. </p>\n", "pids": ["53e9a98eb7602d97032ec5e3", "61c712b75244ab9dcb11b631"], "flag": 1}
{"question": "How do you apply a CNOT on polarization qubits?", "body": "<p>I read that a qubit can be encoded in a <a href=\"https://en.wikipedia.org/wiki/Polarization_%28waves%29\" rel=\"nofollow noreferrer\">polarization state</a> (horizontal or vertical polarization of a photon). How do you perform two-qubit operations on a polarization qubit?</p>\n", "pids": ["53e9a35fb7602d9702c6c748"], "flag": 1}
{"question": "The Pros and Cons of Smoothing spline", "body": "<p>I have a general question. Recently I just learnt Basis Expansion and Regularization. There are several interesting techniques including: <strong>cubic spline, natural spline, b-spline and smoothing spline</strong>.</p>\n\n<p>The question is, what is the <strong>Pros and Cons</strong>(if there is any) of <strong>smoothing spline</strong> compared to the \"typical\" cubic and natural spline where users have to select the knots ?</p>\n\n<p>Well, generally it is stupid to just ask people which method is better without the context of the real problems. Thus I am just asking, based on your experiences, which one is better?</p>\n\n<p>One of the Pros I can see is: smoothing spline technique avoid selecting the knots. </p>\n", "pids": ["599c78ff601a182cd2609fad"], "flag": 1}
{"question": "Choosing the hyperparameters using T-SNE for classification", "body": "<p>In as specific problem that I work with (a competition) I have the follwoing setting: 21 features (numerical on [0,1]) and a binary output. I have approx 100 K rows. The setting seems to be very noisy.</p>\n\n<p>Me and other participants apply feature generation for a while and t-distributed stochastic neighbor embedding turned out to be rather powerful in this setting.</p>\n\n<p>I stumbled upon this <a href=\"http://distill.pub/2016/misread-tsne/\" rel=\"noreferrer\">post \"How to Use t-SNE Effectively\"</a> but still I can not really conclude on how to choose the hyperparameters best in my setting of classifcation.</p>\n\n<p>Are there any rules of thumb (number of features, dimension of embedding -> choice of perplexity)?</p>\n\n<p>I just apply ad-hoc settings at the moment as it takes too long to iterate various settings.\nThanks for any comments.</p>\n", "pids": ["5a260c8617c44a4ba8a32702"], "flag": 1}
{"question": "In CNN, are upsampling and transpose convolution the same?", "body": "<p>Both the terms \"upsampling\" and \"transpose convolution\" are used when you are doing \"deconvolution\" (&lt;-- not a good term, but let me use it here). Originally, I thought that they mean the same thing, but it seems to me that they are different after I read these articles. can anyone please clarify?</p>\n\n<ol>\n<li><p><strong>Transpose convolution</strong>: looks like we can use it when we propoagate the loss via convolutonal neural network.</p>\n\n<p><a href=\"http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/#Backward-Propagation\" rel=\"noreferrer\">http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/#Backward-Propagation</a></p>\n\n<p><a href=\"https://github.com/vdumoulin/conv_arithmetic\" rel=\"noreferrer\">https://github.com/vdumoulin/conv_arithmetic</a></p>\n\n<p><a href=\"https://arxiv.org/pdf/1312.6034v2.pdf\" rel=\"noreferrer\">https://arxiv.org/pdf/1312.6034v2.pdf</a>, section 4 \"For the convolutional layer...\"</p></li>\n<li><p><strong>Upsampling</strong>: seems like we use it when we want to upsample from smaller input to larger input in convnet-decovnet structure. </p>\n\n<p><a href=\"https://www.youtube.com/watch?v=ByjaPdWXKJ4&amp;feature=youtu.be&amp;t=22m\" rel=\"noreferrer\">https://www.youtube.com/watch?v=ByjaPdWXKJ4&amp;feature=youtu.be&amp;t=22m</a></p></li>\n</ol>\n", "pids": ["53e9b40eb7602d9703f04187"], "flag": 1}
{"question": "Why isn&#39;t &quot;Saddle-Free Newton&quot; descent algorithm used in practice?", "body": "<p>Recently I have read a paper by Yann Dauphin et al. <a href=\"https://papers.nips.cc/paper/5486-identifying-and-attacking-the-saddle-point-problem-in-high-dimensional-non-convex-optimization.pdf\" rel=\"noreferrer\"><em>Identifying and attacking the saddle point problem in high-dimensional non-convex optimization</em></a>, where they introduce an interesting descent algorithm called <strong>Saddle-Free Newton</strong>, which seems to be exactly tailored for neural network optimization and shouldn't suffer from getting stuck at saddle points like first order methods as vanilla SGD.</p>\n\n<p>The paper dates back into 2014, so it's nothing brand new, however, I haven't seen it being used \"in the wild\". Why is this method not being used? Is the Hessian computation too prohibitive for real world sized problems/networks? Is there even some open source implementation of this algorithm, possibly to be used with some of the major deep learning frameworks?</p>\n\n<p><strong>Update Feb 2019:</strong> there is an implementation available now: <a href=\"https://github.com/dave-fernandes/SaddleFreeOptimizer\" rel=\"noreferrer\">https://github.com/dave-fernandes/SaddleFreeOptimizer</a>)</p>\n", "pids": ["599c7983601a182cd26469e9"], "flag": 1}
{"question": "Why can RNNs with LSTM units also suffer from &quot;exploding gradients&quot;?", "body": "<p>I have a basic knowledge of how RNNs (and, in particular, with LSTMs units) work. I have a pictorial idea of the architecture of an LSTM unit, that is a cell and a few gates, which regulate the flow of values. </p>\n\n<p>However, apparently, I haven't fully understood how LSTM solves the \"vanishing and exploding gradients\" problem, which occurs while training, using back-propagation through time, a conventional RNN. I haven't had the opportunity to read the papers to fully understand the math.</p>\n\n<p><a href=\"https://stats.stackexchange.com/a/263956/82135\">This answer</a> gives a brief explanation of how RNNs with LSTM units solve the \"vanishing gradients\" problem. Mathematically, the reason seems to be the inexistence of a derivative which does not vanish, i.e. does not tend to zero. Consequently, the author states, \"there is at least one path where the gradient does not vanish\". IMHO, this explanation is a bit vague.</p>\n\n<p>Meanwhile, I was reading the paper <a href=\"https://arxiv.org/abs/1409.3215\" rel=\"noreferrer\">Sequence to Sequence Learning with Neural Networks</a> (by Ilya Sutskever, Oriol Vinyals, Quoc V. Le), and, in that paper, section \"3.4 Training details\", it is stated</p>\n\n<blockquote>\n  <p>Although LSTMs tend to not suffer from the vanishing gradient problem, they can have exploding gradients. </p>\n</blockquote>\n\n<p>I have always thought that RNNs with LSTM units solve both the \"vanishing\" and \"exploding gradients\" problems, but, apparently, RNNs with LSTM units also suffer from \"exploding gradients\". </p>\n\n<p>Intuitively, why is that? Mathematically, what are the reasons?</p>\n", "pids": ["5550413145ce0a409eb3929c"], "flag": 1}
{"question": "Are there connections between long-range entanglement and topological quantum computation?", "body": "<p>Long-range entanglement is characterized by topological order (some kinds of global entanglement properties), and the \"modern\" definition of topological order is <em>the ground state of the system cannot be prepared by a constant-depth circuit from a product state</em>, instead of ground states dependency and boundary excitations in traditional. Essentially, a quantum state which can be prepared by a constant-depth circuit is called <em>trivial state</em>. </p>\n\n<p>On the other hand, quantum states with long-range entanglement are \"robust\". One of the most famous corollaries of quantum PCP conjecture which proposed by Matt Hastings is the <em>No Low-energy Trivial States</em> conjecture, and the weaker case proved by Eldar and Harrow two years ago (i.e. NLETS theorem: <a href=\"https://arxiv.org/abs/1510.02082\" rel=\"nofollow noreferrer\">https://arxiv.org/abs/1510.02082</a>). Intuitively, the probability of a series of the random errors are exactly some log-depth quantum circuit are very small, so it makes sense that the entanglement here is \"robust\". </p>\n\n<p>It seems that this phenomenon is some kinds of similar to topological quantum computation. Topological quantum computation is robust for any local error since the quantum gate here is implemented by braiding operators which is connected to some global topological properties. However, it needs to point that <strong>\"robust entanglement\" in the NLTS conjecture setting only involved the amount of entanglement, so the quantum state itself maybe changed</strong> -- it does not deduce a quantum error-correction code from non-trivial states automatically. </p>\n\n<p>Definitely, long-range entanglement is related to homological quantum error-correction codes, such as the Toric code (it seems that it is related to abelian anyons). However, my question is that are there some connections between long-range entanglement (or \"robust entanglement\" in the NLTS conjecture setting) and topological quantum computation? \nPerhaps there exists some conditions regarding when the correspondent Hamiltonian can deduce a quantum error-correction code. </p>\n", "pids": ["53e9a223b7602d9702b2549b", "56d90113dabfae2eeed7decf", "5c757d2af56def9798ab23b0"], "flag": 1}
{"question": "Did humans almost become extinct about 70,000 years ago?", "body": "<p>I received this screenshot which is actually a post on Facebook by 8facts. It claims that humans nearly became extinct 70,000 years ago when the population sunk to 2,000. </p>\n\n<p><a src=\"https://i.stack.imgur.com/v2QqS.png\" alt=\"Screenshot of claim\"></p>\n\n<p>Is there any evidence that this claim is correct?</p>\n", "pids": ["53e9ada5b7602d97037a0e61"], "flag": 1}
{"question": "When will gradient descent converge to a critical point or to a local/global minima) for non-convex functions?", "body": "<p>What situations do we know of where gradient descent can be shown to converge (either to a critical point or to a local/global minima) for non-convex functions? </p>\n\n\n\n<p>For SGD on non-convex functions, one kind of proof has been reviewed here, \n<a href=\"http://www.cs.cornell.edu/courses/cs6787/2017fa/Lecture7.pdf\" rel=\"noreferrer\">http://www.cs.cornell.edu/courses/cs6787/2017fa/Lecture7.pdf</a> </p>\n", "pids": ["5aed148b17c44a4438154b0e"], "flag": 1}
{"question": "How can I calculate the inner product of two quantum registers of different sizes?", "body": "<p>I found an algorithm that can compute the distance of two quantum states. It is based on a subroutine known as swap test (a fidelity estimator or inner product of two state, btw I don't understand what fidelity mean).</p>\n\n<p>My question is about inner product. How can I calculate the inner product of two quantum registers which contains different number of qubits?</p>\n\n<p>The description of the algorithm is found in <a href=\"https://arxiv.org/abs/1804.10068\" rel=\"noreferrer\">this paper</a>. Based on the 3rd step that appear on the image, I want to prove it by giving an example.</p>\n\n<p>Let:\n$|a| = 5$, $|b| = 5 $, and $ Z = 50 $\n$$|a\\rangle = \\frac{3}{5}|0\\rangle + \\frac{4}{5}|1\\rangle$$  $$|b\\rangle = \\frac{4}{5}|0\\rangle + \\frac{3}{5}|1\\rangle\n$$\nAll we want is the fidelity of the following two states $|\\psi\\rangle$ and $|\\phi\\rangle$ and to calculate the distance between $|a\\rangle$ and $|b\\rangle$is given as:\n$ {|a-b|}^2 = 2Z|\\langle\\phi|\\psi\\rangle|^2$\nso \n$$|\\psi\\rangle = \\frac{3}{5\\sqrt{2}}|00\\rangle + \\frac{4}{5\\sqrt{2}}|01\\rangle+ + \\frac{4}{5\\sqrt{2}}|10\\rangle +  + \\frac{3}{5\\sqrt{2}}|11\\rangle$$\n$$|\\phi\\rangle = \\frac{5}{\\sqrt{50}} (|0\\rangle + |1\\rangle) $$\nthen how to compute \n$$\\langle\\phi|\\psi\\rangle = ??$$</p>\n", "pids": ["56d8d5fbdabfae2eeecbaa9a"], "flag": 1}
{"question": "Fine Tuning vs Joint Training vs Feature Extraction", "body": "<p>I am reading this paper <a href=\"http://zli115.web.engr.illinois.edu/wp-content/uploads/2016/10/0479.pdf\" rel=\"noreferrer\">http://zli115.web.engr.illinois.edu/wp-content/uploads/2016/10/0479.pdf</a></p>\n\n<p>It distinguishes between feature extraction and fine tuning in deep learning. I am not getting the difference as feature extraction is just the same as fine tuning:</p>\n\n<p>As per my understanding: </p>\n\n<p>You train a model on a dataset, use it for training on another dataset. This is fine tuning. This is the same as feature extraction from the first trained model, like in feature extraction also you take the first model and train it on a new dataset.</p>\n\n<p>Is there any difference between the two in the ml literature?</p>\n\n<p>Joint training is a third category I understand as there you train on all data simultaneously.</p>\n", "pids": ["57a4e91aac44365e35c97dc2", "57a4e91aac44365e35c97dc2"], "flag": 1}
